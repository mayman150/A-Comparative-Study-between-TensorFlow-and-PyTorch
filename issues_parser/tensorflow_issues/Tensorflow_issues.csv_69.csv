Issue Number,Issue Title,Issue Body
5792,I am having a problem when adding new op in tensorflow,"I just followed the tutorial when trying to add a new op in tensorflow
I would like to add a new op with which the file name is: rec_conv.cc
The code is like:(Input an tensor and just output a string)
```
#include ""tensorflow/core/framework/op.h""
#include ""tensorflow/core/framework/shape_inference.h""
#include ""tensorflow/core/framework/op_kernel.h""
using namespace tensorflow;
	
REGISTER_OP(""RecConv"")
    .Input(""input: int32"")
    .Output(""output: string"")
    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
      c->set_output(0, c->input(0));
      return Status::OK();
    });

class RecConvOp: public OpKernel{
 public:
	explicit RecConvOp(OpKernelConstruction* context): OpKernel(context){}

 void Compute(OpKernelContext* context) override {
	//const Tensor& input_tensor = context->input(0);
	Tensor* output_tensor = NULL;
	auto output = output_tensor->template scalar<string>();
	output() = ""Output is Rec_conv layer"";
 }
}
REGISTER_KERNEL_BUILDER(Name(""RecConv"").Device(DEVICE_CPU), RecConvOp);
```
-------------------------------------------------
The BUILD file is like:
```
load(""//tensorflow:tensorflow.bzl"", ""tf_custom_op_library"")

tf_custom_op_library(
    name = ""rec_conv.so"",
    srcs = [""rec_conv.cc""],
)
```
---------------------------------------------
However, when I run:
 bazel build -c opt //tensorflow/core/user_ops:rec_conv.so
Error occure like:
```
Server finished RPC without an explicit exit code

lixinyu@lixinyu-PC:~/tensorflow/tensorflow/tensorflow/core/user_ops$ bazel build -c opt //tensorflow/core/user_ops:rec_conv.so
...........
INFO: Found 1 target...
ERROR: /home/lixinyu/tensorflow/tensorflow/tensorflow/core/user_ops/BUILD:3:1: C++ compilation of rule '//tensorflow/core/user_ops:rec_conv.so' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-canonical-system-headers ... (remaining 57 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from tensorflow/core/user_ops/rec_conv.cc:3:0:
./tensorflow/core/framework/op_kernel.h:1097:7: error: expected initializer before 'registrar__body__1__object'
       registrar__body__##ctr##__object(                                 \
       ^
./tensorflow/core/framework/op_kernel.h:1093:3: note: in expansion of macro 'REGISTER_KERNEL_BUILDER_UNIQ'
   REGISTER_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, __VA_ARGS__)
   ^
./tensorflow/core/framework/op_kernel.h:1090:3: note: in expansion of macro 'REGISTER_KERNEL_BUILDER_UNIQ_HELPER'
   REGISTER_KERNEL_BUILDER_UNIQ_HELPER(__COUNTER__, kernel_builder, __VA_ARGS__)
   ^
tensorflow/core/user_ops/rec_conv.cc:32:1: note: in expansion of macro 'REGISTER_KERNEL_BUILDER'
 REGISTER_KERNEL_BUILDER(Name(""RecConv"").Device(DEVICE_CPU), RecConvOp);
 ^
./tensorflow/core/framework/op_kernel.h:1104:30: error: expected unqualified-id before ')' token
                             });
                              ^
./tensorflow/core/framework/op_kernel.h:1093:3: note: in expansion of macro 'REGISTER_KERNEL_BUILDER_UNIQ'
   REGISTER_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, __VA_ARGS__)
   ^
./tensorflow/core/framework/op_kernel.h:1090:3: note: in expansion of macro 'REGISTER_KERNEL_BUILDER_UNIQ_HELPER'
   REGISTER_KERNEL_BUILDER_UNIQ_HELPER(__COUNTER__, kernel_builder, __VA_ARGS__)
   ^
tensorflow/core/user_ops/rec_conv.cc:32:1: note: in expansion of macro 'REGISTER_KERNEL_BUILDER'
 REGISTER_KERNEL_BUILDER(Name(""RecConv"").Device(DEVICE_CPU), RecConvOp);
 ^
Target //tensorflow/core/user_ops:rec_conv.so failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 11.505s, Critical Path: 2.99s
lixinyu@lixinyu-PC:~/tensorflow/tensorflow/tensorflow/core/user_ops$ bazel build -c opt //tensorflow/core/user_ops:rec_conv.so
```
-----------------------------------------------------
Could anyone tell me what type of error it is like and how to debug it cuz I am wondering why there are so many warnings and error promped from the included header file

Thanks in advance
"
5790,Feature proposal: bilinear upsampling transposed convolution initialization.,"Hello,

I have been recently [implementing the FCN-32 network for image segmentation](http://warmspringwinds.github.io/tensorflow/tf-slim/2016/11/22/upsampling-and-image-segmentation-with-tensorflow-and-tf-slim/)
and found out that there is no bilinear upsampling op in Tensorflow or TF-slim.
That would be great if there will be an op that will do that, because that will make it
possible to bilinearly upsample blobs in a differentiable way or initialize upsampling
filter with bilinear kernel.

I have already implemented that and checked correctness.
You can see more if you follow the link. 
If you are interested, I can make a pull request.

Thank you. "
5789,Improve CUDA peer to peer access to support Amazon P2 instances,"If you try to run Tensorflow on a machine that has more than 8 GPU you will receive an error or Warning saying: CUDA_ERROR_TOO_MANY_PEERS.

From the Nvidia forums seems that this is documented behavior:

http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#peer-to-peer-memory-access

> Peer-to-peer memory access must be enabled between two devices by calling cudaDeviceEnablePeerAccess() as illustrated in the following code sample. Each device can support a system-wide maximum of eight peer connections.

TF is doing a full NxN peer access map, each 16x16 and that would explain the error on 16 gpus machines.

The challenge is figuring out which GPUs should peer with each other. 
 We do the full NxN right now since we don't yet have a better answer about the physical topology of the devices.  (E.g., how do you know that the first 8 are all physically the first die, and the second 8 are all physically the second die?)  If such an API exists and we can query it reliably, that might be a better solution.

All the code is in one file: gpu_device.cc

related Issues: 
- https://github.com/tensorflow/tensorflow/issues/5362"
5786,Gradients and variables was not shared in Adam optimizers when using bucketing,"All,

I used bucketing-like technology for seq2seq task:

```python
# For different length in encoder and decoder
model_map = {}
for i in encoder_shape:
    for j in decoder_shape:
        with variable_scope.variable_scope(variable_scope.get_variable_scope(),
                                 reuse=True if tt > 0 else None):
            model = Seq2SeqModel()
            model.build(encoder[:i], decoder[:j])
            model_map[i*100+j] = model
```
And get shared model's parameters:

```python
for t in tf.all_variables():
    print t.name, t.get_shape() 
```

```
Print: 
embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding:0 (50000, 256)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix:0 (1056, 1600)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias:0 (1600,)
```
Model's optimizer is like below:

```python
#every model have an optimizer
params = tf.trainable_variables()
opt = tf.train.AdamOptimizer(1e-3)
gradients = tf.gradients(self.loss, params)
self.optimizer = opt.apply_gradients(zip(gradients, params))
```
But I find that the optimizers don't share gradient:
```
embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding/Adam:0 (50000, 256)
embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding/Adam_1:0 (50000, 256)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix/Adam:0 (1056, 1600)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix/Adam_1:0 (1056, 1600)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias/Adam:0 (1600,)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias/Adam_1:0 (1600,)
embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding/Adam_2:0 (50000, 256)
embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding/Adam_3:0 (50000, 256)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix/Adam_2:0 (1056, 1600)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix/Adam_3:0 (1056, 1600)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias/Adam_2:0 (1600,)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias/Adam_3:0 (1600,)
```
With the growth of the number of buckets, the GPU memory will grow too. And meanwhile I get a larger model in tf.train.Saver.save().

So is it possible to share gradient in bucketing?





"
5785,tensorflow label_image recognize so slow,"I already asked [this question](http://stackoverflow.com/questions/40705203/tensorflow-label-image-recognize-so-slow?noredirect=1#comment68687966_40705203) on stackoverflow but It seems no one knows.

would you mind giving advices to make to code run faster.
Cause It took 5 second on laptop (30 seconds on pi 2) to recognize one picture of letter  

```
(tensorflow)khoa@khoa:~/tensorflow/tf_lv$ time python label_image.py photo1/9_9.jpg 
W tensorflow/core/framework/op_def_util.cc:332] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
t

real	0m2.344s
user	0m3.144s
sys	0m0.512s
```

"
5783,My tensorboard appears many undefined events and charts,"I only summary my loss as xentropy_mean in training ,but in tensorboard ,I had not find the xentropy_mean chart but many other charts I dont know. I don't know where I wrote wrong, and what's the matter indeed.
I wrote the inference(), training() and loss() in this file
`
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import math

import tensorflow.python.platform
import tensorflow as tf


NUM_CLASSES = 16


IMAGE_SIZE = 28
IMAGE_PIXELS = 784


def inference(images, hidden1_units, hidden2_units):




  with tf.name_scope('hidden1'):
    weights = tf.Variable(
        tf.truncated_normal([IMAGE_PIXELS, hidden1_units],
                            stddev=1.0 / math.sqrt(float(IMAGE_PIXELS))),
        name='weights')
    biases = tf.Variable(tf.zeros([hidden1_units]),
                         name='biases')
    hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)

  with tf.name_scope('hidden2'):
    weights = tf.Variable(
        tf.truncated_normal([hidden1_units, hidden2_units],
                            stddev=1.0 / math.sqrt(float(hidden1_units))),
        name='weights')
    biases = tf.Variable(tf.zeros([hidden2_units]),
                         name='biases')
    hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)

  with tf.name_scope('softmax_linear'):
    weights = tf.Variable(
        tf.truncated_normal([hidden2_units, NUM_CLASSES],
                            stddev=1.0 / math.sqrt(float(hidden2_units))),
        name='weights')
    biases = tf.Variable(tf.zeros([NUM_CLASSES]),
                         name='biases')
    logits = tf.matmul(hidden2, weights) + biases
  return logits


def loss(logits, labels):
 
  batch_size = tf.size(labels)
  labels = tf.expand_dims(labels, 1)
  indices = tf.expand_dims(tf.range(0, batch_size), 1)
  concated = tf.concat(1, [indices, labels])
  print('Done2')
  onehot_labels = tf.sparse_to_dense(
      concated, tf.pack([batch_size, 16]), 1.0, 0.0)
  print('Done1')
  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits,
                                                          onehot_labels,
                                                          name='xentropy')
  loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')
  
  return loss


def training(loss, learning_rate):
  tf.summary.scalar(loss.op.name, loss)
  optimizer = tf.train.GradientDescentOptimizer(learning_rate)
  global_step = tf.Variable(0, name='global_step', trainable=False)
  train_op = optimizer.minimize(loss, global_step=global_step)

  return train_op


def evaluation(logits, labels):
  

  correct = tf.nn.in_top_k(logits, labels, 1)
  return tf.reduce_sum(tf.cast(correct, tf.int32))
`

and training process in this file

`from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import os.path
import sys
import time
import numpy as np

import tensorflow as tf

import mnist





TRAIN_FILE = 'train.tfrecords'
VALIDATION_FILE = 'validation.tfrecords'
TEST_FILE='test.tfrecords'


flags = tf.app.flags
FLAGS = flags.FLAGS

flags.DEFINE_string('train_dir', '/home/queenie/image2tfrecord/tfrecords-28-gray/', 'Directory to put the training data.')
flags.DEFINE_string('filename', 'train.tfrecords', 'Directory to put the training data.')
flags.DEFINE_integer('batch_size', 100, 'Batch size.  '
                     'Must divide evenly into the dataset sizes.')
flags.DEFINE_integer('num_epochs', None, 'Batch size.  '
                     'Must divide evenly into the dataset sizes.')
flags.DEFINE_integer('hidden1', 128,'balabala')
flags.DEFINE_integer('hidden2', 32,'balabala')
flags.DEFINE_integer('learning_rate', 0.01,'balabala')
flags.DEFINE_integer('max_steps', 50000,'balabala')


def placeholder_inputs(batch_size):
  images_placeholder=tf.placeholder(tf.float32,shape=(batch_size,mnist.IMAGE_PIXELS))
  labels_placeholder=tf.placeholder(tf.int32,shape=(batch_size))
  return images_placeholder,labels_placeholder

def fill_feed_dict(images_feed,labels_feed,images_pl,labels_pl):
  
  feed_dict={
  images_pl:images_feed,
  labels_pl:labels_feed,
  }
  return feed_dict

def read_and_decode(filename_queue):
  reader = tf.TFRecordReader()
  _, serialized_example = reader.read(filename_queue)
  features = tf.parse_single_example(
      serialized_example,
      # Defaults are not specified since both keys are required.
      features={
          'image_raw': tf.FixedLenFeature([], tf.string),
          'label': tf.FixedLenFeature([], tf.int64),
      })


  image = tf.decode_raw(features['image_raw'], tf.uint8)
  image.set_shape([mnist.IMAGE_PIXELS])

 

 
  image = tf.cast(image, tf.float32) * (1. / 255) - 0.5

  label = tf.cast(features['label'], tf.int32)

  return image, label


def do_eval(sess,eval_correct):
	true_count=0
	for step in xrange(FLAGS.batch_size):
		#print(sess.run(eval_correct))
		true_count+=sess.run(eval_correct)

	precision=float(true_count)/FLAGS.batch_size/FLAGS.batch_size
	print('  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f' %
(FLAGS.batch_size, true_count, precision))
	return precision


def inputs(train, batch_size, num_epochs):

  if not num_epochs: num_epochs = None
  if train=='train':
  	filename=os.path.join(FLAGS.train_dir,TRAIN_FILE)
  elif train=='validation':
  	filename=os.path.join(FLAGS.train_dir,VALIDATION_FILE)
  else:
  	filename=os.path.join(FLAGS.train_dir,TEST_FILE)


 
  with tf.name_scope('input'):
    filename_queue = tf.train.string_input_producer(
        [filename], num_epochs=None)
    image, label = read_and_decode(filename_queue)
    images, sparse_labels = tf.train.shuffle_batch(
        [image, label], batch_size=batch_size, num_threads=2,
        capacity=1000 + 3 * batch_size,
        
        min_after_dequeue=1000)

    return images, sparse_labels


def run_training():
  with tf.Graph().as_default():
    images, labels = inputs(train='train', batch_size=FLAGS.batch_size,
                            num_epochs=FLAGS.num_epochs)

    images_valid,labels_valid=inputs(train='validation', batch_size=FLAGS.batch_size,
                             num_epochs=FLAGS.num_epochs)
    
    images_test,labels_test=inputs(train='test', batch_size=FLAGS.batch_size,
                             num_epochs=FLAGS.num_epochs)

    logits = mnist.inference(images,
                             FLAGS.hidden1,
                             FLAGS.hidden2)
    

    valid_prediction=mnist.inference(images_valid,FLAGS.hidden1,FLAGS.hidden2)

    test_prediction=mnist.inference(images_test,FLAGS.hidden1,FLAGS.hidden2)



    loss = mnist.loss(logits, labels)

    
    train_op = mnist.training(loss, FLAGS.learning_rate)

    eval_correct=mnist.evaluation(logits,labels)

    eval_correct_valid=mnist.evaluation(valid_prediction,labels_valid)

    eval_correct_test=mnist.evaluation(test_prediction,labels_test)

    summary_op=tf.merge_all_summaries()
   
    init_op = tf.group(tf.initialize_all_variables(),
                       tf.initialize_local_variables())

    saver = tf.train.Saver()
    sess = tf.Session()

    
  
    sess.run(init_op)

    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph)


    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(sess=sess, coord=coord)

    try:
      step = 0
      train_precision=0
      validation_precision=0
      test_precision=0
      #while not coord.should_stop():
      while not coord.should_stop():
        start_time = time.time()

     
        _, loss_value,images_see,labels_see = sess.run([train_op, loss,images,labels])

        duration = time.time() - start_time


       
        if step % 100 == 0:
          print('Step %d: loss = %.2f (%.3f sec)' % (step, loss_value,
                                                     duration))
          precision_tr=do_eval(sess,eval_correct)
          summary_str=sess.run(summary_op)
          summary_writer.add_summary(summary_str,step)
    


        if (step + 1) % 1000 == 0 or (step + 1) == FLAGS.max_steps:
          checkpoint_file = os.path.join(FLAGS.train_dir, 'model.ckpt')
          saver.save(sess, checkpoint_file, global_step=step)
          print('Train:')
          do_eval(sess,eval_correct)
          print('Validation:')
          do_eval(sess,eval_correct_valid)
          print('Test:')
          do_eval(sess,eval_correct_test)
        

        step += 1

    except tf.errors.OutOfRangeError:
      print('Done training for %d epochs, %d steps.' % (FLAGS.num_epochs, step))
    finally:
      coord.request_stop()

   
    coord.join(threads)
    sess.close()


run_training()
`

and the tensorboard is as the picture

![2016-11-22 20-43-03](https://cloud.githubusercontent.com/assets/11943769/20524207/53013746-b0f4-11e6-8f25-d8ae5d80b27f.png)

"
5782,model/rnn/translate reads the data model after creating network,"The translate module reads the data files after creating the network, this leads to long waits if there are problems in the data files. 

I have moved the read file section forward in my branch 
https://github.com/h4ck3rm1k3/tensorflow/commit/62d46a3b8687e0b7d5e37320b545ffe63a9361a1#diff-4dada032ac312625f74be392b009cc00R152"
5781,"ImportError: cannot import name pywrap_tensorflow, not resolved by previous fixes","I'm getting an error similar to that in #3217, but it's not resolved by switching directories or adding the lines to my bash profile. I'm using a jupyter notebook. Any suggestions?
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-577-fd66eeda4fb7> in <module>()
      2 import pandas as pd
      3 import scipy as sp
----> 4 import tensorflow as tf
      5 import sklearn.preprocessing as Preprocessing
      6 from sklearn.preprocessing import Imputer

/Users/curr_user/anaconda/lib/python2.7/site-packages/tensorflow/__init__.py in <module>()
     21 from __future__ import print_function
     22 
---> 23 from tensorflow.python import *

/Users/curr_user/anaconda/lib/python2.7/site-packages/tensorflow/python/__init__.py in <module>()
     46 _default_dlopen_flags = sys.getdlopenflags()
     47 sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)
---> 48 from tensorflow.python import pywrap_tensorflow
     49 sys.setdlopenflags(_default_dlopen_flags)
     50 

ImportError: cannot import name pywrap_tensorflow"
5780,freeze_graph error,"Hi there,
I'm using Python 2.7.6, I have the following errors with freeze_graph:
 python tensorflow/python/tools/freeze_graph.py --input_graph=/tmp/imagenet/classify_image_graph_def.pb --input_checkpoint=/home/davide/stmp/flowers-models/inception_v3/all/model.ckpt-500 --output_graph=/tmp/frozen_graph.pb --output_node_names=softmax
Traceback (most recent call last):
  File ""tensorflow/python/tools/freeze_graph.py"", line 137, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""tensorflow/python/tools/freeze_graph.py"", line 134, in main
    FLAGS.output_graph, FLAGS.clear_devices, FLAGS.initializer_nodes)
  File ""tensorflow/python/tools/freeze_graph.py"", line 100, in freeze_graph
    text_format.Merge(f.read().decode(""utf-8""), input_graph_def)
  File ""/usr/lib/python2.7/encodings/utf_8.py"", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xbb in position 1: invalid start byte


Any idea?
Thanks"
5779,[TensorFlow Mechanics 101]: Add conv layers to this tutorial,"It seems the tutorial in **TensorFlow Mechanics 101** has more beautiful structure in coding, and as it currently only contains fully connected layers. Is it a good addition to include conv layers ? If so, please leave a short comment and I'll submit a pull request soon. "
5777,GPU becomes unavailable after computer wakes up ,"I noticed many have issues with GPU being unavailable with message (e.g., [issue 394](https://github.com/tensorflow/tensorflow/issues/394))

`E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_UNKNOWN
` 
some suggested `sudo apt-get install nvidia-modprobe`  but it does not work for all including me. my GPU works until i put the computer to sleep/suspense, but after waking up the computer i always get the message above and the GPU (gtx 1070) is no longer available in execution of the code (only CPU is used) in nvidia docker.  I also noticed if prior to suspending the computer i exit the docker and then restart it when i wake the computer the GPU is still available in docker. So, the problem happens if i suspend the computer while the ipython-notebook session is up and running. 

I am using nvidia-docker 

`nvidia-docker run -it -p 8888:8888 -v /*..../Data/docker:/docker --name TensorFlow   gcr.io/tensorflow/tensorflow:latest-gpu /bin/bash`

Nvidia-smi and nvidia-debugdump -l both show the GPU is installed and driver is up to date within docker and in the host. 

when i run nvidia-smi in docker the output is 

+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.57                 Driver Version: 367.57                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1070    Off  | 0000:01:00.0      On |                  N/A |
|  0%   41C    P0    39W / 180W |    450MiB /  8105MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+

                                                                               


```
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_UNKNOWN
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving CUDA diagnostic information for host: ca234sff235
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: ca234sff235
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: 367.57.0
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.57  Mon Oct  3 20:37:01 PDT 2016
GCC version:  gcc version 4.9.3 (Ubuntu 4.9.3-13ubuntu2) 
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 367.57.0
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:293] kernel version seems to match DSO: 367.57.0
```

Software specs:
OS: Ubuntu 16.04 LTS - 64 bit
GPU driver: nvidia 367.57
Cuda : 7.5"
5776,Unknown events logged while profiling TensorFlow code using Timeline API,"I am seeing Unknown events being logged in the Trace logs using APIs from Timeline.py module. Is this a known issue and any ideas on how this could be fixed? I could not find any references to this issue on GITHUB or StackOverFlow.

Here is couple of examples of ""Unknown"" events:

       {
            ""name"": ""MEMCPYHtoD"",
            ""ph"": ""X"",
            ""ts"": 19926542594074346,
            ""cat"": ""Op"",
            ""args"": {
                ""name"": ""unknown"",
                ""op"": ""MEMCPYHtoD""
            },
            ""pid"": 715,
            ""tid"": 0,
            ""dur"": 12535
        },

        {
            ""tid"": 0,
            ""ph"": ""X"",
            ""name"": ""unknown"",
            ""pid"": 63,
            ""cat"": ""Op"",
            ""args"": {
                ""op"": ""unknown"",
                ""name"": ""unknown""
            },
            ""ts"": 19926135764459654,
            ""dur"": 1147
        },


Operating System: CentOS
Installed version of CUDA and cuDNN: 
Cuda 7.5 , cuDNN 5.1.3
TensorFlow version 0.10 and 0.11 rc0
"
5775,Link to tutorial pages broken,"Hi,

It seems every links to tutorial pages like http://tensorflow.org/tutorials/word2vec/index.md or http://tensorflow.org/tutorials/seq2seq/index.md are broken.

Source: https://github.com/tensorflow/tensorflow/blob/754048a0453a04a761e112ae5d99c149eb9910dd/tensorflow/models/rnn/README.md#L5

https://github.com/tensorflow/tensorflow/blob/754048a0453a04a761e112ae5d99c149eb9910dd/tensorflow/models/image/cifar10/README.md#L9"
5774,per_image_standardization is not recognized,"Hi, 
I installed Tensorflow with Python3 using the pip3 installation instructions from Tensorflow official site.
The version I installed is `0.11.0rc2` and I tried to use `per_image_standardization` tensor for normalization purposes. However it turned out that is not recognized, giving the following error:
```
AttributeError: module 'tensorflow.python.ops.image_ops' has no attribute 'per_image_standardization'
```
Has this error ever observed by someone else?"
5773,extract_image_patches zeros out data for large images,"I'm reading a large image (7128x5097 pixels) and generating patches with extract_image_patches. Depending on the patch size, some or all of the resulting image is zeroed out. Is there a limit on tensor size that it hits?

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
nothing relevant

### Environment info
Operating System: macOS Sierra 10.12.1

Installed version of CUDA and cuDNN: none

A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0-py2-none-any.whl
The output from python -c ""import tensorflow; print(tensorflow.__version__)"".
0.11.0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

The following code generates a random image, scales it up by a factor of 5, pulls a single pixel out of each patch, and writes an image with the result.

Expected behavior: an image of random pixels.
Observed behavior: for small images it works. But for the 5097x7129 image, N=3 works, N=5 gives a completely blank image, and N=7 is blank after the first 998 rows. (It's kind of strange that 7 works better than 5.)

    from __future__ import absolute_import
    from __future__ import print_function
    import tensorflow as tf
    N = 5 # Can try other numbers
    def main(_):
      img = tf.random_uniform([1, 5097, 7129, 3], minval=0, maxval=255, dtype=tf.int32)
      img = tf.cast(img, tf.uint8)
      patches = tf.extract_image_patches(img, [1, N, N, 1], [1, N, N, 1],
        [1, 1, 1, 1], ""SAME"")
      data = patches[0, :, :, 0:3]
    
      f = open('/tmp/img.png', 'w')
      init_op = tf.initialize_all_variables()
      with tf.Session() as sess:
        sess.run(init_op)
        f.write(tf.image.encode_png(data).eval())
      f.close()
    
    if __name__ == ""__main__"":
      tf.app.run()


### What other attempted solutions have you tried?
This is a simplified version of a larger image learning system, and I've cut it down to the problematic code. I've checked the values to make sure the problem is in extract_image_patches and not image_encode_png. The problem seems to happen if the tensor is big, so there's probably some size limit somewhere."
5772,could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM,"The version of cuda and cudnn meets the requirement, but still cannot use cudnn properly.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:
Linux version 3.16.0-30-generic (buildd@kissel) (gcc version 4.8.2 (Ubuntu 4.8.2-19ubuntu1) ) #40~14.04.1-Ubuntu

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root   558720 Sep 15 07:02 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Sep 15 07:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Sep 15 07:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root   415432 Sep 15 07:02 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Sep 15 07:02 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Nov 22 10:55 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Nov 22 10:55 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rw-r--r-- 1 root root 78065952 Nov 22 10:09 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 79337624 Nov 22 10:17 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Nov 22 10:17 /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide:

1. A link to the pip package you installed:
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
0.11.0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
when trying to call a function that is only supported by cudnn, for example conv2d
"
5771,"tf.with_dependencies isn't exposed, but it is used in documentations","There are some examples that uses tf.with_dependencies (ex. [tf.Assert in r0.11](https://www.tensorflow.org/versions/r0.11/api_docs/python/control_flow_ops.html#Assert)) but tf.with_dependencies isn't exposed to tensorflow module.

### Environment info
branch: master branch $ git rev-parse HEAD => c7edafccc

### If possible, provide a minimal reproducible example
```
$ python3 -c ""import tensorflow as tf; tf.with_dependencies()""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: module 'tensorflow' has no attribute 'with_dependencies'
```
Related: (https://github.com/tensorflow/tensorflow/blob/a4c8df209d7413068f4ed3e71c43eb798fbd5580/tensorflow/contrib/layers/python/layers/layers_test.py#L25)"
5770,Documentation of  tf.extract_image_patches is incomplete and slightly inaccurate,"Hi,

The documentation of [tf.extract_image_patches](https://www.tensorflow.org/versions/r0.9/api_docs/python/array_ops.html#extract_image_patches) is unclear and slightly incorrect. 

1. The function call requires the first 5 parameters to be set and throws an error otherwise.The documentation, however, mentions that they are optional parameters.
2. The ""out_rows"" and ""out_cols"" are not defined making it hard to make sense of what this function is actually doing. 
3. The definition of ""rates"" is not clear.. Is patch_size same as k_rows or k_cols?

Running
`test_patches = tf.extract_image_patches(images, padding=""SAME"",ksizes=[1, 32, 32, 1], strides=[1, 32, 32, 1], rates=[1,1, 1, 1])
`
where images = 1X299x299x3 returns me a tensor (test_patches) of shape 1x10x10x3072. 

1.Is test_patches[0,0,0,:] the first patch test_patches[0,0,1,:] the second patch and so on? 
2. If (1) is true, how was the dimension of a patch reduced from 32x32x3 to 3072, i.e., how exactly should this be reshaped? I tried reshaping test_patches[0,0,0,:] to (32,32,3) and (3,32,32) but the resulting image patch does not make sense. 

Clarifying the documentation of this method would be immensely helpful!

### Environment info
Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root   558720 Oct 22 01:37 /opt/cuda-8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Oct 22 01:37 /opt/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Oct 22 01:37 /opt/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 root root   415432 Oct 22 01:37 /opt/cuda-8.0/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Oct 22 01:37 /opt/cuda-8.0/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 79337624 Oct 22 01:48 /opt/cuda-8.0/lib64/libcudnn.so
-rwxr-xr-x 1 root root 79337624 Oct 22 01:48 /opt/cuda-8.0/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 79337624 Oct 22 01:48 /opt/cuda-8.0/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Oct 22 01:48 /opt/cuda-8.0/lib64/libcudnn_static.a

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
1f9e1eb186325dc789e7ea28aa5f7ef1e183f6b9
2. The output of `bazel version`

Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

Just calling this function would do.
"
5769,Misformatted documentation after constant_initializer,"The docs for constant_initializer fail to correctly close a code block in one of the examples.  As a result, many other sections are displayed in raw markdown.

See: https://www.tensorflow.org/versions/r0.11/api_docs/python/state_ops.html#constant_initializer"
5764,No OpKernel for DepthwiseConv2dNative,"When trying to run inference of tf graph by means of [benchmarking tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/benchmark), I'm getting error that indicates absence of [DepthwiseConv2dNative op](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/depthwise_conv_op.cc).

I'm building and running benchmark tool as it described in [Tensorflow Makefile](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile)

Run command:
`adb shell '/data/local/tmp/benchmark --graph=/data/local/tmp/optimized_inference_graph.pb --input_layer=""model/input_node:0"" --input_layer_shape=""1,256,256,3"" --input_layer_type=""float"" --output_layer=""output:0"" '`

I found this op as unsupported [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md). If it is related to this issue, I'm wondering if there is an upcoming patch to support this op? Or maybe there is a way to circumvent it?

Error log:
```
Could not create TensorFlow Session: Invalid argument: No OpKernel was registered to support Op 'DepthwiseConv2dNative' with these attrs.  Registered kernels:
  <no registered kernels>
	 [[Node: model/128to64/conv1/conv3x1x1/depthwise = DepthwiseConv2dNative[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1]](model/128to64/conv1/conv1x1xn/BatchNorm/batchnorm/add_1, model/128to64/conv1/conv3x1x1/depthwise_weights)]]
```
"
5763,The TensorFlow operation concat_offset is undocumented,"This shows up in some protocol buffers.  A vigorous search through the source code produced a short comment in some C++ code that gives some hints about its behaviour.  In particular, the word 'cumsum"" was used.  There appears to be, at times, a second output argument produced, although I have no idea what that could be except a copy of the first output.

A lot of searching turned up nothing useful.

TensorFlow version .11"
5762,BroadcastGradientArgs is used in protocol buffers but undocumented,"Not too much to say about this.  The op, having two outputs, is far from trivial to figure out from its usage.  It is used in a number of the early TensorFlow tutorials.

TensorFlow .11"
5761,Documentation for tf.strided_slice is nearly useless,"The documentation for this op could almost be used as a teaching moment for how to not document something.  In order to understand what it does, it is necessary to not only understand in detail how the related numpy op works, but also understand the mapping between the inputs of that op and the inputs of theTensorFlow op, that are totally different -- something that is far from obvious.

Just to ice the cake, the examples given in the document are for slice, not strided_slice...

Searches didn't turn up anything.  TF version is .11.  The machine and OS are not applicable."
5759,Error running ci_build.sh on docker container mac.,"When I run following command to test the ci_build on my mac

`$ tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/learn/...`

I get following error - 

WORKSPACE: /Users/<username>/tensorflow
CI_DOCKER_EXTRA_PARAMS:
COMMAND: bazel test //tensorflow/learn/...
CI_COMMAND_PREFIX: ./tensorflow/tools/ci_build/builds/with_the_same_user ./tensorflow/tools/ci_build/builds/configured cpu
CONTAINER_TYPE: cpu
BUILD_TAG: tf_ci
  (docker container name will be tf_ci.cpu)

Building container (tf_ci.cpu)...
Sending build context to Docker daemon 222.7 kB
Step 1 : FROM ubuntu:14.04
 ---> 4d44acee901c
Step 2 : MAINTAINER Jan Prach <jendap@google.com>
 ---> Using cache
 ---> 598ad93f9ec8
Step 3 : COPY install/*.sh /install/
 ---> Using cache
 ---> 2e90718bcd83
Step 4 : RUN /install/install_bootstrap_deb_packages.sh
 ---> Using cache
 ---> 785d8c4ecf96
Step 5 : RUN add-apt-repository -y ppa:openjdk-r/ppa &&     add-apt-repository -y ppa:mc3man/trusty-media &&     add-apt-repository -y ppa:george-edison55/cmake-3.x
 ---> Using cache
 ---> 8bbcbdd9d0e3
Step 6 : RUN /install/install_deb_packages.sh
 ---> Using cache
 ---> ddebcc57fb16
Step 7 : RUN /install/install_pip_packages.sh
 ---> Using cache
 ---> 3f6d70765a8b
Step 8 : RUN /install/install_bazel.sh
 ---> Using cache
 ---> c7e6bab7b915
Step 9 : RUN /install/install_proto3.sh
 ---> Using cache
 ---> 5c754e68ad21
Step 10 : RUN /install/install_buildifier.sh
 ---> Using cache
 ---> 348488be0193
Step 11 : RUN /install/install_auditwheel.sh
 ---> Using cache
 ---> 70ee410ea1cb
Step 12 : COPY install/.bazelrc /root/.bazelrc
 ---> Using cache
 ---> 75649c1f71be
Step 13 : ENV BAZELRC /root/.bazelrc
 ---> Using cache
 ---> 79809615d28e
Successfully built 79809615d28e
Running 'bazel test //tensorflow/learn/...' inside tf_ci.cpu...
id: illegal option -- -
usage: id [user]
       id -A
       id -F [user]
       id -G [-n] [user]
       id -M
       id -P [user]
       id -g [-nr] [user]
       id -p [user]
       id -u [-nr] [user]
id: illegal option -- -
usage: id [user]
       id -A
       id -F [user]
       id -G [-n] [user]
       id -M
       id -P [user]
       id -g [-nr] [user]
       id -p [user]
       id -u [-nr] [user]
dialout:x:20:
adduser: Only one or two names allowed"
5758,"Documentation and error messages for tf.tile, tf.constant leave a lot to be desired","I noticed that a protocol buffer did the equivalent of
    tf.tile( x, [] )
and wondered what that actually produced (the documentation was completely unhelpful).  So I tried
    x = tf.Variable([1.,2.,3.,4.])
    y = tf.tile(x,tf.constant(2))
to get started, and got the message ""ValueError: Shape () must have rank 1"".  So I tried
    y = tf.tile(x,tf.constant([2]))
and got the same message(!).  tf.rank(tf.constant([2])) of course returned the value 1, so the message made no sense at all to me.
In my struggle to get an acceptable empty tensor, I tried
    x = tf.constant(shape=[],dtype=""int32"")
This produced the memorable message ""TypeError: constant() takes at least 1 argument (2 given)""
I eventually discovered that tf.tile returns 1 copy of its tensor when the input is an empty list.  It would have been so helpful if the documentation would have just stated this fact...

Searching for tf.tile bugs produced a number of references to the documentation and a lot of hits relating to roofs.

My OS is Ubuntu 64-bit, TF version .11
"
5757,CPU slowdown with Quantized Eight bit graphs,"In attempts to highly optimize my Tensorflow client application (and TF install) for consumer desktop hardware i've noticed (and noticed in other bug reports) that quantized eight bit graphs appear to run very slow.  My goal is to match the realtime 1 batch (1 x 299 x 299 x3 ) iOS performance that the Camera Example gets, yet I can't get a Desktop CPU compile of TF to get lower than roughly 150ms per frame, where in reality close to 16ms per frame is needed for roughly 60hz, or 33ms for 30hz performance. It appears somehow the iOS / ArmV7 build is able to achieve this performance unless I am missing something!

From the discussion group, I was asked by @petewarden to start a bug based on findings

Thread here: https://groups.google.com/a/tensorflow.org/forum/?utm_medium=email&utm_source=footer#!msg/discuss/PJwgfoeNIKs/jiegynxLBAAJ

Briefly, I've added Stat Tracing to the Image Label example.  Modified source is here:

https://gist.github.com/vade/18d7e72f633f9479c5080a251661ebd9

Ive downloaded compiled tensor flow with the following bazel build commands, referenced from the makefile for iOS which speeds things up just a bit more than the standard compile:

` bazel build -c opt --copt=-mavx --cxxopt=-fno-exceptions --cxxopt=--std=c++11 --cxxopt=-DNDEBUG --cxxopt=-DNOTFDBG --cxxopt=-O2 --cxxopt=-DUSE_GEMM_FOR_CONV //tensorflow:libtensorflow_cc.so `

I then compiled Image Label via the standard bazel command:

` bazel build tensorflow/examples/label_image/...`

And ran it with 4 graphs:

* Standard InceptionV3
* InceptionV3 run through Inference Optimizer Script
* InceptionV3 run through Inference Optimizer and Quantizer in Weighted Rounding mode
* InceptionV3 run through Inference Optimizer and Quantizer in eight bit mode

The output of the runs are documented here, in order:

* https://gist.github.com/vade/a7d95da155c25dc8134f7cda8168e540
* https://gist.github.com/vade/71af1cbd38864cb176ce64bcafb934de
* https://gist.github.com/vade/e1923d7e7a9abfe1d8c912cc5d36a763
* https://gist.github.com/vade/1d9d5e102878cfb42f9c02a4200b3a50

Note the time for the Quantized Eight bit mode is roughly 2x longer than previous runs.

As a second set of data, my custom C++ app which uses the same lib_tensorfow_cc.so nets similar results to the benchmark :Â 


* InceptionV3 (no optimizations or quantizations) 
* 222 frames took 32.598143 seconds
* https://gist.github.com/vade/77a9314a5c7a5bda9b4a2c90f691a98e


* InceptionV3 (Inference Optimizations - no quantizations)
* 222 frames took 28.129690 seconds
* https://gist.github.com/vade/1c5dc51015f5a0fa24f4e0a7209cabf9


* InceptionV3 (Inference Optimizations & Quantizations Rounded)
* 222 frames took 25.201791 seconds
* https://gist.github.com/vade/ad8a2c42c5fbcf9be9f074c95d2e95ae


* InceptionV3 (Inference Optimizations & Quantizations Eightbit)
* 222 frames took 63.174700 seconds
* https://gist.github.com/vade/d6dcce06861bf8932446ae5ed33d93bb


Operating System:

`Mac OS X 10.12.1
2.8 GHz Intel Core i7
16GB Ram
Xcode 8.1 / Command Line Tools from 7.3.1 and enabled via xcselect
`
If installed from source, provide 

1. The commit hash

`41285cf7a11fa3a2c2ead6b6e9adcec4232b18ad`

2. The output of

`Build label: 0.4.0-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 19:18:00 2016 (1478114280)
Build timestamp: 1478114280
Build timestamp as int: 1478114280`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)`

See above for source code for minimally modified label image source.

### What other attempted solutions have you tried?

Attempted to run cuda but am targeting consumer desktop systems and would like similar performance to iOS targets for realtime or better than realtime performance for InceptionV3 / pool_3 feature vector determination and possibly labelling / classification.

For my system, cuda compilation netted similar results to CPU, although admittedly I did not enable batch sizes larger than 1. However, I think this is moot because iOS appears to be able to get realtime labelling and desktop cant, (is roughly 10x slower)

### Logs or other output that would be helpful
Logs and links provided in preamble  / description"
5752,Tensorboard - Black box for graphs after upgrading to TF 0.11,"
![tensorboard_issue_0 11](https://cloud.githubusercontent.com/assets/1653419/20492832/46047212-afe4-11e6-8eb0-2938e86390ea.png)

I am currently getting a black box where a graph should be when using Tensorboard. I was previously running TF 0.9 and upgraded last night to 0.11 via the pip link below. When I hover over the black box I do see the onHover messages displaying valid values, but I just can't see anything.

--The error received is below and the same thing shown in the screenshot above:

> All candidate resources failed to load. Media load paused.  127.0.1.1:6006
> Unexpected value  parsing viewBox attribute. d3.js:662:6
> NS_ERROR_FAILURE:  tf-tensorboard.html-28.js:199
> 	LineChart.prototype.setupTooltips/< http://127.0.1.1:6006/dist/tf-tensorboard.html-28.js:199:34
> 	CallbackSet</CallbackSet.prototype.callCallbacks/< http://127.0.1.1:6006/plottable/plottable.js:643:21
> 	Set</Set.prototype.forEach/callbackWrapper http://127.0.1.1:6006/plottable/plottable.js:257:77
> 	forEach self-hosted
> 	Set</Set.prototype.forEach http://127.0.1.1:6006/plottable/plottable.js:258:21
> 	CallbackSet</CallbackSet.prototype.callCallbacks http://127.0.1.1:6006/plottable/plottable.js:642:17
> 	Pointer</Pointer.prototype._handlePointerEvent http://127.0.1.1:6006/plottable/plottable.js:11190:21
> 	Pointer/this._mouseMoveCallback http://127.0.1.1:6006/plottable/plottable.js:11166:65
> 	CallbackSet</CallbackSet.prototype.callCallbacks/< http://127.0.1.1:6006/plottable/plottable.js:643:21
> 	Set</Set.prototype.forEach/callbackWrapper http://127.0.1.1:6006/plottable/plottable.js:257:77
> 	forEach self-hosted
> 	Set</Set.prototype.forEach http://127.0.1.1:6006/plottable/plottable.js:258:21
> 	CallbackSet</CallbackSet.prototype.callCallbacks http://127.0.1.1:6006/plottable/plottable.js:642:17
> 	Mouse</Mouse.prototype._measureAndDispatch http://127.0.1.1:6006/plottable/plottable.js:10501:25
> 	Mouse/processMoveCallback http://127.0.1.1:6006/plottable/plottable.js:10363:65

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
I have not found anyone having this as of yet when performing a search. I was previously running

### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA 8 and Cudnn 5
output of above ls:

> total 64
> drwxr-xr-x  3 root root 4096 Nov 20 21:59 bin
> drwxr-xr-x  5 root root 4096 Nov 20 21:59 doc
> drwxr-xr-x  5 root root 4096 Nov 20 21:59 extras
> drwxr-xr-x  5 root root 4096 Nov 20 22:19 include
> drwxr-xr-x  5 root root 4096 Nov 20 21:59 jre
> drwxr-xr-x  3 root root 4096 Nov 20 22:19 lib64
> drwxr-xr-x  8 root root 4096 Nov 20 21:59 libnsight
> drwxr-xr-x  7 root root 4096 Nov 20 21:59 libnvvp
> drwxr-xr-x  3 root root 4096 Nov 20 21:59 nvml
> drwxr-xr-x  7 root root 4096 Nov 20 21:59 nvvm
> drwxr-xr-x  2 root root 4096 Nov 20 21:59 pkgconfig
> drwxr-xr-x 11 root root 4096 Nov 20 21:59 samples
> drwxr-xr-x  3 root root 4096 Nov 20 21:59 share
> drwxr-xr-x  2 root root 4096 Nov 20 21:59 src
> drwxr-xr-x  2 root root 4096 Nov 20 21:59 tools
> -rw-r--r--  1 root root   20 Nov 20 21:59 version.txt


If installed from binary pip package, provide:

1. A link to the pip package you installed:
Ubuntu/Linux 64-bit, GPU enabled, Python 2.7
Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see ""Install from sources"" below.
TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11
"
5751,"failed sess.run error ""Cannot feed value of shape (50, 2352) for Tensor 'Placeholder:0', which has shape '(?, 784)'""","Hi 
Please Help me...
I learning to tensorflow using my own data based on tutorial expert.
following my code:
```
#datasets define
NUM_CLASSES = 65535
IMAGE_SIZE = 28
IMAGE_PIXELS = IMAGE_SIZE*IMAGE_SIZE*1
```

```
#read datasets
    with open(FLAGS.train, 'r') as f: # train.txt
        train_image = []
        train_label = []
        num = 0
        for line in f:
            if num == 500:
                break
            line = line.rstrip()
            l = line.split(',')
            print(l[0])
            img = cv2.imread(l[0])
            img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))
            train_image.append(img.flatten().astype(np.float32)/255.0)
            tmp = np.zeros(NUM_CLASSES)
            tmp[int(l[1])] = 1
            train_label.append(tmp)
            num += 1
        train_image = np.asarray(train_image)
        train_label = np.asarray(train_label)
        train_len = len(train_image)
```

```
def inference(images_placeholder, keep_prob):
    def weight_variable(shape):
        initial = tf.truncated_normal(shape, stddev=0.1)
        return tf.Variable(initial)
    def bias_variable(shape):
        initial = tf.constant(0.1, shape=shape)
        return tf.Variable(initial)
    def conv2d(x, W):
        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
    def max_pool_2x2(x):
        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                              strides=[1, 2, 2, 1], padding='SAME')
    x_images = tf.reshape(images_placeholder, [-1, IMAGE_SIZE, IMAGE_SIZE, 1])
    with tf.name_scope('conv1') as scope:
        W_conv1 = weight_variable([5, 5, 1, 32])
        b_conv1 = bias_variable([32])
        h_conv1 = tf.nn.relu(conv2d(x_images, W_conv1) + b_conv1)
    with tf.name_scope('pool1') as scope:
        h_pool1 = max_pool_2x2(h_conv1)
    with tf.name_scope('conv2') as scope:
        W_conv2 = weight_variable([5, 5, 32, 64])
        b_conv2 = bias_variable([64])
        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
    with tf.name_scope('pool2') as scope:
        h_pool2 = max_pool_2x2(h_conv2)
    with tf.name_scope('fc1') as scope:
        W_fc1 = weight_variable([7*7*64, 1024])
        b_fc1 = bias_variable([1024])
        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)
    with tf.name_scope('fc2') as scope:
        W_fc2 = weight_variable([1024, NUM_CLASSES])
        b_fc2 = bias_variable([NUM_CLASSES])
    with tf.name_scope('softmax') as scope:
        y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
    return y_conv
```

```
#learn
    with tf.Graph().as_default():
        images_placeholder = tf.placeholder(""float"", shape=(None, IMAGE_PIXELS))
        labels_placeholder = tf.placeholder(""float"", shape=(None, NUM_CLASSES))
        keep_prob = tf.placeholder(""float"")
        
        logits = inference(images_placeholder, keep_prob)
        loss_value = loss(logits, labels_placeholder)
        train_op = training(loss_value, FLAGS.learning_rate)
        print(""train_op ="", train_op)

        acc = accuracy(logits, labels_placeholder)
        
        saver = tf.train.Saver()
        sess = tf.Session()
        sess.run(tf.initialize_all_variables())
        summary_op = tf.merge_all_summaries()
        summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph_def)
        
        if train_len % FLAGS.batch_size is 0:
            train_batch = train_len/FLAGS.batch_size
        else:
            train_batch = (train_len/FLAGS.batch_size)+1
        print(""train_batch = %d"",str(train_batch))
        for step in range(FLAGS.max_steps):
            for i in range(int(train_batch)):
                batch = FLAGS.batch_size*i
                batch_plus = FLAGS.batch_size*(i+1)
                print(""batch_plus ="", batch_plus)
                if batch_plus > train_len: batch_plus = train_len
                sess.run(train_op, feed_dict={
                         images_placeholder: train_image[batch:batch_plus],
                         labels_placeholder: train_label[batch:batch_plus],
                         keep_prob: 0.5})
            
            if step % 10 == 0:
                train_accuracy = 0.0
                for i in range(train_batch):
                    batch = FLAGS.batch_size*i
                    batch_plus = FLAGS.batch_size*(i+1)
                    if batch_plus > train_len: batch_plus = train_len
                    train_accuracy += sess.run(acc, feed_dict={
                                               images_placeholder: train_image[batch:batch_plus],
                                               labels_placeholder: train_label[batch:batch_plus],
                                               keep_prob: 1.0})
                    if i is not 0: train_accuracy /= 2.0
                #summary_str = sess.run(summary_op, feed_dict={
                #    images_placeholder: train_image,
                #    labels_placeholder: train_label,
                #    keep_prob: 1.0})
                #summary_writer.add_summary(summary_str, step)
                print(""step %d, training accuracy %g"",(step, train_accuracy))

    if test_len % FLAGS.batch_size is 0:
        test_batch = test_len/FLAGS.batch_size
    else:
        test_batch = (test_len/FLAGS.batch_size)+1
        print(""test_batch = "",str(test_batch))
        test_accuracy = 0.0
    for i in range(test_batch):
        batch = FLAGS.batch_size*i
        batch_plus = FLAGS.batch_size*(i+1)
        if batch_plus > train_len: batch_plus = train_len
        test_accuracy += sess.run(acc, feed_dict={
                                  images_placeholder: test_image[batch:batch_plus],
                                  labels_placeholder: test_label[batch:batch_plus],
                                  keep_prob: 1.0})
        if i is not 0: test_accuracy /= 2.0
    print(""test accuracy %g"",(test_accuracy))
    save_path = saver.save(sess, FLAGS.save_model)
```
but when I try to run it I gives me an error:
`ValueError:Cannot feed value of shape (50, 2352) for Tensor 'Placeholder:0', which has shape '(?, 784)'`

I feel like i'm overlooking something small but I don't see it.
"
5748,"Bazel build on Windows fails with ""Can't do inplace edit without backup."" error.","

### Environment info
Operating System: Windows 10

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):  No

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)  - c7edafccc793bf87e29aaec90db64471a7a4bb02
2. The output of `bazel version`: 0.4.0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

Bazel build on Windows fails with ""Can't do inplace edit without backup."" error.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

$ /d/tf/tensorflow/tensorflow/tools/ci_build/windows/cpu/pip/build_tf_windows.sh
+ set -e
++ dirname /d/tf/tensorflow/tensorflow/tools/ci_build/windows/cpu/pip/build_tf_windows.sh
+ script_dir=/d/tf/tensorflow/tensorflow/tools/ci_build/windows/cpu/pip
+ cd /d/tf/tensorflow/
+ export TMPDIR=C:/tmp
+ TMPDIR=C:/tmp
+ export BAZEL_SH=C:/tools/msys64/usr/bin/bash
+ BAZEL_SH=C:/tools/msys64/usr/bin/bash
+ export PYTHON_BIN_PATH=I:/Anaconda3/python
+ PYTHON_BIN_PATH=I:/Anaconda3/python
+ export BAZEL_PYTHON=I:/Anaconda3/python
+ BAZEL_PYTHON=I:/Anaconda3/python
+ export 'BAZEL_VS=E:/Program Files (x86)/Microsoft Visual Studio 14.0'
+ BAZEL_VS='E:/Program Files (x86)/Microsoft Visual Studio 14.0'
+ export 'PATH=/I/Anaconda3:/c/Perl64/site/bin:/c/Perl64/bin:/c/Python27:/c/Python27/Scripts:/c/WINDOWS/system32:/c/WINDOWS:/c/WINDOWS/System32/Wbem:/c/WINDOWS/System32/WindowsPowerShell/v1.0:/c/Program Files (x86)/Skype/Phone:/c/Program Files/Git/cmd:/c/Program Files (x86)/Windows Kits/8.1/Windows Performance Toolkit:/c/Program Files/Microsoft SQL Server/110/Tools/Binn:/c/Program Files (x86)/Microsoft SDKs/TypeScript/1.0:/c/Program Files/Microsoft SQL Server/120/Tools/Binn:/c/Users/pavel/.dnx/bin:/c/Program Files/Microsoft DNX/Dnvm:/c/Program Files/Microsoft SQL Server/130/Tools/Binn:/c/WINDOWS/SysWOW64/WindowsPowerShell/v1.0/Modules/TShell/TShell:/c/Program Files/Samsung/AllShare Framework DMS/1.3.23:/c/Program Files/Samsung/AllShare Framework DMS/1.3.23/64bit:/c/Program Files/TortoiseGit/bin:/c/ProgramData/chocolatey/bin:/c/Program Files/CMake/bin:/c/Program Files/Java/jdk1.8.0_112/bin:/usr/bin:/i/Anaconda3:/i/Anaconda3/Scripts:/i/Anaconda3/Library/bin:/c/Users/pavel/AppData/Local/Programs/Python/Python35-32/Scripts:/c/Users/pavel/AppData/Local/Programs/Python/Python35-32:/c/Users/pavel/AppData/Local/Microsoft/WindowsApps:/c/Program Files/CMake/bin:/c/ProgramData/chocolatey/lib/msys2:/:/usr/bin'
+ PATH='/I/Anaconda3:/c/Perl64/site/bin:/c/Perl64/bin:/c/Python27:/c/Python27/Scripts:/c/WINDOWS/system32:/c/WINDOWS:/c/WINDOWS/System32/Wbem:/c/WINDOWS/System32/WindowsPowerShell/v1.0:/c/Program Files (x86)/Skype/Phone:/c/Program Files/Git/cmd:/c/Program Files (x86)/Windows Kits/8.1/Windows Performance Toolkit:/c/Program Files/Microsoft SQL Server/110/Tools/Binn:/c/Program Files (x86)/Microsoft SDKs/TypeScript/1.0:/c/Program Files/Microsoft SQL Server/120/Tools/Binn:/c/Users/pavel/.dnx/bin:/c/Program Files/Microsoft DNX/Dnvm:/c/Program Files/Microsoft SQL Server/130/Tools/Binn:/c/WINDOWS/SysWOW64/WindowsPowerShell/v1.0/Modules/TShell/TShell:/c/Program Files/Samsung/AllShare Framework DMS/1.3.23:/c/Program Files/Samsung/AllShare Framework DMS/1.3.23/64bit:/c/Program Files/TortoiseGit/bin:/c/ProgramData/chocolatey/bin:/c/Program Files/CMake/bin:/c/Program Files/Java/jdk1.8.0_112/bin:/usr/bin:/i/Anaconda3:/i/Anaconda3/Scripts:/i/Anaconda3/Library/bin:/c/Users/pavel/AppData/Local/Programs/Python/Python35-32/Scripts:/c/Users/pavel/AppData/Local/Programs/Python/Python35-32:/c/Users/pavel/AppData/Local/Microsoft/WindowsApps:/c/Program Files/CMake/bin:/c/ProgramData/chocolatey/lib/msys2:/:/usr/bin'
+ export TF_NEED_CUDA=0
+ TF_NEED_CUDA=0
+ bazel clean
ERROR: CreateFile(C:\tmp\Bazel\UUElXoeN\install): The system cannot find the file specified.
 (2)
..............
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
++ bazel info output_base
+ output_base=C:/tmp/Bazel/UUElXoeN
+ bazel shutdown
+ sleep 5
+ rm -rf C:/tmp/Bazel/UUElXoeN
+ echo ''
+ ./configure
/d/tf/tensorflow /d/tf/tensorflow
Can't do inplace edit without backup.
"
5747,Unable to use GPU with Tensorflow 11.0 (regression from 11.0rc2),"Cannot run convolutional network on GPU using TF 11.
It works fine under TF 11rc2. This looks like a regression.

Issue #5555 indicated to install cudnn 5.1. I checked and that is what I appear to have. cudnn.h lists 5.1 as the major/minir version. I also compared the binary file libcudnn.5.dylib downloaded from NVIDIA with the one I have in /usr/local/cuda/lib and they are the same.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://github.com/tensorflow/tensorflow/issues/5555

### Environment info
Operating System: MacOS

Installed version of CUDA and cuDNN:
CUDA Driver Version: 8.0.51 
cuDNN 5.1
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
lrwxr-xr-x  1 root  wheel     33 Oct 24 15:40 /usr/local/cuda/lib/libcuda.1.dylib -> /usr/local/cuda/lib/libcuda.dylib
-rwxr-xr-x  1 root  wheel  13504 Oct 24 22:27 /usr/local/cuda/lib/libcuda.dylib
lrwxr-xr-x@ 1 root  wheel     45 Sep 27 00:00 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a
lrwxr-xr-x@ 1 root  wheel     50 Sep 27 00:00 /usr/local/cuda/lib/libcudart.8.0.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib
lrwxr-xr-x@ 1 root  wheel     46 Sep 27 00:00 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib
lrwxr-xr-x@ 1 root  wheel     49 Sep 27 00:00 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a
lrwxr-xr-x  1 root  wheel     47 Oct 24 15:34 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.5.dylib
lrwxr-xr-x  1 root  wheel     45 Oct 24 15:34 /usr/local/cuda/lib/libcudnn.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.dylib
lrwxr-xr-x  1 root  wheel     48 Oct 24 15:34 /usr/local/cuda/lib/libcudnn_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn_static.a

1. A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.11.0-py3-none-any.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11.0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_3.0_convolutional.py
(run this file with python3 - you will need three additional files from the same directory, namely tensorflowvisu*. matplotlib is also required: ""pip3 matplotlib"")

### What other attempted solutions have you tried?
It works under Tensorflow 11 rc2

### Logs or other output that would be helpful
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: 
name: GeForce GTX 980 Ti
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:c1:00.0
Total memory: 6.00GiB
Free memory: 5.87GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:c1:00.0)
**E tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded runtime CuDNN library: 5105 (compatibility version 5100) but source was compiled with 5005 (compatibility version 5000).  If using a binary install, upgrade your CuDNN library to match.**  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.
F tensorflow/core/kernels/conv_ops.cc:526] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) 
Abort trap: 6

"
5746,Optimization occurs after graph is partitioned across devices,"The optimization (sub-expression, constant folding) of the graphs takes place after partitioning. While this is important, it prevents optimization of logic that is split across devices by an unfortunate placement decision.

In my simple example, constants are assigned to my device graph, and the downstream maths nodes are assigned to the CPU.  Consequently, parts of the graph where constant folding should occur are not eliminated, resulting in substantially larger graphs than is necessary.

I propose that there should be an optmization pass before the graph is partitioned.  I realize that this is awkward, because the optimization takes place on a Graph, not a GraphDef.  "
5745,Constants are placed on a device when they do nothing but feed off-device nodes,"I have created a device that supports integer constant tensors (because I would like to be able to support the inputs to reshape etc...), but not the integer maths operators (because I'm not going to accelerate those initially).

The gradient generation logic creates trees of integer maths.  The constants for this maths are placed on the device, while the maths nodes themselves are placed on the CPU (as expected).

This isn't very sensible.  

I think it would be better that constants are not placed on a device, unless they are feeding downstream nodes that are also on the same device.

There may be some classes of constant (ones with a specific memory placement, very large ones), which would end up on a different device to their downstream nodes, but I think that the default should be to keep them together.

"
5744,Unable to run cifar10_multi_gpu_train as is in TensorFlow master,"Ubuntu 14.04
commit used: a154b6a7826760f30e368e84f51048218002d376

Simply changed num_gpus to 2. I have 2 GPUs. A 1060 and 970. Shows this error:

`ValueError: Variable tower_1/tower_1/conv1/weight_loss/avg/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?`

"
5742,TypeError: ones_initializer() got multiple values for keyword argument 'dtype' when execute the inception_train,"## Exception:

```
...
File ""inception/slim/variables.py"", line 290, in variable
  trainable=trainable, collections=collections)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 1024, in get_variable
  custom_getter=custom_getter)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 850, in get_variable
  custom_getter=custom_getter)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 346, in get_variable
  validate_shape=validate_shape)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 331, in _true_getter
  caching_device=caching_device, validate_shape=validate_shape)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 677, in _get_single_variable
  expected_shape=shape)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 224, in __init__
  expected_shape=expected_shape)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 327, in _init_from_args
  initial_value(), name=""initial_value"", dtype=dtype)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 665, in <lambda>
  shape.as_list(), dtype=dtype, partition_info=partition_info)
TypeError: ones_initializer() got multiple values for keyword argument 'dtype'
```

I think recently changes of tensorflow.python.init_ops influence to this issue.

## [init_ops.py](https://github.com/tensorflow/tensorflow/commit/cfb2280d3f6ced298681bd1141479a59a06abde8)
```diff
< def ones_initializer(dtype=dtypes.float32, partition_info=None):
---
> def ones_initializer(shape, dtype=dtypes.float32, partition_info=None):
```

## [variable_scope.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/variable_scope.py#L665)

```python
 655     # Create the tensor to initialize the variable.
 656     if initializer is None:
 657       initializer = init_ops.uniform_unit_scaling_initializer()
 658     # Clear control dependencies while creating the initializer.
 659     with ops.control_dependencies(None):
 660       if initializing_from_value:
 661         init_val = initializer
 662         variable_dtype = None
 663       else:
 664         init_val = lambda: initializer(
 665             shape.as_list(), dtype=dtype, partition_info=partition_info)
 666         variable_dtype = dtype.base_dtype
```

`lambda:initiallizer` calls with three parameters. So, parameter missmatch occured.

I think it needs to change `variable_scope.py` source code.
"
5741,Python API Docs broken at r0.11,"#4969 isn't fixed at branch r0.11.
https://www.tensorflow.org/versions/r0.11/api_docs/python/state_ops.html#constant_initializer
"
5740,[Compression]Problem at Tensorflow/Model/Compression,"
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

https://github.com/tensorflow/tensorflow/issues/4772
tensorflow/models/compression does not work,but his problem was not same to me.
### Environment info
Operating System:

Ubuntu 14.04
tensorflow cpu-only version:0.8.0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/common_shapes.py"", line 155, in get2d_conv_output_size
    % (row_stride, col_stride, filter_height, filter_width))
ValueError: ('stride must be less than or equal to filter size', 'stride: [2x2] filter: [1x1]')


### What other attempted solutions have you tried?
I have open the common_shapes.py,but don't know how to repair.

"
5738,tf.sub error message for bad types is confusing,"tf.sub() displays a strange error message if the types don't match:
TypeError: DataType uint8 for attr 'T' not in list of allowed values: float16, float32, float64, int32, int64, complex64, complex128

It's unclear what attr 'T' is.

Expected behavior:
for tf.add(), tf.mul(), tf.div(), the message makes sense:
TypeError: Input 'y' of 'Add' Op has type int64 that does not match type uint8 of argument 'x'.

It seems to me that tf.sub() should print a similar message.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
none

### Environment info
Operating System:
Darwin Kens-MacBook-Pro.local 16.1.0 Darwin Kernel Version 16.1.0: Thu Oct 13 21:26:57 PDT 2016; root:xnu-3789.21.3~60/RELEASE_X86_64 x86_64

Installed version of CUDA and cuDNN: none

1. A link to the pip package you installed:
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0-py2-none-any.whl""

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11.0

### If possible, provide a minimal reproducible example 

import tensorflow as tf
x0 = tf.constant(1, dtype=tf.uint8)
x1 = tf.constant(255, dtype=tf.int64)
x2 = tf.sub(x0, x1)
"
5737,quantize_graph contrib tool cannot import name load_quantized_ops_so,"Attempting to run quantize graph via 
`bazel-bin/tensorflow/contrib/quantization/tools/quantize_graph --input=/path/to/graph --output=/path/to/quantized_graph --output_node_names=""name"" --mode=eightbit`

results in 

`line 41, in <module>
    from tensorflow.contrib.quantization import load_quantized_ops_so
ImportError: cannot import name load_quantized_ops_so
`

### Environment info
Operating System:
Mac OS X 10.12.1

Installed version of CUDA and cuDNN: 
8.0

`ls -l /usr/local/cuda/lib/libcud*
-rwxr-xr-x  1 root  wheel  13504 Sep 26 17:59 /usr/local/cuda/lib/libcuda.1.dylib
lrwxr-xr-x  1 root  wheel     45 Sep 26 18:00 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a
lrwxr-xr-x  1 root  wheel     50 Sep 26 18:00 /usr/local/cuda/lib/libcudart.8.0.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib
lrwxr-xr-x  1 root  wheel     46 Sep 26 18:00 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib
lrwxr-xr-x  1 root  wheel     49 Sep 26 18:00 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a
lrwxr-xr-x  1 root  wheel     47 Nov 15 00:44 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.5.dylib
lrwxr-xr-x  1 root  wheel     45 Nov 15 00:44 /usr/local/cuda/lib/libcudnn.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.dylib
lrwxr-xr-x  1 root  wheel     48 Nov 15 00:44 /usr/local/cuda/lib/libcudnn_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn_static.a`
If installed from binary pip package, provide:

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
`282823b877f173e6a33bbc9d4b9ad7dd8413ada6 (0.11.0 tagged)`
2. The output of `bazel version`
`bazel version
Build label: 0.4.0-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 19:18:00 2016 (1478114280)
Build timestamp: 1478114280
Build timestamp as int: 1478114280
`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

N/a

### What other attempted solutions have you tried?
Bazel clean and rebuild TF (results in same issue)

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5736,Training Cifar10 on two GPUs crashed.,"### Environment info
Operating System:16.04.1 LTS (Xenial Xerus)

Installed version of CUDA and cuDNN: 8.0 and 5.0.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root   558720 Nov 19 10:33 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Nov 19 10:33 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Nov 19 10:33 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 root root   415432 Nov 19 10:33 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Nov 19 10:33 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 79337624 Nov 19 10:36 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 79337624 Nov 19 10:36 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 79337624 Nov 19 10:36 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Nov 19 10:36 /usr/local/cuda/lib64/libcudnn_static.a

Installed from source:
1. The commit hash: 8157ae2552f4ec031e9f3183e1dede66444320fd
2. The output of `bazel version`:
Build label: 0.3.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jul 29 09:09:52 2016 (1469783392)
Build timestamp: 1469783392
Build timestamp as int: 1469783392

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
python cifar10_multi_gpu_train.py --num_gpus=2
(Both 'python cifar10_train.py' and 'python cifar10_multi_gpu_train.py --num_gpus=1' work well.)

### Logs or other output that would be helpful
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: TITAN X (Pascal), pci bus id: 0000:04:00.0)
ERROR:tensorflow:Exception in QueueRunner: Expected begin[0] in [0, 32], but got -6
	 [[Node: tower_1/random_crop = Slice[Index=DT_INT32, T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:1""](tower_1/Cast_1, tower_1/random_crop/mod, tower_1/random_crop/size)]]
	 [[Node: tower_1/Div/_82 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:1"", send_device_incarnation=1, tensor_name=""edge_131_tower_1/Div"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op u'tower_1/random_crop', defined at:
  File ""cifar10_multi_gpu_train.py"", line 289, in <module>
    tf.app.run()
  File ""/home/petuum/projects/Poseidon-TensorFlow/_python_build/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""cifar10_multi_gpu_train.py"", line 285, in main
    train()
  File ""cifar10_multi_gpu_train.py"", line 189, in train
    loss = tower_loss(scope)
  File ""cifar10_multi_gpu_train.py"", line 76, in tower_loss
    images, labels = cifar10.distorted_inputs()
  File ""/home/petuum/projects/Poseidon-TensorFlow/_python_build/tensorflow/models/image/cifar10/cifar10.py"", line 156, in distorted_inputs
    batch_size=FLAGS.batch_size)
  File ""/home/petuum/projects/Poseidon-TensorFlow/_python_build/tensorflow/models/image/cifar10/cifar10_input.py"", line 172, in distorted_inputs
    distorted_image = tf.random_crop(reshaped_image, [height, width, 3])
  File ""/home/petuum/projects/Poseidon-TensorFlow/_python_build/tensorflow/python/ops/random_ops.py"", line 326, in random_crop
    return array_ops.slice(value, offset, size, name=name)
  File ""/home/petuum/projects/Poseidon-TensorFlow/_python_build/tensorflow/python/ops/array_ops.py"", line 328, in slice
    return gen_array_ops._slice(input_, begin, size, name=name)
  File ""/home/petuum/projects/Poseidon-TensorFlow/_python_build/tensorflow/python/ops/gen_array_ops.py"", line 2009, in _slice
    name=name)
  File ""/home/petuum/projects/Poseidon-TensorFlow/_python_build/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/home/petuum/projects/Poseidon-TensorFlow/_python_build/tensorflow/python/framework/ops.py"", line 2322, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/petuum/projects/Poseidon-TensorFlow/_python_build/tensorflow/python/framework/ops.py"", line 1244, in __init__
    self._traceback = _extract_stack()

Other threads reported similar errors.

Please help! I'm looking forward to your reply.
Sincerely"
5735,"einsum: ""ij,ji->"" rasing error.","Hi I'm running Linux-64 bit os and I'm getting the following error after running:

```
import tensorflow as tf
I = tf.constant([[1,0,0],[0,1,0],[0,0,1]])
II_tr = tf.einsum('ij,ji->',I,I)
with tf.Session() as sess:
	res = sess.run(II_tr)
	print res
```
`AssertionError: Indices have incorrect format: ij,ji->` Clearly the result here should be 3. 


"
5733,Segmentation violation error after call to the go._Cfunc_TF_NewSession,"The error repeats locally after manual build of the Tensorflow and in the docker container, based mostly on the [Dockerfile.devel](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/Dockerfile.devel)


### Exception:

```
fatal error: unexpected signal during runtime execution                                
[signal SIGSEGV: segmentation violation code=0x1 addr=0x13 pc=0x7f37136ca51f]          
                                                                                       
runtime stack:                                                                         
runtime.throw(0x770629, 0x2a)                                                          
        /usr/local/go/src/runtime/panic.go:566 +0x95                                   
runtime.sigpanic()                                                                     
        /usr/local/go/src/runtime/sigpanic_unix.go:12 +0x2cc                           
                                                                                       
goroutine 1 [syscall, locked to thread]:                                               
runtime.cgocall(0x6b5900, 0xc420049aa8, 0x7f3700000000)                                
        /usr/local/go/src/runtime/cgocall.go:131 +0x110 fp=0xc420049a78 sp=0xc420049a38
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_NewSession(0x7f37000008c0, 0x7f3700130a80, 0x7f3700002be0, 0x0)                                                      
        ??:0 +0x4e fp=0xc420049aa8 sp=0xc420049a78                                     
github.com/tensorflow/tensorflow/tensorflow/go.NewSession(0xc4200fa010, 0xc420049c90, 0x1, 0x1, 0xc420494060)
        /go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:51 +0x17e fp=0xc420049b30 sp=0xc420049aa8
main.recognize(0xc4200e4570, 0xc420130044, 0x449f, 0x44b7, 0xc4201344fa, 0x0, 0x1, 0x76aa86, 0x1b)
        /go/src/Cerber/tensorflow.go:46 +0x55e fp=0xc420049d48 sp=0xc420049b30
main.HandleSendCommand()
        /go/src/Cerber/sendCommand.go:9 +0x239 fp=0xc420049e48 sp=0xc420049d48
main.mainLoop(0x78f270)
        /go/src/Cerber/main.go:44 +0x2b fp=0xc420049e98 sp=0xc420049e48
main.main()
        /go/src/Cerber/main.go:28 +0x4a2 fp=0xc420049f48 sp=0xc420049e98
runtime.main()
        /usr/local/go/src/runtime/proc.go:183 +0x1f4 fp=0xc420049fa0 sp=0xc420049f48
runtime.goexit()
        /usr/local/go/src/runtime/asm_amd64.s:2086 +0x1 fp=0xc420049fa8 sp=0xc420049fa0

goroutine 17 [syscall, locked to thread]:
runtime.goexit()
        /usr/local/go/src/runtime/asm_amd64.s:2086 +0x1

goroutine 25 [IO wait]:
net.runtime_pollWait(0x7f37145e4ff8, 0x72, 0x3)
        /usr/local/go/src/runtime/netpoll.go:160 +0x59
net.(*pollDesc).wait(0xc420057100, 0x72, 0xc420505758, 0xc420016160)
        /usr/local/go/src/net/fd_poll_runtime.go:73 +0x38
net.(*pollDesc).waitRead(0xc420057100, 0xac3ee0, 0xc420016160)
        /usr/local/go/src/net/fd_poll_runtime.go:78 +0x34
net.(*netFD).Read(0xc4200570a0, 0xc42052a000, 0x8000, 0x8000, 0x0, 0xac3ee0, 0xc420016160)
        /usr/local/go/src/net/fd_unix.go:243 +0x1a1
net.(*conn).Read(0xc420028100, 0xc42052a000, 0x8000, 0x8000, 0x0, 0x0, 0x0)
        /usr/local/go/src/net/net.go:173 +0x70
crypto/tls.(*block).readFromUntil(0xc42023a3f0, 0x7f37145e5218, 0xc420028100, 0x5, 0xc420028100, 0x1)
        /usr/local/go/src/crypto/tls/conn.go:476 +0x91
crypto/tls.(*Conn).readRecord(0xc420073880, 0x78fa17, 0xc420073988, 0xc42002b800)
        /usr/local/go/src/crypto/tls/conn.go:578 +0xc4
crypto/tls.(*Conn).Read(0xc420073880, 0xc4201e1000, 0x1000, 0x1000, 0x0, 0x0, 0x0)
        /usr/local/go/src/crypto/tls/conn.go:1113 +0x116
bufio.(*Reader).fill(0xc4203186c0)
        /usr/local/go/src/bufio/bufio.go:97 +0x10c
bufio.(*Reader).Read(0xc4203186c0, 0xc4204fda78, 0x9, 0x9, 0xfef, 0x11, 0x0)
        /usr/local/go/src/bufio/bufio.go:209 +0x1bc
io.ReadAtLeast(0xac1da0, 0xc4203186c0, 0xc4204fda78, 0x9, 0x9, 0x9, 0xc420505c80, 0x50dbce, 0xc420073880)
        /usr/local/go/src/io/io.go:307 +0xa4
io.ReadFull(0xac1da0, 0xc4203186c0, 0xc4204fda78, 0x9, 0x9, 0xc420505c78, 0x457770, 0xc4200001a0)
        /usr/local/go/src/io/io.go:325 +0x58
net/http.http2readFrameHeader(0xc4204fda78, 0x9, 0x9, 0xac1da0, 0xc4203186c0, 0x0, 0x0, 0x1884012202, 0xc4200f2320)
        /usr/local/go/src/net/http/h2_bundle.go:779 +0x7b
net/http.(*http2Framer).ReadFrame(0xc4204fda40, 0xc42048c000, 0x0, 0x0, 0x0)
        /usr/local/go/src/net/http/h2_bundle.go:1001 +0xa4
net/http.(*http2clientConnReadLoop).run(0xc420505f80, 0x78f470, 0xc420020f90)
        /usr/local/go/src/net/http/h2_bundle.go:6004 +0xbb
net/http.(*http2ClientConn).readLoop(0xc420090ea0)
        /usr/local/go/src/net/http/h2_bundle.go:5937 +0xa6
created by net/http.(*http2Transport).newClientConn
        /usr/local/go/src/net/http/h2_bundle.go:5314 +0x709
```

### Container details:
```
$ go env
GOARCH=""amd64"" GOBIN="""" GOEXE="""" GOHOSTARCH=""amd64"" GOHOSTOS=""linux"" GOOS=""linux"" GOPATH=""/go"" GORACE="""" GOROOT=""/usr/local/go"" GOTOOLDIR=""/usr/local/go/pkg/tool/linux_amd64"" CC=""gcc"" GOGCCFLAGS=""-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build477629842=/tmp/go-build -gno-record-gcc-switches"" CXX=""g++"" CGO_ENABLED=""1""
```

```
$ bazel version
Build label: 0.3.2 Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar Build time: Fri Oct 7 17:25:10 2016 (1475861110) Build timestamp: 1475861110 Build timestamp as int: 1475861110
```

```
$ g++ --version
g++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609 Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
```

```
$ g++ -v
Using built-in specs.

COLLECT_GCC=g++
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/5/lto-wrapper                        
Target: x86_64-linux-gnu                                                               
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 5.4.0-6ubuntu1~16.04.4' --with-bugurl=file:///usr/share/doc/gcc-5/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-5 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-5-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-5-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-5-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu                 
Thread model: posix                                                                    
gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4) 
```"
5732,infinite symlink expansion detected,"Hi All,
just starting to learn to build this thing, must be some noob error. Any advice would be appreciated.

```
____Downloading from https://github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz: 50KB
ERROR: infinite symlink expansion detected
[start of symlink chain]
/usr/bin/X11
/usr/bin
[end of symlink chain]
.

____Cloning https://github.com/antirez/linenoise.git: Receiving objects (268 / 393)
ERROR: /home/mdupont/.cache/bazel/_bazel_mdupont/cd1c359a0f897a12f2b0754121ddc2b1/external/local_config_cuda/cuda/BUILD:\
42:12: error globbing [**/*.h]: /home/mdupont/.cache/bazel/_bazel_mdupont/cd1c359a0f897a12f2b0754121ddc2b1/external/loca\
l_config_cuda/cuda/lib/x86_64-linux-gnu/hdf5/serial/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/\
lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib (Too many levels of symbolic\
 links).
ERROR: /home/mdupont/.cache/bazel/_bazel_mdupont/cd1c359a0f897a12f2b0754121ddc2b1/external/local_config_cuda/cuda/BUILD:\
146:12: error globbing [**/*.h]: /home/mdupont/.cache/bazel/_bazel_mdupont/cd1c359a0f897a12f2b0754121ddc2b1/external/loc\
al_config_cuda/cuda/lib/x86_64-linux-gnu/hdf5/serial/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib\
/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib/lib (Too many levels of symboli\
c links).

____Loading package: @local_config_cuda//cuda
ERROR: infinite symlink expansion detected
[start of symlink chain]
/usr/lib/x86_64-linux-gnu/hdf5/serial/lib
/usr/lib/x86_64-linux-gnu/hdf5/serial
[end of symlink chain]
.

```"
5731,Hope intermediate state in dynamic_rnn,"To implement a attention machine, I need the intermediate state to calculate the attention, but dynamic_rnn doesn't return the intermediate states but only final state.
Hope the dynamic_rnn could return intermediate states so that we can implement a attention machine with dynamic network. "
5730,tf.nn.elu returns NaN,"I am using a fairly straight-forward FFN with ELU activations, and getting all NaN from the network output.

This comes in the 4th training epoch so the data did not have any NaN.

### Environment info
Operating System: Mac OS X 10.12.1

Installed version of CUDA and cuDNN: N/A. I'm using CPU version.

tensorflow version: 0.11.0rc2

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

    dense_output = tf.contrib.layers.stack(input, 
                                           tf.contrib.layers.fully_connected,
                                           [config.hidden_size, config.hidden_size // 2, config.hidden_size // 3, target_size],
                                           activation_fn=tf.nn.elu,
                                           weights_initializer=tf.contrib.layers.xavier_initializer(),
                                           scope='FFN')


### Logs or other output that would be helpful

https://gist.github.com/aht/5c719ce162158eaae9beb22555324f9d"
5729,Feature request: Please release an official binary for Raspberry Pi,"The Raspberry Pi is an excellent platform for robotics and automation. The native camera also makes a great combo for portable / embedded / robotics computer vision. Having TensorFlow available on this platform would really open up a lot of options in this context.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

none

### Environment info
Operating System:

Raspbian Jessie on Raspberry Pi 3

### What other attempted solutions have you tried?

https://github.com/samjabrahams/tensorflow-on-raspberry-pi

It only provides a binary for TensorFlow 0.10. I've had lots of issues with it running DNNs trained on 0.11. I need to train on 0.11 because the only fast GPU I have is an Nvidia Pascal chip, and 0.10 doesn't work well on Pascal (due to CUDA version issues).

I've tried to compile 0.11 following the guide there, but there were a lot of errors."
5728,"Get ""argv"" error when trying to run mnist_softmax.py example","Hi,

I am trying to learn tensorflow from the tutorial on [MNIST](https://www.tensorflow.org/versions/r0.11/tutorials/mnist/beginners/index.html). I already have tensorflow installed on my system through conda and have been able to import tensorflow without any problems. Interaction with my GPU is fine when I ran code samples from research paper repositories.

To do so, I cloned the entire tensorflow repo into a local directory, and went into the tutorials/mnist directory. When I try to run the mnist_softmax.py example, I run into the error I have posted below.

`$ python mnist_softmax.py `
`I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally`
`I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally`
`I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally`
`I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally`
`I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally`
`Traceback (most recent call last):`
`  File ""mnist_softmax.py"", line 78, in <module>`
`    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)`
`TypeError: run() got an unexpected keyword argument 'argv'`

Searching stackoverflow, I haven't found much helpful posts on this subject. The two posts I found were http://stackoverflow.com/questions/40513466/tensorflow-retrain-py-app-run-got-unexpected-keyword-argument-argv and http://stackoverflow.com/questions/40357548/inception-v3-guide-on-tensorflow-broken-for-c-and-python, but they are not really solutions to this problem.

So far I can't think of any reason why this would not work, except that maybe I need to compiler and build Tensorflow from source instead of just installing the binaries via conda.

If anyone could help with this, it would be really appreciated.

Thank you.
"
5726,Don't imply top_k is nondifferentiable,"`top_k` is in the [`Evaluation`](https://www.tensorflow.org/versions/master/api_docs/python/nn.html#evaluation) section of the documentation, which says

> The evaluation ops are useful for measuring the performance of a network. Since they are
> nondifferentiable, they are typically used at evaluation time.

This is confusing, since `top_k` is differentiable.  Pointed out by @nmduc: https://github.com/tensorflow/tensorflow/issues/288#issuecomment-261703608."
5722,Async prefetching queue data on GPU,"For example look at te following code:
```python
X = fifo_queue.dequeue_many(100) # Some queue
...  # some processing
f  # reslut of computation
```

```fifo_queue``` holds all its variable and data in RAM, that is on CPU since there's no GPU kernel for it (nor for any other queue that I'm aware of.

However upon running:
```python
sess.run(f)
```

There's a huge bottleneck for dequeuing and copying data from CPU to GPU which could be done async. Here is example of timeline: http://imgur.com/a/1cGHf

How can I tell tensorflow to async prefetch data on GPU (for example 3xbatch size examples or something like that) so that I avoid waiting for QueueDequeuMany and MEMCPYHtoD operations? Closest I could find for an answer is [this](http://stackoverflow.com/questions/38751736/understanding-tensorflow-queues-and-cpu-gpu-transfer) stackoverflow post, but it didn't shed enough light on the problem.
"
5720,freeze_graph not working as expected,"I am currently attempting to export a protobuf file to Android. To do that, I generated a .pbtxt file using http://pastebin.com/HcWA0xMQ to run freeze_graph on. I saved the protobuf file as text because when I try to save it as binary and run it with freeze_graph, I get the following error:

```
Traceback (most recent call last):
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 135, in <module>
    tf.app.run()
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 132, in main
    FLAGS.output_graph, FLAGS.clear_devices, FLAGS.initializer_nodes)
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 98, in freeze_graph
    text_format.Merge(f.read().decode(""utf-8""), input_graph_def)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/encodings/utf_8.py"", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0x96 in position 331: invalid start byte
```

After generating the frozen graph with the .pbtxt file, I tried to run it on Android but for some reason am getting the same output every time regardless of the input. I also noticed, that the frozen graph is actually smaller than the checkpoint file even though it's supposed to be bigger according to the pre-release documentation I got ([deploying.txt](https://github.com/tensorflow/tensorflow/files/601596/deploying.txt)).

### Environment info
Operating System:
Mac OS 10.12
Tensorflow 0.11.0
Android Cyanogenmod 12

Code to create .pb file for `freeze_graph`: http://pastebin.com/HcWA0xMQ
My checkpoint file: [Y6_1476978999.zip](https://github.com/tensorflow/tensorflow/files/601598/Y6_1476978999.zip)


"
5719,[FEATURE REQUEST]Calculate topK on GPU with k-selection algos,"Hi,
I am currently using [tf.nn.top_k](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#top_k) in my code. However, I found this operation is calculated on CPU and it is quite slow.
So I am wondering if it is possible to calculate topK on GPU?

Here are the papers and cuda codes about k-selection on GPU:
http://www.math.grin.edu/~blanchaj/Research/ABGS_KSelection.pdf
https://code.google.com/p/ggks/

Hope someday this feature will be added to tensorflow.
"
5717,How to install Tensorflow on Python3 (using Bash on Ubuntu on Windows),"Hi,

I have Bash on Ubuntu on Windows (on Windows 10) also I have python 2.7, 3.4 and 3.5 installed. When I follow below url to install tensor flow it installs in python 2.7 only.

http://www.hanselman.com/blog/PlayingWithTensorFlowOnWindows.aspx

I want to install tensorflow on Python 3.5. Please let me know how to install the same. To move to python 3.5, I use python3.5 on the Bash command prompt.

Many Thanks, Thirumalai M"
5716,Universal dataset generation toolkit ?,"Is it feasible to add a build-in universal tool to create a TF dataset from raw source data, e.g. `dataset = tf.CreateDataSet(..RAW_SOURCE_PATH..)`, and then can use it like `dataset.train.next_batch, dataset.validation.epochs_completed` etc.."
5715,Problems importing Tensorflow to PyCharm and IDLE,"I am currently trying to use Tensorflow on PyCharm and IDLE. However, whenever I try to import Tensorflow (import tensorflow as tf), I get the following error:

```
Traceback (most recent call last):
  File ""/Users/leslie/PycharmProjects/untitled/tensor.py"", line 2, in <module>
    import tensorflow as tf
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
ImportError: dlopen(/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.8.0.dylib
  Referenced from: /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
  Reason: image not found
```

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

From looking around online, it seems that I need to install cuda on my machine. However, I do not have a NVIDIA graphics card nor a cuda-enabled card.

### Environment info
Operating System:
Mac OS 10.12
Tensorflow 0.11.0"
5707,AttributeError: type object 'NewBase' has no attribute 'is_abstract'  when I have update SIX,"Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Library/Python/2.7/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/Library/Python/2.7/site-packages/tensorflow/python/__init__.py"", line 98, in <module>
    from tensorflow.python.platform import test
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/test.py"", line 63, in <module>
    from tensorflow.python.framework import test_util
  File ""/Library/Python/2.7/site-packages/tensorflow/python/framework/test_util.py"", line 43, in <module>
    from tensorflow.python.platform import googletest
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/googletest.py"", line 32, in <module>
    from tensorflow.python.platform import benchmark  # pylint: disable=unused-import
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/benchmark.py"", line 122, in <module>
    class Benchmark(six.with_metaclass(_BenchmarkRegistrar, object)):
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six.py"", line 566, in with_metaclass
    return meta(""NewBase"", bases, {})
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/benchmark.py"", line 117, in __new__
    if not newclass.is_abstract():
AttributeError: type object 'NewBase' has no attribute 'is_abstract'
"
5705,bazel 0.4 support for tensorflow,"I am trying to build the tensorflow from source. I get errors like ""bazel-out/host/bin/external/grpc/grpc_cpp_plugin: program not found or is not executable"". But builds successfully. If bazel 0.4 is not supported, its a documentation bug here https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html to mention that bazel latest version should be downloaded. I could successfully build with bazel 0.3.x."
5704,null,set to null
5702,Tensorboard interactive demo is down. ,"https://www.tensorflow.org/tensorboard/index.html retuns:

> Error: Not Found
> The requested URL /tensorboard/index.html was not found on this server."
5701,Quantization tool is gone?,"if you run **bazel build tensorflow/contrib/quantization/tools:quantize_graph** with the latest code, it report error: can't not find the files.

if you go to **https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/quantization** folder, the files are not here already and there is no **tools** folder.

"
5700,Definition of epoch_size in PTB model leads to skipping last sample batch,"Not 100% sure this is a bug, please take a look:

The PTB RNN model (tensorflow/models/rnn/ptb/ptb_word_lm.py, line 92) defines a variable called epoch_size as 

self.epoch_size = ((len(data) // batch_size) - 1) // num_steps

(This variable is also defined in the same way in tensorflow/models/rnn/ptb/reader.py, line 108.) The variable is used on line 278 in ptb_word_lm.py:

for step in range(model.input.epoch_size):

I'm not sure why the ""- 1"" term is in the equation -- that is, I think it should be just

self.epoch_size = (len(data) // batch_size) // num_steps

The equation already uses floor division to round down. Currently, if both batch_size and num_steps are 1, epoch_size will be equal to data length - 1, so the last data sample will be skipped."
5696,API pages could use some search optimization,"When I search on Google for Tensorflow methods, the documentation is hard to distinguish in the search results. The API pages have irrelevant titles and aren't as highly ranked as they should be.

To reproduce:
Search for [tf extract_image_patches]
Expected behavior: I get a result with the API documentation: https://www.tensorflow.org/versions/r0.11/api_docs/python/array_ops.html
Observed behavior: this page shows up as result 3 with the mysterious title ""tf.pack - TensorFlow""

Another example is EveryN. If I add enough keywords, I get the API page as result 4 (search on [tf EveryN api tf.contrib.learn]). But it has the inscrutable title ""tf.contrib.learn.monitors.ExportMonitor.run_on_all_workers - TensorFlow""

This makes it difficult to find the documentation for methods.

Suggested fix: maybe make the page titles more descriptive, and add the word ""API""? Maybe have separate pages for each class, like JavaDocs?

"
5695,"strange output and jam while running ""train_setp.run()"" in tensorflow","I am a newcomer of Tensorflow and I encounter trouble while trying to train a convolutional neuralnetwork. I receive massive output information which seems initializing something while running:
**train_step.run(session=sess,feed_dict={x:batch[0],y_:batch[1],keep_prob:0.5})**
What is more, while testing the accuracy of my training data, the program output some information and stop working, so I have to stop it with ""ctrl+c"" 
I think there is something wrong with ""sess""  but I do not know how to fix them. Part of my code are listed below:
to emphasize the places I think are important and help you understand it quickly, I use # in my code and (  )in my output to express what  I think and mark some vital command by ->
```
->sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))
# I initialized my sess
for d in ['/gpu:0']:
    with tf.device(d):
        x=tf.placeholder(tf.float32,shape=[None, 224, 224, 1])
        y_=tf.placeholder(tf.float32,shape=[None,3])
      ->vggNet=vgg16( x, weights='vgg16_weights.npz', sess=sess)
         # vgg16 is a Class to define and initialize neuralnetwork
        cross_entropy = -tf.reduce_sum(y_*tf.log(tf.clip_by_value(vggNet.probs,1e-10,1.0)))
train_step=tf.train.AdamOptimizer(l_rate).minimize(cross_entropy)
correct_prediction=tf.equal(tf.argmax(vggNet.probs,1),tf.argmax(y_,1))
accuracy=tf.reduce_mean(tf.cast(correct_prediction,""float""))
->sess.run(tf.initialize_all_variables())
print ('\n\n\n session run successfully ! \n\n\n')
#I think after this, there should not be any initialize work
for i in range (20000):
    batch=octData.train.next_batch(train_batch_size)
    #load data to batch
    if (i+1)%5==0:
        print '#',
        #this has been printed
    if (i+1)%20==0:
        print ('evaluating train dataset ...')
        #this has been printed but the program get stuck after some output
        train_accuracy = sess.run(accuracy,feed_dict={x:batch[0], y_: batch[1], vggNet.keep_prob: 1.0})
        #after this my program jammed, the following print do not work
        print ""  step %d, training accuracy %g""%(i,train_accuracy)
   ->train_step.run(session=sess,feed_dict={x:batch[0],y_:batch[1],vggNet.keep_prob:0.5})
    #I think all the strange output are printed by this,vggNet.keep_prob is a parameter to control drop out in fc layer
```

According to the tutorial of tensorflow, the output in the loop **for i in range (20000):** should be what I print in the program. However, the following information are presented to me.

```
session run successfully !   
(I believe this is the printed info at previous line before the loop **for i in range (20000):**)


Adam/epsilon: /job:localhost/replica:0/task:0/gpu:0
. . .  . . . (I omit some similar output there )
gradients/clip_by_value/Minimum_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0
. . .  . . . 
fc3/weights/read: /job:localhost/replica:0/task:0/gpu:0
. . .  . . .
I tensorflow/core/common_runtime/simple_placer.cc:819] conv5_3/biases/read: /job:localhost/replica:0/task:0/gpu:0
. . .  . . .
conv5_3/biases/read: /job:localhost/replica:0/task:0/gpu:0
. . . . . . 
. . . . . . 
# # # # evaluating train dataset ...
(I think the program is about to calculate the accuracy of training set)
. . . . . .
fc3/biases/read: /job:localhost/replica:0/task:0/gpu:0
. , . . . .
I tensorflow/core/common_runtime/simple_placer.cc:819] fc1/Reshape/shape: /job:localhost/replica:0/task:0/gpu:0
```
And after that my program got jammed. There is nothing wrong with the batch, which is used to read data and it has nothing to do with tensorflow. I think **sess** is the most likely cause of the problem. Do anybody know what is going on and how to fix it?"
5694,FusedBatchNorm does not support 3D Filters,"The current implementation of `tf.contrib.layers.batch_norm` is quite slow with the default parameters. Recent builds of TF support `fused=True` which forces the use of the faster `nn.fused_batch_norm`. However this method does not support 3D filters for computing the mean and variance. The normal (slower) variant with `fused=False` does not have this problem.

**FusedBatchNorm**:
```python
# Following error is raised when trying to batch normalize 3D filters
elif original_rank not in [2, 4]:
      raise ValueError('Inputs %s has unsupported rank. \
          Expected 2 or 4 but got %d' % (inputs.name, original_rank))
```

And the default implementation without the fused version uses these axis to compute the `tf.nn.moments`:

```python
axis = list(range(inputs_rank - 1))
```

This also works for 3D filters of course. See code: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L483"
5688,tensorflow crashes when using large image with 3d convolutional network,"I'm trying to implement a 3d fully convolutional network on my GPU. But for some reason I get a crash.

### Environment info
Operating System: Ubuntu 14.04 LTS
GPU: GeForce Titan X .

Installed version of CUDA and cuDNN: 8.0 and 5
(attach the output of `ls -l /path/to/cuda/lib/libcud* 
[cud.filelist.txt](https://github.com/tensorflow/tensorflow/files/599236/cud.filelist.txt) )

I installed tensorflow version 0.11.0rc2, and it also reproduce in docker installation (gcr.io/tensorflow/tensorflow:latest-gpu)

### Example code
The following code reproduce the problem:

    import numpy as np
    import tensorflow as tf

    graph = tf.Graph()

    with graph.as_default():
        tf_dataset = tf.placeholder(tf.float32, shape=(1, 512, 512, 512, 1))
        tf_label = tf.placeholder(tf.float32, shape=(1, 512, 512, 512, 1))

        layer1_weights = tf.Variable(tf.truncated_normal((2, 2, 2, 1, 1), stddev=0.1))
        layer1_bias = tf.Variable(tf.zeros(1))

        conv = tf.nn.conv3d(tf_dataset, layer1_weights, (1, 1, 1, 1, 1), padding='SAME')
        logits = tf.nn.relu(conv+layer1_bias)

        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_label))
        optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)

    with tf.Session(graph=graph) as session:
        tf.initialize_all_variables().run()
        batchData = np.random.rand(1, 512, 512, 512, 1).astype(np.float32)
        batchLabels = (np.random.rand(1, 512, 512, 512, 1)>0.5).astype(np.float32)
        feed_dict = {tf_dataset : batchData, tf_label : batchLabels}
        _ = session.run((optimizer, ), feed_dict=feed_dict)

with the following output:

> I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:01:00.0
Total memory: 11.92GiB
Free memory: 11.68GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)
F tensorflow/stream_executor/cuda/cuda_dnn.cc:2440] failed to enqueue convolution on stream: CUDNN_STATUS_NOT_SUPPORTED

"
5684,Building the library on Raspberry Pi results in: undefined reference to `google::protobuf::internal::fixed_address_empty_string',"Hello,

I was told to post this question here:

I am trying to complete a fresh install of Tensorflow on my Raspberry Pi following a failed previous install. I figured it would be easier trying to start fresh so I could more easily document my progress, and what solutions worked or failed. Additionally the new guide is easier to follow than the old guide I was using.

I am following the guide [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#raspberry-pi) and have been able to complete all of the steps up until the `make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=""-Os"" CXX=g++-4.8 `command. NOTE: I did not install the example graph.

However when attempting to run this command I am left with several errors. The full output is rather long, but the main recurring error is similar to:

`test_log.pb.cc:(.text+0x784): undefined reference to `google::protobuf::internal::fixed_address_empty_string'`
This kind of error is repeated several times throughout the output for the `make -f command with test_log.pb.cc:(.text+0x784): ` being replaced with different designations. The output ends with the Following error state:

```
step_stats_collector.cc:(.text+0x46c): undefined reference to `google::protobuf::internal::fixed_address_empty_string'
/home/pi/makevoicedemo/tf/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a(debug_io_utils.o):debug_io_utils.cc:(.text+0x8e8): more undefined references to `google::protobuf::internal::fixed_address_empty_string' follow
collect2: error: ld returned 1 exit status
tensorflow/contrib/makefile/Makefile:501: recipe for target '/home/pi/makevoicedemo/tf/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark' failed
make: *** [/home/pi/makevoicedemo/tf/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark] Error 1
```
I feel like the problem is likely do to an error with protobuf, however I am using the latest version and had no errors installing it. I am using the most recent version of tensorflow and followed the Before you start section in the guide to make sure all dependencies were installed and up to date.

What exactly might be causing this error and how would I go about fixing it?

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

[http://stackoverflow.com/questions/38915709/problems-on-builiding-tensorflow-on-rpi-2](http://stackoverflow.com/questions/38915709/problems-on-builiding-tensorflow-on-rpi-2)



### Environment info
Operating System:
Raspbian Jessie

Installed version of CUDA and cuDNN: 
N/A
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
`ls: cannot access /path/to/cuda/lib/libcud*: No such file or directory
`
If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
`a2d96ca09e9943b4bad65b674d29d380dc6a8327`

2. The output of `bazel version`

```
...........................................................................
Build label: 0.2.1-2016-09-15 (@e7a95e5)
Build target: bazel-out/local_linux-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Sep 16 00:46:39 2016 (1473986799)
Build timestamp: 1473986799
Build timestamp as int: 1473986799

```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
Steps taken (in order) from pre-created directory /tf:

```
git clone https://github.com/tensorflow/tensorflow.git

cd tensorflow

tensorflow/contrib/makefile/download_dependencies.sh

sudo apt-get install -y autoconf automake libtool gcc-4.8 g++-4.8

cd tensorflow/contrib/makefile/downloads/protobuf/

./autogen.sh

./configure

make

sudo make install

sudo ldconfig

cd ../../../../..

make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=""-Os"" CXX=g++-4.8
```
The final command results in the error and is as far as I have been able to progress.


### What other attempted solutions have you tried?
I have not come across any applicable solutions to try. 

Any help would be appreciated.
"
5683,Synchronous distributed training is too slow,"While trying to train Imagenet using Inceptionv3, I noticed the training was proceeding too slow. I then tested with Alexnet and Resnet and I saw the same slow training speed. 

Here is the images/sec I'm able to achieve on various models:

```
Inceptionv3:
# GPU, Images/sec
1,        17.525
2,        34.568
4,        62.580
8,        94.832
16,       99.072
32,       140.704
64,       183.488
128,      322.816

Alexnet:
1,        92.464
2,        189.736
4,        344.336
8,        532.40
16,       710.224
32,       878.944
64,       848.128
128,      874.624

Resnet 152:
1,        10.567
2,        20.224
4,        32.332
8,        37.952
16,       42.416
32,       66.016
64,       95.168
128,      152.192

```
Is it possible there is some bug causing this slow performance?

I'm using EC2 P2 instances (p2.16xlarge). Each instance has 16 GPUs. Each GPU is a Tesla K80. I'm running one worker per GPU and one PS per host. Here is more info on P2 instances: https://aws.amazon.com/ec2/instance-types/p2/

I use randomly generated synthetic data for images and label. I've written some scripts to reproduce this issue in case it helps: https://github.com/indhub/tfperftest/tree/master/perftest

- Inception model is based on https://github.com/tensorflow/models/tree/master/inception. I've done some changes to use randomly generated synthetic data for images and labels. Modified code here: https://github.com/indhub/tfperftest/tree/master/inception
- Resnet model is based on https://github.com/tensorflow/models/tree/master/resnet. I've done some changes to build Resnet 152. Modified code here: https://github.com/indhub/tfperftest/tree/master/resnet
- Alexnet model is based on https://github.com/tensorflow/tensorflow/blob/816ecb7a342c25c19daa8b19627346e1fb38e56f/tensorflow/models/image/alexnet/alexnet_benchmark.py. I've added the fully connected layers at the end. Modified code here: https://github.com/indhub/tfperftest/blob/master/alexnet/alexnet.py

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
http://stackoverflow.com/questions/40411597/synchronous-distributed-training-is-slow

### Environment info
Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
ubuntu@ip-172-31-52-161:~$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root 558720 Sep 14 23:02 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Sep 14 23:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root     19 Sep 14 23:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root 415432 Sep 14 23:02 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root 775162 Sep 14 23:02 /usr/local/cuda/lib64/libcudart_static.a

```

If installed from binary pip package, provide:

1. A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
ubuntu@ip-172-31-52-161:~$ python -c ""import tensorflow; print(tensorflow.__version__)""
```
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
0.11.0rc2

```


### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

Just running https://github.com/tensorflow/models/tree/master/inception reproduces the problem. 
"
5682,Implement a method that returns amount of seconds since the epoch (time),"In order to add timestamp to the ```tf.Print``` (as per #2076 ) there should be a method that provides time (something like: SecondsAfterEpoch). Existing API ([env.h](https://github.com/tensorflow/tensorflow/blob/dd01113c2b9efb16c3c3ea0a4aaa340a0494696f/tensorflow/core/platform/env.h)) provides 2 method to obtain time:
-  [NowSeconds](https://github.com/tensorflow/tensorflow/blob/dd01113c2b9efb16c3c3ea0a4aaa340a0494696f/tensorflow/core/platform/env.h#L217);
- [NowMicros](https://github.com/tensorflow/tensorflow/blob/dd01113c2b9efb16c3c3ea0a4aaa340a0494696f/tensorflow/core/platform/env.h#L213);

This makes both of them unusable for the task of adding the timestamp to the logging output. "
5681,Windows build of the PIP package fails : error LNK1120 LNK2019 LNK2001,"@mrry Thanks for all your contributions to the windows version of tensorflow. 
 I'm building tensorflow on windows 7 with CMake 3.6.3, GIT 2.10.1, Python 3.5.2 (NOT anaconda), the MsBuilt of VS 2015 (v 14.0.252420.1) and swigwin 3.0.10 without the GPU.

It successfully built the tf_tutorials_example_trainer target. However the MsBuild fails to build the PIP package, and gives 113 errors!
This is CMake command I used:

cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release  -DSWIG_EXECUTABLE=c:/swigwin-3.0.10/swig.exe  -DPYTHON_EXECUTABLE=""c:/Program Files (x86)/Python35-32/python.exe"" -DPYTHON_LIBRARIES=""c:/Program Files (x86)/Python35-32/libs/python35.lib"" 

which finished with no errors, and this is MsBuild command I'm trying to run:

MSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj /filelogger

Can anyone tell me what is going wrong?

The error reads like:


> ""C:\Temp\tensorflow\tensorflow\contrib\cmake\release\tf_python_build_pip_package.vcxproj"" (default target) (1) ->
> ""C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj"" (default target) (3) ->
> (Link target) -> 
>   tf_session_helper.obj : error LNK2019: unresolved external symbol __imp_PyBytes_FromStringAndSize referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::CopyStringToPyArrayElement(struct tagPyArrayObject *,void *,struct TF_Tensor *,__int64,__int64)"" (?CopyStringToPyArrayElement@?A0x2033429b@tensorflow@@YA?AVStatus@2@PEAUtagPyArrayObject@@PEAXPEAUTF_Tensor@@_J3@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2001: unresolved external symbol __imp_PyBytes_FromStringAndSize [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyBytes_FromStringAndSize [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   tf_session_helper.obj : error LNK2019: unresolved external symbol __imp_PyBytes_AsString referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::PyArrayDescr_to_TF_DataType(struct _PyArray_Descr *,enum TF_DataType *)"" (?PyArrayDescr_to_TF_DataType@?A0x2033429b@tensorflow@@YA?AVStatus@2@PEAU_PyArray_Descr@@PEAW4TF_DataType@@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyBytes_AsString [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   tf_session_helper.obj : error LNK2019: unresolved external symbol __imp_PyBytes_AsStringAndSize referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::PyBytesArrayMap<class <lambda_61881d22c4163ba98e316eda8a26e1e2> >(struct tagPyArrayObject *,class <lambda_61881d22c4163ba98e316eda8a26e1e2>)"" (??$PyBytesArrayMap@V<lambda_61881d22c4163ba98e316eda8a26e1e2>@@@?A0x2033429b@tensorflow@@YA?AVStatus@1@PEAUtagPyArrayObject@@V<lambda_61881d22c4163ba98e316eda8a26e1e2>@@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2001: unresolved external symbol __imp_PyBytes_AsStringAndSize [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyBytes_AsStringAndSize [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   tf_session_helper.obj : error LNK2019: unresolved external symbol __imp_PyUnicode_AsUTF8AndSize referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::PyBytesArrayMap<class <lambda_61881d22c4163ba98e316eda8a26e1e2> >(struct tagPyArrayObject *,class <lambda_61881d22c4163ba98e316eda8a26e1e2>)"" (??$PyBytesArrayMap@V<lambda_61881d22c4163ba98e316eda8a26e1e2>@@@?A0x2033429b@tensorflow@@YA?AVStatus@1@PEAUtagPyArrayObject@@V<lambda_61881d22c4163ba98e316eda8a26e1e2>@@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   tf_session_helper.obj : error LNK2019: unresolved external symbol __imp_PyDict_Next referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::PyArrayDescr_to_TF_DataType(struct _PyArray_Descr *,enum TF_DataType *)"" (?PyArrayDescr_to_TF_DataType@?A0x2033429b@tensorflow@@YA?AVStatus@2@PEAU_PyArray_Descr@@PEAW4TF_DataType@@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   tf_session_helper.obj : error LNK2019: unresolved external symbol __imp_PyEval_SaveThread referenced in function ""void __cdecl tensorflow::TF_PRunSetup_wrapper(struct TF_DeprecatedSession *,class tensorflow::gtl::InlinedVector<char const *,8> const &,class tensorflow::gtl::InlinedVector<char const *,8> const &,class tensorflow::gtl::InlinedVector<char const *,8> const &,struct TF_Status *,char const * *)"" (?TF_PRunSetup_wrapper@tensorflow@@YAXPEAUTF_DeprecatedSession@@AEBV?$InlinedVector@PEBD$07@gtl@1@11PEAUTF_Status@@PEAPEBD@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyEval_SaveThread [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   tf_session_helper.obj : error LNK2019: unresolved external symbol __imp_PyEval_RestoreThread referenced in function ""void __cdecl tensorflow::TF_PRunSetup_wrapper(struct TF_DeprecatedSession *,class tensorflow::gtl::InlinedVector<char const *,8> const &,class tensorflow::gtl::InlinedVector<char const *,8> const &,class tensorflow::gtl::InlinedVector<char const *,8> const &,struct TF_Status *,char const * *)"" (?TF_PRunSetup_wrapper@tensorflow@@YAXPEAUTF_DeprecatedSession@@AEBV?$InlinedVector@PEBD$07@gtl@1@11PEAUTF_Status@@PEAPEBD@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyEval_RestoreThread [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   tf_session_helper.obj : error LNK2019: unresolved external symbol __imp__Py_NoneStruct referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::TF_Tensor_to_PyObject(struct TF_Tensor *,struct _object * *)"" (?TF_Tensor_to_PyObject@?A0x2033429b@tensorflow@@YA?AVStatus@2@PEAUTF_Tensor@@PEAPEAU_object@@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   cpp_shape_inference.obj : error LNK2001: unresolved external symbol __imp__Py_NoneStruct [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2001: unresolved external symbol __imp__Py_NoneStruct [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   cpp_shape_inference.obj : error LNK2019: unresolved external symbol __imp_PyList_Size referenced in function ""class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > __cdecl tensorflow::swig::RunCppShapeInference(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > const &,struct _object *,class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > const &,struct TF_Status *)"" (?RunCppShapeInference@swig@tensorflow@@YA?AV?$vector@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$allocator@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@@std@@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@4@AEBV34@PEAU_object@@1PEAUTF_Status@@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2001: unresolved external symbol __imp_PyList_Size [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyList_Size [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   cpp_shape_inference.obj : error LNK2019: unresolved external symbol __imp_PyList_GetItem referenced in function ""class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > __cdecl tensorflow::swig::RunCppShapeInference(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > const &,struct _object *,class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > const &,struct TF_Status *)"" (?RunCppShapeInference@swig@tensorflow@@YA?AV?$vector@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$allocator@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@@std@@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@4@AEBV34@PEAU_object@@1PEAUTF_Status@@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2001: unresolved external symbol __imp_PyList_GetItem [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyList_GetItem [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   numpy.obj : error LNK2019: unresolved external symbol __imp_PyObject_GetAttrString referenced in function _import_array [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyObject_GetAttrString [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   numpy.obj : error LNK2019: unresolved external symbol __imp_PyCapsule_GetPointer referenced in function _import_array [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyCapsule_GetPointer [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   numpy.obj : error LNK2019: unresolved external symbol __imp_PyErr_SetString referenced in function ""void __cdecl tensorflow::ImportNumpy(void)"" (?ImportNumpy@tensorflow@@YAXXZ) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyErr_SetString [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   numpy.obj : error LNK2019: unresolved external symbol __imp_PyErr_Format referenced in function _import_array [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   numpy.obj : error LNK2019: unresolved external symbol __imp_PyErr_Print referenced in function ""void __cdecl tensorflow::ImportNumpy(void)"" (?ImportNumpy@tensorflow@@YAXXZ) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2001: unresolved external symbol __imp_PyErr_Print [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   numpy.obj : error LNK2019: unresolved external symbol __imp_PyImport_ImportModule referenced in function _import_array [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   numpy.obj : error LNK2019: unresolved external symbol __imp_PyCapsule_Type referenced in function _import_array [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   numpy.obj : error LNK2019: unresolved external symbol __imp_PyExc_AttributeError referenced in function _import_array [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyExc_AttributeError [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   numpy.obj : error LNK2019: unresolved external symbol __imp_PyExc_ImportError referenced in function ""void __cdecl tensorflow::ImportNumpy(void)"" (?ImportNumpy@tensorflow@@YAXXZ) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   numpy.obj : error LNK2019: unresolved external symbol __imp_PyExc_RuntimeError referenced in function _import_array [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyExc_RuntimeError [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2019: unresolved external symbol __imp_PyType_IsSubtype referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::DoCallPyFunc(struct tensorflow::A0x053e5023::PyCall *)"" (?DoCallPyFunc@?A0x053e5023@tensorflow@@YA?AVStatus@2@PEAUPyCall@12@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2019: unresolved external symbol __imp_PyList_New referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::MakeArgTuple(struct tensorflow::A0x053e5023::PyCall *,struct _object * *)"" (?MakeArgTuple@?A0x053e5023@tensorflow@@YA?AVStatus@2@PEAUPyCall@12@PEAPEAU_object@@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyList_New [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2019: unresolved external symbol __imp_PyList_SetItem referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::MakeArgTuple(struct tensorflow::A0x053e5023::PyCall *,struct _object * *)"" (?MakeArgTuple@?A0x053e5023@tensorflow@@YA?AVStatus@2@PEAUPyCall@12@PEAPEAU_object@@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2019: unresolved external symbol __imp_PyGILState_Ensure referenced in function ""public: virtual void __cdecl tensorflow::PyFuncOp::Compute(class tensorflow::OpKernelContext *)"" (?Compute@PyFuncOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2019: unresolved external symbol __imp_PyGILState_Release referenced in function ""public: virtual void __cdecl tensorflow::PyFuncOp::Compute(class tensorflow::OpKernelContext *)"" (?Compute@PyFuncOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2019: unresolved external symbol __imp_PyErr_Occurred referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::DoCallPyFunc(struct tensorflow::A0x053e5023::PyCall *)"" (?DoCallPyFunc@?A0x053e5023@tensorflow@@YA?AVStatus@2@PEAUPyCall@12@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyErr_Occurred [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2019: unresolved external symbol __imp_Py_BuildValue referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::MakeArgTuple(struct tensorflow::A0x053e5023::PyCall *,struct _object * *)"" (?MakeArgTuple@?A0x053e5023@tensorflow@@YA?AVStatus@2@PEAUPyCall@12@PEAPEAU_object@@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_Py_BuildValue [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   py_func.obj : error LNK2019: unresolved external symbol __imp_PyEval_CallObjectWithKeywords referenced in function ""class tensorflow::Status __cdecl tensorflow::`anonymous namespace'::DoCallPyFunc(struct tensorflow::A0x053e5023::PyCall *)"" (?DoCallPyFunc@?A0x053e5023@tensorflow@@YA?AVStatus@2@PEAUPyCall@12@@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyType_Type referenced in function SwigPyClientData_New [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyBool_Type referenced in function _wrap_FileStatistics_is_directory_set [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyExc_IndexError referenced in function ""struct _object * __cdecl SWIG_Python_ErrorType(int)"" (?SWIG_Python_ErrorType@@YAPEAU_object@@H@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyExc_MemoryError referenced in function ""struct _object * __cdecl SWIG_Python_ErrorType(int)"" (?SWIG_Python_ErrorType@@YAPEAU_object@@H@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyExc_OverflowError referenced in function ""struct _object * __cdecl SWIG_Python_ErrorType(int)"" (?SWIG_Python_ErrorType@@YAPEAU_object@@H@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyExc_NotImplementedError referenced in function _wrap_new_Status [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyExc_SyntaxError referenced in function ""struct _object * __cdecl SWIG_Python_ErrorType(int)"" (?SWIG_Python_ErrorType@@YAPEAU_object@@H@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyExc_SystemError referenced in function ""struct _object * __cdecl SWIG_Python_ErrorType(int)"" (?SWIG_Python_ErrorType@@YAPEAU_object@@H@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyExc_TypeError referenced in function SwigPyObject_append [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyExc_ValueError referenced in function _wrap_StatSummarizer_ProcessStepStats [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyExc_ZeroDivisionError referenced in function ""struct _object * __cdecl SWIG_Python_ErrorType(int)"" (?SWIG_Python_ErrorType@@YAPEAU_object@@H@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyExc_IOError referenced in function ""struct _object * __cdecl SWIG_Python_ErrorType(int)"" (?SWIG_Python_ErrorType@@YAPEAU_object@@H@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyType_Ready referenced in function SwigPyObject_TypeOnce [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyObject_GetAttr referenced in function SWIG_Python_GetSwigThis [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyObject_SetAttr referenced in function SWIG_Python_NewShadowInstance [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyObject_GenericGetAttr referenced in function SwigPyObject_TypeOnce [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyObject_IsTrue referenced in function SwigPyObject_own [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_Py_DecRef referenced in function SwigPyObject_repr [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyObject_Malloc referenced in function SwigPyObject_New [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyObject_Free referenced in function SwigPyObject_dealloc [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyObject_Init referenced in function SwigPyObject_New [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp__PyObject_New referenced in function SWIG_Python_NewPointerObj [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyUnicode_FromStringAndSize referenced in function _wrap_CheckpointReader_get_variable_to_shape_map [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyUnicode_FromString referenced in function SWIG_Python_DestroyModule [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyUnicode_FromFormat referenced in function SwigPyObject_repr [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyUnicode_DecodeUTF8 referenced in function _wrap_StatSummarizer_GetOutputString [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyUnicode_AsUTF8String referenced in function _wrap_TF_PRun [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyUnicode_Concat referenced in function SwigPyObject_repr [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyLong_FromLong referenced in function _wrap_FileStatistics_length_get [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyLong_AsLong referenced in function _wrap_DoQuantizeTrainingOnGraphDefHelper [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2001: unresolved external symbol __imp_PyLong_AsUnsignedLong [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyLong_FromVoidPtr referenced in function SwigPyObject_long [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyLong_FromLongLong referenced in function _wrap_FileStatistics_length_get [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyLong_FromUnsignedLongLong referenced in function _wrap_PyRecordReader_offset [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyLong_AsLongLong referenced in function _wrap_FileStatistics_length_set [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyLong_AsUnsignedLongLong referenced in function _wrap_PyRecordReader_New [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyBool_FromLong referenced in function _wrap_IsDirectory [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyTuple_New referenced in function SwigPyClientData_New [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyTuple_SetItem referenced in function SwigPyClientData_New [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyDict_New referenced in function _wrap_CheckpointReader_get_variable_to_shape_map [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyDict_SetItem referenced in function _wrap_CheckpointReader_get_variable_to_shape_map [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyDict_SetItemString referenced in function PyInit__pywrap_tensorflow [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyModule_GetDict referenced in function PyInit__pywrap_tensorflow [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyInstanceMethod_New referenced in function SWIG_PyInstanceMethod_New [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyCapsule_New referenced in function SWIG_InitializeModule [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyCapsule_Import referenced in function SWIG_InitializeModule [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyErr_Clear referenced in function _wrap_FileStatistics_length_set [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyErr_Fetch referenced in function SwigPyObject_dealloc [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyErr_Restore referenced in function SwigPyObject_dealloc [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyErr_WriteUnraisable referenced in function SwigPyObject_dealloc [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyArg_ParseTuple referenced in function _wrap_PyRecordWriter_Close [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyArg_UnpackTuple referenced in function SwigPyObject_own [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyModule_AddObject referenced in function SWIG_InitializeModule [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyModule_Create2 referenced in function PyInit__pywrap_tensorflow [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyImport_AddModule referenced in function SWIG_InitializeModule [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyObject_Call referenced in function SWIG_Python_NewShadowInstance [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyObject_CallFunctionObjArgs referenced in function SWIG_Python_ConvertPtrAndOwn [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyObject_Size referenced in function _wrap_new_Status [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyObject_GetIter referenced in function ""bool __cdecl tf_vector_input_helper<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >(struct _object *,class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > *,bool (__cdecl*)(struct _object *,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > * const))"" (??$tf_vector_input_helper@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@@YA_NPEAU_object@@PEAV?$vector@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$allocator@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@@std@@P6A_N0QEAV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@2@@Z@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyIter_Next referenced in function ""bool __cdecl tf_vector_input_helper<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >(struct _object *,class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > *,bool (__cdecl*)(struct _object *,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > * const))"" (??$tf_vector_input_helper@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@@YA_NPEAU_object@@PEAV?$vector@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$allocator@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@@std@@P6A_N0QEAV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@2@@Z@Z) [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp_PyObject_IsInstance referenced in function SwigPyClientData_New [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   pywrap_tensorflow.obj : error LNK2019: unresolved external symbol __imp__Py_NotImplementedStruct referenced in function SwigPyObject_richcompare [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
>   C:\Temp\tensorflow\tensorflow\contrib\cmake\release\Release\pywrap_tensorflow.dll : fatal error LNK1120: 90 unresolved externals [C:\Temp\tensorflow\tensorflow\contrib\cmake\release\pywrap_tensorflow.vcxproj]
> 
>     355 Warning(s)
>     113 Error(s)
> 
> Time Elapsed 00:34:22.63
"
5680,Any way to clear/reset the static shape to None?,"`Tensor.set_shape()` doesn't set shape but merge shape. If I don't want the statically-inferred shape, could there be a method to clear it?

The use case is as following: I have:
```python
x = tf.random_uniform([128,10])
# other operations involving x
```
in the graph, but I want to be able to run it (in inference time) with `feed_dict={x: value}` where `value` is a tensor of shape [1, 10]. It would work perfectly if I could somehow set the shape of x to [None, 10].
Currently I'm using `tf.shape()` as argument of `random_uniform` to avoid shape inference and `set_shape` later, which is not a very nice solution."
5677,run bazel build tensorflow/examples/label_image/...  fail,"I just sync the **latest code** and build from source.

https://www.tensorflow.org/versions/r0.11/tutorials/image_recognition/index.html

i run **bazel build tensorflow/examples/label_image/...** get error:

ERROR: /home/scopeserver/RaidDisk/tensorflow/tensorflow/examples/label_image/BUILD:10:1: no such package 'tensorflow/contrib/quantization/kernels': BUILD file not found on package path and referenced by '//tensorflow/examples/label_image:label_image'.
ERROR: Analysis of target '//tensorflow/examples/label_image:label_image' failed; build aborted.
INFO: Elapsed time: 0.116s
"
5676,UnicodeDecodeError when reading from tfrecords,"All I'm really trying to do is read a large array from a tfrecords file. I can do it so long that it's below a 8million ints but above that I get a unicode error, which doesn't seem to make much sense to me. Also, it worth noting that this script works using r0.9. I have about 64GB of ram on my computer so I doubt it's a memory issue. 

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
None

### Environment info
Operating System:
Linux Mint 18 Sarah (GNU/Linux 4.4.0-47-generic x86_64)

Installed version of CUDA and cuDNN: 
not installed

If installed from binary pip package, provide:

1. A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
python -c ""import tensorflow; print(tensorflow.__version__)""

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```
import tensorflow as tf
import numpy as np

dim_size = 9000000

# Create the array
array = np.zeros([dim_size], dtype=int)

example = tf.train.Example(
    features = tf.train.Features(
        feature = {
            'array': tf.train.Feature(
                bytes_list= tf.train.BytesList(value=[array.tostring()])
            )
        }
    )
)

# Write the example to disk
writer = tf.python_io.TFRecordWriter('temp.tfrecords')
writer.write(example.SerializeToString())
writer.close()

# Define input pipeline
queue = tf.train.string_input_producer(['temp.tfrecords'], shuffle=False, num_epochs=1)
reader = tf.TFRecordReader()
_, se = reader.read(queue)

#Define the parsed dict
parsed = tf.parse_single_example(
    serialized=se,
    features={
        ""array"":tf.FixedLenFeature([], tf.string),
    }
)

# Decode the example
tens = tf.decode_raw(parsed['array'], tf.int64)

# Define the init op.
init_op = tf.group(
    tf.initialize_all_variables(),
    tf.initialize_local_variables()
)
with tf.Session() as sess:
    sess.run(init_op)
    # Define coordinator and threads
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord, sess=sess)

    # Run the reading operation
    print sess.run([tens])
    coord.request_stop()
    coord.join(threads)
```

### What other attempted solutions have you tried?
This works using r0.9 and it also works if you lower the dim_size below 800000. So it seems to be an issue with the size and r0.11. I also get the same results if I use a float array as opposed to an int. 

### Logs or other output that would be helpful
```
W tensorflow/core/framework/op_kernel.cc:968] Invalid argument: Could not parse example input, value: '
?Äª""
?Äª""
array?Äª""
?Äª""
?Äª""
Traceback (most recent call last):
  File ""temp.py"", line 52, in <module>
    print sess.run([tens])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 915, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 965, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 972, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 954, in _run_fn
    status, run_metadata)
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors.py"", line 462, in raise_exception_on_not_ok_status
    compat.as_text(pywrap_tensorflow.TF_Message(status)),
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/compat.py"", line 82, in as_text
    return bytes_or_text.decode('utf-8')
  File ""/usr/lib/python2.7/encodings/utf_8.py"", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0x9b in position 40: invalid start byte
```
"
5674,run ./configure error ,"I just sync the latest code and try to build from source. CUDA version 8, cuDNN 5.1.5, Ubuntu 16.04


run ./configure  and get the error below:


ERROR: /home/scopeserver/tensorflow/tensorflow/models/syntaxnet/syntaxnet/BUILD:76:1: **no such package '@org_tensorflow//tensorflow/core':** error loading package 'external': The repository named **'org_tensorflow' could not be resolved and referenced by '//tensorflow/models/syntaxnet/syntaxnet:base'.**
ERROR: /home/scopeserver/tensorflow/tensorflow/models/inception/inception/slim/BUILD:41:1: no such package 'inception': BUILD file not found on package path and referenced by '//tensorflow/models/inception/inception/slim:losses'.
ERROR: /home/scopeserver/tensorflow/tensorflow/models/inception/inception/slim/BUILD:43:12: no such package 'inception': BUILD file not found on package path (this is usually caused by a missing package group in the package-level visibility declaration).
ERROR: Evaluation of query ""deps((//tensorflow/... union @bazel_tools//tools/jdk:toolchain))"" failed: errors were encountered while computing transitive closure.
"
5673,Possible typo in docstring of embedding_rnn_seq2seq and embedding_attention_seq2seq?,"So in the docstring of embedding_rnn_seq2seq:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L296

It says:

```
  This model first embeds encoder_inputs by a newly created embedding (of shape
  [num_encoder_symbols x input_size]). Then it runs an RNN to encode
```

Should that instead read:

```
  [embedding_size x input_size]). Then it runs an RNN to encode
```

Since if you are creating an embedding it is to do dimensionality reduction (and so you usually want your embedding size to be smaller than the number of encoder symbols). Also in the code:

```
    # Encoder.
    encoder_cell = rnn_cell.EmbeddingWrapper(
        cell, embedding_classes=num_encoder_symbols,
        embedding_size=embedding_size)
    _, encoder_state = rnn.rnn(encoder_cell, encoder_inputs, dtype=dtype)
```

It looks like the encoder inputs are mapped to vectors of size embedding_size.

Looking forward to hearing the community thoughts (this is also the case in the docstring of embedding_attention_seq2seq)."
5671,'tensorflow.core.framework.types_pb2' has no attribute 'DT_RESOURCE',"I successfully built the PIP package (at HEAD) on Windows with cmake.  When I tried to import it, I met several errors that all boil down to the following:

```
AttributeError: module 'tensorflow.core.framework.types_pb2' has no attribute 'DT_RESOURCE'
AttributeError: module 'tensorflow.core.framework.types_pb2' has no attribute 'DT_RESOURCE_REF'
```"
5670,Windows cmake build errors,"@mrry I tried to build the HEAD and got the errors below:

```
""C:\src\tensorflow\tensorflow\contrib\cmake\build\tf_python_build_pip_package.vcxproj"" (default target) (1) ->
""C:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.vcxproj"" (default target) (3) ->
(ClCompile target) ->
  c:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.cc(3823): error C2440: 'return': cannot convert from 'tensorflow::Status' to 'bool' [C:\sr
c\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.vcxproj]
  c:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.cc(3827): error C2440: 'return': cannot convert from 'tensorflow::Status' to 'bool' [C:\sr
c\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.vcxproj]
  c:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.cc(5227): error C2660: 'TF_NewSession': function does not take 2 arguments [C:\src\tensorf
low\tensorflow\contrib\cmake\build\pywrap_tensorflow.vcxproj]
  c:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.cc(5343): error C2664: 'void TF_ExtendGraph(TF_DeprecatedSession *,const void *,size_t,TF_
Status *)': cannot convert argument 1 from 'TF_Session *' to 'TF_DeprecatedSession *' [C:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.vcxpr
oj]
  c:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.cc(5544): error C2664: 'void tensorflow::TF_Run_wrapper(TF_DeprecatedSession *,const TF_Bu
ffer *,PyObject *,const tensorflow::NameVector &,const tensorflow::NameVector &,TF_Status *,tensorflow::PyObjectVector *,TF_Buffer *)': cannot convert argument
 1 from 'TF_Session *' to 'TF_DeprecatedSession *' [C:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.vcxproj]
  c:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.cc(5709): error C2664: 'void tensorflow::TF_PRunSetup_wrapper(TF_DeprecatedSession *,const
 tensorflow::NameVector &,const tensorflow::NameVector &,const tensorflow::NameVector &,TF_Status *,const char **)': cannot convert argument 1 from 'TF_Session
 *' to 'TF_DeprecatedSession *' [C:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.vcxproj]
  c:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.cc(5804): error C2664: 'void tensorflow::TF_PRun_wrapper(TF_DeprecatedSession *,const char
 *,PyObject *,const tensorflow::NameVector &,TF_Status *,tensorflow::PyObjectVector *)': cannot convert argument 1 from 'TF_Session *' to 'TF_DeprecatedSession
 *' [C:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.vcxproj]
  c:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.cc(7501): error C2660: 'tensorflow::swig::RunCppShapeInference': function does not take 4
arguments [C:\src\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.vcxproj]

    341 Warning(s)
    8 Error(s)
```"
5669,Small typo in documentation,In the code example in https://www.tensorflow.org/versions/r0.11/api_docs/python/train.html#replica_device_setter  `tf.replica_device_setter` is used instead of `tf.train.replica_device_setter`.
5667,Documentation shows None default instead of actual op attr default,"This is not a bug but a small mistake in the API:
The [documentation ](https://www.tensorflow.org/versions/r0.11/api_docs/python/state_ops.html#assign) says ""use_locking"" defaults to _None_ in **tf.assign**.
That parameter is a boolean, so _None_ would not make a lot of sense. In any case, the source code makes it clear the default value is actually _False_ (file: tensorflow/tensorflow/python/ops/variables.py)

I do not know if this is the case with other boolean default arguments in other functions, but I wanted to point it out."
5666,about  this error when i try to run the existing wide_n_deep_tutorial.py,"Hello,
I get this error when i try to run the existing wide_n_deep_tutorial.py, any ideas on this?

(tensorflow) xx@ubuntu:~$ python wide_n_deep_tutorial.py --model_type=wide_n_deep

Traceback (most recent call last):
  File ""wide_n_deep_tutorial.py"", line 208, in <module>
    tf.app.run()
  File ""/xxxxxxx/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""wide_n_deep_tutorial.py"", line 204, in main
    train_and_eval()
  File ""wide_n_deep_tutorial.py"", line 196, in train_and_eval
    m = build_estimator(model_dir)
  File ""wide_n_deep_tutorial.py"", line 80, in build_estimator
    gender = tf.contrib.layers.sparse_column_with_hash_bucket(
AttributeError: 'module' object has no attribute 'sparse_column_with_hash_bucket'


I have no problems with TF installation, and my tensorflow version is 0.9 ,python 2.7  .Last week,the text_cnn.py  examples run just fine.
Thanks!ï»¿"
5665,Is there a bug in embedding_attention_seq2seq?,"Hi, all,

I think the code of embedding_attention_seq2seq is confusing. And I can't run this code.

```python
if output_projection is None:
      cell = rnn_cell.OutputProjectionWrapper(cell, num_decoder_symbols)
      output_size = num_decoder_symbols

...

      x = linear([inp] + attns, input_size, True)
      # Run the RNN.
      cell_output, state = cell(x, state)

...

with variable_scope.variable_scope(""AttnOutputProjection""):
        output = linear([cell_output] + attns, output_size, True)

```

I don't know what's the meaning of ""AttnOutputProjection"". The attention information has been used in ""x = linear([inp] + attns, input_size, True)"", why adding it again?

And meanwhile what is the meaning of ""[cell_output] + attns"", ""cell_output"" is equal with num_symbols, so why add attens?

In my experiment, the num_decoder_symbols is 10000 and the hidden size is 32, and I get a matrix 10032*10000 at ""AttnOutputProjection"". It will be out of memory.
10032 is a confusing number, I don't know the physical meaning of this number.

So I don't know if it's a bug. If it's a bug, I'm really pleasure to make a PR.
Thanks so much.






"
5664,one function in tensorflow tutorials should be replaced,"I'm learning tutorials of tf.contrib.learn Quickstart in this [website](https://www.tensorflow.org/versions/r0.11/tutorials/tflearn/index.html) and found that the function **tf.contrib.learn.datasets.base.load_csv**  isn't existed.So the following codes
`training_set = tf.contrib.learn.datasets.base.load_csv(filename=IRIS_TRAINING,
                                                       target_dtype=np.int)`
`test_set = tf.contrib.learn.datasets.base.load_csv(filename=IRIS_TEST,
                                                   target_dtype=np.int)`
 should be replaced by
`training_set = tf.contrib.learn.datasets.base.load_csv_with_header(filename=IRIS_TRAINING,
                                                       target_dtype=np.int,features_dtype=np.float32)`
`test_set = tf.contrib.learn.datasets.base.load_csv_with_header(filename=IRIS_TEST,
                                                   target_dtype=np.int,features_dtype=np.float32)
`

and my tensorflow version is  (0.11.0rc1)"
5663,slim.batch_norm used with slim.conv2d problem,"Dear All,
I have met some problems when using the batch norm layer of slim. I trained the same model structure but with different ways to use batch_norm layer, shown below. It seems the output of the two ways to use batch_norm is different to me. I have look inside the code to see. It seems the two way no different at all. But the result is actually not the same. Anyone met it before?

1. net = slim.conv2d(net, 64, [4, 4], 2, normalizer_fn=None, activation_fn=None, biases_initializer=None, reuse=reuse)
   output1 = slim.batch_norm(net)

2. output2 = slim.conv2d(net, 64 ,[4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None, reuse=reuse)


"
5662,Windows support for tf.contrib libraries in the PIP package.,"Is there any documentation or tutorial on how to include tf.contrib libraries in the PIP package built with cmake on Windows?

Or to install tf.contrib libraries as a separate step?"
5661,Why does encoder not have mask option in Seq2Seq model ?,"Hi, all,

There is a confusion that tf's seq2seq models don't have mask option for sequence padding.

As I know, mask and padding always are together. If without mask, the final result of padding is imprecise. And tf's rnns have implemented mask.

So why does seq2seq not have mask option?

```python
#rnn
def rnn(cell, inputs, initial_state=None, dtype=None,
        sequence_length=None, scope=None):

# seq2seq
def embedding_rnn_seq2seq(encoder_inputs,
                          decoder_inputs,
                          cell,
                          num_encoder_symbols,
                          num_decoder_symbols,
                          embedding_size,
                          output_projection=None,
                          feed_previous=False,
                          dtype=None,
                          scope=None):
```






"
5660,How to applicate tensorflow on KNL? any suggestions?thanks very much.,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5659,How to trought cuda/lib path,"Hi 
I am very Struggling without going through the path of cuda/lib.

```
bash-3.2$ python
Python 3.5.2 |Anaconda custom (x86_64)| (default, Jul  2 2016, 17:52:12) 
[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Segmentation fault: 11
```

~/.bash_profile
```
export CUDA_HOME=/usr/local/cuda
export DYLD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/lib
export PATH=""$CUDA_HOME/bin:$PATH""
```

```
bash-3.2$ ls -la /usr/local/cuda/lib/libcud*
lrwxr-xr-x  1 root  admin     33 11 17 11:39 /usr/local/cuda/lib/libcuda.1.dylib -> /usr/local/cuda/lib/libcuda.dylib
-rwxr-xr-x  1 root  wheel  13504  9 27 06:59 /usr/local/cuda/lib/libcuda.dylib
lrwxr-xr-x  1 root  wheel     45  9 27 07:00 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a
lrwxr-xr-x  1 root  wheel     50  9 27 07:00 /usr/local/cuda/lib/libcudart.8.0.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib
lrwxr-xr-x  1 root  wheel     46  9 27 07:00 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib
lrwxr-xr-x  1 root  wheel     49  9 27 07:00 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a
lrwxr-xr-x  1 root  admin     47 11 15 17:38 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.5.dylib
lrwxr-xr-x  1 root  admin     45 11 15 17:38 /usr/local/cuda/lib/libcudnn.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.dylib
lrwxr-xr-x  1 root  admin     48 11 15 17:38 /usr/local/cuda/lib/libcudnn_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn_static.a
```

but, In the following case I Successful ""import tensorflow"" 
```
bash-3.2$ cd /usr/local/cuda/lib
bash-3.2$ python
Python 3.5.2 |Anaconda custom (x86_64)| (default, Jul  2 2016, 17:52:12) 
[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.8.0.dylib locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.8.0.dylib locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.8.0.dylib locally
>>> 
```

"
5652,cifar10_multi_gpu_train.py breaks with more than 1 GPU,"### Environment info
Operating System: Ubuntu 

Installed version of CUDA and cuDNN: 8.0 and 5

1. The commit hash (`git rev-parse HEAD`): 3d41cf77d624aeee0482f92121a9300b29db2809
2. The output of `bazel version`: 
Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

python cifar10_multi_gpu_train.py --num_gpus=2

Both cifar10_train.py and cifar10_multi_gpu_train.py (without specifying num_gpus, so running on a single GPU) work.

### Logs or other output that would be helpful
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Traceback (most recent call last):
  File ""cifar10_multi_gpu_train.py"", line 280, in <module>
    tf.app.run()
  File ""/data/github/tensorflow/_python_build/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""cifar10_multi_gpu_train.py"", line 276, in main
    train()
  File ""cifar10_multi_gpu_train.py"", line 180, in train
    loss = tower_loss(scope)
  File ""cifar10_multi_gpu_train.py"", line 92, in tower_loss
    loss_averages_op = loss_averages.apply(losses + [total_loss])
  File ""/data/github/tensorflow/_python_build/tensorflow/python/training/moving_averages.py"", line 391, in apply
    self._averages[var], var, decay, zero_debias=zero_debias))
  File ""/data/github/tensorflow/_python_build/tensorflow/python/training/moving_averages.py"", line 70, in assign_moving_average
    update_delta = _zero_debias(variable, value, decay)
  File ""/data/github/tensorflow/_python_build/tensorflow/python/training/moving_averages.py"", line 177, in _zero_debias
    trainable=False)
  File ""/data/github/tensorflow/_python_build/tensorflow/python/ops/variable_scope.py"", line 1024, in get_variable
    custom_getter=custom_getter)
  File ""/data/github/tensorflow/_python_build/tensorflow/python/ops/variable_scope.py"", line 850, in get_variable
    custom_getter=custom_getter)
  File ""/data/github/tensorflow/_python_build/tensorflow/python/ops/variable_scope.py"", line 346, in get_variable
    validate_shape=validate_shape)
  File ""/data/github/tensorflow/_python_build/tensorflow/python/ops/variable_scope.py"", line 331, in _true_getter
    caching_device=caching_device, validate_shape=validate_shape)
  File ""/data/github/tensorflow/_python_build/tensorflow/python/ops/variable_scope.py"", line 650, in _get_single_variable
    ""VarScope?"" % name)
ValueError: Variable tower_1/tower_1/conv1/weight_loss/avg/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?"
5650,Problem running word2vec_optimized on Amazon GPU machine,"I've not found anyone reporting this specific issue. I'm trying to run tensorflow word2vec script on a aws
gpu machine through docker-nvidia container and getting this error:
[log.txt](https://github.com/tensorflow/tensorflow/files/595666/log.txt)



### Environment info
Operating System: ubuntu 16.10 on a g2.2xlarge aws machine. Nvidia driver version 367.57

Installed version of CUDA and cuDNN:  
running on docker-nvidia tensorflow-0.11.0-gpu machine
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
./usr/local/nvidia/lib64/libcuda.so
./usr/local/nvidia/lib64/libcuda.so.1
./usr/local/nvidia/lib64/libcuda.so.367.57
./usr/local/cuda-7.5/targets/x86_64-linux/lib/stubs/libcuda.so
./usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudadevrt.a
./usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart_static.a
./usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5
./usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5.18
./usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so
./usr/local/cuda-7.5/extras/Debugger/lib64/libcudacore.a
./usr/local/cuda-7.5/extras/Debugger/include/libcudacore.h
./usr/lib/x86_64-linux-gnu/libcudnn_static_v5.a
./usr/lib/x86_64-linux-gnu/libcudnn.so.5.1.3
./usr/lib/x86_64-linux-gnu/libcudnn_static.a
./usr/lib/x86_64-linux-gnu/libcudnn.so.5
./usr/lib/x86_64-linux-gnu/libcudnn.so




### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
this is the command I executed and first lines of output:

Â´python word2vec_optimized.py --train_data text8 --eval_data questions-words.txt --save_path trainÂ´

### What other attempted solutions have you tried?
Tryed to run the same code on a docker tensorflow-0.10.0 machine (without gpu libraries) and obtained
similar error.

### Logs or other output that would be helpful
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 3.94GiB
Free memory: 3.91GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
I tensorflow/models/embedding/word2vec_kernels.cc:200] Data file: text8 contains 100000000 bytes, 17005207 words, 253854 unique words, 71290 unique frequent words.
Data file:  text8
Vocab size:  71290  + UNK
Words per epoch:  17005207
Eval analogy file:  questions-words.txt
Questions:  17827
Skipped:  1717
W tensorflow/core/framework/op_kernel.cc:940] Failed precondition: Attempting to use uninitialized value global_step
	 [[Node: AssignAdd = AssignAdd[T=DT_INT32, _class=[""loc:@global_step""], use_locking=false, _device=""/job:localhost/replica:0/task:0/cpu:0""](global_step, AssignAdd/value)]]

"
5649,"ContextManager Error on tf.name_scope: RuntimeError(""generator didn't yield"")","I have this minimal code that shows the error:

```
scope = tf.name_scope('loss')
with scope as s:
    print s
    
with scope as s:
    print s
```

Is this a bug or done by design?"
5643,TypeError: run() got an unexpected keyword argument 'argv',"When I followed the TensorFlow Mechanics 101 tutorial  `python fully_connected_feed.py` in `examples/tutorials/mnist` directory, I came across this problem: 
```
Traceback (most recent call last):
  File ""fully_connected_feed.py"", line 277, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
TypeError: run() got an unexpected keyword argument 'argv'
```
I am using tensorflow 0.11 version in Anaconda environment."
5642,Tensorflow built from sources in Docker doesn't recognize GPUs,"I need to build TensorFlow from sources in a Dockerfile (because of our architecture's constraints). Unfortunately, TensorFlow does not recognize the gpus.
I use a Tesla K80, with Nvidia driver's version 367.55

Here is the DockerFile related to Tensorflow:
```
#####       BAZEL        #####
RUN apt-get update \
&& apt-get install -y software-properties-common curl
RUN apt-get update
RUN echo oracle-java8-installer shared/accepted-oracle-license-v1-1 select true | debconf-set-selections

RUN add-apt-repository ppa:webupd8team/java 
RUN apt-get update 
RUN apt-get install -y oracle-java8-installer

RUN echo ""deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8"" | tee /etc/apt/sources.list.d/bazel.list
RUN curl https://storage.googleapis.com/bazel-apt/doc/apt-key.pub.gpg | apt-key add - 
RUN apt-get update
RUN apt-get install --yes --force-yes bazel
RUN apt-get upgrade -y --force-yes bazel
RUN apt-get install -y swig

#####       TENSORFLOW        #####
WORKDIR /Programs
RUN git clone https://github.com/tensorflow/tensorflow.git
WORKDIR /Programs/tensorflow

ENV PYTHON_BIN_PATH /usr/bin/python3.5
ENV TF_NEED_GCP 0
ENV TF_NEED_HDFS 1
ENV TF_NEED_CUDA 1
ENV TF_NEED_OPENCL 0
ENV TF_CUDNN_VERSION 5
ENV TF_CUDA_VERSION 8.0
ENV TF_CUDA_COMPUTE_CAPABILITIES 3.7
ENV GCC_HOST_COMPILER_PATH /usr/bin/gcc
ENV CUDA_TOOLKIT_PATH /usr/local/cuda
ENV CUDNN_INSTALL_PATH /usr/local/cuda

RUN echo /usr/local/lib/python3.5/dist-packages | ./configure && \
    bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package
RUN bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg

RUN pip3 install /tmp/tensorflow_pkg/*.whl --upgrade
```
I run the docker like this : 
```
docker run -it --device /dev/nvidiactl --device /dev/nvidia-uvm --device /dev/nvidia0 --device /dev/nvidia1 tensorflow bash
```
When I am in the Docker, I run this little script to see if it sees gpu's work:
```
import tensorflow as tf
if __name__ == ""__main__"":
    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)
    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))
    print(""Tf version :"",tf.__version__)
```
What it prints : 
```
root@fae4ae4d9fee:/home# CUDA_VISIBLE_DEVICES=0 python3 gpu.py 
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so.8.0 locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_UNKNOWN
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: fae4ae4d9fee
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: fae4ae4d9fee
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 367.55.0
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.55  Tue Sep 27 10:17:05 PDT 2016
GCC version:  gcc version 4.9.2 (Debian 4.9.2-10) 
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 367.55.0
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 367.55.0
Tf version : 0.11.0rc2
```
Note that I obtain the same output when I run this script without the `CUDA_VISIBLE_DEVICES=0` flag

output of `ls -l /path/to/cuda/lib/libcud*`
```
root@fae4ae4d9fee:/home# ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root    558720 Nov 15 11:29 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Nov 15 11:29 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root        19 Nov 15 11:29 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 root root    415432 Nov 15 11:29 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root    775162 Nov 15 11:29 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 1000 users       13 Jul 27 05:55 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 1000 users       17 Jul 27 05:55 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxrwxr-x 1 1000 users 79337624 Jul 27 05:53 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-rw-r-- 1 1000 users 69756172 Jul 27 05:53 /usr/local/cuda/lib64/libcudnn_static.a
```
The commit hash (`git rev-parse HEAD`):
`de6bbda2353b50944bd06d5b04c86f8c0a62792a`

The output of `bazel version`:
```
root@fae4ae4d9fee:/Programs/tensorflow# bazel version
.
Build label: 0.4.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 17:54:14 2016 (1478109254)
Build timestamp: 1478109254
Build timestamp as int: 1478109254
```
Note that the nvidia drivers in the Docker are very aware of the GPU's:
```
root@fae4ae4d9fee:~# nvidia-smi
Wed Nov 16 13:33:16 2016       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.55                 Driver Version: 367.55                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 0000:83:00.0     Off |                    0 |
| N/A   36C    P0    60W / 149W |      0MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           Off  | 0000:84:00.0     Off |                    0 |
| N/A   27C    P0    74W / 149W |      0MiB / 11439MiB |     98%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```

I am not very familiar with Docker, so maybe am I doing something wrong in the Dockerfile. Thank's to anyone who could help me with this !"
5639,KeyError: u'SaveV2' when loading exported model,"I have a TensorFLow model trained on a GPU machine. Next, I need to export it and deploy on CPU only production machine.

I have trained and exported a model from a GPU machine as described in [MNIST export example](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_export.py). Saver object was initialized above.

```
with graph.as_default():
    saver = tf.train.Saver(tf.all_variables(), sharded=True)
...

export_path =  'resnet34_rmsprop_wd1e-1/saves/'
print('Exporting trained model to %s' % export_path)
init_op = tf.group(tf.initialize_all_tables(), name='init_op')
model_exporter = exporter.Exporter(saver)
model_exporter.init(sess.graph.as_graph_def(),
                            init_op=init_op,
                            default_graph_signature=exporter.classification_signature(input_tensor=inference_images,
                                                                                      classes_tensor=inference_class,
                                                                                      scores_tensor=inference_predictions),
                            named_graph_signatures={'inputs': exporter.generic_signature({'images': inference_images}),
                                                    'outputs': exporter.generic_signature({'class': inference_class, 'predictions': inference_predictions})})
model_exporter.export(export_path, tf.constant(1), sess)
print('Done exporting!')
```

Next, I am trying to load saved model to CPU machine with:

`new_saver = tf.train.import_meta_graph('assets/saved_model/export.meta')
new_saver.restore(sess, 'assets/saved_model/export')`

And what I am getting is:

```
Traceback (most recent call last):
File ""script_test_classifier.py"", line 4, in <module>
...
line 33, in __initialize_session__
new_saver = tf.train.import_meta_graph('assets/saved_model/export.meta')
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1711, in import_meta_graph
read_meta_graph_file(meta_graph_or_file), clear_devices)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1598, in _import_meta_graph_def
input_graph_def, name="""", producer_op_list=producer_op_list)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py"", line 258, in import_graph_def
op_def = op_dict[node.op]
KeyError: u'SaveV2'
```

What is the reason of the error and how it could be fixed?

**Production (CPU machine) environment info:**
AWS instance type: m4.xlarge
Operating System: Ubuntu 14.04 x64
Installed version of CUDA and cuDNN: None, I am using CPU version of TF for the production environment
A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl
The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`: 0.11.0
"
5638,train inception from scratch: imagenet_train not a target,"

I successfully compiled tensorflow and I was able to run the retrain binary with my own images. 

I'd like to retrain inception from scratch, as described [here](https://github.com/tensorflow/models/tree/master/inception), but the package is not available:

```
$ bazel build inception/imagenet_train
ERROR: no such target '//:inception/imagenet_train': target 'inception/imagenet_train' not declared in package
```"
5637,word2vec_basic global_variables_initializer error,"I'm running Tensorflow version 0.11.0 which has [this](https://github.com/tensorflow/tensorflow/commit/4cbdead95f22de74bcbc72a68c9a38d465202db9#diff-ae1a8f7b66539f000615a4ab7e4b2151) commit included and yet I get the following error when running the ``word2vec_basic.py`` script:
```
##################################################
0.11.0
##################################################
Found and verified text8.zip
Data size 17005207
Most common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]
Sample data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']
3084 originated -> 12 as
3084 originated -> 5239 anarchism
12 as -> 6 a
12 as -> 3084 originated
6 a -> 195 term
6 a -> 12 as
195 term -> 6 a
195 term -> 2 of
Traceback (most recent call last):
  File ""word2vec_basic.py"", line 183, in <module>
    init = tf.global_variables_initializer()
AttributeError: 'module' object has no attribute 'global_variables_initializer'
```

The part at the top with hashtags is something I added to print out the tf version that is used.
When I rename [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py#L178) line back to ``initialize_all_variables`` it works."
5636,Official download links still point to 0.11.0rc2 instead of 0.11.0,"Hi!

On https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md  the URLs still point to 0.11.0rc2 instead of 0.11.0.

"
5633,module 'tensorflow.python.ops.gen_array_ops' has no attribute '_expand_dims',"After following CMake build for windows, python cannot be loaded with below error message.
>>> import tensorflow
AttributeError: module 'tensorflow.python.ops.gen_array_ops' has no attribute '_expand_dims'
After checking git history, it's related with checkin from Andrew Selle.
SHA-1: a41f0eae0cca59ff211495bd3e9da0daf4ed01e8

### Environment info
Operating System:
Windows Server 2012 R2
"
5632,Feature Request: Perspective Transforms,Currently image processing has some image manipulation functions like brightness adjustment or contrast adjustment.  It would be quite useful to have perspective transforms or other affine transformations to help distort training data.
5631,tf.Print is not an identity op w/ tuples or lists of Tensors; clarify in docs or add warning msg?,"**Documentation issue with bidirectional_dynamic_rnn:**

For ""outputs"":

""...It returns a tuple instead of a single concatenated Tensor, unlike in the bidirectional_rnn. If the concatenated one is preferred, the forward and backward outputs can be concatenated as tf.concat(2, outputs).""

This doesn't appear to work.  As a fix:

output, _ = tf.nn.bidirectional_dynamic_rnn(...)
output=tf.concat(2, tf.unpack(output))

...this appears to be necessary because tf.concat does not view the returned tuple as equivalent to a list of Tensors, but rather appears to treat the tuple (effectively) as a Tensor.

**Possible bug in tf.concat:**

Unclear whether tf.concat(2, output) actually should, in fact, return as the initial documentation for bidirectional_dynamic_rnn suggested.
"
5630,`_bag_features` doesn't work properly in Random Forest (TensorForest),"TensorFlow r0.10 , but code appears to be the same in master.

### To Reproduce
Create Random Forest (`tf.contrib.learn.TensorForestEstimator`) with default parameters (`ForestHParams`) with the exception of setting `feature_bagging_fraction` to anything below 1.0 e.g. 0.8. I believe the issue lies in the `_bag_features` implementation in `tensor_forest.py`.

### Traceback
```
Traceback (most recent call last):
  File ""/.../train.py"", line 55, in train
    monitors=monitors)
  File ""/usr/local/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 240, in fit
    max_steps=max_steps)
  File ""/usr/local/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 550, in _train_model
    train_op, loss_op = self._get_train_ops(features, targets)
  File ""/usr/local/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/random_forest.py"", line 163, in _get_train_ops
    **self.training_args),
  File ""/usr/local/python2.7/dist-packages/tensorflow/contrib/tensor_forest/python/tensor_forest.py"", line 369, in training_graph
    tree_data = self._bag_features(i, tree_data)
  File ""/usr/local/python2.7/dist-packages/tensorflow/contrib/tensor_forest/python/tensor_forest.py"", line 325, in _bag_features
    split_data = array_ops.split(1, self.params.num_features, input_data)
  File ""/usr/local/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 980, in split
    name=name)
  File ""/usr/local/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 2231, in _split
    num_split=num_split, name=name)
  File ""/usr/local/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 627, in apply_op
    (key, op_type_name, attr_value.i, attr_def.minimum))
ValueError: Attr 'num_split' of 'Split' Op passed 0 less than minimum 1.
```
"
5628,"Checkpoint SNAPPY compression, incompatible for inference?","As referenced in [https://github.com/tensorflow/tensorflow/issues/1669](https://github.com/tensorflow/tensorflow/issues/1669), I got the same error when trying to restore from self-finetuned checkpoint

> ""Data loss: Unable to open table file /tmp/model.ckpt-4971: Data loss: corrupted compressed block contents: perhaps your file is in a different file format and you need to use a different restore operator? It's likely that your checkpoint file has been compressed with SNAPPY.""

I fine-tuned the checkpoint `inception_resnet_v2_2016_08_30.ckpt` for my own images TF-Slim (modified [finetune_inception_v3_on_flowers.sh](https://github.com/tensorflow/models/blob/master/slim/scripts/finetune_inception_v3_on_flowers.sh)). The fine-tuning seems to go well, and I get good performance for the test error. But when I try to do inference using the newly created checkpoint I got the above-mentioned same error, the same error happening with with `inspect_checkpoint` -tool.

The demo inference from there works fine as well: [https://github.com/tensorflow/models/blob/master/slim/slim_walkthough.ipynb](https://github.com/tensorflow/models/blob/master/slim/slim_walkthough.ipynb)

In other words, how to save the checkpoints with compatible compression? And how is it possible to save checkpoints on my computer (Ubuntu 14.04, TF 0.11.0rc2, CUDA 8.0) which are not possible to open a moment later?"
5627,Documentation change for 'Adding a new op ShapeFn',"In [Adding a new Op](https://github.com/tensorflow/tensorflow/blob/7f3d8e1f8736f4c812e4a0a96154af3bd3750180/tensorflow/g3doc/how_tos/adding_an_op/index.md) there is the following line of code that describes how to set the shape function:

```python
@tf.RegisterShape(""ZeroOut"")(common_shapes.call_cpp_shape_fn)
```
I think this is wrong (you do not want the `@` sign since it's not being used as a decorator). Also, having an explicit import would be helpful.

So it would be nice to change this to:
```python
from tensorflow.python.framework import common_shapes
tf.RegisterShape(""ZeroOut"")(common_shapes.call_cpp_shape_fn)
```"
5626,glibc error with tensorflow 0.10.0,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Glibc import error when using the v0.10.0 distribution of tensorflow

`ImportError: /local/dist/x86_64-unknown-linux-gnu/lib/libc.so.6: version GLIBC_2.14 not found (required by /home/fjanoos/conda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so)
`

However, the version of glibc visible to python is > 2.15:
```
[19:34 - 1.44][firdaus@gsrs3 27] ~/local/cuda-7.5 >python
Python 3.5.2 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:53:06)
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform
>>> platform.libc_ver()
('glibc', '2.2.5')
>>>
```

### Environment info
Operating System:
Debian 7.8

Installed version of CUDA and cuDNN: 
Cuda 7.5
libcudnn : 5.0

If installed from binary pip package, provide:

1. A link to the pip package you installed:
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp35-cp35m-linux_x86_64.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
Cannot import tensorflow.

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5625,ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory ,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN:   7.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl
pip install --upgrade $TF_BINARY_URL

then 
$python
>>import tensorflow
......
ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory 

I see from https://github.com/tensorflow/tensorflow/issues/5343, it says:
""Correct, starting 0.11.0rc1, all our prebuilt packages are now built for cuda8.
With cuda7.5, you either need to install the 0.11.0rc0 wheel file, or build from sources.
""
so, may I know where I can find 0.11.0rc1 url for pip installation? like:
pip install [0.11.0rc1 url]

no resource from https://pypi.python.org/pypi/tensorflow/0.11.0rc0

I cannot build tensorflow from source code because I work in permission limited environment  and I cannot get the info where cuda is installed but only can use nvcc --version to get cuda related info.



1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5622,Problem in the documentation,"It seems that the documentation has a problem. For example, the most useful functions such as `fit` or `evaluate` in [the documentation of tf.contrib.learn](https://www.tensorflow.org/versions/r0.11/api_docs/python/contrib.learn.html#Estimator) is as follows:

> tf.contrib.learn.Estimator.fit(x=None, y=None, input_fn=None, steps=None, batch_size=None, monitors=None, max_steps=None)
> 
> See Trainable.
> 
> Raises:
> 
> ValueError: If x or y are not None while input_fn is not None.
> ValueError: If both steps and max_steps are not None.
> 

[Trainable](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/trainable.py) does not linked or described in the generated documentation. It's really annoying issue for beginners."
5619,Issue installing from sources with GPU support (l2loss_op_gpu.cu.pic.o' was not created.),"### Problem:
When trying to install from sources using GPU support following the instructions from Tensorflow [documentation](https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#optional-install-cuda-gpus-on-linux) using bazel command,

`bazel build -c opt --config=CUDA --verbose_failures tensorflow/tools/pip_package:build_pip_package`

I encounter the following error.

./tensorflow/core/kernels/l2loss_op.h(32): here
            instantiation of ""void tensorflow::functor::L2Loss<Device, T>::operator()(const Device &, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstTensor, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::Scalar) [with Device=tensorflow::GPUDevice, T=Eigen::half]"" 
tensorflow/core/kernels/l2loss_op_gpu.cu.cc(29): here

10 errors detected in the compilation of ""/tmp/tmpxft_0000551e_00000000-7_l2loss_op_gpu.cu.cpp1.ii"".
ERROR: /home/kenjakt/temp/tensorflow/tensorflow/core/kernels/BUILD:1695:1: output 'tensorflow/core/kernels/_objs/l2loss_op_gpu/tensorflow/core/kernels/l2loss_op_gpu.cu.pic.o' was not created.
ERROR: /home/kenjakt/temp/tensorflow/tensorflow/core/kernels/BUILD:1695:1: not all outputs were created or valid.
Target //tensorflow/tools/pip_package:build_pip_package failed to build


### Related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
The problem seems to be somewhat related to these issues
https://github.com/tensorflow/tensorflow/issues/4103
https://github.com/tensorflow/tensorflow/issues/2143

### Environment info
Operating System: Centos - 6.7
CUDA: 7.5
cuDNN: 5.1.3
GCC: 4.8.2
bazel: 0.3.2
python: 2.7.11 : : Anaconda 4.0.0 (64-bit)

### Other attempted solutions tried
Building with -c opt option excluded as suggested in https://github.com/tensorflow/tensorflow/issues/4103
Adding cxx_flags as mentioned by @chrisburr in https://github.com/tensorflow/tensorflow/issues/1066#issuecomment-200580370"
5618,0.11.0rc2 bug weird placeholder feeding problem when using exponential moving average,"using 0.11.0rc2

this simple (nonesense) script breaks:
```
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)

BATCH_SIZE = 128
learning_rate = 0.01

def model(x):
  """"""Defines the CNN architecture and returns its output tensor.""""""
  ema = tf.train.ExponentialMovingAverage(decay=0.5)

  def mean_var_with_update():
    ema_apply_op = ema.apply([tf.constant(1.0), tf.constant(2.0)])
    return tf.constant(1.0), tf.constant(2.0)

  mean, var = tf.cond(is_training,
                      mean_var_with_update,
                      lambda: (tf.constant(2.0), tf.constant(3.0)))
  return x

batch_size = tf.placeholder(tf.float32, name=""batch_size"")
lr = tf.placeholder(tf.float32, name=""learning_rate"")
is_training = tf.placeholder(tf.bool, name='is_training')
input_image_batch = tf.placeholder(tf.float32, shape=[BATCH_SIZE, 28, 28, 1],
                                   name=""input_image_batch"")
input_label_batch = tf.placeholder(tf.float32, shape=[None, 10], name=""input_label_batch"")
logits = model(input_image_batch)
init_op = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init_op)
```

produces:
```
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:05:00.0)
Traceback (most recent call last):
  File ""/home/schlag/MyStuff/LearnSpecific/env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1021, in _do_call
    return fn(*args)
  File ""/home/schlag/MyStuff/LearnSpecific/env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1003, in _run_fn
    status, run_metadata)
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/home/schlag/MyStuff/LearnSpecific/env/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'is_training' with dtype bool
	 [[Node: is_training = Placeholder[dtype=DT_BOOL, shape=[], _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""slim.py"", line 48, in <module>
    sess.run(init_op)
  File ""/home/schlag/MyStuff/LearnSpecific/env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/home/schlag/MyStuff/LearnSpecific/env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/schlag/MyStuff/LearnSpecific/env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/home/schlag/MyStuff/LearnSpecific/env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'is_training' with dtype bool
	 [[Node: is_training = Placeholder[dtype=DT_BOOL, shape=[], _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]

Caused by op 'is_training', defined at:
  File ""slim.py"", line 36, in <module>
    is_training = tf.placeholder(tf.bool, name='is_training')
  File ""/home/schlag/MyStuff/LearnSpecific/env/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py"", line 1519, in placeholder
    name=name)
  File ""/home/schlag/MyStuff/LearnSpecific/env/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2039, in _placeholder
    name=name)
  File ""/home/schlag/MyStuff/LearnSpecific/env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/home/schlag/MyStuff/LearnSpecific/env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2259, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/schlag/MyStuff/LearnSpecific/env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1130, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'is_training' with dtype bool
	 [[Node: is_training = Placeholder[dtype=DT_BOOL, shape=[], _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
```

I don't understand the problem. If I remove the ema (which I'm not using in the example) it works. I can also fix this by adding a feed dict to the init operation like this: 
```
sess.run(init_op, feed_dict={is_training.name: False})
```
I don't think I have this problem with v0.11. I'm using ema in my batchnorm function. I removed all the unnecessary code from my full implementation.
"
5617,Compile build error tensorflow/tools/pip_package,"Hi
When I tried 
```bazel build -c opt --config=cuda --local_resources 2048,.5,1.0 //tensorflow/tools/pip_package:build_pip_package```

, I see the following error:
```INFO: Found 1 target...
ERROR: /XXXXX/tensorflow/python/BUILD:1926:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow.so' failed: link_dynamic_library.sh failed: error executing command external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o ... (remaining 396 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
clang: warning: argument unused during compilation: '-pthread'
duplicate symbol __Z14tf_git_versionv in:
    bazel-out/local_darwin-py3-opt/bin/tensorflow/core/libframework_internal.pic.lo(version_info.pic.o)
    bazel-out/local_darwin-py3-opt/bin/tensorflow/core/libversion_lib.pic.a(version_info.pic.o)
duplicate symbol __Z19tf_compiler_versionv in:
    bazel-out/local_darwin-py3-opt/bin/tensorflow/core/libframework_internal.pic.lo(version_info.pic.o)
    bazel-out/local_darwin-py3-opt/bin/tensorflow/core/libversion_lib.pic.a(version_info.pic.o)
ld: 2 duplicate symbols for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /XXXX/tensorflow/tensorflow/tools/pip_package/BUILD:81:1 Linking of rule '//tensorflow/python:_pywrap_tensorflow.so' failed: link_dynamic_library.sh failed: error executing command external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o ... (remaining 396 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
INFO: Elapsed time: 2.094s, Critical Path: 1.50s
```

following bazel version:

```
Build label: 0.4.0-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 19:15:37 2016 (1478114137)
Build timestamp: 1478114137
Build timestamp as int: 1478114137```"
5615,"Fails to configure with ""Object of type 'path' has no field ""realpath"""" (BuildFileContainsErrorsException)","```bash
Â» ./configure 
~/tmp/tensorflow ~/tmp/tensorflow
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] 
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] 
No Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/lib/python3/dist-packages
  /usr/local/lib/python3.5/dist-packages
  .
Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]
/home/wojciech/.local/lib/python3.5/site-packages
Do you wish to build TensorFlow with OpenCL support? [y/N] 
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 
Please specify the location where CUDA  toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 
Please specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 6.1
.
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
.
ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/wojciech/tmp/tensorflow/third_party/gpus/cuda_configure.bzl"", line 517
		_create_cuda_repository(repository_ctx)
	File ""/home/wojciech/tmp/tensorflow/third_party/gpus/cuda_configure.bzl"", line 432, in _create_cuda_repository
		_cuda_toolkit_path(repository_ctx, cuda_version)
	File ""/home/wojciech/tmp/tensorflow/third_party/gpus/cuda_configure.bzl"", line 148, in _cuda_toolkit_path
		str(repository_ctx.path(cuda_toolkit...)
	File ""/home/wojciech/tmp/tensorflow/third_party/gpus/cuda_configure.bzl"", line 148, in str
		repository_ctx.path(cuda_toolkit_path).realpath
Object of type 'path' has no field ""realpath"".
```

git hash: 7f3d8e1f8736f4c812e4a0a96154af3bd3750180
```bash
 Â» bazel version                                                                                   
Build label: 0.3.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jul 29 09:09:52 2016 (1469783392)
Build timestamp: 1469783392
Build timestamp as int: 1469783392
```
python 3.5.2

Works fine on the r0.11 branch"
5612,Issue running Tensorflow,"Please forgive me if I use incorrect language - I am very inexperienced utilizing command prompt commands and all similar activities and am trying my best.

I followed the instructions for setting up tensorflow and had it working this afternoon in the command prompt on my Windows machine. This evening I go to start practicing tensorflow and there are issues. When I follow the following directions:

1. Run the docker vm: docker-machine create vdocker -d virtualbox
2. In the command prompt window:
2.A. FOR /f ""tokens=*"" %i IN ('docker-machine env --shell cmd vdocker') DO %i
2.B.  docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow

everything works until 2.B. Then it talks about Jupyter notebook running at all IP addresses.

If i try using: docker run -it b.gcr.io/tensorflow/tensorflow:latest-devel

it says that it can't read the CA certificate for ...vdocker\\ ca.pem and it can't find the path specified.

Further google searching mentioned something about a bash_profile:

export DOCKER_HOST=tcp://192.168.99.100:2376
export DOCKER_MACHINE_NAME=default
export DOCKER_TLS_VERIFY=1
export DOCKER_CERT_PATH=/Users/idanadar/.docker/machine/machines/default

but I have ZERO idea what they are referencing, what the above means, or what to do about it. I can code in python, but the ideas behind the commands to set up tensorflow are above my head. I am currently just googling things to put in the command prompt hoping it will work and I can start practicing tensorflow. Could anyone please provide me very specific instructions for what to do in the command prompt or the Docker QuickStart Terminal so I can resolve this issue? I appreciate your time very much. Sorry for asking such a basic question."
5611,Is there any way to let TensorFlow support Bitcode on iOS?,"I'm trying to use TensorFlow on a iOS App, but my team required Bitcode enabled in the project, so I seek for help here.
"
5609,Add documentation on how to use bucketing functions,"Can someone please add documentation on how to use _tensorflow.contrib.training.bucket_ and _tensorflow.contrib.training.bucket_by_sequence_length_ functions?

NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System: Mac OS X Sierra

Installed version of CUDA and cuDNN: None
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed: Mac OS X Python 2.7 CPU
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.: 0.11.0rc1

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5608,How to dynamically select scope of untied variables during tf.while_loop?,"When using python for loop, one simply creates/selects a new untied variable by using the incrementor to change the scope:
```
for i range(num_untied_layers):  
     with tf.variable_scope(""untied_attention_hop"" + ""/"" + str(i)):
          Wt = tf.get_variable(""W_t"")
          bt = tf.get_variable(""bias_t"")
```

How would one do this with tf.while_loop?

@DeNeutoy"
5606,Support for tf.transpose for tensors of rank 12 or higher,"Can support for `tf.transpose` please be added for tensors above rank 11? Can it be extended to tensors of rank size 40 or 50 on the gpu?

I know this seems large, but I'm trying to implement this tensorization paper where this is demanded. 

https://arxiv.org/pdf/1611.03214v1.pdf"
5601,"wide_n_deep_tutorial.py fails with model_type=deep: Shapes (32561, 1) and (32561,) are incompatible","The [wide_n_deep tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/wide_and_deep/index.html) fails when run with --model_type=deep
It immediately fails with the error:
Shapes (32561, 1) and (32561,) are incompatible

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
This may be due to #4715 
https://github.com/tensorflow/tensorflow/issues/3776 discusses the same flag, but appears to be an unrelated problem

### Environment info
Operating System: macOS Sierra 10.12.1

Installed version of CUDA and cuDNN: none

1. A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0-py2-none-any.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11.0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

1. Download the tutorial code [wide_n_deep_tutorial.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/wide_n_deep_tutorial.py)

2: Run with --model_type=deep
python wide_n_deep_tutorial.py --model_type=deep

### What other attempted solutions have you tried?

The example runs with --model_type=wide or --model_type=wide_n_deep. Just the deep model fails.

### Logs or other output that would be helpful
[out.txt](https://github.com/tensorflow/tensorflow/files/590128/out.txt)

The log shows a lot of warnings about API changes, suggesting the tutorial code should be updated. E.g.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01."
5600,Problems Installing on Windows 10,"I am having trouble building tensorflow on Windows. Here is a detailed list of all the steps I took to get it to build. 

Any help is much appreciated. 

Step-by-step Windows build
 
1. Install the pre-requisites detailed above, and set up your environment.
o   CMake version 3.1 or later, 
ï§  When installing  cmake-3.7.0-rc2-win64-x64.msi , I added CMake to the System Path for all users, in file location C:\Program Files\CMake\
o   Git
ï§  I installed Git-2.10.1-64-bit.exe, selected the option Use Git from the Windows Command Prompt, Checkout Windows-style commit Unix-style line endings, Use Windows default console window
â¢         Enable both file system caching and git credential Manager
o   SWIG
ï§  I downloaded swigwin-3.0.10 from here http://www.swig.org/download.html , unzipped the folder and placed the contents in âC:\toolsâ
2. Run vcvarsall.bat
       
â¢         The instructions say to run this commandâ¦
o   D:\temp> ""C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\amd64\vcvarsall.bat""
 
â¢         However, my ""vcvarsall.bat"" file was actually in a different location -> C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\vcvarsall.bat
o   So I ran this command...
o   D:\temp> ""C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\vcvarsall.bat""
 
3. Clone TensorFlow
 
D:\temp> git clone https://github.com/tensorflow/tensorflow.git
D:\temp> cd tensorflow\tensorflow\contrib\cmake
D:\temp\tensorflow\tensorflow\contrib\cmake> mkdir build
D:\temp\tensorflow\tensorflow\contrib\cmake> cd build
D:\temp\tensorflow\tensorflow\contrib\cmake\build>
 
I ran these commands and everything went smoothly.
 
 
4. Invoke CMake to create Visual Studio solution and project files
 
D:\...\build> cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^
More? -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.10/swig.exe ^
More? -DPYTHON_EXECUTABLE=C:/Users/%USERNAME%/AppData/Local/Continuum/Anaconda3/python.exe ^
More? -DPYTHON_LIBRARIES=C:/Users/%USERNAME%/AppData/Local/Continuum/Anaconda3/libs/python35.lib
 
The problem is my python.exe and python35.lib are in totally different file locations.
 
C:\Windows\System32\tensorflow\tensorflow\contrib\cmake\build> cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^
More? -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.10/swig.exe ^
More? -DPYTHON_EXECUTABLE=C:/Program Files/Anaconda3/python.exe ^
More? -DPYTHON_LIBRARIES= C:/Program Files/Anaconda3/libs/python35.lib
 
 
 
Here is the error codeâ¦
 
-- The C compiler identification is unknown
-- The CXX compiler identification is unknown
CMake Error at CMakeLists.txt:5 (project):
  No CMAKE_C_COMPILER could be found.
 
 
 
CMake Error at CMakeLists.txt:5 (project):
  No CMAKE_CXX_COMPILER could be found.
 
 
 
-- Configuring incomplete, errors occurred!
See also ""C:/Windows/System32/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/CMakeOutput.log"".
See also ""C:/Windows/System32/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/CMakeError.log"".
 
After adding âget.exeâ to my path variable and running this command
 
C:\Windows\System32\tensorflow\tensorflow\contrib\cmake\build>cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^
More? -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.10/swig.exe ^
More? -DPYTHON_EXECUTABLE=C:/Program Files/Anaconda3/python.exe ^
More? -DPYTHON_LIBRARIES= C:/Program Files/Anaconda3/libs/python35.lib
 
 
I get this errorâ¦
 
CMake Error: The source directory ""C:/Windows/System32/tensorflow/tensorflow/contrib/cmake/build/Files/Anaconda3/libs/python35.lib"" does not exist.
Specify --help for usage, or press the help button on the CMake GUI.
 
C:\Windows\System32\tensorflow\tensorflow\contrib\cmake\build>


"
5598,tf.contrib.learn estimators that use feature columns via the input_fun not compatible with x inputs when predicting and not exportable to serving,"I have run into into performance and portability issues with tf.conrtib.learn estimators that use high level feature columns and have done extensive code traversal to figure out a possible solution to make predictions faster.

At the core of the problem is that high level feature column tensors created in the input_fn are transformed and added as input tensors to the actual neural network and/or logistic model. After that the hidden layers and logit (output) layer is added to the graph and the logits for the linear model (if used) are also created. This happens every time you run predict on the estimator, at the cost an overhead of 3-7 seconds.

One solution I tried is based on posts that I read about the x parameter of the predict method (vs input_fn). If you create an iterator that feeds examples (that never sends the StopIteration exception) then you could keep the model ""resident"" avoiding the graph being built every time you call predict.

However, the x parameter as iterable does not work,  because it seems that you can only provide it low level inputs (such as numpy arrays or pandas dataframe of type float or int only). It seems that this solution precludes the nice feature columns such as sparse tensors (for categoricals) and embeddings (to get inputs to the neural net), etc.

Another problem that arises with the above issues with the estimator design is that although it has an export method to create a model that tensorflow serving loads nicely, it will not work, because the graph needs to be built at predict time to extract model inputs from the higher level feature column tensors and of course tensor flow serving does not work like that. It loads a graph and runs inputs to create outputs - similar to the predict method using the x parameter. It does not create graphs on the fly every time a predict call is made.

What is needed as a new feature is that the x and y parameters of the predict method should accept raw inputs (like strings for categorical features/embeddings) that is then passed into the feed_dict parameter of the session run call.

Similarly, for tensorflow serving, it should be possible to export the estimator and write the model client so that the raw feature column values (strings) can be sent to the model instantiated in tensorflow serving. 

This feature is quite urgent in my opinion as models based on the cool abstractions available in the contrib.learn estimator API are not very useful beyond training and evaluation without this requested feature.
"
5597,Seq2seq buckets option confusion,"The model_with_buckets function will **raise error when length of encoder_inputsut, targets, or weights is smaller than the largest (last) bucket ??** why? Shouldn't the opposite be true?

"
5596,grpc async server wrapper bug,"code in distributed_runtime/rpc/grpc_master_service.cc
```
  void HandleRPCsLoop() override {
    ENQUEUE_REQUEST(CreateSession, true);
    ENQUEUE_REQUEST(ExtendSession, false);
    for (int i = 0; i < 100; ++i) {
      ENQUEUE_REQUEST(RunStep, true);
    }
    ENQUEUE_REQUEST(CloseSession, false);
    ENQUEUE_REQUEST(ListDevices, false);
    ENQUEUE_REQUEST(Reset, false);

    void* tag;
    bool ok;
    while (cq_->Next(&tag, &ok)) {
   
      UntypedCall<GrpcMasterService>::Tag* callback_tag =
          static_cast<UntypedCall<GrpcMasterService>::Tag*>(tag);
      if (callback_tag) {
        callback_tag->OnCompleted(this, ok);
        delete callback_tag;
      } else {
        // NOTE(mrry): A null `callback_tag` indicates that this is
        // the shutdown alarm.
        cq_->Shutdown();
      }
    }
  }
```

 **While increasing the test pressure, I found that variable 'ok' will be set false, and 
in callback_tag->OnCompleted, it will not call callback if ok is false, thus   ENQUEUE_REQUEST will not be called, new incoming request will have no chance to be handled,
memory increase more and more, if any bug here?**"
5595,Saving optimizer state (adagrad/momentum/etc.),"Hey everybody,

Last week I asked this question on stackoverflow: https://stackoverflow.com/questions/40547198/saving-the-state-of-the-adagrad-algorithm-in-tensorflow . 
My problem is that I want to save the state of the optimizer (in my case the adagrad accumulators) so I can stop my learning and continue whenever I want. 

Unless I'm mistaken the state of the optimizer can't be saved (you cant pass an optimizer to a tf.train.Saver, right?). A quick (hacky?) solution for me might be is calling Optimizer.get_slot_names() and save the op of each slot. 
The next problem would be putting this op back in the slots, as I don't think there is a set_slot(name,op) at the moment. 

So my questions are: 
- Am I right that this is currently impossible? 
- Do we want to have a set_slot(name,op) function in the Optimizer class? (I am willing to help out with this)
- Do we want to be able to pass an optimizer to a Saver object?"
5594,Doc Errors related to  tf.space_to_batch,"In the[ api-doc related to](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/array_ops.md#tfspace_to_batchinput-paddings-block_size-namenone-space_to_batch) `tf.space_to_batch`, the result of example case of 

> (3) For the following input of shape `[1, 4, 4, 1]` and block_size of 2:
```prettyprint
x = [[[[1],   [2],  [3],  [4]],
      [[5],   [6],  [7],  [8]],
      [[9],  [10], [11],  [12]],
      [[13], [14], [15],  [16]]]]
```

should be 
```prettyprint
x = [[[[1], [3]], [[9], [11]]],
     [[[2], [4]], [[10], [12]]],
     [[[5], [7]], [[13], [15]]],
     [[[6], [8]], [[14], [16]]]]
```
rather than 
```prettyprint
x = [[[[1], [3]], [[5], [7]]],
     [[[2], [4]], [[10], [12]]],
     [[[5], [7]], [[13], [15]]],
     [[[6], [8]], [[14], [16]]]]
```

Docs related to `tf.space_to_batch_nd`, `tf.batch_to_space_nd`, `tf.batch_to_space` have similar problems in their **(3)** cases, too. 

"
5593,windows build: avgpooling_op.obj : error LNK2019,"**using the latest version of the tf_core_kernels, after msbuild(both tf_tutorials_example_trainer and  tf_python_build_pip_package ),build on release ,get errors:**

> 
> avgpooling_op.obj : error LNK2019: æ æ³è§£æçå¤é¨ç¬¦å· ""public: void __cdecl tensorflow::functor::SpatialAvgPooling<struct E
> igen::GpuDevice,struct Eigen::half>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::
> Tensor<struct Eigen::half,4,1,__int64>,16,struct Eigen::MakePointer>,class Eigen::TensorMap<class Eigen::Tensor<stru
> ct Eigen::half const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,int,int,int,enum Eigen::PaddingType const &)"" (
> ??R?$SpatialAvgPooling@UGpuDevice@Eigen@@Uhalf@2@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tens
> or@Uhalf@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@V?$TensorMap@V?$Tensor@$$CBUhalf@Eigen@@$03$00_J@Eigen@@$0BA@
> UMakePointer@2@@4@HHHHAEBW4PaddingType@4@@Z)ï¼è¯¥ç¬¦å·å¨å½æ° ""public: virtual void __cdecl tensorflow::AvgPoolingOp<struct Ei
> gen::GpuDevice,struct Eigen::half>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$AvgPoolingOp@UGpuDevic
> e@Eigen@@Uhalf@2@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z) ä¸­è¢«å¼ç¨ [H:\docker\tensorflow\tensorflow\contrib\cmake\bui
> ld\pywrap_tensorflow.vcxproj]
>   avgpooling_op.obj : error LNK2019: æ æ³è§£æçå¤é¨ç¬¦å· ""public: void __cdecl tensorflow::functor::SpatialAvgPooling<struct E
> igen::GpuDevice,float>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<float,
> 4,1,__int64>,16,struct Eigen::MakePointer>,class Eigen::TensorMap<class Eigen::Tensor<float const ,4,1,__int64>,16,s
> truct Eigen::MakePointer>,int,int,int,int,enum Eigen::PaddingType const &)"" (??R?$SpatialAvgPooling@UGpuDevice@Eigen
> @@M@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@M$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@V?$
> TensorMap@V?$Tensor@$$CBM$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HHHHAEBW4PaddingType@4@@Z)ï¼è¯¥ç¬¦å·å¨å½æ° ""public: virtual v
> oid __cdecl tensorflow::AvgPoolingOp<struct Eigen::GpuDevice,float>::Compute(class tensorflow::OpKernelContext *)"" (
> ?Compute@?$AvgPoolingOp@UGpuDevice@Eigen@@M@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z) ä¸­è¢«å¼ç¨ [H:\docker\tensorflow\te
> nsorflow\contrib\cmake\build\pywrap_tensorflow.vcxproj]
>   avgpooling_op.obj : error LNK2019: æ æ³è§£æçå¤é¨ç¬¦å· ""bool __cdecl tensorflow::RunAvePoolBackwardNHWC<struct Eigen::half>(
> struct Eigen::half const * const,int,int,int,int,int,int,int,int,int,int,int,int,struct Eigen::half * const,struct E
> igen::GpuDevice const &)"" (??$RunAvePoolBackwardNHWC@Uhalf@Eigen@@@tensorflow@@YA_NQEBUhalf@Eigen@@HHHHHHHHHHHHQEAU1
> 2@AEBUGpuDevice@2@@Z)ï¼è¯¥ç¬¦å·å¨å½æ° ""public: virtual void __cdecl tensorflow::AvgPoolingGradOpCustomGPUKernel<struct Eigen:
> :half>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$AvgPoolingGradOpCustomGPUKernel@Uhalf@Eigen@@@tens
> orflow@@UEAAXPEAVOpKernelContext@2@@Z) ä¸­è¢«å¼ç¨ [H:\docker\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.v
> cxproj]
>   avgpooling_op.obj : error LNK2019: æ æ³è§£æçå¤é¨ç¬¦å· ""bool __cdecl tensorflow::RunAvePoolBackwardNHWC<float>(float const *
>  const,int,int,int,int,int,int,int,int,int,int,int,int,float * const,struct Eigen::GpuDevice const &)"" (??$RunAvePoo
> lBackwardNHWC@M@tensorflow@@YA_NQEBMHHHHHHHHHHHHQEAMAEBUGpuDevice@Eigen@@@Z)ï¼è¯¥ç¬¦å·å¨å½æ° ""public: virtual void __cdecl te
> nsorflow::AvgPoolingGradOpCustomGPUKernel<float>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$AvgPooli
> ngGradOpCustomGPUKernel@M@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z) ä¸­è¢«å¼ç¨ [H:\docker\tensorflow\tensorflow\contrib\c
> make\build\pywrap_tensorflow.vcxproj]
>   H:\docker\tensorflow\tensorflow\contrib\cmake\build\Release\pywrap_tensorflow.dll : fatal error LNK1120: 4 ä¸ªæ æ³è§£æçå¤
> é¨å½ä»¤ [H:\docker\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.vcxproj]
> 

Is the erros relateds to the latest commit of the tf_core_kernels.cmake and how may I fix it?"
5592,The performance of fp16  is quite bad.,"https://github.com/tensorflow/tensorflow/issues/1300

I have got a nvidia p100 GPU which is support fp16, and I run the TF case 'cifar10_train.py'. Without option '--use_fp16', the performance is also 1600 examples/sec, and with the option '--use_fp16', the performance down to 500 examples/sec. Any ideas about this issue?

userid@ubuntu-WK-4xP100:~/weike/tensorflow-r0.11/tensorflow/models/image/cifar10$ vi cifar10_train.py 
userid@ubuntu-WK-4xP100:~/weike/tensorflow-r0.11/tensorflow/models/image/cifar10$ python cifar10_train.py 
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally
>> Downloading cifar-10-binary.tar.gz 100.0%
...
2016-11-14 00:07:57.143739: step 0, loss = 4.67 (12.1 examples/sec; 10.549 sec/batch)
2016-11-14 00:07:58.395209: step 10, loss = 4.57 (1693.6 examples/sec; 0.076 sec/batch)
2016-11-14 00:07:59.177525: step 20, loss = 4.97 (1668.9 examples/sec; 0.077 sec/batch)
2016-11-14 00:07:59.957789: step 30, loss = 4.43 (1588.3 examples/sec; 0.081 sec/batch)
2016-11-14 00:08:00.738431: step 40, loss = 4.52 (1690.5 examples/sec; 0.076 sec/batch)
2016-11-14 00:08:01.501940: step 50, loss = 4.33 (1680.4 examples/sec; 0.076 sec/batch)
2016-11-14 00:08:02.241604: step 60, loss = 4.20 (1733.4 examples/sec; 0.074 sec/batch)
2016-11-14 00:08:03.001845: step 70, loss = 4.27 (1706.0 examples/sec; 0.075 sec/batch)
2016-11-14 00:08:03.765522: step 80, loss = 4.18 (1601.3 examples/sec; 0.080 sec/batch)
2016-11-14 00:08:04.516780: step 90, loss = 4.25 (1646.3 examples/sec; 0.078 sec/batch)


userid@ubuntu-WK-4xP100:~/weike/tensorflow-r0.11/tensorflow/models/image/cifar10$ python cifar10_train.py --use_fp16
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
..
2016-11-14 00:09:09.382854: step 0, loss = 4.67 (12.3 examples/sec; 10.411 sec/batch)
2016-11-14 00:09:11.923842: step 10, loss = 4.58 (659.6 examples/sec; 0.194 sec/batch)
2016-11-14 00:09:13.918448: step 20, loss = 6.62 (460.6 examples/sec; 0.278 sec/batch)
2016-11-14 00:09:16.211809: step 30, loss = 4.37 (583.7 examples/sec; 0.219 sec/batch)
2016-11-14 00:09:18.327690: step 40, loss = 4.30 (618.3 examples/sec; 0.207 sec/batch)
2016-11-14 00:09:20.395409: step 50, loss = 4.37 (643.8 examples/sec; 0.199 sec/batch)
2016-11-14 00:09:22.466230: step 60, loss = 4.32 (574.0 examples/sec; 0.223 sec/batch)
2016-11-14 00:09:24.533225: step 70, loss = 4.17 (646.2 examples/sec; 0.198 sec/batch)
2016-11-14 00:09:26.609277: step 80, loss = 2.59 (601.5 examples/sec; 0.213 sec/batch)
2016-11-14 00:09:28.703648: step 90, loss = 4.15 (625.5 examples/sec; 0.205 sec/batch)
"
5591,I only have CUDA 8.0 but Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: ,">>> import tensorflow
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: 
I tensorflow/stream_executor/cuda/cuda_dnn.cc:3448] Unable to load cuDNN DSO
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
"
5589,Summary overwrite earlier models,"Summary writer overwrites the previous version of models. For example, when I save any model that has (step + 1) % 100 == 0, then when saving model-1299 model-299 is deleted.


### Environment info
Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root 189170 Sep 23  2015 /usr/local/cuda-7.5/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Sep 23  2015 /usr/local/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Sep 23  2015 /usr/local/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Sep 23  2015 /usr/local/cuda-7.5/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Sep 23  2015 /usr/local/cuda-7.5/lib/libcudart_static.a

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11.0rc0

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
if (step + 1) % 100 == 0:
  saver.save(sess, 'model', global_step = step)
"
5588,bidirectional_dynamic_rnn: make sequence length optional,"Qualifier: very new to TF, so I may be missing something very obvious.  If so, apologies.

DOCUMENTATION: 

Is a little conflicting:

""sequence_length: An int32/int64 vector, size [batch_size], containing the actual lengths for each of the sequences."" <-- implies sequence_length is required

However...

""The initial state for both directions is zero by default (but can be set optionally) and no intermediate states are ever returned -- the network is fully unrolled for the given (passed in) length(s) of the sequence(s) or completely unrolled if length(s) is not given."" <-- implies sequence_length is not required.

FUNCTIONALITY""

Base on the function itself (""_dynamic_""), I would assume that allowing sequence_length=None is intended (although, in either case, the documentation should be straightened out).

Assuming we do want to allow seq_length=None, the offending portion within bidirectional_dynamic_rnn would appear to be:

inputs_reverse = array_ops.reverse_sequence(...seq_lengths=sequence_length...)

reverse_sequence appears to require seq_lengths != None

Oddly enough, bidirectional_rnn may(?) be robust to this problem, as it uses _reverse_seq, which handles lengths=None.  

That said, I haven't tested this extensively, as I'm of course not 100% sure I've interpreted the above correctly and as to what the intended functionality is.

Given guidance, I could take a stab at a pull request to address the above.  Or maybe this is a quick fix/known issue (or non-issue...).

"
5587,iOS No OpKernel to support TruncatedNormal,"I have a NN similar to this one: http://stackoverflow.com/a/38576462/828184 and my iOS project is based on the simple contrib example.

I write out the graph.pb file like so (and replace it with the original iOS one):
`tf.train.write_graph(sess.graph_def, 'NNModel/', 'graph.pb', as_text=False)`

But XCode crashes on execution with this error:

> RunModelViewController.mm: Could not create TensorFlow Graph: Invalid argument: No OpKernel was registered to support Op 'TruncatedNormal' with these attrs.  Registered kernels:
>   <no registered kernels>
> 	 [[Node: OutputLayer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0](OutputLayer/truncated_normal/shape)]]

I guess it's because of the usage of `tf.truncated_normal(...)`. Is there an alternative to that call or am I doing something wrong?

So far I got a minimalistic multiplication graph working on iOS but no trained NN."
5586,AttributeError: 'LSTMStateTuple' object has no attribute 'get_shape',"My code 
```
cell = cell_fn(args.rnn_size)

        self.cell = cell = rnn_cell.MultiRNNCell([cell] * args.num_layers, state_is_tuple=True)

        self.input_data = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])
        self.targets = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])
        self.initial_state = cell.zero_state(args.batch_size, tf.float32)

        with tf.variable_scope('rnnlm'):
            softmax_w = tf.get_variable(""softmax_w"", [args.rnn_size, args.vocab_size])
            softmax_b = tf.get_variable(""softmax_b"", [args.vocab_size])
            with tf.device(""/cpu:0""):
                embedding = tf.get_variable(""embedding"", [args.vocab_size, args.rnn_size])
                inputs = tf.split(1, args.seq_length, tf.nn.embedding_lookup(embedding, self.input_data))
                inputs = [tf.squeeze(input_, [1]) for input_ in inputs]

        def loop(prev, _):
            prev = tf.matmul(prev, softmax_w) + softmax_b
            prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))
            return tf.nn.embedding_lookup(embedding, prev_symbol)

        initial_input = self.initial_state[0]
        beam_decoder = BeamDecoder(num_classes=3, stop_token=2, beam_size=7, max_len=5)
        _, final_state = tf.nn.seq2seq.rnn_decoder(
                                [beam_decoder.wrap_input(initial_input)] + [None] * 4,
                                beam_decoder.wrap_state(self.initial_state),
                                beam_decoder.wrap_cell(cell),
                                #loop_function = lambda prev_symbol, i: tf.reshape(prev_symbol, [-1, 1])
                                loop_function=loop if infer else None, scope='rnnlm'
                            )
```
there is a problem appeared when I try to run ,the traceback info is as follows
```
[sun ~/workspace/sunxiaobiu/word-rnn-tensorflow 20:23:05]$ python sample.py
Traceback (most recent call last):
  File ""sample.py"", line 42, in <module>
    main()
  File ""sample.py"", line 25, in main
    sample(args)
  File ""sample.py"", line 32, in sample
    model = Model(saved_args, True)
  File ""/Users/sun/workspace/sunxiaobiu/word-rnn-tensorflow/model.py"", line 53, in __init__
    loop_function=loop if infer else None, scope='rnnlm'
  File ""/Library/Python/2.7/site-packages/tensorflow/python/ops/seq2seq.py"", line 146, in rnn_decoder
    output, state = cell(inp, state)
  File ""/Users/sun/workspace/sunxiaobiu/word-rnn-tensorflow/beam_decoder.py"", line 172, in __call__
    cell_outputs, raw_cell_state = self.cell(cell_inputs, past_cell_state)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/ops/rnn_cell.py"", line 813, in __call__
    cur_inp, new_state = cell(cur_inp, cur_state)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/ops/rnn_cell.py"", line 310, in __call__
    concat = _linear([inputs, h], 4 * self._num_units, True)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/ops/rnn_cell.py"", line 889, in _linear
    shapes = [a.get_shape().as_list() for a in args]
AttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'
```
I have tried to put the state_is_tuple=True , but it still not work~
@lukaszkaiser "
5585,Reshape Op not the same as tensorflow.reshape,"I am getting the error `Invalid argument: NodeDef mentions attr 'Tshape' not in Op<name=Reshape; signature=tensor:T, shape:int32 -> output:T; attr=T:type>; NodeDef: Y_GroundTruth = Reshape[T=DT_FLOAT, Tshape=DT_INT32](LOut_Add, Y_GroundTruth/shape)` when attempting to load the file on Android using `tensorflow::Status s = session->Create(graph_def);`.

People with similar problems have mentioned that upgrading to Tensorflow 0.9.0rc0 fixed their problems. However, I am already using the most current Tensorflow build in my jni-build.

Could this be a problem with the variables declared when generating the protobuf file?

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://github.com/tensorflow/tensorflow/issues/3002
https://github.com/tensorflow/tensorflow/issues/1528

### Environment info
Operating System:
Mac OS 10.12
Android Cyanogenmod 12
Tensorflow 0.10.0 on Jupyter

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

**Snippet**
```    
    def reg_perceptron(t, weights, biases):
        t = tf.nn.relu(tf.add(tf.matmul(t, weights['h1']), biases['b1']), name = ""layer_1"")
        t = tf.nn.sigmoid(tf.add(tf.matmul(t, weights['h2']), biases['b2']), name = ""layer_2"")
        t = tf.add(tf.matmul(t, weights['hOut'], name=""LOut_MatMul""), biases['bOut'], name=""LOut_Add"")

        return tf.reshape(t, [-1], name=""Y_GroundTruth"")

    g = tf.Graph()
    with g.as_default():
       ...
       rg_weights = {
        'h1': vs.get_variable(""weights0"", [n_input, n_hidden_1], initializer=tf.contrib.layers.xavier_initializer()),
        'h2': vs.get_variable(""weights1"", [n_hidden_1, n_hidden_2], initializer=tf.contrib.layers.xavier_initializer()),
        'hOut': vs.get_variable(""weightsOut"", [n_hidden_2, 1], initializer=tf.contrib.layers.xavier_initializer())
        }


        rg_biases = {
        'b1': vs.get_variable(""bias0"", [n_hidden_1], initializer=init_ops.constant_initializer(bias_start)),
        'b2': vs.get_variable(""bias1"", [n_hidden_2], initializer=init_ops.constant_initializer(bias_start)),
        'bOut': vs.get_variable(""biasOut"", [1], initializer=init_ops.constant_initializer(bias_start))
        }
        
        #output node
        pred = reg_perceptron(_x, rg_weights, rg_biases)
        ...
    ...

    g_2 = tf.Graph()
    with g_2.as_default():
        ...
        rg_weights_2 = {
        'h1': vs.get_variable(""weights0"", [n_input, n_hidden_1], initializer=tf.contrib.layers.xavier_initializer()),
        'h2': vs.get_variable(""weights1"", [n_hidden_1, n_hidden_2], initializer=tf.contrib.layers.xavier_initializer()),
        'hOut': vs.get_variable(""weightsOut"", [n_hidden_2, 1], initializer=tf.contrib.layers.xavier_initializer())
        }

        rg_biases_2 = {
        'b1': vs.get_variable(""bias0"", [n_hidden_1], initializer=init_ops.constant_initializer(bias_start)),
        'b2': vs.get_variable(""bias1"", [n_hidden_2], initializer=init_ops.constant_initializer(bias_start)),
        'bOut': vs.get_variable(""biasOut"", [1], initializer=init_ops.constant_initializer(bias_start))
        }
    
        pred_2 = reg_perceptron(_x_2, rg_weights_2, rg_biases_2)
        ...
```

### What other attempted solutions have you tried?
I will double check the Tensorflow version tomorrow and make sure that it is the same as the version I am using in the jni-build.

I also attempted to strip the graph using
```
#!/bin/bash
bazel-bin/tensorflow/python/tools/strip_unused --input_graph=/Users/leslie/Downloads/trained_model6.pb --output_graph=/Users/leslie/Downloads/stripped_graph.pb --input_node_names=X_Input --output_node_names=Y_GroundTruth --input_binary=true
```

but the output is simply
```
6

Y_GroundTruthPlaceholder*
dtype0*
shape:
```

and attempting to freeze the graph with

```
#!/bin/bash
bazel-bin/tensorflow/python/tools/freeze_graph \
--input_graph=/Users/leslie/Downloads/trained_model6.pb \
--input_checkpoint=/Users/leslie/Downloads/Y6_1476978999 \
--output_graph=/Users/leslie/Downloads/frozen_graph.pb --output_node_names=Y_GroundTruth
```

gives the error
```
File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/strip_unused.runfiles/org_tensorflow/tensorflow/python/tools/strip_unused.py"", line 77, in <module>
    tf.app.run()
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/strip_unused.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/strip_unused.runfiles/org_tensorflow/tensorflow/python/tools/strip_unused.py"", line 74, in main
    FLAGS.placeholder_type_enum)
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/strip_unused.runfiles/org_tensorflow/tensorflow/python/tools/strip_unused_lib.py"", line 89, in strip_unused_from_files
    placeholder_type_enum)
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/strip_unused.runfiles/org_tensorflow/tensorflow/python/tools/strip_unused_lib.py"", line 62, in strip_unused
    output_node_names)
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/strip_unused.runfiles/org_tensorflow/tensorflow/python/framework/graph_util.py"", line 158, in extract_sub_graph
    assert d in name_to_node_map, ""%s is not in graph"" % d
AssertionError: Y_GroundTruth is not in graph
leslie@MacBook-Pro tensorflow-master $ ./stripunused.sh
1 ops in the final graph.
leslie@MacBook-Pro tensorflow-master $ ./freezegraph.sh
Traceback (most recent call last):
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 135, in <module>
    tf.app.run()
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 132, in main
    FLAGS.output_graph, FLAGS.clear_devices, FLAGS.initializer_nodes)
  File ""/Users/leslie/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 98, in freeze_graph
    text_format.Merge(f.read().decode(""utf-8""), input_graph_def)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/encodings/utf_8.py"", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0x80 in position 278: invalid start byte
```
### Logs or other output that would be helpful
To stop the post from being too cluttered, I have uploaded my code to generate the .PB-file and my model to create the model on Pastebin.

Surprisingly enough, the code used to test the model with the graph used to generate the .PB-file  (lines 154 and 155) does not return any errors (still in the process of checking the outputs).
[PBFileGeneration](http://pastebin.com/6rv1rWV7)

[Model](http://pastebin.com/8DJx1kmL)
"
5584,Who can help me about my cuda-convnet2 reproduction in low accuracy,"I followed the tutorials of cnn and  tried the[ exercise](https://www.tensorflow.org/versions/r0.8/tutorials/deep_cnn/index.html#convolutional-neural-networks) about reproducing  cifar10 model in[ cuda-convnet2.](https://github.com/akrizhevsky/cuda-convnet2)
Recently, I thought I had worked it out, with implementing the local unshared layer by extract_image_patch function and batch_matmul function. [Here is my code of the cifar10.py](https://github.com/SunAriesCN/tensorflow_learning/blob/master/cifar10/exercise/ex2/cifar10_ex2_cuda_convnet.py) However, I found that the trained model is useless, because its accuracy is just 0.101, too low, for evaluation as below:
`precision @ 1 = 0.101`
My inference() function just like this:
```
def inference(images):
  """"""Build the CIFAR-10 model.
  Args:
    images: Images returned from distorted_inputs() or inputs().
  Returns:
    Logits.
  """"""
  # We instantiate all variables using tf.get_variable() instead of
  # tf.Variable() in order to share variables across multiple GPU training runs.
  # If we only ran this model on a single GPU, we could simplify this function
  # by replacing all instances of tf.get_variable() with tf.Variable().
  #
  # conv1
  with tf.variable_scope('conv1') as scope:
    kernel = _variable_with_weight_decay('weights', shape=[5, 5, 3, 64],
                                         stddev=1e-4, wd=0.0)
    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')
    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))
    bias = tf.nn.bias_add(conv, biases)
    conv1 = tf.nn.relu(bias, name=scope.name)
    _activation_summary(conv1)

  # pool1
  pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],
                         padding='SAME', name='pool1')
  # norm1
  norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,
                    name='norm1')

  # conv2
  with tf.variable_scope('conv2') as scope:
    kernel = _variable_with_weight_decay('weights', shape=[5, 5, 64, 64],
                                         stddev=1e-4, wd=0.0)
    conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')
    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))
    print('conv2 is', conv)
    print('biases2 is', biases)
    bias = tf.nn.bias_add(conv, biases)
    conv2 = tf.nn.relu(bias, name=scope.name)
    _activation_summary(conv2)

  # norm2
  norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,
                    name='norm2')
  # pool2
  pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],
                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')

  # local3
  with tf.variable_scope('local3') as scope:
    print('pool2 is', pool2)
    local3_extract_imgs = tf.extract_image_patches(pool2,[1,3,3,1],[1,1,1,1],[1,1,1,1],'SAME')
    print('local3_extract_imgs is', local3_extract_imgs)
    #local3_reshape = tf.reshape(local3_extract_imgs,[FLAGS.batch_size,6,6,3*3*64,1])
    #print('local3_reshape is', local3_reshape)
    kernel = _variable_with_weight_decay('weights', shape=[6,6,64,3*3*64], stddev=0.04, wd=0.004)
    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))
    local3_list = []
    for img in tf.unpack(value=local3_extract_imgs,axis=0):
      #print('raw img is', img)
      img = tf.reshape(img, [6, 6, 3*3*64, 1])
      local = tf.reshape(tf.batch_matmul(kernel, img),[6,6,64])
      #print( 'local is', local)
      local3_list.append(local)

    local3 = tf.nn.relu(tf.nn.bias_add(tf.pack(local3_list), biases), name=scope.name)
    print('local3 is', local3)
    _activation_summary(local3)

  # local4
  with tf.variable_scope('local4') as scope:
    local4_extract_imgs = tf.extract_image_patches(local3,[1,3,3,1],[1,1,1,1],[1,1,1,1],'SAME')
    #local4_reshape = tf.reshape(local4_extract_imgs, [FLAGS.batch_size, 6, 6, 3*3*64, 1])
    kernel = _variable_with_weight_decay( 'weights', shape=[6,6,32,3*3*64], stddev=0.04, wd=0.004) 
    biases = _variable_on_cpu('biases', [32], tf.constant_initializer(0.1))
    local4_list = []
    for img in tf.unpack(value=local4_extract_imgs, axis=0):
      img = tf.reshape(img, [6, 6, 3*3*64, 1])
      local = tf.reshape(tf.batch_matmul(kernel, img), shape=[6,6,32])
      local4_list.append(local)

    local4 = tf.nn.relu(tf.nn.bias_add(tf.pack(local4_list), biases), name=scope.name)
    print('local4 is', local4)
    _activation_summary(local4)

  # softmax, i.e. softmax(WX + b)
  with tf.variable_scope('softmax_linear') as scope:
    reshape = tf.reshape(tensor=local4, shape=[FLAGS.batch_size,-1])

    weights = _variable_with_weight_decay('weights', [6*6*32, NUM_CLASSES],
                                          stddev=1/192.0, wd=0.0)
    biases = _variable_on_cpu('biases', [NUM_CLASSES],
                              tf.constant_initializer(0.0))
    softmax_linear = tf.nn.softmax(tf.add(tf.matmul(reshape, weights), biases, name=scope.name))
    _activation_summary(softmax_linear)

return softmax_linear
```

I have tried my best, and I think my local layer implementation is  theorectically correct, so I have no idea where is wrong on my code. Who can give me some advices?"
5583,error duing running transflow model,"I am following[ this](https://medium.com/jim-fleming/loading-a-tensorflow-graph-with-the-c-api-4caaff88463f#.azr38581z) tutorial:  But as i try to run the loader.cc file after succesfully building it, i get this error: Not found: models/train.pb
I have already copyed the train.pb file into /transflow/transflow/model folder and i also tried to copy this file inside /transflow/bazel-bin/model but it is locked. So how do i remove this error. even after i unlocked the bazel folder and than copied the train.pb file inside models, it shows the same error. "
5582,error duing running transflow model:  ,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5580,TensorFlow r0.11 C impl protobuf package incompatible with Python 3.5,"When building from source (master branch as r0.11 does not build; see https://github.com/tensorflow/tensorflow/issues/5578) bazel builds a protobuf python implementation.

```
$ python -c ""from google.protobuf.internal import api_implementation; print(api_implementation._default_implementation_type)""
python
```

The C implementation referenced in the documentation is incompatible with Python 3.5 in Ubuntu 16.04:

```
$ pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.0.0-cp3-none-linux_x86_64.whl
protobuf-3.0.0-cp3-none-linux_x86_64.whl is not a supported wheel on this platform.
```

Regression?? https://github.com/tensorflow/tensorflow/issues/3856"
5578,Compile TensorFlow r0.11 from source,"1. setup build environment
```
$ cat Dockerfile
FROM ubuntu:16.04

# Bazel.
RUN apt-get update && apt-get install -y --no-install-recommends curl ca-certificates
RUN echo ""deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8"" | tee /etc/apt/sources.list.d/bazel.list
RUN curl https://bazel.build/bazel-release.pub.gpg | apt-key add -
RUN apt-get update && apt-get install -y --no-install-recommends bazel

# TensorFlow src & dev deps.
RUN apt-get install -y --no-install-recommends git python3-numpy swig python3-dev python3-wheel python3-setuptools
RUN ln -s /usr/bin/python3 /usr/local/bin/python
RUN git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git /opt/tensorflow
WORKDIR /opt/tensorflow
$ docker build -t bazel .
```

2. start and attach to build environment:
```
$ docker run -it --name bazel-build bazel
root@c7027f1dec32:/opt/tensorflow# git checkout r0.11
Switched to branch 'r0.11'
Your branch is up-to-date with 'origin/r0.11'.
root@c7027f1dec32:/opt/tensorflow# ./configure 
/opt/tensorflow /opt/tensorflow
Please specify the location of python. [Default is /usr/local/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] 
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] 
No Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/local/lib/python3.5/dist-packages
  /usr/lib/python3/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]

/usr/local/lib/python3.5/dist-packages
Do you wish to build TensorFlow with GPU support? [y/N] 
No GPU support will be enabled for TensorFlow
Configuration finished
Extracting Bazel installation...
.............
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
.............
WARNING: /root/.cache/bazel/_bazel_root/fbc06f9baef46cade6e35d9e4137e37c/external/protobuf/protobuf.bzl:90:19: Variables HOST_CFG and DATA_CFG are deprecated in favor of strings ""host"" and ""data"" correspondingly.
WARNING: /root/.cache/bazel/_bazel_root/fbc06f9baef46cade6e35d9e4137e37c/external/protobuf/protobuf.bzl:96:28: Variables HOST_CFG and DATA_CFG are deprecated in favor of strings ""host"" and ""data"" correspondingly.
INFO: All external dependencies fetched successfully.
root@c7027f1dec32:/opt/tensorflow# 
```

3. Now try to build:
```
root@c7027f1dec32:/opt/tensorflow# bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
WARNING: /root/.cache/bazel/_bazel_root/fbc06f9baef46cade6e35d9e4137e37c/external/protobuf/protobuf.bzl:90:19: Variables HOST_CFG and DATA_CFG are deprecated in favor of strings ""host"" and ""data"" correspondingly.
WARNING: /root/.cache/bazel/_bazel_root/fbc06f9baef46cade6e35d9e4137e37c/external/protobuf/protobuf.bzl:96:28: Variables HOST_CFG and DATA_CFG are deprecated in favor of strings ""host"" and ""data"" correspondingly.
ERROR: /opt/tensorflow/tensorflow/python/BUILD:1728:1: in cc_library rule //tensorflow/python:tf_session_helper: non-test target '//tensorflow/python:tf_session_helper' depends on testonly target '//tensorflow/python:construction_fails_op' and doesn't have testonly attribute set.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
INFO: Elapsed time: 1.643s
root@c7027f1dec32:/opt/tensorflow# 
```
"
5577,Possible Bug - tf.nn.moments differing outputs,"Hello,

I am observing differing outputs from tf.nn.moments when I run it multiple times on the same data, using GPU.  This makes it difficult for me to replicate my learning process!  See the logs at the bottom for what I mean.  I would expect the difference between moments across runs on the same data to be zero, but that is not the case in the logs I attached below (and most of the times I run it).  

If I run on CPU it is fine though.  Also, if I compute moments over smaller sets of data the problems seems to occur less often.

Not sure what would be causing this, my guess would be some sort of numerical instability?  Help would be appreciated!

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None found, I discovered this issue when trying to get replicable results using batch_norm in contrib.

### Environment info
Operating System: Ubuntu 14.04.5 LTS (running in a [singularity](http://singularity.lbl.gov) container on a CentOS 6.7 host). 

Installed version of CUDA and cuDNN: 
I am using CUDA 8.0 with NVIDIA driver 367.48, and cuDNN v5.1 . 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
libOpenCL.so
libOpenCL.so.1
libOpenCL.so.1.0
libOpenCL.so.1.0.0
libcublas.so
libcublas.so.8.0
libcublas.so.8.0.45
libcublas_device.a
libcublas_static.a
libcudadevrt.a
libcudart.so
libcudart.so.8.0
libcudart.so.8.0.44
libcudart_static.a
libcudnn.so
libcudnn.so.5
libcudnn.so.5.1.5
libcudnn_static.a
libcufft.so
libcufft.so.8.0
libcufft.so.8.0.44
libcufft_static.a
libcufftw.so
libcufftw.so.8.0
libcufftw.so.8.0.44
libcufftw_static.a
libcuinj64.so
libcuinj64.so.8.0
libcuinj64.so.8.0.44
libculibos.a
libcurand.so
libcurand.so.8.0
libcurand.so.8.0.44
libcurand_static.a
libcusolver.so
libcusolver.so.8.0
libcusolver.so.8.0.44
libcusolver_static.a
libcusparse.so
libcusparse.so.8.0
libcusparse.so.8.0.44
libcusparse_static.a
libnppc.so
libnppc.so.8.0
libnppc.so.8.0.44
libnppc_static.a
libnppi.so
libnppi.so.8.0
libnppi.so.8.0.44
libnppi_static.a
libnppial.so
libnppial.so.8.0
libnppial.so.8.0.44
libnppicc.so
libnppicc.so.8.0
libnppicc.so.8.0.44
libnppicom.so
libnppicom.so.8.0
libnppicom.so.8.0.44
libnppidei.so
libnppidei.so.8.0
libnppidei.so.8.0.44
libnppif.so
libnppif.so.8.0
libnppif.so.8.0.44
libnppig.so
libnppig.so.8.0
libnppig.so.8.0.44
libnppim.so
libnppim.so.8.0
libnppim.so.8.0.44
libnppist.so
libnppist.so.8.0
libnppist.so.8.0.44
libnppisu.so
libnppisu.so.8.0
libnppisu.so.8.0.44
libnppitc.so
libnppitc.so.8.0
libnppitc.so.8.0.44
libnpps.so
libnpps.so.8.0
libnpps.so.8.0.44
libnpps_static.a
libnvToolsExt.so
libnvToolsExt.so.1
libnvToolsExt.so.1.0.0
libnvblas.so
libnvblas.so.8.0
libnvblas.so.8.0.44
libnvgraph.so
libnvgraph.so.8.0
libnvgraph.so.8.0.44
libnvgraph_static.a
libnvrtc-builtins.so
libnvrtc-builtins.so.8.0
libnvrtc-builtins.so.8.0.44
libnvrtc.so
libnvrtc.so.8.0
libnvrtc.so.8.0.44
stubs
```

I installed tensorflow using the 0.11.0rc2-gpu tag on docker hub.

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
import numpy as np
import tensorflow as tf

batch_size = 2**10
channel_size = 100

if __name__ == ""__main__"":

    with tf.device('/gpu:0'):
        x = tf.placeholder(tf.float32, shape=[None, channel_size],
                           name='input')
        mom = tf.nn.moments(x, [0])

    feed_dict = {}
    feed_dict['input:0'] = np.random.rand(batch_size, channel_size)

    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:
        tf.initialize_all_variables().run()
        [mom_out1] = sess.run([mom], feed_dict=feed_dict)
        [mom_out2] = sess.run([mom], feed_dict=feed_dict)
    print ""DIFFERENCE:"", mom_out1[0][0] - mom_out2[0][0]
```

### What other attempted solutions have you tried?

No other solutions tried.


### Logs or other output that would be helpful

Output of running my the code once:
```
WARNING: Not mounting current directory: user bind control is disabled by system administrator
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:09:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)
DIFFERENCE: -5.96046e-08
```"
5576,win10 pthread.lib can not be found,"errot log:
-- Looking for pthread.h
-- Looking for pthread.h - found
-- Looking for pthread_create
-- Looking for pthread_create - not found
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - found
-- Found Threads: TRUE
how can i fix this problem, i have solved the .h issue ,but the lib issue can be solved in vs by prgma ,but for cmake , i have put prgma in every file related to pthread.h"
5575,"Seq2Seq model decode error problem ""Not found: Tensor name""","I trained with tutorial neural translation model with my toy dataset .
(python translate.py --data_dir data/ --train_dir data/train/ --size=64 --num_layers=2 --steps_per_checkpoint=50)

But when i type decode command (python translate.py --decode --data_dir data/ --train_dir data/train/)

I got error like this. I have attached error log.

Please help me TT

Reading model parameters from data/train/translate.ckpt-236700
W tensorflow/core/framework/op_kernel.cc:968] Not found: Tensor name ""embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix"" not found in checkpoint files data/train/translate.ckpt-236700
         [[Node: save/restore_slice_14 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_14/tensor_name, save/restore_slice_14/shape_and_slice)]]

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://github.com/tensorflow/tensorflow/issues/3776

### Environment info
Operating System: Ubuntu 14.04.3 LTS

Installed version of CUDA and cuDNN: 

-rw-r--r-- 1 root root  189170  7ì 29 00:33 /usr/local/cuda-7.5/lib/libcudadevrt.a
lrwxrwxrwx 1 root root      16  7ì 29 00:33 /usr/local/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root      19  7ì 29 00:33 /usr/local/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root  311596  7ì 29 00:33 /usr/local/cuda-7.5/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root  558020  7ì 29 00:33 /usr/local/cuda-7.5/lib/libcudart_static.a
lrwxrwxrwx 1 root root      17  7ì 29 00:33 /usr/local/cuda-7.5/lib/libcuinj32.so -> libcuinj32.so.7.5
lrwxrwxrwx 1 root root      20  7ì 29 00:33 /usr/local/cuda-7.5/lib/libcuinj32.so.7.5 -> libcuinj32.so.7.5.18
-rwxr-xr-x 1 root root 5396088  7ì 29 00:33 /usr/local/cuda-7.5/lib/libcuinj32.so.7.5.18


If installed from binary pip package, provide:

I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
0.11.0rc0


If installed from source, provide 

### What other attempted solutions have you tried?
- install latest version of tensorflow==0.11.0rc0

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
[error_log.txt](https://github.com/tensorflow/tensorflow/files/587629/error_log.txt)

"
5570,Tensorflow works in command line ipython but not in ipython notebook,"This is a setup issue. Tensorflow works in ipython command line but not in ipython notebook. When import in ipython notebook, I get error:

```
ImportError: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.19' not found (required by /usr/local/packages/python/2.7.10-anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so)


Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.
```

This is possibly related to https://github.com/tensorflow/tensorflow/issues/5141.
Screenshots of the problem is in http://stackoverflow.com/q/40569279/1363677

### Environment info
Operating System:

Red Hat Enterprise Linux Server release 6.4 (Santiago)
`Linux qb2 2.6.32-358.23.2.el6.x86_64 #1 SMP Sat Sep 14 05:32:37 EDT 2013 x86_64 x86_64 x86_64 GNU/Linux`


Installed version of CUDA and cuDNN: 

```
-rw-r--r-- 1 root root  189170 Oct 11 10:13 libcudadevrt.a
lrwxrwxrwx 1 root root      16 Oct 11 10:13 libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root      19 Oct 11 10:13 libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root  311596 Oct 11 10:13 libcudart.so.7.5.18
-rw-r--r-- 1 root root  558020 Oct 11 10:13 libcudart_static.a
lrwxrwxrwx 1 root root      17 Oct 11 10:13 libcuinj32.so -> libcuinj32.so.7.5
lrwxrwxrwx 1 root root      20 Oct 11 10:13 libcuinj32.so.7.5 -> libcuinj32.so.7.5.18
-rwxr-xr-x 1 root root 5396088 Oct 11 10:13 libcuinj32.so.7.5.18
```


```
python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.7.5 locally
0.11.0rc0
```

I'm not sure whether this is relevant, but my ipython kernel is on a remote machine, and the notebook interface is on my local machine. The ipython kernel is started using

`[user@remote ~]$ ipython notebook --no-browser --port=8889`

Then at my local machine, I set up the port forwarding as

`[user@local ~]$ ssh -N -L localhost:8888:localhost:8889 remote`

And the notebook interface is started from the browser at localhost:8888


@drpngx "
5569,Python 3 Builds in CI are failing,"All our python 3 builds for pull requests on our CI are failing with the following error:
```
ERROR: /var/lib/jenkins/workspace/tensorflow-pull-requests-cpu-python3/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/external/bazel_tools/tools/build_defs/pkg/BUILD:44:1: Converting to Python 3: external/bazel_tools/tools/build_defs/pkg/build_tar.py failed: 2to3 failed: error executing command 
  (cd /var/lib/jenkins/workspace/tensorflow-pull-requests-cpu-python3/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace && \
  exec env - \
  bazel-out/host/bin/external/bazel_tools/tools/python/2to3 --no-diffs --nobackups --write --output-dir bazel-out/host/genfiles/python3/external/bazel_tools/tools/build_defs/pkg --write-unchanged-files external/bazel_tools/tools/build_defs/pkg/build_tar.py): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
```

It seems to be independent of the PR we are testing, and the error message above does not really makes sense. @damienmg , could you help us decode the above error
@benoitsteiner , who is running into this problem."
5568,Attempt to create quantized tf.constant results in a TypeError,"### Environment info
Operating System:
MacOS 10.12.1

1. The commit hash (`git rev-parse HEAD`)
f794cd393b1e7821fcc3cdcee9b6a4400f2540bf
2. The output of `bazel version`
Build label: 0.3.1-homebrew
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Sep 27 03:15:13 2016 (1474946113)
Build timestamp: 1474946113
Build timestamp as int: 1474946113

### Repro code
```python
import tensorflow as tf

sess = tf.Session()
with sess.as_default():
     m = tf.constant(3, dtype=tf.qint8)
     print(m.eval())
```
#### result:
```bash
Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
  File ""/Users/b0noI/src/tensorflow/_python_build/tensorflow/python/framework/constant_op.py"", line 163, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))
  File ""/Users/b0noI/src/tensorflow/_python_build/tensorflow/python/framework/tensor_util.py"", line 354, in make_tensor_proto
    nparray = np.array(values, dtype=np_dt)
TypeError: expected a readable buffer object
```"
5564,tutorial - code,"Hello Team,

Yesterday evening I completed your tutorial (https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#5) to take my first steps with tensorflow. During the process I had to complete the code as in label_image.py there is no import sys line.

Cheers!"
5562,square of square root is identity,"```python
import tensorflow as tf

tensor = tf.constant(0.0)
loss = tf.square(tf.sqrt(tensor))
grad = tf.gradients(loss, tensor)

with tf.Session() as sess:
    print grad[0].eval()
```

This gives `nan`. The gradient of `sqrt(x)` with respect to `x` is `inf` at `0` which is likely causing the problem.

Would be useful to have automatic inference for this such that `sqrt` followed by `square` can be removed at least for the purpose of gradient computation. There are other similar cases (e.g. `exp` of `log`) where such inference would help."
5559,print_selective_registration_header,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

print_selective_registration_header is not working with TF master.

### Environment info
Operating System:

MacOSX

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

1. create ops_to_register.h and copy to tensorflow/
2. go to tensorflow/tensorflow.bzl
3. add -DSELECTIVE_REGISTRATION and -Itensorflow/ to tf_copts
4. bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

returns with various (clustering, logging) ops missing error.

### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5555,GPU-enabled Mac build of TensorFlow version 0.11.0rc2-py2 was compiled against cuDNN v5.1,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
This is a regression of issue #3826.

### Environment info
Operating System: macOS Sierra Version 10.12.1 (16B2555)

Installed version of CUDA and cuDNN: cuda_8.0.47_mac, cudnn-8.0-osx-x64-v5.1 (I explain why I am using cuDNN v5.1 rather than cuDNN v5 below.)
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
lrwxr-xr-x  1 root  admin     13 Nov 11 17:13 /usr/local/cuda/lib/libcuda.1.dylib -> libcuda.dylib
-rwxr-xr-x@ 1 root  wheel  13504 Sep 26 17:59 /usr/local/cuda/lib/libcuda.dylib
lrwxr-xr-x@ 1 root  wheel     45 Sep 26 18:00 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a
lrwxr-xr-x@ 1 root  wheel     50 Sep 26 18:00 /usr/local/cuda/lib/libcudart.8.0.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib
lrwxr-xr-x@ 1 root  wheel     46 Sep 26 18:00 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib
lrwxr-xr-x@ 1 root  wheel     49 Sep 26 18:00 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a
lrwxr-xr-x  1 root  admin     47 Nov 11 17:29 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.5.dylib
lrwxr-xr-x  1 root  admin     45 Nov 11 17:29 /usr/local/cuda/lib/libcudnn.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.dylib
lrwxr-xr-x  1 root  admin     48 Nov 11 17:29 /usr/local/cuda/lib/libcudnn_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn_static.a
```

If installed from binary pip package, provide:

1. A link to the pip package you installed: `export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.11.0rc2-py2-none-any.whl`
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
```
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.dylib locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.dylib locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.dylib locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.1.dylib locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.dylib locally
0.11.0rc2
```

If installed from source: Not Applicable

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
1. Set up TensorFlow according to the instructions at  
https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#prepare_environment_for_mac_os_x

    In particular, the page says to install cuDNN v5 from the cuDNN Download page.
2. Test the installation by running:

        cuda-memcheck python -m tensorflow.models.image.mnist.convolutional

    You should see:

    > E tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded runtime CuDNN library: 5005 (compatibility version 5000) but source was compiled with 5105 (compatibility version 5100).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.

### What other attempted solutions have you tried?
Uninstalling cuDNN v5 and installing cuDNN v5.1 (labeled ""cuDNN v5.1 (August 10, 2016), for CUDA 8.0"" on the cuDNN Download page) fixes the issue.

As before in issue #3826, the installation instructions should be corrected to specify that cuDNN v5.1 needs to be installed."
5554,Unable to install GPU enabled TensorFlow,"To install TensorFlow with GPU on an Ubuntu system, I installed CUDA v 8.0 using `cuda-repo-ubuntu1404_8.0.44-1_amd64.deb` and cuDNN using `cudnn-8.0-linux-x64-v5.1`.

The following are the environment variables in ~/.profile file: 

```
LD_LIBRARY_PATH=/usr/local/cuda/lib64
CUDA_PATH=/usr/local/cuda
```

On running the ./configure command inside the tensorflow folder the following error is displayed:

![image](https://cloud.githubusercontent.com/assets/17990840/20231345/07e4f14e-a82f-11e6-9552-c19876c17012.png)

Seeking assistance from @drpngx 

Any help is appreciated.

"
5553,Running own TensorFlow model on Android gives native inference error: âSession was not created with a graph before Run()!â,"I was able to run the Inception-v3 model on Android just fine, and I now want to run my own trained TensorFlow model on Android. I'm following the approach from [TensorFlow's image recognition tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/image_recognition/index.html) and the Android TensorFlow demo, and adapting as necessary. My changes include: (a) integrating Android OpenCV as part of the bazel build (b) using own model and label file and (c) adjusting parameters (img_size, input_mean, input_std, etc.) accordingly.

From Android logcat, running my model with the tensorflow android demo app gives:

```
E/native: tensorflow_inference_jni.cc:202 Error during inference: Invalid argument: Session was not created with a graph before Run()!
...
E/native: tensorflow_inference_jni.cc:159 Output [output/Softmax:0] not found, aborting!

```

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Own (duplicate) SO thread: http://stackoverflow.com/questions/40555749/running-own-tensorflow-model-on-android-gives-native-inference-error-session-w

### Environment info
OS X Yosemite (10.10.5), LGE Nexus 5 (Android 6.0.1), Android SDK 23, Android OpenCV SDK 23, Bazel 0.4.0.

### Steps taken

1. Saved own model's checkpoint (.ckpt) and graph definition (.pb) files separately using `tf.train.Saver()` then `tf.train.write_graph()`
2. Froze graph using freeze_graph.py (using bazel), gives 227.5 MB file
3. Optimized the graph using optimize_for_inference.py (additionally tried strip_unused.py)
4. Copied frozen, optimized, or stripped graph to android/assets
5. Doubled the total byte limit using `coded_stream.SetTotalBytesLimit()` in jni_utils.cc to handle my large model size
6. Built the tensorflow android app using bazel
7. Installed on android device using adb and bazel

As a sanity check, I have tested my model in C++ built with bazel following the tutorial here [label_image](https://www.tensorflow.org/versions/r0.8/how_tos/image_retraining/index.html), and my model correctly outputs a prediction. I have also tried playing with the order by which I save my graph def and checkpoint files before freezing, but no change.

Any help would be great. 
cc @drpngx @andrewharp 
"
5552,[docs] python3 bytes -> string in example in README,"The current README.md indicates the following ""first TensorFlow program"":

```
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
>>> sess.run(hello)
Hello, TensorFlow!
>>> a = tf.constant(10)
>>> b = tf.constant(32)
>>> sess.run(a+b)
42
>>>
```

This works fine under python2, but handling of strings has [changed slightly in python3](http://stackoverflow.com/a/6269785). Suggested improvement to the example program for compatibility with both python2 and python3 (we need to [convert bytes to string](http://stackoverflow.com/a/606199)):

```
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
>>> sess.run(hello).decode(""utf-8"")
Hello, TensorFlow!
>>> a = tf.constant(10)
>>> b = tf.constant(32)
>>> sess.run(a+b)
42
```

Tested from the [wheel build](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#virtualenv-installation) of 0.11.0 (final), [converted to RPM](https://copr.fedorainfracloud.org/coprs/dgoerger/yale-zoo/package/python-tensorflow/), on Fedora 24/25.

Thanks!"
5551,Inconsistent behavior for variables_collections and outputs_collections parameters (contrib/layers),"Using layers from contrib,
- The outputs_collections parameter accepts either a string or list of strings.
- The variables_collections parameter requires a list of strings.

Granted, the documentation does specify this
```
variables_collections: optional list of collections for all the variables or
      a dictionay containing a different list of collection per variable.
outputs_collections: collection to add the outputs.
```
But I don't think it's very obvious.  Furthermore, is it really necessary to have these two parameters behave differently?

The variables_collections parameter is passed to the model_variable function()
Currently, the model_variable() function performs this before creating the variable:
```
  collections = list(collections or [])
  collections += [ops.GraphKeys.VARIABLES, ops.GraphKeys.MODEL_VARIABLES]
```
So, if
```
# variables_collections = 'kernels'
collections
['k', 'e', 'r', 'n', 'e', 'l', 's']
```


Whereas, for outputs_collections it uses the utils.collect_named_outputs() function, wherein
```
# variables_collections = 'kernels'
names = (names,) if isinstance(names, six.string_types) else set(names)
names
('kernels',)
```

Perhaps the behavior of these two parameters should be unified?"
5550,Checkpoint v2 breaking translate.py restore,"The following restore won't work with new checkpoint v2.
https://github.com/tensorflow/tensorflow/blob/816ecb7a342c25c19daa8b19627346e1fb38e56f/tensorflow/models/rnn/translate/translate.py#L134"
5549,unable to generate tensorflow/go/op,"Unable to generate ``tensorflow/go/op``, because of ``ld`` link errors, undefined reference to few stl methods.

I've already tried adding ``-lstdc++ -lgcc -lc`` to ``LDFLAGS`` environmental variable and ``-ldflags`` parameter to ``go generate``

Tensorflow installed from source, commit hash ``20c3d37ecc9bef0e106002b9d01914efd548e66b``

### Environment
Operating system: 
```
Linux 397f80c505a4 4.4.30-1-MANJARO #1 SMP PREEMPT Tue Nov 1 05:47:13 UTC 2016 x86_64 GNU/Linux
```

``go env`` output:
```
GOARCH=""amd64"" GOBIN="""" GOEXE="""" GOHOSTARCH=""amd64"" GOHOSTOS=""linux"" GOOS=""linux"" GOPATH=""/go"" GORACE="""" GOROOT=""/usr/local/go"" GOTOOLDIR=""/usr/local/go/pkg/tool/linux_amd64"" CC=""gcc"" GOGCCFLAGS=""-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build195639664=/tmp/go-build -gno-record-gcc-switches"" CXX=""g++"" CGO_ENABLED=""1""

```

### Error message:

```src/github.com/tensorflow/tensorflow/tensorflow/go/op/generate.go
go generate github.com/tensorflow/tensorflow/tensorflow/go/op                                                         
# github.com/tensorflow/tensorflow/tensorflow/go                                          
/lib/../lib/libtensorflow.so: undefined reference to `vtable for std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'                 
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4.21'                                                                  
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::assign(char const*)@GLIBCXX_3.4.21'          
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()@GLIBCXX_3.4.21'              
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_erase(unsigned long, unsigned long)@GLIBCXX_3.4.21'                                                                                 
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_replace_aux(unsigned long, unsigned long, unsigned long, char)@GLIBCXX_3.4.21'                                                      
/lib/../lib/libtensorflow.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::operator>><char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)@GLIBCXX_3.4.21'                                     
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_stringstream()@GLIBCXX_3.4.21'  
/lib/../lib/libtensorflow.so: undefined reference to `typeinfo for std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'           
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::rfind(char, unsigned long) const@GLIBCXX_3.4.21'                                                                                       
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_append(char const*, unsigned long)@GLIBCXX_3.4.21'                                                                                  
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long, unsigned long)@GLIBCXX_3.4.21'                                                                               
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(unsigned long, unsigned long, char const*) const@GLIBCXX_3.4.21'                                                               
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::reserve(unsigned long)@GLIBCXX_3.4.21'       
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::resize(unsigned long, char)@GLIBCXX_3.4.21'  
/lib/../lib/libtensorflow.so: undefined reference to `vtable for std::__cxx11::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'              
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::find(char, unsigned long) const@GLIBCXX_3.4.21'                                                                                        
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::substr(unsigned long, unsigned long) const@GLIBCXX_3.4.21'                                                                             
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_mutate(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4.21'                                                    
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::find_last_of(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4.21'                                                          
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_replace(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4.21'                                                   
/lib/../lib/libtensorflow.so: undefined reference to `std::thread::_M_start_thread(std::shared_ptr<std::thread::_Impl_base>, void (*)())@GLIBCXX_3.4.21'                            
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::find_first_of(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4.21'                                                         
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()@GLIBCXX_3.4.21'
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::_M_sync(char*, unsigned long, unsigned long)@GLIBCXX_3.4.21'                                                                        
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::swap(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)@GLIBCXX_3.4.21'                                 
/lib/../lib/libtensorflow.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::getline<char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, char)@GLIBCXX_3.4.21'                                  
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(unsigned long, unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const@GLIBCXX_3.4.21'                                                                              
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::find_first_not_of(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4.21'                                                     
/lib/../lib/libtensorflow.so: undefined reference to `VTT for std::__cxx11::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'                 
/lib/../lib/libtensorflow.so: undefined reference to `lgammaf@GLIBC_2.23'                 
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_assign(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'                      
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::find_last_not_of(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4.21'                                                      
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::append(char const*)@GLIBCXX_3.4.21'          
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(char const*) const@GLIBCXX_3.4.21'   
/lib/../lib/libtensorflow.so: undefined reference to `vtable for std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'             
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_construct(unsigned long, char)@GLIBCXX_3.4.21'
/lib/../lib/libtensorflow.so: undefined reference to `std::random_device::_M_init(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::push_back(char)@GLIBCXX_3.4.21'
/lib/../lib/libtensorflow.so: undefined reference to `VTT for std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const@GLIBCXX_3.4.21'
/lib/../lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_create(unsigned long&, unsigned long)@GLIBCXX_3.4.21'
/lib/../lib/libtensorflow.so: undefined reference to `lgamma@GLIBC_2.23'
collect2: error: ld returned 1 exit status
../genop/main.go:15: running ""sh"": exit status 1
src/github.com/tensorflow/tensorflow/tensorflow/go/op/generate.go:15: running ""go"": exit status 1
```
"
5548,Restore and predict tensorflow contrib.learn.DNNRegressor/DNNClassifier without running at least one step of training (which was a missing feature).,"Hi,

I'm following up on the issue that is mentioned in this thread:
https://github.com/tensorflow/tensorflow/issues/3340

Currently the way to restore a trained model is: First created a DNNRegressor/DNNClassifier specifiyng model_dir on constructor, fit() (training step) , and restore it by creating another DNNRegressor/DNNClassifier using the same model_dir in constructor. That works for me and is not the problem.

However, when I want to make the model portable to others, meaning I train on my machine and copy the model file it generates to others, and let them predict on new data sets without training again. It fails.

And from a large and wide search on the issue, I find several resources point out to the same reply: ""Right now, there isn't a way to restore and predict without running at least one step of training (which is a missing feature)""@martinwicke 
Another reference: https://github.com/tensorflow/tensorflow/issues/3306

Since this was the reply 3 months ago, and now I follow @michaelisard 's suggestion to open a separate  issue to track the feature of restoring without predicting.

Look forward to hearing from experts who develops tensorflow, or any walk-around is welcome. Thanks!





"
5545,Use of Inception v5 model to extract characters from video frames,
5544,lack of up-to-date files after upgrading to tensorflow 0.11,"I just upgraded tensorflow to 0.11 by using `conda install -c conda-forge tensorflow` , but still lack of files in `anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/examples/tutorials`, such as `mnist_softmax.py`. The current files I have in this folder are:
```
__init__.py 
__init__.pyc
input_data.py
input_data.pyc
mnist.py
mnist.pyc
```
"
5543,Constant folding doesn't remove control edges,"I believe that when constant folding takes place, and a section of a graph is replaced by a constant, that only the data output edge of the replaced node is removed.  

I believe that I can see that a graph of nodes ending up in a Div (part of the gradient generation bit) is replaced by a Const.  The output of the Div goes to a Mul, and this is changed to the new const correctly.

However, there is a control output from the Div going to a Const (not sure why, but it is).  This is not changed to the Div replacement.  Consequently the dead node pruning doesn't remove the original Div.  

Here is some trace:

During the constant folding:

Graph Before #nodes 67 #edges 109
Graph Constant graph #nodes 32 #edges 42
Constant foldable 32 : 67

Replacing {name:'gradients/Mean_grad/truediv' id:28 op device:{/job:localhost/replica:0/task:0/device:ipu:0} def:{gradients/Mean_grad/truediv = Div[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:ipu:0""](gradients/Mean_grad/Tile, gradients/Mean_grad/Cast)}} :: 0 with a constant
Replacing edge to gradients/Square_grad/mul_1:0

During the post constant folding pruning:

PruneForReverseReachability: gradients/Square_grad/mul_1 <- gradients/Mean_grad/truediv/_0__cf__1
PruneForReverseReachability: gradients/Square_grad/mul/x <- gradients/Mean_grad/truediv

After the pruning:

Graph ConstFolding #nodes 68 #edges 110


When the graph is passed to the device, it contains:

Node: gradients/Square_grad/mul/x = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 2>, _device=""/job:localhost/replica:0/task:0/device:ipu:0""](^gradients/Mean_grad/truediv)

"
5541,tensorflow/examples/learn/text_classification_builtin_rnn_model.py references removed TensorFlowRNNClassifier,"### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root 560184 May 19 01:44 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 May 19 01:47 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root     19 May 19 01:47 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rw-r--r-- 1 root root 394472 May 19 01:44 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root 737516 May 19 01:44 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root     37 Sep 12 12:36 /usr/local/cuda/lib64/libcudnn.so -> /usr/lib/x86_64-linux-gnu/libcudnn.so
lrwxrwxrwx 1 root root     39 Sep 12 12:36 /usr/local/cuda/lib64/libcudnn.so.5 -> /usr/lib/x86_64-linux-gnu/libcudnn.so.5
lrwxrwxrwx 1 root root     43 Sep 12 12:36 /usr/local/cuda/lib64/libcudnn.so.5.1.5 -> /usr/lib/x86_64-linux-gnu/libcudnn.so.5.1.5
lrwxrwxrwx 1 root root     43 Sep 12 12:38 /usr/local/cuda/lib64/libcudnn_static.a -> /usr/lib/x86_64-linux-gnu/libcudnn_static.a
lrwxrwxrwx 1 root root     46 Sep 12 12:38 /usr/local/cuda/lib64/libcudnn_static_v5.a -> /usr/lib/x86_64-linux-gnu/libcudnn_static_v5.a


If installed from source, provide 

1. git rev-parse HEAD = 2ac978d2532dd359dd7ebbd27ac13dfa147d755d
2. $ bazel version
Build label: 0.4.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 17:54:14 2016 (1478109254)
Build timestamp: 1478109254
Build timestamp as int: 1478109254

The file `tensorflow/examples/learn/text_classification_builtin_rnn_model.py` references `TensorFlowRNNClassifier`, which was removed in dfb1bfe6aec58700547f6525289090c737bfe453 so presumably this example should also be removed.

That commit doesn't mention why the class was removed and it looks quite useful. What is the replacement for it? `get_rnn_model()`? I can provide a PR to remove the example but wanted to check first if actually there is another word-level RNN example for `tf.contrib.learn` to point to?
"
5540,help with finetune process,"Hi there,
I have run the finetune_inception_v3_on_flowers.sh slim script example, and I have obtained the graph.pbtxt file. How can I use this file in a Python script for image classification? (e.g., https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/imagenet/classify_image.py)
Thanks."
5539,"Sticky  ""No OpKernel was registered to support Op 'Conv2D' with these attrs.""","There are two issues here:

1: tf.nn.conv2d does not support float64 tensors on CPU although the documentation states it should
2: after the first occurrence of the situation above, tf.nn.conv2d keeps crashing with the same error even when we provide float32 tensors.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://github.com/tensorflow/tensorflow/issues/4929

### Environment info
Operating System: Linux

Installed version of CUDA and cuDNN: None

If installed from binary pip package, provide:
1. A link to the pip package you installed:
-> https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp35-cp35m-linux_x86_64.whl
(not 100% sure though)
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
-> 0.11.0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
# issue 1: this never works although the documentation states that it should
import tensorflow as tf
import numpy as np

input = tf.constant(np.zeros([1,5,5,1]))
filter = tf.constant(np.zeros([3,3,1,1]))
op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='VALID')
tf.Session().run(op)

# issue 2: 
# - this works if executed *before* the part above
# - this does not work if exectuted *after* the part above
import tensorflow as tf
import numpy as np

input2 = tf.constant(np.zeros([1,5,5,1]), dtype=np.float32)
filter2 = tf.constant(np.zeros([3,3,1,1]), dtype=np.float32)
op2 = tf.nn.conv2d(input2, filter2, strides=[1, 1, 1, 1], padding='VALID')
tf.Session().run(op2)
```"
5538,Compiling error when adding -c dbg parameter,"I try to compile tensorflow in Docker machine:
./configure   // all options is default
bazel build -c dbg --local_resources 1500,1,1 --verbose_failures  tensorflow/tools/pip_package:build_pip_package --ignore_unsupported_sandboxing

bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg

the output is here:

Fri Nov 11 04:23:09 UTC 2016 : === Using tmpdir: /tmp/tmp.EhXibedOJY
/tensorflow/bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles /tensorflow
/tensorflow
/tmp/tmp.EhXibedOJY /tensorflow
Fri Nov 11 04:23:15 UTC 2016 : === Building wheel
Traceback (most recent call last):
  File ""setup.py"", line 201, in <module>
    keywords='tensorflow tensor machine learning',
  File ""/usr/lib/python2.7/distutils/core.py"", line 151, in setup
    dist.run_commands()
  File ""/usr/lib/python2.7/distutils/dist.py"", line 953, in run_commands
    self.run_command(cmd)
  File ""/usr/lib/python2.7/distutils/dist.py"", line 972, in run_command
    cmd_obj.run()
  File ""/usr/local/lib/python2.7/dist-packages/wheel/bdist_wheel.py"", line 241, in run
    wheel_name = archive_wheelfile(pseudoinstall_root, archive_root)
  File ""/usr/local/lib/python2.7/dist-packages/wheel/archive.py"", line 22, in archive_wheelfile
    return make_wheelfile_inner(base_name)
  File ""/usr/local/lib/python2.7/dist-packages/wheel/archive.py"", line 72, in make_wheelfile_inner
    writefile(path, date_time)
  File ""/usr/local/lib/python2.7/dist-packages/wheel/archive.py"", line 61, in writefile
    zip.writestr(zinfo, fp.read())
  File ""/usr/lib/python2.7/zipfile.py"", line 1222, in writestr
    self._writecheck(zinfo)
  File ""/usr/lib/python2.7/zipfile.py"", line 1106, in _writecheck
    raise LargeZipFile(""Filesize would require ZIP64 extensions"")
zipfile.LargeZipFile: Filesize would require ZIP64 extensions



"
5537,Disable display âsuccessfully opened CUDA library ****â when import tensorflow,"Hello, 
  when ```import tensorflow``` it will output some info which is boring to me , how to disable this dispaly without compile again? set CUDA_VISIBLE_DEVICES seems no work.  
```
In [1]: import tensorflow as tf;
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.7.5 locally
```

thanks
"
5536,I am trying to build tensorflow from source code and error happed,"after :bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
Things happend like this:

WARNING: /home/lixinyu/tensorflow/tensorflow/tensorflow.bzl:477:26: Variables HOST_CFG and DATA_CFG are deprecated in favor of strings ""host"" and ""data"" correspondingly.
WARNING: /home/lixinyu/tensorflow/tensorflow/tensorflow.bzl:490:24: Variables HOST_CFG and DATA_CFG are deprecated in favor of strings ""host"" and ""data"" correspondingly.
WARNING: /home/lixinyu/.cache/bazel/_bazel_lixinyu/824013fbb9b22e08d948a2226491e595/external/protobuf/protobuf.bzl:90:19: Variables HOST_CFG and DATA_CFG are deprecated in favor of strings ""host"" and ""data"" correspondingly.
WARNING: /home/lixinyu/.cache/bazel/_bazel_lixinyu/824013fbb9b22e08d948a2226491e595/external/protobuf/protobuf.bzl:96:28: Variables HOST_CFG and DATA_CFG are deprecated in favor of strings ""host"" and ""data"" correspondingly.
ERROR: /home/lixinyu/tensorflow/tensorflow/python/BUILD:1044:1: in cc_library rule //tensorflow/python:tf_session_helper: non-test target '//tensorflow/python:tf_session_helper' depends on testonly target '//tensorflow/python:construction_fails_op' and doesn't have testonly attribute set.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
INFO: Elapsed time: 0.209s


I googled this but there is not a trustworthy answer to my issue"
5534,Error while creating apk in TensorFlow Android Camera Demo,"I followed  instruction for TensorFlow Android Camera Demo, I changed the path for NDK and SDK in WORKSPACE and now when I'm trying to build APK, using command:

`$ bazel build //tensorflow/examples/android:tensorflow_demo`

I got such errors:

![screen shot 2016-11-10 at 8 00 20 am](https://cloud.githubusercontent.com/assets/10096433/20200940/18a39390-a7bd-11e6-939a-7a0f9132be11.png)

If I'm trying to build APK in Android Studio I get such Errors:

```
`Error:/private/var/tmp/_bazel_Iryna/c541cf0f6f349cf0d7c8d3692096116a/external/protobuf/BUILD:73:1: C++ compilation of rule '@protobuf//:protobuf_lite' failed: sandbox-exec failed: error executing command /usr/bin/sandbox-exec -f /private/var/tmp/_bazel_Iryna/c541cf0f6f349cf0d7c8d3692096116a/bazel-sandbox/a0350092-17a0-44fc-a63c-6321732c52f4-2/sandbox.sb /bin/false -MD -MF ... (remaining 27 argument(s) skipped).`
Error:Execution failed for task ':buildNative'.
> Process 'command '/usr/local/bin/bazel'' finished with non-zero exit value 1
```

My question in [StackOverflow.](http://stackoverflow.com/questions/40520927/error-while-trying-to-build-apk-of-tensorflow-android-camera-demo)"
5533,no modules in tensorflow/python ... ,"1. The commit hash (`git rev-parse HEAD`) 
    20c3d37ecc9bef0e106002b9d01914efd548e66b

Using CMake, I got and installed python whl, but, 'import tensorflow' causes no module error. 
It seems these two files are needed. 

1. tensorflow/python/ops/gen_resource_variable_ops.py this is already mentioned here: https://github.com/tensorflow/tensorflow/pull/5410) 
2. tensorflow/python/summary/writer/__init__.py 
"
5530,How to allow GPU memory growth under TF slim?,"Under TF library, we can set how GPU memory is used by creating a config as below and then assign to a session.

**config = tf.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.Session(config=config)**

However, I can't find any such config to let **TF slim** library to set memory usage mode. Directly put such config to **slim.learning.train()** method?"
5527,Inaccuracies in tf.reduce_sum,"I've been trying to normalize some vectors by dividing by their sum, but have noticed that this doesn't always result in vectors that sum to one. 

For example:

```
foo = np.random.rand(100)*100 #random floats between 0-100
print(sess.run(tf.reduce_sum(foo/tf.reduce_sum(foo)))) #should return 1
print((foo/foo.sum()).sum()) #does return 1
```

While I realize that this is possible with finite precision floating point operations, I find it odd how readily it occurs, especially when the same operation in numpy doesn't encounter this issue. Is this a known issue? I've also noticed that tf.nn.softmax doesn't appear to suffer from this problem, is there a different op I need to use to ensure proper normalization?"
5525,AttributeError: 'module' object has no attribute 'dtypes',"version r0.11

python 2

Mac OS

gender = tf.contrib.layers.sparse_column_with_integerized_feature(column_name=""sex"",
                                                                      bucket_size=2, dtype=tf.dtypes.int16)


  File ""/Users/sh1ng/Projects/santander/nn/simple.py"", line 220, in <module>
    tf.app.run()
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/sh1ng/Projects/santander/nn/simple.py"", line 216, in main
    train_and_eval()
  File ""/Users/sh1ng/Projects/santander/nn/simple.py"", line 208, in train_and_eval
    m = build_estimator(model_dir)
  File ""/Users/sh1ng/Projects/santander/nn/simple.py"", line 75, in build_estimator
    bucket_size=2, dtype=tf.dtypes.int16)
AttributeError: 'module' object has no attribute 'dtypes'"
5523,"XLA's Dot should follow broadcast semantics from np.matmul, not np.dot","I notice that the [XLA Dot operation](https://www.tensorflow.org/versions/master/resources/xla_prerelease.html#dot) copies ""outer-product style"" broadcast semantics from `numpy.dot`:

| Input                                     | Output                | Semantics                      |
|-------------------------------------------|-----------------------|--------------------------------|
| array [p x q x r] `dot` array [s x r x t] | array [p x q x s x t] | array dot product (read below) |
 
In brief, I think this is a mistake. It would be better to follow the ""[matmul style](http://legacy.python.org/dev/peps/pep-0465/#semantics)"" style broadcasting semantics of Python's `@` operation and NumPy's `matmul`.

matmul's broadcasting is much more general, and in my opinion, also easier to understand. For example, it can do batch matrix-multiplication, but also can still do outer product style broadcasting if you insert dummy dimensions of length 1 (the axes do end up in a different order), e.g.,
batch matmul: [p x q x r] `matmul` [p x r x t] -> [p x q x t]
outer product matmul: [p x 1 x q x r] `matmul` [1 x s x r x t] -> [p x s x q x t]

If we could go back in time as NumPy developers, we assuredly would change `dot` to work this way (now we cannot, because of backwards compatibility concerns). So it would be nice to change this for XLA before we lock in this behavior."
5522,Extracting Bazel installation,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
After I run `./configure`, why it stagnate in the step of `Extracting Bazel installation...` ? 

### Environment info
Operating System:
`Linux k20-1 2.6.32-358.el6.x86_64 #1 SMP Fri Feb 22 00:31:26 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux`

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
cuda 7.5
cuDNN 5"
5521,Do not require execution of ./configure when changing branches,"It would be great to be able to recompile tensorflow without having to call `configure` after changing branches. Currently, I get the following error message:

```
RuntimeError: Run ./configure again, branch was 'refs/heads/master' but is now 'refs/heads/<my branch name>'
```

The main problem with running `configure` again is that a clean build is performed afterwards--which takes some time."
5519,Fine tune inception without TFRecords.,I wonder if I can fine-tune the inception model without using TFRecords format for my dataset in the inception_train script. I have a placeholder for images and a placeholder for labels and during training I feed them in sess.run(). I get low precision on a binary classification problem so I wonder if this approach is wrong. In stackoverflow noone answered. Thanks in advance!
5518,Op type not registered 'SqrtGrad',"I am unable to create the Tensorflow graph from an imported model on Android using JNI. When attempting to load the file with `tensorflow::Status s = session->Create(graph_def);`, I receive the error, `Not found: Op type not registered 'SqrtGrad'`.

I checked `jni-build/jni/include/tensorflow/python/ops/math_ops.py` and `SqrtGrad` does exist. As running the model on Python does not return this error, could this be a problem when I generated my protobuf file with `tf.train.write_graph(sess.graph_def, 'location', 'trained_model.pb', as_text=False)`?

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://github.com/tensorflow/tensorflow/issues/3619
https://github.com/tensorflow/tensorflow/issues/3533

### Environment info
Operating System:
Mac OS 10.12
Android Cyanogenmod 12
Tensorflow 0.10.0 on Jupyter

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
This section of code is from [TensorFlowAndroidMNIST](https://github.com/miyosuda/TensorFlowAndroidMNIST/tree/master/jni-build/jni)

[trained_model.pb.zip](https://github.com/tensorflow/tensorflow/files/583485/trained_model.pb.zip)
```
static std::unique_ptr<tensorflow::Session> session;

static bool g_compute_graph_initialized = false;
using namespace tensorflow;

JNIEXPORT jfloat JNICALL
TENSORFLOW_METHOD(init)(JNIEnv* env, jobject thiz, jobject java_asset_manager, jstring model) {

	const char* const model_cstr = env->GetStringUTFChars(model, NULL);

	tensorflow::SessionOptions options;
	tensorflow::ConfigProto& config = options.config;

	session.reset(tensorflow::NewSession(options));

	tensorflow::GraphDef graph_def;
	AAssetManager* const asset_manager = AAssetManager_fromJava(env, java_asset_manager);

	ReadFileToProto(asset_manager, model_cstr, &graph_def);
	tensorflow::Status s = session->Create(graph_def);

	if (!s.ok()) {
		LOG(ERROR) << ""Could not create Tensorflow Graph: "" << s;
		return -1;
	}
}
```

### What other attempted solutions have you tried?
I have tried adding `tensorflow/contrib/*`to `tf_op_files.txt` and `""//tensorflow/contrib/all_files""` to the tensorflow/BUILD file.
"
5517,Don't support avgpooling op on Windows ?,"## Environment info
Operating System: Windows 10, 64bit, Visual Studio 2015

## Issue
I try compile tensorflow label image sample on windows 10 64bit with Visual Studio 2015.
I got error 'AvgPool' op kernel not found message while loading tensorflow_inception_graph.pb graph.
I check tf_core_kernels.cmake and found follow line.

```
if(WIN32)
  file(GLOB_RECURSE tf_core_kernels_windows_exclude_srcs
      # not working on windows yet
      ""${tensorflow_source_dir}/tensorflow/core/kernels/depthwise_conv_op.cc""  # Cannot find symbol: tensorflow::LaunchConv2DOp<struct Eigen::ThreadPoolDevice, double>::launch(...).
      ""${tensorflow_source_dir}/tensorflow/core/kernels/fact_op.cc""
      ""${tensorflow_source_dir}/tensorflow/core/kernels/meta_support.*""
      ""${tensorflow_source_dir}/tensorflow/core/kernels/*quantiz*.h""
      ""${tensorflow_source_dir}/tensorflow/core/kernels/*quantiz*.cc""
      ""${tensorflow_source_dir}/tensorflow/core/kernels/svd*.cc""
      ""${tensorflow_source_dir}/tensorflow/core/kernels/avgpooling_op.*""
  )
  list(REMOVE_ITEM tf_core_kernels_srcs ${tf_core_kernels_windows_exclude_srcs})
endif(WIN32)
```

Is this mean don't support above ops on windows?
How can I running graph that using these ops?"
5516,TensorFlow is 1.3-7 times slower than Theano for small models,"I created a small benchmark (https://github.com/wjaskowski/tensorflow-vs-theano-benchmark) which shows that, depending on the model architecture, Tensorflow is 1.3-7 times slower than Theano depending on the model architecture. The question is whether this effect is due to a design decision or a performance bug, which may be solved in the future?

Related: https://github.com/fchollet/keras/issues/4287 , #5422"
5515,Supervisor should_stop not working in TF distributed,"Running TensorFlow 0.11.0rc2 and following the example (""Putting it all together: example trainer program""): https://www.tensorflow.org/versions/r0.11/how_tos/distributed/index.html

The workers does not get a should_stop() signal from the master.

Repro:

trainer.py: https://gist.github.com/hholst80/492cfeaad041db7580fa6ddf4480dce1
start: https://gist.github.com/hholst80/892ae7ed3d8db560647a03253c972de1"
5514,AttributeError: 'module' object has no attribute 'global_variables_initializer',"when I was trying a multi gpu training using `python cifar10_multi_gpu_train.py --num_gpus=2`, I got an error:
```
usr@linux:~/tensorflow_source/tensorflow/tensorflow/models/image/cifar10$ python cifar10_multi_gpu_train.py --num_gpus=2
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Traceback (most recent call last):
  File ""cifar10_multi_gpu_train.py"", line 280, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""cifar10_multi_gpu_train.py"", line 276, in main
    train()
  File ""cifar10_multi_gpu_train.py"", line 229, in train
    init = tf.global_variables_initializer()
AttributeError: 'module' object has no attribute 'global_variables_initializer'
```
Seemingly there's no `global_variables_initializer` of tf or in other module?
"
5513,Simplify Android integration,"The current process of building an Android app that uses TensorFlow is unwieldy at best. The only available documentation is baked into the sole example app, which itself is embedded in the TensorFlow build system. Having prebuilt, drop-in Android libraries (or even the ability to build these libraries from source) would, I believe, significantly simplify the process.

I added my own BUILD definitions to build libraries I can easily drop into an Android Studio project (having experience with blaze made this much more tractable):
```
# Inside //tensorflow/contrib/android/BUILD

# Build the JAR.
# Ends up in //my-app/libs/libandroid_tensorflow_inference_java.jar
android_library(
    name = ""android_tensorflow_inference_java"",
    srcs = ["":android_tensorflow_inference_java_srcs""],
)

# Build the SO.
# bazel build //tensorflow/contrib/android:libtensorflow.so \
#   --crosstool_top=//external:android/crosstool \
#   --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \
#   --cpu=armeabi-v7a
# Ends up in //my-app/src/main/jniLibs/armeabi-v7a/libtensorflow.so
LINKER_SCRIPT = ""//tensorflow/contrib/android:jni/version_script.lds""

cc_binary(
    name = ""libtensorflow.so"",
    srcs = [],
    copts = tf_copts(),
    linkopts = [
        ""-landroid"",
        ""-ljnigraphics"",
        ""-llog"",
        ""-lm"",
        ""-z defs"",
        ""-s"",
        ""-Wl,--version-script"",  # This line must be directly followed by LINKER_SCRIPT.
        LINKER_SCRIPT,
    ],
    linkshared = 1,
    linkstatic = 1,
    deps = [
        "":android_tensorflow_inference_jni"",
        ""//tensorflow/core:android_tensorflow_lib"",
        LINKER_SCRIPT,
    ],
)
```

Moreover, if the Android example could rely on these libraries and therefore exist as a ""standalone"" project buildable by Android Studio I think the barrier to entry for TensorFlow on Android would be materially lower."
5512,Re-entering an existing scope with variable_scope produces inconsistent results,"Consider the following example:

```python
with tf.variable_scope(name_or_scope='alpha'):
    with tf.variable_scope(name_or_scope='beta'):
        with tf.variable_scope(name_or_scope=tf.get_variable_scope()):
            a_var = tf.get_variable(shape=(42,), name='my_var') # An arbitrary var
            an_op = tf.reduce_sum(tf.zeros((42,)), name='my_op') # An arbitrary op

print('a_var is named {}'.format(a_var.name))
print('an_op is named {}'.format(an_op.name))
```

This produces the following output:

```
a_var is named alpha/beta/my_var:0
an_op is named alpha/beta/beta/my_op:0
```
Note that re-entering the existing scope appears to correctly name the variable, but introduces a redundant prefix for ops. Is this expected behavior, or a bug?

Tested on `0.11.0rc1`"
5511,Build a static library,"Is there a way to ask the build system bazel to build a static library that one can link a program written using the C++ API against? My apologies for this simple question, but I am very unfamiliar with this build system. I try to add some code to tensorflow/tensorflow/BUILD

```
cc_binary(
    name = ""libtensorflow_gpu.a"",
    linkstatic = 1,
    linkshared = 0,
    deps = [
        ""//tensorflow/c:c_api"",
        ""//tensorflow/core:tensorflow"",
    ],
)
```

but it failed, it will show these log


>ERROR: /gruntdata/jefby/alicpp/external/tensorflowserving/tensorflowserving-50129ec0b407e5778282ee8d7610a9494cfcf6b2/tensorflow/tensorflow/BUILD:209:1: Linking of rule '//tensorflow:libtensorflow_gpu.a' failed: gcc failed: error executing command /usr/bin/gcc -o bazel-out/local-opt/bin/tensorflow/libtensorflow_gpu.a -pthread -Wl,-no-as-needed -B/usr/bin -B/usr/bin -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/usr/lib/gcc/x86_64-unknown-linux-gnu/4.9.2/../../../../lib64/crt1.o: In function `_start':
(.text+0x20): undefined reference to `main'
collect2: error: ld returned 1 exit status
Target //tensorflow:libtensorflow_gpu.a failed to build



"
5507,nvcc warning: option '--relaxed-constexpr' has been deprecated,"# Description

Build with CUDNn 5, CUDA 8.0, tensorflow 0.11.0 rc1.

```
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```

Get a lot ```Too many warnings: nvcc warning option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.```

![image](https://cloud.githubusercontent.com/assets/3538629/20159915/ae552718-a71e-11e6-9f94-043d7f382e17.png)

In the console, this happens a lot, any way to turn it off?"
5504,Android arm64-v8a (armv8) native libs build error,"Hello,

I am encountering an error trying to build Tensorflow for arm64-v8a. *All other architectures build successfully*.

Operating system: OS X 10.11
Tensorflow repo commit: v0.11.0rc2 (tagged release)

From the Tensorflow repository root directory, I run:

```
bazel build -c opt //tensorflow/examples/android:tensorflow_native_libs \
--crosstool_top=//external:android/crosstool \
--host_crosstool_top=@bazel_tools//tools/cpp:toolchain \
--verbose_failures \
--cpu=arm64-v8a
```

The error emitted is:

```ERROR: /Users/kevin/work/mobile-sdk/android/sdk/tensorflow/tensorflow/examples/android/BUILD:14:1: Linking of rule '//tensorflow/examples/android:libtensorflow_demo.so' failed: aarch64-linux-android-gcc failed: error executing command
  (cd /private/var/tmp/_bazel_kevin/47b9700ecb360f2f1d6606e4f92873e1/execroot/tensorflow && \
  exec env - \
  external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64/bin/aarch64-linux-android-gcc -shared -o bazel-out/aarch64-linux-android-4.9-gnu-libstdcpp-opt/bin/tensorflow/examples/android/libtensorflow_demo.so -Wl,-whole-archive bazel-out/aarch64-linux-android-4.9-gnu-libstdcpp-opt/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/imageutils_jni.o bazel-out/aarch64-linux-android-4.9-gnu-libstdcpp-opt/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/rgb2yuv.o bazel-out/aarch64-linux-android-4.9-gnu-libstdcpp-opt/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so/tensorflow/examples/android/jni/yuv2rgb.o bazel-out/aarch64-linux-android-4.9-gnu-libstdcpp-opt/bin/tensorflow/contrib/android/libandroid_tensorflow_inference_jni.lo bazel-out/aarch64-linux-android-4.9-gnu-libstdcpp-opt/bin/tensorflow/core/libandroid_tensorflow_lib.lo bazel-out/aarch64-linux-android-4.9-gnu-libstdcpp-opt/bin/tensorflow/core/kernels/libandroid_tensorflow_kernels.lo bazel-out/aarch64-linux-android-4.9-gnu-libstdcpp-opt/bin/tensorflow/core/libandroid_tensorflow_lib_lite.lo bazel-out/aarch64-linux-android-4.9-gnu-libstdcpp-opt/bin/tensorflow/core/libprotos_all_cc.a bazel-out/aarch64-linux-android-4.9-gnu-libstdcpp-opt/bin/external/protobuf/libprotobuf.a bazel-out/aarch64-linux-android-4.9-gnu-libstdcpp-opt/bin/external/protobuf/libprotobuf_lite.a -Wl,-no-whole-archive external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/arm64-v8a/libgnustl_static.a external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/arm64-v8a/libsupc++.a -landroid -ljnigraphics -llog -lm -z defs -s '-Wl,--icf=all' -Wl,--version-script tensorflow/contrib/android/jni/version_script.lds -lz -static-libgcc -no-canonical-prefixes '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64/bin/../lib/gcc/aarch64-linux-android/4.9.x/../../../../aarch64-linux-android/bin/ld: unrecognized option '--icf=all'
external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64/bin/../lib/gcc/aarch64-linux-android/4.9.x/../../../../aarch64-linux-android/bin/ld: use the --help option for usage information
```

As stated, I have built several other architectures successfully with this method (changing the `cpu` flag to `armeabi-v7a`, `x86`, `x86_64` all build successfully).

Thanks for any help! Let me know if I can provide any more info."
5501,ExtractImagePatches Gradient doesn't work if batch size is unknown,"See #3672 comment by @mohamedadaly
His fix is to add 
```
  batch_size = array_ops.shape(op.inputs[0])[0]
```
after this:
```
  batch_size, rows_in, cols_in, channels = [
    dim.value for dim in op.inputs[0].get_shape()
  ]
```
in `tensorflow/python/ops/array_grad.py`"
5500,tf.case unexpected behaviour with tf.placeholder in predicate ,"I am using a `tf.case` to distinguish between `N` different cases to return exactly one of `N` output tensors. Crucially, I am using a `tf.placeholder` in the predicates. The toy example below exemplifies my code:

```python
import tensorflow as tf

N = 6
length = tf.placeholder(dtype=tf.int32, shape={})

tensors =[tf.constant(i * 100) for i in range(N)]
default = lambda: tf.constant(-2)
predicates = [(tf.equal(length, tf.constant(i, dtype=tf.int32)), lambda: tensors[i]) for i in range(N)]

mycase = tf.case(predicates, default, exclusive=True)

with tf.Session() as session:
  session.run(tf.initialize_all_variables())

  for l in range(N):
    out = session.run(mycase, feed_dict = {length : l})
    print(""output %d\t(length = %d)"" % (out,l))
  ```
As output I would expect 
```
output 0	(length = 0)
output 100	(length = 1)
output 200	(length = 2)
output 300	(length = 3)
output 400	(length = 4)
output 500	(length = 5)
```
However, I get
```
output 500	(length = 0)
output 500	(length = 1)
output 500	(length = 2)
output 500	(length = 3)
output 500	(length = 4)
output 500	(length = 5)

```

Comparing a constant to a placeholder usually does not cause problems. Am I stretching something too far by emulating such dynamic behaviour using `case` plus `palceholder`?

 
Setup: Ubuntu 14.04, tensorflow 0.11.0rc2 from the provided tensorflow-0.11.0rc2-cp34-cp34m-linux_x86_64.whl


"
5498,Change HTTP source locations away from Sourceforge,"### Problem

There are a bunch of sources downloaded over HTTP during the build process that depend on Sourceforge (libjpeg, giflib, boost, etc.). Unfortunately, Sourceforge presents a download delay at download initiation time, often suffers timeouts, and the download speeds are really slow. This significantly impacts build times.

### Solution

The sources could migrate to a subproject under the TensorFlow Github org, or to another Github repo that could host them, or to a CDN. Whatever the solution may be, this could help prevent timeouts and significantly improve the build speeds.

Note: I could issue a PR but the question is what location for these sources the TensorFlow team would find acceptable as an alternative to SourceForge."
5496,tensorflow ./configure error  Unrecognized option: --action_env=PATH," ./configure 

Please specify the location of python. [Default is /usr/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] y
Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

Using python library path: /usr/local/lib/python2.7/dist-packages
Do you wish to build TensorFlow with OpenCL support? [y/N] n
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-8.0/
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 5.0.5
Please specify the location where cuDNN 5.0.5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-8.0/]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 3.5,6.1
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=115
INFO: Reading options for 'clean' from /home/fang/tensorflow/tools/bazel.rc:
  Inherited 'build' options: --force_python=py2 --host_force_python=py2 --python2_path=/usr/bin/python --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --define PYTHON_BIN_PATH=/usr/bin/python --spawn_strategy=standalone --genrule_strategy=standalone
**INFO: Reading options for 'clean' from /etc/bazel.bazelrc:
  Inherited 'build' options: --action_env=PATH --action_env=LD_LIBRARY_PATH --action_env=TMPDIR --test_env=PATH --test_env=LD_LIBRARY_PATH
Unrecognized option: --action_env=PATH**

Any clue what happened? Thanks.
"
5495,Modifying the convolution operation,"Hi,

I wanted to test a modification to the convolutional operation. Which files should I change in the source code to implement and test my modifications? I have seen some [low level .cc code](https://github.com/tensorflow/tensorflow/blob/754048a0453a04a761e112ae5d99c149eb9910dd/tensorflow/core/kernels/conv_grad_ops.cc) which seems to implement convolutions. However, I'm not sure about exactly which files I should modify to implement my modification. 

Also is there a cleaner way (as in, a high-level pythonic way) to  test modifications to the convolutional operation without losing out on the speed of Tensorflow?

Thanks! "
5493,TensorBoard giving all black events and distributions,"Each time after typing ""tensorboard --logdir=logs""
only ""Starting TensorBoard 29 on port 6006"" is shown
so I need to type ""http://0.0.0.0:6006"" myself.
Then the graph of neural network and histograms are well displayed, 
but events and distributions are all black, like this:

![capture d ecran 2016-11-09 a 11 59 42](https://cloud.githubusercontent.com/assets/18445114/20136246/08436326-a674-11e6-90d8-8d34c6a455ce.png)


Mac OS enivrement, python version 2.7.
I'm sure that the code is good because someone else runs it correctly on his Mac.
What should be the problem?
"
5492,"tf.assign does not update variable shape if tf.Variable(..., validate_shape=True) initially","Unless the variable is initially created with tf.Variable(..., validate_shape=False), updating a variable using `tf.assign(..., validate_shape=False)` does not update the variable shape. 

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None

### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: CUDA 8.0 and cuDNN 5.1
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

``` bash
$ ls -l /usr/local/cuda-8.0/lib64/libcud*
-rw-r--r-- 1 root root 558720 Sep 15 01:02 /usr/local/cuda-8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Sep 15 01:05 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root     19 Sep 15 01:05 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root 415432 Sep 15 01:02 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root 775162 Sep 15 01:02 /usr/local/cuda-8.0/lib64/libcudart_static.a
$ ls -l /usr/local/cudnn-5.1-cuda-8.0/lib64/
total 145608
lrwxrwxrwx 1 root root       13 Oct 28 10:07 libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Oct 28 10:07 libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 Oct 28 10:07 libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Oct 28 10:07 libcudnn_static.a
```

If installed from binary pip package, provide:

1. A link to the pip package you installed:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#pip-installation

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```bash
$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
0.11.0rc2
```

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

In the following script, if var is created with `validate_shape=True`, subsequent `tf.assign` operations don't update the shape (they remain as [1]), *but they do update the data*.

However, if the var is created with `validate_shape=False`, subsequent `tf.assign` operations do update both data and the shape,  setting the shape to [1], [10], and [20] respectively.

```python
import numpy as np
import tensorflow as tf

dtype = np.float64
shape = (10, )

ph = tf.placeholder(dtype=dtype)
var = tf.Variable(tf.ones(shape=(1,), dtype=dtype), validate_shape=True)
op = tf.assign(var, ph, validate_shape=False)

init_op = tf.initialize_all_variables()

with tf.Session() as S:
    S.run(init_op)
    print S.run(tf.shape(var)) # [1]
    print S.run(var)           # [1.]
    S.run(op, feed_dict={ph: np.ones(shape=(10,), dtype=dtype)})
    print S.run(tf.shape(var)) # [1], should be [10]
    print S.run(var)           # [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]

    S.run(op, feed_dict={ph: np.ones(shape=(20,), dtype=dtype)})
    print S.run(tf.shape(var)) # [1], should be [20]
    print S.run(var)           # [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.]
```

### What other attempted solutions have you tried?



### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5488,Tensoflow slim eval_image_classifier with TypeError Can not convert a dict_values into a Tensor or Operation.),"Iâm studying the tensoflow, and want to test the example of slim. When I command ./scripts/train_lenet_on_mnist.sh, The program run to eval_image_classifier give a Type Error, The Error information as follows:

I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Evaluating /tmp/lenet-model/model.ckpt-20002
INFO:tensorflow:Starting evaluation at 2016-11-09-02:55:57
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties:
name: Quadro K5000
major: 3 minor: 0 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 3.94GiB
Free memory: 3.61GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro K5000, pci bus id: 0000:03:00.0)
INFO:tensorflow:Executing eval ops
INFO:tensorflow:Executing eval_op 1/100
INFO:tensorflow:Error reported to Coordinator: <class 'TypeError'>, Fetch argument **dict_values([<tf.Tensor 'accuracy/update_op:0' shape=() dtype=float32>, <tf.Tensor 'recall_at_5/update_op:0' shape=() dtype=float32>]) has invalid type <class 'dict_values'>, must be a string or Tensor. (Can not convert a dict_values into a Tensor or Operation.)
Traceback (most recent call last):**
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 218, in __init__
    fetch, allow_tensor=True, allow_operation=True))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2455, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2547, in _as_graph_element_locked
    % (type(obj).__name__, types_str))
TypeError: Can not convert a dict_values into a Tensor or Operation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""eval_image_classifier.py"", line 191, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""eval_image_classifier.py"", line 187, in main
    variables_to_restore=variables_to_restore)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/evaluation.py"", line 359, in evaluate_once
    global_step=global_step)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/evaluation.py"", line 260, in evaluation
    sess.run(eval_op, eval_op_feed_dict)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 902, in _run
    fetch_handler = _FetchHandler(self._graph, fetches, feed_dict_string)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 358, in __init__
    self._fetch_mapper = _FetchMapper.for_fetch(fetches)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 189, in for_fetch
    return _ElementFetchMapper(fetches, contraction_fn)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 222, in __init__
    % (fetch, type(fetch), str(e)))
TypeError: Fetch argument dict_values([<tf.Tensor 'accuracy/update_op:0' shape=() dtype=float32>, <tf.Tensor 'recall_at_5/update_op:0' shape=() dtype=float32>]) has invalid type <class 'dict_values'>, must be a string or Tensor. (Can not convert a dict_values into a Tensor or Operation.)

I don't know what happened to the program, I didnot revised any code, just download the code package from github, and for datadownload and train, which give correct result.Is there any help me?  I am waiting online. Thanks
"
5487,Update Cmake minimum requirement to v3.5,"As it seems to have appeared an [issue with Cmake 3.3](https://github.com/tensorflow/tensorflow/issues/17#issuecomment-258649999) and the minimum known working Cmake version apparently is 3.5 [(see here)](https://github.com/tensorflow/tensorflow/pull/5071#issuecomment-255490169). Should the minimum requirement be updated on [CmakeLists](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/CMakeLists.txt#L2) to 3.5 and the [readme](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md#pre-requisites) for minimum 3.5 up to 3.6?
If those changes look relevant and are the ones to be made I could update them and submit a PR."
5485,Possible bug when instantiating multi RNN cell in PTB LSTM model,"Note sure whether this is a bug, since TensorFlow API is unclear on this. Would like someone more familiar with TensorFlow to investigate.

The possible bug is in file tensorflow/models/rnn/ptb/ptb_word_lm.py on line 115. The line reads:

cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * config.num_layers, state_is_tuple=True)

According to the API reference, the constructor for MultiRNNCell is:

tf.nn.rnn_cell.MultiRNNCell.__init__(cells, state_is_tuple=True)

where 

cells: list of RNNCells that will be composed in this order.

The following notation:

[lstm_cell] * config.num_layers 

will create a list of size config.num_layers, where each element in the list is a reference to the same object lstm_cell. This potentially means that if we modify one layer of ""cell"", we will also be modifying all the other layers. Is this what we want?"
5484,"""bazel build tensorflow/python/tools:freeze_graph"" error","When I try to build the freeze_graph tool, I see the following error:

```
ERROR: /home/xxxxxx/src/tensorflow/tensorflow/python/BUILD:1907:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow.so' failed: link_dynamic_library.sh failed: error executing command external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored /usr/bin/gcc -shared -o bazel-out/local-fastbuild/bin/tensorflow/python/_pywrap_tensorflow.so -Wl,--version-script ... (remaining 10 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
bazel-out/local-fastbuild/bin/tensorflow/core/libversion_lib.a(version_info.pic.o): In function `tf_git_version()':
version_info.cc:(.text+0x0): multiple definition of `tf_git_version()'
bazel-out/local-fastbuild/bin/tensorflow/core/libframework_internal.lo(version_info.pic.o):version_info.cc:(.text+0x0): first defined here
bazel-out/local-fastbuild/bin/tensorflow/core/libversion_lib.a(version_info.pic.o): In function `tf_compiler_version()':
version_info.cc:(.text+0xd): multiple definition of `tf_compiler_version()'
bazel-out/local-fastbuild/bin/tensorflow/core/libframework_internal.lo(version_info.pic.o):version_info.cc:(.text+0xd): first defined here
collect2: error: ld returned 1 exit status
Target //tensorflow/python/tools:freeze_graph failed to build
```

Any thoughts how to resolve? I thought maybe I cloned the repo at a bad time, so I fetched the latest HEAD, and it solved my issue for one build, but all subsequent builds have failed.

```
$ bazel version
Build label: 0.4.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 17:54:14 2016 (1478109254)
Build timestamp: 1478109254
Build timestamp as int: 1478109254
```"
5483,"tf.contrib.learn Quickstart tutorial code doesn't run, no attribute 'load_csv'","I am trying to run the sample code in the tutorial here (I named the source file 'tf_iris.py'):
https://www.tensorflow.org/versions/r0.11/tutorials/tflearn/index.html#tf-contrib-learn-quickstart

It gives the following error:

```
  File ""tf_iris.py"", line 13, in <module>
    training_set = tf.contrib.learn.datasets.base.load_csv(filename=IRIS_TRAINING,
AttributeError: 'module' object has no attribute 'load_csv'
```

I installed TF on OS X using virtualenv, following instructions here:
https://www.tensorflow.org/versions/master/get_started/os_setup.html#virtualenv-installation

The version of TF installed is OS X / Python 2.7 / CPU, i.e.:
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0rc1-py2-none-any.whl
"
5482,TensorFlow crashing on IBM POWER; request debug advice,"We're seeing various crashes while running TensorFlow on IBM POWER systems with Ubuntu 16.04. We'd welcome any debugging advice or comments, especially about debug features or about reducing the size/complexity of TF to simplify debug.

Problem isolation information:

- Occurs with any of TF 0.9, 0.10, and recent master (e.g. 2cbb9b52 of Oct 26th)

- Occurs while training inception model on ILSVRC 2012 dataset. Model is from: https://github.com/tensorflow/models.git  inception/

- Independent of CUDA / GPU; occurs even if we compile with:
    TF_NEED_CUDA=0
    TF_NEED_GCP=0
    TF_NEED_HDFS=0

- Occurs after varying run times. Appears to occur sooner with higher thread counts. Very possibly a race of some sort.

- Does not occur with Ubuntu 15.10's GLIBC 2.21 (or earlier) but does occur with Ubuntu 16.04's GLIBC 2.23 (or later). So appears to be a problem in (or at least exposed by) GLIBC 2.22 or 2.23.

- TF runs (mostly) clean under valgrind --tool=memcheck. (There are some complaints about bad behavior by python at startup, but then silence. We see similar complaints running other python apps.)


To try to simplify analysis, we're:

- Building without CUDA, GCP, HDFS support

- Limiting threading by forcing tensorflow/core/platform/posix/port.cc NumSchedulableCPUs() to return a small value

- Forcing gcc to perform extra stack checking (updating tf_copts in tensorflow/tensorflow.bzl to include ""-fstack-protector-all"")


Nature of the crash:

The crash is usually a segfault, and often because a pointer was damaged while it was sitting on the stack.

The damage is quite consistent. Under linux on POWER, pointers to stack and heap will generally have the form 0x00003nnn nnnnnnnn. The damage always seems to be that the high half-word is changed from 0x0000 to 0x0001 (so looks like a short/half is set or incremented).

Occasionally the damaged pointer started life as NULL, and so we end up with a dereference of 0x0001000000000000.

In one case the pointer that was damaged was the stack pointer (r1), which would not normally be itself stored and retrieved from the stack. So maybe in that damage occurred:
a) while the thread was inactive and r1 sitting in a context save area,
b) in some odd case where r1 was saved on the stack, e.g. setjmp() / longjmp().

That suggests the crashing thread may not be the thread that's causing the damage.

I didn't find any obvious matches on stackoverflow (no crash reports with ""stack smashing"" or ""power""). I did see (unresolved) issue #3174 from July, but can't be sure that's related."
5481,How to output .pb file directly instead of .ckpt checkpoint files during training,"Now during training session, the output files are all .ckpt  which are very large. Is there any api can output .pb file directly during training. In fact, .ckpt file is not so useful for us, we only care about the final output."
5480,Creating TensorFlow device issue and perfromance drop,"Now I have 4 GeForce GTX TITAN X on my server. I want to run 4 tensor flow app independently on different GPU. I use the following code to assign GPU for different app, such as the 1st app use gpu:0 and 2nd app use gpu:1.

**tf.device('/gpu:0')**

However, whenever i run any app individually or all apps at same time, each app CMD window still outputs as below. Each creates 4 devices no matter other one(s) use these device or not.

After starting 3 apps, which are assigned the first 3 GPU (0,1,2) for each of them, then i start the 4th app for GPU:3, which is the 4th GPU, the app has dramatic performance drop.

Now i am using **Ubuntu 16.04, cuda 8 + cuDNN 5.1.** I do not know why this happen. I am not clear about if each app could run separately on different GPU on the same machine. 



**I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:0a:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)**
"
5479,theano.clone feature,"Are there some plans to do extension like a **theano.clone** ?

[Description from a original API:](http://deeplearning.net/software/theano/library/#theano.clone)

`theano.clone(output, replace=None, strict=True, share_inputs=True)`

Function that allows replacing subgraphs of a computational graph.
It returns a copy of the initial subgraph with the corresponding substitutions.

**Parameters:**

- **output** (Theano Variables (or Theano expressions)) â Theano expression that represents the computational graph.

- **replace** (dict) â Dictionary describing which subgraphs should be replaced by what.

- **share_inputs** (bool) â If True, use the same inputs (and shared variables) as the original graph. If False, clone them. Note that cloned shared variables still use the same underlying storage, so they will always have the same value.

It would be great if we can do similar things in **tensorflow** with easy.
"
5478,ImportError: No module named tensorflow - Can't install Tensorflow,"I am trying to install tensorflow on mac and it's giving me this error.

ImportError: No module named tensorflow

Here is what I have done in the terminal

`sudo easy_install pip 

sudo easy_install --upgrade six
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0-py3-none-any.whl
sudo -H pip3 install --upgrade $TF_BINARY_URL`


After that I try to run python and tensorflow to check my installation. It doesn't work. I have spent 3 hours on the problem.

Here is another post about it. http://stackoverflow.com/questions/40472144/importerror-no-module-named-tensorflow-cant-install-tensorflow?noredirect=1#comment68200554_40472144"
5477,Deal with _control_flow_context when copying op,"In the current implementation of copying ops (both `tf.contrib.copy_graph` and `tf.contrib.graph_editor`)
The code of copying an op looks like this
```python
# copy inputs
inputs_ = copy_func(op.inputs)
# copy control_inputs
control_inputs_ = copy_func(control_inputs)
# copy _node_def, _op_def
node_def_ = deepcopy(op._node_def)
op_def_ = deepcopy(op._op_def)
output_types_ = op._output_types[:]
input_types_ = op._input_types[:]
# copy name
name_ = copy_func(op.name)
# init the new op with above copies
new_op = tf_ops.Operation(node_def_, ...)
# ... copy shape and add to graph
```
But the `op._control_flow_context` is not copied at all. This causes problems when trying to compute gradients on a copied subgraph with control flow op like `tf.cond`. The error looks like
```python
    grads = optimizer.compute_gradients(-lower_bound)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 253, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py"", line 461, in gradients
    out_grads[i] = control_flow_ops.ZerosLikeOutsideLoop(op, i)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1310, in ZerosLikeOutsideLoop
    pred = op_ctxt.pred
AttributeError: 'NoneType' object has no attribute 'pred'
```
This is because the function `ZerosLikeOutsideLoop` uses `_control_flow_context` when the op is `tf.switch`
```
def ZerosLikeOutsideLoop(op, index):
  """"""Create zeros_like for the specified output of an op.""""""
  val = op.outputs[index]
  if not IsSwitch(op):
    return array_ops.zeros_like(val, optimize=False)
  else:
    op_ctxt = op._get_control_flow_context()
    pred = op_ctxt.pred
    branch = op_ctxt.branch
    switch_val = switch(op.inputs[0], pred)[1 - branch]
    zeros_shape = array_ops.shape_internal(switch_val, optimize=False)
    return array_ops.zeros(zeros_shape, dtype=val.dtype)
```
I tried setting `new_op. _control_flow_context` as `op._control_flow_context`
Now the error step passed. But I'm not sure whether this is right for dealing with _control_flow_context copy. Do you have some advice?"
5476,CUDNN_STATUS_BAD_PARAM in version 0.11.0rc1,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

Following steps i did:
1. Install tensorflow
2. Execute the source example to make sure everything is fine
3. Run srcnn.py in  https://github.com/liliumao/Tensorflow-srcnn/blob/master/srcnn.py

Then I encounter the error message
F tensorflow/stream_executor/cuda/cuda_dnn.cc:444] could not set cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM

What is more strange is that the program did trained 160 times and then show the error message.
And it only happens after iteration 160 times.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
#2033 #1787

### Environment info
Operating System : CentOS 7.2.1511+ tensorflow 0.11.0rc1

Installed version of CUDA and cuDNN: CUDA 8.0 & cuDNN 5.1
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11.0rc1

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
https://github.com/liliumao/Tensorflow-srcnn/blob/master/srcnn.py

### What other attempted solutions have you tried?
1. Transfer the cuda version to 7.5, however the tf.0.11.0rc1 needs cuda 8.0.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties:
name: GeForce GTX 980
major: 5 minor: 2 memoryClockRate (GHz) 1.3925
pciBusID 0000:03:00.0
Total memory: 3.94GiB
Free memory: 3.82GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:03:00.0)
2016-11-08 06:08:00.274964: step 0, duration = 0.457
2016-11-08 06:08:00.705598: step 10, duration = 0.020
2016-11-08 06:08:01.106745: step 20, duration = 0.019
2016-11-08 06:08:01.492362: step 30, duration = 0.019
2016-11-08 06:08:01.849530: step 40, duration = 0.018
2016-11-08 06:08:02.245288: step 50, duration = 0.019
2016-11-08 06:08:02.629120: step 60, duration = 0.019
2016-11-08 06:08:02.979037: step 70, duration = 0.018
2016-11-08 06:08:03.341024: step 80, duration = 0.018
2016-11-08 06:08:03.706578: step 90, duration = 0.019
2016-11-08 06:08:04.098436: step 100, duration = 0.019
2016-11-08 06:08:04.476913: step 110, duration = 0.019
2016-11-08 06:08:04.895861: step 120, duration = 0.019
2016-11-08 06:08:05.262154: step 130, duration = 0.019
2016-11-08 06:08:05.670712: step 140, duration = 0.019
2016-11-08 06:08:06.018086: step 150, duration = 0.018
2016-11-08 06:08:06.387210: step 160, duration = 0.018
F tensorflow/stream_executor/cuda/cuda_dnn.cc:444] could not set cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM
[1]    3640 abort (core dumped)  python3 srcnn.py


"
5473,modprobe: ERROR: ../libkmod/libkmod-module.c:832 kmod_module_insert_module() could not find module by name='nvidia_367_uvm',"here is the details:
modprobe: ERROR: ../libkmod/libkmod-module.c:832 kmod_module_insert_module() could not find module by name='nvidia_367_uvm'
modprobe: ERROR: could not insert 'nvidia_367_uvm': Unknown symbol in module, or unknown parameter (see dmesg)
E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_UNKNOWN
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:140] kernel driver does not appear to be running on this host (gzhao-b1208): /proc/driver/nvidia/version does not exist
I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.

it worked fine yesterday."
5470,Cannot import graph_def for 8-bit Quantized cnn model,"Following steps I did:
1. Train a CNN model on MNIST using tensorflow tutorials(Deep MNIST for Experts)(CONV+CONV+FC). Saved this model as binary protobuf(.pb).
2. Using 8-bit Quantization api, converted previously saved model to 8-bit model as binary proto(.pb). 
3. Read 8-bit binary-proto to tensorflow, by first creating graph_def and importing graph def to tf.Session()
```python
with sess.as_default() :
   with tf.Graph().as_default():
       graph_def = tf.GraphDef()
             with open(input_file_name, 'rb') as f:
                 proto_b = f.read()
                 graph_def.ParseFromString(proto_b)	
                 _ = tf.import_graph_def(graph_def, name="""")
``` 

However, this gives error on tf.import_graph_def as
`ValueError: graph_def is invalid at node u'concat_eightbit_reshape_concat/values_0': Input tensor 'concat/values_0:0' Cannot convert a tensor of type int32 to an input of type float32.`

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?


### Environment info
Operating System: Ubuntu 16.04 + tensorflow 0.11.0rc2

Installed version of CUDA and cuDNN: No


If installed from binary pip package, provide:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0rc2-cp27-none-linux_x86_64.whl





### What other attempted solutions have you tried?
1. I am able to correctly import quantized graph def for pre-trained inception model(.pb).
2. When I define Multi-layer perceptron model for MNIST, it can import quantized graph_def. 
3. All the quantization headers are imported correctly as
``` python
from tensorflow.contrib.quantization import load_quantized_ops_so
from tensorflow.contrib.quantization.kernels import load_quantized_kernels_so
load_quantized_ops_so.Load()
load_quantized_kernels_so.Load()
``` 

"
5468,Any plans for TF to support FP16&INT8?,"nVidia releases P100, P4, and P40 GPUs, and it also releases TensorRT for inference to support FP16 and INT8. Any plans for TensorFlow?"
5465,Exploration of cmake on Ubuntu: /tensorflow/stream_executor/gcuda.h,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

### Environment info
Operating System: Ubuntu14.04

Installed version of CUDA and cuDNN: 8.0/5.1.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
f870373756f8017cf89c7a6e3889539aba834265 

I'm exploring TensorFlow build with cmake on Ubuntu14.04

While trying building, I'm stuck with the following error.

It seems to me ..
1. device_functions.h header is not included? 
2. add/remove definitions such as -D__NVCC__? 
3. tf_stream_executor.cmake file looks incomplete. what do I need to add to the file? 

```
> In file included from /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.cc:16:0:
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:234:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ clock_t __gcuda_nvcc_clock() { return clock(); }
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:235:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ int __gcuda_nvcc__clz(int x) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:238:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ int __gcuda_nvcc__clzll(long long int x) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:241:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ float __gcuda_nvcc__fdividef(float a, float b) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:244:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ int __gcuda_nvcc__ffsll(long long int x) { // NOLINT
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:247:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ int __gcuda_nvcc__popc(unsigned int x) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:250:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ float __gcuda_nvcc__powf(float a, float b) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:253:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ void __gcuda_nvcc__sincosf(
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:257:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ unsigned int __gcuda_nvcc__umulhi(
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:263:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ unsigned int __gcuda_nvcc__ballot(int x) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:274:9: error: â::absâ has not been declared
>  using ::abs;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:275:9: error: â::atomicAddâ has not been declared
>  using ::atomicAdd;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:276:9: error: â::atomicCASâ has not been declared
>  using ::atomicCAS;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:277:9: error: â::ceilâ has not been declared
>  using ::ceil;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:278:9: error: â::ceilfâ has not been declared
>  using ::ceilf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:279:9: error: â::cosâ has not been declared
>  using ::cos;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:280:9: error: â::cosfâ has not been declared
>  using ::cosf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:281:9: error: â::erfcinvâ has not been declared
>  using ::erfcinv;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:282:9: error: â::erfcinvfâ has not been declared
>  using ::erfcinvf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:283:9: error: â::expâ has not been declared
>  using ::exp;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:284:9: error: â::expfâ has not been declared
>  using ::expf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:285:9: error: â::fabsâ has not been declared
>  using ::fabs;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:286:9: error: â::fabsfâ has not been declared
>  using ::fabsf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:287:9: error: â::floorâ has not been declared
>  using ::floor;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:288:9: error: â::floorfâ has not been declared
>  using ::floorf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:289:9: error: â::fabsâ has not been declared
>  using ::fabs;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:290:9: error: â::fabsfâ has not been declared
>  using ::fabsf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:291:9: error: â::fmaâ has not been declared
>  using ::fma;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:292:9: error: â::fmafâ has not been declared
>  using ::fmaf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:293:9: error: â::fmaxâ has not been declared
>  using ::fmax;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:294:9: error: â::fmaxfâ has not been declared
>  using ::fmaxf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:295:9: error: â::fminâ has not been declared
>  using ::fmin;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:296:9: error: â::fminfâ has not been declared
>  using ::fminf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:297:9: error: â::logâ has not been declared
>  using ::log;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:298:9: error: â::log1pâ has not been declared
>  using ::log1p;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:299:9: error: â::log1pfâ has not been declared
>  using ::log1pf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:300:9: error: â::logfâ has not been declared
>  using ::logf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:301:9: error: â::maxâ has not been declared
>  using ::max;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:302:9: error: â::minâ has not been declared
>  using ::min;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:303:9: error: â::powfâ has not been declared
>  using ::powf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:305:9: error: â::sinâ has not been declared
>  using ::sin;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:306:9: error: â::sinfâ has not been declared
>  using ::sinf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:307:9: error: â::sincosâ has not been declared
>  using ::sincos;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:308:9: error: â::sincosfâ has not been declared
>  using ::sincosf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:309:9: error: â::sincospiâ has not been declared
>  using ::sincospi;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:310:9: error: â::sincospifâ has not been declared
>  using ::sincospif;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:311:9: error: â::sqrtâ has not been declared
>  using ::sqrt;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:312:9: error: â::sqrtfâ has not been declared
>  using ::sqrtf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:313:9: error: â::tanhâ has not been declared
>  using ::tanh;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:314:9: error: â::truncâ has not been declared
>  using ::trunc;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:315:9: error: â::truncfâ has not been declared
>  using ::truncf;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:316:9: error: â::truncâ has not been declared
>  using ::trunc;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:326:1: error: â__forceinline__â does not name a type
>  __forceinline__ __host__ __device__ float rsqrtf(float x) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:329:1: error: â__forceinline__â does not name a type
>  __forceinline__ __host__ __device__ double rsqrt(double x) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:334:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ int clock() { return __gcuda_nvcc_clock(); }
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:336:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ int __clz(int x) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:340:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ int __clz(long long int x) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:344:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ float __fdividef(float a, float b) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:348:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ int __ffsll(long long int x) { // NOLINT
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:352:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ int __popc(unsigned int x) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:356:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ float __powf(float a, float b) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:360:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ void __sincosf(float x, float *sptr, float *cptr) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:364:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ unsigned int __umulhi(unsigned int x,
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:378:1: error: â__forceinline__â does not name a type
>  __forceinline__ __device__ unsigned int __ballot(int x) {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:384:9: error: â::__shflâ has not been declared
>  using ::__shfl;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:385:9: error: â::__shfl_downâ has not been declared
>  using ::__shfl_down;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:386:9: error: â::__shfl_upâ has not been declared
>  using ::__shfl_up;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:387:9: error: â::__shfl_xorâ has not been declared
>  using ::__shfl_xor;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:391:9: error: â::__ldgâ has not been declared
>  using ::__ldg;
>          ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:402:8: error: â__device__â does not name a type
>  inline __device__ int isfinite(float x) {
>         ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:405:8: error: â__device__â does not name a type
>  inline __device__ int isfinite(double x) {
>         ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.h:408:8: error: â__device__â does not name a type
>  inline __device__ int isfinite(long double x) {
>         ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.cc:23:1: error: âmapâ in namespace âstdâ does not name a type
>  std::map<void *, KernelCacheConfig> &GetGcudaccStubToCacheConfigMap() {
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.cc:29:5: error: âStreamExecutorâ was not declared in this scope
>      StreamExecutor *stream_exec) {
>      ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.cc:29:21: error: âstream_execâ was not declared in this scope
>      StreamExecutor *stream_exec) {
>                      ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.cc:29:34: error: expected â,â or â;â before â{â token
>      StreamExecutor *stream_exec) {
>                                   ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.cc:102:1: error: expected â}â at end of input
>  }  // namespace perftools
>  ^
> /home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.cc:102:1: error: expected â}â at end of input
> make[2]: *** [CMakeFiles/tf_stream_executor.dir/home/ubuntu/workspace/tensorflow/tensorflow/stream_executor/gcuda.cc.o] Error 1
> make[1]: *** [CMakeFiles/tf_stream_executor.dir/all] Error 2
> make: *** [all] Error 2
```"
5464,Can't find input_layer after freezing graph for Cifar10 model (it uses shuffle queue),"I've run [cifar10_train.py]( https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_train.py
) example for some time and saved graph and checkpoint files. After that I used freeze_graph.py from python/tools and it worked fine, no errors. Later I've built [label_image](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image) example, it worked fine with it's predefined values, but when I tried to use frozen graph and provided different flags, it failed because I couldn't find proper --input_layer value. I've tried many different values but nothing worked.

I've tried most of operations as --input_layer in this code snippet from Cifar10 example but none worked for me:

```
def read_cifar10(filename_queue):
  """"""Reads and parses examples from CIFAR10 data files.

  Recommendation: if you want N-way read parallelism, call this function
  N times.  This will give you N independent Readers reading different
  files & positions within those files, which will give better mixing of
  examples.

  Args:
    filename_queue: A queue of strings with the filenames to read from.

  Returns:
    An object representing a single example, with the following fields:
      height: number of rows in the result (32)
      width: number of columns in the result (32)
      depth: number of color channels in the result (3)
      key: a scalar string Tensor describing the filename & record number
        for this example.
      label: an int32 Tensor with the label in the range 0..9.
      uint8image: a [height, width, depth] uint8 Tensor with the image data
  """"""

  class CIFAR10Record(object):
    pass
  result = CIFAR10Record()

  # Dimensions of the images in the CIFAR-10 dataset.
  # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the
  # input format.
  label_bytes = 1  # 2 for CIFAR-100
  result.height = 32
  result.width = 32
  result.depth = 3
  image_bytes = result.height * result.width * result.depth
  # Every record consists of a label followed by the image, with a
  # fixed number of bytes for each.
  record_bytes = label_bytes + image_bytes

  # Read a record, getting filenames from the filename_queue.  No
  # header or footer in the CIFAR-10 format, so we leave header_bytes
  # and footer_bytes at their default of 0.
  reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)
  result.key, value = reader.read(filename_queue)

  # Convert from a string to a vector of uint8 that is record_bytes long.
  record_bytes = tf.decode_raw(value, tf.uint8, name=""input_layer_node"")

  # The first bytes represent the label, which we convert from uint8->int32.
  result.label = tf.cast(
      tf.slice(record_bytes, [0], [label_bytes]), tf.int32)

  # The remaining bytes after the label represent the image, which we reshape
  # from [depth * height * width] to [depth, height, width].
  depth_major = tf.reshape(tf.slice(record_bytes, [label_bytes], [image_bytes]),
                           [result.depth, result.height, result.width])
  # Convert from [depth, height, width] to [height, width, depth].
  result.uint8image = tf.transpose(depth_major, [1, 2, 0])

  return result
```

Anyone had success with this one?

>### Environment info
>Operating System: Ubuntu 14.04
>CUDA: 8.0
>cuDNN: 5.0
>tf.__version__
'0.11.0rc2'

"
5462,"dist_test local k8s cluster setup is broken, use kubernetes/minikube","**Feature Request/Documentation Request**

local k8s cluster dist_test broken, use [kubernetes/minikube](https://github.com/kubernetes/minikube) instead


As of commit 21a7ae05e04f4f060938db08015cb47896970dd1, the dockerfile for setting up a local cluster for dist_test is broken.  This dockerfile imports start_local_k8s_service.sh and other scripts that were deleted with this merge.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/local/Dockerfile#L18
```
$ docker build .
...
Step 9 : ADD start_local_k8s_cluster.sh /var/k8s/start_local_k8s_cluster.sh
lstat start_local_k8s_cluster.sh: no such file or directory
...
```

Instead of this dockerfile, this local cluster setup should be switched over to Minikube, the officially supported method for non-k8s-development local clusters.

http://kubernetes.io/docs/getting-started-guides/minikube/

As a maintainer for minikube, I would happily create a PR with instructions and a tutorial on how to run dist_test locally.  If this sounds good to you, please assign this issue to me.      
"
5460,reduce_sum extremely slow on gpu for complex dtypes,"## Description
`tf.reduce_sum` takes an order of magnitude longer to compute when the tensor is a complex dtype and the computation takes place on a gpu. I've tried to investigate the source of the problem and it's not clear to me whether this is a Tensorflow issue or an Eigen issue, but I thought I'd raise it here first.

## Environment
Ubuntu 16.04 LTS
Tensorflow: 1fcd6d1294564066c6f92b121a3aaf4ed186dc1a
GPU: Titan X
Python 2.7.11

## Diagnostics/Reproducibility:
I produced a tensorflow timeline trace. The trace shows that reductions for a real and complex tensor on the cpu, and for a real tensor on the gpu, takes no longer than 1.3 ms. The reduction of a complex tensor of the same size takes about 196 ms on the gpu.  In particular this time is spent in a dedicated GPU stream, where the input arguments are marked as undefined in the trace.

More specifically, here's a table summarizing the relevant parts of the trace:

### CPU, Complex Reduction
Start | Wall Duration (ms) | Self time (ms) | Arg: input0 | Arg: input1 | Arg: name | Arg: op
-----|--------------------|---------------|------------|------------|------------|--------
0.076 ms | 1.174 ms | 1.174 ms | ""cplx_var/read"" | ""cplx_reduction/range"" | ""cplx_reduction/Sum"" | ""Sum""

### GPU, Real Reduction
Start | Wall Duration (ms) | Self time (ms) | Arg: input0 | Arg: input1 | Arg: name | Arg: op
-----|--------------------|---------------|------------|------------|------------|--------
0.087 ms | 1.267 ms | 1.267 ms | ""real_var/read"" | ""real_reduction_1/range"" | ""real_reduction_1/Sum"" | ""Sum""
1.355 ms | 0.043 ms | 0.043 ms | undefined | undefined | ""real_reduction_1/Sum"" | ""Sum""

### CPU, Real Reduction
Start | Wall Duration (ms) | Self time (ms) | Arg: input0 | Arg: input1 | Arg: name | Arg: op
-----|--------------------|---------------|------------|------------|------------|--------
4.010 ms | 0.465 ms | 0.465 ms | ""real_var/read/_7"" | ""real_reduction/range"" | ""real_reduction/Sum"" | ""Sum""

### GPU, Complex Reduction (Slow)
Start | Wall Duration (ms) | Self time (ms) | Arg: input0 | Arg: input1 | Arg: name | Arg: op
-----|--------------------|---------------|------------|------------|------------|--------
4.019 ms | 0.070 ms | 0.070 ms | ""cplx_var/read/_5"" | ""cplx_reduction_1/range"" | ""cplx_reduction_1/Sum"" | ""Sum""
4.078 ms | 195.994 ms | 195.994 ms | undefined | undefined | ""cplx_reduction_1/Sum"" | ""Sum""

The trace and a screenshot are attached as a text file and pdf file, respectively. The code that generated the trace is provided below:

```python
import tensorflow as tf
import numpy as np
from tensorflow.python.client import timeline

def reduction_tester(real_var, cplx_var):
    with tf.name_scope('real_reduction'):
        reduced_real = tf.reduce_sum(real_var)
    with tf.name_scope('cplx_reduction'):
        reduced_cplx = tf.reduce_sum(cplx_var)
    return reduced_real, reduced_cplx

def main():
    R_DTYPE = np.float32
    C_DTYPE = np.complex64
    r = np.random.randn(1000, 2000).astype(R_DTYPE)
    i = np.random.randn(1000, 2000).astype(R_DTYPE)
    real_var = tf.get_variable('real_var', initializer=r,
                               dtype=tf.as_dtype(R_DTYPE))
    cplx_var = tf.get_variable('cplx_var', initializer=r+1j*i,
                               dtype=tf.as_dtype(C_DTYPE))

    with tf.device('/cpu'):
        real_reduc_cpu, cplx_reduc_cpu = reduction_tester(real_var, cplx_var)

    with tf.device('/gpu'):
        real_reduc_gpu, cplx_reduc_gpu = reduction_tester(real_var, cplx_var)

    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True,
                                            allow_soft_placement=False))
    init = tf.initialize_all_variables()
    sess.run(init)

    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
    run_metadata = tf.RunMetadata()
    ops = [real_reduc_cpu, cplx_reduc_cpu, real_reduc_gpu, cplx_reduc_gpu]
    ret = sess.run(ops, options=run_options, run_metadata=run_metadata)

    real_np_sum = np.sum(r.astype(R_DTYPE))
    cplx_np_sum = np.sum((r+1j*i).astype(C_DTYPE))
    assert np.allclose(ret[0], real_np_sum, rtol=1e-4)
    assert np.allclose(ret[1], cplx_np_sum, rtol=1e-4)
    assert np.allclose(ret[2], real_np_sum, rtol=1e-4)
    assert np.allclose(ret[3], cplx_np_sum, rtol=1e-4)

    tl = timeline.Timeline(run_metadata.step_stats)
    with open('/home/sarroff/tmp/timeline.trace', 'w') as f:
        f.write(tl.generate_chrome_trace_format(show_memory=True))

if __name__ == '__main__':
    main()
```

## Partial Workaround
It's easy to avoid placing explicit calls to `tf.reduce_sum` by flattening the tensor into a row and performing a matrix multiply with a tensor column of 1s. The performance on complex tensors using the gpu is reasonable using this approach. However Tensorflow uses reductions internally for many gradient computations and these are harder to avoid.

[timeline.trace.txt](https://github.com/tensorflow/tensorflow/files/576345/timeline.trace.txt)
[chrome_tracing.pdf](https://github.com/tensorflow/tensorflow/files/576234/chrome_tracing.pdf)
"
5458,Tensorflow on android: directly build app in python?,"The sample app given by google for tensorflow on android is written in C++.

I have a tensorflow application written in python. This application currently runs on desktop. I want to move the application to android platform. Can I use bazel to build the application that is written in python directly for android? Thanks."
5455,Unable to save the wide and deep model in a tensorflow session ,"I am running the wide and deep model in TensorFlow serving and to export the trained model I am using the piece of code

![image](https://cloud.githubusercontent.com/assets/17990840/20066180/b18823aa-a4de-11e6-9c88-455b0df31c91.png)
 But while using the command ` saver = tf.train.Saver()` the error ` ValueError: No variable to save is displayed`

![image](https://cloud.githubusercontent.com/assets/17990840/20066325/2b4db204-a4df-11e6-8572-5bc26bd63e55.png)

How can I save the model, so that a servable is created which is required while loading the exported model in tensorflow standard server? Any help is appreciated."
5453,tensorflow/core/util/event.proto: File not found while building with custom C++ project,"I'm building tensorflow inside a C++ project and link with it using bazel build script. I'm using the master version of tensorflow and here a the BUILD file 

```
cc_library(
    name = ""tf-net"",
    hdrs = [""model.h""],
    srcs = [
        ""model.cc"",
    ],
    linkopts = [""-lm""],
    deps = [
        ""@org_tensorflow//tensorflow/core:core_cpu"",
        ""@org_tensorflow//tensorflow/core:lib"",
        ""@org_tensorflow//tensorflow/core:tensorflow""
    ],
	visibility=[""//visibility:public""]
)
```

This worked for previous version of tensorflow but now I get 
```
tensorflow/core/util/event.proto: File not found.
tensorflow/core/debug/debug_service.proto: Import ""tensorflow/core/util/event.proto"" was not found or had errors.
tensorflow/core/debug/debug_service.proto:38:25: ""Event"" is not defined.
```

It seems that it tries to compile the proto file debug_service.proto but can't find the needed dependencies.
"
5452,Tensorflow for SegNet,"Hi 

I just would like to know are there any Tensorflow implementation for the SegNet, (https://arxiv.org/pdf/1511.00561.pdf)

Thanks,

NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5448,Tensorflow hangs when initializing variables in a multi process setting,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
Closest I found was https://github.com/tensorflow/tensorflow/issues/4767
But I don't intend to change the datatypes  of any variables...

### Environment info
Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: CUDA 7.5 and CUDNN 4.0.7
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root 189170 Aug 25 02:29 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Aug 25 02:29 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Aug 25 02:29 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Aug 25 02:29 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Aug 25 02:29 /usr/local/cuda/lib/libcudart_static.a

CUDNN libs are in /cuda/lib64/ (output of `ls -l /path/to/cuda/lib64/libcud*`):
-rw-r--r-- 1 root root   322936 Aug 25 02:29 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 25 02:29 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 25 02:29 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 25 02:29 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 25 02:29 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 61453024 Aug 25 02:36 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 61453024 Aug 25 02:36 /usr/local/cuda/lib64/libcudnn.so.4
-rwxr-xr-x 1 root root 61453024 Aug 25 02:36 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Aug 25 02:36 /usr/local/cuda/lib64/libcudnn_static.a

But **I have installed Tensorflow CPU only version in the virtualenv I am testing this code on**, hence it might not be using CUDA at all as far as this issue is concerned (I am debugging an issue that occurred on a EC2 machine which has no GPU, by reproducing it in my local system)
 
If installed from binary pip package, provide:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0rc2-cp27-none-linux_x86_64.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.0.11.0rc2

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I have saved a minimal working code which reproduces this issue at [gist](https://gist.github.com/ramnath-k/d299964fead58c0d1e0df9c2190a4f91)

To reproduce the issue:
1. Call saver.save in the main thread and checkpoint at least one tf.Variable
2. loading this checkpoint from main thread and evaluating the variable works fine
3. if I now launch a subprocess and try to load the checkpoint in that, Tensorflow hangs at sess.run(tf.initialize_all_variables())

### What other attempted solutions have you tried?
I tried putting a container with names suffixed by the subprocess pid but it didn't help. I also tried a basic version of create_local_server and it didn't work too

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
I don't see any errors in the console when the code hangs. "
5447,invalid conversion from 'cudnnDropoutStruct*' to 'int' [-fpermissive]     ,"Hi all,
I am trying to compile tensorflow-0.11 + bazel 0.3.2 on RHEL 6 with cuda 7.0 + cudnn 7.5.5.0 + gcc 4.9.
The compilation command is :
EXTRA_BAZEL_ARGS=""--jobs 10"" bazel build -c opt --config=cuda --jobs 10 //tensorflow/tools/pip_package:build_pip_package 

Compilation of rule '//tensorflow/stream_executor:stream_executor' fails with cuda specific message.

I have latest version of compilers at non standard path , hence i had modified some variables in CROSSTOOL.tpl + third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl. I am attaching **compilation error logs**, **CROSSTOOL.tpl** and **third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl** for your reference.


Though i am able to compile cpu-only version of tensorflow successfully. 
Please let me know if any information is needed from my side.
Eagerly awaiting your replies.


[crosstool_wrapper_driver_is_not_gcc.tpl.txt](https://github.com/tensorflow/tensorflow/files/575209/crosstool_wrapper_driver_is_not_gcc.tpl.txt)
[CROSSTOOL.tpl.txt](https://github.com/tensorflow/tensorflow/files/575211/CROSSTOOL.tpl.txt)
[tensorflow_build2.log.txt](https://github.com/tensorflow/tensorflow/files/575210/tensorflow_build2.log.txt)




"
5446,Bus error in quantized network on Android,"We have a tensorflow image processing network, which executes fine on osX, iOS and Android. Now that quantization has been pulled into core, we wanted to use it to optimize our install size on phones.

When we run the quantization process there are as expected small differences in the output on the Mac, but nothing that seems unreasonable. Further, when the quantized network is run on iOS it gives a warning that zero is outside the quantization range and it has to revert to a slow version to handle convolution padding. However it runs fine and the numbers are plausible.

On Android, however, and running with precisely the same code that worked perfectly with the unquantized version, it completely breaks. On one phone it gives outputs on the order of 1000 where we expect values on the order of 1. On another, probably the more reasonable, phone it just dies following a bus error. This has been true on the latest commits sampled over the last several days.

If it's relevant, the network was converted from a caffe predecessor using this tool: https://github.com/ethereon/caffe-tensorflow
Regrettably I'm unable to upload the source code or network in question."
5445,tf.gather doesn't run on GPU for DT_INT32,"As I know, `tf.gather` should be able to operate on a GPU device according to this issue: #2502

I installed the latest version of `r0.11` branch (commit hash written below) and ran the following code:
```python
    import tensorflow as tf
    x = tf.constant([1,2,3,4,5])
    idx = tf.constant([0,1,2,3,4])
    with tf.device('/gpu:0'):
        y = tf.gather(x, idx)
    sess = tf.Session()
    print(sess.run(y))
```

and it returned the following error message:

    tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'Gather': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
         [[Node: Gather = Gather[Tindices=DT_INT32, Tparams=DT_INT32, validate_indices=true, _device=""/device:GPU:0""](Const, Const_1)]]

If I change `'/gpu:0'` into `'/cpu:0'`, it works well. Can you give me any hint on this?

### Environment info
Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: CUDA 8.0 and cuDNN 5.1.5

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
7197421df430a51383fba7c4e7ff9a3fd7795535
2. The output of `bazel version`
Build label: 0.3.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jul 29 09:09:52 2016 (1469783392)
Build timestamp: 1469783392
Build timestamp as int: 1469783392"
5444,AttributeError:  module 'tensorflow.contrib.learn.python.learn.datasets.base' has no attribute 'load_csv',"I had install tensorflow in ubuntu with Anaconda install. I try to run neural network sample but get 
AttributeError:  module 'tensorflow.contrib.learn.python.learn.datasets.base' has no attribute 'load_csv' error.
Any clue?

Thanks,"
5443,"einsum with ellipses ""..."" (indefinite number of axes)","Thank you very much for providing the (numpy) einsum feature in tensorflow, that is really great. The documentation for einsum says to look at the numpy documentation as it provides the same api. It is not exactly the same, one difference is the possibility of using ""..."" in numpy which seems not to be implemented in tensorflow. This would definitely be a nice feature to have in tensorflow also since that way one could build various function/transformations in tensorflow which are not dependent on the number of axis the tensor has (i.e. the specific use case). 

Here is the error I encountered when trying to do that:
`d = tf.einsum(""i...,ij->j..."",c,b)`

> ---------------------------------------------------------------------------
> AssertionError                            Traceback (most recent call last)
> <ipython-input-12-d7c0123ec21a> in <module>()
> ----> 1 d = tf.einsum(""i...,ij->j..."",c,b)
> 
> //anaconda/envs/chaos/lib/python3.5/site-packages/tensorflow/python/ops/special_math_ops.py in einsum(axes, *inputs)
>     100   match = re.match('([a-z,]+)->([a-z]+)', axes)
>     101   assert match, \
> --> 102     ""Indices have incorrect format: %s"" % axes
>     103 
>     104   inputs = list(inputs)
> 
> AssertionError: Indices have incorrect format: i...,ij->j..."
5440,Load user defined op with relative path,"How to load a user defined op with relative path? It works fine with absolute path. But I want to do it using relative path.

**I used this command to build the op:** 
`bazel build -s --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" -c opt //tensorflow/core/user_ops:zero_out.so`

**The build file I used is:** 

```python
load(""//tensorflow:tensorflow.bzl"", ""tf_custom_op_library"")
tf_custom_op_library(
    name = ""zero_out.so"",
    srcs = [""zero_out.cc""],
)
```

**The output of the build command is :** 

```
INFO: Found 1 target...
>>>>> # //tensorflow/core/user_ops:zero_out.so [action 'Creating runfiles tree bazel-out/local-opt/bin/tensorflow/core/user_ops/zero_out.so.runfiles']
(cd /private/var/tmp/_bazel_sahilsingla/c1460bc7debae191fe6190e883a41a47/execroot/tensorflow && \
  exec env - \
    PATH=/Library/Frameworks/Python.framework/Versions/2.7/bin:/Library/Frameworks/Python.framework/Versions/2.7/bin:/Users/sahilsingla/Downloads/earthengine-api/demos/trendy-lights/google-cloud/google-cloud-sdk/bin:/opt/local/bin:/opt/local/sbin:/opt/local/bin:/opt/local/sbin:/Users/sahilsingla/torch/install/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/Users/sahilsingla/.local/bin:/opt/X11/bin:/Users/sahilsingla/torch/install/lib/luarocks/rocks:/usr/local/cuda/bin:/Users/sahilsingla/.local/bin:/usr/local/mysql/bin:/usr/local/sbin \
    TMPDIR=/var/folders/n6/kj5blsmn39qfzncks2_rt8pm0000gn/T/ \
  /private/var/tmp/_bazel_sahilsingla/c1460bc7debae191fe6190e883a41a47/execroot/tensorflow/_bin/build-runfiles bazel-out/local-opt/bin/tensorflow/core/user_ops/zero_out.so.runfiles_manifest bazel-out/local-opt/bin/tensorflow/core/user_ops/zero_out.so.runfiles)
>>>>> # //tensorflow/core/user_ops:zero_out.so [action 'Compiling tensorflow/core/user_ops/zero_out.cc']
(cd /private/var/tmp/_bazel_sahilsingla/c1460bc7debae191fe6190e883a41a47/execroot/tensorflow && \
  exec env - \
    PATH=/Library/Frameworks/Python.framework/Versions/2.7/bin:/Library/Frameworks/Python.framework/Versions/2.7/bin:/Users/sahilsingla/Downloads/earthengine-api/demos/trendy-lights/google-cloud/google-cloud-sdk/bin:/opt/local/bin:/opt/local/sbin:/opt/local/bin:/opt/local/sbin:/Users/sahilsingla/torch/install/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/Users/sahilsingla/.local/bin:/opt/X11/bin:/Users/sahilsingla/torch/install/lib/luarocks/rocks:/usr/local/cuda/bin:/Users/sahilsingla/.local/bin:/usr/local/mysql/bin:/usr/local/sbin \
    TMPDIR=/var/folders/n6/kj5blsmn39qfzncks2_rt8pm0000gn/T/ \
  external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-D_GLIBCXX_USE_CXX11_ABI=0' '-std=c++0x' -MD -MF bazel-out/local-opt/bin/tensorflow/core/user_ops/_objs/zero_out.so/tensorflow/core/user_ops/zero_out.pic.d '-frandom-seed=bazel-out/local-opt/bin/tensorflow/core/user_ops/_objs/zero_out.so/tensorflow/core/user_ops/zero_out.pic.o' -fPIC -DEIGEN_MPL2_ONLY -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/protobuf -iquote bazel-out/local-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -isystem external/protobuf/src -isystem bazel-out/local-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/local-opt/genfiles/external/eigen_archive -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/core/user_ops/zero_out.cc -o bazel-out/local-opt/bin/tensorflow/core/user_ops/_objs/zero_out.so/tensorflow/core/user_ops/zero_out.pic.o)
>>>>> # //tensorflow/core/user_ops:zero_out.so [action 'Linking tensorflow/core/user_ops/zero_out.so']
(cd /private/var/tmp/_bazel_sahilsingla/c1460bc7debae191fe6190e883a41a47/execroot/tensorflow && \
  exec env - \
  external/local_config_cc/cc_wrapper.sh -shared -o bazel-out/local-opt/bin/tensorflow/core/user_ops/zero_out.so -Wl,-all_load bazel-out/local-opt/bin/tensorflow/core/user_ops/_objs/zero_out.so/tensorflow/core/user_ops/zero_out.pic.o bazel-out/local-opt/bin/external/protobuf/libprotobuf.pic.a bazel-out/local-opt/bin/external/protobuf/libprotobuf_lite.pic.a '' -lpthread -lstdc++ -lm -undefined dynamic_lookup -headerpad_max_install_names)
Target //tensorflow/core/user_ops:zero_out.so up-to-date:
  bazel-bin/tensorflow/core/user_ops/zero_out.so
INFO: Elapsed time: 3.717s, Critical Path: 3.36s
```

**Pleas let me know if there is a way to make it work.**
"
5439,Fail to export model with exporter with distributed session,"Hi,

I met an issue as follow when I was trying to export the model with distributed session,

Do you have any idea about how to fix this issue. Thanks

Exporting trained model to./model/
Traceback (most recent call last):
  File ""dnn_train.py"", line 399, in <module>
    tf.app.run()
  File ""/gruntdata/DL_dataset/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 32, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""dnn_train.py"", line 396, in main
    run_training(server.target, cluster_spec)
  File ""dnn_train.py"", line 318, in run_training
    default_graph_signature=signature)
  File ""/gruntdata/DL_dataset/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/session_bundle/exporter.py"", line 198, in init
    ops.add_to_collection(constants.GRAPH_KEY, graph_any_buf)
  File ""/gruntdata/DL_dataset/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 4073, in add_to_collection
    get_default_graph().add_to_collection(name, value)
  File ""/gruntdata/DL_dataset/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2689, in add_to_collection
    self._check_not_finalized()
  File ""/gruntdata/DL_dataset/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2088, in _check_not_finalized
    raise RuntimeError(""Graph is finalized and cannot be modified."")
RuntimeError: Graph is finalized and cannot be modified.
"
5438,TensorBoard could not refresh automatically when use HDFS path as logdir?,"Environment
https://github.com/tensorflow/ecosystem/blob/master/docker/Dockerfile.hdfs

I use the following command to start a tensorflow job. It works well. However, the tensor board could not refresh automatically unless restart the tensor board server.

<pre><code>
python mnist.py --data_dir=hdfs://hdpalt/user/danrtsey.wy/mnist-data --train_dir=hdfs://hdpalt/user/danrtsey.wy/.slider/checkpoints/test1
</code></pre>
<pre><code>
tensorboard --logdir=hdfs://hdpalt/user/danrtsey.wy/.slider/checkpoints/test1
</code></pre>

BTW, i find the file size of event file on HDFS does not update. Although, the content has changed. Is this the reason?
<pre><code>
$hadoop fs -ls hdfs://hdpalt/user/danrtsey.wy/.slider/checkpoints/test1/events.out.tfevents.1478500140.8e103b0b7135
-rw-r--r--   3 yarn danrtsey.wy         40 2016-11-07 14:29 hdfs://hdpalt/user/danrtsey.wy/.slider/checkpoints/test1/events.out.tfevents.1478500140.8e103b0b7135
</code></pre>
<pre><code>
$hadoop fs -cat hdfs://hdpalt/user/danrtsey.wy/.slider/checkpoints/test1/events.out.tfevents.1478500140.8e103b0b7135 | wc -l
9312
</code></pre>"
5437,AlreadyExistsError: Resource _tensor_arrays,"I was trying to use a tf.while loop inside another tf.while loop . I cross checked many times , but I am getting this error . If somehow managed to get over this error , I am getting another error called nothing to read from index 0 of tensor array , as nothing has been written to it . If you guys want , I can post the full code . This code is based on the modification of code by @alrojo , from his wondeful tutorial . 



![issue1](https://cloud.githubusercontent.com/assets/10637096/20048372/1d95eeda-a4e2-11e6-8011-36fdfaf35f8c.png)
![issue2](https://cloud.githubusercontent.com/assets/10637096/20048373/1d96cf9e-a4e2-11e6-9c78-e8e8836767f9.png)

"
5436,How to know whether TF is using cudnn?,">>> import tensorflow as tf
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
>>> 

"
5435,User defined op without input + control dependencies causes op execution error,"1. Define a user-defined op without input, with 1 output:
REGISTER_OP(""MyOp"")
  .Output(""output: T"")
  .Attr(.....)

2. in python code:
op1 = my_op(attrs)

with tf.control_dependencies([op1]):
  op2 = otherOp

This runs OK, both op1 and op2 execute once:
sess.run(op2)


This is WRONG:
sess.run([op1, op2])
op1 will execute 2 times.

If adding an input for MyOp, op1 will execute only once as expected for 
 sess.run([op1, op2])"
5434,0.11.0rc2 Problem on building target with GPU support,"CentOS 7.2, 
Python 2.7.12, 
cuda 8.0   //cuda-repo-rhel7-8-0-local-8.0.44-1.x86_64.rpm
cudnn 5.1  //cudnn-8.0-linux-x64-v5.1.tgz

$ git rev-parse HEAD
9d045888a3b565e856287381b581eed02750f976

$ bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package --verbose_failures
INFO: $TEST_TMPDIR defined: output root default is '/home/rnd/tmp'.
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
INFO: Found 1 target...
ERROR: /home/rnd/tmp/_bazel_rnd/707043e71401a80a1e11714c15a7b311/external/pcre/BUILD:5:1: undeclared inclusion(s) in rule '@pcre//:pcre':
this rule is missing dependency declarations for the following files included by 'external/pcre/pcre_valid_utf8.c':
  '/lib/gcc/x86_64-redhat-linux/4.8.5/include/limits.h'
  '/lib/gcc/x86_64-redhat-linux/4.8.5/include/syslimits.h'
  '/lib/gcc/x86_64-redhat-linux/4.8.5/include/stddef.h'
  '/lib/gcc/x86_64-redhat-linux/4.8.5/include/stdarg.h'
  '/lib/gcc/x86_64-redhat-linux/4.8.5/include/stdint.h'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 3.073s, Critical Path: 0.68s
$echo $TF_NEED_CUDA
1
$bazel version
INFO: $TEST_TMPDIR defined: output root default is '/home/rnd/tmp'.
Build label: 0.4.0-2016-11-07 (@fa407e5)
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Sun Nov 6 17:25:58 2016 (1478453158)
Build timestamp: 1478453158
Build timestamp as int: 1478453158
$


if building without GPU will be OK. And get tensorflow-0.11.0rc2-cp27-cp27m-linux_x86_64.whl
if add --config=cuda will get errors like above"
5432,Error building from source,"Hi,

I'm trying to build from master branch and getting this error during the `./configure` step:
```
ERROR: /home/ghedeon/tf/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_input//': Error downloading from https://github.com/polymerelements/iron-input/archive/1.0.10.tar.gz to /home/ghedeon/.cache/bazel/_bazel_ghedeon/dad96730576e51486fd99d150d1fdbd2/external/iron_input: Error downloading https://github.com/polymerelements/iron-input/archive/1.0.10.tar.gz to /home/ghedeon/.cache/bazel/_bazel_ghedeon/dad96730576e51486fd99d150d1fdbd2/external/iron_input/1.0.10.tar.gz: Timed out connecting to https://github.com/polymerelements/iron-input/archive/1.0.10.tar.gz : connect timed out and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: /home/ghedeon/tf/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_input//': Error downloading from https://github.com/polymerelements/iron-input/archive/1.0.10.tar.gz to /home/ghedeon/.cache/bazel/_bazel_ghedeon/dad96730576e51486fd99d150d1fdbd2/external/iron_input: Error downloading https://github.com/polymerelements/iron-input/archive/1.0.10.tar.gz to /home/ghedeon/.cache/bazel/_bazel_ghedeon/dad96730576e51486fd99d150d1fdbd2/external/iron_input/1.0.10.tar.gz: Timed out connecting to https://github.com/polymerelements/iron-input/archive/1.0.10.tar.gz : connect timed out and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: Evaluation of query ""deps((//tensorflow/... union @bazel_tools//tools/jdk:toolchain))"" failed: errors were encountered while computing transitive closure.
```

tf master/9d04588
Bazel 0.4.0
CUDA 7.5
cuDNN 5.0
python 3.5.2

"
5430,RNN AutoEncoder,"Hello, I am writting implementation for RNN autoencoder. The decoder layer is trying to predict next word.

My code looks like this:
```
class RnnAutoencoder():
   def __init__(...):
   ...
   # Encoder
   self.z_codes, self.enc_state = tf.nn.dynamic_rnn(self._enc_cell, inputs, dtype=tf.float32)

   # Intermediate layer after encoder
   last_output = self.z_codes[-1]
   self.pred_m = tf.nn.relu(tf.matmul(last_output, self.weight_m) + self.bias_m)

   # Decoder
   dec_input = self.pred_m
   dec_state = self.enc_state

   dec_outputs = []
   for step in range(len(inputs)):
      if step>0: vs.reuse_variables()
      dec_input_, dec_state = self._dec_cell(dec_input_, dec_state)
      dec_input_ = tf.matmul(dec_input_, dec_weight_) + dec_bias_
      dec_outputs.append(dec_input_)


inputs = tf.placeholder(tf.float32, [1, None, 300])

```

But I get error:
TypeError: object of type 'Tensor' has no len()
on line:     for step in range(len(inputs)):

I know that i cannot apply len on Tensor in tensorflow but how can I iterate(for variable time steps) and do it the way that **next input of decoder is output from previous step**(of the same decoder). Basic tf.nn.dynamic_rnn doesn't work with this situation.

I read many implementations of lstm, rnn, auencoders on github but it is always with fixed size sequences or the implementation of decoder which doesn't get input which is output from previous step. I read seq2seq tutorial but it doesn't use the intermediate layer for encoding sequences as I need in my model and also i am not sure if it can handle dynamic size of sequences.

"
5428,How to make the ./configure find package in local place,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
My server cannot connect to the Internet, when I `./configure`, it will download package from Internet, of course this will fail. So I download the package manually.
E.G.
`ERROR: package contains errors: tensorflow/core/debug.
ERROR: error loading package 'tensorflow/core/debug': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error downloading from http://github.com/google/protobuf/archive/008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz to /mnt/a/usr/75c879a7665c1f6bb168362b3b0eb86b/external/protobuf: Error downloading http://github.com/google/protobuf/archive/008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz to /mnt/a/usr/75c879a7665c1f6bb168362b3b0eb86b/external/protobuf/008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz: Failed to connect to http://github.com/google/protobuf/archive/008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz : github.com.`

I download the `protobuf-008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz` and move it under `/mnt/a/usr/75c879a7665c1f6bb168362b3b0eb86b/external/protobuf/`, but it still fails. It seems the `./configure` will ignore the local package

Anyway to solve this...? It's troubling to install tensorflow on the NFS without Internet.
### Environment info
Operating System:
Linux gs07 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt25-2+deb8u3 (2016-07-02) x86_64 GNU/Linux
Installed version of CUDA and cuDNN: cuda 8.0 cudnn 5.1
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
-rw-r--r-- 1 root staff   558720 Nov  4 10:59 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root staff       16 Nov  4 10:59 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root staff       19 Nov  4 10:59 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 root staff   415432 Nov  4 10:59 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root staff   775162 Nov  4 10:59 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root staff 79337624 Nov  4 11:10 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root staff 79337624 Nov  4 11:10 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root staff 79337624 Nov  4 11:10 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root staff 69756172 Nov  4 11:10 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5427,tensorflow.contrib.layers.feature_column_ops with tf.placeholder tensors,"Following up on the TF.Learn tutorials demonstrating linear models with categorical variables (https://www.tensorflow.org/versions/r0.9/tutorials/linear/overview.html), I have tried to re-use the functions & abstractions from `tensorflow.contrib.layers.feature_column_ops` to hash, encode & cross my input categorical columns while still handling the rest of the computing in low-level TensorFlow.

However, when I pass a normal Tensor (or placeholder) as values of the `columns_to_tensors` parameters of `weighted_sum_from_feature_columns` (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/feature_column_ops.py#L460), it fails because of the `shape` parameter being not available.

Is there any way or plan to enable passing any Tensors other than SparseTensors to this function?"
5426,bazel test failing for tensorflow new op on MAC OS X,"import tensorflow as tf

class ZeroOutTest(tf.test.TestCase):
	zero_out_module = zero_out_module = tf.load_op_library('/Users/sahilsingla/tensorflow/bazel-bin/tensorflow/core/user_ops/zero_out.so')
	def testZeroOut(self):
		with self.test_session():
			result = zero_out_module.zero_out([5, 4, 3, 2, 1])
			value = result.eval()
		self.assertAllEqual(value, [5, 0, 0, 0, 0])

if __name__ == ""__main__"":
	tf.test.main()

When I run: bazel test tensorflow/python/kernel_tests:zero_out_op_test

I get the error: tensorflow.python.framework.errors.NotFoundError: dlopen(zero_out.so, 6): image not found.

The funny thing is this does load when I do : python -c ""import tensorflow as tf; zero_out_module = tf.load_op_library('/Users/sahilsingla/tensorflow/bazel-bin/tensorflow/core/user_ops/zero_out.so')""
but doesn't load with bazel test.

Can anyone please suggest what I am doing wrong here? How can this error be removed?"
5425,XCode CpResource imagenet_comp_graph_label_strings.txt No such file or directory,"When I compile the iOS simple project I get the following error:

> CpResource data/imagenet_comp_graph_label_strings.txt /Users/CYL/Library/Developer/Xcode/DerivedData/tf_ios_makefile_example-agwbsoccjjkvrwgzihhrjmljlwss/Build/Products/Debug-iphonesimulator/tf_ios_makefile_example.app/imagenet_comp_graph_label_strings.txt
>     cd /Users/CYL/tensorflowGIT/tensorflow/contrib/ios_examples/simple
>     export PATH=""/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/usr/bin:/Applications/Xcode.app/Contents/Developer/usr/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin""
>     builtin-copy -exclude .DS_Store -exclude CVS -exclude .svn -exclude .git -exclude .hg -resolve-src-symlinks /Users/CYL/tensorflowGIT/tensorflow/contrib/ios_examples/simple/data/imagenet_comp_graph_label_strings.txt /Users/CYL/Library/Developer/Xcode/DerivedData/tf_ios_makefile_example-agwbsoccjjkvrwgzihhrjmljlwss/Build/Products/Debug-iphonesimulator/tf_ios_makefile_example.app

> error: /Users/CYL/tensorflowGIT/tensorflow/contrib/ios_examples/simple/data/imagenet_comp_graph_label_strings.txt: No such file or directory

![screen shot 2016-11-06 at 12 13 27](https://cloud.githubusercontent.com/assets/10122382/20037125/98009b8e-a41a-11e6-88da-7758b79134c5.png)

I did everything up to the compile in XCode part as described [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/ios_examples). I downgraded from XCode 8 to XCode 7.3.1 with no change. I have MacOS El Capitan."
5423,"'module' object has no attribute 'Default' [Pip Installation, Ubuntu 14.04, cuda 8.0, cudnn 5.1]","I just use **Pip Installation** method to install tensorflow 0.11 on ubuntu 14.04. And I installed cuda8.0, cudnn 5.1. The installation went well, but when I tried to import tensorflow in python, the following error occurred.
```bash
>>> import tensorflow
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 53, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 9, in <module>
    from google.protobuf import symbol_database as _symbol_database
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/symbol_database.py"", line 164, in <module>
    _DEFAULT = SymbolDatabase(pool=descriptor_pool.Default())
AttributeError: 'module' object has no attribute 'Default'
```
How to solve this problem? Thanks."
5422,Why my TF is much slower than Theano?,"Using keras,TF cost 10s for each epoch,and Theano only cost 2s!
I'm using Ubuntu16.04 sever,GTX1060,CUDA8.0,cudnn5.1
~$ python
Python 2.7.12 (default, Jul  1 2016, 15:12:24) 
[GCC 5.4.0 20160609] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

>>> import tensorflow as tf
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
>>> tf
<module 'tensorflow' from '/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.pyc'>
"
5419,Broken build on gcc 6.2.1,"ERROR: /XXX/tensorflow/core/kernels/BUILD:2632:1: C++ compilation of rule '//tensorflow/core/kernels:quantized_ops' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-canonical-system-headers ... (remaining 125 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/core/kernels/quantize_op.cc: In instantiation of 'void tensorflow::QuantizeV2Op<Device, T>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::ThreadPoolDevice; T = Eigen::QInt16]':
tensorflow/core/kernels/quantize_op.cc:166:1:   required from here
tensorflow/core/kernels/quantize_op.cc:116:33: error: no matching function for call to 'std::function<float(float)>::function(<unresolved overloaded function type>)'
                 .unaryExpr(std::function<float(float)>(round))
                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ./tensorflow/core/framework/op.h:19:0,
                 from tensorflow/core/kernels/quantize_op.cc:20:
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2115:7: note: candidate: template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor)
       function<_Res(_ArgTypes...)>::
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2115:7: note:   template argument deduction/substitution failed:
tensorflow/core/kernels/quantize_op.cc:116:33: note:   couldn't deduce template parameter '_Functor'
                 .unaryExpr(std::function<float(float)>(round))
                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ./tensorflow/core/framework/op.h:19:0,
                 from tensorflow/core/kernels/quantize_op.cc:20:
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1897:7: note: candidate: std::function<_Res(_ArgTypes ...)>::function(std::function<_Res(_ArgTypes ...)>&&) [with _Res = float; _ArgTypes = {float}]
       function(function&& __x) : _Function_base()
       ^~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1897:7: note:   no known conversion for argument 1 from '<unresolved overloaded function type>' to 'std::function<float(float)>&&'
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2101:5: note: candidate: std::function<_Res(_ArgTypes ...)>::function(const std::function<_Res(_ArgTypes ...)>&) [with _Res = float; _ArgTypes = {float}]
     function<_Res(_ArgTypes...)>::
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2101:5: note:   no known conversion for argument 1 from '<unresolved overloaded function type>' to 'const std::function<float(float)>&'
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1877:7: note: candidate: std::function<_Res(_ArgTypes ...)>::function(std::nullptr_t) [with _Res = float; _ArgTypes = {float}; std::nullptr_t = std::nullptr_t]
       function(nullptr_t) noexcept
       ^~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1877:7: note:   no known conversion for argument 1 from '<unresolved overloaded function type>' to 'std::nullptr_t'
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1870:7: note: candidate: std::function<_Res(_ArgTypes ...)>::function() [with _Res = float; _ArgTypes = {float}]
       function() noexcept
       ^~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1870:7: note:   candidate expects 0 arguments, 1 provided
tensorflow/core/kernels/quantize_op.cc: In instantiation of 'void tensorflow::QuantizeV2Op<Device, T>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::ThreadPoolDevice; T = Eigen::QUInt16]':
tensorflow/core/kernels/quantize_op.cc:166:1:   required from here
tensorflow/core/kernels/quantize_op.cc:116:33: error: no matching function for call to 'std::function<float(float)>::function(<unresolved overloaded function type>)'
                 .unaryExpr(std::function<float(float)>(round))
                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ./tensorflow/core/framework/op.h:19:0,
                 from tensorflow/core/kernels/quantize_op.cc:20:
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2115:7: note: candidate: template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor)
       function<_Res(_ArgTypes...)>::
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2115:7: note:   template argument deduction/substitution failed:
tensorflow/core/kernels/quantize_op.cc:116:33: note:   couldn't deduce template parameter '_Functor'
                 .unaryExpr(std::function<float(float)>(round))
                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ./tensorflow/core/framework/op.h:19:0,
                 from tensorflow/core/kernels/quantize_op.cc:20:
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1897:7: note: candidate: std::function<_Res(_ArgTypes ...)>::function(std::function<_Res(_ArgTypes ...)>&&) [with _Res = float; _ArgTypes = {float}]
       function(function&& __x) : _Function_base()
       ^~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1897:7: note:   no known conversion for argument 1 from '<unresolved overloaded function type>' to 'std::function<float(float)>&&'
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2101:5: note: candidate: std::function<_Res(_ArgTypes ...)>::function(const std::function<_Res(_ArgTypes ...)>&) [with _Res = float; _ArgTypes = {float}]
     function<_Res(_ArgTypes...)>::
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2101:5: note:   no known conversion for argument 1 from '<unresolved overloaded function type>' to 'const std::function<float(float)>&'
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1877:7: note: candidate: std::function<_Res(_ArgTypes ...)>::function(std::nullptr_t) [with _Res = float; _ArgTypes = {float}; std::nullptr_t = std::nullptr_t]
       function(nullptr_t) noexcept
       ^~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1877:7: note:   no known conversion for argument 1 from '<unresolved overloaded function type>' to 'std::nullptr_t'
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1870:7: note: candidate: std::function<_Res(_ArgTypes ...)>::function() [with _Res = float; _ArgTypes = {float}]
       function() noexcept
       ^~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1870:7: note:   candidate expects 0 arguments, 1 provided
tensorflow/core/kernels/quantize_op.cc: In instantiation of 'void tensorflow::QuantizeV2Op<Device, T>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::ThreadPoolDevice; T = Eigen::QInt8]':
tensorflow/core/kernels/quantize_op.cc:166:1:   required from here
tensorflow/core/kernels/quantize_op.cc:116:33: error: no matching function for call to 'std::function<float(float)>::function(<unresolved overloaded function type>)'
                 .unaryExpr(std::function<float(float)>(round))
                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ./tensorflow/core/framework/op.h:19:0,
                 from tensorflow/core/kernels/quantize_op.cc:20:
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2115:7: note: candidate: template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor)
       function<_Res(_ArgTypes...)>::
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2115:7: note:   template argument deduction/substitution failed:
tensorflow/core/kernels/quantize_op.cc:116:33: note:   couldn't deduce template parameter '_Functor'
                 .unaryExpr(std::function<float(float)>(round))
                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ./tensorflow/core/framework/op.h:19:0,
                 from tensorflow/core/kernels/quantize_op.cc:20:
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1897:7: note: candidate: std::function<_Res(_ArgTypes ...)>::function(std::function<_Res(_ArgTypes ...)>&&) [with _Res = float; _ArgTypes = {float}]
       function(function&& __x) : _Function_base()
       ^~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1897:7: note:   no known conversion for argument 1 from '<unresolved overloaded function type>' to 'std::function<float(float)>&&'
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2101:5: note: candidate: std::function<_Res(_ArgTypes ...)>::function(const std::function<_Res(_ArgTypes ...)>&) [with _Res = float; _ArgTypes = {float}]
     function<_Res(_ArgTypes...)>::
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2101:5: note:   no known conversion for argument 1 from '<unresolved overloaded function type>' to 'const std::function<float(float)>&'
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1877:7: note: candidate: std::function<_Res(_ArgTypes ...)>::function(std::nullptr_t) [with _Res = float; _ArgTypes = {float}; std::nullptr_t = std::nullptr_t]
       function(nullptr_t) noexcept
       ^~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1877:7: note:   no known conversion for argument 1 from '<unresolved overloaded function type>' to 'std::nullptr_t'
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1870:7: note: candidate: std::function<_Res(_ArgTypes ...)>::function() [with _Res = float; _ArgTypes = {float}]
       function() noexcept
       ^~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1870:7: note:   candidate expects 0 arguments, 1 provided
tensorflow/core/kernels/quantize_op.cc: In instantiation of 'void tensorflow::QuantizeV2Op<Device, T>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::ThreadPoolDevice; T = Eigen::QUInt8]':
tensorflow/core/kernels/quantize_op.cc:166:1:   required from here
tensorflow/core/kernels/quantize_op.cc:116:33: error: no matching function for call to 'std::function<float(float)>::function(<unresolved overloaded function type>)'
                 .unaryExpr(std::function<float(float)>(round))
                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ./tensorflow/core/framework/op.h:19:0,
                 from tensorflow/core/kernels/quantize_op.cc:20:
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2115:7: note: candidate: template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor)
       function<_Res(_ArgTypes...)>::
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2115:7: note:   template argument deduction/substitution failed:
tensorflow/core/kernels/quantize_op.cc:116:33: note:   couldn't deduce template parameter '_Functor'
                 .unaryExpr(std::function<float(float)>(round))
                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ./tensorflow/core/framework/op.h:19:0,
                 from tensorflow/core/kernels/quantize_op.cc:20:
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1897:7: note: candidate: std::function<_Res(_ArgTypes ...)>::function(std::function<_Res(_ArgTypes ...)>&&) [with _Res = float; _ArgTypes = {float}]
       function(function&& __x) : _Function_base()
       ^~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1897:7: note:   no known conversion for argument 1 from '<unresolved overloaded function type>' to 'std::function<float(float)>&&'
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2101:5: note: candidate: std::function<_Res(_ArgTypes ...)>::function(const std::function<_Res(_ArgTypes ...)>&) [with _Res = float; _ArgTypes = {float}]
     function<_Res(_ArgTypes...)>::
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:2101:5: note:   no known conversion for argument 1 from '<unresolved overloaded function type>' to 'const std::function<float(float)>&'
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1877:7: note: candidate: std::function<_Res(_ArgTypes ...)>::function(std::nullptr_t) [with _Res = float; _ArgTypes = {float}; std::nullptr_t = std::nullptr_t]
       function(nullptr_t) noexcept
       ^~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1877:7: note:   no known conversion for argument 1 from '<unresolved overloaded function type>' to 'std::nullptr_t'
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1870:7: note: candidate: std::function<_Res(_ArgTypes ...)>::function() [with _Res = float; _ArgTypes = {float}]
       function() noexcept
       ^~~~~~~~
/usr/lib/gcc/x86_64-pc-linux-gnu/6.2.1/../../../../include/c++/6.2.1/functional:1870:7: note:   candidate expects 0 arguments, 1 provided"
5417,1% GPU usage and slow training times after unknown DSO update?,"Tensorflow with CUDA was working fine. Cross-entropy loss was going to zero (CIFAR-10 and a very simple CNN), but training error stayed around the same as random chance. I mention this in case it may be related to my issue.

In between runs, not 5 minutes after it was just working, I mysteriously got this error message about my video driver: 

`kernel version 361.42.0 does not match DSO version 367.57.0`

I never updated anything, so that's strange. I update my video driver using `apt-get` and the Ubuntu ppa repo, then restart. I didn't check what version the video driver was before the update but I assume it was 361.42?

The error message is gone, but **training is now an order of magnitude slower with ~1% GPU usage and ~5% CPU usage**. `nvidia-smi` indicates 90% memory usage, which means the model is in memory, but what before took ~0.4 seconds per batch is now taking 4+ seconds per batch.

I tried re-installing CUDA and cuDNN from official sources but no change.
CUDA bandwidth test and deviceQuery results normal.

Ubuntu 16.04
Tensorflow 0.10.0 (built from source w/ CC 3.5 and 5.0)
nvidia Quadro K2200
CUDA 8.0
cuDNN 5.1.5
Python 2.7"
5416,Possible Bug - Varying session run times when parallelized across GPUs on one node,"Hello tensorflow team!

I have been trying to parallelize my 3D convolution network across 2 GPUs on the same node (using data parallelism), and have found that some of my session runs took significantly longer than others.  Upon closer investigation using your timeline feature, I found that sometimes GPU1 would wait a certain amount of time before starting to run its convolutions even as GPU0 was happily chugging along. In the most extreme case, execution would happen essentially sequentially, doubling my runtime!  

I am attaching screenshots of my timelines from three sessions to show you what I mean...

In the first one, everything is fine, it is executing both towers in parallel:
![run55](https://cloud.githubusercontent.com/assets/177576/20033120/cc17df8c-a356-11e6-8ef3-55cfdeb9d244.png)
In the second, I see the ""sequential"" behaviour:
![run56](https://cloud.githubusercontent.com/assets/177576/20033121/cd4d9e96-a356-11e6-8ef1-091edd981fdf.png)
In the last one, I see something in between:
![run30](https://cloud.githubusercontent.com/assets/177576/20033136/2b7f68b4-a357-11e6-9eb5-92f9a30a5fa3.png)

I know this happens even when I am not logging metadata because I still see a large spread of runtime distributions without logging on (see parallel-nometadata.txt at the bottom).  Also, dumping the GraphDef proto at each step tells me that the ops are correctly assigned to the different GPUs (I have attached those, as well as my timeline files, at the bottom).

I actually briefly talked about this with @mrry in person a little over a week ago, and we did not find anything obviously wrong at first glance.  Any help you could provide would be much appreciated!  

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

I have not found any related Github or StackOverflow threads.  I have been using the Timeline profiling feature as described [here](https://github.com/tensorflow/tensorflow/issues/1824).

### Environment info
Operating System: Ubuntu 14.04.5 LTS (running in a [singularity](http://singularity.lbl.gov) container on a CentOS 6.7 host). 

Installed version of CUDA and cuDNN: 
I am using CUDA 8.0 with NVIDIA driver 367.48, and cuDNN v5.1 . 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
libOpenCL.so
libOpenCL.so.1
libOpenCL.so.1.0
libOpenCL.so.1.0.0
libcublas.so
libcublas.so.8.0
libcublas.so.8.0.45
libcublas_device.a
libcublas_static.a
libcudadevrt.a
libcudart.so
libcudart.so.8.0
libcudart.so.8.0.44
libcudart_static.a
libcudnn.so
libcudnn.so.5
libcudnn.so.5.1.5
libcudnn_static.a
libcufft.so
libcufft.so.8.0
libcufft.so.8.0.44
libcufft_static.a
libcufftw.so
libcufftw.so.8.0
libcufftw.so.8.0.44
libcufftw_static.a
libcuinj64.so
libcuinj64.so.8.0
libcuinj64.so.8.0.44
libculibos.a
libcurand.so
libcurand.so.8.0
libcurand.so.8.0.44
libcurand_static.a
libcusolver.so
libcusolver.so.8.0
libcusolver.so.8.0.44
libcusolver_static.a
libcusparse.so
libcusparse.so.8.0
libcusparse.so.8.0.44
libcusparse_static.a
libnppc.so
libnppc.so.8.0
libnppc.so.8.0.44
libnppc_static.a
libnppi.so
libnppi.so.8.0
libnppi.so.8.0.44
libnppi_static.a
libnppial.so
libnppial.so.8.0
libnppial.so.8.0.44
libnppicc.so
libnppicc.so.8.0
libnppicc.so.8.0.44
libnppicom.so
libnppicom.so.8.0
libnppicom.so.8.0.44
libnppidei.so
libnppidei.so.8.0
libnppidei.so.8.0.44
libnppif.so
libnppif.so.8.0
libnppif.so.8.0.44
libnppig.so
libnppig.so.8.0
libnppig.so.8.0.44
libnppim.so
libnppim.so.8.0
libnppim.so.8.0.44
libnppist.so
libnppist.so.8.0
libnppist.so.8.0.44
libnppisu.so
libnppisu.so.8.0
libnppisu.so.8.0.44
libnppitc.so
libnppitc.so.8.0
libnppitc.so.8.0.44
libnpps.so
libnpps.so.8.0
libnpps.so.8.0.44
libnpps_static.a
libnvToolsExt.so
libnvToolsExt.so.1
libnvToolsExt.so.1.0.0
libnvblas.so
libnvblas.so.8.0
libnvblas.so.8.0.44
libnvgraph.so
libnvgraph.so.8.0
libnvgraph.so.8.0.44
libnvgraph_static.a
libnvrtc-builtins.so
libnvrtc-builtins.so.8.0
libnvrtc-builtins.so.8.0.44
libnvrtc.so
libnvrtc.so.8.0
libnvrtc.so.8.0.44
stubs
```

I installed tensorflow using the 0.11.0rc2-gpu tag on docker hub.

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

Here is the code I used to generate all the data I am sharing.

```
import os
import time
import timeit

import google
import numpy as np
import tensorflow as tf

grid_size = 9
channel_size = 4
batch_size = 2**9
num_convs = 8
log_metadata = True
towers = 2
num_train_batches = 100


def define_model(towers):
    tower_outs = []
    for i in range(0, towers):
        with tf.device('/gpu:{:}'.format(i)):
            with tf.name_scope('TOWER_{:}'.format(i)):
                tower_outs.append(define_tower(i))
                tf.get_variable_scope().reuse_variables()
    return tower_outs


def define_tower(gpu_num):
    x = tf.placeholder(
        tf.float32,
        shape=[None, grid_size, grid_size, grid_size, channel_size],
        name='grid')

    num_inputs = channel_size
    for i in range(num_convs):
        with tf.variable_scope(""conv{:d}"".format(i)):
            weights = tf.get_variable(
                ""weights"",
                [3, 3, 3, num_inputs, 32])
            x = tf.nn.conv3d(x, weights, [1, 1, 1, 1, 1], 'SAME')
            num_inputs = 32

    return x


if __name__ == ""__main__"":

    # Define model.
    tower_outs = define_model(towers)

    # Create inputs.
    feed_dict = {}
    for i in range(towers):
        feed_dict['TOWER_{:}/grid:0'.format(i)] = np.random.rand(
            batch_size, grid_size, grid_size, grid_size, channel_size)

    # Prepare for logging.
    if log_metadata:
        run_options = tf.RunOptions(
            trace_level=tf.RunOptions.FULL_TRACE,
            output_partition_graphs=True)
        run_metadata = tf.RunMetadata()
        kwargs = {'options': run_options,
                  'run_metadata': run_metadata}

        curr_time = time.strftime(""%Y-%m-%d-%H-%M-%S"")
        if log_metadata:
            out_dir = curr_time
            os.mkdir(out_dir)
    else:
        kwargs = {}

    # Run model.
    train_learning_times = []
    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:
        tf.initialize_all_variables().run()
        for i in range(num_train_batches):
            learning_time_start = timeit.default_timer()
            _ = sess.run(tower_outs, feed_dict=feed_dict, **kwargs)
            train_learning_times.append(timeit.default_timer() -
                                        learning_time_start)

            if log_metadata:
                from tensorflow.python.client import timeline
                tl = timeline.Timeline(run_metadata.step_stats)
                ctf = tl.generate_chrome_trace_format()
                with open('{}/timeline_parallel_{}.json'
                          .format(curr_time, i), 'w') as f:
                    f.write(ctf)
                with open('{}/run_metadata_{}.txt'
                          .format(curr_time, i), 'w') as f:
                    f.write(
                        google.protobuf.text_format.MessageToString(
                            run_metadata))

    # Print stats
    print 'Histogram counts: {}'.format(
        np.histogram(train_learning_times[2:])[0])
    print 'Histogram edges: {}'.format(
        np.histogram(train_learning_times[2:])[1])
    print 'Median time for learning: {:5.2f}'.format(
        np.median(train_learning_times))
```

### What other attempted solutions have you tried?

No other solutions tried.




### Logs or other output that would be helpful
Dump of GraphDef and timeline json for each of 100 runs.

[2016-11-05-18-52-32.zip](https://github.com/tensorflow/tensorflow/files/573462/2016-11-05-18-52-32.zip)

Output of code with log_metadata set to True:
[parallel.txt](https://github.com/tensorflow/tensorflow/files/573464/parallel.txt)

Output of code with log_metadata set to False:
[parallel-nometadata.txt](https://github.com/tensorflow/tensorflow/files/573465/parallel-nometadata.txt)"
5415,UnsupportedWheel: tensorflow-0.11.0rc2-cp27-cp27mu-linux_x86_64.whl,"Hi all,

I'm updating my tensorflow from r0.10 to r0.11 or the master, but after I run the cmd:
```
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
```
I just got a `tensorflow-0.11.0rc2-cp27-cp27mu-linux_x86_64.whl` instead of `tensorflow-0.11.0rc2-py2-none-any.whl`. And this file always caused an `UnsupportedWheel` error when I run pip install. 

This is the pip.log:
```
------------------------------------------------------------
/usr/bin/pip run on Sat Nov  5 16:59:34 2016
tensorflow-0.11.0rc2-cp27-cp27mu-linux_x86_64.whl is not a supported wheel on this platform.
Exception information:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/dist-packages/pip/basecommand.py"", line 122, in main
    status = self.run(options, args)
  File ""/usr/lib/python2.7/dist-packages/pip/commands/install.py"", line 257, in run
    InstallRequirement.from_line(name, None))
  File ""/usr/lib/python2.7/dist-packages/pip/req.py"", line 168, in from_line
    raise UnsupportedWheel(""%s is not a supported wheel on this platform."" % wheel.filename)
UnsupportedWheel: tensorflow-0.11.0rc2-cp27-cp27mu-linux_x86_64.whl is not a supported wheel on this platform.
```

Operating system: Ubuntu 14.04
Kernel release: 4.4.0-45-generic
Cuda toolkit: 8.0.44
cuDNN: 5.1.5
GPU: GTX 1080
bazel version: 0.4.0
gcc and g++: 4.8.5
python: 2.7.6

I wonder what  `cp27-cp27mu` means and why I can't get an supported .whl file?
 "
5414,how to run distributed version on mutiple CPUs but not GPUs. ,"when i run scripts like follows:
CUDA_VISIBLE_DEVICES='' python distribute.py --ps_hosts=192.168.1.100:2222 --worker_hosts=192.168.1.100:2224,192.168.1.100:2225 --job_name=ps --task_index=0

CUDA_VISIBLE_DEVICES='' python distribute.py --ps_hosts=192.168.1.100:2222 --worker_hosts=192.168.1.100:2224,192.168.1.100:2225 --job_name=worker --task_index=0

CUDA_VISIBLE_DEVICES='' python distribute.py --ps_hosts=192.168.1.100:2222 --worker_hosts=192.168.1.100:2224,192.168.1.100:2225 --job_name=worker --task_index=1 

terminal will not start , I am confused. when I change one of the CUDA_VISIBLE_DEVICES=''  to CUDA_VISIBLE_DEVICES=0,  it works .  But I need just CPUs without a GPU"
5413,StudentT.cdf() bug,"With the TF0.11 rc2 (also with rc0) I get the following error while trying to evaluate the CDF of the StudentT distribution:
```
----> 1 a.cdf(5.0)

/home/ilm/.local/lib/python2.7/site-packages/tensorflow/contrib/distributions/python/ops/distribution.pyc in cdf(self, value, name)
    496         values of type `self.dtype`.
    497     """"""
--> 498     self._check_hasattr(self._cdf)
    499     with self._name_scope(name, values=[value]):
    500       value = ops.convert_to_tensor(value, name=""value"")

AttributeError: 'StudentT' object has no attribute '_cdf'

```
Is the CDF of StudentT supported? According to the docs it should:
https://www.tensorflow.org/versions/r0.11/api_docs/python/contrib.distributions.html#StudentT

MWE:
```
import tensorflow as tf
a = tf.contrib.distributions.StudentT(5.0, 0.0, 1.0)
a.cdf(5.0)
```"
5412,Request: Functionality for obtaining gradients that are internal to a while_loop,"I'd like to manipulate the gradients that are internal to a while loop. The actual purpose is to view / manipulate recurrent-neural-network behavior, but here is a simplified example to get the idea across:

```
t_0 = tf.constant(0)
x_0 = tf.constant(1.0)
size = 3
x_ta = tf.TensorArray(tf.float32, size=size)

def cond(t, x_prev, x_ta):
    return tf.less(t, size)

def body(t, x_prev, x_ta):
    x = 2*x_prev
    x_ta = x_ta.write(t, x)
    return t + 1, x, x_ta

_, _, x_ta = tf.while_loop(cond, body, [t_0, x_0, x_ta])
x = x_ta.pack()

loss = x[size-1]

dloss_dx, = tf.gradients(loss, x)

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    print(sess.run(dloss_dx))
```

In this example, `x[t] = 2*x[t-1]` for all `t`, so we'd like `dloss_dx` to be `[4., 2., 1.]`. We instead get `[ 0.  0.  1.]`. I don't think this is a bug: we're actually taking the derivative with respect to the pack operation, which `x[2]` doesn't actually depend on.

Please correct me if I'm wrong, but I think it's currently impossible to obtain `[4., 2., 1.]` in the general case. (One hack here would be to compute gradients within the `while_loop` and then form a cumulative product corresponding to the chain rule, but this won't work with vector-valued `x[t]`'s because there's no way to get the Jacobians).

But the gradients with respect to each of these time steps must live somewhere. Can we add a property to the `TensorArray` class to be able to obtain these?"
5409,TF_OperationOutputType returns values not contained in TF_DataType,"For example, if TF_OperationOutputType is used on a Variable node of 
type Double, the function returns value 102, which corresponds to DT_DOUBLE_REF
in protobuf DataType enum (types.proto). However, value 102 is not defined in 
TF_DataType enum (c_api.h).

This inconsistency can be easily avoided by using integers instead of TF_DataType enum,
however it should be probably fixed at some point.  "
5408,[feature request] GPU Kernel for SparseSegmentMean/SparseSegmentMeanGrad,"I'm using embedding_lookup_sparse op (with 'mean' combiner) to do dictionary learning -- sparse lookup is needed because each object is associated with variable length of word list. But it seems there is no gpu kernel implemented for SparseSegmentMean/SparseSegmentMeanGrad. This operation bottlenecks the entire speed.

Wondering if there are plans to implement gpu kernel for these two ops? I believe they are of general interests to people working on NLP, attributes learning as well.

Thanks!
"
5407,tf.contrib.metrics.streaming_precision doesn't accept predictions and labels of dtype tf.bool,"According to documentation and comments in code, ""tf.contrib.metrics.streaming_precision"" should accept predictions and labels of boolean type, but it doesn't seem to be true.

To reproduce, modify testAllCorrect procedure in [this file](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/metrics/python/ops/metric_ops_test.py) by adding dtype=tf.bool to tf.constant, as below:
```
  def testAllCorrect(self):
    inputs = np.random.randint(0, 2, size=(100, 1))

    predictions = tf.constant(inputs, dtype=tf.bool)
    labels = tf.constant(inputs, dtype=tf.bool)
    precision, update_op = metrics.streaming_precision(
        predictions, labels)
```

The test will fail:
```
tensorflow/contrib/metrics/python/ops % python ./metric_ops_test.py
======================================================================
ERROR: testAllCorrect (__main__.StreamingPrecisionTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""./metric_ops_test.py"", line 656, in testAllCorrect
    predictions, labels)
  File ""/home/sergeii/tools/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/deprecation.py"", line 218, in new_func
    return func(*args, **kwargs)
  File ""/home/sergeii/tools/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/metrics/python/ops/metric_ops.py"", line 572, in streaming_precision
    updates_collections=None, name=None)
  File ""/home/sergeii/tools/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/metrics/python/ops/metric_ops.py"", line 215, in _streaming_true_positives
    is_true_positive = math_ops.logical_and(math_ops.equal(labels, 1),
  File ""/home/sergeii/tools/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 726, in equal
    result = _op_def_lib.apply_op(""Equal"", x=x, y=y, name=name)
  File ""/home/sergeii/tools/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 490, in apply_op
    preferred_dtype=default_dtype)
  File ""/home/sergeii/tools/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 657, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/sergeii/tools/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 180, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/sergeii/tools/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 163, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))
  File ""/home/sergeii/tools/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 353, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/home/sergeii/tools/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 290, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected bool, got 1 of type 'int' instead.
````

This happens in _streaming_true_positives function in [this file](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/metrics/python/ops/metric_ops.py), when executing ```math_ops.equal(labels, 1)```

Can be repeated simply as:
```
import numpy as np
from tensorflow.python.ops import math_ops
import tensorflow as tf

label = tf.constant(np.array([1, 0, 1]), dtype=tf.bool)
math_ops.equal(label, 1)
```

### Environment info
Operating System: Ubuntu 14.04.1

```
%ls -l /usr/local/cuda/lib64/libcud*  
-rw-r--r-- 1 root root    558720 Oct 20 14:53 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Oct 20 14:53 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root        19 Oct 20 14:53 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 root root    415432 Oct 20 14:53 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root    775162 Oct 20 14:53 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 1000 users       13 Jul 26 22:55 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 1000 users       17 Jul 26 22:55 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxrwxr-x 1 1000 users 79337624 Jul 26 22:53 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-rw-r-- 1 1000 users 69756172 Jul 26 22:53 /usr/local/cuda/lib64/libcudnn_static.a
```

```
python -c ""import tensorflow; print(tensorflow.__version__)""
Version: 0.11.0rc2
```
"
5406,TF_GraphImportGraphDef breaks down while importing graphs with control flow ops,"I've encountered issues when trying to load graphs from python which contain
dropout or batch norm. In the following example:
```python
    x = tf.placeholder(tf.float64, [None, 3])

    w = tf.Variable(tf.random_normal([3, 3], dtype=tf.float64))
    h = tf.matmul(x, w)

    is_training = tf.Variable(True, trainable=False)
    h_dropout = tf.contrib.layers.dropout(h, keep_prob=0.5, is_training=is_training)
```
TF_GraphImportGraphDef breaks down and I get the following message:

*SIGSEGV (0xb) at pc=0x000000013539dcac, pid=23288, tid=0x0000000000006a1b
C  [libtensorflow.dylib+0x14cac]  tensorflow::shape_inference::InferenceContext::Rank(tensorflow::shape_inference::ShapeHandle) const+0x1c*

The same happens if I replace dropout operation with batch norm:
```python
tf.contrib.layers.batch_norm(h, center=True, scale=True, is_training=is_training)
```

It seems to me this problem is related to the presence of control flow ops."
5404,"VARIABLES Collection name is deprecated, please use GLOBAL_VARIABLES instead","I pulled the latest HEAD a few mins ago and ran my code.  I started to get the listed error:

**WARNING:tensorflow:VARIABLES Collection name is deprecated, please use GLOBAL_VARIABLES instead.**
**VARIABLES will be removed after 2017-03-02**

I didn't fully debug all the causes but seems like there is errors thrown when the following lines are hit:

> from tensorflow.contrib.session_bundle import exporter

if I remove that line, it seems to move to another line building the graph, not sure if it is a ""get_variables()"" operation or something.  I don't use VARIABLES anywhere in  my code.  Given the ""saver"" below causing a similar issue, it is possible my ""histogram_summary"" or ""scalar_summary"" ops may have triggered this as well while building the graph.

The same error is printed on each iteration of ""save()"" with the saver, this really messes up my logging to the screen:
> save_path = saverRun.save(session, saveto)

Seems like something within the Saver and possibly the ""variables"" might need updating."
5401,Creating and fitting a Trainable leaks file descriptors ,"Creating a Trainable and calling fit() on it leaks file descriptors.

### Environment info
Operating System: Mac OS X

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

None

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

0.11.0rc0

If installed from source, provide 

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
import numpy as np
import tensorflow
from tensorflow.contrib import learn, layers

def input_fn():
    return (
        {'a': tensorflow.constant([1.1, 2.2, 3.3], dtype=tensorflow.float32)}, 
        tensorflow.constant([5.0, 8.0, 12.5], dtype=tensorflow.float32))

while True:
    linear_regressor = learn.LinearRegressor(
        feature_columns=[layers.real_valued_column('a')])
    linear_regressor.fit(input_fn=input_fn, steps=1)
```

### Logs or other output that would be helpful

Traceback (most recent call last):
  File ""tensor_bug.py"", line 13, in <module>
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 333, in fit
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 708, in _train_model
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 285, in _monitored_train
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitored_session.py"", line 368, in run
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitored_session.py"", line 521, in run
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitored_session.py"", line 488, in run
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitored_session.py"", line 612, in run
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitored_session.py"", line 634, in _call_hook_before_run
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/basic_session_run_hooks.py"", line 180, in before_run
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/training_util.py"", line 76, in write_graph
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 211, in write_string_to_file
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 89, in write
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 81, in _prewrite_check
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py"", line 66, in __exit__
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
tensorflow.python.framework.errors.ResourceExhaustedError: /var/folders/6c/3pzbp8jj3zd0lkhsszmvyd5h001cct/T/tmpzr7juea4/graph.pbtxt

During the run ""lsof"" is indicating that the number of file descriptors used is increased on every loop iteration."
5399,Seg faults when build with Hadoop file system support,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
No
### Environment info
Operating System: CentOS with kernel 3.10.0-123.el7.x86_64

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): 8.0

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`) c80ef0cd19a3ac9ad0657f617b4e7328f6a48ac3
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
tensorflow_serving/example/mnist_export.py

### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
When run tensorflow build with HDFS support (HDFS is configured and loaded, but not used), python crash with segment faults, here is the backtrace:
```
(gdb) bt
#0  update_refs (containers=<optimized out>) at /usr/src/debug/Python-2.7.5/Modules/gcmodule.c:400
#1  collect (generation=2) at /usr/src/debug/Python-2.7.5/Modules/gcmodule.c:998
#2  0x00007fb2a3102227 in collect_generations () at /usr/src/debug/Python-2.7.5/Modules/gcmodule.c:1124
#3  _PyObject_GC_Malloc (basicsize=3) at /usr/src/debug/Python-2.7.5/Modules/gcmodule.c:1585
#4  0x00007fb2a310226d in _PyObject_GC_New (tp=tp@entry=0x7fb2a338a220 <_PyWeakref_RefType>) at /usr/src/debug/Python-2.7.5/Modules/gcmodule.c:1595
#5  0x00007fb2a309a456 in new_weakref (ob=ob@entry=<TensorProto at remote 0x6fe0cf8>, callback=callback@entry=0x0) at /usr/src/debug/Python-2.7.5/Objects/weakrefobject.c:36
#6  0x00007fb2a309d5f3 in PyWeakref_NewProxy (ob=<TensorProto at remote 0x6fe0cf8>, callback=<optimized out>) at /usr/src/debug/Python-2.7.5/Objects/weakrefobject.c:840
#7  0x00007fb2a31158c7 in weakref_proxy (self=<optimized out>, args=<optimized out>) at /usr/src/debug/Python-2.7.5/Modules/_weakref.c:73
#8  0x00007fb2a30d2b94 in call_function (oparg=<optimized out>, pp_stack=0x7fffd07e3c50) at /usr/src/debug/Python-2.7.5/Python/ceval.c:4098
#9  PyEval_EvalFrameEx (
    f=f@entry=Frame 0x31c0bc0, for file /home/heliangliang/tf/lib/python2.7/site-packages/google/protobuf/internal/python_message.py, line 1393, in __init__ (self=<_Listener at remote 0x6fdced0>, parent_message=<TensorProto at remote 0x6fe0cf8>), throwflag=throwflag@entry=0) at /usr/src/debug/Python-2.7.5/Python/ceval.c:2740
#10 0x00007fb2a30d41ad in PyEval_EvalCodeEx (co=<optimized out>, globals=<optimized out>, locals=locals@entry=0x0, args=args@entry=0x5510ba8, argcount=2, kws=kws@entry=0x0, kwcount=kwcount@entry=0, 
    defs=defs@entry=0x0, defcount=defcount@entry=0, closure=0x0) at /usr/src/debug/Python-2.7.5/Python/ceval.c:3330
#11 0x00007fb2a3061098 in function_call (func=<function at remote 0x305be60>, arg=(<_Listener at remote 0x6fdced0>, <TensorProto at remote 0x6fe0cf8>), kw=0x0)
    at /usr/src/debug/Python-2.7.5/Objects/funcobject.c:526
#12 0x00007fb2a303c073 in PyObject_Call (func=func@entry=<function at remote 0x305be60>, arg=arg@entry=(<_Listener at remote 0x6fdced0>, <TensorProto at remote 0x6fe0cf8>), kw=kw@entry=0x0)
    at /usr/src/debug/Python-2.7.5/Objects/abstract.c:2529
#13 0x00007fb2a304b085 in instancemethod_call (func=<function at remote 0x305be60>, arg=(<_Listener at remote 0x6fdced0>, <TensorProto at remote 0x6fe0cf8>), kw=0x0)
    at /usr/src/debug/Python-2.7.5/Objects/classobject.c:2602
#14 0x00007fb2a303c073 in PyObject_Call (func=func@entry=<instancemethod at remote 0x5516820>, arg=arg@entry=(<TensorProto at remote 0x6fe0cf8>,), kw=kw@entry=0x0)
    at /usr/src/debug/Python-2.7.5/Objects/abstract.c:2529
#15 0x00007fb2a3093167 in slot_tp_init (self=<optimized out>, args=(<TensorProto at remote 0x6fe0cf8>,), kwds=0x0) at /usr/src/debug/Python-2.7.5/Objects/typeobject.c:5692
#16 0x00007fb2a3091e7f in type_call (type=<optimized out>, args=(<TensorProto at remote 0x6fe0cf8>,), kwds=0x0) at /usr/src/debug/Python-2.7.5/Objects/typeobject.c:745
#17 0x00007fb2a303c073 in PyObject_Call (func=func@entry=<type at remote 0x2ef68b0>, arg=arg@entry=(<TensorProto at remote 0x6fe0cf8>,), kw=kw@entry=0x0) at /usr/src/debug/Python-2.7.5/Objects/abstract.c:2529
#18 0x00007fb2a30d034c in do_call (nk=<optimized out>, na=1, pp_stack=0x7fffd07e4230, func=<type at remote 0x2ef68b0>) at /usr/src/debug/Python-2.7.5/Python/ceval.c:4316
#19 call_function (oparg=<optimized out>, pp_stack=0x7fffd07e4230) at /usr/src/debug/Python-2.7.5/Python/ceval.c:4121
#20 PyEval_EvalFrameEx (
    f=f@entry=Frame 0x6c355c0, for file /home/heliangliang/tf/lib/python2.7/site-packages/google/protobuf/internal/python_message.py, line 489, in init (self=<TensorProto at remote 0x6fe0cf8>, kwargs={}), 
    throwflag=throwflag@entry=0) at /usr/src/debug/Python-2.7.5/Python/ceval.c:2740
#21 0x00007fb2a30d41ad in PyEval_EvalCodeEx (co=<optimized out>, globals=<optimized out>, locals=locals@entry=0x0, args=args@entry=0x57ef6a8, argcount=1, kws=kws@entry=0x0, kwcount=kwcount@entry=0, 
    defs=defs@entry=0x0, defcount=defcount@entry=0, closure=(<cell at remote 0x31858d8>, <cell at remote 0x3185910>)) at /usr/src/debug/Python-2.7.5/Python/ceval.c:3330
#22 0x00007fb2a3061098 in function_call (func=<function at remote 0x318c500>, arg=(<TensorProto at remote 0x6fe0cf8>,), kw=0x0) at /usr/src/debug/Python-2.7.5/Objects/funcobject.c:526
#23 0x00007fb2a303c073 in PyObject_Call (func=func@entry=<function at remote 0x318c500>, arg=arg@entry=(<TensorProto at remote 0x6fe0cf8>,), kw=kw@entry=0x0)
    at /usr/src/debug/Python-2.7.5/Objects/abstract.c:2529
#24 0x00007fb2a304b085 in instancemethod_call (func=<function at remote 0x318c500>, arg=(<TensorProto at remote 0x6fe0cf8>,), kw=0x0) at /usr/src/debug/Python-2.7.5/Objects/classobject.c:2602
#25 0x00007fb2a303c073 in PyObject_Call (func=func@entry=<instancemethod at remote 0x557f410>, arg=arg@entry=(), kw=kw@entry=0x0) at /usr/src/debug/Python-2.7.5/Objects/abstract.c:2529
#26 0x00007fb2a3093167 in slot_tp_init (self=<optimized out>, args=(), kwds=0x0) at /usr/src/debug/Python-2.7.5/Objects/typeobject.c:5692
#27 0x00007fb2a3091e7f in type_call (type=<optimized out>, args=(), kwds=0x0) at /usr/src/debug/Python-2.7.5/Objects/typeobject.c:745
#28 0x00007fb2a303c073 in PyObject_Call (
    func=func@entry=<GeneratedProtocolMessageType(__module__='tensorflow.core.framework.tensor_pb2', TENSOR_CONTENT_FIELD_NUMBER=4, TENSOR_SHAPE_FIELD_NUMBER=2, _UpdateOneofState=<function at remote 0x318fc80>, MergeFromString=<function at remote 0x318f938>, dtype=<property at remote 0x3183af8>, __str__=<function at remote 0x318f5f0>, SerializeToString=<function at remote 0x318f7d0>, _SetListener=<function at remote 0x305bc80>, _oneofs=<member_descriptor at remote 0x2fd2128>, _cached_byte_size_dirty=<member_descriptor at remote 0x2fd2998>, string_val=<property at remote 0x3183db8>, _unknown_fields=<member_descriptor at remote 0x2fd2c68>, HasField=<function at remote 0x318f488>, _Modified=<function at remote 0x318fc08>, _extensions_by_name={}, __weakref__=<getset_descriptor at remote 0x2fd2b90>, DTYPE_FIELD_NUMBER=1, __init__=<function at remote 0x318c500>, double_val=<property at remote 0x3183d08>, scomplex_val=<property at remote 0x3183e10>, SCOMPLEX_VAL_FIELD_NUMBER=9, half_val=<property at remote 0x3183c58>, int_val=<property...(truncated), arg=arg@entry=(), kw=kw@entry=0x0) at /usr/src/debug/Python-2.7.5/Objects/abstract.c:2529
#29 0x00007fb2a30d034c in do_call (nk=<optimized out>, na=0, pp_stack=0x7fffd07e4810, 
    func=<GeneratedProtocolMessageType(__module__='tensorflow.core.framework.tensor_pb2', TENSOR_CONTENT_FIELD_NUMBER=4, TENSOR_SHAPE_FIELD_NUMBER=2, _UpdateOneofState=<function at remote 0x318fc80>, MergeFromString=<function at remote 0x318f938>, dtype=<property at remote 0x3183af8>, __str__=<function at remote 0x318f5f0>, SerializeToString=<function at remote 0x318f7d0>, _SetListener=<function at remote 0x305bc80>, _oneofs=<member_descriptor at remote 0x2fd2128>, _cached_byte_size_dirty=<member_descriptor at remote 0x2fd2998>, string_val=<property at remote 0x3183db8>, _unknown_fields=<member_descriptor at remote 0x2fd2c68>, HasField=<function at remote 0x318f488>, _Modified=<function at remote 0x318fc08>, _extensions_by_name={}, __weakref__=<getset_descriptor at remote 0x2fd2b90>, DTYPE_FIELD_NUMBER=1, __init__=<function at remote 0x318c500>, double_val=<property at remote 0x3183d08>, scomplex_val=<property at remote 0x3183e10>, SCOMPLEX_VAL_FIELD_NUMBER=9, half_val=<property at remote 0x3183c58>, int_val=<property...(truncated))
    at /usr/src/debug/Python-2.7.5/Python/ceval.c:4316
#30 call_function (oparg=<optimized out>, pp_stack=0x7fffd07e4810) at /usr/src/debug/Python-2.7.5/Python/ceval.c:4121
#31 PyEval_EvalFrameEx (
    f=f@entry=Frame 0x35b42f0, for file /home/heliangliang/tf/lib/python2.7/site-packages/google/protobuf/internal/python_message.py, line 432, in MakeSubMessageDefault (message=<AttrValue at remote 0x6fe0c80>), throwflag=throwflag@entry=0) at /usr/src/debug/Python-2.7.5/Python/ceval.c:2740
#32 0x00007fb2a30d41ad in PyEval_EvalCodeEx (co=<optimized out>, globals=<optimized out>, locals=locals@entry=0x0, args=<optimized out>, argcount=argcount@entry=1, kws=0x72e07a8, kwcount=0, defs=0x0, 
    defcount=0, closure=closure@entry=(<cell at remote 0x3196d70>, <cell at remote 0x3196da8>)) at /usr/src/debug/Python-2.7.5/Python/ceval.c:3330
```
"
5396,"tf.train.range_input_producer(epoch_size, shuffle=True) does not terminate","Hey guys,

While working on language modeling using PTB dataset  [(as shown in TensorFlow tutorial)](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py) I had an issue with `ptb_producer `[(see on StackOverflow)](http://stackoverflow.com/questions/40406469/tf-nn-embedding-lookup-does-nothing-blocking-the-execution-but-no-associated-cp).

Long story short, it turns out that `ptb_producer` never terminates.

To debug, I tried to 'manually' run `ptb_producer` with the code below.

```
import tensorflow as tf

learning_rate = 1.0
num_layers = 2
num_steps = 20
hidden_size = 2
epochs = 50
batch_size = 20
vocab_size = 10000

# Loading data
import tensorflow.models.rnn.ptb.reader as reader

ptb_data_path = '<path>/tensorflow/ptb_data/simple-examples/data/'
(train, valid, test, _) = reader.ptb_raw_data(ptb_data_path)

raw_data = train
name = None

# Exact content of PTBProducer
with tf.name_scope(name, ""PTBProducer"", [raw_data, batch_size, num_steps]):
    raw_data = tf.convert_to_tensor(raw_data, name=""raw_data"", dtype=tf.int32)

    data_len = tf.size(raw_data)
    batch_len = data_len // batch_size
    data = tf.reshape(raw_data[0 : batch_size * batch_len],
                      [batch_size, batch_len])

    epoch_size = (batch_len - 1) // num_steps
    assertion = tf.assert_positive(
        epoch_size,
        message=""epoch_size == 0, decrease batch_size or num_steps"")
    with tf.control_dependencies([assertion]):
        epoch_size = tf.identity(epoch_size, name=""epoch_size"")

    i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()
    x = tf.slice(data, [0, i * num_steps], [batch_size, num_steps])
    y = tf.slice(data, [0, i * num_steps + 1], [batch_size, num_steps])
```

And then running to find out where thing is getting into troubles
`sess = tf.Session()` then `sess.run(epoch_size)` gives `2323`



Running `sess.run(tf.train.range_input_producer(epoch_size, shuffle=True).dequeue())` just waits (it does not terminate nor induce CPU load, i.e. same problem than when I run the whole code).

In fact, even `queue = tf.train.range_input_producer(epoch_size, shuffle=True)` (which can be intermediate step for previous syntax) does nothing. There is the problem line, still don't know why

I am not sure how this issue could be related to be, thus it might be a bug.

# Config Information
- `tf.__version__` = '0.11.0rc2'
- python 3.5.2
- Ubuntu 16.04 
"
5394,Distributed training hangs,"As mentioned in #4651, during training with syncreplicasoptimizer, tensorflow must run into hanging(after thousands steps). This does not happen with simple network setup. 
Both workers and pses are still ""alive"", no errors/exceptions are reported. The saver thread keeps working.

Environment info
the cluster is set on 2 servers, one ps and one worker on each. And each worker works on 4 gpu cards.

Operating System:
Centos (customized)

Installed version of CUDA and cuDNN: 
CUDA 7.5
cnDNN 5.1

installed from source,  
build on branch r0.11, and r0.10

trace log after hanging
[ps0_pstack.txt](https://github.com/tensorflow/tensorflow/files/570595/ps0_pstack.txt)
[ps0_strace.txt](https://github.com/tensorflow/tensorflow/files/570597/ps0_strace.txt)
[ps1_pstack.txt](https://github.com/tensorflow/tensorflow/files/570598/ps1_pstack.txt)
[ps1_strace.txt](https://github.com/tensorflow/tensorflow/files/570602/ps1_strace.txt)
[worker0_pstack.txt](https://github.com/tensorflow/tensorflow/files/570601/worker0_pstack.txt)
[worker0_strace.txt](https://github.com/tensorflow/tensorflow/files/570600/worker0_strace.txt)
[worker1_pstack.txt](https://github.com/tensorflow/tensorflow/files/570596/worker1_pstack.txt)
[worker1_strace.txt](https://github.com/tensorflow/tensorflow/files/570599/worker1_strace.txt)










"
5393,Error in `/home/software/anaconda2/bin/python': invalid fastbin entry (free): 0x00007f2fa8023940,"**Tensorflow version: 0.11.0rc1 (compile from source)
OS: CentOS Linux release 7.0.1406 (Core) 64bit
model: models/inception**

I am training inception model from scratch following [this](https://github.com/tensorflow/models/tree/master/inception), but after about 11500 steps got this error:

```
...
...
2016-11-03 22:37:06.142819: step 11540, loss = 9.38 (66.9 examples/sec; 0.957 sec/batch)
2016-11-03 22:37:15.753609: step 11550, loss = 9.22 (67.4 examples/sec; 0.950 sec/batch)
2016-11-03 22:37:25.332004: step 11560, loss = 9.51 (65.6 examples/sec; 0.975 sec/batch)
*** Error in `/home/software/anaconda2/bin/python': invalid fastbin entry (free): 0x00007f2fa8023940 ***
======= Backtrace: =========
/lib64/libc.so.6(+0x7d19d)[0x7f315d7b919d]
/home/software/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0x248ff48)[0x7f314baa2f48]
/home/software/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0x244520f)[0x7f314ba5820f]
/home/software/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow19LocalRendezvousImpl4SendERKNS_10Rendezvous9ParsedKeyERKNS1_4ArgsERKNS_6TensorEb+0xf9)[0x7f314bb9e7f9]
/home/software/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow22IntraProcessRendezvous4SendERKNS_10Rendezvous9ParsedKeyERKNS1_4ArgsERKNS_6TensorEb+0xb4)[0x7f314ba57b74]
/home/software/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow6SendOp7ComputeEPNS_15OpKernelContextE+0x346)[0x7f314baa3736]
/home/software/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0x242ea59)[0x7f314ba41a59]
/home/software/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0x2422e30)[0x7f314ba35e30]
/home/software/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0x3c8)[0x7f314bc474a8]
/home/software/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x22)[0x7f314bc46c72]
/home/software/anaconda2/bin/../lib/libstdc++.so.6(+0xb4870)[0x7f3149153870]
/lib64/libpthread.so.0(+0x7df3)[0x7f315e20ddf3]
/lib64/libc.so.6(clone+0x6d)[0x7f315d8321ad]
======= Memory map: ========
00400000-00401000 r-xp 00000000 fd:02 34476856                           /home/software/anaconda2/bin/python2.7
00600000-00601000 rw-p 00000000 fd:02 34476856                           /home/software/anaconda2/bin/python2.7
0067e000-42ae4000 rw-p 00000000 00:00 0                                  [heap]
200000000-200100000 rw-s 1026d71000 00:05 221089                         /dev/nvidiactl
200100000-204100000 ---p 00000000 00:00 0 
204100000-204200000 rw-s f70ee2000 00:05 221089                          /dev/nvidiactl
204200000-204300000 ---p 00000000 00:00 0 
204300000-204400000 rw-s f75483000 00:05 221089                          /dev/nvidiactl
204400000-204500000 ---p 00000000 00:00 0 
204500000-204600000 rw-s 1014d38000 00:05 221089                         /dev/nvidiactl
204600000-208600000 ---p 00000000 00:00 0 
208600000-208700000 rw-s f7735a000 00:05 221089                          /dev/nvidiactl
208700000-208800000 ---p 00000000 00:00 0 
208800000-208900000 rw-s f7777d000 00:05 221089                          /dev/nvidiactl
208900000-208a00000 ---p 00000000 00:00 0 
208a00000-208b00000 rw-s f77eaa000 00:05 221089                          /dev/nvidiactl
208b00000-20cb00000 ---p 00000000 00:00 0 
...
...
```"
5392,AttributeError: 'module' object has no attribute 'learn',"In your first code example you have the following function tf.contrib.learn being called:

```
  run_config = tf.contrib.learn.estimators.RunConfig(
      num_cores=3, gpu_memory_fraction=0.6)
```

But if you look at the options you won't see learn....  

```
>>> dir(tf.contrib)
['__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'absolute_import', 'division', 'layers', 'print_function', 'util']
```
So you get the error:
```
Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""<stdin>"", line 6, in main
AttributeError: 'module' object has no attribute 'learn'
```
"
5391,[Feature Request] Loop_function argument for seq2seq models,"The RNN decoder has a [parameters](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L117) `loop_function` which allows to do some pre-processing on the output of the RNN before connecting the output on the next input.

That would be great to have this parameters for `embedding_rnn_seq2seq` and `embedding_rnn_decoder`. For now the only control we can have is no loop function at all when `feed_previous=False` or an argmax on the output called internally [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L274) .

The loop function parameters should be really useful to sample from the softmax distribution, instead of only taking the most likely output (as it is the case now with `feed_previous`) or to implement [scheduled sampling](https://arxiv.org/abs/1506.03099). 

For now the only solution is to re-create custom versions of `embedding_rnn_decoder` `embedding_rnn_seq2seq` just to change this parameters.
"
5390,"tf.variable_scope() does not allow variables to be defined for individual towers under a scope, in tensorflow/tensorflow/contrib/slim/python/slim/nets/inception_v3.py","I have been working with inception_v3 model from past few weeks and I came across this issue with the inception model defined under tensorflow/tensorflow/contrib/slim/python/slim/nets/inception_v3.py. 

This newer inception model cannot create variables for individual towers in a multi-gpu environment defined under a tower scope and fails with the following error:

**ValueError: Variable tower_1//Conv2d_1a_3x3/weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?**

The source of this error stems from defining logits with scope, as follows,

    logits = inception.inception_v3(inputs=images, num_classes=num_classes,
                                              is_training=is_training,
                                              dropout_keep_prob=dropout_rate,
                                              reuse=None,
                                              scope=scope)

The aforementioned error arises despite setting reuse=None. 

Suppose, scope isn't defined,

    logits = inception.inception_v3(inputs=images, num_classes=num_classes,
                                                    is_training=is_training,
                                                    dropout_keep_prob=dropout_rate)

logits layer then builds for multiple GPUs, in my training environment without ending up with a ValueError. The model was indeed designed to be defined without a scope? My investigation of the code showed that the source of this error arises from the following 2 lines within ..slim/nets/inception_v3.py file, 

       with tf.variable_scope(scope, 'InceptionV3', [inputs, num_classes],
                                                    reuse=reuse) as scope:
      
       with tf.variable_scope(scope, 'InceptionV3', [inputs]):

Tower variables are successfully created for the first tower (or a single GPU) whilst failing to creating the same variables for remaining towers (remainder of GPUs), with a 'scope' defined, the model ends up producing a ValueError. As one of the workarounds, I began using this model without defining a scope for tower creation in multi-gpu environment.

OPTIONAL WORKAROUND:

As an optional workaround, I figured changing the way the variables are defined by changing variable definition from **with tf.variable_scope** to  **with tf.name_scope**. This seems to have fixed the ValueError issue. I'm now able to define logits for 'n' GPU setting, with ""scope"" as a functional parameter (the towers and their respective variables are successfully created for each of the several available GPUs, in a multi-GPU setting). Also, as an added bonus I did observe that the ""graph"" view on tensorboard looked more organized and nicely segmented in contrast to the default code (default code is the one that made use of **with tf.variable_scope**). Please let me know if this is indeed an existing issue with this newer inception_v3 model or am I doing something wrong in the way I am defining my logits layer. 

I am confident, I am following the right steps because,

1. My model seems to train and test perfectly without a scope defined while using the default inception_v3.py to build the logits,
2. My model seems to train and test perfectly after replacing variable_scope with name_scope and passing individual tower scope as an argument to build the logits layer.
3. I am following the same methodology used in the following code, https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py to define my logits layers for multiple towers in the tower_loss function of my train file.

Any inputs would be much appreciated,"
5389,[minor enhancement] Absolute vs. Relative import,"I am raising a question if absolute imports should be changed to relative -- even if not in all the files, but at least in the files that have to be grouped together.
According to [PEP 328](https://www.python.org/dev/peps/pep-0328/#rationale-for-relative-imports):
> ... the most important [usage case ...] is being able to rearrange the structure of large packages without having to edit sub-packages. In addition, a module inside a package can't easily import itself without relative imports.

I understand that absolute imports help avoid ""shadowing"" of the modules/methods with the same names, but if the naming convention of the relative imports is enforced to be protected (`_name`), the problem could be mitigated."
5383,GraphDef cannot be larger than 2GB using input pipelines,"_ValueError: GraphDef cannot be larger than 2GB._

I'm not loading my data into a constant. I'm using an input pipeline to prefetch small batches. My graph works with cifar10 but if I use my SVHN input pipeline I get the error posted above. Both input pipeline scripts are virtually the same. How can it be that my data becomes part of the graph?

### Environment info
CUDA 8.0.27
ccuDNN 5.1.5
Tensorflow 0.11 (manually compiled)
bazel 0.3.2
Nvidia 1080 GTX

### What other attempted solutions have you tried?
cifar10 input pipeline works, but svhn gives 2GB error

A working but slim version of the main script
```
import tensorflow as tf

from libs.components import conv2d, batch_norm, flatten, dense
from datasets.cifar10 import cifar10_data
from datasets.svhn import svhn_data

## ----------------------------------------------------------------------------
## CONFIGURATION
BATCH_SIZE = 128
LOGS_PATH = ""/home/chuck/MyStuff/cnn_test/logs/InitialTests/4/""
EPOCHS = 300  # max number of epochs if the network never converges
learning_rate = 0.01

## ----------------------------------------------------------------------------
## DATA INPUT
#data = cifar10_data(batch_size=BATCH_SIZE)
data = svhn_data(batch_size=BATCH_SIZE)

with tf.device('/cpu:0'):
  train_image_batch, train_label_batch = data.build_train_data_tensor(shuffle=True)
  test_image_batch, test_label_batch = data.build_test_data_tensor(shuffle=False)

NUMBER_OF_CLASSES = data.NUMBER_OF_CLASSES
IMG_SIZE = data.IMAGE_SIZE
NUM_CHANNELS = data.NUM_OF_CHANNELS
TRAIN_SET_SIZE = data.TRAIN_SET_SIZE
TEST_SET_SIZE = data.TEST_SET_SIZE
TRAIN_BATCHES_PER_EPOCH = int(TRAIN_SET_SIZE / BATCH_SIZE)  # only used for training

## ----------------------------------------------------------------------------
## MODEL STRUCTURE
is_training = tf.placeholder(tf.bool, name='is_training')


def conv_block(data, n_filter, scope, stride=1):
  """"""An ConvBlock is a repetitive composition used in the model.""""""
  with tf.variable_scope(scope):
    conv = conv2d(data, n_filter, ""conv"",
                  k_h=3, k_w=3,
                  stride_h=stride, stride_w=stride,
                  initializer=tf.random_normal_initializer(stddev=0.01),
                  bias=True,
                  padding='SAME')
    norm = batch_norm(conv, n_filter, is_training, scope=""bn"")
    relu = tf.nn.relu(norm)

    conv2 = conv2d(relu, n_filter, ""conv2"",
                   k_h=3, k_w=3,
                   stride_h=stride, stride_w=stride,
                   initializer=tf.random_normal_initializer(stddev=0.01),
                   bias=True,
                   padding='SAME')
    norm2 = batch_norm(conv2, n_filter, is_training, scope=""bn2"")
    relu2 = tf.nn.relu(norm2)

    conv3 = conv2d(relu2, n_filter, ""conv3"",
                   k_h=3, k_w=3,
                   stride_h=stride, stride_w=stride,
                   initializer=tf.random_normal_initializer(stddev=0.01),
                   bias=True,
                   padding='SAME')
    norm3 = batch_norm(conv3, n_filter, is_training, scope=""bn3"")
    relu3 = tf.nn.relu(norm3)

    return relu3


def model(x):
  """"""Defines the CNN architecture and returns its output tensor.""""""
  block1 = conv_block(x, 64, ""block1"")
  pool1 = tf.nn.max_pool(block1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=""SAME"")

  block2 = conv_block(pool1, 128, ""block2"")
  pool2 = tf.nn.max_pool(block2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=""SAME"")

  block3 = conv_block(pool2, 256, ""block3"")
  pool3 = tf.nn.max_pool(block3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=""SAME"")

  flat = flatten(pool3)

  dense1 = dense(flat, 4096, is_training, tf.nn.relu, scope=""dense1"", dropout=True,
                 initializer=tf.random_normal_initializer(stddev=0.01))
  dense2 = dense(dense1, 4096, is_training, tf.nn.relu, scope=""dense2"", dropout=True,
                 initializer=tf.random_normal_initializer(stddev=0.01))
  dense3 = dense(dense2, 4096, is_training, tf.nn.relu, scope=""dense3"", dropout=True,
                 initializer=tf.random_normal_initializer(stddev=0.01))
  dense6 = dense(dense3, NUMBER_OF_CLASSES, is_training, tf.nn.relu, scope=""dense6"", dropout=False,
                 initializer=tf.random_normal_initializer(stddev=0.01))
  return dense6


## ----------------------------------------------------------------------------
## LOSS AND ACCURACY
with tf.variable_scope(""model""):
  batch_size = tf.placeholder(tf.float32, name=""batch_size"")

  input_image_batch = tf.placeholder(tf.float32, shape=[BATCH_SIZE, IMG_SIZE, IMG_SIZE, NUM_CHANNELS],
                                     name=""input_image_batch"")
  input_label_batch = tf.placeholder(tf.float32, shape=[None, NUMBER_OF_CLASSES], name=""input_label_batch"")

  logits = model(input_image_batch)

with tf.variable_scope(""loss""):
  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(
    logits,
    tf.cast(input_label_batch, tf.float32),
    name=""cross-entropy"")
  loss = tf.reduce_mean(cross_entropy, name='loss')

with tf.variable_scope(""accuracy""):
  top_1_correct = tf.nn.in_top_k(logits, tf.argmax(input_label_batch, 1), 1)
  top_n_correct = tf.nn.in_top_k(logits, tf.argmax(input_label_batch, 1), 3)

predictions = tf.argmax(logits, 1)
label_batch_id = tf.argmax(input_label_batch, 1)

## ----------------------------------------------------------------------------
## OPTIMIZER
global_step = tf.get_variable('global_step', [],
                              initializer=tf.constant_initializer(0),
                              trainable=False)
lr = tf.placeholder(tf.float32, name=""learning_rate"")
train_op = tf.train.MomentumOptimizer(lr, 0.9).minimize(loss, global_step=global_step)

## ----------------------------------------------------------------------------
## SUMMARIES
summary_op = tf.merge_all_summaries()

## ----------------------------------------------------------------------------
## INITIALIZATION
init_op = tf.initialize_all_variables()
writer = tf.train.SummaryWriter(LOGS_PATH, graph=tf.get_default_graph())
saver = tf.train.Saver()
sess = tf.Session()

# initialize queue threads
coord = tf.train.Coordinator()
threads = tf.train.start_queue_runners(coord=coord, sess=sess)

# initialize variables
sess.run(init_op)

## ----------------------------------------------------------------------------
## HELPER FUNCTIONS
def next_feed_dic(image_batch, label_batch, train=True):
  """"""Fetches a mini-batch of images and labels and builds a feed-dictonary""""""
  with tf.device('/cpu:0'):
    curr_image_batch, curr_label_batch = sess.run([image_batch, label_batch])

    feed_dict = {
      input_image_batch: curr_image_batch,
      input_label_batch: curr_label_batch,
      batch_size: curr_image_batch.shape[0],
      is_training.name: train,
      lr.name: learning_rate
    }
    return feed_dict

## ----------------------------------------------------------------------------
## PERFORM TRAINING

# train cycles
for j in range(EPOCHS):
  print(""epoch "", j)
  print(""epoch.batches curr_loss (avg_loss)"")
  for i in range(TRAIN_BATCHES_PER_EPOCH):
    feed_dict = next_feed_dic(train_image_batch, train_label_batch, train=True)
    _, curr_loss, summary, step = sess.run([train_op, loss, summary_op, global_step], feed_dict=feed_dict)

    if i % 30 == 0:
      print(""{:3d}.{:03d} {:.5f}"".format(j, i, curr_loss))

print(""done"")
```

The cifar10 input pipeline (this one works fine)
```
import tensorflow as tf

from utils import cifar10
from tensorflow.python.framework import ops

class cifar10_data:
  """"""
  Downloads the CIFAR10 dataset and creates an input pipeline ready to be fed into a model.

  - Reshapes flat images into 32x32
  - converts [0 1] to [-1 1]
  - shuffles the input
  - builds batches
  """"""
  NUM_THREADS = 8
  NUMBER_OF_CLASSES = 10

  TRAIN_SET_SIZE = 50000
  TEST_SET_SIZE =  10000
  IMAGE_SIZE = 32
  NUM_OF_CHANNELS = 3

  def __init__(self, batch_size):
    """""" Downloads the cifar10 data if necessary. """"""
    self.batch_size = batch_size
    cifar10.maybe_download_and_extract()

  def build_train_data_tensor(self, shuffle=False, augmentation=False):
    images, _, targets = cifar10.load_training_data()
    return self.__build_generic_data_tensor(images,
                                            targets,
                                            shuffle,
                                            augmentation)

  def build_test_data_tensor(self, shuffle=False, augmentation=False):
    images, _, targets = cifar10.load_test_data()
    return self.__build_generic_data_tensor(images,
                                            targets,
                                            shuffle,
                                            augmentation)

  def __build_generic_data_tensor(self, raw_images, raw_targets, shuffle, augmentation):
    """""" Creates the input pipeline and performs some preprocessing. """"""

    images = ops.convert_to_tensor(raw_images)
    targets = ops.convert_to_tensor(raw_targets)

    set_size, width, height, channels = raw_images.shape

    images = tf.reshape(images, [set_size, width, height, channels])
    image, label = tf.train.slice_input_producer([images, targets], shuffle=shuffle)

    # Data Augmentation
    if augmentation:
      # TODO
      # make sure after further preprocessing it is [0 1]
      pass

    # convert the given [0, 1] to [-1, 1]
    image = tf.sub(image, 0.5)
    image = tf.mul(image, 2.0)

    images_batch, labels_batch = tf.train.batch([image, label], batch_size=self.batch_size, num_threads=self.NUM_THREADS)

    return images_batch, labels_batch
```

The not working SVHN input pipeline (virtually the same input pipeline script)
```
import tensorflow as tf

from utils import svhn
from tensorflow.python.framework import ops

class svhn_data:
  """"""
  Downloads the SVHN dataset and creates an input pipeline ready to be fed into a model.

  - Reshapes flat images into 32x32
  - converts [0 1] to [-1 1]
  - shuffles the input
  - builds batches
  """"""
  NUM_THREADS = 8
  NUMBER_OF_CLASSES = 100

  TRAIN_SET_SIZE = 73257
  TEST_SET_SIZE =  26032
  IMAGE_SIZE = 32
  NUM_OF_CHANNELS = 3

  def __init__(self, batch_size):
    """""" Downloads the cifar100 data if necessary. """"""
    self.batch_size = batch_size
    svhn.download_data()

  def build_train_data_tensor(self, shuffle=False, augmentation=False):
    images, _, targets = svhn.load_training_data()
    return self.__build_generic_data_tensor(images,
                                            targets,
                                            shuffle,
                                            augmentation)

  def build_test_data_tensor(self, shuffle=False, augmentation=False):
    images, _, targets = svhn.load_test_data()
    return self.__build_generic_data_tensor(images,
                                            targets,
                                            shuffle,
                                            augmentation)

  def __build_generic_data_tensor(self, raw_images, raw_targets, shuffle, augmentation):
    """""" Creates the input pipeline and performs some preprocessing. """"""

    images = ops.convert_to_tensor(raw_images)
    targets = ops.convert_to_tensor(raw_targets)

    set_size, width, height, channels = raw_images.shape

    images = tf.reshape(images, [set_size, width, height, channels])
    image, label = tf.train.slice_input_producer([images, targets], shuffle=shuffle)

    # Data Augmentation
    if augmentation:
      # TODO
      # make sure after further preprocessing it is [0 1]
      pass

    # convert the given [0, 1] to [-1, 1]
    image = tf.sub(image, 0.5)
    image = tf.mul(image, 2.0)

    images_batch, labels_batch = tf.train.batch([image, label],
                                                batch_size=self.batch_size,
                                                num_threads=self.NUM_THREADS)

    return images_batch, labels_batch
```"
5381,Documentation For The New Version of Histogram on TensorBoard,"Hello~

I'm trying to interpret the new version of the histogram and it looks like the x-axis represents the value/bin, y-axis represent the step/time, and **z-axis represents the density since it is a continuous number. In addition, the color represents the standard deviation??** 

Is my interpretation correct? If so, I can help putting up the documentation for the new histogram tab.

Thanks!

NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5380,'tensorflow/core/public/session.h' file not found,"I didn't find anything about this problem. I'm creating the python package from the source with bazel, the commands used are the same of the official guide in the section [create pip package](https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#create-the-pip-package-and-install).

The file *.whl* generated is working but doesn't have some include files that I use in a new op created in C++. The missing files are **session_options.h** and **session.h** which, however, are present in the official *.whl* of tensorflow that you can download (the binary package pre-compiled).

To add those files I had to insert some requirements in *tensorflow/core/BUILD*:

```

---
 tensorflow/core/BUILD | 5 +++++
 1 file changed, 5 insertions(+)

diff --git a/tensorflow/core/BUILD b/tensorflow/core/BUILD
index 79546cc..7d9e9a2 100644
--- a/tensorflow/core/BUILD
+++ b/tensorflow/core/BUILD
@@ -214,6 +214,9 @@ cc_library(
         ""platform/strong_hash.h"",
         ""platform/thread_annotations.h"",
         ""platform/types.h"",
+        ""public/version.h"",
+        ""public/session.h"",
+        ""public/session_options.h"",
     ],
     visibility = [""//visibility:public""],
     deps = [
@@ -299,6 +302,8 @@ tf_cuda_library(
         ""framework/type_traits.h"",
         ""framework/types.h"",
         ""public/version.h"",
+        ""public/session.h"",
+        ""public/session_options.h"",
         ""util/bcast.h"",
         ""util/cuda_kernel_helper.h"",
         ""util/device_name_utils.h"",
-- 
2.10.2
```

Is it normal or I missed some configuration during the building? I could not fix it without this additions.

### Environment info
Operating System: macOS Sierra (10.12.1)

Installed version of CUDA and cuDNN: NO CUDA

Source:

1. The commit hash: ""eaa9dde98d95f843ad1d3d0f5956693991372e4a""
2. Bazel version:
```
Build label: 0.3.2-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Sat Oct 8 08:02:20 2016 (1475913740)
Build timestamp: 1475913740
Build timestamp as int: 1475913740
```

### Example to test

If you try to import a graph as you can see in the [guide](https://www.tensorflow.org/versions/r0.11/api_docs/cc/index.html) you need to require the header: `#include ""tensorflow/core/public/session.h""`.


### Logs or other output that would be helpful
```
... fatal error: 'tensorflow/core/public/session.h' file not found
#include ""tensorflow/core/public/session.h""
         ^
1 error generated.
make: *** [...] Error 1
```
"
5379,C++ SetDefaultDevice does not appear to work properly,"I'm using a simple C++ session that works fine otherwise. Trying to use `tensorflow::graph::SetDefaultDevice` to pin on either CPU or GPU (per id) does not appear to work:

- without `SetDefaultDevice`:

```
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 1:   Y Y   
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus i
d: 0000:02:00.0)  
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus i
d: 0000:03:00.0) 
```
all goes well beyond this point.

- now trying to pin on `GPU0`:
```
tensorflow::graph::SetDefaultDevice(""/gpu:0"", &graph_def);
```
yields
```
E tensorflow/core/common_runtime/direct_session.cc:132] Invalid argument: Could not parse entry in 'visible_device_list': '/gpu:0'.  visible_device_list = /gpu:0
```
Same with `/cpu:0`, no surprise.

- looking at https://github.com/tensorflow/tensorflow/blob/f7ec99516ce0e0937e0b865e90aa02c748cd36c6/tensorflow/core/common_runtime/gpu/gpu_device.cc#L808 it seems the code is rather looking for an int ? Trying it out:

```
tensorflow::graph::SetDefaultDevice(""0"",&graph_def);
```
yields
```
I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0)
E tensorflow/core/common_runtime/gpu/process_state.cc:108] Invalid allocator type: 0
```

Am I doing something wrong or has something changed (maybe due to 3e8c4fd7403659ec32b9fec90a78831043aa0786 ?)

The tutorial at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/tutorials/example_trainer.cc#L104 still calls on `SetDefaultDevice` the way I tried to use it, this seems odd :)
"
5378,Issue Linking of rule '//tensorflow/python:_pywrap_tensorflow.so' failed while building,"I have added a new Op kernel in ""user_ops"" folder of ""tensorflow"" source directory. I have also written a test to verify if the Op is successfully implemented. But while building and testing my Op kernel using the command, ""bazel test //tensorflow/user_ops:xxxx_test"", I am getting the following error:
Linking of rule '//tensorflow/python:_pywrap_tensorflow.so' failed: gcc failed: error executing command /usr/bin/gcc -shared -o bazel-out/local-py3-fastbuild/bin/tensorflow/python/_pywrap_tensorflow.so -Wl,--version-script tensorflow/tf_version_script.lds -pthread -Wl,-no-as-needed -B/usr/bin -B/usr/bin ... (remaining 9 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.  
I am unable to build and test my new Op kernel. Please help in resolving this issue as I am blocked because of this error."
5377,How to slice a tensor for custom loss?,"Trying to implement a custom loss function that works as following in Theano:
```
        def sparse_sqe(y_true, y_pred):
            ix = y_true.nonzero()
            return (y_pred[ix] - y_true[ix]) ** 2
```
e.g. y_true = [[0, 0, 0, 0, 5], [9, 0, 0, 0, 0]]
y_pred = [[0.2, 0.1, 0.2, 0, 4.8], [9.5, 0.3, 0.1, 0, 0]]

would return ([4.8, 9.5] - [5, 9]) ** 2 = 0.29
The loss should only be calculated for the y_pred values at the index of the nonzero y_true values.

I tried

```
z = tf.constant(0, tf.float32)
ix = tf.where(tf.not_equal(y_true, z))
(y_pred[ix] - y_true[ix]) ** 2
```
but you cannot slice like a numpy array. I also tried tf.gather, but this applies to a collection of tensors, and it will slice the vectors, instead of the elements of those vectors.



Any help would be greatly appreciated."
5375,Error cloning linenoise,"This is a helpful note for anyone who might come across the following error, building tensorflow on arch linux (I may also have some funky ssh-agent settings causing this issue):


```
ERROR: /home/user/testing/tensorflow/tensorflow/tools/tfprof/BUILD:22:1: no such package '@linenoise//': Error cloning repository: ssh://git@github.com/antirez/linenoise/archive/1.0.tar.gz: Auth cancel caused by ssh://git@github.com/antirez/linenoise/archive/1.0.tar.gz: Auth cancel caused by Auth cancel and referenced by '//tensorflow/tools/tfprof:tfprof'.
ERROR: /home/user/testing/tensorflow/tensorflow/tools/tfprof/BUILD:22:1: no such package '@linenoise//': Error cloning repository: ssh://git@github.com/antirez/linenoise/archive/1.0.tar.gz: Auth cancel caused by ssh://git@github.com/antirez/linenoise/archive/1.0.tar.gz: Auth cancel caused by Auth cancel and referenced by '//tensorflow/tools/tfprof:tfprof'.
ERROR: Evaluation of query ""deps((//tensorflow/... union @bazel_tools//tools/jdk:toolchain))"" failed: errors were encountered while computing transitive closure.
```

I was able to remedy this problem by changing the block for linenoise `tensorflow/workspace.bzl:181` to:

```
  native.new_local_repository(
    name = ""linenoise"",
    path = ""/path/to/local_repository"",
    build_file = str(Label(""//:linenoise.BUILD"")),
  )
```
"
5374,Configure requires user interaction in r0.11,"The ./configure in the r0.11 branch requires user interaction if there is more than one PYTHON_LIBRARY_PATH found by the `util/python/python_config.sh` script. In r0.10 it was possible to run a ./configure without user interaction. Furthermore, in the PR #5135 the script was changed to make it possible to directly specify the PYTHON_LIBRARY_PATH to prevent the need of user interaction.

I think this fix should also be merged into to the r0.11 branch to ensure tensorflow can be configured/build without user interaction (when there are multiple pythons installed). "
5373,tf.assign_from_checkpoint_fn needs write_version argument to pass to tf.Saver,"Hi,
according to [slim_walkthrough.ipython](https://github.com/tensorflow/models/blob/master/slim/slim_walkthough.ipynb), when we load from checkpoints we can use `assign_from_checkpoint_fn` function.

But (maybe i thought) inside of `slim.assign_from_checkpoint_fn`, it create `tf.Saver` but there is no `write_version` args. And in my case, I have some ckpt with saver V2 but default saver version is 1 and `slim.assign_from_checkpoint_fn` doesn't have any code about this version issue so I can't load model using this function.

Any clue or plan to handle this issue?
Thanks."
5372,Option to check every write in TFRecordWriter.,"Referencing this [post](http://stackoverflow.com/questions/40370866/tf-corrupted-record-while-training/40396754#40396754) on stackoverflow.

There may be situations when we write huge databases of images into a TFRecord (or at least a few TFRecords). It would be good if there's an option to check every write to prevent such cases of corrupted data happening during training.

@allenlavoie "
5371,Is tensorflow threadsafe in feedforward prediction of trained models.,"#### Question:

I'ved trained a text classification model using tensorflow and also wrapped Java interface for feedward prediction. And I'm wondering if tensorflow is threadsafe in feedforward prediction. 

Thanks"
5369,Support reading data from HDFS with Kerberos,"
Now TensorFlow and read/write data from HDFS cluster. But we have tested that it doesn't support HDFS with Kerberos. The log looks like this.

![screen shot 2016-11-03 at 15 25 37](https://cloud.githubusercontent.com/assets/2715000/19958692/3415c576-a1dc-11e6-906b-7e4d4af63574.png)

### Environment info

Operating System: CentOS 7.0
TensorFlow Version: 0.11.0rc1

Refer to https://github.com/tensorflow/tensorflow/issues/5316"
5366,"Does tensorflow support structure of nested sequence like Paddle? Like ""each timestep of the input sequence is also a sequence""?","For example, 

X=[[x11, x12, x13], [x21, x22], [x31, x32, x33, x34]], Y=[y1, y2, y3]. 
This way the initial state of the sequence could be initialized to **0** vector.

Thanks"
5363,Convert retrained data into .pb format for ios camera example?,"I retrained image data using the tutorial at ((https://www.tensorflow.org/versions/r0.9/how_tos/image_retraining/index.html)) I did all the steps until `bazel build tensorflow/examples/image_retraining:retrain`. I was wondering how to turn this image training data into a .pb file that I can use in the ios camera example.

Thank you for your help!"
5362,CUDA_TOO_MANY_PEERS exception when launching on p2.16xlarge on aws,"This issue is identical to the issue discussed [here](https://devtalk.nvidia.com/default/topic/970010/cuda-peer-resources-error-when-running-on-more-than-8-k80s-aws-p2-16xlarge-/).

When launching tensorflow to train on more than 8 gpu instances, tensorflow will cause a CUDA_TOO_MANY_PEERS error in the driver. The Tesla K80 shows up as 2 gpu instances internally so even though the p2.16xlarge technically only has 8 gpus it looks to the driver like it has 16. It seems that the cuda p2p system limits any gpu to only connect to a maximum 8 other gpus via p2p, but when the graph is launched, tensorflow (quite understandably) attempts to create a p2p connection between every gpu in the graph.

Is there some way to disable p2p or is there a way via intelligent graph construction to limit the number of connections any given gpu requires, or even use a resource pool for gpu p2p connections?

```bash
ubuntu@host:~/workspace/nn$ nvidia-smi
Wed Nov  2 20:53:20 2016       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 361.93.02              Driver Version: 361.93.02                 |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 0000:00:0F.0     Off |                    0 |
| N/A   45C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           Off  | 0000:00:10.0     Off |                    0 |
| N/A   39C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           Off  | 0000:00:11.0     Off |                    0 |
| N/A   50C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           Off  | 0000:00:12.0     Off |                    0 |
| N/A   43C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla K80           Off  | 0000:00:13.0     Off |                    0 |
| N/A   50C    P8    57W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla K80           Off  | 0000:00:14.0     Off |                    0 |
| N/A   41C    P8    70W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla K80           Off  | 0000:00:15.0     Off |                    0 |
| N/A   51C    P0    56W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla K80           Off  | 0000:00:16.0     Off |                    0 |
| N/A   43C    P0    71W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   8  Tesla K80           Off  | 0000:00:17.0     Off |                    0 |
| N/A   46C    P0    56W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   9  Tesla K80           Off  | 0000:00:18.0     Off |                    0 |
| N/A   39C    P0    71W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|  10  Tesla K80           Off  | 0000:00:19.0     Off |                    0 |
| N/A   49C    P0    58W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|  11  Tesla K80           Off  | 0000:00:1A.0     Off |                    0 |
| N/A   40C    P0    73W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|  12  Tesla K80           Off  | 0000:00:1B.0     Off |                    0 |
| N/A   49C    P0    58W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|  13  Tesla K80           Off  | 0000:00:1C.0     Off |                    0 |
| N/A   40C    P0    70W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|  14  Tesla K80           Off  | 0000:00:1D.0     Off |                    0 |
| N/A   49C    P0    60W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|  15  Tesla K80           Off  | 0000:00:1E.0     Off |                    0 |
| N/A   41C    P0    69W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
ubuntu@host:~/workspace/nn$ python3 deploy_local.py 
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:0f.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3bb3f120
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 1 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:10.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3bf86790
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 2 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:11.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3c3cf0c0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 3 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:12.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x4a7fe070
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 4 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:13.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x4ac4dd20
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 5 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:14.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x4b0a16a0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 6 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:15.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x4b4f9220
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 7 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:16.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x4b9545d0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 8 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:17.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x4bdb3920
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 9 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:18.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x4c216790
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 10 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:19.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x4c67d450
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 11 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1a.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x4cae8580
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 12 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1b.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x28999af0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 13 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1c.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x28e0bf00
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 14 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1d.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x29282290
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 15 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1e.0
Total memory: 11.17GiB
Free memory: 11.11GiB
E tensorflow/core/common_runtime/direct_session.cc:132] Internal: Internal: failed to enable peer access from 0x1c961680 to 0x18f1ac60: CUDA_ERROR_TOO_MANY_PEERS
Traceback (most recent call last):
  File ""deploy_local.py"", line 39, in <module>
    n_test_batches=4,
  File ""/home/ubuntu/workspace/nn/nn/model/network.py"", line 271, in train
    test_steps=test_steps, save_steps=save_steps, load_all=load_all, debug=debug, **kwargs)
  File ""/home/ubuntu/workspace/nn/nn/train/train.py"", line 86, in train_model
    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options)) as sesh:
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py"", line 1138, in __init__
    super(Session, self).__init__(target, graph, config=config)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py"", line 502, in __init__
    self._session = tf_session.TF_NewSession(opts, status)
  File ""/usr/lib/python3.4/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors.InternalError: Failed to create session.
```"
5361,"Object of type 'path' has no field ""realpath"".","i get the latest code, installed **bazel 0.3.2**. but still meet errors when run **./configure** for build from source.

root@scopephotos:/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow# ./configure 
/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow /home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow
Please specify the location of python. [Default is /usr/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] n
No Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

/usr/local/lib/python2.7/dist-packages
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5
Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify the Cudnn version you want to use. [Leave empty to use system default]: **5.1.3**
Please specify the location where cuDNN 5.1.3 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
.
**ERROR:** com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/third_party/gpus/cuda_configure.bzl"", line 517
		_create_cuda_repository(repository_ctx)
	File ""/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/third_party/gpus/cuda_configure.bzl"", line 432, in _create_cuda_repository
		_cuda_toolkit_path(repository_ctx, cuda_version)
	File ""/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/third_party/gpus/cuda_configure.bzl"", line 148, in _cuda_toolkit_path
		str(repository_ctx.path(cuda_toolkit...)
	File ""/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/third_party/gpus/cuda_configure.bzl"", line 148, in str
		repository_ctx.path(cuda_toolkit_path).realpath
**Object of type 'path' has no field ""realpath"".**
"
5360,how to build iOS static library using bazel,"I'm working with tag `v0.11.0.rc2`.

Following the instructions here https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/makefile/README.md I have successfully built tensorflow for iOS using the makefile approach.  However, I have wondered about the first line in the readme
>The recommended way to build TensorFlow from source is using the Bazel open-source build system

I can't find any targets in the bazel BUILD files that would build `libprotobuf-lite.a`, `libprotobuf.a`, and `libtensorflow-core.a` that the makefile approach builds.

Does anyone know how to build the static libs for iOS using Bazel?  Is there a reason/advantage to do so?"
5357,Bazel fails to clean,"Bazel fails to clean with following message
```
WARNING: Output base '/home/username/.cache/bazel/_bazel_username/acf2af86672e1552dfd6edd47d54a950' is on NFS. This may lead to surprising failures and undetermined behavior.
.
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
ERROR: /home/username/.cache/bazel/_bazel_username/acf2af86672e1552dfd6edd47d54a950/server (Directory not empty).
```
Replacement of `bazel clean --expunge` with `bazel clean --expunge_async` [here](https://github.com/tensorflow/tensorflow/blob/master/configure#L25) fixes the issue.
### Environment info
Operating System:
Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
$ ls -l /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcud*
-rw-r--r-- 1 root root 558720 Sep 15 02:02 /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Sep 15 02:05 /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root     19 Sep 15 02:05 /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root 415432 Sep 15 02:02 /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.44
-rw-r--r-- 1 root root 775162 Sep 15 02:02 /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
``` 

1. The commit hash (`git rev-parse HEAD`)
```
$ git rev-parse HEAD
7443479c9261b893d00c923bf53d924bbae9bc64
```
2. The output of `bazel version`
```
$ bazel version
WARNING: Output base '/home/username/.cache/bazel/_bazel_chaimb/acf2af86672e1552dfd6edd47d54a950' is on NFS. This may lead to surprising failures and undetermined behavior.
Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110
```
"
5354,failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED on a AWS p2.xlarge instance,"Hi,

I have been running docker images on a **Centos 7.0 AWS p2.xlarge** instance. I have previously installed on it:
CUDA: **cuda-repo-rhel7-8.0.44-1.x86_64.rpm**
NVIDIA **drivers 361.42**

I have also installed **nvidia-docker** [following instructions](https://github.com/NVIDIA/nvidia-docker)

I have successfully run all notebooks from Docker images (as fas as I've tried tensorflow/tensorflow:latest-devel-gpu and tensorflow/tensorflow:latest-gpu):

Running **tensorflow** version within the docker containter: **0.11.0rc2**
**Bazel** version: Build label: **0.3.2**
root@de73edc73418:~# nvidia-smi -l
Wed Nov  2 12:02:54 2016       
+------------------------------------------------------+                       
| NVIDIA-SMI 361.42     Driver Version: 361.42         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 0000:00:1E.0     Off |                    0 |
| N/A   57C    P0    70W / 149W |  10948MiB / 11519MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

However when I try to launch a [Single GPU computing example with tensorflow](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/5_MultiGPU/multigpu_basics.py) and get the following error:

`I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_3: /job:localhost/replica:0/task:0/gpu:0
MatMul_4: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_4: /job:localhost/replica:0/task:0/gpu:0
MatMul_5: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_5: /job:localhost/replica:0/task:0/gpu:0
MatMul_6: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_6: /job:localhost/replica:0/task:0/gpu:0
MatMul_7: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_7: /job:localhost/replica:0/task:0/gpu:0
MatMul_8: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_8: /job:localhost/replica:0/task:0/gpu:0
MatMul_9: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_9: /job:localhost/replica:0/task:0/gpu:0
AddN: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:819] AddN: /job:localhost/replica:0/task:0/cpu:0
E tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
W tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support
E tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
W tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support
`

Not sure if is something related to Nvidia drivers, OS or some library mismatch. Any idea?
"
5352,Missing information in inception_train.py,"
I wanted to fine-tune inception network using my dataset, which is way too big. Converting to TFRecords format is not the best option because it uses a lot of GB in hard disk. I used a placeholder for images and a placeholder for labels and here https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py
I converted the command in line 336 in    _, loss_value = sess.run([train_op, loss], feed_dict={images_placeholder: images , labels_placeholder: labels}). I think I achieved fine-tuning, so you could add it to the documentation. 
                              
                              "
5351,Installing Tensor flow on multiple machines (on GCP).,"i am trying to install tensorflow on two machines(2 instances on Google Cloud Platform) how i can do that?
or it is not supported only thing is you can write programs in tensorflow in distributed manner. "
5350,Sampled and regular softmax should use the same weight matrix shape,"As it is now, the softmax samplers [sampled_softmax_loss](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#sampled_softmax_loss) and [nce_loss](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#nce_loss) require a `|C|x|H|` weight matrix, while the logits from [softmax](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#softmax) come from a `|H|x|C|`-sized one. This discrepancy is problematic on two levels:
1. it makes for an inconsistent API;
1. it results in a performance hit, because if one uses a sampled method for training and softmax for testing (as is usual when the number of classes is huge), one has to call `tf.transpose` somewhere, which does not work well with sparse input (see #4138).

In my case, I can choose between 21150 / 18300 or 22350 / 11900 train / test wps, depending on whether the `tf.transpose` happens on the sampled softmax loss during training or on regular softmax during testing. In either case, the performance is suboptimal.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

As mentioned above, #4138. The fix there, however, is in the client code, not the API in question.

### Environment info
Operating System: `Linux 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt20-1+deb8u3 (2016-01-17) x86_64 GNU/Linux`

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
`/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44`; I don't have cuDNN at the moment

If installed from binary pip package, provide:

1. A link to the pip package you installed: the official GPU install for Python 3.4
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`: `0.11.0rc1`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I cannot do that right now, but one can experiment with e.g. the PTB example.

### What other attempted solutions have you tried?
N/A"
5349,Include libcurl into the bazel build,"Currently tensorflow serving project will build gcs_file_system target which may fail, with the following message:
```
ERROR: /home/heliangliang/work/tensorflow/tensorflow/core/platform/cloud/BUILD:49:1: C++ compilation of rule '//tensorflow/core/platform/cloud:http_request' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-canonical-system-headers ... (remaining 100 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from ./tensorflow/core/platform/cloud/http_request.h:22:0,
                 from tensorflow/core/platform/cloud/http_request.cc:16:
tensorflow/core/platform/cloud/http_request.cc: In member function 'virtual tensorflow::Status tensorflow::HttpRequest::Init()':
tensorflow/core/platform/cloud/http_request.cc:219:30: error: 'CURL_HTTP_VERSION_2_0' was not declared in this scope
                              CURL_HTTP_VERSION_2_0);
```

The reason is gcs_file_system dependens on libcurl 7.33.0+, and this is higher than the default package versions of many Linux distros.

It's better to include libcurl as bazel build library instead of using the system one."
5347,Change http://ufpr.dl.sourceforge.net links for http_archive to another more stable one,"TensorFlow build dependens on external links, for example:
```python
  native.new_http_archive(                                                      
    name = ""gif_archive"",                                                       
    url = ""http://ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz"",
    sha256 = ""34a7377ba834397db019e8eb122e551a49c98f49df75ec3fcc92b9a794a4f6d1"",
    strip_prefix = ""giflib-5.1.4/lib"",                                          
    build_file = str(Label(""//:gif.BUILD"")),                                    
  )
```
Looks like http://ufpr.dl.sourceforge.net is just a SF mirror located in Brazil, and not quite stable, see #3929, #4085. I also encountered this some times. Considering change to another stable one, for example: http://downloads.sourceforge.net

A list of SF sites/mirrors:
https://github.com/fink/fink-mirrors/blob/master/sourceforge"
5345,tensor layer,"Does tensorflow support or has tensor layer function. If it has than how can we implement it.
Thank You"
5344,Import error: AttributeError: 'module' object has no attribute 'Default',"### Environment info
Operating System:  Ubuntu 14.04 LTS

Installed version of CUDA and cuDNN: CUDA-8.0 and cuDNN v5.1

Hi everyone:
   I have met an ImportError and do not what happened? Before this, I use tensorflow normally for about one month.
   Can anyone help me? Thanks a lot!

The error info as following (in Ipython).

```python
In [2]: import tensorflow as tf
```
```
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcurand.so.8.0 locally

AttributeError                            Traceback (most recent call last)
<ipython-input-2-41389fad42b5> in <module>()
----> 1 import tensorflow as tf

/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py in <module>()
     21 from __future__ import print_function
     22 
---> 23 from tensorflow.python import *
     24 
     25 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py in <module>()
     61 
     62 # Protocol buffers
---> 63 from tensorflow.core.framework.graph_pb2 import *
     64 from tensorflow.core.framework.node_def_pb2 import *
     65 from tensorflow.core.framework.summary_pb2 import *

/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py in <module>()
      7 from google.protobuf import message as _message
      8 from google.protobuf import reflection as _reflection
----> 9 from google.protobuf import symbol_database as _symbol_database
     10 from google.protobuf import descriptor_pb2
     11 # @@protoc_insertion_point(imports)

/usr/local/lib/python2.7/dist-packages/google/protobuf/symbol_database.py in <module>()
    163 
    164 
--> 165 _DEFAULT = SymbolDatabase(pool=descriptor_pool.Default())
    166 
    167 

AttributeError: 'module' object has no attribute 'Default'
```"
5343,ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory,"I have installed cuda 7.5, not 8, but when I get this error when I try to import tensflow (having installed ts binaries for 7.5, gpu, linux).  I have tried un- and re-installing everything repeatedly.  I may have at one time attempted to install cuda 8 in the past, but 7.5 is in my $path.

the complete error:
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory
```"
5342,Gradient for gather_nd is not implemented,"Hi all,

when I use `tf.gather_nd`, It gives me the error ""NotImplementedError: Gradient for gather_nd is not implemented"".

I can temporarily solve this problem to flatten both of `params` and `indices` and then use `tf.gather`. But it isn't the best way to do so.

Is there any plan to support that? Thanks!"
5341,TensorBoard not working with 0.11 RC1,"All I see is a blank page when I go to localhost:6006

Browser: Chrome (Version 54.0.2840.71 (64-bit))
Here's the full stack trace:

127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET / HTTP/1.1"" 200 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /webcomponentsjs/webcomponents-lite.min.js HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /dist/bazel-html-imports.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /lib/css/global.css HTTP/1.1"" 200 -
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /dist/tf-tensorboard.html HTTP/1.1"" 200 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /polymer/polymer.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /iron-icons/iron-icons.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-tabs/paper-tabs.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-dialog/paper-dialog.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-toolbar/paper-toolbar.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-button/paper-button.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-checkbox/paper-checkbox.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-header-panel/paper-header-panel.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /lodash/lodash.min.js HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-slider/paper-slider.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-input/paper-input.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /d3/d3.js HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-styles/paper-styles.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-dropdown-menu/paper-dropdown-menu.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-menu/paper-menu.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-item/paper-item.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /iron-collapse/iron-collapse.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /plottable/plottable.js HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /plottable/plottable.css HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-icon-button/paper-icon-button.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-toggle-button/paper-toggle-button.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /lodash/lodash.min.js HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /graphlib/dist/graphlib.core.js HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /dagre/dist/dagre.core.js HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /lodash/lodash.min.js HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /graphlib/dist/graphlib.core.js HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /iron-flex-layout/iron-flex-layout.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /iron-list/iron-list.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-item/all-imports.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-progress/paper-progress.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-radio-group/paper-radio-group.html HTTP/1.1"" 404 -
127.0.0.1 - - [02/Nov/2016 08:59:41] code 404, message Not Found
127.0.0.1 - - [02/Nov/2016 08:59:41] ""GET /paper-tooltip/paper-tooltip.html HTTP/1.1"" 404 -
"
5340,Rename argument names in tf.train.exponential_decay(),"The current function signature reads: 

```python
tf.train.exponential_decay(learning_rate, global_step, decay_steps, decay_rate, staircase=False, name=None)
```

When passing the parameters by keyword name (for example after reading a configuration file), it's pretty weird that the first parameter is called `learning_rate` since the function can be used for other decaying parameters as well.

A better name would be `initial_value`."
5338,Failed to run MNIST example on Android,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
#4623
#4451

### Environment info
Operating System: Ubuntu 14.04
If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`): 3d35376a66cde4f3e614c746d3c8708d15caa1b5
2. The output of `bazel version`: Build label: 0.3.2

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

- Train using [MNIST tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html)
- `tf.train.write_graph(..., mnist_graph.txt, as_text=True)`
- freeze graph `bazel-bin/.../freeze_graph --input_graph=.../mnist_graph.txt --input_checkpoint=.../mnist_model.ckpt --output_graph=.../mnist_graph_frozen.pb --output_node_names=""output_node""`
- strip graph `bazel-bin/..bazel-bin/.../strip_unused --input_graph=.../mnist_graph_frozen.pb --output_graph=.../mnist_graph_frozen_stripped.pb --input_node_names=""input_node"" --output_node_names=""output_node"" --input_binary=true`
- Java code: basically I took part of TensorFlowImageListener and part of TensorFlowImageClassifier
  - Remove the image preprocessing part, instead pass in the raw mnist datapoint of shape [784] as floatValues
  - `inferenceInterface.fillNodeFloat(âinput_node"", 1, 28, 28, 1, floatValues); //When training I was reshaping the datapoint to 28x28. `
  - `inferenceInterface.runInference(new String[] {""output_node""})`
  - `inferenceInterface.readNodeFloat(""output_node"", outputs"")`

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
10-23 19:16:51.918: I/native(10721): tensorflow_inference_jni.cc:126 Creating session.
10-23 19:16:51.967: I/native(10721): tensorflow_inference_jni.cc:137 Tensorflow graph loaded from: file:///android_asset/mnist_graph_frozen_stripped.pb
10-23 19:16:51.967: I/native(10721): tensorflow_inference_jni.cc:140 Initialization done in 137.556ms
10-23 19:16:51.967: I/MainActivity(10721): Tensorflow model initialized
10-23 19:16:51.988: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e
10-23 19:16:51.988: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e
10-23 19:16:52.194: I/native(10721): tensorflow_inference_jni.cc:197 End computing. Ran in 205ms (205ms avg over 1 runs)
**10-23 19:16:52.194: E/native(10721): tensorflow_inference_jni.cc:202 Error during inference: Invalid argument: You must feed a value for placeholder tensor 'Placeholder' with dtype float
10-23 19:16:52.194: E/native(10721): 	 \[\[Node: Placeholder = Placeholder \[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]**
10-23 19:16:52.194: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e
10-23 19:16:52.194: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e
**10-23 19:16:52.195: E/native(10721): tensorflow_inference_jni.cc:159 Output [output_node] not found, aborting!**

**Thanks for reading this. Please let me know if there's any other information I need to provide.** "
5337,How to install Tensorflow on windows for Ananconda?,"![image](https://cloud.githubusercontent.com/assets/12981723/19903991/c07a065c-a03e-11e6-8265-512ad1077b41.png)
"
5336,Regression: PyUnicodeUCS4_AsUTF8String on 0.11.0rc0 to 0.11.0rc2,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
http://stackoverflow.com/questions/33795982/undefined-symbol-pyunicodeucs4-fromstringandsize-with-tensorflow-on-heroku
### Environment info
Operating System:
Heroku
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0rc2-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?
Confirmed working on https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
```
Nov 01 15:05:13 i23d-staging app/worker.1:      import tensorflow as tf 
Nov 01 15:05:13 i23d-staging app/worker.1:    File ""/app/.heroku/python/lib/python2.7/site-packages/tensorflow/__init__.py"", line 23, in <module> 
Nov 01 15:05:13 i23d-staging app/worker.1:      from tensorflow.python import * 
Nov 01 15:05:13 i23d-staging app/worker.1:    File ""/app/.heroku/python/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module> 
Nov 01 15:05:13 i23d-staging app/worker.1:      from tensorflow.python import pywrap_tensorflow 
Nov 01 15:05:13 i23d-staging app/worker.1:    File ""/app/.heroku/python/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module> 
Nov 01 15:05:13 i23d-staging app/worker.1:      _pywrap_tensorflow = swig_import_helper() 
Nov 01 15:05:13 i23d-staging app/worker.1:    File ""/app/.heroku/python/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper 
Nov 01 15:05:13 i23d-staging app/worker.1:      _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description) 
Nov 01 15:05:13 i23d-staging app/worker.1:  ImportError: /app/.heroku/python/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: PyUnicodeUCS4_AsUTF8String 
```"
5335,Is there any way to add classes in inception?,"Hi there,
I'm working on retrain example; I have TensorFlow built from source on Ubuntu 14.04, and the examples on flowers work great. However, the process strips away the Inception's final layer and removes all 1,000 existing categories, which means it can now identify 5 species of flowers, but can no longer identify pandas, for example. https://www.tensorflow.org/versions/r0.8/how_tos/image_retraining/index.html

How can I add the 5 flower categories to the existing 1,000 categories from ImageNet (and add training for those 5 new flower categories) so that I have 1,005 categories that a test image can be classified as? In other words, be able to identify both those pandas and sunflowers?

Thanks"
5334,tensorboard raises `FailedPreconditionError`,"## Description
Tensorboard always raises the exception `FailedPreconditionError` in my environment. I have it running with parameter `logdir` pointing to a directory that is tracking active experiments. Tensorboard raises an exception after a few minutes with a Traceback similar to the following:
```bash
tensorboard --debug --logdir .
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:TensorBoard is in debug mode.
INFO:tensorflow:Starting TensorBoard in directory /media/data/sarroff/experiments/source_separation/logdir3
INFO:tensorflow:TensorBoard path_to_run is: {'/media/data/sarroff/experiments/source_separation/logdir3': None}
INFO:tensorflow:TensorBoard is tag: 33
Starting TensorBoard 33 on port 6006
(You can navigate to http://127.0.1.1:6006)
INFO:tensorflow:Adding events from directory /media/data/sarroff/experiments/source_separation/logdir3/train/161031224434
INFO:tensorflow:Constructing EventAccumulator for /media/data/sarroff/experiments/source_separation/logdir3/train/161031224434
DEBUG:tensorflow:Opening a record reader pointing at /media/data/sarroff/experiments/source_separation/logdir3/train/161031224434/events.out.tfevents.1477968276.eltopo
DEBUG:tensorflow:No more events in /media/data/sarroff/experiments/source_separation/logdir3/train/161031224434/events.out.tfevents.1477968276.eltopo
INFO:tensorflow:No path found after /media/data/sarroff/experiments/source_separation/logdir3/train/161031224434/events.out.tfevents.1477968276.eltopo
INFO:tensorflow:Multiplexer done loading. Load took 49.9 secs

... <snip> ...

Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/tensorboard/backend/server.py"", line 126, in _ReloadForever
    ReloadMultiplexer(multiplexer, path_to_run)
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/tensorboard/backend/server.py"", line 100, in ReloadMultiplexer
    multiplexer.AddRunsFromDirectory(path, name)
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/summary/event_multiplexer.py"", line 178, in AddRunsFromDirectory
    for subdir in GetLogdirSubdirectories(path):
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/summary/event_multiplexer.py"", line 396, in <genexpr>
    subdir
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/summary/impl/io_wrapper.py"", line 50, in ListRecursively
    for dir_path, _, filenames in gfile.Walk(top):
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 415, in walk
    listing = list_directory(top)
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 391, in list_directory
    file_list = get_matching_files(os.path.join(compat.as_str_any(dirname), ""*""))
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 260, in get_matching_files
    compat.as_bytes(filename), status)]
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
FailedPreconditionError: /media/data/sarroff/experiments/source_separation/logdir3/train/161031224434/model.ckpt-263550.index
```
The accompanying exception message mentions a different file every time and the exception is raised at some arbitrary time after execution. It is therefore not easy to replicate my issue deterministically.

## Environment
Ubuntu 16.04LTS
TensorFlow commit 1fcd6d1294564066c6f92b121a3aaf4ed186dc1a


## Proposed Cause
This is just a guess; I'm not too familiar with the code: The exception is raised in `FileSystem::GetMatchingPaths`. Perhaps, while traversing the directory, some files get incorrectly marked as directories. If so, then the error probably happens during the call to `opendir` in `PosixFileSystem::GetChildren`. Error codes which are mapped to `FailedPreconditionError` are listed in `tensorflow/core/platform/posix/error.cc`. A likely error code causing the exception is `ENOTDIR`. I don't have an explanation as to why files would occasionally be incorrectly marked as directories. Perhaps there is a problem unique to my environment.

I've also noticed the recent Issue https://github.com/tensorflow/tensorflow/issues/4921, which specifically mentions problems with `FileSystem::GetMatchingPaths`. Perhaps this issue is connected with that one."
5333,Problem compiling tensorflow for iOS on Sierra/Xcode 8,"with xcode-select pointed to Xcode 8:

```
$ xcode-select -p
/Applications/Xcode.app/Contents/Developer
```

I get the following compile error with build_all_ios.sh on Sierra:

```
checking whether we are cross compiling... configure: error: in `/Users/serkan/tensorflow/tensorflow/contrib/makefile/downloads/protobuf':
configure: error: cannot run C compiled programs.
If you meant to cross compile, use `--host'.
See `config.log' for more details
```

Not sure if this is related to Xcode 8 or to code signing on Sierra

"
5332,about how to conduct the tensor like the numpy or theao,"I can get the result by numpy or theano,but for tensorflow it may not support this
How can I do to get the result that I want
>>>import tensorflow as tf
>>> x = [[1,2,3],[4,5,6]]
>>> y = [0,1]
>>> z = [1,2]
>>> x = tf.constant(x)
>>> y = tf.constant(y)
>>> z = tf.constant(z)
>>> m = x[y,z]  # m = [2,6] is what I expect ,I just make a simple example ,Thanks
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/users3/htleng/.local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 383, in _SliceHelper
    name=name)
  File ""/users3/htleng/.local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 537, in strided_slice
    shrink_axis_mask=shrink_axis_mask)
  File ""/users3/htleng/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2750, in strided_slice
    shrink_axis_mask=shrink_axis_mask, name=name)
  File ""/users3/htleng/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 749, in apply_op
    op_def=op_def)
  File ""/users3/htleng/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2382, in create_op
    set_shapes_for_outputs(ret)
  File ""/users3/htleng/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1783, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/users3/htleng/.local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1645, in _DelegateStridedSliceShape
    return common_shapes.call_cpp_shape_fn(op, input_tensors_needed=[1, 2, 3])
  File ""/users3/htleng/.local/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 596, in call_cpp_shape_fn
    raise ValueError(err.message)
ValueError: Shape must be rank 1 but is rank 2
"
5328,Is there any way to use `gather_nd` more simpler?,"Hi all, 

Now I'm using [tf.gather_nd](https://www.tensorflow.org/versions/r0.11/api_docs/python/array_ops.html#gather_nd). 

When batched indexing into a matrix:
```
indices = [[[0, 0]], [[0, 1]]]
params = [['a', 'b'], ['c', 'd']]
output = [['a'], ['b']]
```

I wonder if there any simpler solution if my `indices.shape[0] = params.shape[0]`. That means I want to take values from **EVERY** row of params. 

So if I want to get 
`output = [['a'], ['c']]` ('a' is from params[0], 'c' is from params[1])
 I can code like `indices = [[0], [0]]` instead of `indices = [[[0, 0]], [[1, 0]]]` since people hardly have the row info in `indices`

For example,
```
import tensorflow as tf

indices = [[[0, 4], [0, 1], [0, 6], [0, 2]],
          [[1, 1], [1, 4], [1, 0], [1, 9]],
          [[2, 5], [2, 1], [2, 9], [2, 6]]]

params = [[4,6,3,6,7,8,4,5,3,8], [9,5,6,2,6,5,1,9,6,4], [4,6,6,1,3,2,6,7,1,8]]
output = tf.gather_nd(params, indices)

sess = tf.Session()
print sess.run(output)
```
There output is 
```
[[7 6 4 3]
 [5 6 9 4]
 [2 6 8 6]]
```

I want to take out 7, 6, 4, 3 from params[0]. However, I have to set row index 0 in `indices` because params[0][4] = 7, params[0][1] = 6, params[0][6] = 4, params[0][2] = 3.
But what I already know is just 
```
raw_indices = [[4, 1, 6, 2],
               [1, 4, 0, 9],
               [5, 1, 9, 6]]
```
How can I add the ""row index"" in each elem of `raw_indices` to get
```
indices = [[[0, 4], [0, 1], [0, 6], [0, 2]],
          [[1, 1], [1, 4], [1, 0], [1, 9]],
          [[2, 5], [2, 1], [2, 9], [2, 6]]]
```


ï¿¼


ï¿¼
ï¿¼ï¿¼ï¿¼"
5327,"Build error: Eigen/src/Core/arch/CUDA/PacketMathHalf.h(45): error: identifier ""__half2half2"" is undefined","I'm getting the following errors when I try to build TensorFlow:

```
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/PacketMathHalf.h(45): error: identifier ""__half2half2"" is undefined                                                                                                                   [136/14011]
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/PacketMathHalf.h(53): error: identifier ""__halves2half2"" is undefined
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/PacketMathHalf.h(57): error: identifier ""__halves2half2"" is undefined
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/PacketMathHalf.h(65): error: identifier ""__low2half"" is undefined
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/PacketMathHalf.h(66): error: identifier ""__high2half"" is undefined
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/PacketMathHalf.h(81): error: identifier ""__halves2half2"" is undefined
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/PacketMathHalf.h(88): error: identifier ""__halves2half2"" is undefined
```

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
Nothing.

### Environment info
Operating System:
Ubuntu 14.04.1
gcc-4.8.4
bazel 0.3.2
TensorFlow: Master 6f7cf60a4158a6d

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
cuda: 7.5
cudnn: 5.1.5
```
 â¯ ls -lh /usr/local/cuda-7.5/lib64/libcud*
-rw-r--r-- 1 root root 316K Aug  7  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root   16 Aug  7  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root   18 Aug  7  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.7
-rwxr-xr-x 1 root root 375K Aug  7  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.7
-rw-r--r-- 1 root root 704K Aug  7  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
 â¯ ls -lh /usr/local/cudnn-5.1/lib64 
lrwxrwxrwx 1 root root  13 Oct 21 18:33 libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root  17 Oct 21 18:33 libcudnn.so.5 -> libcudnn.so.5.1.5
-r-xr-xr-x 1 root root 76M Oct 21 18:33 libcudnn.so.5.1.5
-r-xr-xr-x 1 root root 67M Oct 21 18:33 libcudnn_static.a

```

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
6f7cf60a4158a6d7861dc1b41a6446b575153a2e
2. The output of `bazel version`
```
Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110
```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5326,Feature Request: Optimizer that can perform Sparse Updates,"context:
https://www.reddit.com/r/MachineLearning/comments/5abcd4/r161009027_scaling_memoryaugmented_neural/d9fz62u/

Feature request to add optimizer that can perform sparse updates so that [1610.09027] ""Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes"" from DeepMind can be implemented in Tensorflow.

@alrojo"
5324,Small documentation error in iOS Example,"I'm following the wonderfully comprehensive instructions here (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/ios_examples/README.md)  for building an iOS project with tensorflow with the makefile system. 

The instructions, in the section ""creating your own app"" suggest adding 
tensorflow/contrib/makefile/downloads/eigen-latest
to the header search paths; however this folder does not exist after running the make scripts.
I believe it should be changed to 
tensorflow/contrib/makefile/downloads/eigen


(I have not seen anything suggesting tensorflow can be built for iOS using bazel, so I assume that this remains the recommended approach.)"
5323,Memoization,"I have a particle physics optimization problem where my graph contains a large subgraph that only needs to be calculated once every couple of iterations. The code I'm currently using for this uses memoization to create a significant increase in performance for these types of problems. I've been looking into porting the graph calculation part of my current code to TensorFlow, but it seems like the absence of memoization might become a show-stopper.

Are there plans to include support for memoization? If not, do you think this would be a good addition and do you have ideas on how to do this? I would be willing to contribute, if possible.

Ideally, one would be able to activate memoization per node/operation, so as to avoid performance hits due to overhead in nodes that need to be recalculated every time (i.e. that receive different arguments every time).

Perhaps this could be implemented using partial_run (#672), but I suspect a native c++ implementation would be vastly superior."
5322,Remove unnecessary GCS customized python code,"We have a GCS-like file system (blob store) and added the support without any customized python code (event summary input for tensorboard is not needed either).

It's better to clean them up. At least, refactor and clean up the following code because wen shouldn't change any python code when we adding a new file system:
```python
    if (io_wrapper.IsGCSPath(specification) or                                  
        specification.startswith('hdfs://')): 
```

I can contribute if no one is working on this."
5321,Filesystem FileExists interface is broken,"The FileSystem define the following interface, which can't handle temporary runtime errors properly but just swallow them (like GCS, HDFS and any customized DFS),
```c++
virtual bool FileExists(const string& fname) = 0;
```
It should be changed to
```c++
virtual Status FileExists(const string& fname) = 0;
```
I can provide a patch if no one is working on this."
5320,How to Read tensorflow source code with an IDE ?,Is there any IDE support bazel so that I can use IDE to read the source code ? 
5319,"Object of type 'path' has no field ""realpath"".","I upgraded to 0.11rc1 as you have advised, @tatatodd in issue #4841 . I did a `sudo ./configure`, and this was the result:

```
$ sudo ./configure
~/tensorflow ~/tensorflow
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] N
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] N
No Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/local/lib/python3.5/dist-packages
  /usr/lib/python3/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]

/usr/local/lib/python3.5/dist-packages
Do you wish to build TensorFlow with GPU support? [y/N] Y
GPU support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-8.0
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 
Please specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-8.0]: 
libcudnn.so resolves to libcudnn.5
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
.
ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/darth/tensorflow/third_party/gpus/cuda_configure.bzl"", line 517
		_create_cuda_repository(repository_ctx)
	File ""/home/darth/tensorflow/third_party/gpus/cuda_configure.bzl"", line 432, in _create_cuda_repository
		_cuda_toolkit_path(repository_ctx, cuda_version)
	File ""/home/darth/tensorflow/third_party/gpus/cuda_configure.bzl"", line 148, in _cuda_toolkit_path
		str(repository_ctx.path(cuda_toolkit...)
	File ""/home/darth/tensorflow/third_party/gpus/cuda_configure.bzl"", line 148, in str
		repository_ctx.path(cuda_toolkit_path).realpath
Object of type 'path' has no field ""realpath"".
```

Thanks in advance for your response."
5317,Build - leftover bazel processes after build complete,"After running a successful build, 2 or 3 bazel processes remain along with many child processes for each one - they don't take up any CPU resources. Have to kill the processes manually to get rid of them.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None!

### Environment info
Operating System:
```Slackware 64 14.2```

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
libcudadevrt.a
libcudart.so -> libcudart.so.8.0
libcudart.so.8.0 -> libcudart.so.8.0.44
libcudart.so.8.0.44
libcudart_static.a
libcudnn.so -> libcudnn.so.5
libcudnn.so.5 -> libcudnn.so.5.1.5
libcudnn.so.5.1.5
libcudnn_static.a
```

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
```6f7cf60a4158a6d7861dc1b41a6446b575153a2e```

2. The output of `bazel version`
```
Build label: 0.3.2- (@non-git)
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Sun Oct 16 21:50:19 2016 (1476654619)
Build timestamp: 1476654619
Build timestamp as int: 1476654619
```
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

o Configure with GPU support and run a standard build.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

```
ps aux | grep bazel
```
```
root     21080  0.5  0.3 50920612 649256 ?     Ssl  19:00   0:09 bazel(tensorflow) -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/root/.cache/bazel/_bazel_root/d63fa4ac02658c8e5f9c2e0f1f523a93 -Xverify:none -Djava.util.logging.config.file=/root/.cache/bazel/_bazel_root/d63fa4ac02658c8e5f9c2e0f1f523a93/javalog.properties -Djava.library.path=/root/.cache/bazel/_bazel_root/install/26cccb4705ab94af88df4f6dfb1e20c4/_embedded_binaries/ -Dfile.encoding=ISO-8859-1 -jar /root/.cache/bazel/_bazel_root/install/26cccb4705ab94af88df4f6dfb1e20c4/_embedded_binaries/A-server.jar --max_idle_secs 10800 --install_base=/root/.cache/bazel/_bazel_root/install/26cccb4705ab94af88df4f6dfb1e20c4 --install_md5=26cccb4705ab94af88df4f6dfb1e20c4 --output_base=/root/.cache/bazel/_bazel_root/d63fa4ac02658c8e5f9c2e0f1f523a93 --workspace_directory=/usr/local/src/tensorflow/tensorflow-git --deep_execroot --experimental_oom_more_eagerly_threshold=100 --nofatal_event_bus_exceptions --product_name=Bazel --option_sources=
root     23518 10.0  1.1 51042312 2339964 ?    Ssl  19:03   2:31 bazel(tensorflow) -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/root/.cache/bazel/_bazel_root/d63fa4ac02658c8e5f9c2e0f1f523a93 -Xverify:none -Djava.util.logging.config.file=/root/.cache/bazel/_bazel_root/d63fa4ac02658c8e5f9c2e0f1f523a93/javalog.properties -Djava.library.path=/root/.cache/bazel/_bazel_root/install/26cccb4705ab94af88df4f6dfb1e20c4/_embedded_binaries/ -Dfile.encoding=ISO-8859-1 -jar /root/.cache/bazel/_bazel_root/install/26cccb4705ab94af88df4f6dfb1e20c4/_embedded_binaries/A-server.jar --max_idle_secs 10800 --install_base=/root/.cache/bazel/_bazel_root/install/26cccb4705ab94af88df4f6dfb1e20c4 --install_md5=26cccb4705ab94af88df4f6dfb1e20c4 --output_base=/root/.cache/bazel/_bazel_root/d63fa4ac02658c8e5f9c2e0f1f523a93 --workspace_directory=/usr/local/src/tensorflow/tensorflow-git --deep_execroot --experimental_oom_more_eagerly_threshold=100 --nofatal_event_bus_exceptions --product_name=Bazel --option_sources=
```"
5316,Invalid argument when accessing HDFS,"We have installed pseudo-distributed HDFS in local and use the default port, 9000. We follow the example code from `https://github.com/tensorflow/tensorflow/issues/2218` but it throws `InvalidArgumentError`.

Our code looks like this and it works if we change to local filesystem.

```
hdfs_path = ""hdfs://127.0.0.1:9000/cancer_train.csv.tfrecords""
filename_queue = tf.train.string_input_producer(
    tf.train.match_filenames_once(hdfs_path),
    num_epochs=epoch_number)
label, features = read_and_decode(filename_queue)
batch_labels, batch_features = tf.train.shuffle_batch(
    [label, features],
    batch_size=batch_size,
    num_threads=thread_number,
    capacity=capacity,
    min_after_dequeue=min_after_dequeue)
```

And the error log looks like this.

```
hdfsGetPathInfo(): constructNewObjectOfPath error:
java.lang.IllegalArgumentException: Can not create a Path from an empty string
        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)
        at org.apache.hadoop.fs.Path.<init>(Path.java:134)
W tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000
hdfsGetPathInfo(): constructNewObjectOfPath error:
java.lang.IllegalArgumentException: Can not create a Path from an empty string
        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)
        at org.apache.hadoop.fs.Path.<init>(Path.java:134)
W tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000
hdfsGetPathInfo(): constructNewObjectOfPath error:
java.lang.IllegalArgumentException: Can not create a Path from an empty string
        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)
        at org.apache.hadoop.fs.Path.<init>(Path.java:134)
W tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000
hdfsGetPathInfo(): constructNewObjectOfPath error:
java.lang.IllegalArgumentException: Can not create a Path from an empty string
        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)
        at org.apache.hadoop.fs.Path.<init>(Path.java:134)
W tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000
Traceback (most recent call last):
  File ""./hdfs.py"", line 237, in <module>
    sess.run(init_op)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 915, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 965, in _do_run
    target_list, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 985, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: hdfs://127.0.0.1:9000
         [[Node: matching_filenames/MatchingFiles = MatchingFiles[_device=""/job:localhost/replica:0/task:0/cpu:0""](matching_filenames/MatchingFiles/pattern)]]
         [[Node: matching_filenames_1/Assign/_6 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send
_device_incarnation=1, tensor_name=""edge_117_matching_filenames_1/Assign"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
```

### Environment info
Operating System: CentOS 7.0
TensorFlow: 0.11.0rc1

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5314,"Add more ""synthetic"" datasets in the `contrib.learn`","The feature request is as in the title -- having synthetic datasets for demo purposes, and to see how different algorithms behave would be beneficial. It is fairly straightforward to generate two-dimensional multi-class set for a lot of synthetic problems."
5310,Makefile downloads/ breaks ./configure,"I'm rebuilding tf on Sierra and with CUDA 8.0 and Xcode 8.0 but ./configure fails with:

INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
........
ERROR: /Users/serkan/tensorflow/tensorflow/contrib/makefile/downloads/protobuf/BUILD:544:1: no such target '//external:gson': target 'gson' not declared in package 'external' defined by /Users/serkan/tensorflow/WORKSPACE and referenced by '//tensorflow/contrib/makefile/downloads/protobuf:protobuf_java_util'.
ERROR: /Users/serkan/tensorflow/tensorflow/contrib/makefile/downloads/protobuf/BUILD:544:1: no such target '//external:gson': target 'gson' not declared in package 'external' defined by /Users/serkan/tensorflow/WORKSPACE and referenced by '//tensorflow/contrib/makefile/downloads/protobuf:protobuf_java_util'.
ERROR: /Users/serkan/tensorflow/tensorflow/contrib/makefile/downloads/protobuf/BUILD:544:1: no such target '//external:guava': target 'guava' not declared in package 'external' (did you mean 'java'?) defined by /Users/serkan/tensorflow/WORKSPACE and referenced by '//tensorflow/contrib/makefile/downloads/protobuf:protobuf_java_util'.
ERROR: Evaluation of query ""deps((//tensorflow/... union @bazel_tools//tools/jdk:toolchain))"" failed: errors were encountered while computing transitive closure.

perhaps bazel has changed something about how it handles dependencies?"
5309,Pylint `disable` should be followed by `enable`,"There is a problem, which might have high severity:

A lot of files disable `pylint` messages, but don't enable them in the end -- this potentially might cause a missed warning if several files are imported, because `# pylint disable` is a global disable.

[Here are all the files that modify the `pylint` related to the `wildcard-import`](https://github.com/tensorflow/tensorflow/search?utf8=%E2%9C%93&q=pylint+disable+wildcard-import&type=Code)
[Here is an example file that doesn't revert the modifications](https://github.com/tensorflow/tensorflow/blob/754048a0453a04a761e112ae5d99c149eb9910dd/tensorflow/contrib/learn/python/learn/preprocessing/__init__.py)

There might be other wildcards that are disabled without reverting the changes"
5308,[Readability Issue] Using __all__ vs. wildcards,"I have noticed that a lot of `__init__.py` files in the repo include 

```python
# pylint: disable=wildcard-import
from <...> import *
# pylint: enable=wildcard-import
```

I believe a more appropriate approach would be to use `__all__`. According to PEP 8 documentation:

> To better support introspection, modules should explicitly declare the names in their public API using the __all__ attribute. Setting __all__ to an empty list indicates that the module has no public API."
5305,More programmatically configurable TensorBoard graph visualization,"I'm repeatedly making small tweaks to graphs and visualizing them in TensorBoard.
Here are two feature requests for TensorBoard that would make this workflow significantly smoother:

(1)
Allow the user to specify that a node should always be drawn in the main graph or as an auxiliary node.  Alternatively, add an option to draw all nodes in main graph.

Currently, TensorBoard chooses to put nodes in a subgraph as auxiliary nodes (within the subgraph). Adding a node to the main graph consists of ""open subgraph, click auxiliary node to add to main graph"", which needs to be repeated for each auxiliary node to move because ""add to main graph"" collapses all subgraphs. This pain could also be partially alleviated by an option to ""Shift + Click"" to add/remove multiple nodes from the main graph at once.

(2)
Allow the user to force edges to be drawn when both nodes are in the main graph.

Example case:
Let op ``X`` be in the top level graph. Let ``SG`` be a subgraph and let ``SG`` contain 10 subgraphs ``F_i`` for ``i=1,...,10`` that all take ``X`` as input.
TensorBoard will draw an edge from ``X`` to ``SG``, but each ``F_i`` will have it's dependence on ``X`` noted as an auxiliary input. There is no way to add ``X`` to the main graph because it is already in the main graph (but visualized as an aux input). 
It would nice for there to be a way for there to be one edge from ``X`` to ``SG``, and then 10 edges connecting the entry point of ``X`` into ``SG`` with each of the ``F_i``. Ideally this option would also have a programmatic interface or at least a default to set."
5303,Error compiling on ARM with -mfpu=neon: canât find a register in class âLO_REGSâ while reloading âasmâ,"Hi,

I am trying to compile TF for an ARM device and to exploit NEON-related optimizations.
Basically, I follow these instructions for PI (my device is a Sabre Board, not PI): https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile

but with a bit different flags, namely:
`make -f tensorflow/contrib/makefile/Makefile OPTFLAGS=""-Ofast -mfpu=neon -funsafe-math-optimizations -ftree-vectorize"" HOST_OS=LINUX`

because my CPU does not support vfpv4:

```
cat /proc/cpuinfo
processor	: 0
model name	: ARMv7 Processor rev 10 (v7l)
BogoMIPS	: 7.54
Features	: half thumb fastmult vfp edsp neon vfpv3 tls vfpd32
CPU implementer	: 0x41
CPU architecture: 7
CPU variant	: 0x2
CPU part	: 0xc09
CPU revision	: 10
```

The error I got:
```
/root/tensorflow_exp/tensorflow/contrib/makefile/downloads/gemmlowp/meta/streams_arm_32.h: In static member function âstatic void gemmlowp::meta::GemmExecutorPackLHS::ExecuteDispatch3D(const P&) [with P = gemmlowp::meta::GemmParams<unsigned char, int, gemmlowp::meta::ColumnMajorWithSum, gemmlowp::meta::RowMajorWithSum, gemmlowp::meta::QuantizedStaticPreprocessedAsInt32, gemmlowp::meta::RowMajor>; int m = 1; int n = 8; int k = 8; int m_leftovers = 0; int n_leftovers = 7; int k_leftovers = 4]â:
/root/tensorflow_exp/tensorflow/contrib/makefile/downloads/gemmlowp/meta/streams_arm_32.h:4211:59: error: canât find a register in class âLO_REGSâ while reloading âasmâ
         ""d25"", ""d26"", ""d27"", ""d28"", ""d29"", ""cc"", ""memory"");
                                                           ^
/root/tensorflow_exp/tensorflow/contrib/makefile/downloads/gemmlowp/meta/streams_arm_32.h:4211:59: error: âasmâ operand has impossible constraints
make: *** [/root/tensorflow_exp/tensorflow/contrib/makefile/gen/obj/tensorflow/core/kernels/meta_support.o] Error 1
```

As far as I understand, it complains about too little registers, which wonders me, since ARM has 16 registers. If I remove ` -mfpu=neon` flag, everything works like a charm. 

I would greatly appreciated for any suggestions.

### Environment info
Ubuntu 14.04.4 LTS
`Linux sabresd 4.1.15-1.0.0+g3924425 #1 SMP PREEMPT Sun Mar 13 14:09:51 CST 2016 armv7l armv7l armv7l GNU/Linux`

Installed version of CUDA and cuDNN: 
No CUDA installed
TF commit hash: `1fcd6d1294564066c6f92b121a3aaf4ed186dc1a`
"
5302,C++ memory leak after `Session::Close()` /  C++ equivalent to Python `reset_default_graph()` ?,"Using C++ API, memory (RAM) does not appear to be fully released after `Session::Close()` is called. 

See code snippet below. Running it within a loop eventually eats up all RAM and gets killed by system.

From reading around, I understand that the closing of the session does not release the underlying graph. In Python it seems that `reset_default_graph()` releases the graph resources.

Is there any equivalent to `reset_default_graph()` in C++ ?

I initially reported this question on the mailing list, https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/NG7n6emda78 with no echo, so posted as an issue here. My apologies if this isn't the right procedure.

Note:
GPU memory appears to not be released when looking it up with `nvidia-smi` but I believe it is an `nvidia-smi` problem as in practice the GPU memory appears to be reusable, so no problem on this side.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

http://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session
https://github.com/tensorflow/tensorflow/issues/1578
https://github.com/fchollet/keras/issues/2102
https://github.com/tensorflow/tensorflow/issues/700
https://github.com/tensorflow/tensorflow/issues/3106

### Environment info
Operating System:

Ubuntu 16.04 LTS

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rw-r--r-- 1 root root   560184 Sep  7 18:22 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Sep  7 18:22 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Sep  7 18:22 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 Sep  7 18:22 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 Sep  7 18:22 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 79337624 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 79337624 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 79337624 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Sep 11 08:45 /usr/local/cuda/lib64/libcudnn_static.a
```

### From source installation

1. The commit hash (`git rev-parse HEAD`)

```
5c1ca717e8ddd16b0be8410a798dc174380a600d
```

2. The output of `bazel version`

```
Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110
```
### Short code snippet

Put the code below into a loop, and RAM keeps on growing, replace `_inputLayer` and `_outputLayer` with proper network layer names, and `vtfinputs` is a `std::vector<tensorflow::Tensor>`.

```C++
tensorflow::GraphDef graph_def;
tensorflow::Status graphLoadedStatus = ReadBinaryProto(tensorflow::Env::Default(),graphFile,&graph_def);
tensorflow::SessionOptions options;
tensorflow::ConfigProto &config = options.config;
config.mutable_gpu_options()->set_allow_growth(true);
std::unique_ptr<tensorflow::Session> session = std::unique_ptr<tensorflow::Session>(tensorflow::NewSession(options));
tensorflow::Status session_create_status = session->Create(graph_def);                                                        
...                                                                               
tensorflow::Status run_status  = session->Run({{_inputLayer,*(vtfinputs.begin())}},{_outputLayer},{},&finalOutput)  /* runs file, results are what they should be, and are acquired via finalOutput. */
...
session->Close();                                                                                                          
session.reset();

/* RAM keeps building up if code above put into a loop */
```
### What other attempted solutions have you tried?

using ```session->Reset(options,containers)``` does not appear to compile (Reset does not exist for Session). Looking at ```session.h``` and ```direct_session.h``` I don't yet understand why this is the case. 


"
5301,Feature request: Automated builds for AVX2 ,Would it be possible to add also AVX2 optimized builds to the automated PIP builds provided by Google? 
5299,How can I make distributed tensorFlow support failover?,"I create a 4 nodes tensorflow cluster, 2 worker, 2 ps. When the worker or ps fails, I relaunch it with the same configuration on the machine. However, it cannot continue to work from the checkpoint.
Does distributed tensorflow still not support failover?

This file ""model.ckpt-24"" is only on the machine( task 0 of worker), the trace is as follows.

Traceback (most recent call last):
  File ""/dump/9/nm-local-dir/usercache/danrtsey.wy/appcache/application_1477899492621_0004/container_e07_1477899492621_0004_01_000003/app/install/trainer.py"", line 107, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/dump/9/nm-local-dir/usercache/danrtsey.wy/appcache/application_1477899492621_0004/container_e07_1477899492621_0004_01_000003/app/install/trainer.py"", line 87, in main
    with sv.managed_session(server.target) as sess:
  File ""/usr/lib64/python2.7/contextlib.py"", line 17, in __enter__
    return self.gen.next()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 969, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 797, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 386, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 958, in managed_session
    start_standard_services=start_standard_services)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 715, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 227, in prepare_session
    config=config)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 173, in _restore_checkpoint
    saver.restore(sess, ckpt.model_checkpoint_path)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1345, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 915, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 965, in _do_run
    target_list, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 985, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /dump/6/nm-logs/application_1477899492621_0004/container_e07_1477899492621_0004_01_000003/model.ckpt-24: Not found: /dump/6/nm-logs/application_1477899492621_0004/container_e07_1477899492621_0004_01_000003
	 [[Node: save/restore_slice_1 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=""/job:ps/replica:0/task:1/cpu:0""](_recv_save/Const_0_S3, save/restore_slice_1/tensor_name, save/restore_slice_1/shape_and_slice)]]

Caused by op u'save/restore_slice_1', defined at:
  File ""/dump/9/nm-local-dir/usercache/danrtsey.wy/appcache/application_1477899492621_0004/container_e07_1477899492621_0004_01_000003/app/install/trainer.py"", line 107, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/dump/9/nm-local-dir/usercache/danrtsey.wy/appcache/application_1477899492621_0004/container_e07_1477899492621_0004_01_000003/app/install/trainer.py"", line 71, in main
    saver = tf.train.Saver()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 986, in __init__
    self.build()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1015, in build
    restore_sequentially=self._restore_sequentially)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 620, in build
    restore_sequentially, reshape)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 357, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 270, in restore_op
    preferred_shard=preferred_shard))
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py"", line 204, in _restore_slice
    preferred_shard, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 359, in _restore_slice
    preferred_shard=preferred_shard, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 749, in apply_op
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2380, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1298, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on /dump/6/nm-logs/application_1477899492621_0004/container_e07_1477899492621_0004_01_000003/model.ckpt-24: Not found: /dump/6/nm-logs/application_1477899492621_0004/container_e07_1477899492621_0004_01_000003
	 [[Node: save/restore_slice_1 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=""/job:ps/replica:0/task:1/cpu:0""](_recv_save/Const_0_S3, save/restore_slice_1/tensor_name, save/restore_slice_1/shape_and_slice)]]"
5297,Issue on Compile protobuf.sh?,"Hi,

I am trying to setup latest version from tensorflow for iOS, in the process first step to  run **download_dependencies.sh** works fine, and then in the next step to run the **compile_ios_protobuf.sh**  is resulting in following error:

    .....
    glibtoolize: copying file 'm4/ltsugar.m4'
    glibtoolize: copying file 'm4/ltversion.m4'
    glibtoolize: copying file 'm4/lt~obsolete.m4'
    configure.ac:61: installing './compile'
    configure.ac:48: installing './missing'
    benchmarks/Makefile.am: installing './depcomp'
    + rm -rf autom4te.cache config.h.in~
    + exit 0
    + '[' 0 -ne 0 ']'
    + make distclean
    make: *** No rule to make target `distclean'.  Stop.

Let me know If I am missing anything, Please guide.

Thanks "
5295,"Python import error, undefined symbol: _Z14tf_git_versionv","NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.


### Environment info
Operating System: Ubuntu16.04

Installed version of CUDA and cuDNN: 8.0 and 5

Python 2.7.12 (default, Jul  1 2016, 15:12:24)
[GCC 5.4.0 20160609] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
ImportError: /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: _Z14tf_git_versionv

I'm getting this error above with r0.10, can you please give me some insights or solutions to this? 

Thanks"
5293,TFRecord file support with Hadoop Mapreduce/Spark,"MR/Spark are commonly used for ETL and feature generation, it's better to support close integration with such systems. More specifically, supporting the following:
1. TFRecord file Mapreduce InputFormat/OutputFormat
2. Integrating Feature/Example proto classes
"
5291,[Bug] reduce_logsumexp examples do not work in 0.11.0rc1,"Version: 0.11.0rc1

These examples do not work:

```
# 'x' is [[0, 0, 0]]
#         [0, 0, 0]]
tf.reduce_logsumexp(x, 0) ==> [log(2), log(2), log(2)]
tf.reduce_logsumexp(x, 1) ==> [log(3), log(3)]
```

Because:
`tf.squeeze(t, squeeze_dims)` does not take integer for `squeeze_dims`
"
5289,TF freezes and gets killed while training /saving a network,"I am trying to train a deep network from scratch (a 4 layer [CIFAR](https://www.tensorflow.org/versions/r0.11/tutorials/deep_cnn/index.html#cifar-10-model) network) on an image collection of 100K images. The TF instance hangs (while training or while saving using tf.Saver) and then gets killed without any error message.

I've tried the following things without any use:

a. Reduced the batch size from 32 to 8.

b. Set config's allow GPU growth option to True

But the problem still persists. 

Has anybody else faced this issue? Is this because of insufficient memory? Is there a way to train a model under constrained memory conditions (although, 12 GB isn't bad)? 
 Any tips to avoid this would be very helpful. 
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

I've looked at other similar issues posted but haven't found any useful solution.
https://github.com/tensorflow/tensorflow/issues/2121
http://stackoverflow.com/questions/38958737/tensorflow-training-got-stuck-after-some-steps-how-to-investigate
https://github.com/tensorflow/tensorflow/issues/1962
### Environment info

GPU details: I am running this model on a  Tesla K40c (12GB memory).
Operating System:  4.7.0-1-amd64 #1 SMP Debian 4.7.6-1 (2016-10-07) x86_64 GNU/Linux

Installed version of CUDA and cuDNN: 
/opt/cuda-8.0/lib64/libcudnn.so.5
/opt/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0

(Cuda version: 8.0 and cuDNN version 5)
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.11.0rc1

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
   ec7f37e40fedb23435bfb7e28668e5fa63ff52f3
2. The output of `bazel version`

Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

This issue is happening when I am trying to train/ save a model
"
5287,[tf.learn] MetricSpec doesn't work with streaming_mean,"MetricSpecs always pass both values and labels to metrics, meaning metrics which don't use labels like streaming_mean are broken.
"
5286,gcc compile failure on Cray XC30,"Operating System:Cray XC30 (Linux)

$ git rev-parse HEAD
6bf2cc7e618ef16ab36b903752d51316ce99ad99
$ bazel version
Build label: unknown-2016-10-30 (@5abb90d)
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Sun Oct 30 14:59:29 2016 (1477839569)
Build timestamp: 1477839569
Build timestamp as int: 1477839569

$ bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

$ gcc -v
Using built-in specs.
COLLECT_GCC=/opt/gcc/4.8.1/bin/../snos/bin/gcc
COLLECT_LTO_WRAPPER=/opt/gcc/4.8.1/snos/libexec/gcc/x86_64-suse-linux/4.8.1/lto-wrapper
Target: x86_64-suse-linux
Configured with: ../cray-gcc-4.8.1/configure --prefix=/opt/gcc/4.8.1/snos --disable-nls --libdir=/opt/gcc/4.8.1/snos/lib --enable-languages=c,c++,fortran --with-gxx-include-dir=/opt/gcc/4.8.1/snos/include/g++ --with-slibdir=/opt/gcc/4.8.1/snos/lib --with-system-zlib --enable-shared --enable-__cxa_atexit --build=x86_64-suse-linux --with-mpc=/opt/gcc/mpc/0.8.1 --with-mpfr=/opt/gcc/mpfr/2.4.2 --with-gmp=/opt/gcc/gmp/4.3.2
Thread model: posix
gcc version 4.8.1 20130531 (Cray Inc.) (GCC) 

$ uname -a
Linux - 3.0.101-0.47.86.1.11753.0.PTF-default #1 SMP Wed Oct 19 14:11:00 UTC 2016 (56c73f1) x86_64 x86_64 x86_64 GNU/Linux

$ python
Python 2.7.6 (default, Mar 10 2014, 14:13:45) 
[GCC 4.8.1 20130531 (Cray Inc.)] on linux2

Log attached.
[log.txt](https://github.com/tensorflow/tensorflow/files/560597/log.txt)
"
5285,(0.11) parse_single_example doesn't play well with read_file,"minimal reproduction:

```
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.DEBUG)
index = ['a', 'b', 'c']

with tf.python_io.TFRecordWriter('test.pb2') as writer:
    writer.write(tf.train.Example(features=tf.train.Features(
        feature={'index': tf.train.Feature(bytes_list=tf.train.BytesList(
            value=index))})).SerializeToString())

index_example = tf.read_file('test.pb2')
index = tf.parse_single_example(
    index_example,
    {'index': tf.FixedLenFeature([3], tf.string)}
)['index']

with tf.Session() as sess:
    tf.logging.debug(index_example.eval())
    tf.logging.debug(index.eval())
```

You'll notice that read_file works just fine, and outputs bytes as expected, but then the process will completely lock up, and does not respond to SIGINT, responding only to SIGKILL or SIGTERM. Not sure what's going on here, although I suspect that read_file is reading some leading/trailing bytes that TFRecordReader strips off. 

Still it seems like TFRecords should be a valid I/O format without requiring a filename queue, (e.g. for reading in initial vocabulary files), and I thought that `read_file` + `parse_single_example` would be the expected way to do this. Instead I guess I need to use `make_tensor_proto` or something? Not sure why this is a separate serialization strategy... and completely missing from the docs.

At the very least, `parse_single_example` should fail and not livelock when it gets these strings. 

EDIT: For people wondering what the correct pattern is it appears to be something like:

```
import tensorflow as tf
from tensorflow.contrib.util import make_tensor_proto

tf.logging.set_verbosity(tf.logging.DEBUG)
index = ['a', 'b', 'c']

with open('test.pb2', 'wb') as writer:
    writer.write(make_tensor_proto(index, dtype=tf.string, shape=[3]).SerializeToString())

index_example = tf.read_file('test.pb2')
index = tf.parse_tensor(index_example, tf.string)

with tf.Session() as sess:
    tf.logging.debug(index_example.eval())
    tf.logging.debug(index.eval())
```
"
5284,"tf.contrib.learn output shapes : shapes (?, 1) and (?,) are incompatible","I tried to train a binary DNNClassifier  similar as the example on https://www.tensorflow.org/versions/r0.11/tutorials/tflearn/index.html#tf-contrib-learn-quickstart.

I got the following traceback
[traceback.txt](https://github.com/tensorflow/tensorflow/files/560406/traceback.txt)

I explored the tensorflow source code and found that it may relate to _get_in_out_shape function in tensorflow/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py

![image](https://cloud.githubusercontent.com/assets/11754923/19836102/024ac634-9ed2-11e6-89cc-e9dc2623424b.png)

When doing a binary classification,y_shape is something like[batch_size,1].Line 52 changes it into [1].Line 54,55 change it into [].And finally the output_shape is [batch_size,].However the correct ouput shape should be [batch_size,1].

To sum up,we do not need to skip 1st dimension if it is 1 and len(y_shape)=1.
"
5283,Is there a way of 'cutting' a network?,"I wonder if there is a way of 'cutting' the network. What I want to achieve is fine-tuning of the whole inception v3 network and then implement transfer learning by replacing the last 2 inception modules with new layers. I did the whole fine-tuning using this code https://github.com/tensorflow/models/tree/master/inception on my own dataset taking the last checkpoint that I need but now I don't know how I can implement the transfer learning by taking the output of 8th inception module and train the new layers. Is there a standard tensorflow-way of doing this operation? 
"
5282, Couldn't open CUDA library libcupti.so.7.5,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
### Environment info

Operating System: Linux Ubuntu 14.04 LTS (64bit)

Installed version of CUDA and cuDNN:  CUDA7.5, cuDNN4
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): 

-rw-r--r-- 1 root root 189170 Apr 23  2016 libcudadevrt.a
lrwxrwxrwx 1 root root     16 Apr 23  2016 libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Apr 23  2016 libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Apr 23  2016 libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Apr 23  2016 libcudart_static.a

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`) c82f4962b9b8ba871880958a459d6d4f3587111b
2. The output of `bazel version` 0.3.2
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

codes are from: https://github.com/tensorflow/tensorflow/raw/r0.11/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py

goes wrong here:

```
if i % 100 == 99:  # Record execution stats
        run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
        run_metadata = tf.RunMetadata()
        summary, _ = sess.run([merged, train_step],
                              feed_dict=feed_dict(True),
                              options=run_options,
                              run_metadata=run_metadata)
        train_writer.add_run_metadata(run_metadata, 'step%03d' % i)
        train_writer.add_summary(summary, i)
        print('Adding run metadata for', i)
```
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).

```
Accuracy at step 0: 0.1045
Accuracy at step 10: 0.6843
Accuracy at step 20: 0.8074
Accuracy at step 30: 0.8511
Accuracy at step 40: 0.878
Accuracy at step 50: 0.8869
Accuracy at step 60: 0.89
Accuracy at step 70: 0.8928
Accuracy at step 80: 0.893
Accuracy at step 90: 0.8945
I tensorflow/stream_executor/dso_loader.cc:119] Couldn't open CUDA library libcupti.so.7.5. LD_LIBRARY_PATH: /home/wk15/intel/mkl/lib/intel64:/usr/local/cuda/lib64:/home/wk15/intel/mkl/lib/intel64::/home/wk15/intel/mkl/lib/:/home/wk15/lib:/home/wk15/local/lib:/home/wk15/intel/mkl/lib/:/home/wk15/lib:/home/wk15/local/lib:/home/wk15/boost-1-61-binary/lib
F tensorflow/core/platform/default/gpu/cupti_wrapper.cc:59] Check failed: ::tensorflow::Status::OK() == (::tensorflow::Env::Default()->GetSymbolFromLibrary( GetDsoHandle(), kName, &f)) (OK vs. Not found: /home/wk15/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: cuptiActivityRegisterCallbacks)could not find cuptiActivityRegisterCallbacksin libcupti DSO
```
"
5281,feature: permutation,"This is a feature request on a Tensor creation function based on problems met when using tf.transpose.
Suppose I want to transpose a Tensor `a` (not variable) into a new Tensor, exchanging its two dimensions. Indices of the two dimensions are represented by two Tensors `b` and `c`.
From what I understand, there are only one complicated way of generating the argument `perm` in tf.transpose to achieve this in Tensorflow. That's by using tf.select twice.

``` python
dims = tf.range(5)
b = tf.constant(1)
c = tf.constant(3)
b_mask = tf.cast(tf.one_hot(b, 5), tf.bool)
c_mask = tf.cast(tf.one_hot(c, 5), tf.bool)
bs = tf.ones(5, tf.int32) * b
cs = tf.ones(5, tf.int32) * c
perm_1 = tf.select(b_mask, cs, dims)
perm_2 = tf.select(c_mask, bs, perm_1)
# ==> perm2: [0, 3, 2, 1, 4]
```

I personally feel this is too redundant for achieving such a simple operation. Could it be possible to add some op that generate permutations when it is not possible to be achieved by tf.gather (target dims are dynamic)?
"
5280,Ubuntu 16.04 - GPU-enabled binary for Python3.5 in Anaconda - NVidia Compute Capability 2.1 GPU not detected,"### Issue

I have an old GPU (GTX 560 Ti) with a power compute of 2.1, according to the Nvidia website. 

I am using Anaconda3 on Ubuntu, and I used the following binary to install Tensorflow:

```
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp35-cp35m-linux_x86_64.whl
```

Tensorflow is running, but trying the [Tensorflow.org test about using GPUs](https://www.tensorflow.org/versions/r0.11/how_tos/using_gpu/index.html), I get this output:

```
Device mapping: no known devices.
I tensorflow/core/common_runtime/direct_session.cc:252] Device mapping:

MatMul_5: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_5: /job:localhost/replica:0/task:0/cpu:0
```

Trying a manual device placement using `with tf.device('/gpu:0'):`, I get 

```
InvalidArgumentError: Cannot assign a device to node 'MatMul_4': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0
     [[Node: MatMul_4 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/device:GPU:0""](a_4, b_4)]]
```
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

I found this [https://github.com/tensorflow/tensorflow/issues/227](old issue): Compute capability < 3.5. The OP had the same GPU, but it was for a build from source.
### Environment info

Operating System: **Ubuntu 16.04**

Installed version of CUDA and cuDNN: **8.0.27 + 5.1.5**
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rw-r--r-- 1 root root   560184 Okt 29 20:06 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Okt 29 20:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Okt 29 20:06 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 Okt 29 20:05 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 Okt 29 20:06 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. A link to the pip package you installed:

```
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp35-cp35m-linux_x86_64.whl
```
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
0.11.0rc1
```
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

I tried the example in the test from the link above:

```
# Creates a graph.
with tf.device('/gpu:0'):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
  c = tf.matmul(a, b)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print sess.run(c)
```
"
5277,Eigen implemented CPU op is 10 times slower than OpenMP,"I implemented a phase CPU operator consisting of four loop levels. I couldn't find any Eigen tensor docs at that stage so I use OpenMP to trivially parallelise the outer loops. I recently found the Eigen tensor documentation so I thought I'd take advantage of it and get all the multithreading/AVX/SSE goodies for free!

Unfortunately the Eigen version is about 10 times slower!
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
### Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: CUDA 8.0 and cuDNN 5.1
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
$ ls -l /usr/local/cuda-8.0/lib64/libcud*
-rw-r--r-- 1 root root 558720 Sep 15 01:02 /usr/local/cuda-8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Sep 15 01:05 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root     19 Sep 15 01:05 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root 415432 Sep 15 01:02 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root 775162 Sep 15 01:02 /usr/local/cuda-8.0/lib64/libcudart_static.a
```

```
$ ls -l /usr/local/cudnn-5.1-cuda-8.0/lib64/lib*
lrwxrwxrwx 1 root root       13 Oct 28 10:07 /usr/local/cudnn-5.1-cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Oct 28 10:07 /usr/local/cudnn-5.1-cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 Oct 28 10:07 /usr/local/cudnn-5.1-cuda-8.0/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Oct 28 10:07 /usr/local/cudnn-5.1-cuda-8.0/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. A link to the pip package you installed: python 2.7 linux GPU nightly
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so locally
0.11.0rc1
```

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
- [Source code](https://github.com/ska-sa/montblanc/blob/07fa1dd8860de8f3e95a1ceada7524bdaa5c87a7/montblanc/impl/rime/tensorflow/rime_ops/phase_op_cpu.h).
- [Makefile](https://github.com/ska-sa/montblanc/blob/07fa1dd8860de8f3e95a1ceada7524bdaa5c87a7/montblanc/impl/rime/tensorflow/rime_ops/Makefile). In terms of optimisations I'm using **-O2** and **-fopenmp**
- [Test Case](https://github.com/ska-sa/montblanc/blob/07fa1dd8860de8f3e95a1ceada7524bdaa5c87a7/montblanc/impl/rime/tensorflow/rime_ops/test_phase.py) and timing code.
#### OpenMP
- Timings

```
Tensorflow custom GPU time 0.342187
Tensorflow expression GPU time 0.270267
Tensorflow CPU time 0.417076
Numpy CPU time 2.542890
```
- Code

``` cpp
// Compute the complex phase
#pragma omp parallel for
for(int src=0; src<nsrc; ++src)
{
    FT l = lm(src,0);
    FT m = lm(src,1);
    FT n = std::sqrt(1.0 - l*l - m*m) - 1.0;

    for(int time=0; time<ntime; ++time)
    {
        for(int antenna=0; antenna<na; ++antenna)
        {
            FT u = uvw(time,antenna,0);
            FT v = uvw(time,antenna,1);
            FT w = uvw(time,antenna,2);

            FT real_phase_base = minus_two_pi_over_c*(l*u + m*v + n*w);

            for(int chan=0; chan<nchan; ++chan)
            {
                // Our real phase input to the exponential function is purely imaginary so we can
                // can elide a call to std::exp<complex<FT>> and just compute the cos and sin
                FT real_phase = real_phase_base*frequency(chan);
                complex_phase(src,time,antenna,chan) = { std::cos(real_phase), std::sin(real_phase) };
            }
        }
    }
}
```
#### Eigen
- Timings

```
Tensorflow custom GPU time 0.344653
Tensorflow expression GPU time 0.275525
Tensorflow CPU time 9.616667
Numpy CPU time 2.505482
```
- Code

``` cpp
// Doing it this way might give us SIMD's and threading automatically...
const CPUDevice & device = context->eigen_device<CPUDevice>();

// Shapes for reshaping and broadcasting
Eigen::DSizes<int, 4>   lm_shape(nsrc, 1,     1,  1    );
Eigen::DSizes<int, 4>  uvw_shape(1,    ntime, na, 1    );
Eigen::DSizes<int, 4> freq_shape(1,    1,     1,  nchan);

auto l = lm.slice(
        Eigen::DSizes<int, 2>(0,    0),
        Eigen::DSizes<int, 2>(nsrc, 1))
    .reshape(lm_shape);
auto m = lm.slice(
        Eigen::DSizes<int, 2>(0,    1),
        Eigen::DSizes<int, 2>(nsrc, 1))
    .reshape(lm_shape);

auto u = uvw.slice(
        Eigen::DSizes<int, 3>(0,     0,  0),
        Eigen::DSizes<int, 3>(ntime, na, 1))
    .reshape(uvw_shape);

auto v = uvw.slice(
        Eigen::DSizes<int, 3>(0,     0,  1),
        Eigen::DSizes<int, 3>(ntime, na, 1))
    .reshape(uvw_shape);

auto w = uvw.slice(
        Eigen::DSizes<int, 3>(0,     0,  2),
        Eigen::DSizes<int, 3>(ntime, na, 1))
    .reshape(uvw_shape);

// Compute n
auto n = (l.constant(1.0) - l*l - m*m).sqrt() - l.constant(1.0);

// Compute the real phase
auto real_phase = (
    l.broadcast(uvw_shape)*u.broadcast(lm_shape) +
    m.broadcast(uvw_shape)*v.broadcast(lm_shape) +
    n.broadcast(uvw_shape)*w.broadcast(lm_shape))
        .broadcast(freq_shape);

// Reshape and broadcast frequency to match real_phase
auto f = frequency.reshape(freq_shape).broadcast(
    Eigen::DSizes<int, 4>(nsrc, ntime, na, 1));

// Calculate the phase
auto phase = real_phase*f*real_phase.constant(minus_two_pi_over_c);
auto sinp = phase.unaryExpr(Eigen::internal::scalar_sin_op<FT>());
auto cosp = phase.unaryExpr(Eigen::internal::scalar_cos_op<FT>());

// Now evaluate the complex phase on the device
// by combining the cosine and sine of the phase
// to form a complex number
complex_phase.device(device) = cosp.binaryExpr(
    sinp, make_complex_functor<FT>());
```
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
5276,TensorBoard histograms NaN value handling,"Recently I had to fight a lot with exploding gradients and thereby weights turning NaN after only several iterations event hough I was using _tf.contrib.layers.variance_scaling_initializer_ correctly. To monitor the problem I started saving weight histograms which seemed totally messed up. I thought this was due to me using the initializer wrongly and only after some debugging I realised my initialization was totally fine. The NaN values appearing in iteration _n_ seem to mess with the visualization of values in previous iterations which seems like a very misleading behaviour to me. Histograms and distributions should be visualized correctly until this is not really possible because of ill values.

I can easily provide tensorflow summary data to reproduce this behaviour.
"
5275,[Windows] Cannot import _pywrap_tensorflow when zlib.dll is not in PATH,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

[#1013](https://github.com/tensorflow/tensorflow/issues/1013)
etc...
### Environment info

Operating System:

Windows 10
Installed version of CUDA and cuDNN: 
No CUDA (""CPU support only"")

Pip wheel was self-build. Here's the output of `python -c ""import tensorflow; print(tensorflow.__version__)""`: [in attatchment](https://github.com/tensorflow/tensorflow/files/559847/output.txt)

If installed from source, provide 
git-rev output - 3737ac321e67410bf061257d5f644eae8abbf79b
No bazel (is it required?)
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

`import tensorflow`
### What other attempted solutions have you tried?

Install with `python setup.py install` and generally avoid any tedious building/making but with no success.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
[output.txt](https://github.com/tensorflow/tensorflow/files/559849/output.txt)
"
5272,"Tensorflow stop running while running ""sess=tf.Session()""","I am running tensorflow on ubuntu14.04 server using GPU and I had successuflly run the demo in the tutorial about mnist a few days ago.
Today, I run the same demo but to find it get stucked. I find out that I can import tensorflow successfully, but every time I run ""sess=tf.Session()"" the program will stop. It is strange that **neither error information sent back nor the python quit**. The cursor just stop there, enen ""ctrl+c"" does not work. 
As the server I installed tensorflow is public, I suspect that someone had changed something on the server. But I do not know. How can I fix it?
"
5268,Can I use multiple CPU but none GPU on inception v3 code?,"I have access to GPUs on the server, but the sysadmin has trouble on setting up CuDNN and CUDA, and I found when I use multi CPU on CIFAR-10 code, the speed was similar with GPUs. 
So I wonder whether there is a way to use the inception code to train the ImageNet in a environment with multiple CPUs like 32 or 64 CPU cores but none GPU?
"
5264,Error for souce code installation for Ubuntu14.04,"Hello, TF experts:
I want to install TF from source code**(I have already installed TF from virtualenv, so I dont know if this is a problem)**, but when I run `./configure`, I always get the error:

> WARNING: Output base '/aramis/home/wen/.cache/bazel/_bazel_wen/0e4e3a4a81f88b598a8f8eff37db10f2' is on NFS. This may lead to surprising failures and undetermined behavior.
> ........
> INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
> ERROR: /aramis/home/wen/.cache/bazel/_bazel_wen/0e4e3a4a81f88b598a8f8eff37db10f2/server (Directory not empty).

I tried the command below:
`bazel clean --expunge
, bazel clean --expunge_async`

It does not work.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

http://stackoverflow.com/questions/40144776/tensorflow-installation-error-directory-not-empty/40309084#40309084
### Environment info

Operating System: Ubuntu14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
low_source/tensorflow$ ls /usr/local/cuda/lib64/libcud*
/usr/local/cuda/lib64/libcudadevrt.a
/usr/local/cuda/lib64/libcudart.so
/usr/local/cuda/lib64/libcudart.so.7.5
/usr/local/cuda/lib64/libcudart.so.7.5.18
/usr/local/cuda/lib64/libcudart_static.a
/usr/local/cuda/lib64/libcudnn.so
/usr/local/cuda/lib64/libcudnn.so.4
/usr/local/cuda/lib64/libcudnn.so.4.0.7
/usr/local/cuda/lib64/libcudnn_static.a

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`) f794cd393b1e7821fcc3cdcee9b6a4400f2540bf
2. The output of `bazel version`

> WARNING: Output base '/aramis/home/wen/.cache/bazel/_bazel_wen/0e4e3a4a81f88b598a8f8eff37db10f2' is on NFS. This may lead to surprising failures and undetermined behavior.
> ........
> Build label: 0.3.2
> Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
> Build time: Fri Oct 7 17:25:10 2016 (1475861110)
> Build timestamp: 1475861110
> Build timestamp as int: 1475861110
> [1]+  Interrupt               /aramis/home/wen/.dropbox-dist/dropboxd  (wd: ~)
> (wd now: /aramis/dataARAMIS/users/junhao.wen/DeepLearning/TensorFlow/tensorflow_source/tensorflow)

Can you help me?????
Thanks in advance
"
5263,OOM Error Message Should Show Which GPU is Out of Memory,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

I've created a few overflow threads in regards to balancing seq2seq memory loads over multiple gpus here:

http://stackoverflow.com/questions/39773645/split-rnn-memory-consumption-evenly-between-gpus-in-tensorflow
### Environment info

Operating System:

Ubuntu 14.04 CUDA 7.5 -- tensorflow 0.11
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

Simply load two matrices. One incredibly larger one on a gpu0 and a smaller one on gpu1. It would be great if the OOM message could tell you which gpu ran out of memory. This way you can redistribute resources from one gpu to another.
### What other attempted solutions have you tried?

Currently I look at all tensors assigned per device and how large each tensor it is. I then sum the size of these tensors using the following code:

``` python
def calculate_variable_sizes_per_device(batch_size = 64):
  dev_list = get_available_gpus()
  dev_size_list = [[dev_list[i], 0] for i in xrange(len(dev_list))]

  tf.logging.info('calculating variable sizes on respective devices: %d' % len(dev_list))
  print('dev_list', dev_list)
  for eachvar in tf.all_variables():
    device = eachvar.device
    print('device', device)
    var_shape = find_replace_list(eachvar.get_shape().as_list(), '?', batch_size)
    print('varshape',var_shape)
    var_size = np.prod(np.array(var_shape))
    print('varsize', var_size)  

    for i,dev in enumerate(dev_list):
      if dev.replace('/','') in device.lower():
        dev_size_list[i][1] += var_size

  return dev_size_list

def find_replace_list(list_, find, replace):
  for n,i in enumerate(list_):
    if i==find:
      list_[n]=replace
  return list_


def get_available_gpus():
  local_device_protos = device_lib.list_local_devices()
  return [x.name for x in local_device_protos] #if x.device_type == 'GPU']
```
"
5261,Running a computation graph in C++ with custom ops,"The current C API does not seem to support loading custom op library, which is tf.load_op_library for python.
Because of this, I cannot run a computation graph with custom ops.
Is there any way I can register custom ops in C?
"
5260,Why the embedding_lookup() returns zeros when the index exceed embedding matrix size?,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

I'm now using TF version 0.10.0 installed from source.
I'm not sure its a bug or intended implementation but the `embedding_lookup()` returns zeros when the index exceed embedding matrix size. For example,

```
 import tensorflow as tf
 import numpy as np

 embd_mat = np.linspace(1,10,10).reshape([10,1])*np.array([1,2,3]).reshape([1,3])
 idx = np.linspace(0,19,20)

 embd_in = tf.placeholder(tf.float32,[10,3])
 idx_in = tf.placeholder(tf.int32,[20])

 output = tf.nn.embedding_lookup(embd_in,idx_in)

 with tf.Session() as sess:
     sess.run(tf.initialize_all_variables())

     embd_out = sess.run(output,feed_dict={embd_in:embd_mat, idx_in:idx})

     print embd_out
```

The output of above code is,

```
[[  1.   2.   3.]
 [  2.   4.   6.]
 [  3.   6.   9.]
 [  4.   8.  12.]
 [  5.  10.  15.]
 [  6.  12.  18.]
 [  7.  14.  21.]
 [  8.  16.  24.]
 [  9.  18.  27.]
 [ 10.  20.  30.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]]
```

Is there any reason it returns zeros not raises an error?
I think that case happens only when programmers make a mistake.
Unless there is any specific reason which I don't know of, I think it should raise a value error that the index is exceeding the matrix size.    
"
5258,access list input in self-defined op in tensorflow,"I want to define an op myself according to documents in tensorflow provided in the link below:
https://www.tensorflow.org/versions/r0.11/how_tos/adding_an_op/index.html#naming

The simplest example is as below:
1. You register the variables
`
REGISTER_OP(""ZeroOut"")
    .Input(""to_zero: int32"")
    .Output(""zeroed: int32"")
`
1. You covert input to a C++ reference as shown here:

`
void Compute(OpKernelContext* context) override {
    // Grab the input tensor
    const Tensor& input_tensor = context->input(0);
    auto input = input_tensor.flat<int32>();
....
}
`

So my question is: if the input is a list of tensors, then should we convert it into vector<Tensor> in C++, like the example below?
`
const vector<Tensor>& input_tensor = context->input(0);
`
"
5257,tf.while_loop seg faults upon setting parallel_iterations=0,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Haven't found segmentation error related issue with tf.while_loop yet.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
cuda-7.5
-rw-r--r-- 1 root root 189170 Jun 14 14:21 libcudadevrt.a
lrwxrwxrwx 1 root root     16 Jun 14 14:21 libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Jun 14 14:21 libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Jun 14 14:21 libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Jun 14 14:21 libcudart_static.a

If installed from binary pip package, provide:
1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

``` python
import tensorflow as tf                                                                                                                                                                        
import numpy as np                                                                                                                                                                             

i = tf.constant(0)                                                                                                                                                                             
s = tf.constant(0)                                                                                                                                                                             
x = tf.random_uniform([], 0, 761-64, dtype=tf.int32)                                                                                                                                           
p = tf.Print(x, [x], message=""This is random x: "")                                                                                                                                             
c = lambda i,s,x,p: tf.less(i, 50)                                                                                                                                                             
b = lambda i,s,x,p: (tf.add(i, 1), tf.add(s, x),tf.random_uniform([], 0,                                                                                                                       
    761-64, dtype=tf.int32),tf.Print(x, [x], message=""This is random x: ""))                                                                                                                    
r = tf.while_loop(c, b, [i,s,x,p], parallel_iterations=1)

sess = tf.Session()                                                                                                                                                                            
init = tf.initialize_all_variables().run                                                                                                                                                       
print sess.run(r)
```
### What other attempted solutions have you tried?

only ways which do not use the while loop.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).

error output:
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.4 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:04:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)
Segmentation fault (core dumped)
"
5255,Error compiling Raspberry Pi label_image,"Hi there,
I'm trying to build Temsorflow on a Raspberry pi 3 running Raspbian Jessie and kernel 4.3.
I followed the instructions on: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile 
When I compile the label_image example, as described in:
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/pi_examples
I receive the following compilation errors with:  make -f tensorflow/contrib/pi_examples/label_image/Makefile

gcc --std=c++11 -O0 -I/usr/local/include -I. -I/home/pi/utensor/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/downloads -I/home/pi/utensor/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/downloads/eigen-latest/ -I/home/pi/utensor/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/proto/ -I/home/pi/utensor/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/proto_text/ -c tensorflow/contrib/pi_examples/label_image/label_image.cc -o /home/pi/utensor/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o
In file included from ./tensorflow/core/framework/tensor.h:19:0,
                 from tensorflow/contrib/pi_examples/label_image/label_image.cc:32:
./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:4:42: fatal error: unsupported/Eigen/CXX11/Tensor: No such ffile or directory
 #include ""unsupported/Eigen/CXX11/Tensor""
                                                                    ^
compilation terminated.

Is there anyway to fix it?
Thanks.
"
5254,Error when using tf.contrib.crf and tflearn to build sequential labeling tasks,"I'm using tf.contrib.crf and tflearn to build sequential labeling tasks,

Build when testing the implementation, the InvalidArgumentError occurs in sess.run

Here's the snippet code.

``` python
import numpy as np
import tensorflow as tf
import tflearn

def retrieve_sequence_length(data):
    with tf.name_scope('sequence_length'):
        used = tf.sign(tf.abs(data))
        length = tf.cast(tf.reduce_sum(used, reduction_indices=[1, 2]), tf.int32)
    return length 

def loss(x, y, sequence_length):
    with tf.name_scope('loss'):
        n_states = x.get_shape()[-1].value
        transition_params = tflearn.variable(name='transition_params', shape=[n_states, n_states], 
                                             initializer='xavier', dtype=tf.float32)
        loss = tf.contrib.crf.crf_log_norm(x, sequence_length, transition_params)
        # loss, _ = tf.contrib.crf.crf_log_likelihood(x, y, sequence_length, transition_params)
    return tf.reduce_mean(loss)

# Data settings.
num_examples = 10000
num_words = 20
num_features = 100
num_tags = 5

# Random features.
x = np.random.uniform(low=0.1, high=1.1, size=(num_examples, num_words, num_features)).astype(np.float32)

# Random tag indices representing the gold sequence.
y = np.random.randint(num_tags, size=[num_examples, num_words]).astype(np.int32)

# All sequences in this example have the same length, but they can be variable in a real model.
# sequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)


input0 = tflearn.input_data(shape=[None, num_words, num_features], dtype=tf.float32)
sequence_length = retrieve_sequence_length(input0)
print 'sequence_length: ', sequence_length

unary_scores = tflearn.time_distributed(input0, tflearn.fully_connected, [num_tags, 'softmax'])
print 'unary_score: ', unary_scores

net = tflearn.regression(unary_scores,
                         placeholder=tf.placeholder(shape=[None, num_words], dtype=tf.int32),
                         learning_rate=0.001,
                         optimizer='sgd',
                         loss=lambda x, y: loss(x, y, sequence_length),
                         metric=None,
                         n_classes=num_tags,
                         to_one_hot=False)

model = tflearn.DNN(net)

model.fit(x, y, batch_size=32)
```

The stacktrace is :

```
Traceback (most recent call last):
  File ""c.py"", line 54, in <module>
    model.fit(x, y, batch_size=32)
  File ""/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/models/dnn.py"", line 214, in fit
    callbacks=callbacks)
  File ""/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/helpers/trainer.py"", line 304, in fit
    show_metric)
  File ""/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/helpers/trainer.py"", line 762, in _train
    feed_batch)
  File ""/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 915, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 965, in _do_run
    target_list, options, run_metadata)
  File ""/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 985, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: All inputs to node SGD/gradients/loss/RNN/while/expand_dims_state_grad/Reshape/StackPush must be from the same frame.
```
"
5253,Let user to choice whether to do bazel clean during configure,"Currently running the configure will do 'bazel clean --expunge' by default.  It is OK for the first time to run configure.  But when I need to rerun the configure (because some errors occur, I will retry), I have to spend much time to download files from internet again each time during to the execution of 'bazel clean --expunge'. 

So, should we let user to choice whether to do bazel clean during configure?
"
5252,multigpu gradient averaging if grad_op is IndexedSlices; race condition in apply_gradients?,"If one follows the [`cifar10_multi_gpu_train.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py) example (build two towers that share weights, feed data independently, collect gradients, average them, apply then) and passes gradients to the [`average_gradients()`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L110) function, but graph uses `tf.gather` consequently, the resulting gradient op will be `IndexedSlices` that has many `-1` values in `indices` field (from my experience, not sure about why this happens), so when tensorflow will attempt to apply `tensorflow.python.ops.gradients._IndexedSlicesToTensor` to convert it to Tensor (to apply `tf.expand_dims` on it), it will fail on [`unsorted_segment_sum`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/gradients.py#L92) , because `-1`s are indeed not in the indexes range. I have explicitly printed `w_grad_op.indices` and they looked like: 

```
[0 1 2 3 6 4 5 6 7 8 9 13 12 11 15 16 ... 230 231 -1 -1 ... -1 280 -1 -1 265 -1 -1 ... -1]
```

\- so the `average_gradients()` indeed fails on these examples (people have been reporting similar problems [[1]](http://stackoverflow.com/questions/37074077/fail-to-average-indexedslices-on-porting-ptb-word-lm-py-to-multi-gpu-towers), [[2]](http://stackoverflow.com/questions/39017896/tensorflow-how-to-average-several-indexedslicesvalue) .. 2-3 more around the web).

One way of dealing with (solution 1) it is just applying gradients consequentially (with lower learning rate) instead of averaging them first:

```
 train_op = tf.group(*[gd.apply_gradients(grad) for grad in tower_grads])
```

\-  this works great and scales nicely, but (in my case) led to some weird convergence issues (eventually leading to `nan`s popping here and there), possibly because of some sort of race conditions (?), while applying gradients (`gd.apply_gradients()` is probably not very atomic). One possible workaround (solution 2) might be to use `tf.control_dependencies`:

```
def rigid_op_sequence(op_lambdas):
    ## equivalent to:
    ## op = op1()
    ## with.control_dependencies([op]):
    ##    op = op2()
    ##    with.control_dependencies([op]):
    ##        op = op3()
    ##        ...
    ## return op

    with ExitStack() as stack:
        for op_func in op_lambdas:
            op = op_func()
            context = tf.control_dependencies([op])
            stack.enter_context(context)
    return op

grad_update_lambdas = [(lambda: gd.apply_gradients(grad)) for grad in tower_grads]
train_op = rigid_op_sequence(grad_update_lambdas)
```

however this solution seems to somewhat significantly degenerate performance, because of that ""blocking"" (GPU load dropped from ~90% to ~60%).

Several fundamental questions:
1. What is officially recommended way of dealing with this ""multigpu IndexedSlices"" case? (could not find any; people keep asking)
2. Does (solution 1) indeed might experience race condition or tensorflow handles it somehow and my convergences issues were not related to that? (and we all can just use solution 1)
"
5251,Incorrect comment on cifar10.py,"Hi there,
On line 259 of cifar10.py, the comment is `# softmax, i.e. softmax(WX + b)`, but actually this layer only did a liner calculation(wx+b). So I believe this is a little bit misunderstanding for a newbie like me. 
"
5250,NaN gradient after py_func call,"Hello,

I did implemented faster rcnn with py_func op. 
- py-func is placed in the middle of graph. And there are the other path in parallel with py_func node.
- I did not add any gradient function for it, So it should ignore gradient path through py_func. And gradient calculation should done with connection from the other path.

It works fine in tensorflow r0.9 version. 
But, in the tensorflow version > r0.9, the node before py_func get NaN error when writing histogram summary. .
I did check several version: r0.10, r0.11, all of them does not worked.

Is there any change in gradient calculation for the node which have connection with py_func node ?
Or should I use py-func in different way?

Any advice will be helpful for me.
Thanks in advance.
"
5249,AttributeError: 'module' object has no attribute 'save_v2',"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None
### Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
/usr/local/cuda/lib64/libcudadevrt.a    /usr/local/cuda/lib64/libcudart.so.8.0.44  /usr/local/cuda/lib64/libcudnn.so.5
/usr/local/cuda/lib64/libcudart.so  /usr/local/cuda/lib64/libcudart_static.a   /usr/local/cuda/lib64/libcudnn.so.5.1.5
/usr/local/cuda/lib64/libcudart.so.8.0  /usr/local/cuda/lib64/libcudnn.so      /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   `0.11.0rc1`

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

`tf.train.Saver(..., write_version=tf.train.SaverDef.V2)`
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).

```
 File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1077, in __init__
   self.build()
 File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1106, in build
   restore_sequentially=self._restore_sequentially)
 File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 702, in build
   save_tensor = self._AddSaveOps(filename_tensor, saveables)
 File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 309, in _AddSaveOps
   save = self.save_op(filename_tensor, saveables)
 File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 252, in save_op
   return io_ops.save_v2(filename_tensor, tensor_names, tensor_slices,
AttributeError: 'module' object has no attribute 'save_v2'
```
"
5247,tensorboard demos don't work because of wrong paths,"Checked on commit 32d1dcc10e1fdf33dc6742337c6e0869f7b3c557.

Issue:
While going through tensorboard/DEVELOPMENT.MD it is not possible to have tensorboard's demos working as demo's html as well as components htmls import other html with wrong file names.

For example in:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/demo/index.html

there is an import of `../components/tf-tensorboard/tf-tensorboard.html` and in fact this file doesn't exist. It exist under slightly different file name with replaced ""-"" with ""_"" (../components/tf_tensorboard/tf-tensorboard.html)

The difference is in directory names.
The same occurs if I want to load particular component's demo.
"
5245,mean_squared_error gives warning about sum_of_squared_error,"I used tf.contrib.losses.mean_squared_error, but during training stage, tensorflow give me warning `WARNING:tensorflow:sum_of_squares (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-10-01.`

But I already used mean_squared_error, so this warning should not show. 

Also the mean_squared_error [definition link](https://www.tensorflow.org/versions/r0.11/api_docs/python/contrib.losses.html#mean_squared_error) has the same warning, which I guess should not be there?
"
5244,Allow setting session level options and run_metadata in SKFlow Estimator.fit(),"Feature request: Allow specifying `Session.run()` parameters `options` and `run_metadata` when calling `Estimator.fit()`.  

Use case: The [Chrome Timeline profiling method](http://stackoverflow.com/questions/37751739/tensorflow-code-optimization-strategy/37774430#37774430) requires setting these options.

Possible implementation:  add an additional fields to the `RunConfig` class that can be set when when the `Estimator` is initialized. Then pass these options to `graph_actions._monitored_train()`, which then added them to the `MonitoredSession.run()` function call.
"
5243,Bug with cifar10 ?,"Hi everyone,
I'm trying to make prediction with the cifar-10 model in /tensorflow/models/image/cifar10
But it don't work.
Here is the code I tried : 

```
from PIL import Image
import tensorflow as tf
from tensorflow.models.image.cifar10 import cifar10
import itertools
width = 24
height = 24

categories = [ ""airplane"",""automobile"",""bird"",""cat"",""deer"",""dog"",""frog"",""horse"",""ship"",""truck"" ]

filename = ""toto.jpg"" # absolute path to input image
im = Image.open(filename)
im.save(filename, format='JPEG', subsampling=0, quality=100)
x = tf.placeholder(tf.float32, [None, 24, 24, 3])
logits = cifar10.inference(x)
_, top_k_pred = tf.nn.top_k(logits, k=5)
init_op = tf.initialize_all_variables()
with tf.Session() as sess:
 # Restore variables from training checkpoint.
    input_img = tf.image.decode_jpeg(tf.read_file(filename), channels=3)
    tf_cast = tf.cast(input_img, tf.float32)
    float_image = tf.image.resize_image_with_crop_or_pad(tf_cast, height, width)
    images = tf.expand_dims(float_image, 0)
    i = images.eval()
    print (i)
    sess.run(init_op, feed_dict={x: i})
    variable_averages = tf.train.ExponentialMovingAverage(
        cifar10.MOVING_AVERAGE_DECAY)
    variables_to_restore = variable_averages.variables_to_restore()
    saver = tf.train.Saver(variables_to_restore)
    ckpt = tf.train.get_checkpoint_state('/tmp/cifar10_train')
    if ckpt and ckpt.model_checkpoint_path:
        print(""ckpt.model_checkpoint_path "", ckpt.model_checkpoint_path)
        saver.restore(sess, ckpt.model_checkpoint_path)
    else:
        print('No checkpoint file found')
        exit(0)
    _, top_indices = sess.run([_, top_k_pred])
    for key, value in enumerate(top_indices[0]):
        print (categories[value] + "", "" + str(_[0][key]))
```

And here is the error I got : 
```
InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [18,384] rhs shape= [2304,384]
     [[Node: save/Assign_5 = Assign[T=DT_FLOAT, _class=[""loc:@local3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](local3/weights, save/RestoreV2_5)]]
```

So, it seems than Tensorflow is not happy because the shape of the single image I want to predict [1,24,24,3] don't fit with the shape of a normal batch [128,24,24,3]
But, for one single image, it's necessary like this.

Maybe I miss something but I don't get it... Or maybe it's a bug ?
I already asked the question on stackoverflow in first place, here : http://stackoverflow.com/questions/40266275/tensorflow-and-cifar-10-testing-single-images#

But since it could be a bug, and nobody answered, I post here..

Thanks in advance!
"
5242,Windows GPU gradient always 0 but CPU works,"Hello all,
I was working on installing and testing the new windows gpu support and it does not seem to be working right for me. To start off, I was following [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md) and I have all of the same software as their windows 10 known good configuration, except I have Microsoft Visual Studio **Community** 2015 with Visual C++ 2015.
My github head is: 2cbb9b529a6723ebbe07663156b18c04fbaf4531
After I few times of trying to get it to install, I managed to get it to install by changing to cmake 3.6 from 3.7. It installed fine but it does not seem to work properly. 
I downloaded some known good code, file [here](http://pastebin.com/AiTaaizs), and when I run it specifiying that tensorflow should use cpu, I get good output that looks like [this](http://pastebin.com/nQFcMZ07). If I allow it to run on gpu, I get bad output that looks like [this](http://pastebin.com/dcDYsfWr). I am not sure why. I feel like it is probably an issue with my install even though it had no errors. Any help would be greatly appreciated.
"
5240,"0.11.0rc1 linux 2.7 GPU nightlies ignore CUDA 7.5 installation, wants CUDA 8.0","A couple of days ago the 0.11.0rc1 nightly depended on CUDA 7.5 [#269 for example](https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/269/). I've just downloaded today's nightly and it seems to want CUDA 8.0. Is CUDA 8.0 the new pip binary dependency or is this a mistake?
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

N/A
### Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: CUDA 7.5 and cuDNN 4.0.7
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
$ ls -l /usr/lib/x86_64-linux-gnu/libcud*
-rw-r--r-- 1 root root   322936 Sep 19  2015 /usr/lib/x86_64-linux-gnu/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Mar 30  2016 /usr/lib/x86_64-linux-gnu/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Mar 30  2016 /usr/lib/x86_64-linux-gnu/libcudart.so.7.5 -> libcudart.so.7.5.18
-rw-r--r-- 1 root root   383336 Sep 19  2015 /usr/lib/x86_64-linux-gnu/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Sep 19  2015 /usr/lib/x86_64-linux-gnu/libcudart_static.a
lrwxrwxrwx 1 root root       12 Jun  5 01:26 /usr/lib/x86_64-linux-gnu/libcuda.so -> libcuda.so.1
lrwxrwxrwx 1 root root       17 Jun  5 01:26 /usr/lib/x86_64-linux-gnu/libcuda.so.1 -> libcuda.so.364.19
-rw-r--r-- 1 root root 16963368 Apr 19  2016 /usr/lib/x86_64-linux-gnu/libcuda.so.364.19
lrwxrwxrwx 1 root root       13 Aug 29 10:59 /usr/lib/x86_64-linux-gnu/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 root root       17 Aug 29 10:59 /usr/lib/x86_64-linux-gnu/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxr-xr-x 1 root root 61453024 Aug 29 10:59 /usr/lib/x86_64-linux-gnu/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Aug 29 10:59 /usr/lib/x86_64-linux-gnu/libcudnn_static.a
```

If installed from binary pip package, provide:
1. A link to the pip package you installed:
   [link](https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.11.0rc1-cp27-none-linux_x86_64.whl)
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
$ python -c 'import tensorflow'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/sperkins/venv/tftest/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/home/sperkins/venv/tftest/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 60, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/sperkins/venv/tftest/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/sperkins/venv/tftest/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/home/sperkins/venv/tftest/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory


Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.
```

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
5237,Problem compiling tensorflow for iOS ,"**Environment info:**
Operating System: macOS 10.11.6â¨
xcode 7.3.1â¨

**Steps to reproduce:**
I follow the steps from here [ios_examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/ios_examples) and the steps specific to install for iOS described here
[makefile](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile)

**Basically what i did:**
- Clone the repository
- Download the graph
- Build

**Building all at once:** 

`tensorflow/contrib/makefile/build_all_ios.sh`

Results in:

```
+ PROTOC_PATH=/Users/ppcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc
+ [[ ! -f /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc ]]
+ echo 'protoc not found at /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc. Build it first.'
protoc not found at /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc. Build it first.
+ make_host_protoc /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host
+ [[ ! -n /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host ]]
+ HOST_GENDIR=/Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host
+ ./autogen.sh
Google Mock not present.  Fetching gmock-1.7.0 from the web...
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   129    0   129    0     0    172      0 --:--:-- --:--:-- --:--:--   172
100  362k  100  362k    0     0   177k      0  0:00:02  0:00:02 --:--:--  349k
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   129    0   129    0     0    176      0 --:--:-- --:--:-- --:--:--   176
100  618k  100  618k    0     0   288k      0  0:00:02  0:00:02 --:--:--  511k
+ autoreconf -f -i -Wall,no-obsolete
configure.ac:30: error: possibly undefined macro: AC_PROG_LIBTOOL
      If this token and others are legitimate, please use m4_pattern_allow.
      See the Autoconf documentation.
autoreconf: /usr/local/Cellar/autoconf/2.69/bin/autoconf failed with exit status: 1


```

**Building by hand:**

I have downloaded all dependencies with the command:
`tensorflow/contrib/makefile/download_dependencies.sh`
Result:
`download_dependencies.sh completed successfully.`

**Than when I try to compile protobufs:**

`tensorflow/contrib/makefile/compile_ios_protobuf.sh`

**I have the following result, similar to the one from above:**

```
+ PROTOC_PATH=/Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc
+ [[ ! -f /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc ]]
+ echo 'protoc not found at /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc. Build it first.'
protoc not found at /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc. Build it first.
+ make_host_protoc /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host
+ [[ ! -n /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host ]]
+ HOST_GENDIR=/Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host
+ ./autogen.sh
+ autoreconf -f -i -Wall,no-obsolete
configure.ac:30: error: possibly undefined macro: AC_PROG_LIBTOOL
      If this token and others are legitimate, please use m4_pattern_allow.
      See the Autoconf documentation.
autoreconf: /usr/local/Cellar/autoconf/2.69/bin/autoconf failed with exit status: 1


```

**Observation:**

When I look into the folder from bellow it contains an empty folder named lib:
`tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios`

The folder from bellow is empty:
`tensorflow/tensorflow/contrib/makefile/gen/protobuf-host`

Conclusion: it seems to me that there is a problem building protobuf.
What does the message ""Google Mock not present."" exactly mean?
"
5236,Extend the info in the placement log to include the node type,"Small suggestion:

In the function SimplePlacer::AssignAndLog, change the print and log to be:

```
printf(""%s (%s): %s\n"", node->name().c_str(),
       node->type_string().c_str(),
       node->assigned_device_name().c_str());
```
"
5235,ResourceExhaustedError on GPU,"Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: CUDA 8.0, cuDNN 5

(please attach the output of ls -l /path/to/cuda/lib/libcud*):

/usr/local/cuda/lib64/libcudadevrt.a
/usr/local/cuda/lib64/libcudart.so
/usr/local/cuda/lib64/libcudart.so.8.0
/usr/local/cuda/lib64/libcudart.so.8.0.27
/usr/local/cuda/lib64/libcudart_static.a
/usr/local/cuda/lib64/libcudnn.so
/usr/local/cuda/lib64/libcudnn.so.5
/usr/local/cuda/lib64/libcudnn.so.5.0.5
If installed from sources, provide the commit hash:
2cbb9b529a6723ebbe07663156b18c04fbaf4531

Hi All, 
I am able to run the following code on CPU, but when on GPU, I got a `ResourceExhaustedError`, My GPU is an GTX1080 one, which has 8G memeory.

```
import tensorflow as tf
import numpy as np

sess = tf.Session()

inputs = tf.placeholder(tf.float32, shape=(30,224,224,512))
with tf.device('/gpu:0') as d:
    kernel = tf.Variable(tf.truncated_normal([9,9,512,36], dtype=tf.float32,stddev=1e-1), name='weights')
    conv = tf.nn.conv2d(inputs, kernel, [1, 1, 1, 1], padding='SAME')

inputs_arr = np.random.random((30,224,224,512)).astype(np.float32)
sess.run(tf.initialize_variables([kernel]))
cc = sess.run(conv, feed_dict={inputs: inputs_arr})
```

Error message:

```
---------------------------------------------------------------------------
ResourceExhaustedError                    Traceback (most recent call last)
/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
    971     try:
--> 972       return fn(*args)
    973     except errors.OpError as e:

/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
    953                                  feed_dict, fetch_list, target_list,
--> 954                                  status, run_metadata)
    955 

/home/xlws/anaconda3/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)
     65             try:
---> 66                 next(self.gen)
     67             except StopIteration:

/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()
    462           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 463           pywrap_tensorflow.TF_GetCode(status))
    464   finally:

ResourceExhaustedError: OOM when allocating tensor with shape[30,36,224,224]
     [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_1, weights/read)]]
     [[Node: Conv2D/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_4_Conv2D"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

During handling of the above exception, another exception occurred:

ResourceExhaustedError                    Traceback (most recent call last)
<ipython-input-1-92fd065a1eed> in <module>()
     12 inputs_arr = np.random.random((30,224,224,512)).astype(np.float32)
     13 sess.run(tf.initialize_variables([kernel]))
---> 14 cc = sess.run(conv, feed_dict={inputs: inputs_arr})

/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    715     try:
    716       result = self._run(None, fetches, feed_dict, options_ptr,
--> 717                          run_metadata_ptr)
    718       if run_metadata:
    719         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
    913     if final_fetches or final_targets:
    914       results = self._do_run(handle, final_targets, final_fetches,
--> 915                              feed_dict_string, options, run_metadata)
    916     else:
    917       results = []

/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
    963     if handle is None:
    964       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
--> 965                            target_list, options, run_metadata)
    966     else:
    967       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
    983         except KeyError:
    984           pass
--> 985       raise type(e)(node_def, op, message)
    986 
    987   def _extend_graph(self):

ResourceExhaustedError: OOM when allocating tensor with shape[30,36,224,224]
     [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_1, weights/read)]]
     [[Node: Conv2D/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_4_Conv2D"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op 'Conv2D', defined at:
  File ""/home/xlws/anaconda3/lib/python3.5/runpy.py"", line 184, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/xlws/anaconda3/lib/python3.5/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py"", line 596, in launch_instance
    app.start()
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py"", line 442, in start
    ioloop.IOLoop.instance().start()
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py"", line 162, in start
    super(ZMQIOLoop, self).start()
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py"", line 883, in start
    handler_func(fd_obj, events)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 391, in execute_request
    user_expressions, allow_stdin)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py"", line 199, in do_execute
    shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2723, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2825, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2885, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-92fd065a1eed>"", line 10, in <module>
    conv = tf.nn.conv2d(inputs, kernel, [1, 1, 1, 1], padding='SAME')
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 394, in conv2d
    data_format=data_format, name=name)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 748, in apply_op
    op_def=op_def)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2403, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1305, in __init__
    self._traceback = _extract_stack()

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[30,36,224,224]
     [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_1, weights/read)]]
     [[Node: Conv2D/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_4_Conv2D"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```
"
5234,tensorflow/core/framework/op_kernel.cc:968 Invalid argument: Could not parse example input,"I'm trying to convert images (PNG) to `tf-records` files. When I read `tf-records` files. I saw lots of unreadable code on the screen. Please help to find the problem. I list my problems and code below:

I need to convert a sequence of images (10 PNGs) into a single `tf-records` file. I have several sequences of images and each sequence (10 PNGs) is in a folder. Here is the code I used to convert images to `tf-records`:

```
import os, sys
import tensorflow as tf
import numpy as np
from PIL import Image

def _int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

def _bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

def read():
    # parent folder contains all sequence, each sequence (10 png) is in a sub-folder 
    parent_foler = sys.argv[1]
    for folder in os.listdir(parent_foler):
        images = read_images_from(parent_foler + '/' + folder)
        num_examples = len(images)

        print 'Number of images: ' + str(num_examples)
        outputFile = os.path.join(parent_foler, folder + '.tfrecords')
        writer = tf.python_io.TFRecordWriter(outputFile)
        fs = {}
        for index in range(num_examples):
            image_raw = images[index].tostring()
            image_name = 'move/' + str(index) + '/image/encoded'
            fs[image_name] = _bytes_feature(image_raw)
            print folder + ':' + image_name
        print 'Size of Features:' + str(len(fs))
        example = tf.train.Example(features=tf.train.Features(feature=fs))
        writer.write(example.SerializeToString())
        writer.close()

def read_images_from(folder_name):
    images = []
    files_to_read = [folder_name + '/' + folder_name.split('/')[-1] + '_' + str(i + 1) + '.png' for i in range(10)]
    for filename in files_to_read:
        im = Image.open(filename)
        im = np.asarray(im, np.uint8)
        images.append(im)
    images = np.array(images)
    print'shape of images: ' + str(images.shape)
    return images

if __name__ == ""__main__"":
    read()
```

Here is the code to read these `tf-records` files: (adapted from [this code](https://github.com/tensorflow/models/blob/master/video_prediction/prediction_input.py))

```
ORIGINAL_WIDTH = 2048
ORIGINAL_HEIGHT = 1536
COLOR_CHAN = 4

def build_tfrecord_input(tf_folder):
    filenames = [foldername + '/' + tf_file for tf_file in os.listdir(tf_folder)]
    filename_queue = tf.train.string_input_producer(filenames, shuffle=True)
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    image_seq = []

    # FLAGS.sequence_length = 10
    for i in range(FLAGS.sequence_length): 
        image_name = 'move/' + str(i) + '/image/encoded'
        features = {image_name: tf.FixedLenFeature([1], tf.string)}
        features = tf.parse_single_example(serialized_example, features=features)
        image = tf.decode_raw(features[image_name], tf.uint8)
        image = tf.reshape(image, shape=[ORIGINAL_HEIGHT,ORIGINAL_WIDTH,COLOR_CHAN])
        image.set_shape([ORIGINAL_HEIGHT, ORIGINAL_WIDTH, COLOR_CHAN])

        crop_size = min(ORIGINAL_HEIGHT, ORIGINAL_WIDTH)
        image = tf.image.resize_image_with_crop_or_pad(image, crop_size, crop_size)
        image = tf.reshape(image, [1, crop_size, crop_size, COLOR_CHAN])
        image = tf.image.resize_bicubic(image, [IMG_HEIGHT, IMG_WIDTH])
        image = tf.cast(image, tf.float32) / 255.0
        image_seq.append(image)

        image_seq = tf.concat(0, image_seq)

    return image_seq
```

When the training code runs to

```
tf.train.start_queue_runners(sess)
sess.run(tf.initialize_all_variables())
```

I saw unreadable code:

ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½|ï¿½ï¿½ï¿½|ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½}ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½}ï¿½ï¿½ï¿½}ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½}ï¿½ï¿½~|ï¿½~}{ï¿½~}{ï¿½~}{ï¿½~}{ï¿½~}{ï¿½ï¿½~|ï¿½ï¿½ï¿½}ï¿½ï¿½ï¿½}ï¿½ï¿½ï¿½}ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½|ï¿½ï¿½ï¿½|ï¿½ï¿½ï¿½|ï¿½ï¿½ï¿½|ï¿½ï¿½ï¿½}ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½}ï¿½ï¿½ï¿½{ï¿½~}yï¿½}|xï¿½|{wï¿½|{wï¿½}|xï¿½|{wï¿½{zvï¿½zyuï¿½xwsï¿½wvrï¿½vuqï¿½utpï¿½tsoï¿½tsoï¿½tsoï¿½utpï¿½tsoï¿½utpï¿½utpï¿½utpï¿½tsoï¿½tsoï¿½utpï¿½utpï¿½tsoï¿½utpï¿½utpï¿½vuqï¿½wvrï¿½xwsï¿½yxtï¿½zyuï¿½{zvï¿½|{wï¿½}|xï¿½}|xï¿½}|xï¿½}|xï¿½}|xï¿½}|xï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}yï¿½~}xï¿½ï¿½~yï¿½ï¿½~wï¿½ï¿½~wï¿½ï¿½~wï¿½ï¿½~wï¿½ï¿½~wï¿½ï¿½~wï¿½ï¿½~wï¿½ï¿½~wï¿½ï¿½~wï¿½ï¿½~W tensorflow/core/framework/op_kernel.cc:968] Invalid argument: Could not parse example input, value: '
ï¿½ï¿½ï¿½<
ï¿½ï¿½ï¿½ï¿½
ï¿½move/7/image/encodedï¿½ï¿½ï¿½ï¿½ï¿½
ï¿½ï¿½ï¿½ï¿½

Can anyone tell me which part of the code is wrong?

Thanks very much in advance,
Andy.
"
5231,[FEATURE REQUEST] More than 2D matmul,"Hello!
I just would like to know if high dimensional matmul will be supported in the future?
For example, I have a 3D tensor a and a matrix b as below:

``` python
a = [[[1,1],
         [1,1]],
        [[2,2],
         [2,2]]]
b = [[1,1], [1,1]]
```

In numpy, np.dot(a, b) will return

``` python
[[[2,2],
   [2,2]],
  [[4,4],
    [4,4]]]
```

But in tensorflow tf.matmul only supports 2D \* 2D.

Actually using tf.conv2d and reshaping can do the same thing,  it would be more natural that tf.matmul could do as well. And such operators frequently occurr in NLP tasks like attention or memory network.

Forgive my offense and really thanks for any help
"
5230,Cannot compile library  for iOS. Please see attached issues with compiling protobuf. ,"checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... configure: error: in `/Users/arpit/Desktop/tensorflow-master/tensorflow/contrib/makefile/downloads/protobuf':
configure: error: cannot run C compiled programs.
If you meant to cross compile, use`--host'.
See `config.log' for more details
"
5228,Poor VGG performance in slim.,"Hello,

I have been following the slim tutorial:
https://github.com/tensorflow/models/blob/master/slim/slim_walkthough.ipynb

And decided to replace the Inception model v1 that is used in the example with VGG model
from tensorflow. I took it from here:
https://github.com/tensorflow/models/tree/master/slim#pre-trained-models

I have changed the code to work with VGG, but I got a considerably worse accuracy
even on simple images for VGG, while it works perfectly for Inception v1. Even though the
reported accuracy for VGG and Inception v1 are more or less equal in the imagenet.

I don't know if there is a bug in my code or the model is bad.

Here is the code that I have used:

```
%matplotlib inline

from matplotlib import pyplot as plt

import numpy as np
import os
import tensorflow as tf
import urllib2

from datasets import imagenet
from nets import vgg
from preprocessing import vgg_preprocessing

slim = tf.contrib.slim

image_size = vgg.vgg_19.default_image_size

checkpoints_dir = '/tmp/checkpoints'



with tf.Graph().as_default():
    url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'
    url = 'https://upload.wikimedia.org/wikipedia/commons/d/d9/First_Student_IC_school_bus_202076.jpg'
    image_string = urllib2.urlopen(url).read()
    image = tf.image.decode_jpeg(image_string, channels=3)
    processed_image = vgg_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)
    processed_images  = tf.expand_dims(processed_image, 0)

    # Create the model, use the default arg scope to configure the batch norm parameters.
    with slim.arg_scope(vgg.vgg_arg_scope()):
        logits, _ = vgg.vgg_19(processed_images, num_classes=1000, is_training=False)
    probabilities = tf.nn.softmax(logits)

    init_fn = slim.assign_from_checkpoint_fn(
        os.path.join(checkpoints_dir, 'vgg_19.ckpt'),
        slim.get_model_variables('vgg_19'))

    with tf.Session() as sess:
        init_fn(sess)
        np_image, probabilities = sess.run([image, probabilities])
        probabilities = probabilities[0, 0:]
        sorted_inds = [i[0] for i in sorted(enumerate(-probabilities), key=lambda x:x[1])]

    plt.figure()
    plt.imshow(np_image.astype(np.uint8))
    plt.axis('off')
    plt.show()


    names = imagenet.create_readable_names_for_imagenet_labels()
    for i in range(5):
        index = sorted_inds[i]
        print('Probability %0.2f%% => [%s]' % (probabilities[index], names[index]))

```
"
5225,"Shape must be rank 0 but is rank 1, Potential issue with parse_single_sequence_example","### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Spent quite some time digging around didn't come up with anything from stack overflow or other issues that landed near my issues. I also debugged the stack trace all the way down into where it jumps out of python and didn't come up with anything particularly useful.  
### Environment info

Operating System:
Ubuntu 16.04 64bit

Installed version of CUDA and cuDNN: 8 and 5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

-rw-r--r-- 1 root root 558720 Sep 14 19:02 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Sep 14 19:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root     19 Sep 14 19:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root 415432 Sep 14 19:02 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root 775162 Sep 14 19:02 /usr/local/cuda/lib64/libcudart_static.a

If installed from binary pip package, provide:
1. A link to the pip package you installed:
2. The output from `python3 -c ""import tensorflow; print(tensorflow.__version__)""`.

I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
0.11.0rc1
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
import tensorflow as tf
import tempfile
from IPython import embed

sequences = [[1, 2, 3], [4, 5, 1], [1, 2]]
label_sequences = [[0, 1, 0], [1, 0, 0], [1, 1]]

def make_example(sequence, labels):

    ex = tf.train.SequenceExample()

    sequence_length = len(sequence)
    ex.context.feature[""length""].int64_list.value.append(sequence_length)

    fl_tokens = ex.feature_lists.feature_list[""tokens""]
    fl_labels = ex.feature_lists.feature_list[""labels""]
    for token, label in zip(sequence, labels):
        fl_tokens.feature.add().int64_list.value.append(token)
        fl_labels.feature.add().int64_list.value.append(label)
    return ex


writer = tf.python_io.TFRecordWriter('./test.tfrecords')
for sequence, label_sequence in zip(sequences, label_sequences):
    ex = make_example(sequence, label_sequence)
    writer.write(ex.SerializeToString())
writer.close()

tf.reset_default_graph()

file_name_queue = tf.train.string_input_producer(['./test.tfrecords'], num_epochs=None)

reader = tf.TFRecordReader()



context_features = {
    ""length"": tf.FixedLenFeature([], dtype=tf.int64)
}
sequence_features = {
    ""tokens"": tf.FixedLenSequenceFeature([], dtype=tf.int64),
    ""labels"": tf.FixedLenSequenceFeature([], dtype=tf.int64)
}

ex = reader.read(file_name_queue)

# Parse the example (returns a dictionary of tensors)
context_parsed, sequence_parsed = tf.parse_single_sequence_example(
    serialized=ex,
    context_features=context_features,
    sequence_features=sequence_features
)


context = tf.contrib.learn.run_n(context_parsed, n=1, feed_dict=None)
print(context[0])
sequence = tf.contrib.learn.run_n(sequence_parsed, n=1, feed_dict=None)
print(sequence[0])

```
### What other attempted solutions have you tried?

This was the quickest reproduction I could put together using some sample code from the web with a few tweaks. Initially I was trying to do this on a more serious problem with an entirely different dataset/proto, but same issue. I've considered skipping this and using some other file format. However, I think the binary format will be best.  
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).

Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py"", line 594, in call_cpp_shape_fn
    status)
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in **exit**
    next(self.gen)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors.InvalidArgumentError: Shape must be rank 0 but is rank 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""my_test.py"", line 51, in <module>
    sequence_features=sequence_features
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/parsing_ops.py"", line 640, in parse_single_sequence_example
    feature_list_dense_defaults, example_name, name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/parsing_ops.py"", line 837, in _parse_single_sequence_example_raw
    name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_parsing_ops.py"", line 285, in _parse_single_sequence_example
    name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 749, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2382, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 1783, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py"", line 596, in call_cpp_shape_fn
    raise ValueError(err.message)
ValueError: Shape must be rank 0 but is rank 1
"
5223,dynamic_RNN fails on mac with unspecified batch_Size,"tl;dr:
dynamic_rnn fails on OS X with unspecified batch_size but works fine on Ubuntu 14.04/Python3.4.3.  It seems that on OS X the 'None != ""?""' evaluates poorly, then at some point in ops/rnn.py +918 this equality fails:
 if const_batch_size != got_batch_size:
(i.e. None != Dimension(""?""))

My best guess is that Dimension(""?"") is hacked in such a way that any comparison using it returns some fake None which for some reason on OSX + python 3.4 means true (I tried explicitly ""if None:"" as a sanity check, it evaluates as false).  For now I've modified the offending code to be: 
if const_batch_size != got_batch_size:
      if  (const_batch_size != got_batch_size) == got_batch_size or (const_batch_size != got_batch_size) == const_batch_size:
            print(""weird dimensions stuff in ops/rnn.py, what the shit python?"")
            continue
      raise ValueError(
          ""Batch_size is not the same for all the elements in the input."")

This
### Environment info

Operating System:
OS X 10.12
Python 3.4.1
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
N/A (CPU version)

If installed from binary pip package, provide:
0.11.0rc1 (just installed wheel)
also fails on 0.10.0rc1, 0.10.0 (though it works on 0.10.0 on Linux)
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code).  It may work with less but this was a simpl

import tensorflow as tf

input_size = 256
length = 100
num_classes = 64

data = tf.placeholder(tf.float32, [None, length, input_size])
target = tf.placeholder(tf.float32, [None, length, num_classes])

max_length = int(target.get_shape()[1])
num_classes = int(target.get_shape()[2])

network = tf.nn.rnn_cell.GRUCell(200)
output, new_state = tf.nn.dynamic_rnn(network, data, dtype=tf.float32)
### What other attempted solutions have you tried?

Works fine on my Linux box with or without GPU
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
Traceback (most recent call last):
  File ""<my_directory>/tensorflow_mac_fail_test.py"", line 18, in <module>
    output, new_state = tf.nn.dynamic_rnn(network, data, dtype=tf.float32)
  File ""/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py"", line 836, in dynamic_rnn
    dtype=dtype)
  File ""/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py"", line 920, in _dynamic_rnn_loop
    ""Batch_size is not the same for all the elements in the input."")
ValueError: Batch_size is not the same for all the elements in the input.
"
5222,what is the feature layer of inception v1 model,"As show in **classify_image.py** for inception v3 model, the feature layer is **pool_3:0**

```
# 'pool_3:0': A tensor containing the next-to-last layer containing 2048
#   float description of the image.
```

I print out the nodes of inception v1 model .pb file as below. I guess the feature layer is **avgpool0/reshape**, is that right? 

input
conv2d0_w
conv2d0_b
conv2d1_w
conv2d1_b
conv2d2_w
conv2d2_b
... 
...
...
...
mixed5b/concat_dim
mixed5b
**avgpool0**
head0_pool
head0_bottleneck_pre_relu/conv
head0_bottleneck_pre_relu
head0_bottleneck
head0_bottleneck/reshape/shape
head0_bottleneck/reshape
nn0_pre_relu/matmul
nn0_pre_relu
nn0
nn0/reshape/shape
nn0/reshape
softmax0_pre_activation/matmul
softmax0_pre_activation
softmax0
head1_pool
head1_bottleneck_pre_relu/conv
head1_bottleneck_pre_relu
head1_bottleneck
head1_bottleneck/reshape/shape
head1_bottleneck/reshape
nn1_pre_relu/matmul
nn1_pre_relu
nn1
nn1/reshape/shape
nn1/reshape
softmax1_pre_activation/matmul
softmax1_pre_activation
softmax1
avgpool0/reshape/shape
**avgpool0/reshape**
softmax2_pre_activation/matmul
softmax2_pre_activation
softmax2
output
output1
output2
"
5221,tf.nn.softmax on GPU causes CUDA_ERROR_ILLEGAL_ADDRESS (okay on CPU),"CentOS 7
Tensorflow 0.10.0
TITAN X (Pascal) 367.44

I restore a model previously saved with `tf.train.Saver()` and try to compute probabilities of outputs for a given input batch. Whenever I try to execute `tf.nn.softmax` on GPU, I get an error:

```
E tensorflow/stream_executor/cuda/cuda_driver.cc:1140] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_ADDRESS :: No stack trace available
F tensorflow/core/common_runtime/gpu/gpu_util.cc:370] GPU sync failed
E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
```

but same computations work just fine on CPU:

```
print('run 1: logits')
logits = s.run(model.other.logits_labl, tf_run_args)
print(logits.shape) # (1001, 289)
print(np.max(logits), np.min(logits)) # 1.80996 -0.752239

print('run 2: probs in np')
probs = s.run(tf.nn.softmax(logits))
print(probs.shape) # (1001, 289)
print(np.sum(probs, axis=1)) # [ 1.   ...  1.00000012  1.          1.00000012]

print('run 3: probs on cpu')
with tf.device('/cpu:0'):
    t = tf.nn.softmax(model.other.logits_labl)
print(s.run(t, tf_run_args)) # okay

print('run 4: probs on gpu')
with tf.device('/gpu:0'):
    t2 = tf.nn.softmax(model.other.logits_labl)
print(s.run(t2, tf_run_args)) # error
```

produces

```
run 1: logits
(1001, 289)
1.80996 -0.752239
run 2: probs in np
(1001, 289)
[ 1.          0.99999994  1.         ...,  1.00000012  1.          1.00000012]
run 3: probs on cpu
[[ 0.00353091  0.0032969   0.00355321 ...,  0.00368173  0.00337926
   0.00326502]
 [ 0.00343715  0.00313538  0.00379693 ...,  0.00426536  0.0032676
   0.0031463 ]
 [ 0.00346572  0.00300998  0.00389543 ...,  0.00458091  0.0031747
   0.0030867 ]
 ...,
 [ 0.0035709   0.00302548  0.00384262 ...,  0.0042819   0.00318443
   0.00299288]
 [ 0.00353101  0.00305104  0.00379521 ...,  0.00428836  0.0031993
   0.0029559 ]
 [ 0.00352879  0.00302152  0.00380528 ...,  0.0043787   0.00318416
   0.00294856]]
run 4: probs on gpu
E tensorflow/stream_executor/cuda/cuda_driver.cc:1140] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_ADDRESS :: No stack trace available
F tensorflow/core/common_runtime/gpu/gpu_util.cc:370] GPU sync failed
E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
Aborted
```

`gdb` does not give any additional details

```
... same as above
[New Thread 0x7fff41ffb700 (LWP 26404)]
E tensorflow/stream_executor/cuda/cuda_driver.cc:1140] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_ADDRESS :: No stack trace available
E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
F tensorflow/core/common_runtime/gpu/gpu_util.cc:370] GPU sync failed
F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1

Program received signal SIGABRT, Aborted.
[Switching to Thread 0x7fff5effd700 (LWP 26391)]
0x00007ffff6a315f7 in raise () from /lib64/libc.so.6
Missing separate debuginfos, use: debuginfo-install libX11-1.6.3-2.el7.x86_64 libXau-1.0.8-2.1.el7.x86_64 libXdmcp-1.1.1-6.1.el7.x86_64 libuuid-2.23.2-26.el7_2.3.x86_64
```

Surprisingly, this error occurred just recently. I have been working with this same codebase for months and before now nothing like this happened, but now it is 100% reproducible on my machine with this specific (code, driver version, etc), so it is not something that effects everyone, but rather pops up randomly. I might have changed operation device placement recently.

code (unfortunately, large piece of code that required certain data; failed to produce a minimal reproducing code): [[link]](https://gist.github.com/MInner/4faa684a1d0d7eac6fafb9d6b08adfc3)

full gdb output (without prints): [[link]](http://pastebin.com/q7ftuZcp)

environment:

```
$ ls -l /usr/lib/libcu*
lrwxrwxrwx. 1 root root      12 Oct  3 15:36 /usr/lib/libcuda.so -> libcuda.so.1
lrwxrwxrwx. 1 root root      17 Oct  3 15:36 /usr/lib/libcuda.so.1 -> libcuda.so.367.44
-rwxr-xr-x. 1 root root 7747600 Oct  3 15:36 /usr/lib/libcuda.so.367.44
$ ls -l /usr/local/cuda/lib64/
lrwxrwxrwx. 1 1000 users       13 Jul 27 01:55 libcudnn.so -> libcudnn.so.5
lrwxrwxrwx. 1 1000 users       17 Jul 27 01:55 libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxrwxr-x. 1 1000 users 79337624 Jul 27 01:53 libcudnn.so.5.1.5
-rw-rw-r--. 1 1000 users 69756172 Jul 27 01:53 libcudnn_static.a
```

Possibly related issues: #2117 #1450 #2810 #665 #1060 #4425
"
5220,go,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
5216,sparse tensor.shape method returns a tensor object  ,"sparse tensor.shape method returns a tensor object which seems to be of no use to extract the actual shape of the sparse tensor without resorting to run function.

To clarify what I mean, first consider a sparse tensor:

 a = tf.SparseTensor(indices=[[0, 0, 0], [1, 2, 1]], values=[1.0+2j, 2.0], shape=[3, 4, 2])

a.shape returns:

 tf.Tensor 'SparseTensor_1/shape:0' shape=(3,) dtype=int64

This is kind of no use. 

Now, consider a dense tensor:

a = tf.constant(np.random.normal(0.0, 1.0, (4, 4)).astype(dtype=np.complex128))

a.get_shape() returns:
TensorShape([Dimension(4), Dimension(4)])

I can use this output and cast it into a list or tuple of integers without ever invoking run(). However, I cannot do the same for sparse tensor, unless I first convert sparse tensor to dense (which is _not_ implemented for complex sparse tensor yet) and then call get_shape() method on it, but this is kind of  redundant, defeats the purpose of using a sparse tensor in the first place and also leads to error down the road if the input sparse tensor is complex.

Is there a way to obtain the shape of a sparse tensor without invoking run() or converting it to a dense tensor first?
"
5214,"Unable to run ""bazel build tensorflow/examples/image_retraining:retrain","Hello! I was running the tensorflow example to retrain, and I got this error.

/Users/student/Downloads/tf/tensorflow/core/BUILD:1030:1: no such target '//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package 'tensorflow/tools/git' defined by /Users/student/Downloads/tf/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: /Users/student/Downloads/tf/tensorflow/core/BUILD:1030:1: no such target '//tensorflow/tools/git:gen/head': target 'gen/head' not declared in package 'tensorflow/tools/git' defined by /Users/student/Downloads/tf/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: /Users/student/Downloads/tf/tensorflow/core/BUILD:1030:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /Users/student/Downloads/tf/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: Analysis of target '//tensorflow/examples/image_retraining:retrain' failed; build aborted.
INFO: Elapsed time: 1.020s

Does anyone know what I am doing wrong?
"
5213,dyld: lazy symbol binding failed,"I use OSX10.12, I try to use OpenCV in tensorflow, I use the first method which is mentioned [here](http://stackoverflow.com/questions/34984290/building-opencv-code-using-bazel).

I build my code successfully but there are some questions as following when I execute it:
`dyld: lazy symbol binding failed: Symbol not found: __ZN2cv6String8allocateEm
Referenced from: /Users/philokey/Practice/github/tensorflow/./bazel-bin/tensorflow/examples/test_cv/test_cv
Expected in: flat namespace`

The build file is as following:

```
cc_binary(
name = ""test_cv"",
srcs = [
    ""test_cv.cc"",
],
deps = [
    ""@opencv//:opencv"",
],
)
```

How can I sovle this problem?
By the way, the question is also asked in [stackoverflow](http://stackoverflow.com/questions/40259156/osx-tensorflow-opencv-symbol-not-found-expected-in-flat-namespace)
"
5212,ubuntu16.04 GTX1060 cuda8.0 Found 0 targets...,"tensorflow$ ./configure ~/Documents/tensorflow ~/Documents/tensorflow
Please specify the location of python. [Default is /home/hammer/anaconda2/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] y
Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /home/hammer/anaconda2/lib/python2.7/site-packages
  /home/hammer/Documents/SSD/caffe/python
Please input the desired Python library path to use.  Default is [/home/hammer/anaconda2/lib/python2.7/site-packages]

/home/hammer/anaconda2/lib/python2.7/site-packages
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 
Please specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
libcudnn.so resolves to libcudnn.5
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.

INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
...........
INFO: All external dependencies fetched successfully.
Configuration finished
GT72VR-6RD:~/Documents/tensorflow$ bazel build -c opt --config=cuda
INFO: Found 0 targets...
INFO: Elapsed time: 1.535s, Critical Path: 0.01s

I get no error, but I don't know what to do.
"
5205,tensorflow runs much slower/ installation issue?,"I installed tensorflow version 0.11.0rc0 using the .whl provided and the following code runs terribly slower (on macosx cpu) compared to its numpy counterpart.

Is  tf version  0.11.0rc0 a stable release?  Is tensorflow expected to run extremely slow inside a python for loop?

```
from math import *
import numpy as np
import sys
from multiprocessing import Pool
import tensorflow as tf

def Trajectory_Fun(tspan, a, b, session=None, server=None):
    if session==None:
        if server==None:
            sess = tf.Session()
        else:
            sess = tf.Session(server.target)       
    else:
        sess = session
    B = np.zeros(np.size(tspan), dtype=np.float64)
    B[0] = b
    for i, t in enumerate(tspan):
        r = np.random.rand(1)
        if r>a:
            c = sess.run(tf.trace(tf.random_normal((4, 4), r, 1.0)))
        else:
            c = 0.0 # sess.run(tf.trace(tf.random_normal((4, 4), 0.0, 1.0)))
        B[i] = c
    if session==None:
        sess.close()
    return B


def main(argv):
   tspan = np.arange(0.0, 1000.0)
   a = 0.1
   b = 0.0
   B = Trajectory_Fun(tspan, a, b, None, None)
   print 'Done!'


if __name__ == ""main"":
    main(sys.argv[1:]) `
```
"
5203,Explanation about 'SAME' padding doesn't cover edge cases,"In the [docs](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#convolution), it explains the padding as follows:

```
For the 'SAME' padding, the output height and width are computed as:

out_height = ceil(float(in_height) / float(strides[1]))
out_width  = ceil(float(in_width) / float(strides[2]))

and the padding on the top and left are computed as:

pad_along_height = ((out_height - 1) * strides[1] +
                    filter_height - in_height)
pad_along_width = ((out_width - 1) * strides[2] +
                   filter_width - in_width)
pad_top = pad_along_height / 2
pad_left = pad_along_width / 2
```

When `in_height=20, stride=2, filter_height=1`, we will end up with `pad_along_height=-1`. I think it's unclear what this means (is there padding or not?). Further explanation are needed to document the behavior in this case.

Also, when `in_height=19, stride=2, filter_height=1`, we will end up with `out_height=10, pad_along_height=0, pad_top=0`.  But with 19 inputs and stride=2 how can you have 10 output without padding? This doesn't seem right.
"
5202,Bug report: Commit 20c02ff broke something concerning building example /label_image for Raspberry Pi,"This is the diff in question:
https://github.com/tensorflow/tensorflow/commit/20c02ffe0e6b8af4902487f852e15daa16caa523#diff-48887acc98c15e53f942842ecd65190fR318

I managed to successfully build this example by changing code. Since I'm not really good with C++ I'm not sure if my solution is the best. It would be great if someone more experienced could take a look at it.

Here is the issue where I explain how I fixed it: https://github.com/tensorflow/tensorflow/issues/5200
"
5200,Error when building /pi_examples/label_image on RPi 3 (/usr/include/jpeglib.h:792:3: error: âsize_tâ does not name a type),"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Some comments here mention the same problem: https://github.com/tensorflow/tensorflow/issues/4680#issuecomment-256078792
### Environment info

Operating System:
Raspberry Pi 3
RASPBIAN JESSIE WITH PIXEL
Image with PIXEL desktop based on Debian Jessie
Version:September 2016
Release date:2016-09-23
Kernel version:4.4
If installed from source, provide 
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

followed instructions here:
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/pi_examples/
### What other attempted solutions have you tried?

Tried changing compiler defined in Makefile to g++-4.8 but to no avail
### Logs or other output that would be helpful

> make -f tensorflow/contrib/pi_examples/label_image/Makefile 
> gcc --std=c++11 -O0 -I/usr/local/include -I. -I/home/pi/code/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/downloads -I/home/pi/code/tensorflow/t
> ensorflow/contrib/pi_examples/label_image/../../makefile/downloads/eigen/ -I/home/pi/code/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/proto
> / -I/home/pi/code/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/proto_text/ -c tensorflow/contrib/pi_examples/label_image/label_image.cc -o /
> home/pi/code/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o
> In file included from tensorflow/contrib/pi_examples/label_image/label_image.cc:26:0:
> /usr/include/jpeglib.h:792:3: error: âsize_tâ does not name a type
>    size_t free_in_buffer; /\* # of byte spaces remaining in buffer _/
>    ^
> /usr/include/jpeglib.h:804:3: error: âsize_tâ does not name a type
>    size_t bytes_in_buffer; /_ # of bytes remaining in buffer _/
>    ^
> In file included from /usr/include/jpeglib.h:29:0,
>                  from tensorflow/contrib/pi_examples/label_image/label_image.cc:26:
> /usr/include/jpeglib.h:835:3: error: âsize_tâ has not been declared
>    JMETHOD(void *, alloc_small, (j_common_ptr cinfo, int pool_id,
>    ^
> /usr/include/jpeglib.h:837:3: error: âsize_tâ has not been declared
>    JMETHOD(void FAR *, alloc_large, (j_common_ptr cinfo, int pool_id,
>    ^
> In file included from tensorflow/contrib/pi_examples/label_image/label_image.cc:26:0:
> /usr/include/jpeglib.h:990:34: error: âsize_tâ has not been declared
>  EXTERN(void) jpeg_CreateCompress JPP((j_compress_ptr cinfo,
>                                   ^
> /usr/include/jpeglib.h:992:36: error: âsize_tâ has not been declared
>  EXTERN(void) jpeg_CreateDecompress JPP((j_decompress_ptr cinfo,
>                                     ^
> /usr/include/jpeglib.h:1000:30: error: âFILEâ has not been declared
>  EXTERN(void) jpeg_stdio_dest JPP((j_compress_ptr cinfo, FILE \* outfile));
>                               ^
> /usr/include/jpeglib.h:1001:29: error: âFILEâ has not been declared
>  EXTERN(void) jpeg_stdio_src JPP((j_decompress_ptr cinfo, FILE \* infile));
>                              ^
> tensorflow/contrib/pi_examples/label_image/label_image.cc: In function âtensorflow::Status LoadJpegFile(std::string, std::vector<unsigned char>_, int_, int_, int_)â:
> tensorflow/contrib/pi_examples/label_image/label_image.cc:108:32: error: cannot convert âFILE_ {aka _IO_FILE_}â to âint_â for argument â2â to âvoid jpeg_stdio_src(j_dec
> ompress_ptr, int_)â
>    jpeg_stdio_src(&cinfo, infile);
>                                ^
> tensorflow/contrib/pi_examples/label_image/label_image.cc: In function âint main(int, char__)â:
> tensorflow/contrib/pi_examples/label_image/label_image.cc:318:3: error: âvectorâ was not declared in this scope
>    vector tensorflow::Flag > flag_list = {
>    ^
> tensorflow/contrib/pi_examples/label_image/label_image.cc:318:3: note: suggested alternatives:
> In file included from /usr/include/c++/4.9/vector:64:0,
>                  from tensorflow/contrib/pi_examples/label_image/label_image.cc:29:
> /usr/include/c++/4.9/bits/stl_vector.h:214:11: note:   âstd::vectorâ
>      class vector : protected _Vector_base<_Tp, _Alloc>
>            ^
> /usr/include/c++/4.9/bits/stl_vector.h:214:11: note:   âstd::vectorâ
> tensorflow/contrib/pi_examples/label_image/label_image.cc:333:52: error: âflag_listâ was not declared in this scope
>    string usage = tensorflow::Flags::Usage(argv[0], flag_list);
>                                                     ^
> tensorflow/contrib/pi_examples/label_image/label_image.cc:335:8: error: in argument to unary !
>    if (!parse_result) {
>         ^
> tensorflow/contrib/pi_examples/label_image/label_image.cc:341:49: error: cannot convert âstd::string {aka std::basic_string<char>}â to âconst char_â for argument â1â to
>  âvoid tensorflow::port::InitMain(const char_, int_, char_**)â
>    tensorflow::port::InitMain(usage, &argc, &argv);
>                                                  ^
> tensorflow/contrib/pi_examples/label_image/Makefile:79: recipe for target '/home/pi/code/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contri
> b/pi_examples/label_image/label_image.o' failed
> make: *_\* [/home/pi/code/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o] Error 1
"
5199,tensor.eval() function converts a tensor to a numpy array is very slow. ,"I am using inception V1 model to predict image. The input needs a 4d array.

This section is read a image and resize to 224 \* 224 \* 3, then whitening, then convert to 4D tensor

---

  with open(image, 'rb') as f:
    image_data = f.read()

  image_buffer=tf.image.decode_jpeg(image_data)
  resize_image=tf.image.resize_images(image_buffer,[224,224])
  unified_image=tf.image.per_image_whitening(resize_image)
  image_4dTensor=tf.expand_dims(unified_image, 0)

---

This section is to input an image and run the session. Since i can't input a 4D tensor but a numpy array into the session, I need convert 4D tensor to 4D array by call **tensor.eval()**. However i found that this conversion for a 1 \* 224 \* 224 \* 3 tensor is very slow. It needs 0.4-0.6s. The prediction itself only takes less than 0.2s (run through 22 layers for a input 4D array ). So Is there anyway to convert a tensor to a numpy array faster?

  with tf.Session() as sess:

```
stamp1=time.time()
image_array=image_4dTensor.eval()
time_cost=time.time()-stamp1
print (time_cost)
```
"
5197,Mac nightly build links in readme are broken,"Maybe this is because the last successful build was a month ago?

e.g. 
Mac CPU-only: Python 3 ->
https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac1-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.11.0rc1-py3-none-any.whl

This page shows:

```
HTTP ERROR 404

Problem accessing /view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac1-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.11.0rc1-py3-none-any.whl. Reason:

    Not Found
```
"
5195,"Sum Total of in-use chunks: 7.23GiB, but it tried to allocate 8.00GiB","> I tensorflow/core/common_runtime/bfc_allocator.cc:689]      Summary of in-use Chunks by size: 
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 22 Chunks of size 256 totalling 5.5KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 5 Chunks of size 512 totalling 2.5KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 1280 totalling 1.2KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 7499 Chunks of size 2048 totalling 14.65MiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1087 Chunks of size 4096 totalling 4.25MiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 4608 totalling 4.5KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 6144 totalling 6.0KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 616 Chunks of size 8192 totalling 4.81MiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 9984 totalling 9.8KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 4 Chunks of size 10240 totalling 40.0KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 2 Chunks of size 12288 totalling 24.0KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 303 Chunks of size 14336 totalling 4.14MiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 5 Chunks of size 198656 totalling 970.0KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 208384 totalling 203.5KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 919 Chunks of size 8388608 totalling 7.18GiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 10775552 totalling 10.28MiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 14428160 totalling 13.76MiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 7.23GiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats: 
> Limit:                  7967745639
> InUse:                  7764832256
> MaxInUse:               7764842496
> NumAllocs:                   60834
> MaxAllocSize:             14428160
> 
> W tensorflow/core/common_runtime/bfc_allocator.cc:270] ****************************************************************************************************
> W tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 8.00MiB.  See logs for memory state.
> W tensorflow/core/framework/op_kernel.cc:968] Resource exhausted: OOM when allocating tensor with shape[1024,2048]
> E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 8.00G (8589934592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
> E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 8.00G (8589934592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY

I have a 8G GPU memory (7.8G for free), and the allocator need to use 7.23G, which could be able to allocate.
But, it tried to allocate 8.00G, and threw out CUDA_ERROR_OUT_OF_MEMORY
I also set `config.gpu_options.allow_growth=True` , but it didn't matter.
How can I solve it? Thanks a lot!
"
5193,CuSPARSE support,"For some machine learning /algorithm problems, we require to multiply matrices with vectors. In some cases - especially those associated with large graph analytics, the matrices are sparse. Given the major limitation with GPUs is the limited GPU memory, representing the matrix in sparse format is vital.

To this end, the CUSPARSE libraries (http://docs.nvidia.com/cuda/cusparse/) provide a suitable object model and various functions for sparse matrix/vector operations.

I would therefore like to request a basic CUSPARSE implementation. 
e.g. - 
- CSR matrix representation - (see http://docs.nvidia.com/cuda/cusparse/#compressed-sparse-row-format-csr)
- basic matrix-vector multiplication for CSR representations (see http://docs.nvidia.com/cuda/cusparse/#cusparse-lt-t-gt-csrmv)

NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
5191,"sucessfully configure, but build error with bazel","the configure sucessfully finished
but when run ""bazel build -c opt //tensorflow/tools/pip_package:build_pip_package""
it reports the error: ......./tensorflow/tensorflow/python/BUILD:1806:1: in cc_library rule //tensorflow/python:tf_session_helper: non-test target '//tensorflow/python:tf_session_helper' depends on testonly target '//tensorflow/python:construction_fails_op' and doesn't have testonly attribute set
"
5190,tf.self_adjoint_eig does not work for complex matrices,"The documentation of tf.self_adjoint_eig (and the likes) does not state that which data types are accepted by this function. Turns out, only float32 and float64. But the name is misleading: self-adjointness is a property of complex matrices, and one could expect that this function would work on complex64 and complex128 as well.

For me it would be very useful if tf.self_adjoint_eig could work for complex matrices.

Please amend the documentation with the list of accepted dtypes (this goes for SVD and other similar functions as well). And of course it would be great if tf.self_adjoint_eig could accept complex data. :)
"
5189,lstm with variable bath_size,"we know ,during training,we need to feed_dict a batch.However,in the last epoch, the number of data is less than a batch size.how could i do? i try to use variable batch_size,but i meet some problems. the code is below:
input_data = tf.placeholder(tf.int32, [None, num_steps])
with tf.variable_scope('forward'):
            cellL = tf.nn.rnn_cell.BasicLSTMCell(hidden_size, forget_bias=1.0)
state_init_L = tf.get_variable(""init_L"", initializer=cellL.zero_state(tf.shape(input_data)[0],tf.float32))

here,  i want to initialize it,error is 
ValueError: initial_value must have a shape specified: Tensor(""model/init_variable_L/zeros:0"", shape=(?, 100), dtype=float32, device=/device:GPU:0)

thanks~
"
5188,"freeze_graph.py ""AttributeError: 'module' object has no attribute 'checkpoint_exists' in latest commit","NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

none, latest commit from 4 days ago caused this issue to arise.
### Environment info

Operating System: OSX Sierra

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
no Cuda support

If installed from binary pip package, provide:
1. A link to the pip package you installed: compiled from source
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.11.0rc1

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
   bac7faa9a3eb5b60687a83336202cd3493de5385
2. The output of `bazel version`
   Build label: 0.3.2-homebrew
   Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Sat Oct 8 08:02:20 2016 (1475913740)
   Build timestamp: 1475913740
   Build timestamp as int: 1475913740
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
### What other attempted solutions have you tried?

Used a version prior to the latest commit 4 days ago and it worked.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).

$ python freeze_graph.py --input_graph=train.txt --input_checkpoint=model.ckpt-194000 --output_graph=frozen_graph.pb --output_node_names=final_result

  File ""freeze_graph.py"", line 135, in <module>
    tf.app.run()
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""freeze_graph.py"", line 132, in main
    FLAGS.output_graph, FLAGS.clear_devices, FLAGS.initializer_nodes)
  File ""freeze_graph.py"", line 84, in freeze_graph
    if not tf.train.checkpoint_exists(input_checkpoint):
AttributeError: 'module' object has no attribute 'checkpoint_exists'
"
5187,Reading data from tfrecords error,"When I use tf to read traing and testing data from tfrecords, it runed for a while, then stoped with errors like this (this is testing net error, traing net is the same problem):
INFO:tensorflow:Executing eval_op 8133/15916
INFO:tensorflow:Executing eval_op 8134/15916
INFO:tensorflow:Executing eval_op 8135/15916
INFO:tensorflow:Executing eval_op 8136/15916
INFO:tensorflow:Executing eval_op 8137/15916
INFO:tensorflow:Executing eval_op 8138/15916
INFO:tensorflow:Executing eval_op 8139/15916
INFO:tensorflow:Executing eval_op 8140/15916
INFO:tensorflow:Executing eval_op 8141/15916
INFO:tensorflow:Executing eval_op 8142/15916
INFO:tensorflow:Executing eval_op 8143/15916
INFO:tensorflow:Executing eval_op 8144/15916
INFO:tensorflow:Executing eval_op 8145/15916
INFO:tensorflow:Executing eval_op 8146/15916
INFO:tensorflow:Executing eval_op 8147/15916
INFO:tensorflow:Executing eval_op 8148/15916
INFO:tensorflow:Executing eval_op 8149/15916
INFO:tensorflow:Executing eval_op 8150/15916
INFO:tensorflow:Executing eval_op 8151/15916
INFO:tensorflow:Executing eval_op 8152/15916
INFO:tensorflow:Executing eval_op 8153/15916
INFO:tensorflow:Executing eval_op 8154/15916
INFO:tensorflow:Executing eval_op 8155/15916
INFO:tensorflow:Executing eval_op 8156/15916
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors.InvalidArgumentError'>, Input to reshape is a tensor with 836310 values, but the requested shape has 65712
         [[Node: Reshape_14 = Reshape[T=DT_UINT8, _device=""/job:localhost/replica:0/task:0/gpu:0""](case_1/If_2/Merge, Reshape_14/shape)]]
         [[Node: eval_image/Mul/_3773 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_152_eval_image/Mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op u'Reshape_14', defined at:
  File ""eval_image_classifier.py"", line 210, in <module>
    tf.app.run()
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""eval_image_classifier.py"", line 130, in main
    common_queue_min=FLAGS.batch_size)
  File ""/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py"", line 78, in __init__
    tensors = dataset.decoder.decode(data, items)
  File ""/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py"", line 398, in decode
    outputs.append(handler.tensors_to_item(keys_to_tensors))
  File ""/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py"", line 297, in tensors_to_item
    image = self._decode(image_buffer, image_format)
  File ""/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py"", line 328, in _decode
    image = array_ops.reshape(image, self._shape)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/ops/gen_array_ops.py"", line 1758, in reshape
    name=name)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py"", line 2333, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py"", line 1252, in __init__
    self._traceback = _extract_stack()

Traceback (most recent call last):
  File ""eval_image_classifier.py"", line 210, in <module>
    tf.app.run()
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""eval_image_classifier.py"", line 206, in main
    variables_to_restore=variables_to_restore)
  File ""/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/evaluation.py"", line 323, in evaluate_once
    global_step=global_step)
  File ""/usr/lib/python2.7/contextlib.py"", line 35, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/training/supervisor.py"", line 969, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/training/supervisor.py"", line 797, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/training/coordinator.py"", line 386, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/training/queue_runner.py"", line 225, in _run
    sess.run(enqueue_op)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py"", line 915, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py"", line 965, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py"", line 985, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 836310 values, but the requested shape has 65712
         [[Node: Reshape_14 = Reshape[T=DT_UINT8, _device=""/job:localhost/replica:0/task:0/gpu:0""](case_1/If_2/Merge, Reshape_14/shape)]]
         [[Node: eval_image/Mul/_3773 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_152_eval_image/Mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op u'Reshape_14', defined at:
  File ""eval_image_classifier.py"", line 210, in <module>
    tf.app.run()
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""eval_image_classifier.py"", line 130, in main
    common_queue_min=FLAGS.batch_size)
  File ""/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py"", line 78, in __init__
    tensors = dataset.decoder.decode(data, items)
  File ""/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py"", line 398, in decode
    outputs.append(handler.tensors_to_item(keys_to_tensors))
  File ""/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py"", line 297, in tensors_to_item
    image = self._decode(image_buffer, image_format)
  File ""/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py"", line 328, in _decode
    image = array_ops.reshape(image, self._shape)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/ops/gen_array_ops.py"", line 1758, in reshape
    name=name)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py"", line 2333, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py"", line 1252, in __init__
    self._traceback = _extract_stack()
###### 

while I wrote the tfrecords like this:

def _process_image(file_path, label, coder, logfile=None):
    """"""Process a single image file.

```
Args:
    filename: string, path to an image file e.g., '/path/to/example.JPG'.
    coder: instance of ImageCoder to provide TensorFlow image coding utils.
Returns:
    image_buffer: string, JPEG encoding of RGB image.
    height: integer, image height in pixels.
    width: integer, image width in pixels.
""""""
# Clean the dirty data.
if _is_not_jpg(file_path):
    print('Image %s is not a JPEG image, and its label is %d' % (file_path, label))
    if logfile:
        logfile.write('Image %s is not a JPEG image, and its label is %d\n' % (file_path, label))
    return -1, None

if not tf.gfile.Exists(file_path):
    print('Image %s is not exist, and its label is %d' % (file_path, label))
    if logfile:
        logfile.write('Image %s is not exist, and its label is %d\n' % (file_path, label))
    return -1, None

# Read the image file.
image_data = tf.gfile.FastGFile(file_path, 'r').read()

# Decode the RGB JPEG.
height, width, channels = coder.read_image_dims(image_data)

# Check that image converted right
if height != 148 and width != 148 and channels != 3:
    print('The size of image %s is wrong, which is h[%d] w[%d] c[%d], but requested h[148] w[148] c[148]\n' % (file_path, height, width, channels))
    if logfile:
        logfile.write('The size of image %s is wrong, which is h[%d] w[%d], but requested h[148] w[148] c[148]\n' % (file_path, height, width, channels))
    return -1, None

return 0, _convert_to_example(image_data, height, width, channels, 'jpg', label)
```

def _process_image_files_batch(coder, thread_index, ranges, name, filenames, labels, num_shards, logfile=None):

```
num_threads = len(ranges)
assert not num_shards % num_threads
num_shards_per_batch = int(num_shards / num_threads)

shard_ranges = np.linspace(ranges[thread_index][0], ranges[thread_index][1], num_shards_per_batch + 1).astype(int)
num_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]

counter = 0
for s in xrange(num_shards_per_batch):
    # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'
    shard = thread_index * num_shards_per_batch + s
    output_file = '%s-%.5d-of-%.5d.tfrecord' % (name, shard, num_shards)
    writer = tf.python_io.TFRecordWriter(output_file)

    shard_counter = 0
    files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)
    for i in files_in_shard:
        file_path = filenames[i]
        label = labels[i]

        errCode, example = _process_image(file_path, label, coder, logfile)
        if -1 == errCode:
            continue

        writer.write(example.SerializeToString())
        shard_counter += 1
        counter += 1

        if not counter % 1000:
            print('%s [thread %d]: Processed %d of %d images in thread batch.' % (datetime.now(), thread_index, counter, num_files_in_thread))
            sys.stdout.flush()

    print('%s [thread %d]: Wrote %d images to %s' % (datetime.now(), thread_index, shard_counter, output_file))
    sys.stdout.flush()
    shard_counter = 0
print('%s [thread %d]: Wrote %d images to %d shards.' % (datetime.now(), thread_index, counter, num_files_in_thread))
sys.stdout.flush()
```
###### 

So I checked all the images as the same shape and same size of 65712, and write them by jpg format, Ibut I don't know where the problem is.
"
5184,"Can't run iOS makefile on MacOS Sierra, required file 'build-aux/ltmain.sh' not found","Well from now on I should probably think twice before I update. Before it used to work correctly but now I get this message when i run `compile_ios_protobuf.sh`

```
+ ./autogen.sh
+ autoreconf -f -i -Wall,no-obsolete
/usr/local/bin/glibtoolize: line 406: /usr/local/Library/ENV/4.3/sed: No such file or directory
/usr/local/bin/glibtoolize: line 2513: /usr/local/Library/ENV/4.3/sed: No such file or directory
/usr/local/bin/glibtoolize: line 2513: /usr/local/Library/ENV/4.3/sed: No such file or directory
/usr/local/bin/glibtoolize: line 3601: /usr/local/Library/ENV/4.3/sed: No such file or directory
/usr/local/bin/glibtoolize: line 3845: /usr/local/Library/ENV/4.3/sed: No such file or directory
/usr/local/bin/glibtoolize: line 861: /usr/local/Library/ENV/4.3/sed: No such file or directory
: putting auxiliary files in '.'.
: copying file './ltmain.sh'
/usr/local/bin/glibtoolize: line 3771: /usr/local/Library/ENV/4.3/sed: No such file or directory
configure.ac:30: error: required file 'build-aux/ltmain.sh' not found
autoreconf: automake failed with exit status: 1
```

I hav MacOS Sierra installed and Xcode 8. If anyone has a workaround for this please let me know.
"
5183,"Problems when using ""bazel build""  to download ImageNet data","Hi all,
I tried to download the Imagenet data with the code provided in Inception model, but there was a problem when I used code:
 `bazel build inception/download_and_preprocess_imagenet`
The tensorflow was installed in a Singularity container. And the environment is a high-performance cluster.
### Running Code:

`[yichengwang125@i21a-s2 ~]$ ml load tensorflow`
`[yichengwang125@i21a-s2 ~]$ cd ufrc/image/image/models-master/inception/`
`[yichengwang125@i21a-s2 inception]$ touch WORKSPACE`
`[yichengwang125@i21a-s2 inception]$ DATA_DIR=$HOME/image/`
`[yichengwang125@i21a-s2 inception]$ bazel build inception/download_and_preprocess_imagenet`
`WARNING: Output base /home/yichengwang125/.cache/bazel/_bazel_yichengwang125/bad337a79300dc0e5a9ba2ac2e22c48a' is on NFS. This may lead to surprising failures and undetermined behavior.`
`WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
INFO: Found 1 target...`
`Target //inception:download_and_preprocess_imagenet up-to-date:
  bazel-bin/inception/download_and_preprocess_imagenet
INFO: Elapsed time: 2.952s, Critical Path: 0.02s`
`ERROR  : Could not remove session directory /tmp/.singularity-session-4308.2575366.144117625721484141: Device or resource busy`
### Environment info

Operating System:
Red Hat Enterprise Linux Server release 6.7 (Santiago)
### I tried to

`lsof +D /tmp/.singularity-session-4308.2575366.144117625721484141`
but only shows
`COMMAND   PID     USER             FD   TYPE    DEVICE SIZE/OFF       NODE NAME`
`java         25707  yichengwang125  7r   DIR             8,3            4096 43779163 /tmp/.singularity-session-4308.2575366.144117625721484141`
"
5182,Build error: missing dependency declarations for the following files included by 'external/jpeg_archive,"I have problem when building r0.9 source code without GPU, always have below errors:
ERROR: /home/hadoop/.cache/bazel/_bazel_hadoop/688bf433e3d98b943fba735d08e17b8c/external/jpeg_archive/BUILD:77:1: undeclared inclusion(s) in rule '@jpeg_archive//:jpeg':
this rule is missing dependency declarations for the following files included by 'external/jpeg_archive/jpeg-9a/jdatasrc.c':
'bazel-out/host/genfiles/external/jpeg_archive/jconfig.h'.

The error file is changed if I run bazel build again, in fact the file exists in the directory.
There is no problem when I build TF master source code, version 0.11.
bazel version is 0.3.2-jdk7.
Build command:
bazel build -c opt //tensorflow/tools/pip_package:build_pip_package --local_resources 4096,.5,1.0

I saw some fix  are related with GPU, but I didn't configure GPU.
"
5181,Better support for initializing without explicit initializer for tf.string,"When we use `tf.get_variable()` we have to provide `initializer` except `DT_FLOAT` dtype, or it causes error.

```
tf.get_variable(name=""a"", shape=(), dtype=tf.string)

TypeError: Expected string, got -1.7320508075688772 of type 'float' instead.
```

While I think it's unfriendly to TensorFlow users. So I want to open a PR to support initializing from non initializer for `tf.string`. 

The same issue for `tf.int` is [#4419](https://github.com/tensorflow/tensorflow/issues/4419).
And I have opend a PR [#4816](https://github.com/tensorflow/tensorflow/pull/4826)  to fix that including `tf.string`, but @ebrevdo suggested  me to open a separate PR fot `tf.string`.

@aselle Could you ensure is it a issue and may I open a PR to fix it?
"
5180,OutOfRangeError ,"---

My input data https://www.kaggle.com/c/titanic/download/train.csv

I get OutOfRangeError while training. Can  someone tell me why out of range  error is thrown for below code.
`
import tensorflow as tf
import csv
import os
# initialize variables / model parameters

W = tf.Variable(tf.zeros([5,1]),name=""weights"")
W=tf.cast(W, tf.float32)
b=tf.Variable(0.,)
# Linear Regression inference is now used for combining inputs

def combine_inputs(X):
    return tf.matmul(X,W)+b
# New inferred value is the sigmoid applied the output of linear regression

def inference(X):
    return tf.sigmoid(combine_inputs(X))
def loss(X,Y):  
     return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(combine_inputs(X), Y))

def read_csv(batch_size, file_name, record_defaults):
    filename_queue = tf.train.string_input_producer([os.path.dirname(""**file**"") + ""/"" + file_name]) 
    reader = tf.TextLineReader(skip_header_lines=1)  
    key, value = reader.read(filename_queue) 
    # decode_csv will convert a Tensor from type string (the text line) in  
    # a tuple of tensor columns with the specified defaults, which also  
    # sets the data type for each column  
    decoded = tf.decode_csv(value, record_defaults=record_defaults) 
    # batch actually reads the file and loads ""batch_size"" rows in a single tensor  
    return tf.train.shuffle_batch(decoded,  
                                  batch_size=batch_size,
                                  capacity=batch_size \* 50,  
                                  min_after_dequeue=batch_size)
def inputs():  
    passenger_id,survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked = read_csv(100,""train.csv"", [[0.0], [0.0], [0], [""""], [""""], [0.0], [0.0], [0.0], [""""], [0.0], [""""], [""""]])
    print(""Read Data Success"")
    print(passenger_id)
    # convert categorical data  
    is_first_class = tf.to_float(tf.equal(pclass, [1]))  
    is_second_class = tf.to_float(tf.equal(pclass, [2]))  
    is_third_class = tf.to_float(tf.equal(pclass, [3]))  
    gender = tf.to_float(tf.equal(sex, [""female""]))  
    # Finally we pack all the features in a single matrix;  
    # We then transpose to have a matrix with one example per row and one feature per column.  
    features = tf.transpose(tf.pack([is_first_class, is_second_class, is_third_class, gender, age]))  
    survived = tf.reshape(survived, [100, 1]) 
    return features, survived

def train(total_loss):
    learning_rate =0.01
    return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)
# Calculate Accuracy

def evaluate(sess, X, Y):  
    predicted = tf.cast(inference(X) > 0.5, tf.float32)  
    print( sess.run(tf.reduce_mean(tf.cast(tf.equal(predicted, Y), tf.float32))))
# Create saver

saver =tf.train.Saver()
# Launch the graph in a session, setup boilerplate

with tf.Session() as sess:
    tf.initialize_all_variables().run()
    X,Y = inputs()
    total_loss=loss(X,Y)
    train_op=train(total_loss)

```
coord=tf.train.Coordinator()
threads=tf.train.start_queue_runners(sess=sess,coord=coord)

# Actual Training Loop
training_steps=1000
for step in range(training_steps):
    sess.run([train_op])
    # for debugging and learning purposes, see how the loss gets decremented through training steps
    #if step % 10 == 0 :
    #    print ""loss : "",sess.run([total_loss])

evaluate(sess,X,Y)

coord.request_stop()
coord.join(threads)
# Store the current values of each variable. By default keep most recent 5 files and delete rest
saver.save(sess,'my-model-logistic',global_step=step)
sess.close()
```

`

---

OutOfRangeError                           Traceback (most recent call last)
/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, _args)
    714     try:
--> 715       return fn(_args)
    716     except errors.OpError as e:

/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
    696                                  feed_dict, fetch_list, target_list,
--> 697                                  status, run_metadata)
    698 

/usr/lib/python3.5/contextlib.py in **exit**(self, type, value, traceback)
     65             try:
---> 66                 next(self.gen)
     67             except StopIteration:

/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()
    449           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 450           pywrap_tensorflow.TF_GetCode(status))
    451   finally:

OutOfRangeError: RandomShuffleQueue '_398_shuffle_batch_16/random_shuffle_queue' is closed and has insufficient elements (requested 100, current size 0)
     [[Node: shuffle_batch_16 = QueueDequeueMany[_class=[""loc:@shuffle_batch_16/random_shuffle_queue""], component_types=[DT_FLOAT, DT_FLOAT, DT_INT32, DT_STRING, DT_STRING, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_STRING, DT_FLOAT, DT_STRING, DT_STRING], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch_16/random_shuffle_queue, shuffle_batch_16/n)]]

During handling of the above exception, another exception occurred:

OutOfRangeError                           Traceback (most recent call last)
<ipython-input-227-58fbb156a050> in <module>()
     13     training_steps=1000
     14     for step in range(training_steps):
---> 15         sess.run([train_op])
     16         # for debugging and learning purposes, see how the loss gets decremented through training steps
     17         #if step % 10 == 0 :

/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    370     try:
    371       result = self._run(None, fetches, feed_dict, options_ptr,
--> 372                          run_metadata_ptr)
    373       if run_metadata:
    374         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
    634     try:
    635       results = self._do_run(handle, target_list, unique_fetches,
--> 636                              feed_dict_string, options, run_metadata)
    637     finally:
    638       # The movers are no longer used. Delete them.

/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
    706     if handle is None:
    707       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
--> 708                            target_list, options, run_metadata)
    709     else:
    710       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/home/jenisha/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
    726         except KeyError:
    727           pass
--> 728       raise type(e)(node_def, op, message)
    729 
    730   def _extend_graph(self):
"
5179,Undefined reference to CheckOpMessageBuilder::NewString() when linking libtensorflow_cc.so,"I am trying to use the TensorFlow Session C++ API (Python-free) to load a pre-trained model for inference. For build-time considerations, I am trying to deploy TensorFlow as a ""system"" package by linking against libtensorflow_cc.so and including headers into my Bazel-based workspace which has its own copies of protobuf and Eigen. I am almost there except that I have run into linker errors for missing implementations of tensorflow::internal::CheckOpMessageBuilder::NewString(). The symbols appear to be exported by libtensorflow_cc.so and it does seem to all be linking correctly, just not this symbol.

Any help fixing this issue or suggestions for a better way of doing this would be greatly appreciated.

Thanks, 
Hemal

My setup is the following: 
Docker image from ubuntu:16.04 using gcc5.
Bazel 0.3.1 (needed to upgrade from 0.3.0 because of other Tensorflow build issues) 
I matched the Eigen version but the protobuf used to build the Tensorflow wheel below is installed via apt-get and there is another copy (3.0.0) within my workspace's third_party directory.

The following is in my Dockerfile to build and ""deploy"" Tensorflow: 
RUN git clone https://github.com/tensorflow/tensorflow.git /tmp/tensorflow \ 
&& cd /tmp/tensorflow && git checkout r0.11 \ 
&& yes '' | ./configure \ 
&& bazel build -c opt //tensorflow/tools/pip_package:build_pip_package \ 
&& /tmp/tensorflow/bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg \ 
&& pip2 install --quiet --upgrade /tmp/tensorflow_pkg/*.whl \ 
&& bazel build -c opt //tensorflow:libtensorflow_cc.so \ 
&& cp /tmp/tensorflow/bazel-bin/tensorflow/libtensorflow_cc.so /usr/lib/libtensorflow_cc.so \ 
&& ln -sv /usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow /usr/include/tensorflow \ 
&& ln -sv /usr/local/lib/python2.7/dist-packages/tensorflow/include/third_party /usr/include/third_party

164:1: Linking of rule '//estimation/detection:playback_ground_truth' failed: clang-3.6 failed: error executing command 
  (cd /code/.cache/bazel/_bazel_hemalshah/6fa7a91faa1abdfbb41bc875fa66f0f6/execroot/robotics && \
  exec env - \
  /usr/bin/clang-3.6 -o bazel-out/local_linux-opt/bin/estimation/detection/playback_ground_truth -L/usr/lib/python2.7/config-x86_64-linux-gnu -L/usr/lib -Wl,-O1 -Wl,-Bsymbolic-functions -pthread -B/usr/bin/ -Wl,@bazel-out/local_linux-opt/bin/estimation/detection/playback_ground_truth-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.

bazel-out/local_linux-opt/bin/estimation/detection/libtof_pose_estimator.lo(tof_pose_estimator.o): In function `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >* tensorflow::internal::MakeCheckOpString<long long, long long>(long long const&, long long const&, char const*)':
/usr/include/tensorflow/core/platform/default/logging.h:170: undefined reference to`tensorflow::internal::CheckOpMessageBuilder::NewString()'
bazel-out/local_linux-opt/bin/estimation/detection/libtof_pose_estimator.lo(tof_pose_estimator.o): In function `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >* tensorflow::internal::MakeCheckOpString<unsigned long, unsigned long>(unsigned long const&, unsigned long const&, char const*)':
/usr/include/tensorflow/core/platform/default/logging.h:170: undefined reference to`tensorflow::internal::CheckOpMessageBuilder::NewString()'
"
5170,"files not found ""graph.pb.h"" and ""image_ops.h""","The 2 files below are included in main.cc of label image example, but i can't find these 2 **.h** files in the relevant **ops** and **framework** folders. So we can remove them out directly?
# include ""**tensorflow/cc/ops/image_ops.h**""
# include ""**tensorflow/core/framework/graph.pb.h**""

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/main.cc#L38

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/main.cc#L40
"
5169,Windows GPU random initialization not working,"Using `tf.truncated_normal` (and possibly the other random functions too) on my GPU (GTX 1060) with the new Windows build produces only zeros whereas running it on my CPU works as expected.

Example code:

``` Python
with tf.device('/cpu:0'):
    with tf.Session() as sess:
        # Something random, as expected
        print(""CPU:"", sess.run(tf.truncated_normal([5])))

with tf.device('/gpu:0'):
    with tf.Session() as sess:
        # All zeros
        print(""GPU:"", sess.run(tf.truncated_normal([5])))
```

I used the same setup as [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md) with CMake 3.6 and rolled back to https://github.com/tensorflow/tensorflow/commit/41ba1e0e6fbf443f1a972ff0130ba6741b9b7a50 to fix the issue with eigen not compiling.

// Also it seems the result of any calculation involving a tf.Variable becomes 0, while just running / printing the variable itself shows its correct value (CPU works fine though).
"
5168,[unexpected keyword argument 'syntax'] occurs on Ubuntu 16.04 with protobuf 3 of 4e8497d by installing from source,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
#4
### Environment info

Operating System: Ubuntu 16.04
Installed version of CUDA and cuDNN: CUDA 8 & CUDNN 5.1
1. The commit hash (`git rev-parse HEAD`)
   Download the zip file by http. Version:[4e8497d](https://github.com/tensorflow/tensorflow/commit/4e8497dcdb7918082732c01cf777f3559fc8168b)
2. The output of `bazel version`
   Build label: 0.3.2
   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Fri Oct 7 17:25:10 2016 (1475861110)
   Build timestamp: 1475861110
   Build timestamp as int: 1475861110
### What other attempted solutions have you tried?

Change /usr/bin/protoc & /usr/include/google version from 2 to 3.
### Logs or other output that would be helpful

[2,290 / 2,578] Still waiting for 196 jobs to complete:
      Running (standalone):
Target //tensorflow/tools/pip_package:build_pip_package up-to-date:
  bazel-bin/tensorflow/tools/pip_package/build_pip_package
INFO: Elapsed time: 2425.533s, Critical Path: 2122.33s
#### Problem

python -c ""import tensorflow""

I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so locally
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/name/.local/lib/python2.7/site-packages/tensorflow/**init**.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/home/name/.local/lib/python2.7/site-packages/tensorflow/python/**init**.py"", line 63, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/home/name/.local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2
  File ""/home/name/.local/lib/python2.7/site-packages/tensorflow/core/framework/node_def_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/home/name/.local/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/home/name/.local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2
  File ""/home/name/.local/lib/python2.7/site-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 22, in <module>
    serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""m\n\x0eResourceHandle\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tB4\n\x18org.tensorflow.frameworkB\x13ResourceHandleProtoP\x01\xf8\x01\x01\x62\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'syntax'
"
5163,AttributeError: 'module' object has no attribute 'histogram',"### Environment info

Operating System: MacOS 10.12

Running tensorflow (0.11.0rc1), I'm trying to retrain the Inception's final layer with my own set of images, and I'm running into this error:

<img width=""749"" alt=""screen shot 2016-10-24 at 12 56 46 am"" src=""https://cloud.githubusercontent.com/assets/8280282/19637602/c7ea232e-9984-11e6-8d9d-5e0ba56a7b47.png"">
"
5162,How to use tf c api with cuda ?,"I followed the  tutorial of  ""https://www.tensorflow.org/versions/r0.11/tutorials/image_recognition/index.html#usage-with-the-c-api"" 

but it is only support CPU, so how to enable GPU supported ? 
"
5161,`import tensorflow` with CUDA throws segmentation fault in macOS,"```
$ export DYLD_LIBRARY_PATH=/usr/local/cuda/lib
$ python -c 'import tensorflow'
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.dylib locally
[1]    9772 segmentation fault  python -c 'import tensorflow'
```
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Similar one: http://stackoverflow.com/questions/38924568/tensorflow-0-10-cuda-on-osx-segfaults-on-python-import
But the answer is not helpful.
### Environment info

Operating System: macOS 10.12

Installed version of CUDA and cuDNN:

```
$ ls -l libcud*
-rwxr-xr-x 1 root wheel 13504 Sep 27 06:59 libcuda.dylib
lrwxr-xr-x 1 root wheel    45 Sep 27 07:00 libcudadevrt.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a
lrwxr-xr-x 1 root wheel    50 Sep 27 07:00 libcudart.8.0.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib
lrwxr-xr-x 1 root wheel    46 Sep 27 07:00 libcudart.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib
lrwxr-xr-x 1 root wheel    49 Sep 27 07:00 libcudart_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a
```

If installed from binary pip package, provide:
1. A link to the pip package you installed:

wheel: https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.11.0rc1-py2-none-any.whl
(CUDA driver version: 8.0.46)
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

Not possible.
### Logs or other output that would be helpful

How can I capture more detail of the segmentation fault? I will attach more if it is possible.
"
5160,installation issueï¼Can we install TensorFlow in Ubuntu14.04 without UI environment?,"Can we install TensorFlow in Ubuntu14.04 **without UI environment**?
I try install to install tensorflow in ubuntu with out UI, but i fail. So I want to know ,does the tensorflow support the ubuntu without UI environment?  thanks~
### Environment info

Operating System:
Ubuntu 14.04 without UI.
`Linux data-science-toolbox 3.13.0-24-generic #47-Ubuntu SMP Fri May 2 23:30:00 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux`

If installed from binary pip package, provide:
1. A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0rc1-cp27-none-linux_x86_64.whl
"
5159,r0.11 iOS build and examples fail with duplicate symbols in libtensorflow-core.a,"This is from a fresh checkout of commit-id 40d28e24df77130792dc20408e45dda3154b9bc2, the current r0.11 branch.

On Mac OS 10.11.6 and Xcode 8.0, building the iOS library with build_ios_all.sh completes without errors, but attempting to actually build the Xcode projects in contrib/ios_examples or use the resulting libtensorflow-core.a in my own project fails with a linker error.

```
duplicate symbol __Z14tf_git_versionv in:
    /Users/avalys/Desktop/tensorflow.build_ios/tensorflow/contrib/ios_examples/simple/../../makefile/gen/lib/libtensorflow-core.a(version_info.o)
duplicate symbol __Z19tf_compiler_versionv in:
    /Users/avalys/Desktop/tensorflow.build_ios/tensorflow/contrib/ios_examples/simple/../../makefile/gen/lib/libtensorflow-core.a(version_info.o)
ld: 2 duplicate symbols for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
```

And indeed, nm -a libtensorflow-core.a | grep git_version gives:

```
0000000000000000 T __Z14tf_git_versionv
0000000000000000 T __Z14tf_git_versionv
```
"
5156,Feature Request : inline graph visualization for ipython,"Building TensorFlow graphs is much easier when done in an interactive environment like ipython.

Would be nice to have an interactive display of the current graph inline in ipython using something like mpld3. Another simpler possibility would be to just output an image of the current graph (no interactivity).
"
5155,Cannot install tensorflow on OSX,"I'm having issues installing tensorflow on my mac device. I seem to be getting a protobuf version mismatch with rc0 wheel. 

> Installing collected packages: protobuf, tensorflow
>   Found existing installation: protobuf 3.0.0a2
>     Uninstalling protobuf-3.0.0a2:
>       Successfully uninstalled protobuf-3.0.0a2
>   Found existing installation: tensorflow 0.11.0rc0
>     Uninstalling tensorflow-0.11.0rc0:
>       Successfully uninstalled tensorflow-0.11.0rc0
> Successfully installed protobuf-3.0.0 tensorflow-0.11.0rc1

And then trying to import

```
python -c ""import tensorflow""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 53, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/node_def_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 22, in <module>
    serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""z\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x12\x14\n\x0cunknown_rank\x18\x03 \x01(\x08\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tB2\n\x18org.tensorflow.frameworkB\x11TensorShapeProtosP\x01\xf8\x01\x01\x62\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'syntax'
```

This thread https://github.com/tensorflow/tensorflow/issues/11 seems to mention this to be a protobuf version mismatch error but I'm not sure. 

Any workarounds or if anyone has a clue on what's wrong?
"
5154,Unknown git option: -C,"I'm trying to compile the latest TensorFlow, but I'm getting a `git` error:

```
$ bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
INFO: Loading package: @local_config_xcode//
INFO: Found 1 target...
INFO: From Executing genrule //tensorflow/core:version_info_gen:
Unknown option: -C
usage: git [--version] [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           [-c name=value] [--help]
           <command> [<args>]
! 
```

It looks like the `git -C` option is used, but that is only supported in git version >= 1.8.

It looks like it's not worth requiring git 1.8 just for this?
"
5153,skflow: DNNClassifier fit has no logdir Parameter,"I'm missing the logdir parameter on DNNClassifier  fit. This is either a bug or a changed behaviour that I don't get (sorry if this should be on stackoverflow, I'm not sure)

TensorFlowDNNClassifier tells me it's depracted and I should use DNNClassifier:
![tensorflowdnnclassifier](https://cloud.githubusercontent.com/assets/10122382/19629647/835ef85c-9979-11e6-9966-0aeedb8107bc.png)

But when I use DNNClassifier the classifier.fit() Method loses it's logdir parameter (I use for tensorboard):
![logdir](https://cloud.githubusercontent.com/assets/10122382/19629870/60dd7ba0-997e-11e6-8071-5c5f1c1ee81c.PNG)

The behaviour slightly changes in general like now max_steps behaves like steps previously did and steps or no parameter about steps trains very long/forever.
"
5152,cmake build doesn't work for debug build,"On Windows, cmake build work fine for release build.

But for debug build, some projects are still using Release settings, for example:

protobuf\src\protobuf\Release\protoc.exe is used, should be protobuf\src\protobuf\Debug\protoc.exe
zlib.lib is used, should be zlibd.lib
"
5151,Error with running tensorflow/tensorflow/examples/tutorials/mnist/fully_connected_feed.py,"I am not able to run the example for mnist
$ python fully_connected_feed.py 
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
Error Log: Traceback (most recent call last):
  File ""fully_connected_feed.py"", line 268, in <module>
    tf.app.run()
  File ""/home/aashishk/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""fully_connected_feed.py"", line 219, in main
    run_training()
  File ""fully_connected_feed.py"", line 143, in run_training
    **summary = tf.summary.merge_all()
AttributeError: 'module' object has no attribute 'merge_all'**
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

http://stackoverflow.com/questions/33772833/error-while-merging-summaries-for-tensorboard
### Environment info

Operating System: Ubuntu

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): none

**Tensorflow** **0.10.0** installed using **conda** **4.2.9**
I am only taking the examples folder from here to test with the above version
"
5149,Error installing from source,"In the procedure of installing from source, 
when I try to do ""bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg""

then an error occurs and the message is like this:
""error: can't copy 'tensorflow/models/embedding/gen_word2vec.py': doesn't exist or not a regular file""

In the directory of '_tensorflow/models/embedding/_', there does not exist named ""gen_word2vec.py"", only ""word2vec.py"" is in there.
(Changing the file name ""word2vec.py"" as ""gen_word2vec.py"", but it does not make it.)

OS : OS X El Capitan(10.11.6)
TensorFlow : r0.11(Same problem occurs r0.10)

In #4234, recommended method is installing the TF's branch r0.10, but it does not work for me.
How can I solve it?

<img width=""656"" alt=""2016-10-23 8 05 16"" src=""https://cloud.githubusercontent.com/assets/22737703/19625753/111ae2aa-995c-11e6-93c0-464fb1443589.png"">
"
5147,Add 'dynamic_pad' flag to `shuffle_batch` as implemented in `batch`,"The `tf.train.batch()` function had a nice `dynamic_pad` flag:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/input.py#L567
Is there anything holding us batch from implementing it in `tf.train.shuffle_batch()`:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/input.py#L778
"
5143,Error building from source,"Hi all, 

I'm trying to build TF from source so that I can run it in development mode and be able to expand the functionality of some of the modules, but am running into some snags with the bazel building. 
### Environment info

Operating System:

Mac OSX Yosemite

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
   
   ec7f37e40fedb23435bfb7e28668e5fa63ff52f3
2. The output of `bazel version`
   
   Build label: 0.3.2-2016-10-22 (@088bbc6)
   Build target: bazel-out/local-    opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Sun Oct 23 00:04:18 2016 (1477181058)
   Build timestamp: 1477181058
   Build timestamp as int: 1477181058

Running: `bazel build -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures`
gives

```
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
ERROR: /Users/mihaileric/Documents/Research/tensorflow/tensorflow/python/BUILD:1806:1: in cc_library rule //tensorflow/python:tf_session_helper: non-test target '//tensorflow/python:tf_session_helper' depends on testonly target '//tensorflow/python:construction_fails_op' and doesn't have testonly attribute set.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
INFO: Elapsed time: 0.848s
```

I'm having a lot of difficulty interpreting these error messages  and am not finding too much on Stack Overflow or other TF git threads. Any help would be greatly appreciated!
"
5141,ipython ImportError: Library not loaded: @rpath/libcudart.8.0.dylib,"I just installed 0.11rc1 from pip (`TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.11.0rc1-py2-none-any.whl`), with a brand-new CUDA 8.0 installation, and got this error:

```
In [1]: import tensorflow as tf
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-1-41389fad42b5> in <module>()
----> 1 import tensorflow as tf

/Users/me/anaconda/lib/python2.7/site-packages/tensorflow/__init__.py in <module>()
     21 from __future__ import print_function
     22
---> 23 from tensorflow.python import *
     24
     25

/Users/me/anaconda/lib/python2.7/site-packages/tensorflow/python/__init__.py in <module>()
     47 _default_dlopen_flags = sys.getdlopenflags()
     48 sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)
---> 49 from tensorflow.python import pywrap_tensorflow
     50 sys.setdlopenflags(_default_dlopen_flags)
     51

/Users/me/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()
     26                 fp.close()
     27             return _mod
---> 28     _pywrap_tensorflow = swig_import_helper()
     29     del swig_import_helper
     30 else:

/Users/me/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in swig_import_helper()
     22         if fp is not None:
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
     25             finally:
     26                 fp.close()

ImportError: dlopen(/Users/me/anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.8.0.dylib
  Referenced from: /Users/me/anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
  Reason: image not found
```

(Similar to https://github.com/tensorflow/tensorflow/issues/4187 but different error.)
Looks like a [path issue](http://stackoverflow.com/questions/37933890/tensorflow-gpu-setup-error-with-cuda-on-pycharm) but I don't see a problem:

```
â  ~ echo $PATH
/Users/me/anaconda/bin:/usr/local/cuda/bin:/Developer/NVIDIA/CUDA-8.0/bin:/opt/local/bin:/opt/local/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin
â  ~ echo $DYLD_LIBRARY_PATH
/usr/local/cuda/lib:/Developer/NVIDIA/CUDA-8.0/lib:
â  ~ ll /Developer/NVIDIA/CUDA-8.0/lib/libcudart*
-rwxr-xr-x 1 root wheel 285K Sep 27 00:59 /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib
lrwxr-xr-x 1 root wheel   19 Sep 27 00:59 /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib -> libcudart.8.0.dylib
-rw-r--r-- 1 root wheel 599K Sep 27 00:59 /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a
```

I also get a segfault when importing in python:

```
â  ~ python -c ""import tensorflow;""
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.dylib locally
[1]    60723 segmentation fault  python -c ""import tensorflow;""
```

Tried the [suggestion from the docs](https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#mac-os-x-segmentation-fault-when-import-tensorflow), didn't work:

```
ln -sf /usr/local/cuda/lib/libcuda.dylib /usr/local/cuda/lib/libcuda.1.dylib
```

On OSX 10.11.6, CUDA 8.0.46, no CUDNN installed yet.

Is this a SIP issue? Should the install procedure be updated?
I don't know if I can turn off SIP, this is a work computer.
"
5138,"failed to install tensorflow while doing ""pip install""","I am using ubuntu with GPU and follow the tutorial ""Installing from sources"". I successfully go through previous steps, but have trouble at the final step. After running: 
""sudo bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg""
I got this:
""......
Sun Oct 23 00:22:33 CST 2016 : === **Output wheel file is in: /tmp/tensorflow_pkg**""

However, when I run the last step:
""sudo pip install /tmp/tensorflow_pkg/tensorflow-0.11.0rc1-py2-none-any.whl""
I got:
""**IOError: [Errno 2] No such file or directory: '/tmp/tensorflow_pkg/tensorflow-0.11.0rc1-py2-none-any.whl**'""
I knew that the name of the .whl file will depend on your platform. But there is **no folder called tmp**, and I also **cannot find the .whl file** in my tensorflow folder.
I am a beginer, could anyone tells me how to solve it ?
"
5137,tf.train.batch does not work with tf.train.string_input_producer,"When I try to batch results from `tf.train.string_input_producer` nothing happens and timeouts occur on a regular basis. Identical code is located at [tensorflow documentation](https://www.tensorflow.org/versions/r0.11/how_tos/reading_data/index.html#batching). Please see the code below.
### Environment info

Operating System:
ElementaryOS Freya

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
 ~ î°  ls -l /usr/local/cuda-7.5/lib64/libcud*

-rw-r--r-- 1 root root 322936 Ð°Ð²Ð³.  15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Ð°Ð²Ð³.  15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Ð°Ð²Ð³.  15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336 Ð°Ð²Ð³.  15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192 Ð°Ð²Ð³.  15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
```

If installed from binary pip package, provide:
1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc0-cp35-cp35m-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
 ~ î° python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
0.11.0rc0
```
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
import tensorflow as tf

def load_png(input_queue):
    reader = tf.WholeFileReader()
    _, data = reader.read(input_queue)
    data = tf.image.decode_png(data)
    data.set_shape([28, 28, 3])
    return data

tf.reset_default_graph()
config = tf.ConfigProto()
# config.operation_timeout_in_ms=100000

train_dataset = notMNISTDataset(url='http://yaroslavvb.com/upload/notMNIST/', 
                    filename='notMNIST_large.tar.gz',
                   num_classes=10)

filenames = glob.glob(train_dataset._data_folder + '/**/*.png', recursive=True)
filename_queue = tf.train.string_input_producer(filenames, name='filename_queue', shuffle=False, capacity=100)
data = train_dataset._load_png(filename_queue)

# all breaks when we try to batch Reader results
label_batch = tf.train.batch([data],
                              batch_size=5,
                              capacity=100,
                              allow_smaller_final_batch=True, 
                              name='batch_queue')

with tf.Session(config=config) as sess:
    print(""Starting session"")
    tf.initialize_local_variables().run()
    coordinator = tf.train.Coordinator()

    while not coordinator.should_stop():  
        print(""Running batch reading op"")
        threads = tf.train.start_queue_runners(coord=coordinator)
        b = sess.run([label_batch])
        print(b)

    print(""Requesting stop..."")
    coordinator.request_stop()
    coordinator.join(threads)
```
### What other attempted solutions have you tried?

Variations of this code from SO
"
5136,How do I train a semantic segmentation to recognise only one type of object? ,"I want to detect and segment hands in images and that is the only thing I want to detect. 
I 'm using FCN. How do I train it to recognise only the object I want ?
"
5134,Get HTTP 404 ERROR with all the version when installï¼,"Hello,when I install tensorflow with the version of OS X python3 gpu, it brings me the error as 

```
""HTTP error 404 while getting https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.11.0rc1-py3-none-any.whl
  Could not install requirement tensorflow==0.11.0rc1 from https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.11.0rc1-py3-none-any.whl because of error 404 Client Error: Not Found for url: https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.11.0rc1-py3-none-any.whl""
```

How to solve it?
"
5133,"Tensorboard not executing as '__main__', name conflict with directory?","### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

[Similar errors identified as name conflicts between module and directory](http://stackoverflow.com/questions/24829769/module-object-has-no-attribute-main-django)
### Environment info

Operating System:  macOS Sierra

If installed from binary pip package, provide:
1. A link to the pip package you installed:
   current osx [nightly](https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=mac-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.11.0rc0-py2-none-any.whl)
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.11.0rc0
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

In terminal window run 'tensorboard'

Output: 

> File ""<TENSORFLOW DIR>/tensorflow/lib/python2.7/site-packages/tensorflow/tensorboard/tensorboard.py"", line 43, in main
>     logdir = os.path.expanduser(FLAGS.logdir)
> AttributeError: 'NoneType' object has no attribute 'logdir'
### What other attempted solutions have you tried?

A workaround is to rename tensorboard.py (I used tensorboard1.py) and execute with full path to that file.

Originally I printed `__name__`  and learned it was 'tensorflow.tensorboard.tensorboard'.
"
5126,Documentation request: NN regression,"There is a disconnect between the CSV documentation and the regression docs. I've documented one example here: http://stackoverflow.com/questions/40093776/csv-tensorflow-regression-via-neural-network-model

I would like to request clearer examples of feeding neural networks with CSV or NDArrays. Most of the NN examples I've seen were strictly classification. They do not show how to take Numpy NDarrays (features x instances or class column) or CSV to predict a regression column.

The documentation I found on these pages below was confusing or vague. Overall, there are major gaps for doing the task above. The proposed documentation would clearly demonstrate with complete code using any of these: DNNRegressor, TensorFlowDNNRegressor, LinearRegressor, TensorFlowLinearRegressor, TensorFlowRNNRegressor, TensorFlowRegressor. If such documentation exists and I have yet to discover it, please advise me. Thanks.
- Base code that reads CSV and works (classifier): https://www.tensorflow.org/versions/r0.11/tutorials/tflearn/index.html
- Regressor: https://www.tensorflow.org/versions/r0.11/api_docs/python/contrib.learn.html#DNNRegressor
- CSV reading: https://www.tensorflow.org/versions/master/how_tos/reading_data/index.html#csv-files
- Column embedding: https://www.tensorflow.org/versions/r0.11/tutorials/wide_and_deep/index.html
- List of APIs (DNNRegressor, TensorFlowDNNRegressor, LinearRegressor, TensorFlowLinearRegressor, TensorFlowRNNRegressor, TensorFlowRegressor): https://www.tensorflow.org/versions/r0.11/api_docs/python/contrib.learn.html
"
5125,"InvalidArgumentError : input must be 4-dimensional[100,100,3]","I am trying to use inception V1 model to predict single image. The example on the tensor flow website uses inception V3, which needs 1.7s-1.9s on a single Tian X GPU. This is not fast. 

I use the following python code to test V3 performance, which by changing **classify_image.py**

```
 #... above code is for load graph and read image

t1=time.time()

softmax_tensor = sess.graph.get_tensor_by_name('softmax:0') 
predictions = sess.run(softmax_tensor,{'DecodeJpeg/contents:0': image_data}) 
predictions= np.squeeze(fpredictions)

delta=time.time()-t1
print(delta)
```

I think the major reason is V3 has 42 layers, which is too large. 

However, when i change the above code for V1 model. I meet errors. First I get the node names from V1 model .pb file as below:
**input
conv2d0_w
conv2d0_b
conv2d1_w**
...
...
...
**softmax2
output
output1
output2**

So the entry point of V1 model is **input**. The entry point of V3 is **DecodeJpeg/contents**, which accept image buffer from **tf.gfile.FastGFile(image, 'rb').read()** function directly. But V1 does not. So i use the code below to get the image and return as an array.

**image_data**=**cv2**.imread(image)  

Now the code for V1 model become for prediction become

```
softmax_tensor = sess.graph.get_tensor_by_name('softmax2:0')
predictions = sess.run(softmax_tensor, {'input:0': image_data})
```

However, I get error below when i run the code.

InvalidArgumentError (see above for traceback): **input must be 4-dimensional**[100,100,3]
     [[Node: conv2d0_pre_relu/conv = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_input_0, conv2d0_w)]]

It says it need a 4-dimensional input. My image array has width, height and channel only. So how can i create a 4D tensor from a single image for V1 model as input data?
"
5122,custom CUDA op example returns random values,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Nothing
### Environment info

Operating System:

```
$ uname -a
Linux n-62-18-47 2.6.32-642.6.1.el6.x86_64 #1 SMP Wed Oct 5 08:48:31 CDT 2016 x86_64 x86_64 x86_64 GNU/Linux
```

Installed version of CUDA and cuDNN: CUDA: 8, cuDNN 5.1
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
$ ls -l /appl/cuda/8.0/lib64/libcud*
-rw-r--r-- 1 sebo root 560184 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 sebo root     16 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 sebo root     19 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 sebo root 394472 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 sebo root 737516 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart_static.a
```

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`) 5a5a25ea3ebef623e07fb9a46419a9df377a37a5
2. The output of `bazel version` 

```
$ bazel version
Build label: 0.3.2- (@non-git)
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 21 15:09:04 2016 (1477062544)
Build timestamp: 1477062544
Build timestamp as int: 1477062544
```
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

Using the CUDA example from: https://github.com/tensorflow/tensorflow/tree/r0.11/tensorflow/g3doc/how_tos/adding_an_op

1) compile example

```
export TF_INC=/zhome/ff/2/77654/stdpy3/lib/python3.5/site-packages/tensorflow/include

nvcc -std=c++11 -c -o cuda_op_kernel.cu.o cuda_op_kernel.cu.cc \
-I $TF_INC -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC

g++ -std=c++11 -shared -o cuda_op_kernel.so cuda_op_kernel.cc \
cuda_op_kernel.cu.o -I $TF_INC -fPIC -L /appl/cuda/8.0/lib64 -L /appl/cudnn/v5.1-prod/lib64 -lcudart
```

2) edit `tensorflow.g3doc.how_tos.adding_an_op import cuda_op` to `import cuda_op` in `cuda_op_test.py`.
### What other attempted solutions have you tried?
- I tried a non CUDA example, worked fine.
- I tried a diffrent cuda kernel (square operator) also failed.
- I added `printf` to the kernel launcher and made sure it was executed.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).

```
CUDA_VISIBLE_DEVICES=3 python3 cuda_op_test.py
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/core/common_runtime/gpu/gpu_device.cc:944] Found device 0 with properties:
name: Tesla K40c
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:02:00.0
Total memory: 11.25GiB
Free memory: 11.15GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0)
Failed to get the number of CUDA devices: CUDA driver version is insufficient for CUDA runtime version
not equal where =  (array([0, 1, 2, 3, 4]),)
not equal lhs =  [ 280541332  143397048 2031878174 1533025280 1612453930]
not equal rhs =  [6 5 4 3 2]
F.
======================================================================
FAIL: test (__main__.AddOneTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""cuda_op_test.py"", line 31, in test
    self.assertAllEqual(result.eval(), [6, 5, 4, 3, 2])
  File ""/zhome/ff/2/77654/stdpy3/lib/python3.5/site-packages/tensorflow/python/framework/test_util.py"", line 499, in assertAllEqual
    np.testing.assert_array_equal(a, b)
  File ""/zhome/ff/2/77654/stdpy3/lib/python3.5/site-packages/numpy/testing/utils.py"", line 813, in assert_array_equal
    verbose=verbose, header='Arrays are not equal')
  File ""/zhome/ff/2/77654/stdpy3/lib/python3.5/site-packages/numpy/testing/utils.py"", line 739, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Arrays are not equal

(mismatch 100.0%)
 x: array([ 280541332,  143397048, 2031878174, 1533025280, 1612453930], dtype=int32)
 y: array([6, 5, 4, 3, 2])

----------------------------------------------------------------------
Ran 2 tests in 0.213s

FAILED (failures=1)
```

---

It looks like the output just contains random memory. Perhaps the GPU memory isn't copied back to the host memory.
"
5120,Error : AttributeError: 'module' object has no attribute 'maybe_download_and_extract',"When I do : 

import cifar10
cifar10.maybe_download_and_extract()

I get the error: AttributeError: 'module' object has no attribute 'maybe_download_and_extract'
how Do I download and extract the model?
"
5119,When I do : ,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
5118,seq2seq tutorial example not working for python 3.4/3.5,"I am trying to get the sequence-to-sequence Tensorflow tutorial (https://www.tensorflow.org/versions/r0.11/tutorials/seq2seq/index.html) up and running, but after downloading the WMT data, I am facing an error upon creating the vocabulary: 

```
>> python3 translate.py --data_dir ~/tf-data/
Preparing WMT data in /home/user/tf-data/
Creating vocabulary /home/user/tf-data/vocab40000.fr from data /home/user/tf-data/giga-fren.release2.fixed.fr
Traceback (most recent call last):
  File ""translate.py"", line 290, in <module>
    tf.app.run()
  File ""/home/user/tensorflow3/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""translate.py"", line 287, in main
    train()
  File ""translate.py"", line 147, in train
    FLAGS.data_dir, FLAGS.en_vocab_size, FLAGS.fr_vocab_size)
  File ""/home/user/tensorflow3/lib/python3.5/site-packages/tensorflow/models/rnn/translate/data_utils.py"", line 271, in prepare_wmt_data
    create_vocabulary(fr_vocab_path, train_path + "".fr"", fr_vocabulary_size, tokenizer)
  File ""/home/user/tensorflow3/lib/python3.5/site-packages/tensorflow/models/rnn/translate/data_utils.py"", line 140, in create_vocabulary
    tokens = tokenizer(line) if tokenizer else basic_tokenizer(line)
  File ""/home/user/tensorflow3/lib/python3.5/site-packages/tensorflow/models/rnn/translate/data_utils.py"", line 109, in basic_tokenizer
    words.extend(_WORD_SPLIT.split(space_separated_fragment))
TypeError: cannot use a bytes pattern on a string-like object
```

Operating System: Ubuntu 16.04.1 LTS

I tried running on two different systems (Python 3.4.3, Python 3.5.2), and the same error arises.

I am running an up-to-date, CPU-only version of Tensorflow 0.11.0rc0 (for the appropriate version of Python 3.4/3.5) in a virtualenv, with an up-to-date version of the github repository.

My hunch is that this is related to a similar issue (https://github.com/tensorflow/tensorflow/issues/1432) that had been previously fixed, but this error is not identical, so am not sure if this is new.

Any insight would be much appreciated!
"
5117,"""Cannot assign a device to node..."" bug in TensorArrayScatter_grad when using pre_scanned tensor in double loop of scan/while/map","### Environment info

tensorflow branch : 0.11.0rc0
CUDA version : 7.0
cuDNN version : 6.5.48
OS version : Ubuntu 14.04.5 LTS
GPU : GPU0 titan x(maxwell), GPU1 Tesla K20c(not using in this code)
(Also using anaconda2 environment and Jupyter with tf.InteractiveSession())
### The bug (or is this intended error?)

I was using tf.scan() and tf.map() to code seq-2-seq encoder decoder structure with attention mechanism. 
When i tried to put scanned tensor in map_fn() inside another scan(), the graph is drawn as normally and i even can evaluate the value of output tensor. 

However when i try to optimize, or get gradient of that tensor, the bug pops up saying `InvalidArgumentError: Cannot assign a device to node 'gradients/scan_1/while/map/TensorArrayPack/TensorArrayScatter_grad/TensorArrayGather/f_acc': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/GPU:0`.

I tried `config.allow_soft_placement = True`, but it only changed the error log and didn't work.
It was really awkward that the error log complains about AttrValue must not be the value of DT_STRING_REF when i set `config.allow_soft_placement = True`

My code is like ,in simplified version ,following : (i wrote a bug-reproducing example code at the bottom)
`encoder_states = tf.scan(_encoder_step, encoder_inputs, initializer=encoder_initial_states)`
`decoder_states = tf.scan(_decoder_step, decoder_inputs, initializer=encoder_states[-1]`

, and in `def _decoder_step(prev_h, inputs):` i used `tf.map_fn()` to get aligned context of encoder states as attention mechanism in https://arxiv.org/abs/1409.0473.

It looks like following : 
in `_decoder_step(prev_h, inputs)`:

```
    def alignment_model(inputs):
        # prev_h has the shape of [num_layer, num_batch, num_hidden]; prev_h[0] is the value of the first layer in decoder.
        alignment_state = tf.nn.tanh(_linear([inputs, prev_h[0], output_dim=num_slot, bias=False))
        return _linear([alignment_state], output_dim=1, bias=False)
    alignment = tf.map_fn(alignment_model, encoder_states) # and here the bug comes.
```
### error message

with `config.allow_soft_placement = False` :

```
InvalidArgumentError: Cannot assign a device to node 'gradients/Decoder/scan/while/Attention/map/TensorArrayPack/TensorArrayScatter_grad/TensorArrayGather/f_acc': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/GPU:0'
Colocation Debug Info:
Colocation group had the following types and devices: 
TensorArrayWrite: GPU CPU 
TensorArray: GPU CPU 
StackPush: GPU CPU 
TensorArrayRead: GPU CPU 
Range: GPU CPU 
Stack: GPU CPU 
StackPop: GPU CPU 
Const: GPU CPU 
TensorArrayScatter: GPU CPU 
RefEnter: GPU CPU 
Enter: GPU CPU 
TensorArrayGather: GPU CPU 
StridedSlice: GPU CPU 
TensorArrayGrad: GPU CPU 
Identity: GPU CPU 
Shape: GPU CPU 
     [[Node: gradients/Decoder/scan/while/Attention/map/TensorArrayPack/TensorArrayScatter_grad/TensorArrayGather/f_acc = Stack[_class=[""loc:@Decoder/scan/while/Attention/map/TensorArray""], elem_type=DT_INT32, stack_name=""""]()]]

Caused by op u'gradients/Decoder/scan/while/Attention/map/TensorArrayPack/TensorArrayScatter_grad/TensorArrayGather/f_acc', defined at:
  File ""/home/youaredeadl/anaconda2/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py"", line 596, in launch_instance
    app.start()
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py"", line 442, in start
    ioloop.IOLoop.instance().start()
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py"", line 162, in start
    super(ZMQIOLoop, self).start()
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py"", line 883, in start
    handler_func(fd_obj, events)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 391, in execute_request
    user_expressions, allow_stdin)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py"", line 199, in do_execute
    shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2723, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2825, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2885, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-16-940fe231159a>"", line 3, in <module>
    grads, _ = tf.clip_by_global_norm(tf.gradients(model.loss, tvars, aggregation_method=tf.AggregationMethod.ADD_N), 1)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 469, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/tensor_array_grad.py"", line 213, in _TensorArrayScatterGrad
    grad = g.gather(indices)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/tensor_array_ops.py"", line 301, in gather
    element_shape=element_shape)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 1302, in _tensor_array_gather
    element_shape=element_shape, name=name)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 749, in apply_op
    op_def=op_def)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2380, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1302, in __init__
    self._control_flow_context.AddOp(self)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1941, in AddOp
    self._AddOpInternal(op)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1965, in _AddOpInternal
    self.AddValue(x)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1900, in AddValue
    real_val = grad_ctxt.grad_state.GetRealValue(val)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 987, in GetRealValue
    history_value = cur_grad_state.AddForwardAccumulator(cur_value)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 861, in AddForwardAccumulator
    acc = gen_data_flow_ops._stack(value.dtype.base_dtype, name=""f_acc"")
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 1104, in _stack
    stack_name=stack_name, name=name)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 749, in apply_op
    op_def=op_def)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2380, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1298, in __init__
    self._traceback = _extract_stack()

...which was originally created as op u'Decoder/scan/while/Attention/map/TensorArrayPack/TensorArrayScatter', defined at:
  File ""/home/youaredeadl/anaconda2/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
[elided 17 identical lines from previous traceback]
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2885, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-15-153e1e7c7c3b>"", line 6, in <module>
    num_slot=_num_slot)
  File ""<ipython-input-13-1ccd26e81475>"", line 34, in __init__
    initializer=self.decoder_initial_states) # shape of [time, num_layer, batch, num_hidden]
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/functional_ops.py"", line 563, in scan
    back_prop=back_prop, swap_memory=swap_memory)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2518, in while_loop
    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2356, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2306, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/functional_ops.py"", line 553, in compute
    a_out = fn(packed_a, packed_elems)
  File ""<ipython-input-13-1ccd26e81475>"", line 98, in _decoder_step
    context = self._get_context(encoder_last_states, states[0])
  File ""<ipython-input-13-1ccd26e81475>"", line 81, in _get_context
    alignment = tf.map_fn(alignment_hidden_layer, encoder_states) # shape of [time, batch, 1]
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/functional_ops.py"", line 333, in map_fn
    elem_ta.unpack(elem) for elem_ta, elem in zip(elems_ta, elems_flat)]
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/tensor_array_ops.py"", line 391, in unpack
    indices=math_ops.range(0, num_elements), value=value, name=name)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/tensor_array_ops.py"", line 412, in scatter
    name=name)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 1447, in _tensor_array_scatter
    name=name)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 749, in apply_op
    op_def=op_def)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2380, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/youaredeadl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1298, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Cannot assign a device to node 'gradients/Decoder/scan/while/Attention/map/TensorArrayPack/TensorArrayScatter_grad/TensorArrayGather/f_acc': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/GPU:0'
Colocation Debug Info:
Colocation group had the following types and devices: 
TensorArrayWrite: GPU CPU 
TensorArray: GPU CPU 
StackPush: GPU CPU 
TensorArrayRead: GPU CPU 
Range: GPU CPU 
Stack: GPU CPU 
StackPop: GPU CPU 
Const: GPU CPU 
TensorArrayScatter: GPU CPU 
RefEnter: GPU CPU 
Enter: GPU CPU 
TensorArrayGather: GPU CPU 
StridedSlice: GPU CPU 
TensorArrayGrad: GPU CPU 
Identity: GPU CPU 
Shape: GPU CPU 
     [[Node: gradients/Decoder/scan/while/Attention/map/TensorArrayPack/TensorArrayScatter_grad/TensorArrayGather/f_acc = Stack[_class=[""loc:@Decoder/scan/while/Attention/map/TensorArray""], elem_type=DT_INT32, stack_name=""""]()]]
```

with `config.allow_soft_placement = True`:

```
InvalidArgumentError: AttrValue must not have reference type value of string_ref
     for attr 'tensor_type'
    ; NodeDef: scan_1/while/map/TensorArray/_211 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_666_scan_1/while/map/TensorArray"", tensor_type=DT_STRING_REF, _device=""/job:localhost/replica:0/task:0/cpu:0""](^_cloopscan_1/while/map/TensorArrayPack_1/range/delta/_37); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
     [[Node: scan_1/while/map/TensorArray/_211 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_666_scan_1/while/map/TensorArray"", tensor_type=DT_STRING_REF, _device=""/job:localhost/replica:0/task:0/cpu:0""](^_cloopscan_1/while/map/TensorArrayPack_1/range/delta/_37)]]
```
### reproducible example code

```
import tensorflow as tf
import numpy as np

in_data_for_pre_scan = np.ones(shape=[2, 8, 5], dtype=np.float64)
in_data_for_post_scan = np.ones(shape=[2, 8, 5], dtype=np.float64)
initial_state_data_for_pre_scan = np.zeros(shape=[8, 5], dtype=np.float64)
initials_state_data_for_post_scan = np.zeros(shape=[8, 5], dtype=np.float64)

inputs_for_pre_scan = tf.placeholder(shape=[None, None, 5], dtype=tf.float64)
inputs_for_post_scan = tf.placeholder(shape=[None, None, 5], dtype=tf.float64)
initial_state_for_pre_scan = tf.placeholder(shape=[None, 5], dtype=tf.float64)
initial_state_for_post_scan = tf.placeholder(shape=[None, 5], dtype=tf.float64)

weight = tf.get_variable('W', [5, 5], dtype=tf.float64)

def pre_scan(states, inputs):    
    return states + tf.matmul(inputs, weight)

def post_scan(states, inputs):
    def inner_map(inputs):
        return inputs
    loop_output = tf.map_fn(inner_map, pre_scanned[0]) 

    return states + loop_output + inputs

pre_scanned = tf.scan(pre_scan, inputs_for_pre_scan, initializer=initial_state_for_pre_scan)
res = tf.scan(post_scan, inputs_for_post_scan, initializer=initial_state_for_post_scan)

opt_func = tf.train.AdamOptimizer()
tvars = tf.trainable_variables()
grads, _ = tf.clip_by_global_norm(tf.gradients(tf.reduce_mean(tf.square(res)), tvars, aggregation_method=tf.AggregationMethod.ADD_N), 1)
optimizer = opt_func.apply_gradients(zip(grads, tvars))

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
#config.allow_soft_placement = True
sess = tf.InteractiveSession(config=config)
sess.run(tf.initialize_all_variables())

sess.run(res, feed_dict={inputs_for_pre_scan:in_data_for_pre_scan, 
                         initial_state_for_pre_scan:initial_state_data_for_pre_scan, 
                         inputs_for_post_scan:in_data_for_post_scan, 
                         initial_state_for_post_scan:initials_state_data_for_post_scan}) # this runs as just fine.

sess.run(optimizer, feed_dict={inputs_for_pre_scan:in_data_for_pre_scan, 
                               initial_state_for_pre_scan:initial_state_data_for_pre_scan, 
                               inputs_for_post_scan:in_data_for_post_scan, 
                               initial_state_for_post_scan:initials_state_data_for_post_scan}) # this doesn't work.
```

The log says about 'scatter()' in 'ops/tensor_array_ops.py' and `_tensor_array_scatter' in`ops/gen_data_flow_ops.py`, which is written in this branch.

@ebrevdo would anybody get me some hints about this?

---
### edited :

if i only run the optimizer part without running res, such as,

```
'''
sess.run(res, feed_dict={inputs_for_pre_scan:in_data_for_pre_scan, 
                         initial_state_for_pre_scan:initial_state_data_for_pre_scan, 
                         inputs_for_post_scan:in_data_for_post_scan, 
                         initial_state_for_post_scan:initials_state_data_for_post_scan}) # this runs as just fine.
'''
sess.run(optimizer, feed_dict={inputs_for_pre_scan:in_data_for_pre_scan, 
                               initial_state_for_pre_scan:initial_state_data_for_pre_scan, 
                               inputs_for_post_scan:in_data_for_post_scan, 
                               initial_state_for_post_scan:initials_state_data_for_post_scan}) # this doesn't work.
```

then it works fine. 

but still if i run both of them, sess.run(optimizer) raises `InvalidArgumentError`. could it be problem in my GPU config? actually when i execute `nvidia-smi`, it says that GPU0 is Tesla k20c and GPU1 is Geforce gtx titan x, but tensorflow says in the reverse order.
"
5115,timeout breaks FIFOQueue,"Ubuntu 14.04.5 LTS
0.10.0rc0

Using timeout with notebooks is very useful in case you dequeue an empty queue or enqueue a full one. The problem is that after a timeout occurs a enqueue or dequeueop  throws an error

```
import tensorflow as tf
with tf.device(""/cpu:0""):
    ph = tf.placeholder(tf.float32)
    q = tf.FIFOQueue(2, tf.float32)
    enq = q.enqueue(ph)
    deq = q.dequeue()
    timeout_option = tf.RunOptions(timeout_in_ms=1000)
sess = tf.Session()
sess.run(deq, options=timeout_option)
```

here i get the usual timeout error. The problem is that when I then run
`sess.run(enq, feed_dict={ph:2}, options=timeout_option)`

i get the error:

```
---------------------------------------------------------------------------
CancelledError                            Traceback (most recent call last)
<ipython-input-24-9067a9d62797> in <module>()
----> 1 sess.run(Q, options=timeout_option)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    715     try:
    716       result = self._run(None, fetches, feed_dict, options_ptr,
--> 717                          run_metadata_ptr)
    718       if run_metadata:
    719         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    913     if final_fetches or final_targets:
    914       results = self._do_run(handle, final_targets, final_fetches,
--> 915                              feed_dict_string, options, run_metadata)
    916     else:
    917       results = []

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
    963     if handle is None:
    964       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
--> 965                            target_list, options, run_metadata)
    966     else:
    967       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
    983         except KeyError:
    984           pass
--> 985       raise type(e)(node_def, op, message)
    986 
    987   def _extend_graph(self):

CancelledError: Dequeue operation was cancelled
     [[Node: fifo_queue_Dequeue = QueueDequeue[_class=[""loc:@fifo_queue""], component_types=[DT_FLOAT, DT_INT64, DT_FLOAT], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](fifo_queue)]]
     [[Node: PlaceholderWithDefault/_25 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_14_PlaceholderWithDefault"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
Caused by op u'fifo_queue_Dequeue', defined at:
  File ""<string>"", line 1, in <module>
  File ""/home/cgel/.local/lib/python2.7/site-packages/IPython/kernel/zmq/kernelapp.py"", line 469, in main
    app.start()
  File ""/home/cgel/.local/lib/python2.7/site-packages/IPython/kernel/zmq/kernelapp.py"", line 459, in start
    ioloop.IOLoop.instance().start()
  File ""/usr/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py"", line 160, in start
    super(ZMQIOLoop, self).start()
  File ""/home/cgel/.local/lib/python2.7/site-packages/tornado/ioloop.py"", line 883, in start
    handler_func(fd_obj, events)
  File ""/home/cgel/.local/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 433, in _handle_events
    self._handle_recv()
  File ""/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 465, in _handle_recv
    self._run_callback(callback, msg)
  File ""/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 407, in _run_callback
    callback(*args, **kwargs)
  File ""/home/cgel/.local/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/cgel/.local/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py"", line 281, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/cgel/.local/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py"", line 245, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/cgel/.local/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py"", line 389, in execute_request
    shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/cgel/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2741, in run_cell
    interactivity=interactivity, compiler=compiler)
  File ""/home/cgel/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2827, in run_ast_nodes
    if self.run_code(code):
  File ""/home/cgel/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2883, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-73bf93787995>"", line 76, in <module>
    input_state, action, Y = q.dequeue()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/data_flow_ops.py"", line 418, in dequeue
    self._queue_ref, self._dtypes, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 863, in _queue_dequeue
    timeout_ms=timeout_ms, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 747, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2372, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1298, in __init__
    self._traceback = _extract_stack()
```
"
5114,Issues with tf.get_shape().as_list() and creating index for tf.gather(),"Environment: 
ubuntu 16.04

Installed version of CUDA and cuDNN: 

```
-rw-r--r-- 1 root root   558720 Sep 14 16:02 /usr/local/cuda-8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Sep 14 16:05 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Sep 14 16:05 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root   415432 Sep 14 16:02 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Sep 14 16:02 /usr/local/cuda-8.0/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       17 Oct 11 12:52 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5.1.5
lrwxrwxrwx 1 root root       17 Oct 16 00:02 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
lrwxrwxrwx 1 root root       17 Oct 11 12:52 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 Oct 11 12:51 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Oct 11 12:51 /usr/local/cuda-8.0/lib64/libcudnn_static.a
```
1. The commit hash (`git rev-parse HEAD`): 4bac93835b585cc44fe502f7617ad7ab54265c14
2. The output of `bazel version` 

```
$ bazel version
Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110
```
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

https://gist.github.com/odellus/b520c8990997672ef84c0465c7c337fb
### What other attempted solutions have you tried?

I tried to use `tf.gather_nd()` but it doesn't work on the GPU at this time, so I'm using an alternative.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
https://gist.github.com/odellus/d4b01bf0e7179f19458f12f93fee517d
"
5113,Memory corrupt when running in distributed mode with CUDA 8.0 and Tesla M40,"We have implemented tested the distributed TensorFlow applications. It works in CPU environment and the GPU environment with CUDA 7.5 and Tesla K40. But it fails with CUDA 8.0 and Tesla M40.

![screen shot 2016-10-21 at 19 10 37](https://cloud.githubusercontent.com/assets/2715000/19597024/9882b2de-97c4-11e6-930a-3c373524d21b.png)

![screen shot 2016-10-21 at 19 11 16](https://cloud.githubusercontent.com/assets/2715000/19597035/ab8502ec-97c4-11e6-9028-80d10347dbf2.png)

Not sure if it's related to CUDA 8.0. The test code is [here](https://github.com/tobegit3hub/distributed_tensorflow) and 100% re-produce if I run it with CUDA 8.0 and Tesla M40.
### Environment info

Operating System: CentOS 7.0
CUDA and cuDNN: CUDA 8.0 and cuDNN v5
TensorFlow version: 0.11.0rc0
"
5112,Does tensorflow support to write checkpoint to hdfs?,"now tensorflow 0.11 can read data from hdfs, so how can I write checkpoint to hdfs? for example:

``` python
saver.save(save_path='hdfs://some_dir')
```
"
5111,android example with a new model which has a large .pb file(180mb),"hi guys
i tried to run the android example with a new model which has a large .pb file(180mb), and i get the error.

10-21 15:32:02.172 19751-19816/org.tensorflow.demo A/native: jni_utils.cc:128 Check failed: message->ParseFromArray(memory, data_size) 
10-21 15:32:02.172 19751-19816/org.tensorflow.demo A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 19816 (ImageListener)

i thought it's a limitation of reading file with native code.
does anyone get the same problem or have a way to deal it?
thank for your time.
"
5110,Fail to export model with exporter with distributed session,"We have try `exporter` and `signature` to export our TensorFlow models. The code works in standalone mode but not in distributed mode.

We got `InvalidArgumentError` when calling `exporter.Exporter(saver).init()`. It asks to feed the placeholder but it's not training process and I just want to get the `op`'s name to pass as model's signatures. The error log looks like this.

![screen shot 2016-10-21 at 17 27 17](https://cloud.githubusercontent.com/assets/2715000/19593672/52ddc706-97b4-11e6-8b5e-f278d2197dc2.png)

Do anyone has tried to export models with distributed session? Here is my sample code if it helps.

![screen shot 2016-10-21 at 17 28 22](https://cloud.githubusercontent.com/assets/2715000/19593691/67092bf8-97b4-11e6-872a-e6b4daf05005.png)
### Environment info

Operating System: Ubuntu 16.04
CUDA and cuDNN: Not install
TensorFlow version: 0.11.0rc0
"
5109,Segmentation fault with basic indexing and slicing ,"The following code generates a segmentation fault.
It should obviously return an error because op has only one dimension and a ask for two.
But an alert is probably more informative than a segmentation fault.
(Tensorflow 0.11.0rc0)

```
import tensorflow as tf

v = tf.Variable([1,1,1])
op = v * v
value = op[0,:]

sess = tf.Session()
print(sess.run(value))
```
"
5106,"Problems with TF_GraphGetTensorNumDims when applied to ""Variable"" operations","For some reason, when applying _TF_GraphGetTensorNumDims_ to a ""Variable"" operation,
the functions returns -1, even though the shape and number of dimensions are 
well defined.

A simple example:

``` C++
#include <string>
#include <iostream>
#include ""tensorflow/c/c_api.h""

int main() {

  // creating a TF_Graph
  TF_Graph* graph = TF_NewGraph();

  // creating a ""Variable"" operation
  TF_OperationDescription* opDesc = TF_NewOperation(graph, ""Variable"", ""w"");
  const long long dims[2] = {2, 2};
  TF_SetAttrShape(opDesc, ""shape"", dims, 2);
  TF_SetAttrType(opDesc, ""dtype"", TF_DOUBLE);

  TF_Status* status = TF_NewStatus();
  TF_Operation* w = TF_FinishOperation(opDesc, status);
  std::string finish_message = std::string(TF_Message(status));

  TF_Port w_port = {w, 0};
  int w_num_dims = TF_GraphGetTensorNumDims(graph, w_port, status);
  std::string num_dims_message = std::string(TF_Message(status));

  std::cout << ""finish_message: "" << finish_message << '\n';
  std::cout << ""w_num_dims: "" << w_num_dims << '\n';
  std::cout << ""num_dims_message: "" << num_dims_message << '\n';

  TF_DeleteGraph(graph);
  TF_DeleteStatus(status);

  return 0;
}
```

The program returns:

```
finish_message:
w_num_dims: -1
num_dims_message:
```

However, if I do the same for a ""Placeholder"" operation (by simply replacing 
""Variable"" with ""Placeholder), the returned number of dimensions is 2 (as expected).

It seems to me like a bug. It might be related to the previous issue that 
I reported (#5059), since the inability to determine the shape of a tensor at a particular node propagates through the graph.
"
5099,lookup_embedding returning 0 on missing index,"If I create a variable with the first dimension equal to k and I use it for looking up vectors with lookup_embeddings, if I input an invalid index (higher than k or lower than 0) the lookup just returns 0s.
In the code below I create a 10x2 embedding matrix e, so that each embedding is of dimension 2. i then lookup for a number that is the step number. This has no use, it's just for showing the issue. Obviously for the first 10 steps the value I fetch is a random embedding of dimension 2, after the tenth iteration, I start getting all 0s.

I think this should be documented. I'm not sure if it is a good default or not, probably it is, but at least there should be a warning or something similar telling that you are trying to access an index that is not there. It would be really useful for debugging. I would have saved few hours of work if I noticed this before.
### Environment info

Operating System: Ubuntu 16.04 64bit
Installed version of CUDA and cuDNN: cuda 8.0 cudnn 5.1
Tensorflow version: 0.10.0 compiled for cuda 8.0 (but it is not the issue)
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
import numpy as np
import tensorflow as tf

num_embedding = 10
embedding_size = 2

x = np.array([[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]])
y = np.array([0, 0, 0, 1, 1, 1, 1, 1, 1])

graph = tf.Graph()
with graph.as_default():
    x_p = tf.placeholder(tf.float32, shape=[None, 2])
    e_p = tf.placeholder(tf.int64, shape=[])

    y_p = tf.placeholder(tf.float32, shape=[None])
    y_pe = tf.expand_dims(y_p, 1)

    w = tf.Variable(tf.random_normal([2, 1]))
    b = tf.Variable(tf.random_normal([1]))
    e = tf.Variable(tf.random_normal([num_embedding, embedding_size]))

    embed = tf.nn.embedding_lookup(e, e_p)

    logits = tf.matmul(x_p, w) + b + tf.reduce_sum(embed)

    xe = tf.nn.sigmoid_cross_entropy_with_logits(logits, y_pe)
    loss = tf.reduce_mean(xe)

    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.cast(tf.nn.sigmoid(logits) > 0.5, tf.float32), y_pe), tf.float32))
    optimizer = tf.train.AdamOptimizer(0.5).minimize(loss)

    #Dangling nodes in the computational graph
    z_p = tf.placeholder(tf.float32, shape=[None, 2])
    u = tf.Variable(tf.random_normal([2, 1]))
    l = tf.matmul(z_p, u)

    saver = tf.train.Saver()

with tf.Session(graph=graph) as session:
    tf.initialize_all_variables().run()
    for step in range(201):
        if step % 100 == 0:
            save_path = saver.save(session, ""lc_{:04d}.ckpt"".format(step))
        _, loss_val, acc_val, embed_val = session.run(
            [optimizer, loss, accuracy, embed],
            feed_dict={x_p: x, e_p: step, y_p: y})
        print(""step {step} - loss: {loss_val:.6f}, acc: {acc_val:.4f}"".format(step=step, loss_val=loss_val, acc_val=acc_val))
        print(""embed_val: {}"".format(embed_val))

```
"
5098,"Boston.py tutorial runs but, no predictions produced","Hard to get going when Tutorial does not work as expected..  I'm sure it is simple but not for me yet!
NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
### Environment info

Operating System:
Ubuntu 16.05 Cudnn 5.1 Cuda 8 Nvidia 1070
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   
   I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcublas.so locally
   I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcudnn.so locally
   I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcufft.so locally
   I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcurand.so locally
   0.11.0rc0

Just running the Boston.py tutorial as is from the current repo unmodified:
It seems to train But just produces an estimator object and does not produce predictions, no errors (the warning are a bit of a concern.
this is the last train cycle and the report of the estimator object (see end).

```
: GeForce GTX 1070, pci bus id: 0000:01:00.0)
INFO:tensorflow:Restored model from /tmp/tmpq10r1l1a
INFO:tensorflow:Eval steps [0,1) for training step 5000.
INFO:tensorflow:Saving evaluation summary for 5000 step: loss = 21.8338
Loss: 21.833767
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column.       Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
Predictions: <generator object BaseEstimator._infer_model_as_iterable at 0x7f34042198e0>
```
"
5096,"Cannot run  ""bazel build tensorflow/examples/image_retraining:retrain""","Hi,

I've been having issues in building the [image retraining](https://www.tensorflow.org/versions/r0.11/how_tos/image_retraining/index.html#training-on-flowers) example. When I run bazel build tensorflow/examples/image_retraining:retrain I get the following error:

ERROR: $TF_HOME/tensorflow/core/BUILD:991:1: Executing genrule //tensorflow/core:version_info_gen failed: bash failed: error executing command /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; tensorflow/tools/git/gen_git_source.py --generate  ""bazel-out/host/genfiles/tensorflow/core/util/version_info.cc""': com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Traceback (most recent call last):
  File ""tensorflow/tools/git/gen_git_source.py"", line 221, in <module>
    generate(args.generate)
  File ""tensorflow/tools/git/gen_git_source.py"", line 152, in generate
    spec, head_symlink, _, dest_file = arglist
ValueError: need more than 1 value to unpack
Target //tensorflow/examples/image_retraining:retrain failed to build

The file gen_git_source.py exists but the file ""bazel-out/host/genfiles/tensorflow/core/util/version_info.cc"" does not seem to exist. 

Could this be happening because the generate() method inside gen_git_source expects multiple arguments which are not being provided?
## **Environment info**

Debian 4.6.4-1
## **What other attempted solutions have you tried?**

If I comment out the line 991 in core/BUILD, that doesn't help either. It gives an array of other errors.

I found another related error: https://github.com/tensorflow/tensorflow/issues/4701
"
5095,Error in build phase (iOS and Android sample),"Hi, 
   I followed all the instructions to build the iOS sample app but I encountered many errors like this: 

```
./tensorflow/core/framework/types.h:112:48: error: unknown type name 'DataType'
inline bool TypesCompatible(DataType expected, DataType actual) {
                                               ^
./tensorflow/core/framework/types.h:142:11: error: unknown type name 'DataType'
template <DataType VALUE>
```

and all in the same file: **types.h**

I dind't found anything on the web (or Stackoverflow) about these errors. 
### Environment info

Operating System: MacOS Sierra version 10.12 (16A323)

I used Docker quickstart terminal to run tensorflow and build the apps. 
Also with the Android sample app I have the same issues. 

I followed also this [blog](https://petewarden.com/2016/02/28/tensorflow-for-poets/) and all the instruction here in the github project, but I receive the same errors also opening the project with xCode Version 8.0 (8A218a). 

Could you please help me to understand how to solve the problem with the DataType? 

Thanks
Fabio
"
5092,GPU sync failed when use mesos and nvidia-docker for distributed training,"### Environment info

host os: centos7
host cuda: `/usr/local/cuda -> cuda-7.5`
docker images: [Dockerfile](https://github.com/chenbiaolong/tfmesos/blob/master/docker/Dockerfile)
total 4 GPUs, output of `curl -s slave-ip:3476/mesos/cli`

```
--attributes=gpus:eJzUlN9r2zAQx9_3V4x7tlL9sGTJb6mzldINwtbsZfThJEuLqWsXO00pIf_7zoEyAmFjEMaqJ0u6u-_39OG8g29xGJu-g3IHi6HZxgFKUFrOCgcZVKvFnPbFTMM-g0XcNiGOUH7fwWp1vaCbq-WK-UQrcMsMcscwFcikVYqZOmBSmCvjAtVa4mZNGRd13F5026ZukNPp576OLR3fxrHF9zeSH0L758mHlJosLFfzlJqu2bxAyemuup68Xj6NBwOcVsllyflsKnc5_yIoURv6xK5-bupJ1FIQ-a_aPtyPU3bVD1MfhbbkID70A9WW5hB02z_2bf_j5dDlsUr-qvKp6e6hVPu7DD7iQ9NSMNzEx5ZMZzAfwtSnojfLXoVk7swvpR18qCooN8NTzOCq7T3SC-SFcxl8XeMQa9rZKbcbN9htoDQ5acoKwzpCKaTlR91Jfuhvnx1RQY9ae2sYL0LOguOGuYSeKa2Tz9FH7sVJKuJsVPLfU8nPQ0W-JSo6cZnnKJg20TLpuWdJG8us1UIIZ4Wo_Ukq8q-piNNUrPoXs2Lf1Kwor40mWaYxchZ9on9ZEo5JlM4r5VQI-iQVdTYqf5iVM1FR_zeVu_27nwEAAP__G6_XAw --resources=gpus:{GPU-bffffc08-6a09-af7a-2833-6dcaf3a4369c,GPU-aba55b86-07c4-c906-9fab-355fb4abe0b1,GPU-5f0244a1-56e8-2b0b-f568-8851119811db,GPU-3b565496-5ae0-ebf8-6f19-2a29b3393cc5}
```
### tensorflow info

**In docker images**:
pip install from:

```
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl; python_version == '2.7'
>>> import tensorflow; print(tensorflow.__version__)
0.9.0
```
### details

I try to use **mesos** and **nvidia-docker** for tensorflow distributed training.The main idea of my code (code fork from [douban/tfmesos](https://github.com/douban/tfmesos))is mapping host GPUs into nvidia-docker and run distributed training scrip in docker environment.Most of my code is in [chenbiaolong/tfmesos/docker](https://github.com/chenbiaolong/tfmesos/tree/master/docker),you can see how I build my docker images in Dockerfile.

However,when I try to start training(use [nvidia_docker_run.sh](https://github.com/chenbiaolong/tfmesos/blob/master/nvidia_docker_run.sh)), I got errors:

```
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {node39.com:36921}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:42324, node39.com:36202, node39.com:58828}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:42324
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=3; total_num_replicas=3
I1020 09:07:12.418039 10 sync_replicas_optimizer.py:175] SyncReplicas enabled: replicas_to_aggregate=3; total_num_replicas=3
I1020 09:07:12.592327 10 mnist_replica.py:200] Chief Worker 0: Initializing session...
Traceback (most recent call last):
  File ""/mnt/example/mnist/mnist_replica.py"", line 247, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/mnt/example/mnist/mnist_replica.py"", line 211, in main
    config=sess_config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 684, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 176, in prepare_session
    sess.run(init_op, feed_dict=init_feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 372, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 636, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 708, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.AbortedError: RecvTensor expects a different device incarnation: 7338322613985075898 vs. 11093212615818549611. Your worker job was probably restarted. Check your worker job for the reason why it was restarted.
     [[Node: truncated_normal_S3 = _Recv[client_terminated=false, recv_device=""/job:ps/replica:0/task:0/cpu:0"", send_device=""/job:worker/replica:0/task:0/gpu:0"", send_device_incarnation=7338322613985075898, tensor_name=""edge_42_truncated_normal"", tensor_type=DT_FLOAT, _device=""/job:ps/replica:0/task:0/cpu:0""]()]]
E tensorflow/stream_executor/cuda/cuda_driver.cc:1140] could not synchronize on CUDA context: CUDA_ERROR_DEINITIALIZED :: No stack trace available
F tensorflow/core/common_runtime/gpu/gpu_util.cc:370] GPU sync failed
Aborted (core dumped)
Traceback (most recent call last):
  File ""/usr/local/bin/tfrun"", line 84, in <module>
    subprocess.check_call(cmd, shell=True)
  File ""/usr/lib/python2.7/subprocess.py"", line 540, in check_call
    raise CalledProcessError(retcode, cmd)
subprocess.CalledProcessError: Command 'python /mnt/example/mnist/mnist_replica.py --ps_hosts node39.com:36921 --worker_hosts node39.com:42324,node39.com:36202,node39.com:58828 --job_name worker --task_index 0' returned non-zero exit status 134

```

Although **nvidia_docker_run.sh** throw errors, mesos tasks(both job:ps and job:worker) seems work well,util they are killed by the framework. Run **nvidia-smi** can see 3GPUs are used(since I ran 3 workers and each work cost 1 GPU ). My training scrip is [mnist_replica.py](https://github.com/chenbiaolong/tfmesos/blob/master/docker/example/mnist/mnist_replica.py)
### logs

**Logs from tasks** is available [here](https://github.com/chenbiaolong/tfmesos/tree/master/docker/logs)

**mesos slave start**

```
mesos-slave  --master=$master_ip \
            --containerizers=docker,mesos \
            --hostname=slave-ip \
            --ip=slave-ip \
            --log_dir=/var/log/mesos/ \
            --work_dir=/var/lib/mesos/ \
            $(curl -s slave-ip:3476/mesos/cli)
```
"
5090,LSTM's forget gate biases,"Hi all,

I was looking into the LSTMCell code and I got confused:

[Line 505](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L505) show us the computations of new input and the gates: input, forget and output.

Both [line 517](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L517) and [line 520](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L517) show the addition of the forget gate (which is a scalar in this particular piece of code).

I got confused by this addition as it seems to be already done when we split the gate's values  in line 505 as mentioned before. Am I missing something or is this a second addition to the forget gate computations? If it is a second addition, wouldn't that change the computations?

By the way, that bias shouldn't be a vector instead of a single scalar?

Sorry if I am saying nonsense. but I'd like to double check that before saying it is a bug.
"
5089,word2vec_basic: matplotlib warning,"Running the example: `word2vec_basic` - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py

returns the following warning 

```
/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/matplotlib/collections.py:548: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison
  if self._edgecolors == 'face':
```

platforms

```
$ sw_vers
ProductName:    Mac OS X
ProductVersion: 10.12
BuildVersion:   16A323
$ python -c 'import tensorflow; print tensorflow.__version__'
0.11.0rc0
```
"
5087,C++ style concern of potential memory leak,"All the factories methods consisting a `static` pointer to heap allocated variable potentially cause memory leak, as the static in-function variables are allocated/disposed for the program life-time, but if the object is dynamically allocated on heap, the object itself is never disposed (only its pointer gets disposed).

For example, in [session_factory.cc:37](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/session_factory.cc#L37)

``` cpp
static mutex* get_session_factory_lock() {
  static mutex session_factory_lock;
  return &session_factory_lock;
}

typedef std::unordered_map<string, SessionFactory*> SessionFactories;
SessionFactories* session_factories() {
  static SessionFactories* factories = new SessionFactories;
  return factories;
}
```

Note that the `factories` is a _static pointer_, not a _pointer to a static object_. Since the object itself is not static, it will not be disposed and cause memory leak.

Suggested change:

``` cpp
static mutex* get_session_factory_lock() {
  static mutex session_factory_lock;
  return &session_factory_lock;
}

typedef std::unordered_map<string, SessionFactory*> SessionFactories;
SessionFactories* session_factories() {
  static SessionFactories factories = SessionFactories();
  return &factories;
}
```

One could easily write a small program and use `valgrind` to verify the memory leak. One example is [here](https://gist.github.com/a5b0d262e5f64f36b299003634493eca).
"
5086,Some workers doesn't exist when training in distributed mode,"We have tried distributed TensorFlow and it works for training. But sometimes only some workers will execute the code and exit after training. Sometimes all workers will exit finally with the same code. 

The code of distributed TensorFlow application is [here](https://github.com/tobegit3hub/deep_recommend_system/tree/master/distributed). Is that a bug or can anyone explain why?
### Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN:  Not installed.

TensorFlow version: 0.11.0rc0
"
5084,[feature request] Defining gradient functions of new Ops using custom python functions,"As explained in https://www.tensorflow.org/versions/r0.11/how_tos/adding_an_op/index.html, the gradient functions for new Ops have to use other tensorflow Ops. This is a big limitation for me. I want to use other python functions to implement the gradient function.

Btw, this is a good [answer](http://stackoverflow.com/questions/39048984/tensorflow-how-to-write-op-with-gradient-in-python) to define new Ops purely in python, but it still has the limitation that the gradient function has to use other existing tensorflow Ops.
"
5083,Strange memory usage with atrous_conv2d on 1D signal.,"I am trying to build my own wavenet to generate sound.  For this I need to perform a dilated convolution on a 1D signal.  To accomplish this I simply added dummy dimension to my input and filter.

```
def dilated_causal_conv1d(x, filter, dialation):
    padding = (tf.shape(filter)[0] - 1) * dialation
    x = tf.pad(x, ((0, 0), (padding, 0), (0, 0)))
    filter = tf.expand_dims(filter, 0)
    x = tf.expand_dims(x, 0)
    x = tf.nn.atrous_conv2d(x, filter, dialation, 'VALID')
    x = tf.squeeze(x, (0,))
    return x[:, padding:]
```

This appears to be working although I have not tried training it yet.  I have just managed to send a bunch of zeros through the network to make sure all of the shapes are in alignment.  When I ran it with an input of size (2, 16000) I got an error saying...

> W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.75GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.

I did manage to successfully run even with this message so I increased the batch size and ran it again and it still worked.  I kept doing this and I was able to get my batch size up to 64 and it still has not failed to execute.  This is strange to me since I only ever get these warning when I am on the verge of running out of memory.  I remember reading somewhere that atrous_conv2d can be very inefficient in terms of memory on 1D signals, however I have not been able to find that again or an explanation of why.

I am using the latest tensorflow on Ubuntu 16.04 with Cuda 8.  The size of the dilations range from 1 to 1024 in powers of 2 increments.
"
5082,Feature request - Check that QueueRunner enqueue ops use the correct queue,"The documentation for [`tf.train.QueueRunner.__init__`](https://www.tensorflow.org/versions/r0.11/api_docs/python/train.html#QueueRunner) states:

""The enqueue ops do not have to all be the same op, but it is expected that they all enqueue tensors in `queue`.""

Would it be possible for tensorflow to check that the given ops do in fact enqueue tensors in the correct queue, and throw an error if they do not?  I encountered a problem recently where I mistakenly passed the wrong queue to my `QueueRunner`, and as a result, the clean shutdown behavior described [here](https://www.tensorflow.org/versions/r0.11/how_tos/reading_data/index.html#creating-threads-to-prefetch-using-queuerunner-objects) wasn't working as expected.  Changing to the correct queue solved the problem.  This was definitely user error on my part, but it was a bit tricky to track this problem down, and it seems like the kind of thing that would be possible to check automatically.
"
5081,why there are so many different versions for models?,"I am confused about the versions of tensor flow models. There are at lease 3.

1) This one i can call as **main** folder.

https://github.com/tensorflow/models

2) Another one is inside of the main folder is called **slim** and it has instructions about how to use, such as **train_image_classifier.py** , which currently i am using. I do not need write more code, just input some parameters.

https://github.com/tensorflow/models/tree/master/slim

3) the second **slim** is in the folder blow, which provide different instructions as above **slim**.  It seems that I must write additional python code to make it work. And the **learning.py** under this slim folder is different from above **train_image_classifier.py**.

https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim
# 

Is there any necessity to provide so many branches or versions?  I guess they belong to different teams? Is there any consensus (internally) about which is the major one? This may not be a technical issue but a political issue.
"
5080,no such package '@lodash//': Error downloading...,"Trying to install Tensorflow and getting this issue:

chad@chad-GA-990XA-UD3:~/tensorflow$ ./configure
~/tensorflow ~/tensorflow
Please specify the location of python. [Default is /usr/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] n
No Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

/usr/local/lib/python2.7/dist-packages
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 5.1.5
Please specify the location where cuDNN 5.1.5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.

INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
..........
ERROR: /home/chad/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@lodash//': Error downloading from https://github.com/lodash/lodash/archive/3.8.0.tar.gz to /home/chad/.cache/bazel/_bazel_chad/e711407cb831141b1f7166a396931060/external/lodash: Error downloading https://github.com/lodash/lodash/archive/3.8.0.tar.gz to /home/chad/.cache/bazel/_bazel_chad/e711407cb831141b1f7166a396931060/external/lodash/3.8.0.tar.gz: Timed out connecting to https://github.com/lodash/lodash/archive/3.8.0.tar.gz : connect timed out and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: /home/chad/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@lodash//': Error downloading from https://github.com/lodash/lodash/archive/3.8.0.tar.gz to /home/chad/.cache/bazel/_bazel_chad/e711407cb831141b1f7166a396931060/external/lodash: Error downloading https://github.com/lodash/lodash/archive/3.8.0.tar.gz to /home/chad/.cache/bazel/_bazel_chad/e711407cb831141b1f7166a396931060/external/lodash/3.8.0.tar.gz: Timed out connecting to https://github.com/lodash/lodash/archive/3.8.0.tar.gz : connect timed out and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: Evaluation of query ""deps((//tensorflow/... union @bazel_tools//tools/jdk:toolchain))"" failed: errors were encountered while computing transitive closure.
chad@chad-GA-990XA-UD3:~/tensorflow$ 

Can anyone help?
"
5078,Tensorflow on Ubuntu 14 with cuda 8 and cudnn 5.1,"Hello I am trying to install tensorflow on ubuntu 14 with cuda 8 and cudnn 5.1. I followed the instructions here  https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#installing-from-sources
I was able to run the demo model but when I try to import tensorflow in python I get the following error

> > > import tensorflow
> > > I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally
> > > I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.1.5 locally
> > > I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally
> > > I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
> > > I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/**init**.py"", line 23, in <module>
> > >     from tensorflow.python import *
> > >   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/**init**.py"", line 63, in <module>
> > >     from tensorflow.core.framework.graph_pb2 import *
> > >   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 9, in <module>
> > >     from google.protobuf import symbol_database as _symbol_database
> > >   File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/symbol_database.py"", line 165, in <module>
> > >     _DEFAULT = SymbolDatabase(pool=descriptor_pool.Default())
> > > AttributeError: 'module' object has no attribute 'Default'
"
5073,export/00000000-tmp/export-?????-of-00001 is not in all_model_checkpoint_paths. Manually adding it.,"Now that I am using the 11rc, I am seeing a lot of this printed out:

```
INFO in saver: /output/4885/export/00000000-tmp/export-?????-of-00001 is not in all_model_checkpoint_paths. Manually adding it.
```

I believe when I call:

```
# Done once:
saver = tf_saver.Saver(sharded=True)
model_exporter = exporter.Exporter(saver)
model_exporter.init(...)
...
# Done each epoch / step:
model_exporter.export(export_path, tf.constant(i), sess)
```
### Environment info

Operating System:
Using nvidia Docker,

```
uname -a
Linux b2dcea60c730 3.13.0-57-generic #95-Ubuntu SMP Fri Jun 19 09:28:15 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
```

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
# ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
```
1. The commit hash (`git rev-parse HEAD`)
   `8915f0f8072c406ae3fe0dff888f51b4cad02d7d`
2. The output of `bazel version`

```
# bazel version
INFO: Reading 'startup' options from /root/.bazelrc: --batch
Extracting Bazel installation...
Build label: 0.3.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jul 29 09:09:52 2016 (1469783392)
Build timestamp: 1469783392
Build timestamp as int: 1469783392
```
"
5070,Upgrade Udacity class Docker image.,"Current Docker image uses TF 7.1.0, which is no longer showing on the online documentation page.
Need to:

1- Update to latest stable release.
2- Make sure the assignments still work.
3- Move from b.gcr.io to gcr.io
"
5069,symbol(s) not found for architecture amrv7 and armv64,"Using XCode 8 and OSX Sierra, the TensorFlow iOS build fails with:

```
Undefined symbols for architecture armv7:
  ""google::protobuf::Any::MergeFrom(google::protobuf::Any const&)"", referenced from:
      tensorflow::MetaGraphDef_MetaInfoDef::UnsafeMergeFrom(tensorflow::MetaGraphDef_MetaInfoDef const&) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      google::protobuf::internal::GenericTypeHandler<google::protobuf::Any>::Merge(google::protobuf::Any const&, google::protobuf::Any*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
  ""google::protobuf::internal::WireFormatLite::WriteBytesMaybeAliased(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, google::protobuf::io::CodedOutputStream*)"", referenced from:
      tensorflow::Event::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(event.pb.o)
      tensorflow::TaggedRunMetadata::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(event.pb.o)
      tensorflow::TensorProto::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(tensor.pb.o)
      tensorflow::Summary_Image::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(summary.pb.o)
      tensorflow::Summary_Audio::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(summary.pb.o)
      tensorflow::Summary_Value::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(summary.pb.o)
      tensorflow::AttrValue::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(attr_value.pb.o)
      ...
  ""vtable for google::protobuf::internal::MapFieldBase"", referenced from:
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2ftest_5flog_2eproto_impl() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::BenchmarkEntry() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::New(google::protobuf::Arena*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::CPUInfo() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::New(google::protobuf::Arena*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MachineConfiguration::_slow_mutable_cpu_info() in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::GenericTypeHandler<tensorflow::BenchmarkEntry>::New(google::protobuf::Arena*) in libtensorflow-core-armv7.a(test_log.pb.o)
      ...
  NOTE: a missing vtable usually means the first non-inline virtual member function has no definition.
  ""typeinfo for google::protobuf::Any"", referenced from:
      google::protobuf::Any* google::protobuf::Arena::CreateMaybeMessage<google::protobuf::Any>(google::protobuf::Arena*, ...) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MetaGraphDef_MetaInfoDef::UnsafeMergeFrom(tensorflow::MetaGraphDef_MetaInfoDef const&) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::MetaGraphDef_MetaInfoDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
  ""google::protobuf::internal::InitEmptyString()"", referenced from:
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2ftest_5flog_2eproto_impl() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fsaved_5ftensor_5fslice_2eproto_impl() in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fmemmapped_5ffile_5fsystem_2eproto_impl() in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fevent_2eproto_impl() in libtensorflow-core-armv7.a(event.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto_impl() in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto_impl() in libtensorflow-core-armv7.a(saver.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2fqueue_5frunner_2eproto_impl() in libtensorflow-core-armv7.a(queue_runner.pb.o)
      ...
  ""google::protobuf::io::CodedOutputStream::default_serialization_deterministic_"", referenced from:
      tensorflow::BenchmarkEntry::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::JobDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      tensorflow::MetaGraphDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::SignatureDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::ConfigProto::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(config.pb.o)
      tensorflow::NodeDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(node_def.pb.o)
      ...
  ""google::protobuf::internal::MapFieldBase::SpaceUsedExcludingSelfNoLock() const"", referenced from:
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue> in libtensorflow-core-armv7.a(test_log.pb.o)
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long> in libtensorflow-core-armv7.a(test_log.pb.o)
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::CollectionDef> in libtensorflow-core-armv7.a(meta_graph.pb.o)
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::SignatureDef> in libtensorflow-core-armv7.a(meta_graph.pb.o)
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::TensorInfo> in libtensorflow-core-armv7.a(meta_graph.pb.o)
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int> in libtensorflow-core-armv7.a(config.pb.o)
      ...
  ""google::protobuf::internal::MapFieldBase::SyncRepeatedFieldWithMapNoLock() const"", referenced from:
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue> in libtensorflow-core-armv7.a(test_log.pb.o)
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long> in libtensorflow-core-armv7.a(test_log.pb.o)
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::CollectionDef> in libtensorflow-core-armv7.a(meta_graph.pb.o)
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::SignatureDef> in libtensorflow-core-armv7.a(meta_graph.pb.o)
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::TensorInfo> in libtensorflow-core-armv7.a(meta_graph.pb.o)
      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int> in libtensorflow-core-armv7.a(config.pb.o)
      ...
  ""google::protobuf::Any::Any()"", referenced from:
      google::protobuf::Any* google::protobuf::Arena::CreateMaybeMessage<google::protobuf::Any>(google::protobuf::Arena*, ...) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MetaGraphDef_MetaInfoDef::UnsafeMergeFrom(tensorflow::MetaGraphDef_MetaInfoDef const&) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::MetaGraphDef_MetaInfoDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
  ""google::protobuf::Any_default_instance_"", referenced from:
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto_impl() in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::MetaGraphDef_MetaInfoDef::UnsafeMergeFrom(tensorflow::MetaGraphDef_MetaInfoDef const&) in libtensorflow-core-armv7.a(meta_graph.pb.o)
  ""google::protobuf::Any::ByteSizeLong() const"", referenced from:
      tensorflow::MachineConfiguration::ByteSizeLong() const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MetaGraphDef_MetaInfoDef::ByteSizeLong() const in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::CollectionDef_AnyList::ByteSizeLong() const in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::CollectionDef::ByteSizeLong() const in libtensorflow-core-armv7.a(meta_graph.pb.o)
  ""google::protobuf::protobuf_AddDesc_google_2fprotobuf_2fany_2eproto()"", referenced from:
      tensorflow::protobuf_AddDesc_tensorflow_2fcore_2futil_2ftest_5flog_2eproto_impl() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto_impl() in libtensorflow-core-armv7.a(meta_graph.pb.o)
  ""google::protobuf::io::CodedInputStream::ReadLengthAndPushLimit()"", referenced from:
      tensorflow::BenchmarkEntries::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MachineConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::SavedSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      tensorflow::SavedTensorSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      tensorflow::MemmappedFileSystemDirectory::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)
      tensorflow::ClusterDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      tensorflow::MetaGraphDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      ...
  ""google::protobuf::internal::RepeatedPtrFieldBase::InternalExtend(int)"", referenced from:
      tensorflow::BenchmarkEntries::UnsafeMergeFrom(tensorflow::BenchmarkEntries const&) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MachineConfiguration::UnsafeMergeFrom(tensorflow::MachineConfiguration const&) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::SavedSliceMeta::UnsafeMergeFrom(tensorflow::SavedSliceMeta const&) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      tensorflow::SavedTensorSliceMeta::UnsafeMergeFrom(tensorflow::SavedTensorSliceMeta const&) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      tensorflow::MemmappedFileSystemDirectory::UnsafeMergeFrom(tensorflow::MemmappedFileSystemDirectory const&) in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)
      tensorflow::ClusterDef::UnsafeMergeFrom(tensorflow::ClusterDef const&) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      tensorflow::QueueRunnerDef::UnsafeMergeFrom(tensorflow::QueueRunnerDef const&) in libtensorflow-core-armv7.a(queue_runner.pb.o)
      ...
  ""google::protobuf::io::CodedInputStream::CheckEntireMessageConsumedAndPopLimit(int)"", referenced from:
      tensorflow::BenchmarkEntries::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MachineConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::SavedSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      tensorflow::SavedTensorSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      tensorflow::MemmappedFileSystemDirectory::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)
      tensorflow::ClusterDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      tensorflow::MetaGraphDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      ...
  ""google::protobuf::io::CodedInputStream::ReadVarint64Fallback()"", referenced from:
      tensorflow::BenchmarkEntry::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CommitId::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MemoryInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::AvailableDeviceInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::TestResults::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)3, 0>::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      ...
  ""google::protobuf::io::CodedInputStream::ReadVarintSizeAsIntFallback()"", referenced from:
      tensorflow::BenchmarkEntry::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MachineConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::TestResults::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::Parser<google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>, google::protobuf::Map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue> >::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::SavedSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      ...
  ""google::protobuf::internal::empty_string_once_init_"", referenced from:
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2ftest_5flog_2eproto_impl() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fsaved_5ftensor_5fslice_2eproto_impl() in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fmemmapped_5ffile_5fsystem_2eproto_impl() in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fevent_2eproto_impl() in libtensorflow-core-armv7.a(event.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto_impl() in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto_impl() in libtensorflow-core-armv7.a(saver.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2fqueue_5frunner_2eproto_impl() in libtensorflow-core-armv7.a(queue_runner.pb.o)
      ...
  ""google::protobuf::io::CodedInputStream::IncrementRecursionDepthAndPushLimit(int)"", referenced from:
      tensorflow::BenchmarkEntry::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MachineConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::TestResults::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::Parser<google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>, google::protobuf::Map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue> >::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::SavedSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      ...
  ""google::protobuf::internal::MapFieldBase::~MapFieldBase()"", referenced from:
      tensorflow::BenchmarkEntry::~BenchmarkEntry() in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::~MapField() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::~CPUInfo() in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)3, 0>::~MapField() in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::~MapField() in libtensorflow-core-armv7.a(test_log.pb.o)
      non-virtual thunk to google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::~MapField() in libtensorflow-core-armv7.a(test_log.pb.o)
      non-virtual thunk to google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::~MapField() in libtensorflow-core-armv7.a(test_log.pb.o)
      ...
  ""google::protobuf::io::CodedOutputStream::WriteVarint32SlowPath(unsigned int)"", referenced from:
      tensorflow::QueueRunnerDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(queue_runner.pb.o)
      tensorflow::CollectionDef_Int64List::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::CollectionDef_FloatList::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::VersionDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(versions.pb.o)
      tensorflow::SaveSliceInfoDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(variable.pb.o)
      tensorflow::TensorProto::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(tensor.pb.o)
      tensorflow::HistogramProto::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(summary.pb.o)
      ...
  ""google::protobuf::io::CodedOutputStream::WriteStringWithSizeToArray(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned char*)"", referenced from:
      tensorflow::EntryValue::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BuildConfiguration::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CommitId::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::GPUInfo::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::PlatformInfo::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      ...
  ""google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, google::protobuf::io::CodedOutputStream*)"", referenced from:
      tensorflow::EntryValue::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BuildConfiguration::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CommitId::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::GPUInfo::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::PlatformInfo::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      ...
  ""google::protobuf::Arena::AddListNode(void*, void (*)(void*))"", referenced from:
      void google::protobuf::Arena::Own<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >*) in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::RepeatedPtrField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >::Add() in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::Any* google::protobuf::Arena::CreateMaybeMessage<google::protobuf::Any>(google::protobuf::Arena*, ...) in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::SyncRepeatedFieldWithMapNoLock() const in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::Map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue>::Init() in libtensorflow-core-armv7.a(test_log.pb.o)
      void google::protobuf::Arena::Own<google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0> >(google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>*) in libtensorflow-core-armv7.a(test_log.pb.o)
      void google::protobuf::Arena::OwnDestructor<google::protobuf::internal::Mutex>(google::protobuf::internal::Mutex*) in libtensorflow-core-armv7.a(test_log.pb.o)
      ...
  ""google::protobuf::internal::WireFormatLite::VerifyUtf8String(char const*, int, google::protobuf::internal::WireFormatLite::Operation, char const*)"", referenced from:
      tensorflow::EntryValue::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::EntryValue::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::EntryValue::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BuildConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      ...
  ""google::protobuf::protobuf_InitDefaults_google_2fprotobuf_2fany_2eproto()"", referenced from:
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2ftest_5flog_2eproto_impl() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto_impl() in libtensorflow-core-armv7.a(meta_graph.pb.o)
  ""google::protobuf::internal::MergeFromFail(char const*, int)"", referenced from:
      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)
      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(event.pb.o)
      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(saver.pb.o)
      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(queue_runner.pb.o)
      ...
  ""google::protobuf::internal::GeneratedMessageReflection::GeneratedMessageReflection(google::protobuf::Descriptor const*, google::protobuf::Message const*, int const*, int, int, int, google::protobuf::DescriptorPool const*, google::protobuf::MessageFactory*, int, int)"", referenced from:
      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::CollectionDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::SignatureDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::TensorInfo, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(config.pb.o)
      ...
  ""google::protobuf::internal::MapFieldBase::InitMetadataOnce() const"", referenced from:
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)3, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapField<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, (google::protobuf::internal::WireFormatLite::FieldType)5, (google::protobuf::internal::WireFormatLite::FieldType)9, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::CollectionDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(meta_graph.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::SignatureDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(meta_graph.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::TensorInfo, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(meta_graph.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)5, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(config.pb.o)
      ...
  ""google::protobuf::internal::RegisterMapEntryDefaultInstance(google::protobuf::MessageLite*)"", referenced from:
      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::CollectionDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::SignatureDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::TensorInfo, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(config.pb.o)
      ...
  ""google::protobuf::io::CodedInputStream::ReadTagFallback(unsigned int)"", referenced from:
      tensorflow::EntryValue::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntries::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BuildConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CommitId::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MemoryInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      ...
  ""google::protobuf::io::CodedInputStream::ReadVarint32Fallback(unsigned int)"", referenced from:
      tensorflow::SavedSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      tensorflow::LogMessage::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(event.pb.o)
      tensorflow::SessionLog::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(event.pb.o)
      tensorflow::ServerDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      google::protobuf::internal::MapEntryLite<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, (google::protobuf::internal::WireFormatLite::FieldType)5, (google::protobuf::internal::WireFormatLite::FieldType)9, 0>::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      google::protobuf::internal::MapEntryLite<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, (google::protobuf::internal::WireFormatLite::FieldType)5, (google::protobuf::internal::WireFormatLite::FieldType)9, 0>::Parser<google::protobuf::internal::MapField<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, (google::protobuf::internal::WireFormatLite::FieldType)5, (google::protobuf::internal::WireFormatLite::FieldType)9, 0>, google::protobuf::Map<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      tensorflow::SaverDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saver.pb.o)
      ...
  ""google::protobuf::Any::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*)"", referenced from:
      tensorflow::MachineConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MetaGraphDef_MetaInfoDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::CollectionDef_AnyList::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
  ""google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(google::protobuf::Descriptor const*, google::protobuf::Message const*, int const*, int, int, int, void const*, int, int, int, int)"", referenced from:
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2futil_2ftest_5flog_2eproto() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2futil_2fevent_2eproto() in libtensorflow-core-armv7.a(event.pb.o)
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto() in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fframework_2ftensor_5fslice_2eproto() in libtensorflow-core-armv7.a(tensor_slice.pb.o)
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fsummary_2eproto() in libtensorflow-core-armv7.a(summary.pb.o)
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto() in libtensorflow-core-armv7.a(attr_value.pb.o)
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fexample_2ffeature_2eproto() in libtensorflow-core-armv7.a(feature.pb.o)
      ...
  ""google::protobuf::Arena::AllocateAligned(std::type_info const*, unsigned long)"", referenced from:
      tensorflow::EntryValue::New(google::protobuf::Arena*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::New(google::protobuf::Arena*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::ByteSizeLong() const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntries::New(google::protobuf::Arena*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BuildConfiguration::New(google::protobuf::Arena*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      ...
  ""google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(google::protobuf::Descriptor const*, google::protobuf::Message const*, int const*, int, int, int, int, int, int)"", referenced from:
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2futil_2ftest_5flog_2eproto() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2futil_2fsaved_5ftensor_5fslice_2eproto() in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2futil_2fmemmapped_5ffile_5fsystem_2eproto() in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2futil_2fevent_2eproto() in libtensorflow-core-armv7.a(event.pb.o)
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto() in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto() in libtensorflow-core-armv7.a(saver.pb.o)
      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fqueue_5frunner_2eproto() in libtensorflow-core-armv7.a(queue_runner.pb.o)
      ...
  ""google::protobuf::io::CodedInputStream::BytesUntilTotalBytesLimit() const"", referenced from:
      tensorflow::CollectionDef_FloatList::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)
      tensorflow::TensorProto::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(tensor.pb.o)
      tensorflow::HistogramProto::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(summary.pb.o)
      tensorflow::AttrValue_ListValue::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(attr_value.pb.o)
      tensorflow::FloatList::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(feature.pb.o)
  ""google::protobuf::internal::MapFieldBase::SetMapDirty()"", referenced from:
      tensorflow::BenchmarkEntry::UnsafeMergeFrom(tensorflow::BenchmarkEntry const&) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::MergeFrom(google::protobuf::internal::MapFieldLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0> const&) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::UnsafeMergeFrom(tensorflow::CPUInfo const&) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)3, 0>::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)
      ...
  ""google::protobuf::internal::MapFieldBase::SyncMapWithRepeatedField() const"", referenced from:
      tensorflow::benchmark_model::InitializeSession(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::unique_ptr<tensorflow::Session, std::__1::default_delete<tensorflow::Session> >*, std::__1::unique_ptr<tensorflow::StatSummarizer, std::__1::default_delete<tensorflow::StatSummarizer> >*) in benchmark_model.o
      tensorflow::BenchmarkEntry::UnsafeMergeFrom(tensorflow::BenchmarkEntry const&) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::BenchmarkEntry::ByteSizeLong() const in libtensorflow-core-armv7.a(test_log.pb.o)
      ...
  ""typeinfo for google::protobuf::internal::MapFieldBase"", referenced from:
      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue> in libtensorflow-core-armv7.a(test_log.pb.o)
      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long> in libtensorflow-core-armv7.a(test_log.pb.o)
      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > in libtensorflow-core-armv7.a(tensorflow_server.pb.o)
      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::CollectionDef> in libtensorflow-core-armv7.a(meta_graph.pb.o)
      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::SignatureDef> in libtensorflow-core-armv7.a(meta_graph.pb.o)
      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::TensorInfo> in libtensorflow-core-armv7.a(meta_graph.pb.o)
      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int> in libtensorflow-core-armv7.a(config.pb.o)
      ...
  ""google::protobuf::io::CodedInputStream::DecrementRecursionDepthAndPopLimit(int)"", referenced from:
      tensorflow::BenchmarkEntry::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::CPUInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::MachineConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::TestResults::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::Parser<google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>, google::protobuf::Map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue> >::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::SavedSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)
      ...
  ""google::protobuf::internal::fixed_address_empty_string"", referenced from:
      tensorflow::TestReporter::Initialize() in reporter.o
      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2ftest_5flog_2eproto_impl() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::EntryValue::UnsafeMergeFrom(tensorflow::EntryValue const&) in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::EntryValue::~EntryValue() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::EntryValue::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)
      tensorflow::EntryValue::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)
```

Anyone run into this issue?
"
5068,"Restoring a tensorflow model for finetuning, with âslim.learning.trainâ","with slim.learning.train (TF 0.11), I would like to restore a model from a checkpoint and continue the training. The model had a successful training session, and I would like to fine tune it. However, when I do that, TF crash with an error 
`Init operations did not make model ready.`

I do the training with:

```
tf.contrib.slim.learning.train(
    train_op,
    train_dir,
    log_every_n_steps=FLAGS.log_every_n_steps,
    graph=g,
    global_step=model.global_step,
    number_of_steps=FLAGS.number_of_steps,
    init_fn=model.init_fn,
    saver=model.saver,
    session_config=session_config)
```

I tried 3 alternatives:
### 1

Following [this doc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/session_manager.py#L183)

```
model.init_fn = None
```
### 2

```
with g.as_default():
    model_path = tf.train.latest_checkpoint(train_dir)
    if model_path:
        def restore_fn(sess):
            tf.logging.info(
                ""Restoring SA&T variables from checkpoint file %s"",
                restore_fn.model_path)
            model.saver.restore(sess, restore_fn.model_path)
        restore_fn.model_path = model_path
        model.init_fn = restore_fn
    else:
        model.init_fn = None
```
### 3

Following [slim doc](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)

```
with g.as_default():
    model_path = tf.train.latest_checkpoint(train_dir)
    if model_path:
        variables_to_restore = tf.contrib.slim.get_variables_to_restore()
        model.init_fn = tensorflow.contrib.framework.assign_from_checkpoint_fn(
            model_path, variables_to_restore)
    else:
        model.init_fn = None
```
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

http://stackoverflow.com/questions/38499136/tensorflow-learn-initialize-variables
### Environment info

Operating System:
Linux

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. A link to the pip package you installed:
   https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc0-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
   I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
   I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
   I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
   0.11.0rc0
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).

[alternative1.txt](https://github.com/tensorflow/tensorflow/files/538795/alternative1.txt)
[alternative2.txt](https://github.com/tensorflow/tensorflow/files/538797/alternative2.txt)
[alternative3.txt](https://github.com/tensorflow/tensorflow/files/538796/alternative3.txt)
"
5067,Does TensorFlow support Intel PHI?,"Intel is driving Caffe to support MKL. Any plans to make tensorflow support Intel PHI also?
"
5066,Multiple GPU Memory Being Allocated for single device script,"I am unable to run a TF script on a single GPU. Both of my GTX 1080's memory are being fully absorbed by Tensorflow when the model is initialized, but only one of the GPU is being used for computations (based on what I'm seeing in nvidia-smi).

Because both GPUs memory are fully occupied, I cannot run two models at once.

<img width=""572"" alt=""screen shot 2016-10-18 at 11 11 38 pm"" src=""https://cloud.githubusercontent.com/assets/4795661/19507497/4293ff2e-9588-11e6-92dd-4b79b86eaa9e.png"">
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

http://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory
https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/jw4FtKOivZE
### Environment info

Operating System:
Ubuntu 16.04

Installed version of CUDA and cuDNN: 
Cuda Toolkit 8.0, cuDNN 5.1.5

```
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcudnn.so.5.1.5 locally
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcurand.so.8.0 locally
0.11.0rc0
```

```
Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110
```
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

I'm using the example from here: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/convolutional_network.py
### What other attempted solutions have you tried?

CUDA_VISIBLE_DEVICES

and

config = tf.ConfigProto(
    device_count = {'GPU': 1}
)

sess = tf.Session(config=config)

and 

with tf.device('/gpu:0'):
 ...
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
5065,How to export the wide and deep model and use java client to request,
5064,Urgently need the pip installation package with ubuntu14/04/05 & cuda8 & cudnn5(bithpy27 an py34)),"In some country , it cannot download some package like bazel or protobuff etc, so install from source is impossible.
### Environment info

Operating System:
ubuntu14/04/05

Installed version of CUDA and cuDNN: 
cuda8 & cudnn5
"
5061,Feature Request - expose protobuf on syntaxnet as 'first class' interface,"Clearly syntaxnet will parse sentences out of the box to a terminal with / without CoNLL format.

echo I saw the dude with glasses|./syntaxnet/demo.sh
<img width=""298"" alt=""screen shot 2016-10-18 at 20 10 02"" src=""https://cloud.githubusercontent.com/assets/289994/19502649/725582b6-957c-11e6-8c94-e2230f6146ec.png"">

I'm using a tensorflow in docker container - and now I want to interface to it from some other software via an api. I'd like to use some server side swift code. 

I spent time looking at following (parsey flask wrapper) 
https://github.com/JoshData/parsey-mcparseface-server

(parsey django wrapper) 
https://github.com/dan-nadler/ParseyAPI

and https://github.com/dmansfield/parsey-mcparseface-api

The last repo exposes parsey via protobufs - 
https://github.com/dmansfield/parsey-mcparseface-api/blob/160f3cbb5f96eff5fb8b73624228ceb7c8208b71/parsey_api/parsey_api.proto

using tensorflow serving but he had to fork the project and patch the files. 

While there's been help from other engineers to assist to get project working
https://github.com/dmansfield/parsey-mcparseface-api/issues/1

I suggest supporting protobufs out of the box as an api
"
5059,Problems with TF_GraphImportGraphDef while loading certain types of graphs,"I have experienced problems when using TF_GraphImportGraphDef to import
certain graphs with gradients from Python, and I suspect the function might have a bug.

The simplest example of a problematic graph is:

``` python
x = tf.placeholder(tf.float64, [1, 2], name=""x"")
y = tf.placeholder(tf.float64, [1, 2], name=""y"")
z = tf.add(x, y, name=""z"")

tf.gradients(z, [x, y])
```

When running TF_GraphImportGraphDef, I get the following error message:
_Cannot infer multiple unknown dimensions in shape [?,?]_. 

Surprisingly, if I change the shape of one of the inputs ([1, 2] => [None, 2]):

``` python
x = tf.placeholder(tf.float64, [None, 2], name=""x"")
y = tf.placeholder(tf.float64, [1, 2], name=""y"")
z = tf.add(x, y, name=""z"")

tf.gradients(z, [x, y])
```

everything works fine and I can successfully load the graph. 
I don't see a reason why I am not allowed to load the graph in the first example.

I've made all the necessary checks and I am sure the graphs I create in Python 
are correct (I can run them, and I get correct values for outputs and gradients).
Also, when I run the second graph (that was created in Python, and that I am able to load) 
using C API, everything works fine.
"
5056,Protobuf incompatible with google-cloud-python?,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
- [Tensoflow Installation from source README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#installing-from-sources)
- [Old google-cloud-sdk question of code.google.com](https://code.google.com/p/google-cloud-sdk/issues/detail?id=24)
### Environment info

Ubuntu 14.04
### Installed version of CUDA and cuDNN:

Cuda Toolkit 7.5 and cuDNN v5
### pip packages installed from source, provide

https://google-cloud-python.readthedocs.io/en/stable/#

```
$ git clone git://github.com/GoogleCloudPlatform/google-cloud-python.git
$ cd google-cloud-python
$ python setup.py install
```

Tensorflow source
1. The commit hash (`git rev-parse HEAD`): 

```
2ed280b4f553e6aa1c7fe0bb41d52456a0ae452c
```
1. The output of `bazel version`

```
Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110
```
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

Trying to import google.cloud

```
python -c ""from google.cloud import logging as gclogging;""
```

results in the following error

```
ImportError: No module named cloud
```
### What other attempted solutions have you tried?

Whenever I install google protobuf using either of the following commands

```
sudo pip install /tmp/tensorflow_pkg/tensorflow-0.11.0rc0-py2-none-any.whl
# OR
pip install dist/<wheel file name>
```

I can no longer import google.cloud. 
### Logs or other output that would be helpful

I'm aware of the fact that you can build TensorFlow with Google Cloud Platform support comes with integration when running  `./configure`. Howoever it's not clear how to integrate with Google Stackdriver.
"
5050,tf.Session.reset crashes after starting the chief queue runner,"Code to reproduce:

``` python
import tempfile
import time

import tensorflow as tf


def main(_):
    sync = True
    start_chief_queue_runners = True

    is_chief = True
    server = tf.train.Server.create_local_server()
    logdir = tempfile.mkdtemp()

    graph = tf.Graph()

    device_setter = tf.train.replica_device_setter(worker_device='/job:worker/task:0')
    with graph.as_default(), tf.device(device_setter):
        # Build loss op.
        x = tf.random_normal([100, 128])
        y = tf.Variable(initial_value=tf.random_normal([100, 128]))
        global_step = tf.Variable(0)
        loss = tf.reduce_sum(tf.squared_difference(x, y), name='loss')

        # Set up optimizer.
        optim = tf.train.GradientDescentOptimizer(0.001)
        if sync:
            optim = tf.train.SyncReplicasOptimizerV2(optim, 1)
        minimize = optim.minimize(loss, global_step=global_step, name='train_op')

        ready_for_local_init = None
        local_step_init = None
        if sync:
            init_tokens = optim.get_init_tokens_op()
            chief_qr = optim.get_chief_queue_runner()
            ready_for_local_init = optim.ready_for_local_init_op
            local_step_init = optim.local_step_init_op
        init_op = tf.initialize_all_variables()

    sv = tf.train.Supervisor(graph=graph,
                             is_chief=is_chief,
                             ready_for_local_init_op=ready_for_local_init,
                             init_op=init_op,
                             local_init_op=local_step_init,
                             recovery_wait_secs=1,
                             global_step=global_step,
                             logdir=logdir)

    config = server.server_def.default_session_config
    sess = sv.prepare_or_wait_for_session(server.target, config=config,
                                          start_standard_services=False)

    with sess.as_default():
        if is_chief and sync and start_chief_queue_runners:
            sv.start_queue_runners(sess, [chief_qr])
            init_tokens.run()

    # Wait for the queue runner to start.
    time.sleep(2)

    tf.Session.reset(server.target)

    time.sleep(1)
    print('restarted session')

    server.join()


if __name__ == '__main__':
    tf.app.run(main)
```

What I see:

```
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job local -> {0 -> localhost:33954}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:211] Started server with target: grpc://localhost:33954
I tensorflow/core/distributed_runtime/master_session.cc:869] Start master session 3d7c628e8fd8d707 with config: 

*** Error in `/home/daeyun/anaconda3/bin/python': double free or corruption (fasttop): 0x00007f2000087ca0 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x77725)[0x7f20f0d35725]
/lib/x86_64-linux-gnu/libc.so.6(+0x7ff4a)[0x7f20f0d3df4a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f20f0d41abc]
/home/daeyun/anaconda3//lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0x11ae503)[0x7f20c471b503]
/home/daeyun/anaconda3//lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow26ConditionalAccumulatorBase16TryAttemptLockedEPSt6vectorINS0_7CleanUpESaIS2_EE+0x6c)[0x7f20c471be2c]
/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow26ConditionalAccumulatorBase13FlushUnlockedEv+0x7b)[0x7f20c471c0fb]
/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow26ConditionalAccumulatorBase6CancelEPNS_19CancellationManagerEx+0xde)[0x7f20c471c33e]
/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow19CancellationManager11StartCancelEv+0x28b)[0x7f20c59a5bab]
/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0xc51a16)[0x7f20c41bea16]
/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0xc5d743)[0x7f20c41ca743]
/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0xc62704)[0x7f20c41cf704]
/usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80)[0x7f20c3045c80]
/lib/x86_64-linux-gnu/libpthread.so.0(+0x76fa)[0x7f20f179e6fa]
/lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7f20f0dc4b5d]
```

This seems to happen after `SyncReplicasOptimizerV2`'s chief queue runner starts.
This does not happen when `start_chief_queue_runners` or `sync` variable is `False`. 

System info: Nightly build (Python 3.4), Anaconda, Ubuntu 16.04
"
5048,Arbitrary sized inputs for FCNs are slow.,"Hi,

OS and version: TF r0.11.0rc0, Linux 64bit, cudnn-7.5-v5.1

I am using TF-Slim and a FCN-style architecture based on ResNets. I experience extremely slow training times: 5-10x slower compared to an equivalent Caffe implementation.

I train fully-convolutionally, and my images are of arbitrary sizes and aspect ratios. The training code uses FIFOQueue and preloads data in a separate thread. I use batch_size=1 as all images are of different sizes.

If I feed dummy random numpy tensors of fixed size, it works very fast. I tried to generate input tensors of 10 predefined sizes and fed them sequentially, the first 10 iterations were slow, but then it speeds back up. Looks like it does some extra work for each input size. I only used Caffe before, and there it was possible to resize all tensors per batch efficiently, somehow.

Am I missing some simple trick or is it a bug?
"
5046,Multi-core not being utilized?,"I have a 8 vCPUs 30GB Debian instance on the Google Cloud Platform, running the TensorFlow implementation of the WaveNet from https://github.com/ibab/tensorflow-wavenet  

I noticed that CPU usage stays around 13%, as if only one of the 8 vCPUs is being used. I have found this issue https://github.com/tensorflow/tensorflow/issues/583 which seems to indicate that such problem should have been fixed. 

Any advice on what I need to do in order for all of the vCPUs on my instance to be full utilized in such a case? Thanks!
"
5043,Sudden OOM error with Tensorflow embedding_attention_seq2seq after successful runs,"I've already found plenty of issues on the particular topic of memory issues with TensorFlow [here](https://github.com/tensorflow/tensorflow/issues/352), [here](https://github.com/tensorflow/tensorflow/issues/136), [here](https://github.com/tensorflow/tensorflow/issues/138), [here](https://github.com/tensorflow/tensorflow/issues/1355) and [here](https://github.com/tensorflow/tensorflow/issues/492) and we are still awaiting fixes for the same.

I have implemented the RNN embedding Encoder Attention Decoder model as described by this [tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/seq2seq/index.html) using a custom language pair.

I **successfully implemented** it and the training started after I determined the maximum parameter values of:

Size of NN: 340
Batch Size: 32
Total Vocabulary:
English: 50000 words
Tamil: 40000 words

and trained on it quite a few times.

```
Preparing WMT data in /home/hans/Documents/MAC/SUCCESSFUL MODELS/ADD/Tensorflow with Eng and Tam Word2Vec/
Creating 3 layers of 325 units.
Reading model parameters from /home/hans/Documents/MAC/SUCCESSFUL MODELS/ADD/Tensorflow with Eng and Tam Word2Vec/checkpoints/translate.ckpt-9500
Reading development and training data (limit: 0).
  reading data line 100000
   Word2Vec English Encoding Successful!
   Word2Vec Tamil Encoding Successful!
global step 10000 learning rate 0.5000 step-time 1.56 perplexity 33.47
  eval: bucket 0 perplexity 10.47
  eval: bucket 1 perplexity 14.57
  eval: bucket 2 perplexity 20.74
  eval: bucket 3 perplexity 35.82
  eval: bucket 4 perplexity 42.77

.......................................
.......................................
.......................................

global step 109000 learning rate 0.4522 step-time 1.04 perplexity 3.79
  eval: bucket 0 perplexity 20.10
  eval: bucket 1 perplexity 18.52
  eval: bucket 2 perplexity 17.32
  eval: bucket 3 perplexity 28.79
  eval: bucket 4 perplexity 18.48
  eval: bucket 5 perplexity 17.07
  eval: bucket 6 perplexity 15.35
  eval: bucket 7 perplexity 29.22
  eval: bucket 8 perplexity 26.05
  eval: bucket 9 perplexity 28.58

```

I'm using Ubuntu 16.04 LTS with a 2GB Nvidia 650M GeForce card with:

```
nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2015 NVIDIA Corporation
Built on Tue_Aug_11_14:27:32_CDT_2015
Cuda compilation tools, release 7.5, V7.5.17
```

```
root@hans-Lenovo-IdeaPad-Y500:/opt/cuda/lib64# ls
libcudnn.so  libcudnn.so.4  libcudnn.so.4.0.7  libcudnn_static.a
```

```
root@hans-Lenovo-IdeaPad-Y500:/opt/cuda/lib64# pip list | grep tensorflow
tensorflow (0.8.0)

```

```
root@hans-Lenovo-IdeaPad-Y500:/opt/cuda/lib64# ls -l /usr/lib/x86_64-linux-gnu/libcud*
-rw-r--r-- 1 root root   322936 Sep 19  2015 /usr/lib/x86_64-linux-gnu/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Mar 30  2016 /usr/lib/x86_64-linux-gnu/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Mar 30  2016 /usr/lib/x86_64-linux-gnu/libcudart.so.7.5 -> libcudart.so.7.5.18
-rw-r--r-- 1 root root   383336 Sep 19  2015 /usr/lib/x86_64-linux-gnu/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Sep 19  2015 /usr/lib/x86_64-linux-gnu/libcudart_static.a
lrwxrwxrwx 1 root root       12 Apr 14  2016 /usr/lib/x86_64-linux-gnu/libcuda.so -> libcuda.so.1
lrwxrwxrwx 1 root root       17 Aug 14 16:25 /usr/lib/x86_64-linux-gnu/libcuda.so.1 -> libcuda.so.367.35
-rw-r--r-- 1 root root 16881416 Mar 23  2016 /usr/lib/x86_64-linux-gnu/libcuda.so.361.42
-rwxr-xr-x 1 root root  8121032 Aug 14 14:14 /usr/lib/x86_64-linux-gnu/libcuda.so.367.35
lrwxrwxrwx 1 root root       13 Oct  1 05:55 /usr/lib/x86_64-linux-gnu/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 root root       17 Oct  1 05:55 /usr/lib/x86_64-linux-gnu/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxr-xr-x 1 root root 61453024 Oct  1 05:55 /usr/lib/x86_64-linux-gnu/libcudnn.so.4.0.7
lrwxrwxrwx 1 root root       17 Oct  1 05:43 /usr/lib/x86_64-linux-gnu/libcudnn.so.5 -> libcudnn.so.5.1.3
-rwxr-xr-x 1 root root 60696704 Oct  1 05:43 /usr/lib/x86_64-linux-gnu/libcudnn.so.5.1.3
-rw-r--r-- 1 root root 62025862 Oct  1 05:55 /usr/lib/x86_64-linux-gnu/libcudnn_static.a

```

Since then, I required the cuDNN package for other purposes and installed cuDNN 5 first. found out that Tensorflow 0.8 works with cudnn 4 only and reinstalled the version 4 and the model testing worked correctly. But when I tried to run the model after the cudnn install:

```

................................
................................
...............................
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 1640704 totalling 1.56MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 1660928 totalling 1.58MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 1676544 totalling 1.60MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 235 Chunks of size 1849600 totalling 414.52MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 2 Chunks of size 1893120 totalling 3.61MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 1936640 totalling 5.54MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2023680 totalling 1.93MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2041088 totalling 1.95MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2067200 totalling 1.97MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2151936 totalling 2.05MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2154240 totalling 2.05MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2174208 totalling 2.07MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2328320 totalling 2.22MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2543872 totalling 2.43MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2590208 totalling 2.47MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2610176 totalling 2.49MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 2774272 totalling 7.94MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2861312 totalling 2.73MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2974976 totalling 2.84MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 2994176 totalling 2.86MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 3042816 totalling 2.90MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 3445760 totalling 3.29MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 120 Chunks of size 3699200 totalling 423.34MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 2 Chunks of size 3939072 totalling 7.51MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 4348416 totalling 4.15MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 4418816 totalling 4.21MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 4980736 totalling 4.75MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 5232128 totalling 4.99MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 5960960 totalling 5.68MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 54400000 totalling 51.88MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 54545920 totalling 52.02MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] Sum Total of in-use chunks: 1.40GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:694] Stats: 
Limit:                  1534525440
InUse:                  1506072064
MaxInUse:               1506336256
NumAllocs:                  286635
MaxAllocSize:             92850432

W tensorflow/core/common_runtime/bfc_allocator.cc:270] ****************************************************************************************************
W tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 903.1KiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:900] Resource exhausted: OOM when allocating tensor with shape[680,340]
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=9028 evicted_count=9000 eviction_rate=0.996899 and unsatisfied allocation rate=0
Traceback (most recent call last):
  File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/home/hans/Documents/HANS/MAC/SUCCESSFUL MODELS/ADD/Tensorflow with Eng and Tam Word2Vec/src/translate.py"", line 350, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/home/hans/Documents/HANS/MAC/SUCCESSFUL MODELS/ADD/Tensorflow with Eng and Tam Word2Vec/src/translate.py"", line 347, in main
    train()
  File ""/home/hans/Documents/HANS/MAC/SUCCESSFUL MODELS/ADD/Tensorflow with Eng and Tam Word2Vec/src/translate.py"", line 186, in train
    target_weights, bucket_id, False)
  File ""src/seq2seq_model.py"", line 205, in step
    outputs = session.run(output_feed, input_feed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 340, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 564, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 637, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 659, in _do_call
    e.code)
tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[680,680]
     [[Node: gradients_9/model_with_buckets/embedding_attention_seq2seq_9/embedding_attention_decoder/attention_decoder/MultiRNNCell_34/Cell0/GRUCell/Gates/Linear/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](model_with_buckets/embedding_attention_seq2seq_9/embedding_attention_decoder/attention_decoder/MultiRNNCell_34/Cell0/GRUCell/Gates/Linear/concat, gradients_9/model_with_buckets/embedding_attention_seq2seq_9/embedding_attention_decoder/attention_decoder/MultiRNNCell_34/Cell0/GRUCell/Gates/add_grad/Reshape)]]
     [[Node: clip_by_global_norm_9/clip_by_global_norm_9/_2/_7992 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_624162_clip_by_global_norm_9/clip_by_global_norm_9/_2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op u'gradients_9/model_with_buckets/embedding_attention_seq2seq_9/embedding_attention_decoder/attention_decoder/MultiRNNCell_34/Cell0/GRUCell/Gates/Linear/MatMul_grad/MatMul_1', defined at:
  File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/home/hans/Documents/HANS/MAC/SUCCESSFUL MODELS/ADD/Tensorflow with Eng and Tam Word2Vec/src/translate.py"", line 350, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/home/hans/Documents/HANS/MAC/SUCCESSFUL MODELS/ADD/Tensorflow with Eng and Tam Word2Vec/src/translate.py"", line 347, in main
    train()
  File ""/home/hans/Documents/HANS/MAC/SUCCESSFUL MODELS/ADD/Tensorflow with Eng and Tam Word2Vec/src/translate.py"", line 122, in train
    model = create_model(sess, False)
  File ""/home/hans/Documents/HANS/MAC/SUCCESSFUL MODELS/ADD/Tensorflow with Eng and Tam Word2Vec/src/translate.py"", line 98, in create_model
    forward_only=forward_only)
  File ""src/seq2seq_model.py"", line 142, in __init__
    gradients = tf.gradients(self.losses[b], params)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py"", line 481, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py"", line 511, in _MatMulGrad
    math_ops.matmul(op.inputs[0], grad, transpose_a=True))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py"", line 1036, in matmul
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 911, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1154, in __init__
    self._traceback = _extract_stack()

...which was originally created as op u'model_with_buckets/embedding_attention_seq2seq_9/embedding_attention_decoder/attention_decoder/MultiRNNCell_34/Cell0/GRUCell/Gates/Linear/MatMul', defined at:
  File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
[elided 5 identical lines from previous traceback]
  File ""/home/hans/Documents/HANS/MAC/SUCCESSFUL MODELS/ADD/Tensorflow with Eng and Tam Word2Vec/src/translate.py"", line 98, in create_model
    forward_only=forward_only)
  File ""src/seq2seq_model.py"", line 133, in __init__
    softmax_loss_function=softmax_loss_function)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/seq2seq.py"", line 961, in model_with_buckets
    decoder_inputs[:bucket[1]])
  File ""src/seq2seq_model.py"", line 132, in <lambda>
    lambda x, y: seq2seq_f(x, y, False),
  File ""src/seq2seq_model.py"", line 96, in seq2seq_f
    feed_previous=do_decode)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/seq2seq.py"", line 718, in embedding_attention_seq2seq
    initial_state_attention=initial_state_attention)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/seq2seq.py"", line 643, in embedding_attention_decoder
    initial_state_attention=initial_state_attention)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/seq2seq.py"", line 556, in attention_decoder
    cell_output, state = cell(x, state)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py"", line 659, in __call__
    cur_inp, new_state = cell(cur_inp, cur_state)

hans@hans-Lenovo-IdeaPad-Y500:~/Documents/HANS/MAC/SUCCESSFUL MODELS/ADD/Tensorflow with Eng and Tam Word2Vec$ 

```

The pool allocator for my GPU is only going up to 300 from 100 when before, it went up to somewhere north of 6500. I don't know if this happened because of cudnn but this started right after I installed it. Please help.
"
5042,onb.26@,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
5040,possible bug in translate.py,"Hi there,
I read translate.py (/tensorflow/models/rnn/translate/translate.py), and got confused on the implement of decoder:
step1: when decode a new  input sentence, it is ok to chose a proper bucketId to do decode 
step2: tokenize the inputs(line244): 
       encoder_inputs, decoder_inputs, target_weights = model.get_batch({bucket_id: [(token_ids, [])]}, bucket_id)
step3: model.step the same as training procedure did

My question:  
The decoder_inputs are all zeros, except that the first one was assgined GO, Is this ok for a decoder? should't the LSTM's input be assgined with the previous LSTM's output, one by one?
"
5039,Tensorboard delete option for runs,"Since many of us train with Tensorflow on a remote server and use Tensorboard to monitor and evaluate the training I think it would be useful to add a delete option for specific runs on the Tensorboard dashboard.
When I debug a training process I monitor what the network is doing and sometimes restart the process very quickly. Like this my data directory easily gets filled with a lot of fail runs. Deleting them from command is a little tedious cause you always have to check in Tensorboard which ones you might want to keep. And usually you have to close Tensorboard to be able to delete them at all.

Maybe you guys have a suggestion for an improved workflow! Otherwise I think being able to delete runs directly from Tensorboard would be a nice addition. As part of this an 'active' flag for  whether a run is still running might be interesting as well. Obviously this flag would disable the deletion option.

I am looking forward to your feedback!

Edit: If this is really a feature worth integrating I would be happy to look into it and submit a PR.
"
5038,Can I install TensorFlow on the Pi zero,"Hi,

Can I install TensorFlow on the Pi zero.

I tried ""sudo pip2 install tensorflow-0.9.0-cp27-none-linux_armv7l.whl""

but it returned
tensorflow-0.9.0-cp27-none-linux_armv7l.whl is not a supported wheel on this platform.
Storing debug log for failure in /root/.pip/pip.log

I haven't try from Docker image yet. is it possible ?
or Can I install the C++  code ?

thank you and regards,
Khoa
"
5037,Feature request: bounds_check header in python package,"I think it would be useful if ""tensorflow/core/kernels/bounds_check.h"" was included in the python package, so that FastBoundsCheck() can be used in a custom Op when building against the binary package.

I patched this manually by adding bounds_check.h to framework_headers in tensorflow/core/BUILD:

``` diff
diff --git a/tensorflow/core/BUILD b/tensorflow/core/BUILD
index 2c936bd..44210f7 100644
--- a/tensorflow/core/BUILD
+++ b/tensorflow/core/BUILD
@@ -1136,6 +1136,7 @@ filegroup(
         ""framework/type_traits.h"",
         ""framework/types.h"",
         ""framework/unique_tensor_references.h"",
+        ""//tensorflow/core/kernels:bounds_check.h"",
         ""lib/core/errors.h"",
         ""lib/core/notification.h"",
         ""lib/core/refcount.h"",
```

I'm not sure if this is the correct way of doing this, so I'm making a feature request instead of a pull request.

Thanks!
"
5036,Feature request: Inception v3 MetaGraph,"Would it be possible for the TensorFlow developers to put a tar-ball online with the Inception v3 saved as a MetaGraph? I can't find it anywhere.

I'm currently using the following tar-ball with a frozen graph for Inception v3:

http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz

The problem is that I cannot continue training that graph because it is frozen, so all the variables have been converted to constants before it was saved. I can't find a way to convert the constants back to variables so I don't think that is possible. (There are also some deprecation warnings regarding BatchNormWithGlobalNormalization so it will presumably stop working at some point in the future).

After searching for a solution for days, I found that you have released a newer checkpoint-file for Inception v3:

http://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz

I downloaded it but it's only the checkpoint-file, not the graph-definition. So in my Python code I would apparently have to create the Inception graph using this function first:

https://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py#L52

But this apparently requires building TensorFlow from source, as far as I could understand from the README. There's also several options for using the function and it apparently has to be wrapped in arg_scopes and what-not:

https://github.com/tensorflow/models/blob/master/inception/inception/inception_model.py#L76-87

Would it be possible to update the above tar-ball (dated 2016-03-01) so it also contains the MetaGraph-files, so I can load it more easily and use it in my own Python program? I have another data-set so I replace the softmax-layer of the Inception-graph, and I also want to continue optimizing the rest of the variables of the Inception-graph.

Please also consider including a small example program in the tar-ball (or a link to some python-code), as it would make it a lot easier for everyone who wants to use it. Or at least make a list of all the relevant tensor-names (input, output, etc.)

Thanks!
"
5033,Provide manylinux1 wheels on PyPI,"Context: [what is manylinux1 tag](https://github.com/pypa/manylinux).

Currently, Tensorflow wheels on PyPI suck. As many know, we cannot upload specific Linux wheels on PyPI because the cheese shop prohibits different flavors (though Windows and macOS are OK). However, one can upload universal Linux wheels aka manylinux1 (see the link from above). There is a tool which helps making manylinux1 wheels called [auditwheel](https://github.com/pypa/auditwheel).

```
auditwheel show tensorflow-0.11.0rc0-cp35-cp35m-linux_x86_64.whl 

tensorflow-0.11.0rc0-cp35-cp35m-linux_x86_64.whl is consistent with
the following platform tag: ""manylinux1_x86_64"".

The wheel references no external versioned symbols from system-
provided shared libraries.

The wheel requires no external shared libraries! :)
```

This basically means that we can execute `auditwheel repair` and obtain the manylinux1 wheel.

Thus I propose to upload CPU-only wheels for Linux for Python 2/3 to PyPI with manylinux1 tag.
"
5032,AttributeError: 'module' object has no attribute 'batch_fft',"Hi, 

I just reinstalled rebuilt tensorflow from source to use CUDA v8 (I changed GPU to gtx1070)

I was running tf.batch_fft perfectly fine previously. But now it returns 

AttributeError: 'module' object has no attribute 'batch_fft'

Can someone point me to where this batch_fft is implemented now? I am using version 0.11.0rc0 now. 

I can't remember if I was using 0.10 previously or not. Did the API change?

Thanks in advance! :) 
"
5029,Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error downloading from http://github.com/google/protobuf/archive/c2b3e70efd2038a54ef8973771ac58192885125e.tar.gz ,"Firstly, there is no internet access. And I'm sure protobuf is installed successly:

```
protoc --version
libprotoc 3.1.0
```

But there is the error on the tensorflow's configure:

```
./configure 
/data/home/darrenqiu/tensorflow-master /data/home/darrenqiu/tensorflow-master
Please specify the location of python. [Default is /usr/local/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] n
No Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/local/lib/python2.7/site-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/site-packages]

/usr/local/lib/python2.7/site-packages
Do you wish to build TensorFlow with GPU support? [y/N] n
No GPU support will be enabled for TensorFlow
Configuration finished
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
.........
ERROR: package contains errors: tensorflow/contrib/metrics.
ERROR: error loading package 'tensorflow/contrib/metrics': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error downloading from http://github.com/google/protobuf/archive/c2b3e70efd2038a54ef8973771ac58192885125e.tar.gz to /root/.cache/bazel/_bazel_root/028d9ecced2b5d3d3b3ba6868668372d/external/protobuf: Error downloading http://github.com/google/protobuf/archive/c2b3e70efd2038a54ef8973771ac58192885125e.tar.gz to /root/.cache/bazel/_bazel_root/028d9ecced2b5d3d3b3ba6868668372d/external/protobuf/c2b3e70efd2038a54ef8973771ac58192885125e.tar.gz: Proxy address 10.14.36.84:8080 is not a valid URL.
```

Are There other ways to solve in the absence of a network?
"
5027,Trouble with mnist_rnn model,"When running with script 'tensorflow/tensorflow/examples/skflow/mnist_rnn.py', I got the following error.

Traceback (most recent call last):
  File ""mnist_rnn.py"", line 68, in <module>
    classifier.fit(X_train, y_train, logdir=""/tmp/mnist_rnn"")
  File ""/home/xing/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 257, in fit
    monitors=monitors)
  File ""/home/xing/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 662, in _train_model
    train_op, loss_op = self._get_train_ops(features, targets)
  File ""/home/xing/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 963, in _get_train_ops
    _, loss, train_op = self._call_model_fn(features, targets, ModeKeys.TRAIN)
  File ""/home/xing/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 946, in _call_model_fn
    return self._model_fn(features, targets, mode=mode)
  File ""/home/xing/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 493, in _model_fn
    predictions, loss = model_fn(features, targets)
  File ""mnist_rnn.py"", line 60, in rnn_model
    return learn.models.logistic_regression(encoding, y)
  File ""/home/xing/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/models.py"", line 148, in logistic_regression
    'weights', [x.get_shape()[1], y.get_shape()[-1]], dtype=dtype)
AttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'

Is there something wrong with learn package? My tensor version is 0.11.0rc0, installed with pip.
"
5022,SyncReplicasOptimizer hangs,"I'm using `SyncReplicasOptimizerV2` with a shared queue that closes at the end of an epoch. The workers catch the OutOfRange exception and one of them resets the session. (I think that's the expected workflow).

I think the workers sometimes get stuck in the sync op, maybe if they are waiting on other workers that started after the queue ran out. Is this an expected behavior, and if so what is the recommended way to prevent this?
"
5017,"TF Quit working with  /lib/libstdc++.so.6: version `CXXABI_1.3.8' not found, I then reinstalled ","I had it working, and then went to use it once again (after some ""normal"" Ubuntu system updates one of which may have been bazel?) And I got the traceback with the CXXABI_1.3.8' not found

So how should I remove the whole install and try again? or something easier?

NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

While I found this on SO I did not feel I should be messing around with this?
http://stackoverflow.com/questions/23494103/version-cxxabi-1-3-8-not-found-required-by
### Environment info

Operating System:
Linux Ubuntu 16.04 Python3.5 Anaconda in root Using an NVIDIA 1060 board
Installed version of CUDA 8 and cuDNN: cudNN v5.1
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
ls /usr/local/cuda/lib64/libcudnn*
/usr/local/cuda/lib64/libcudnn.so    /usr/local/cuda/lib64/libcudnn.so.5.1.5
/usr/local/cuda/lib64/libcudnn.so.5  /usr/local/cuda/lib64/libcudnn_static.a

Not sure what got updated but I got this message when importing tensorflow (which I had installed from source. So I reinstalled from source,, and got the same result but with the added message about should not run from source tree??

If installed from binary pip package, provide:
1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   ImportError: /home/tom/anaconda3/bin/../lib/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so)
   Error importing tensorflow.  Unless you are using bazel,
   you should not try to import tensorflow from its source directory;
   please exit the tensorflow source tree, and relaunch your python interpreter
   from there.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`) 
28166c086204c5ca4134086f250469a3802546ea
2. The output of `bazel version`
Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
### What other attempted solutions have you tried?

Reinstall.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
tom@tomServal:~$ python -c ""import tensorflow; print(tensorflow.**version**)""
Traceback (most recent call last):
  File ""/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/**init**.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
  File ""/home/tom/anaconda3/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/tom/anaconda3/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /home/tom/anaconda3/bin/../lib/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/**init**.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/**init**.py"", line 60, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/**init**.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
  File ""/home/tom/anaconda3/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/tom/anaconda3/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /home/tom/anaconda3/bin/../lib/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so)

Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.
"
5014,Python Tools Missing,"The tools found under tensorflow/python/tools are not packaged along with the pip package making them only usable through bazel (as demonstrated in their header documentation).  It's not clear to me how bazel is told which bits of python should be part of the pip package but these would be very useful to have access to from python code (ie: optimize_for_inference_lib).
"
5012,Error executing download_and_preprocess_imagenet,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
### Environment info

Operating System: macOS Yosemite

Installed version of CUDA and cuDNN: 
None (CPU only)

If installed from binary pip package, provide:
1. A link to the pip package you installed:
   https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0rc0-py3-none-any.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.11.0rc0
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

When following the guide (https://github.com/tensorflow/models/tree/master/inception) for configuring inceptionv3 I ran this command;
bazel-bin/inception/download_and_preprocess_imagenet ""${DATA_DIR}""
### What other attempted solutions have you tried?

None
### Logs or other output that would be helpful

Finished downloading and preprocessing the ImageNet data.
Saving results to /Volumes/Seagate External/imagenet
Successfully read 615299 bounding boxes across 544546 images.
Determining list of input files and labels from /Volumes/Seagate External/imagenet/raw-data/validation/.
Finished finding files in 100 of 1000 classes.
Finished finding files in 200 of 1000 classes.
Finished finding files in 300 of 1000 classes.
Finished finding files in 400 of 1000 classes.
Finished finding files in 500 of 1000 classes.
Finished finding files in 600 of 1000 classes.
Finished finding files in 700 of 1000 classes.
Finished finding files in 800 of 1000 classes.
Finished finding files in 900 of 1000 classes.
Finished finding files in 1000 of 1000 classes.
Traceback (most recent call last):
 File ""/private/var/tmp/_bazel_karllattimer/ed3d80c94eb22e8491a82fd78ab7022c/inception/bazel-out/local-fastbuild/bin/inception/build_imagenet_data.runfiles/inception/inception/data/build_imagenet_data.py"", line 704, in <module>
   tf.app.run()
 File ""/Users/karllattimer/Projects/tensorflow-testing/venv/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 30, in run
   sys.exit(main(sys.argv[:1] + flags_passthrough))
 File ""/private/var/tmp/_bazel_karllattimer/ed3d80c94eb22e8491a82fd78ab7022c/inception/bazel-out/local-fastbuild/bin/inception/build_imagenet_data.runfiles/inception/inception/data/build_imagenet_data.py"", line 698, in main
   FLAGS.validation_shards, synset_to_human, image_to_bboxes)
 File ""/private/var/tmp/_bazel_karllattimer/ed3d80c94eb22e8491a82fd78ab7022c/inception/bazel-out/local-fastbuild/bin/inception/build_imagenet_data.runfiles/inception/inception/data/build_imagenet_data.py"", line 597, in _process_dataset
   filenames, synsets, labels = _find_image_files(directory, FLAGS.labels_file)
 File ""/private/var/tmp/_bazel_karllattimer/ed3d80c94eb22e8491a82fd78ab7022c/inception/bazel-out/local-fastbuild/bin/inception/build_imagenet_data.runfiles/inception/inception/data/build_imagenet_data.py"", line 529, in _find_image_files
   random.shuffle(shuffled_index)
 File ""/Users/karllattimer/Projects/tensorflow-testing/venv/lib/python3.5/random.py"", line 272, in shuffle
   x[i], x[j] = x[j], x[i]
"
5008,Compilation on Power8 and CUDA 7.5,"I am compiling tensorflow on a Power8 CPU with CUDA enabled and I am getting the following error when running this command:

bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

ERROR: /tensorflow/tensorflow/core/kernels/BUILD:46:1: output 'tensorflow/core/kernels/_objs/strided_slice_op_gpu/tensorflow/core/kernels/strided_slice_op_gpu.cu.pic.o' was not created.
ERROR:/tensorflow/tensorflow/core/kernels/BUILD:1714:1: C++ compilation of rule '//tensorflow/core/kernels:training_ops' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 118 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
gcc: internal compiler error: Killed (program cc1plus)

My gcc version is 4.8.4 on Ubuntu 14.04

Is this version of GCC supported for the compilation of tensorflow? Do I need a different version? Has anyone encountered a similar problem?
"
5007,Update classify_image.py code to use latest pre-trained model,"The code in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/imagenet/classify_image.py references the older pre-trained model at http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz however, a new pre-trained model is available at http://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz and is referenced in other parts of the code tree (such as https://github.com/tensorflow/models/tree/master/inception).

Please update the code in classify_image.py to reflect the latest pre-trained  model.
"
5005,Mismatch between TFLearn documentation and tutorial,"Hi all,

The changes to the metric creation in Estimator in tflearn don't match the current documentation on monitors. For example:

https://www.tensorflow.org/versions/r0.11/tutorials/monitors/index.html

suggests:

```
validation_metrics = {""accuracy"": tf.contrib.metrics.streaming_accuracy,
                      ""precision"": tf.contrib.metrics.streaming_precision,
                      ""recall"": tf.contrib.metrics.streaming_recall}
validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(
    test_set.data,
    test_set.target,
    every_n_steps=50,
    metrics=validation_metrics)
```

wheras 

https://github.com/tensorflow/tensorflow/blob/r0.11/tensorflow/contrib/learn/python/learn/estimators/rnn.py

contains:

```
# Single head metrics.
      if isinstance(predictions, dict):
        raise ValueError(
            'Metrics passed provide only name, no prediction, '
            'but predictions are dict. '
            'Metrics: %s, Targets: %s.' % (metrics, targets))
```
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None
### Environment info

Operating System:

Max OSX El Capitan

Installed version of CUDA and cuDNN:

N/A - cpu version
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

0.11.0rc0
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

https://gist.github.com/alexshires/d9674c58e352ad81be43f5f7da74c7e1
### What other attempted solutions have you tried?

Looking up MetricSpec configuration - no examples or help available
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).

https://gist.github.com/alexshires/5310a751e9b767fbd3595570d618c342
"
5003,C API crashes on simple problems  ,"I am trying to incorporate Tensorflow into a larger OS X project, so using the stand-alone static library build (from contrib/makefile) and C API.

Once all the linking issues are resolved, the simplest Tensorflow programs compile fine, but do not run. I have so far found two issues when creating operations similarly to the c_api_test file:
- When adding a constant Operation, Tensorflow crashes on exit from TF_SetAttrTensor(). The issue is that the managed buffer is deallocated, but still has refcount of 1. I am not sure why this happens since the managed buffer should supposedly be passed to the node_builder (which should retain the reference), but the buffer still gets deallocated.
- Trying to work around that, it almost immediately hits another issue: TF_FinishOperation crashes because node_builder.Finalize call does not set the props of the Node and so ret->name() returns NULL.

I do not know the codebase well enough (just started today), so perhaps you could point me to a possible underlying cause.

Using OS X 10.11.6, Xcode 8, libc++ and C++14. Tensorflow current as of October 16.
"
5002,could you release binary for cuda8,"Could you release binary package for cuda8?

Some devices, e.g., gtx 1070/1080, build off cuda8. It will save a lot of work for installation from source.

thanks.
"
4999,[bugs] TensorFlow ci_build docker bazel extration error,"Within the past week I started getting a bazel extraction error when trying to build my docker image for testing.
Below is a reproducible description of the error.

Generic Ubuntu 14.04 on AWS (c4.4xlarge)

```
$uname -r
3.13.0-91-generic
```

Install docker according to installation instructions at [docker ubuntu](https://docs.docker.com/engine/installation/linux/ubuntulinux/) with a docker group added to the default user.

```
$sudo apt-get install git
$git clone https://github.com/tensorflow/tensorflow.git
$cd tensorflow
$tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...
```

I then receive the following error

```
Step 10 : RUN /install/install_buildifier.sh
 ---> Running in f38c73826642
Cloning into 'buildifier'...
/buildifier /
Extracting Bazel installation...
.
ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'go/def.bzl': no such package '@io_bazel_rules_go//go': Error cloning repository: https://github.com/bazelbuild/rules_go.git: cannot open git-upload-pack caused by https://github.com/bazelbuild/rules_go.git: cannot open git-upload-pack caused by java.lang.RuntimeException: Unexpected error: java.security.InvalidAlgorithmParameterException: the trustAnchors parameter must be non-empty caused by Unexpected error: java.security.InvalidAlgorithmParameterException: the trustAnchors parameter must be non-empty caused by the trustAnchors parameter must be non-empty.
____Elapsed time: 1.730s
The command '/bin/sh -c /install/install_buildifier.sh' returned a non-zero code: 1
ERROR: docker build failed. Dockerfile is at /home/ubuntu/tensorflow/tensorflow/tools/ci_build/Dockerfile.cpu
```
"
4998,Please make the documentation headlines linkable/clickable,"That would make it easier to refer to particular parts/anchors in the documentation.
"
4997,xcode build system broken,"I am getting the error  'unsupported/Eigen/CXX11/Tensor' while trying to run camera example in iOS i do have Eigen installed on my mac..
"
4996,tensorflow/core/framework/common_shape_fns.h not in includes path (v0.11.0rc0),"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None
### Environment info

Operating System: **Ubuntu 14.04 x64**

Installed version of CUDA and cuDNN: **CUDA 7.5 and CUDNN 5.1**

```
$ ll /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5*
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18*
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18*
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 60696704 Sep 21 21:07 /usr/local/cuda/lib64/libcudnn.so*
-rwxr-xr-x 1 root root 60696704 Sep 21 21:07 /usr/local/cuda/lib64/libcudnn.so.5*
-rwxr-xr-x 1 root root 60696704 Sep 21 21:07 /usr/local/cuda/lib64/libcudnn.so.5.1.3*
-rw-r--r-- 1 root root 59715990 Sep 21 21:07 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. A link to the pip package you installed: **https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc0-cp27-none-linux_x86_64.whl**
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   **0.11.0rc0**
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

Cannot `#include ""tensorflow/core/framework/common_shape_fns.h` to use `::tensorflow::shape_inference::UnchangedShape`

Also:

```
$ ls /usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/framework/common_shape_fns.h
ls: cannot access /usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/framework/common_shape_fns.h: No such file or directory
```
### What other attempted solutions have you tried?

Use python to infer custom op's shape instead (which works):

``` python
tf.RegisterShape(""MyOp"")(common_shapes.unchanged_shape)
```
"
4995,Partial training of im2txt runs only 1 step,"After running an initial training of model 'im2txt' of 5100 steps, when trying to run more steps, it only runs one and saves the model, i've tried using 10 , 100 and 5000 steps

model url: https://github.com/tensorflow/models/tree/master/im2txt

Params:
--input_file_pattern=""/Users/carlosescamilla/im2text/data/mscoco/train-?????-of-00256"" 
--inception_checkpoint_file=""/Users/carlosescamilla/im2text/data/inception_v3.ckpt"" 
--train_dir=""/Users/carlosescamilla/im2text/model/train""
 --train_inception=false 
--number_of_steps=100

Output:

I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.dylib locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.dylib locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.dylib locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.1.dylib locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.dylib locally
INFO:tensorflow:Prefetching values from 256 files matching /Users/carlosescamilla/im2text/data/mscoco/train-?????-of-00256
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] OS X does not support NUMA - returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: 
name: GeForce GT 750M
major: 3 minor: 0 memoryClockRate (GHz) 0.9255
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.77GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)
INFO:tensorflow:Starting Session.
INFO:tensorflow:Starting Queues.
INFO:tensorflow:global_step/sec: 0
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 759.69MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 759.69MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 1.01GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 1.01GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 759.69MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 759.69MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 1.51GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 1.51GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 2.22GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 2.22GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
INFO:tensorflow:global step 5111: loss = 3.0275 (45.44 sec/step)
INFO:tensorflow:Stopping Training.
INFO:tensorflow:Finished training! Saving model to disk.
### Environment info

MacOS 10.11.6 El Capitan

Installed version of CUDA and cuDNN: 
CUDA Toolkit 7.5
cuDNN 5005

installed with pip3
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.11.0rc0-py3-none-any.whl
"
4994,Feature request: ExportCostModels in C/Python API?,"Exporting cost models of graphs seems to be a great feature with which users could figure out the resource-intensive (or even slowest) part of graphs, but currently it's not visible in the C/Python API.

I've tried to make it work and found that ExportCostModels() is not a member function in the ""Session"" interface. Also, a CostGraphDef object is related to a partition of some graph, placed on some device. ExportCostModels() in ""DirectSession"" only provides a mapping from partitions (note that for all the graphs executed) to CostGraphDef objects and it's hard to get CostGraphDef directly for the concerning parts. So I think there should be more works to make the code eligible and easy for use.

I wonder whether is anybody working on this and how developers think about this feature. Thank you!
"
4993,Uninitialized memory read on send_device_incarnation,"Running the following snippet several times shows random numbers in the `send_device_incarnation` of last device which looks like uninitialized memory read. @dave-andersen would know if it's still a priority to get rid of such reads

```
import tensorflow as tf

config = tf.ConfigProto(device_count={""CPU"": 3},
                    inter_op_parallelism_threads=3,
                    intra_op_parallelism_threads=1)
with tf.device(""cpu:0""):
    a = tf.ones(())
with tf.device(""cpu:1""):
    b = tf.ones(())
with tf.device(""cpu:2""):
    c = a+b

sess = tf.Session(config=config)
run_options = options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE,
                                    output_partition_graphs=True)
run_metadata = tf.RunMetadata()
sess.run(c, options=run_options, run_metadata=run_metadata)
print(str(run_metadata))

```

This shows something like this

```
    attr {
      key: ""send_device_incarnation""
      value {
        i: -1672352343731902606
      }
    }
    attr {
      key: ""tensor_name""
      value {
        s: ""add:0""
      }
    }
  }
  versions {
    producer: 15
  }
}

```
"
4991,E tensorflow/core/framework/op_kernel.cc:925] unknown op: Round,"Hi, sorry I am a bit new to Tensorflow and could not find this error anywhere else.
My system is:
Ubuntu 14.04.5 LTS
CUDA 8.0.44 cuDNN 5.1 on Titan X Pascal

```
-rw-r--r-- 1 root root   558720 Oct 15 18:04 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Oct 15 18:04 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Oct 15 18:04 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 root root   415432 Oct 15 18:04 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Oct 15 18:04 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Oct 15 23:51 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Oct 15 23:51 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 Oct 15 18:24 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Oct 15 18:24 /usr/local/cuda/lib64/libcudnn_static.a
```

Tensorflow 0.11(f794cd393b1e7821fcc3cdcee9b6a4400f2540bf)
Bazel  0.3.2

My problem is:

```
import tensorflow as tf
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcurand.so.8.0 locally
sess = tf.Session()
a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 3], name='a')
b = tf.matmul(a, a)
print sess.run(b)
E tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: ""Round"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: Round
E tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: ""Round"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: Round
E tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: ""Round"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } }') for unknown op: Round
E tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: ""Round"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: Round
E tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: ""Round"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_HALF } } }') for unknown op: Round
E tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: ""Round"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: Round
E tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: ""Round"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: Round
E tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: ""Round"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } }') for unknown op: Round
E tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: ""Round"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }') for unknown op: Round
E tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: ""Round"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_HALF } } }') for unknown op: Round
[[ 27.  30.  33.]
 [ 60.  69.  78.]
 [ 66.  78.  90.]]
```

This error only comes up once, could you please guide me on what is going on here?

Thank you!
"
4989,Fail to load user op compiled by bazel with gcc 6,"User op built by bazel with gcc >=5 could not be loaded in python. Hope there is a solution to pass g++ config to bazel.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

[#2455 Adding a New Op Error: can not load the customed file](https://github.com/tensorflow/tensorflow/issues/2455)
[Custom new operation in Tensorflow results in exception 'pointer being freed was not allocated'](http://stackoverflow.com/questions/38048266/custom-new-operation-in-tensorflow-results-in-exception-pointer-being-freed-was)
### Environment info

Operating System: macOS 10.12

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)

73b01567d68d4639d2329deb335ddfcd9c04f87c
1. The output of `bazel version`

```
Build label: 0.3.1-homebrew
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Aug 4 09:58:27 2016 (1470304707)
Build timestamp: 1470304707
Build timestamp as int: 1470304707
```
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

zero_out.cc:

```
#include ""tensorflow/core/framework/op.h""
#include ""tensorflow/core/framework/op_kernel.h""

using namespace tensorflow;

REGISTER_OP(""ZeroOut"")
    .Input(""to_zero: int32"")
    .Output(""zeroed: int32"");

class ZeroOutOp : public OpKernel {
 public:
  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}

  void Compute(OpKernelContext* context) override {
    // Grab the input tensor
    const Tensor& input_tensor = context->input(0);
    auto input = input_tensor.flat<int32>();

    // Create an output tensor
    Tensor* output_tensor = NULL;
    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),
                                                     &output_tensor));
    auto output = output_tensor->flat<int32>();

    // Set all but the first element of the output tensor to 0.
    const int N = input.size();
    for (int i = 1; i < N; i++) {
      output(i) = 0;
    }

    // Preserve the first input value if possible.
    if (N > 0) output(0) = input(0);
  }
};

REGISTER_KERNEL_BUILDER(Name(""ZeroOut"").Device(DEVICE_CPU), ZeroOutOp);
```

BUILD

```
load(""//tensorflow:tensorflow.bzl"", ""tf_custom_op_library"")

tf_custom_op_library(
    name = ""zero_out.so"",
    srcs = [""zero_out.cc""]
)
```

run:

```
bazel build -c opt //tensorflow/core/user_ops:zero_out.so
```

then load the lib from python:

```
>>> import tensorflow as tf
>>> tf.load_op_library('zero_out.so')
python(61257,0x7fffb7e123c0) malloc: *** error for object 0x7fa5fcb46028: pointer being freed was not allocated
*** set a breakpoint in malloc_error_break to debug
```
### What other attempted solutions have you tried?

Firstly, I tried to rebuild it with g++, with the option of `-D_GLIBCXX_USE_CXX11_ABI=0` mentioned in the tutorial:

```
g++ -v -std=c++11 -shared zero_out.cc -o zero_out.so -fPIC -I $TF_INC -O2 -undefined dynamic_lookup -D_GLIBCXX_USE_CXX11_ABI=0
```

it works.

Then, I tried to add this option to bazel:

```
bazel build --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" -c opt //tensorflow/core/user_ops:zero_out.so
```

the problem is still there.
### Logs or other output that would be helpful

[bazel log](https://gist.github.com/tongda/b9b7c17c9d574669a0925e5606d9aa23)
"
4988,Error building tensorflow from source,"Getting below error while building tensorflow from source.  

$ sudo bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

/home/jenisha/.cache/bazel/_bazel_root/d76a8cba20478b6f06262b0e7e986df4/external/nanopb_git/BUILD:6:1: undeclared inclusion(s) in rule '@nanopb_git//:nanopb':
this rule is missing dependency declarations for the following files included by 'external/nanopb_git/pb_common.c':
  '/usr/include/stdc-predef.h'
  '/usr/lib/gcc/x86_64-linux-gnu/4.8/include/stdint.h'
  '/usr/include/stdint.h'
  '/usr/include/features.h'
  '/usr/include/x86_64-linux-gnu/sys/cdefs.h'
  '/usr/include/x86_64-linux-gnu/bits/wordsize.h'
  '/usr/include/x86_64-linux-gnu/gnu/stubs.h'
  '/usr/include/x86_64-linux-gnu/gnu/stubs-64.h'
  '/usr/include/x86_64-linux-gnu/bits/wchar.h'
  '/usr/lib/gcc/x86_64-linux-gnu/4.8/include/stddef.h'
  '/usr/lib/gcc/x86_64-linux-gnu/4.8/include/stdbool.h'
  '/usr/include/string.h'
  '/usr/include/xlocale.h'
  '/usr/include/x86_64-linux-gnu/bits/string.h'
  '/usr/include/x86_64-linux-gnu/bits/string2.h'
  '/usr/include/endian.h'
  '/usr/include/x86_64-linux-gnu/bits/endian.h'
  '/usr/include/x86_64-linux-gnu/bits/byteswap.h'
  '/usr/include/x86_64-linux-gnu/bits/types.h'
  '/usr/include/x86_64-linux-gnu/bits/typesizes.h'
  '/usr/include/x86_64-linux-gnu/bits/byteswap-16.h'
  '/usr/include/stdlib.h'
  '/usr/include/x86_64-linux-gnu/bits/string3.h'.
"
4987,Feature request: dropout with noise_shape does not support varied batchsize,"Since it's convenient to support varied batchsize in tf.placeholder by setting the head element of argument ""shape"" to None, tf.nn.dropout does not allow None in its argument ""noise_shape"", leading to models using dropout with noise_shape cumbersome to implement varied batchsize.  I wonder is it possible to allow None in noise_shape for better support for varied batchsize? Thank you!
"
4984,gcc: error trying to exec 'as': execvp: No such file or directory,"I think the problem is that `as` wasn't installed with `gcc` and thus `gcc -print-prog-name=as` just prints `as`. `as` is in my path, but not in the same location as `gcc`.

```
$ which gcc
/appl/gcc/4.9.2/bin/gcc
$ which as
/appl/binutils/2.25.1/bin/as
```
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

there are a couple:
- gcc: error trying to exec 'as': execvp: No such file or directory: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=40339
- gcc: error trying to exec 'as': execvp: No such file or directory https://decibel.ni.com/content/thread/39592
- Building TensorFlow with custom GCC requires hardcoded ld,nm and as https://github.com/bazelbuild/bazel/issues/1713 â I tried setting `build --action_env=PATH`, but that did change anything.
### Environment info

Operating System:

```
$ uname -a
Linux n-62-18-47 2.6.32-573.22.1.el6.x86_64 #1 SMP Tue Mar 22 17:15:28 CDT 2016 x86_64 x86_64 x86_64 GNU/Linux 
```

Installed version of CUDA and cuDNN: CUDA: 8.0, cuDNN 5.1.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
$  ls -l /appl/cuda/8.0/lib64/libcud*
-rw-r--r-- 1 sebo root 560184 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 sebo root     16 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 sebo root     19 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 sebo root 394472 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 sebo root 737516 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart_static.a
```

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`): `f794cd393b1e7821fcc3cdcee9b6a4400f2540bf`
2. The output of `bazel version`: 

```
$ bazel --batch version
INFO: Reading 'startup' options from /zhome/ff/2/77654/.bazelrc: --batch --output_user_root=/work1/s123598/.bazel
Build label: 0.3.2-2016-10-13 (@2891ec5)
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Oct 13 15:05:25 2016 (1476371125)
Build timestamp: 1476371125
Build timestamp as int: 1476371125
```
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
# install tensorflow
git clone https://github.com/tensorflow/tensorflow
cd tensorflow
curl -L https://github.com/tensorflow/tensorflow/pull/4983.patch | git am -

# set configuration parameters
export PYTHON_BIN_PATH=`which python3` # ~/stdpy3/bin/python3
export TF_NEED_GCP=0
export TF_NEED_HDFS=0
export TF_NEED_CUDA=1
export GCC_HOST_COMPILER_PATH=`which gcc` # /appl/gcc/4.9.2/bin/gcc
export TF_CUDA_VERSION=8.0
export CUDA_TOOLKIT_PATH=/appl/cuda/8.0/
export TF_CUDNN_VERSION=5
export CUDNN_INSTALL_PATH=$HOME/cuda/ # the cuDNN version provide IT is too old (5.0.4), so I downloaded the latest and unpacked it in $HOME
export TF_CUDA_COMPUTE_CAPABILITIES=""3.5,5.2""

cat > $HOME/.bazelrc <<EOF
# --batch: always run in batch mode, since there are some firewall issues.
# --output_user_root: HOME is NFS (filesystem), this will not work with bazel, use WORKDIR instead
startup --batch --output_user_root=$WORKDIR/.bazel
EOF

# one python configuration can't be set directly use yes to accept automatically
yes """" | CC=gcc CXX=g++ ./configure

# build tensorflow
CC=gcc CXX=g++ bazel build --copt=""-w"" \
--ignore_unsupported_sandboxing --spawn_strategy=standalone --verbose_failures \
-c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```
### What other attempted solutions have you tried?
- I've tried symlinking gcc and as into the same path, but then cc1 and the gcc header files can't be found.
- I've tried searching for how bazel or tensorflow finds `as` but I can't find that code.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).

full log: https://gist.github.com/AndreasMadsen/7bf11dcf5c53981e532f67850e5b2b9b

```
gcc: error trying to exec 'as': execvp: No such file or directory
ERROR: /zhome/ff/2/77654/tensorflow/tensorflow/contrib/rnn/BUILD:101:1: output 'tensorflow/contrib/rnn/_objs/python/ops/_gru_ops_gpu/tensorflow/contrib/rnn/kernels/gru_ops_gpu.cu.pic.o' was not created.
ERROR: /zhome/ff/2/77654/tensorflow/tensorflow/contrib/rnn/BUILD:101:1: not all outputs were created.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 320.454s, Critical Path: 196.64s
```
"
4981,FastGFile ResourceExhaustedError,"In https://github.com/tensorflow/models/commit/2390974a03a62b1388a004173477418db267074a @cshallue changed some `tf.gfile.FastGFile()` calls to `open()` because two RedHat users reported in #4685 that it causes ResourceExhaustedError even though resources don't appear to be exhausted.

We've also had the same issue reported in tensorflow/models#531, tensorflow/models#489, and tensorflow/models#480 but we're still waiting to learn if they're using RedHat.

Assigning to @rohan100jain who has done work on this code in the past.
"
4978,contrib.layers and multigpu: variable scope issues,"I guess, issues regarding stuff in `tf.contrib` working nicely with tensorflow itself are also welcome here? Otherwise, I'll move it to the `tflearn` issue tracker.

**tl;dr**: using contrib.layers in multigpu setting (multiple ""towers"" in separate name scopes) leads to scope errors; using ordinary `tf.get_variable(..)` works just fine

tensorflow 0.10.0
cuda 7.5

basic fully connected network to classify mnist: 

```
def build_fc_dnn():
    X = tf.placeholder(tf.float32, [None, 784])
    y = tf.placeholder(tf.float32, [None, 10])

    depth = 5

    last_layer = X
    argkw = dict(num_outputs=20, activation_fn=tf.nn.relu)
    for _ in range(depth):
        last_layer = tf.contrib.layers.fully_connected(last_layer, **argkw)
    logits = tf.contrib.layers.fully_connected(last_layer, num_outputs=10)

    loss = tf.nn.softmax_cross_entropy_with_logits(logits, y)
    y_train_eq_pred = tf.equal(tf.argmax(y,1), tf.argmax(logits,1))
    acc = tf.reduce_mean(tf.cast(y_train_eq_pred, tf.float32))

    return X, y, loss, acc
```

and the code that builds graph (analogues to cifar multigpu example):

```
    ...
    tower_vars = []
    for tower_id in range(len(device_id_list)):
        with tf.device('/gpu:%d' % tower_id):
            with tf.name_scope('tower_%d' % tower_id) as scope:
                X, y, loss, acc = build_model()
                tower_vars.append([gd.compute_gradients(loss), loss, acc, (X, y)])
                tf.get_variable_scope().reuse_variables()

    tower_grads, tower_loss, tower_acc, xy_pairs = zip(*tower_vars)
    train_op = gd.apply_gradients(average_gradients(tower_grads))
    loss = tf.reduce_mean(tower_loss)
    acc = tf.reduce_mean(tower_acc)
    init_op = tf.initialize_all_variables()
```

if I do that, I get an error: `ValueError: Variable fully_connected_6/weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?`

If I look into `tflearn` docs (`tf.contrib.layers` is basically `tflearn`, right?), they suggest building multigpu code as follows:

```
with tf.device('/gpu:0'):
    # Force all Variables to reside on the CPU.
    with tf.arg_ops([tflearn.variables.variable], device='/cpu:0'):
        model1 = my_model(placeholder_X)
# Reuse Variables for the next model
tf.get_variable_scope().reuse_variables()
with tf.device('/gpu:1'):
    with tf.arg_ops([tflearn.variables.variable], device='/cpu:0'):
        model2 = my_model(placeholder_X)
```

those docs are probably somewhat outdated, because `tf.arg_ops` is not there anymore; the closest thing I could find is the following:

```
    arg_scope = tf.contrib.framework.arg_scope
    create_var_op = tf.contrib.framework.python.ops.variables.variable
    ...
    tower_vars = []
    for tower_id in range(len(device_id_list)):
        with tf.device('/gpu:%d' % tower_id):
            with tf.name_scope('tower_%d' % tower_id) as scope:
            variables_on_cpu = arg_scope([create_var_op], device='/cpu:0')
            with variables_on_cpu:
                 X, y, loss, acc = build_model()
                 tower_vars.append([gd.compute_gradients(loss), loss, acc, (X, y)])
                 tf.get_variable_scope().reuse_variables()

    tower_grads, tower_loss, tower_acc, xy_pairs = zip(*tower_vars)
    train_op = gd.apply_gradients(average_gradients(tower_grads))
    loss = tf.reduce_mean(tower_loss)
    acc = tf.reduce_mean(tower_acc)
    init_op = tf.initialize_all_variables()
```

but it also does not help (same error).

[issue](https://github.com/tensorflow/serving/issues/136) with similar error message
[full](https://gist.github.com/MInner/58fa334574138f1ce1359258f27af19a) code that reproduces error
"
4975,bazel version check should be in tf_workspace(),"@ic suggested in #4458 to have `./configure` check the Bazel version. This would probably save time for a lot of people. It should be relatively straightforward to implement, because even if Bazel is compiled from git, it still displays a version tag.

```
$ bazel version
Build label: 0.3.2-2016-10-14 (@183147e)
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 14 21:34:37 2016 (1476480877)
Build timestamp: 1476480877
Build timestamp as int: 1476480877
```

@martinwicke what version do we currently support? Bazel â¥0.3.1?
"
4974,Hermetically seal the protobuf build,"Our protobuf rules don't always compile if sandboxing is enabled in `~/.bazelrc`. For example:

```
build --worker_sandboxing=true  
build --spawn_strategy=sandboxed  
build --genrule_strategy=sandboxed
test --spawn_strategy=sandboxed
```

We end up with errors like this when compiling things like `bazel build tensorflow/python/tools:strip_unused`.

```
INFO: From ProtoCompile tensorflow/python/training/checkpoint_state_pb2.py:
external/protobuf/python: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/contrib/session_bundle/manifest_pb2.py:
external/protobuf/python: warning: directory does not exist.
INFO: From ProtoCompile tensorflow/contrib/tensorboard/plugins/projector/projector_config_pb2.py:
external/protobuf/python: warning: directory does not exist.
ERROR: /usr/local/google/home/jart/code/tensorflow-clean/tensorflow/contrib/tfprof/tools/tfprof/BUILD:42:1: null failed: linux-sandbox failed: error executing command 
  (cd /usr/local/google/home/jart/.cache/bazel/_bazel_jart/534cc9069a4bd39f8bace6b1039c6506/bazel-sandbox/978fc997-2a45-4494-836a-df35eb0b4705-842/execroot/tensorflow-clean && \
  exec env - \
  /usr/local/google/home/jart/.cache/bazel/_bazel_jart/534cc9069a4bd39f8bace6b1039c6506/execroot/tensorflow-clean/_bin/linux-sandbox @/usr/local/google/home/jart/.cache/bazel/_bazel_jart/534cc9069a4bd39f8bace6b1039c6506/bazel-sandbox/978fc997-2a45-4494-836a-df35eb0b4705-842/linux-sandbox.params -- bazel-out/host/bin/external/protobuf/protoc '--python_out=bazel-out/local-fastbuild/genfiles/' -I. -Iexternal/protobuf/python -Ibazel-out/local-fastbuild/genfiles/external/protobuf/python tensorflow/contrib/tfprof/tools/tfprof/tfprof_log.proto tensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto).
external/protobuf/python: warning: directory does not exist.
tensorflow/core/framework/tensor_shape.proto: File not found.
tensorflow/core/framework/types.proto: File not found.
tensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto: Import ""tensorflow/core/framework/tensor_shape.proto"" was not found or had errors.
tensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto: Import ""tensorflow/core/framework/types.proto"" was not found or had errors.
tensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto:9:12: ""DataType"" is not defined.
tensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto:45:12: ""TensorShapeProto"" is not defined.
Target //tensorflow/python/tools:strip_unused failed to build
INFO: Elapsed time: 53.186s, Critical Path: 40.69s
```

We might want to rewrite the protobuf rules so they can have well defined relationships.
"
4971,Center loss,"It seems that center loss seems good in the recognition area to minize the variation of cluter. There is a caffe implementation of this loss. 
URL: https://github.com/ydwen/caffe-face/

I wrote some code but it seems not correct:

``` Python
def center_loss(features, labels, name):
    with tf.name_scope(name=name):
       feat_dim = features.get_shape().as_list()[1]
       batch_size = features.get_shape().as_list()[0]
       centers = tf.get_variable('center', shape=[FLAGS.num_classes, feat_dim])
       # compute loss & update center
       loss = 0
       for i in range(batch_size):
           ft = features[i, :]
           idx = labels[i]
           c = tf.gather(centers, idx)
          loss += tf.reduce_mean(tf.square(tf.sub(ft, c)))
      loss /= batch_size
```

Is there can help me to understand better with Tensorflow, I can make a PR.
"
4970,CRC Error on Retraining Inception_v3,"Hi.

I tried to follow the tutorial given on https://www.tensorflow.org/versions/r0.9/how_tos/image_retraining/index.html. I'm on MacOS Sierra and installed a separate version of python via homebrew, which is located in ""/usr/local/bin/python"".

Now, I installed and compiled tensorflow from source and set the python location to ""/usr/local/bin/python"" and the library path to ""/usr/local/lib/python2.7/site-packages"". After compiling the retrain files, I get an error on running 

```
bazel-bin/tensorflow/examples/image_retraining/retrain` --image_dir ~/flower_photos
```

which is

```
Traceback (most recent call last):
  File ""/Users/marcel/dev/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 1014, in <module>
    tf.app.run()
  File ""/Users/marcel/dev/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/marcel/dev/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 752, in main
    maybe_download_and_extract()
  File ""/Users/marcel/dev/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 314, in maybe_download_and_extract
    tarfile.open(filepath, 'r:gz').extractall(dest_directory)
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py"", line 2079, in extractall
    self.extract(tarinfo, path)
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py"", line 2116, in extract
    self._extract_member(tarinfo, os.path.join(path, tarinfo.name))
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py"", line 2192, in _extract_member
    self.makefile(tarinfo, targetpath)
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py"", line 2233, in makefile
    copyfileobj(source, target)
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py"", line 266, in copyfileobj
    shutil.copyfileobj(src, dst)
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 49, in copyfileobj
    buf = fsrc.read(length)
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py"", line 831, in read
    buf += self.fileobj.read(size - len(buf))
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py"", line 743, in read
    return self.readnormal(size)
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py"", line 758, in readnormal
    return self.__read(size)
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py"", line 748, in __read
    buf = self.fileobj.read(size)
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/gzip.py"", line 268, in read
    self._read(readsize)
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/gzip.py"", line 315, in _read
    self._read_eof()
  File ""/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/gzip.py"", line 354, in _read_eof
    hex(self.crc)))
IOError: CRC check failed 0x39de13a7 != 0x630e11cfL
```

Any insights on that? Sounds like the download is corrupted and I already re-downloaded the images several times. I think it actually doesn't rely on the images, because the error is the same no matter what directory I hand to --image_dir.

Thanks in advance
"
4969,Messy in Python API Docs - state_ops.html#constant_initializer,"https://www.tensorflow.org/versions/r0.11/api_docs/python/state_ops.html#constant_initializer

On Constant Initializer  -> Examples:

The very large gray box contains the html of other initializer docs. Hope it can be fixed. 
"
4968,TensorFlow produces arbitrary results without error when using large amounts of GPU memory,"### Environment info

Operating System: Docker container based on `nvidia/cuda:7.5-cudnn5-devel` running on CentOS

If installed from binary pip package, provide:
1. A link to the pip package you installed: `pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc0-cp34-cp34m-linux_x86_64.whl`
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
0.11.0rc0
```
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

``` python
import numpy as np
import tensorflow as tf

mb = 100
sz = int(mb * 1e6 / 4)
total_gb = 11
n = int(total_gb / mb * 1000)
x = np.array(np.random.randn(sz), dtype=np.float32)

with tf.Graph().as_default():
    place = tf.placeholder(tf.float32, shape=[sz])
    with tf.device('/gpu:0'):
        x_gpu = [tf.Variable(place, dtype=tf.float32) for i in range(n)]
    init = tf.initialize_all_variables()
    with tf.Session() as sess:
        sess.run(init, feed_dict={place: x})
        # I know it's not optimal, but to make it more comparable to the Theano code below
        x_out = [sess.run(v) for v in x_gpu]

delta = [np.sum(np.abs(xi - x)) for xi in x_out]
print(delta)
```

Executed using `python3 memcheck_tensorflow.py`
#### Expected output:

```
some tensorflow output ...

[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
```
#### Actual output:

```
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: 
name: Tesla K40m
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:81:00.0
Total memory: 11.25GiB
Free memory: 11.15GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:81:00.0)
[28209880.0, 28208760.0, 28208760.0, 28209880.0, 28206538.0, 28208760.0, 28212806.0, 28209880.0, 28209880.0, 28208760.0, 28211926.0, 28209880.0, 28208760.0, 28209880.0, 28209880.0, 28206538.0, 28206538.0, 28209880.0, 28208760.0, 28212806.0, 28208760.0, 28209880.0, 28209880.0, 28209880.0, 28207726.0, 28208760.0, 28206538.0, 28209880.0, 28206538.0, 28210806.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209880.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28206602.0, 28209472.0, 28209472.0, 28208760.0, 28208760.0, 28209880.0, 28208760.0, 28207726.0, 28209880.0, 28208760.0, 28208760.0, 28209880.0, 28209880.0, 28206602.0, 28209880.0, 28209880.0, 28208760.0, 28209880.0, 28209880.0, 28209880.0, 28208760.0, 28206538.0, 28209880.0, 28209880.0, 28208760.0, 28208760.0, 28206602.0, 28207726.0, 28209880.0, 28207726.0, 28209880.0, 28209880.0, 28209880.0, 28211926.0, 28209880.0, 28208760.0, 28209880.0, 28208760.0, 28208760.0, 28209880.0, 28209880.0, 28209880.0, 28209880.0, 28209880.0, 28209880.0, 28206538.0, 28209880.0, 28209880.0, 28209880.0, 28209880.0, 28210806.0, 28209880.0, 28208760.0, 28208760.0, 28209880.0, 28206538.0, 28208760.0, 28209880.0, 28206602.0, 28208760.0, 28208760.0]
```
### What other attempted solutions have you tried?

I've verified that this problem exists on at least one other GPU (I've seen it on Nvidia GPUs K40m and K80).

I've run similar code in Theano without any problems (same GPU, same Docker container):

``` python
import numpy as np
import theano

mb = 100
sz = int(mb * 1e6 / 4)
total_gb = 11
n = int(total_gb / mb * 1000)
x = np.array(np.random.randn(sz), dtype=np.float32)

x_gpu = [theano.shared(x) for i in range(n)]
x_out = [v.get_value() for v in x_gpu]

delta = [np.sum(np.abs(xi - x)) for xi in x_out]
print(delta)
```

Executed using `THEANO_FLAGS=device=gpu,floatX=float32 python3 memcheck_theano.py`
#### Output

```
Using gpu device 0: Tesla K40m (CNMeM is disabled, cuDNN 5103)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
```
"
4966,Android example giving wrong results on Samsung Galaxy A3,"I've built the android demo and installed the same APK on 3 phones: Samsung S6, HTC one M9, and Samsung Galaxy A3. 
On the Galaxy A3 only the results are wrong; whereas the other phones give sensible results for various things in the office (photocopier, monitor, laptop etc) the A3 produces much lower scores and suggests things like oscillascope and nematode.

Additionally, the preview window is small and skewed. Suspecting an odd resolution might have confused things, I forced it to 640*480 but the problem persists. 

I do not know whether this is unique to the A3 .
"
4965,Feature request: Hamiltonian Monte Carlo ,"Hamiltonian Monte Carlo (HMC), also known as Hybrid Monte Carlo, is an efficient Markov Chain Monte Carlo (MCMC) method that exploits gradient information to improve on the simpler MCMC methods. See this freely available book chapter by Radford Neal:

http://www.mcmchandbook.net/HandbookChapter5.pdf

It has been successfully applied to Bayesian inference in Neural Networks, again  by Neal. See for instance Neal's thesis which later became a book:

http://www.cs.toronto.edu/~radford/ftp/thesis.pdf

HMC is heavily used in modern Bayesian modelling, For instance, HMC and its variants are the primary inference method for Stan, a popular probabilistic programming language:

http://mc-stan.org/

It would be useful to be able to use HMC in TensorFlow much as one is currently able to use Optimizers such as Adam or Momentum optimization. Much of the requisite code would be similar to the optimizer code which can be found here:

https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/training

I've raised this feature request as a place to discuss the potential addition of HMC to TensorFlow. 
"
4964,Where is the documentation for contrib/layers? (Docs in general ...),"In another thread I asked about consolidation of the builder API's for TensorFlow. (https://github.com/tensorflow/tensorflow/issues/3771)

The response was that contrib/layers was going to be one of the official builder API's to be included in TensorFlow core along with contrib/learn. So I wanted to see how it works and learn how to use it. But the only documentation I could find for contrib/layers was this:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/README.md

https://www.tensorflow.org/versions/r0.11/api_docs/python/contrib.layers.html

Is this really all the documentation there is for contrib/layers? Surely there must be more? You couldn't possibly expect people to be able to learn how to use it from these two documents alone? The README doesn't even make any sense. Am I missing something?

Please allow me a short rant.

I'm sure you're familiar with scikit-learn's beautifully designed API and extensive, polished documentation. It might serve as a good inspiration for TensorFlow. You may think that you don't have time to streamline the TensorFlow API and improve the documentation because there's more important things that must be done. But I believe this is actually the single most important thing you could do to move the project forward. Here's why:

If each new person wastes 10 hours trying to learn TensorFlow and there's 10,000 people who are learning to use it, then it's 100,000 wasted developer-hours! I actually think those numbers are very conservative. Personally I've probably wasted more than 100 hours trying to figure out how the complicated and poorly documented TensorFlow API works, and it seems there's many more than 10,000 people using TensorFlow. So maybe it's more than 1 million wasted developer-hours in total! That is 500 developer-years (assuming a month is about 160 work-hours)! Imagine if this developer-time was put into more constructive use. All it takes is for the TensorFlow API and docs to be more polished so it would be easier to learn. It would be a tiny investment in time and effort from the dev-team, compared to the return you'll get in productivity from the community. I really wish this is something you would prioritize highly.

Thanks!
"
4963,protoc failed: error executing command,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None
### Environment info

Operating System:

```
uname -a
Linux n-62-18-47 2.6.32-573.22.1.el6.x86_64 #1 SMP Tue Mar 22 17:15:28 CDT 2016 x86_64 x86_64 x86_64 GNU/Linux
```

Installed version of CUDA and cuDNN: CUDA: 8.0, cuDNN 5.0
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
ls -l /appl/cuda/8.0/lib64/libcud*
-rw-r--r-- 1 sebo root 560184 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 sebo root     16 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 sebo root     19 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 sebo root 394472 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 sebo root 737516 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart_static.a
```

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`): 8d1198374477e9c7e01893103233da984f302924
2. The output of `bazel version`

```
bazel --batch version
INFO: Reading 'startup' options from /zhome/ff/2/77654/.bazelrc: --batch --output_user_root=/work1/s123598/.bazel
Build label: 0.3.2-2016-10-13 (@2891ec5)
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Oct 13 15:05:25 2016 (1476371125)
Build timestamp: 1476371125
Build timestamp as int: 1476371125
```
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
# install tensorflow
git clone https://github.com/tensorflow/tensorflow
cd tensorflow
# set configuration parameters
export PYTHON_BIN_PATH=`which python3`
export TF_NEED_GCP=0
export TF_NEED_HDFS=0
export TF_NEED_CUDA=1
export GCC_HOST_COMPILER_PATH=`which gcc`
export TF_CUDA_VERSION=8.0
export CUDA_TOOLKIT_PATH=/appl/cuda/8.0/
export TF_CUDNN_VERSION=5
export CUDNN_INSTALL_PATH=/appl/cudnn/v5.0-prod
export TF_CUDA_COMPUTE_CAPABILITIES=""3.5,5.2""

cat > $HOME/.bazelrc <<EOF
# --batch: always run in batch mode, since there are some firewall issues.
# --output_user_root: HOME is NFS (filesystem), this will not work with bazel, use WORKDIR instead
startup --batch --output_user_root=$WORKDIR/.bazel
EOF

# one python configuration can't be set directly use yes to accept automatically
yes """" | CC=gcc CXX=g++ ./configure

# build tensorflow
CC=gcc CXX=g++ bazel build --copt=""-w"" --ignore_unsupported_sandboxing --spawn_strategy=standalone --verbose_failures \
-c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```
### What other attempted solutions have you tried?

Just getting here took some time. I had to compile bazel, pcre, swig. Put bazel in batch model and get a workdirectory that wasn't NFS. But this I have no idea how to fix.
### Logs or other output that would be helpful

full log: https://gist.github.com/AndreasMadsen/474389dc54efe948e9887eafb78679ef

```
INFO: From ProtoCompile tensorflow/core/example/example.pb.h [for host]:
bazel-out/host/genfiles/external/protobuf/src: warning: directory does not exist.
ERROR: /zhome/ff/2/77654/tensorflow/tensorflow/core/debug/BUILD:33:1: null failed: protoc failed: error executing command
  (cd /work1/s123598/.bazel/48591a606b240b3533e6a6889ad3b508/execroot/tensorflow && \
  exec env - \
  bazel-out/host/bin/external/protobuf/protoc '--cpp_out=bazel-out/local_linux-py3-opt/genfiles/' '--plugin=protoc-gen-grpc=bazel-out/host/bin/external/grpc/grpc_cpp_plugin' '--grpc_out=bazel-out/local_linux-py3-opt/genfiles/' -I. -Iexternal/protobuf/src -Ibazel-out/local_linux-py3-opt/genfiles/external/protobuf/src tensorflow/core/debug/debug_service.proto): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
bazel-out/local_linux-py3-opt/genfiles/external/protobuf/src: warning: directory does not exist.
bazel-out/host/bin/external/grpc/grpc_cpp_plugin: program not found or is not executable
--grpc_out: protoc-gen-grpc: Plugin failed with status code 1.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: /zhome/ff/2/77654/tensorflow/tensorflow/tools/pip_package/BUILD:23:1 null failed: protoc failed: error executing command
  (cd /work1/s123598/.bazel/48591a606b240b3533e6a6889ad3b508/execroot/tensorflow && \
  exec env - \
  bazel-out/host/bin/external/protobuf/protoc '--cpp_out=bazel-out/local_linux-py3-opt/genfiles/' '--plugin=protoc-gen-grpc=bazel-out/host/bin/external/grpc/grpc_cpp_plugin' '--grpc_out=bazel-out/local_linux-py3-opt/genfiles/' -I. -Iexternal/protobuf/src -Ibazel-out/local_linux-py3-opt/genfiles/external/protobuf/src tensorflow/core/debug/debug_service.proto): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
INFO: Elapsed time: 189.979s, Critical Path: 68.86s
```
"
4960,distributed inception was killed,"# problem

when I startup a distributed inception on a single machine with one ps and two workers, i.e. `ps:192.168.184.33:9000; worker:192.168.184.33:9001,192.168.184.33:9001`, after a few steps, the ps and workers was killed

ps says:

``` shell
*** Error in `/usr/bin/python': invalid fastbin entry (free): 0x00007fafdd048f30 ***
======= Backtrace: =========
/lib64/libc.so.6(+0x7d023)[0x7fb1035cd023]
/export/wangqingze/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so(_ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0x3e6)[0x7fb0ecf0a466]
/export/wangqingze/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x22)[0x7fb0ecf09c12]
/lib64/libstdc++.so.6(+0xb5220)[0x7fb0ea555220]
/lib64/libpthread.so.0(+0x7dc5)[0x7fb104021dc5]
/lib64/libc.so.6(clone+0x6d)[0x7fb10364628d]
======= Memory map: ========
00400000-00401000 r-xp 00000000 08:02 67430429                           /usr/bin/python2.7
00600000-00601000 r--p 00000000 08:02 67430429                           /usr/bin/python2.7
00601000-00602000 rw-p 00001000 08:02 67430429                           /usr/bin/python2.7
01c63000-0713e000 rw-p 00000000 00:00 0                                  [heap]
7faf94000000-7faf94103000 rw-p 00000000 00:00 0 
7faf94103000-7faf98000000 ---p 00000000 00:00 0 
7faf985c4000-7faf985c5000 ---p 00000000 00:00 0 
7faf985c5000-7faf98dc5000 rwxp 00000000 00:00 0 
7faf98dc5000-7fafa0000000 rw-p 00000000 00:00 0 
7fafa0000000-7fafa1850000 rw-p 00000000 00:00 0 
7fafa1850000-7fafa4000000 ---p 00000000 00:00 0 
7fafa4023000-7fafa8000000 rw-p 00000000 00:00 0 
7fafa8000000-7fafa8768000 rw-p 00000000 00:00 0 
7fafa8768000-7fafac000000 ---p 00000000 00:00 0 
7fafac000000-7fafaffff000 rw-p 00000000 00:00 0 
7fafaffff000-7fafb0000000 ---p 00000000 00:00 0 
7fafb0033000-7fafb2ffe000 rw-p 00000000 00:00 0 
7fafb2ffe000-7fafb2fff000 ---p 00000000 00:00 0 
7fafb2fff000-7fafb37ff000 rwxp 00000000 00:00 0                          [stack:9683]
7fafb37ff000-7fafb3800000 ---p 00000000 00:00 0 
7fafb3800000-7fafb4000000 rwxp 00000000 00:00 0                          [stack:9682]
7fafb4000000-7fafb7fe4000 rw-p 00000000 00:00 0 
7fafb7fe4000-7fafb8000000 ---p 00000000 00:00 0 
7fafb8000000-7fafbbf9c000 rw-p 00000000 00:00 0 
7fafbbf9c000-7fafbc000000 ---p 00000000 00:00 0 
7fafbc000000-7fafbff77000 rw-p 00000000 00:00 0 
7fafbff77000-7fafc0000000 ---p 00000000 00:00 0 
7fafc0000000-7fafc3ff0000 rw-p 00000000 00:00 0 
7fafc3ff0000-7fafc4000000 ---p 00000000 00:00 0 
7fafc4000000-7fafc7ffb000 rw-p 00000000 00:00 0 
7fafc7ffb000-7fafc8000000 ---p 00000000 00:00 0 
7fafc8000000-7fafcbfee000 rw-p 00000000 00:00 0 
7fafcbfee000-7fafcc000000 ---p 00000000 00:00 0 
7fafcc000000-7fafcffc5000 rw-p 00000000 00:00 0 
7fafcffc5000-7fafd0000000 ---p 00000000 00:00 0 
7fafd0024000-7fafd07f9000 rw-p 00000000 00:00 0 
7fafd07f9000-7fafd07fa000 ---p 00000000 00:00 0 
7fafd07fa000-7fafd0ffa000 rwxp 00000000 00:00 0                          [stack:9681]
7fafd0ffa000-7fafd0ffb000 ---p 00000000 00:00 0 
7fafd0ffb000-7fafd17fb000 rwxp 00000000 00:00 0                          [stack:9680]
7fafd17fb000-7fafd17fc000 ---p 00000000 00:00 0 
7fafd17fc000-7fafd1ffc000 rwxp 00000000 00:00 0                          [stack:9679]
7fafd1ffc000-7fafd1ffd000 ---p 00000000 00:00 0 
7fafd1ffd000-7fafd27fd000 rwxp 00000000 00:00 0                          [stack:9678]
7fafd27fd000-7fafd27fe000 ---p 00000000 00:00 0 
7fafd27fe000-7fafd2ffe000 rwxp 00000000 00:00 0                          [stack:9677]
7fafd2ffe000-7fafd2fff000 ---p 00000000 00:00 0 
7fafd2fff000-7fafd37ff000 rwxp 00000000 00:00 0                          [stack:9676]
7fafd37ff000-7fafd3800000 ---p 00000000 00:00 0 
7fafd3800000-7fafd4000000 rwxp 00000000 00:00 0                          [stack:9675]
7fafd4000000-7fafd7ff9000 rw-p 00000000 00:00 0 
7fafd7ff9000-7fafd8000000 ---p 00000000 00:00 0 
7fafd8000000-7fafdbfdf000 rw-p 00000000 00:00 0 
7fafdbfdf000-7fafdc000000 ---p 00000000 00:00 0 
7fafdc000000-7fafdfff4000 rw-p 00000000 00:00 0 
7fafdfff4000-7fafe0000000 ---p 00000000 00:00 0 
7fafe0000000-7fafe3f6c000 rw-p 00000000 00:00 0 
7fafe3f6c000-7fafe4000000 ---p 00000000 00:00 0 
7fafe4000000-7fafe7f23000 rw-p 00000000 00:00 0 
7fafe7f23000-7fafe8000000 ---p 00000000 00:00 0 
7fafe8000000-7fafebfca000 rw-p 00000000 00:00 0 
7fafebfca000-7fafec000000 ---p 00000000 00:00 0 
7fafec000000-7fafeffd5000 rw-p 00000000 00:00 0 
7fafeffd5000-7faff0000000 ---p 00000000 00:00 0 
7faff002f000-7faff07f9000 rw-p 00000000 00:00 0 
7faff07f9000-7faff07fa000 ---p 00000000 00:00 0 
7faff07fa000-7faff0ffa000 rwxp 00000000 00:00 0                          [stack:9674]
7faff0ffa000-7faff0ffb000 ---p 00000000 00:00 0 
7faff0ffb000-7faff17fb000 rwxp 00000000 00:00 0                          [stack:9673]
7faff17fb000-7faff17fc000 ---p 00000000 00:00 0 
7faff17fc000-7faff1ffc000 rwxp 00000000 00:00 0                          [stack:9672]
7faff1ffc000-7faff1ffd000 ---p 00000000 00:00 0 
7faff1ffd000-7faff27fd000 rwxp 00000000 00:00 0                          [stack:9671]
7faff27fd000-7faff27fe000 ---p 00000000 00:00 0 
7faff27fe000-7faff2ffe000 rwxp 00000000 00:00 0                          [stack:9670]
7faff2ffe000-7faff2fff000 ---p 00000000 00:00 0 
7faff2fff000-7faff37ff000 rwxp 00000000 00:00 0                          [stack:9669]
7faff37ff000-7faff3800000 ---p 00000000 00:00 0 
7faff3800000-7faff4000000 rwxp 00000000 00:00 0                          [stack:9668]
7faff4000000-7faff7fd9000 rw-p 00000000 00:00 0 
7faff7fd9000-7faff8000000 ---p 00000000 00:00 0 
7faff8000000-7faffbff6000 rw-p 00000000 00:00 0 
7faffbff6000-7faffc000000 ---p 00000000 00:00 0 
7faffc000000-7faffffae000 rw-p 00000000 00:00 0 
7faffffae000-7fb000000000 ---p 00000000 00:00 0 
7fb000000000-7fb003ff5000 rw-p 00000000 00:00 0 
7fb003ff5000-7fb004000000 ---p 00000000 00:00 0 
7fb004000000-7fb007f7f000 rw-p 00000000 00:00 0 
7fb007f7f000-7fb008000000 ---p 00000000 00:00 0 
7fb008000000-7fb00bfee000 rw-p 00000000 00:00 0 
7fb00bfee000-7fb00c000000 ---p 00000000 00:00 0 
7fb00c000000-7fb00ffca000 rw-p 00000000 00:00 0 
7fb00ffca000-7fb010000000 ---p 00000000 00:00 0 
7fb010000000-7fb013fec000 rw-p 00000000 00:00 0 
7fb013fec000-7fb014000000 ---p 00000000 00:00 0 
7fb01402f000-7fb0147f9000 rw-p 00000000 00:00 0 
7fb0147f9000-7fb0147fa000 ---p 00000000 00:00 0 
7fb0147fa000-7fb014ffa000 rwxp 00000000 00:00 0                          [stack:9667]
7fb014ffa000-7fb014ffb000 ---p 00000000 00:00 0 
7fb014ffb000-7fb0157fb000 rwxp 00000000 00:00 0                          [stack:9666]
7fb0157fb000-7fb0157fc000 ---p 00000000 00:00 0 
7fb0157fc000-7fb015ffc000 rwxp 00000000 00:00 0                          [stack:9665]
7fb015ffc000-7fb015ffd000 ---p 00000000 00:00 0 
7fb015ffd000-7fb0167fd000 rwxp 00000000 00:00 0                          [stack:9664]
7fb0167fd000-7fb0167fe000 ---p 00000000 00:00 0 
7fb0167fe000-7fb016ffe000 rwxp 00000000 00:00 0                          [stack:9663]
7fb016ffe000-7fb016fff000 ---p 00000000 00:00 0 
7fb016fff000-7fb0177ff000 rwxp 00000000 00:00 0                          [stack:9662]
7fb0177ff000-7fb017800000 ---p 00000000 00:00 0 
7fb017800000-7fb018000000 rwxp 00000000 00:00 0                          [stack:9661]
7fb018000000-7fb01bfef000 rw-p 00000000 00:00 0 
7fb01bfef000-7fb01c000000 ---p 00000000 00:00 0 
7fb01c000000-7fb01fffa000 rw-p 00000000 00:00 0 
7fb01fffa000-7fb020000000 ---p 00000000 00:00 0 
7fb020000000-7fb023f75000 rw-p 00000000 00:00 0 
7fb023f75000-7fb024000000 ---p 00000000 00:00 0 
7fb024000000-7fb027fb0000 rw-p 00000000 00:00 0 
7fb027fb0000-7fb028000000 ---p 00000000 00:00 0 
7fb028000000-7fb02bffa000 rw-p 00000000 00:00 0 
7fb02bffa000-7fb02c000000 ---p 00000000 00:00 0 
7fb02c000000-7fb02fe64000 rw-p 00000000 00:00 0 
7fb02fe64000-7fb030000000 ---p 00000000 00:00 0 
7fb030000000-7fb033ff8000 rw-p 00000000 00:00 0 
7fb033ff8000-7fb034000000 ---p 00000000 00:00 0 
7fb034000000-7fb038000000 rw-p 00000000 00:00 0 
7fb038044000-7fb0387f9000 rw-p 00000000 00:00 0 
7fb0387f9000-7fb0387fa000 ---p 00000000 00:00 0 
7fb0387fa000-7fb038ffa000 rwxp 00000000 00:00 0                          [stack:9660]
7fb038ffa000-7fb038ffb000 ---p 00000000 00:00 0 
7fb038ffb000-7fb0397fb000 rwxp 00000000 00:00 0                          [stack:9659]
7fb0397fb000-7fb0397fc000 ---p 00000000 00:00 0 
7fb0397fc000-7fb039ffc000 rwxp 00000000 00:00 0                          [stack:9658]
7fb039ffc000-7fb039ffd000 ---p 00000000 00:00 0 
7fb039ffd000-7fb03a7fd000 rwxp 00000000 00:00 0                          [stack:9657]
7fb03a7fd000-7fb03a7fe000 ---p 00000000 00:00 0 
7fb03a7fe000-7fb03affe000 rwxp 00000000 00:00 0                          [stack:9656]
7fb03affe000-7fb03afff000 ---p 00000000 00:00 0 
7fb03afff000-7fb03b7ff000 rwxp 00000000 00:00 0                          [stack:9655]
7fb03b7ff000-7fb03b800000 ---p 00000000 00:00 0 
7fb03b800000-7fb03c000000 rwxp 00000000 00:00 0                          [stack:9654]
7fb03c000000-7fb040000000 rw-p 00000000 00:00 0 
7fb040000000-7fb043fde000 rw-p 00000000 00:00 0 
7fb043fde000-7fb044000000 ---p 00000000 00:00 0 
7fb044000000-7fb044021000 rw-p 00000000 00:00 0 
7fb044021000-7fb048000000 ---p 00000000 00:00 0 
7fb048000000-7fb048021000 rw-p 00000000 00:00 0 
7fb048021000-7fb04c000000 ---p 00000000 00:00 0 
7fb04c000000-7fb04c021000 rw-p 00000000 00:00 0 
7fb04c021000-7fb050000000 ---p 00000000 00:00 0 
7fb050026000-7fb0507f9000 rw-p 00000000 00:00 0 
7fb0507f9000-7fb0507fa000 ---p 00000000 00:00 0 
7fb0507fa000-7fb050ffa000 rwxp 00000000 00:00 0                          [stack:9653]
7fb050ffa000-7fb050ffb000 ---p 00000000 00:00 0 
7fb050ffb000-7fb0517fb000 rwxp 00000000 00:00 0                          [stack:9652]
7fb0517fb000-7fb0517fc000 ---p 00000000 00:00 0 
7fb0517fc000-7fb051ffc000 rwxp 00000000 00:00 0                          [stack:9651]
7fb051ffc000-7fb051ffd000 ---p 00000000 00:00 0 
7fb051ffd000-7fb0527fd000 rwxp 00000000 00:00 0                          [stack:9650]
7fb0527fd000-7fb0527fe000 ---p 00000000 00:00 0 
7fb0527fe000-7fb052ffe000 rwxp 00000000 00:00 0                          [stack:9649]
7fb052ffe000-7fb052fff000 ---p 00000000 00:00 0 
7fb052fff000-7fb0537ff000 rwxp 00000000 00:00 0                          [stack:9648]
7fb0537ff000-7fb053800000 ---p 00000000 00:00 0 
7fb053800000-7fb054000000 rwxp 00000000 00:00 0                          [stack:9647]
7fb054000000-7fb054021000 rw-p 00000000 00:00 0 
7fb054021000-7fb058000000 ---p 00000000 00:00 0 
7fb058000000-7fb058021000 rw-p 00000000 00:00 0 
7fb058021000-7fb05c000000 ---p 00000000 00:00 0 
7fb05c000000-7fb05c021000 rw-p 00000000 00:00 0 
7fb05c021000-7fb060000000 ---p 00000000 00:00 0 
7fb060000000-7fb060021000 rw-p 00000000 00:00 0 
7fb060021000-7fb064000000 ---p 00000000 00:00 0 
7fb064000000-7fb064021000 rw-p 00000000 00:00 0 
7fb064021000-7fb068000000 ---p 00000000 00:00 0 
7fb068000000-7fb068021000 rw-p 00000000 00:00 0 
7fb068021000-7fb06c000000 ---p 00000000 00:00 0 
7fb06c000000-7fb06c021000 rw-p 00000000 00:00 0 
7fb06c021000-7fb070000000 ---p 00000000 00:00 0 
7fb070000000-7fb070021000 rw-p 00000000 00:00 0 
7fb070021000-7fb074000000 ---p 00000000 00:00 0 
7fb074000000-7fb074021000 rw-p 00000000 00:00 0 
7fb074021000-7fb078000000 ---p 00000000 00:00 0 
7fb078000000-7fb078021000 rw-p 00000000 00:00 0 
7fb078021000-7fb07c000000 ---p 00000000 00:00 0 
7fb07c000000-7fb07c021000 rw-p 00000000 00:00 0 
7fb07c021000-7fb080000000 ---p 00000000 00:00 0 
7fb080000000-7fb080021000 rw-p 00000000 00:00 0 
7fb080021000-7fb084000000 ---p 00000000 00:00 0 
7fb084000000-7fb084021000 rw-p 00000000 00:00 0 
7fb084021000-7fb088000000 ---p 00000000 00:00 0 
7fb088026000-7fb0887f9000 rw-p 00000000 00:00 0 
7fb0887f9000-7fb0887fa000 ---p 00000000 00:00 0 
7fb0887fa000-7fb088ffa000 rwxp 00000000 00:00 0                          [stack:9646]
7fb088ffa000-7fb088ffb000 ---p 00000000 00:00 0 
7fb088ffb000-7fb0897fb000 rwxp 00000000 00:00 0                          [stack:9645]
7fb0897fb000-7fb0897fc000 ---p 00000000 00:00 0 
7fb0897fc000-7fb089ffc000 rwxp 00000000 00:00 0                          [stack:9644]
7fb089ffc000-7fb089ffd000 ---p 00000000 00:00 0 
7fb089ffd000-7fb08a7fd000 rwxp 00000000 00:00 0                          [stack:9643]
7fb08a7fd000-7fb08a7fe000 ---p 00000000 00:00 0 
7fb08a7fe000-7fb08affe000 rwxp 00000000 00:00 0                          [stack:9642]
7fb08affe000-7fb08afff000 ---p 00000000 00:00 0 
7fb08afff000-7fb08b7ff000 rwxp 00000000 00:00 0                          [stack:9641]
7fb08b7ff000-7fb08b800000 ---p 00000000 00:00 0 
7fb08b800000-7fb08c000000 rwxp 00000000 00:00 0                          [stack:9640]
7fb08c000000-7fb08c021000 rw-p 00000000 00:00 0 
7fb08c021000-7fb090000000 ---p 00000000 00:00 0 
7fb090000000-7fb090021000 rw-p 00000000 00:00 0 
7fb090021000-7fb094000000 ---p 00000000 00:00 0 
7fb094085000-7fb0947f9000 rw-p 00000000 00:00 0 
7fb0947f9000-7fb0947fa000 ---p 00000000 00:00 0 
7fb0947fa000-7fb094ffa000 rwxp 00000000 00:00 0                          [stack:9639]
7fb094ffa000-7fb094ffb000 ---p 00000000 00:00 0 
7fb094ffb000-7fb0957fb000 rwxp 00000000 00:00 0                          [stack:9638]
7fb0957fb000-7fb0957fc000 ---p 00000000 00:00 0 
7fb0957fc000-7fb095ffc000 rwxp 00000000 00:00 0                          [stack:9637]
7fb095ffc000-7fb095ffd000 ---p 00000000 00:00 0 
7fb095ffd000-7fb0967fd000 rwxp 00000000 00:00 0                          [stack:9636]
7fb0967fd000-7fb0967fe000 ---p 00000000 00:00 0 
7fb0967fe000-7fb096ffe000 rwxp 00000000 00:00 0                          [stack:9635]
7fb096ffe000-7fb096fff000 ---p 00000000 00:00 0 
7fb096fff000-7fb0977ff000 rwxp 00000000 00:00 0                          [stack:9634]
7fb0977ff000-7fb097800000 ---p 00000000 00:00 0 
7fb097800000-7fb098000000 rwxp 00000000 00:00 0                          [stack:9633]
7fb098000000-7fb098021000 rw-p 00000000 00:00 0 
7fb098021000-7fb09c000000 ---p 00000000 00:00 0 
7fb09c000000-7fb09c021000 rw-p 00000000 00:00 0 
7fb09c021000-7fb0a0000000 ---p 00000000 00:00 0 
7fb0a0000000-7fb0a0021000 rw-p 00000000 00:00 0 
7fb0a0021000-7fb0a4000000 ---p 00000000 00:00 0 
7fb0a4000000-7fb0a4021000 rw-p 00000000 00:00 0 
7fb0a4021000-7fb0a8000000 ---p 00000000 00:00 0 
7fb0a8000000-7fb0a8021000 rw-p 00000000 00:00 0 
7fb0a8021000-7fb0ac000000 ---p 00000000 00:00 0 
7fb0ac000000-7fb0ac021000 rw-p 00000000 00:00 0 
7fb0ac021000-7fb0b0000000 ---p 00000000 00:00 0 
7fb0b0000000-7fb0b0021000 rw-p 00000000 00:00 0 
7fb0b0021000-7fb0b4000000 ---p 00000000 00:00 0 
7fb0b4000000-7fb0b4021000 rw-p 00000000 00:00 0 
7fb0b4021000-7fb0b8000000 ---p 00000000 00:00 0 
7fb0b8000000-7fb0b8021000 rw-p 00000000 00:00 0 
7fb0b8021000-7fb0bc000000 ---p 00000000 00:00 0 
7fb0bc000000-7fb0bc021000 rw-p 00000000 00:00 0 
7fb0bc021000-7fb0c0000000 ---p 00000000 00:00 0 
7fb0c0000000-7fb0c0021000 rw-p 00000000 00:00 0 
7fb0c0021000-7fb0c4000000 ---p 00000000 00:00 0 
7fb0c4000000-7fb0c4021000 rw-p 00000000 00:00 0 
7fb0c4021000-7fb0c8000000 ---p 00000000 00:00 0 
7fb0c8000000-7fb0c8021000 rw-p 00000000 00:00 0 
7fb0c8021000-7fb0cc000000 ---p 00000000 00:00 0 
7fb0cc045000-7fb0cc046000 ---p 00000000 00:00 0 
7fb0cc046000-7fb0cc846000 rwxp 00000000 00:00 0                          [stack:9632]
7fb0cc846000-7fb0cc847000 ---p 00000000 00:00 0 
7fb0cc847000-7fb0cd047000 rwxp 00000000 00:00 0                          [stack:9631]
7fb0cd047000-7fb0cd048000 ---p 00000000 00:00 0 
7fb0cd048000-7fb0cd848000 rwxp 00000000 00:00 0                          [stack:9630]
7fb0cd848000-7fb0cd849000 ---p 00000000 00:00 0 
7fb0cd849000-7fb0ce049000 rwxp 00000000 00:00 0                          [stack:9629]
7fb0ce049000-7fb0ce04a000 ---p 00000000 00:00 0 
7fb0ce04a000-7fb0ce84a000 rwxp 00000000 00:00 0                          [stack:9621]
7fb0ce8fc000-7fb0ceffe000 rw-p 00000000 00:00 0 
7fb0ceffe000-7fb0cefff000 ---p 00000000 00:00 0 
7fb0cefff000-7fb0cf7ff000 rwxp 00000000 00:00 0                          [stack:9628]
7fb0cf7ff000-7fb0cf800000 ---p 00000000 00:00 0 
7fb0cf800000-7fb0d0000000 rwxp 00000000 00:00 0                          [stack:9627]
7fb0d0000000-7fb0d0021000 rw-p 00000000 00:00 0 
7fb0d0021000-7fb0d4000000 ---p 00000000 00:00 0 
7fb0d4045000-7fb0d4046000 ---p 00000000 00:00 0 
7fb0d4046000-7fb0d4846000 rwxp 00000000 00:00 0                          [stack:9626]
7fb0d4846000-7fb0d4847000 ---p 00000000 00:00 0 
7fb0d4847000-7fb0d5047000 rwxp 00000000 00:00 0                          [stack:9625]
7fb0d5047000-7fb0d5048000 ---p 00000000 00:00 0 
7fb0d5048000-7fb0d5848000 rwxp 00000000 00:00 0                          [stack:9624]
7fb0d5848000-7fb0d5849000 ---p 00000000 00:00 0 
7fb0d5849000-7fb0d6049000 rwxp 00000000 00:00 0                          [stack:9623]
7fb0d6049000-7fb0d604a000 ---p 00000000 00:00 0 
7fb0d604a000-7fb0d684a000 rwxp 00000000 00:00 0                          [stack:9622]
7fb0d684a000-7fb0d684b000 ---p 00000000 00:00 0 
7fb0d684b000-7fb0d704b000 rwxp 00000000 00:00 0                          [stack:9620]
7fb0d704b000-7fb0d704c000 ---p 00000000 00:00 0 
7fb0d704c000-7fb0d784c000 rwxp 00000000 00:00 0                          [stack:9619]
7fb0d784c000-7fb0d784d000 ---p 00000000 00:00 0 
7fb0d784d000-7fb0d804d000 rwxp 00000000 00:00 0                          [stack:9618]
7fb0d804d000-7fb0d804e000 ---p 00000000 00:00 0 
7fb0d804e000-7fb0d884e000 rwxp 00000000 00:00 0                          [stack:9617]
7fb0d884e000-7fb0d8856000 r-xp 00000000 08:02 101040862                  /usr/lib64/python2.7/lib-dynload/_json.so
7fb0d8856000-7fb0d8a55000 ---p 00008000 08:02 101040862                  /usr/lib64/python2.7/lib-dynload/_json.so
7fb0d8a55000-7fb0d8a56000 r--p 00007000 08:02 101040862                  /usr/lib64/python2.7/lib-dynload/_json.so
7fb0d8a56000-7fb0d8a57000 rw-p 00008000 08:02 101040862                  /usr/lib64/python2.7/lib-dynload/_json.so
7fb0d8a57000-7fb0d8d58000 rw-p 00000000 00:00 0 
7fb0d8d58000-7fb0d8d5c000 r-xp 00000000 08:02 100710418                  /usr/lib64/libuuid.so.1.3.0
7fb0d8d5c000-7fb0d8f5b000 ---p 00004000 08:02 100710418                  /usr/lib64/libuuid.so.1.3.0
7fb0d8f5b000-7fb0d8f5c000 r--p 00003000 08:02 100710418                  /usr/lib64/libuuid.so.1.3.0
7fb0d8f5c000-7fb0d8f5d000 rw-p 00004000 08:02 100710418                  /usr/lib64/libuuid.so.1.3.0
7fb0d8f5d000-7fb0d9020000 rw-p 00000000 00:00 0 
7fb0d905a000-7fb0d90dc000 rw-p 00000000 00:00 0 
7fb0d90dc000-7fb0d90e0000 r-xp 00000000 08:02 101040863                  /usr/lib64/python2.7/lib-dynload/_localemodule.so
7fb0d90e0000-7fb0d92df000 ---p 00004000 08:02 101040863                  /usr/lib64/python2.7/lib-dynload/_localemodule.so
7fb0d92df000-7fb0d92e0000 r--p 00003000 08:02 101040863                  /usr/lib64/python2.7/lib-dynload/_localemodule.so
7fb0d92e0000-7fb0d92e1000 rw-p 00004000 08:02 101040863                  /usr/lib64/python2.7/lib-dynload/_localemodule.so
7fb0d92e1000-7fb0d9363000 rw-p 00000000 00:00 0 
7fb0d9363000-7fb0d9376000 r-xp 00000000 08:02 104223611                  /usr/lib64/python2.7/lib-dynload/_ssl.so
7fb0d9376000-7fb0d9575000 ---p 00013000 08:02 104223611                  /usr/lib64/python2.7/lib-dynload/_ssl.so
7fb0d9575000-7fb0d9576000 r--p 00012000 08:02 104223611                  /usr/lib64/python2.7/lib-dynload/_ssl.so
7fb0d9576000-7fb0d957a000 rw-p 00013000 08:02 104223611                  /usr/lib64/python2.7/lib-dynload/_ssl.so
7fb0d957a000-7fb0d9589000 r-xp 00000000 08:02 101576783                  /usr/lib64/python2.7/lib-dynload/_socketmodule.so
7fb0d9589000-7fb0d9788000 ---p 0000f000 08:02 101576783                  /usr/lib64/python2.7/lib-dynload/_socketmodule.so
7fb0d9788000-7fb0d9789000 r--p 0000e000 08:02 101576783                  /usr/lib64/python2.7/lib-dynload/_socketmodule.so
7fb0d9789000-7fb0d978e000 rw-p 0000f000 08:02 101576783                  /usr/lib64/python2.7/lib-dynload/_socketmodule.so
7fb0d978e000-7fb0d97cf000 rw-p 00000000 00:00 0 
7fb0d97cf000-7fb0d97d3000 r-xp 00000000 08:02 104223823                  /usr/lib64/python2.7/lib-dynload/zlibmodule.so
7fb0d97d3000-7fb0d99d2000 ---p 00004000 08:02 104223823                  /usr/lib64/python2.7/lib-dynload/zlibmodule.so
7fb0d99d2000-7fb0d99d3000 r--p 00003000 08:02 104223823                  /usr/lib64/python2.7/lib-dynload/zlibmodule.so
7fb0d99d3000-7fb0d99d5000 rw-p 00004000 08:02 104223823                  /usr/lib64/python2.7/lib-dynload/zlibmodule.so
7fb0d99d5000-7fb0d9a16000 rw-p 00000000 00:00 0 
7fb0d9a16000-7fb0db7a3000 r-xp 00000000 08:02 34762224                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcurand.so.7.5.18
7fb0db7a3000-7fb0db9a3000 ---p 01d8d000 08:02 34762224                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcurand.so.7.5.18
7fb0db9a3000-7fb0dcd74000 rw-p 01d8d000 08:02 34762224                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcurand.so.7.5.18
7fb0dcd74000-7fb0dd27e000 rw-p 00000000 00:00 0 
7fb0dd27e000-7fb0dde60000 r-xp 00000000 08:02 40780306                   /usr/lib64/nvidia/libcuda.so.352.79
7fb0dde60000-7fb0de05f000 ---p 00be2000 08:02 40780306                   /usr/lib64/nvidia/libcuda.so.352.79
7fb0de05f000-7fb0de21d000 rw-p 00be1000 08:02 40780306                   /usr/lib64/nvidia/libcuda.so.352.79
7fb0de21d000-7fb0de233000 rw-p 00000000 00:00 0 
7fb0de233000-7fb0e4ba3000 r-xp 00000000 08:02 37679427                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcufft.so.7.5.18
7fb0e4ba3000-7fb0e4da2000 ---p 06970000 08:02 37679427                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcufft.so.7.5.18
7fb0e4da2000-7fb0e4e47000 rw-p 0696f000 08:02 37679427                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcufft.so.7.5.18
7fb0e4e47000-7fb0e4e6e000 rw-p 00000000 00:00 0 
7fb0e4e6e000-7fb0e8780000 r-xp 00000000 08:02 34912963                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudnn.so
7fb0e8780000-7fb0e897f000 ---p 03912000 08:02 34912963                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudnn.so
7fb0e897f000-7fb0e8990000 rw-p 03911000 08:02 34912963                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudnn.so
7fb0e8990000-7fb0e89b9000 rw-p 00000000 00:00 0 
7fb0e89b9000-7fb0ea082000 r-xp 00000000 08:02 37679451                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcublas.so.7.5.18
7fb0ea082000-7fb0ea281000 ---p 016c9000 08:02 37679451                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcublas.so.7.5.18
7fb0ea281000-7fb0ea28d000 rw-p 016c8000 08:02 37679451                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcublas.so.7.5.18
7fb0ea28d000-7fb0ea298000 rw-p 00000000 00:00 0 
7fb0ea298000-7fb0ea29f000 r-xp 00000000 08:02 100671127                  /usr/lib64/librt-2.17.so
7fb0ea29f000-7fb0ea49e000 ---p 00007000 08:02 100671127                  /usr/lib64/librt-2.17.so
7fb0ea49e000-7fb0ea49f000 r--p 00006000 08:02 100671127                  /usr/lib64/librt-2.17.so
7fb0ea49f000-7fb0ea4a0000 rw-p 00007000 08:02 100671127                  /usr/lib64/librt-2.17.so
7fb0ea4a0000-7fb0ea589000 r-xp 00000000 08:02 100710424                  /usr/lib64/libstdc++.so.6.0.19
7fb0ea589000-7fb0ea789000 ---p 000e9000 08:02 100710424                  /usr/lib64/libstdc++.so.6.0.19
7fb0ea789000-7fb0ea791000 r--p 000e9000 08:02 100710424                  /usr/lib64/libstdc++.so.6.0.19
7fb0ea791000-7fb0ea793000 rw-p 000f1000 08:02 100710424                  /usr/lib64/libstdc++.so.6.0.19
7fb0ea793000-7fb0ea7a8000 rw-p 00000000 00:00 0 
7fb0ea7a8000-7fb0ea803000 r-xp 00000000 08:02 40780164                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5.18
7fb0ea803000-7fb0eaa02000 ---p 0005b000 08:02 40780164                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5.18
7fb0eaa02000-7fb0eaa06000 rw-p 0005a000 08:02 40780164                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5.18
7fb0eaa06000-7fb0f53ba000 r-xp 00000000 08:05 300654753                  /export/wangqingze/bazel_output/505f9aca2a9fc3d10d7d985215ae4971/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow.so
7fb0f53ba000-7fb0f55ba000 ---p 0a9b4000 08:05 300654753                  /export/wangqingze/bazel_output/505f9aca2a9fc3d10d7d985215ae4971/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow.so
7fb0f55ba000-7fb0f567d000 r--p 0a9b4000 08:05 300654753                  /export/wangqingze/bazel_output/505f9aca2a9fc3d10d7d985215ae4971/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow.so
7fb0f567d000-7fb0f5681000 rw-p 0aa77000 08:05 300654753                  /export/wangqingze/bazel_output/505f9aca2a9fc3d10d7d985215ae4971/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow.so
7fb0f5681000-7fb0f5f6e000 rw-p 00000000 00:00 0 
7fb0f5fa5000-7fb0f601d000 r-xp 00000000 08:02 6969005                    /usr/lib/python2.7/site-packages/numpy/random/mtrand.so
7fb0f601d000-7fb0f621c000 ---p 00078000 08:02 6969005                    /usr/lib/python2.7/site-packages/numpy/random/mtrand.so
7fb0f621c000-7fb0f621d000 r--p 00077000 08:02 6969005                    /usr/lib/python2.7/site-packages/numpy/random/mtrand.so
7fb0f621d000-7fb0f6258000 rw-p 00078000 08:02 6969005                    /usr/lib/python2.7/site-packages/numpy/random/mtrand.so
7fb0f6258000-7fb0f629a000 rw-p 00000000 00:00 0 
7fb0f629a000-7fb0f62a3000 r-xp 00000000 08:02 105561601                  /usr/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so
7fb0f62a3000-7fb0f64a2000 ---p 00009000 08:02 105561601                  /usr/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so
7fb0f64a2000-7fb0f64a3000 r--p 00008000 08:02 105561601                  /usr/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so
7fb0f64a3000-7fb0f64a4000 rw-p 00009000 08:02 105561601                  /usr/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so
7fb0f64a4000-7fb0f64a5000 r-xp 00000000 08:02 104223623                  /usr/lib64/python2.7/lib-dynload/future_builtins.so
7fb0f64a5000-7fb0f66a4000 ---p 00001000 08:02 104223623                  /usr/lib64/python2.7/lib-dynload/future_builtins.so
7fb0f66a4000-7fb0f66a5000 r--p 00000000 08:02 104223623                  /usr/lib64/python2.7/lib-dynload/future_builtins.so
7fb0f66a5000-7fb0f66a6000 rw-p 00001000 08:02 104223623                  /usr/lib64/python2.7/lib-dynload/future_builtins.so
7fb0f66a6000-7fb0f66e7000 rw-p 00000000 00:00 0 
7fb0f66e7000-7fb0f670f000 r-xp 00000000 08:02 6968988                    /usr/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so
7fb0f670f000-7fb0f690e000 ---p 00028000 08:02 6968988                    /usr/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so
7fb0f690e000-7fb0f690f000 r--p 00027000 08:02 6968988                    /usr/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so
7fb0f690f000-7fb0f6910000 rw-p 00028000 08:02 6968988                    /usr/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so
7fb0f6910000-7fb0f6913000 r-xp 00000000 08:02 6968987                    /usr/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so
7fb0f6913000-7fb0f6b13000 ---p 00003000 08:02 6968987                    /usr/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so
7fb0f6b13000-7fb0f6b14000 r--p 00003000 08:02 6968987                    /usr/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so
7fb0f6b14000-7fb0f6b15000 rw-p 00004000 08:02 6968987                    /usr/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so
7fb0f6b15000-7fb0f6b56000 rw-p 00000000 00:00 0 
7fb0f6b56000-7fb0f6b59000 r-xp 00000000 08:02 101801477                  /usr/lib64/python2.7/lib-dynload/fcntlmodule.so
7fb0f6b59000-7fb0f6d58000 ---p 00003000 08:02 101801477                  /usr/lib64/python2.7/lib-dynload/fcntlmodule.so
7fb0f6d58000-7fb0f6d59000 r--p 00002000 08:02 101801477                  /usr/lib64/python2.7/lib-dynload/fcntlmodule.so
7fb0f6d59000-7fb0f6d5a000 rw-p 00003000 08:02 101801477                  /usr/lib64/python2.7/lib-dynload/fcntlmodule.so
7fb0f6d5a000-7fb0f6d5d000 r-xp 00000000 08:02 101040906                  /usr/lib64/python2.7/lib-dynload/_randommodule.so
7fb0f6d5d000-7fb0f6f5c000 ---p 00003000 08:02 101040906                  /usr/lib64/python2.7/lib-dynload/_randommodule.so
7fb0f6f5c000-7fb0f6f5d000 r--p 00002000 08:02 101040906                  /usr/lib64/python2.7/lib-dynload/_randommodule.so
7fb0f6f5d000-7fb0f6f5e000 rw-p 00003000 08:02 101040906                  /usr/lib64/python2.7/lib-dynload/_randommodule.so
7fb0f6f5e000-7fb0f6f82000 r-xp 00000000 08:02 100710414                  /usr/lib64/liblzma.so.5.0.99
7fb0f6f82000-7fb0f7181000 ---p 00024000 08:02 100710414                  /usr/lib64/liblzma.so.5.0.99
7fb0f7181000-7fb0f7182000 r--p 00023000 08:02 100710414                  /usr/lib64/liblzma.so.5.0.99
7fb0f7182000-7fb0f7183000 rw-p 00024000 08:02 100710414                  /usr/lib64/liblzma.so.5.0.99
7fb0f7183000-7fb0f71e3000 r-xp 00000000 08:02 100710500                  /usr/lib64/libpcre.so.1.2.0
7fb0f71e3000-7fb0f73e2000 ---p 00060000 08:02 100710500                  /usr/lib64/libpcre.so.1.2.0
7fb0f73e2000-7fb0f73e3000 r--p 0005f000 08:02 100710500                  /usr/lib64/libpcre.so.1.2.0
7fb0f73e3000-7fb0f73e4000 rw-p 00060000 08:02 100710500                  /usr/lib64/libpcre.so.1.2.0
7fb0f73e4000-7fb0f7405000 r-xp 00000000 08:02 100710510                  /usr/lib64/libselinux.so.1
7fb0f7405000-7fb0f7605000 ---p 00021000 08:02 100710510                  /usr/lib64/libselinux.so.1
7fb0f7605000-7fb0f7606000 r--p 00021000 08:02 100710510                  /usr/lib64/libselinux.so.1
7fb0f7606000-7fb0f7607000 rw-p 00022000 08:02 100710510                  /usr/lib64/libselinux.so.1
7fb0f7607000-7fb0f7609000 rw-p 00000000 00:00 0 
7fb0f7609000-7fb0f761f000 r-xp 00000000 08:02 100671125                  /usr/lib64/libresolv-2.17.so
7fb0f761f000-7fb0f781f000 ---p 00016000 08:02 100671125                  /usr/lib64/libresolv-2.17.so
7fb0f781f000-7fb0f7820000 r--p 00016000 08:02 100671125                  /usr/lib64/libresolv-2.17.so
7fb0f7820000-7fb0f7821000 rw-p 00017000 08:02 100671125                  /usr/lib64/libresolv-2.17.so
7fb0f7821000-7fb0f7823000 rw-p 00000000 00:00 0 
7fb0f7823000-7fb0f7826000 r-xp 00000000 08:02 100858119                  /usr/lib64/libkeyutils.so.1.5
7fb0f7826000-7fb0f7a25000 ---p 00003000 08:02 100858119                  /usr/lib64/libkeyutils.so.1.5
7fb0f7a25000-7fb0f7a26000 r--p 00002000 08:02 100858119                  /usr/lib64/libkeyutils.so.1.5
7fb0f7a26000-7fb0f7a27000 rw-p 00003000 08:02 100858119                  /usr/lib64/libkeyutils.so.1.5
7fb0f7a27000-7fb0f7a34000 r-xp 00000000 08:02 100930551                  /usr/lib64/libkrb5support.so.0.1
7fb0f7a34000-7fb0f7c34000 ---p 0000d000 08:02 100930551                  /usr/lib64/libkrb5support.so.0.1
7fb0f7c34000-7fb0f7c35000 r--p 0000d000 08:02 100930551                  /usr/lib64/libkrb5support.so.0.1
7fb0f7c35000-7fb0f7c36000 rw-p 0000e000 08:02 100930551                  /usr/lib64/libkrb5support.so.0.1
7fb0f7c36000-7fb0f7c4b000 r-xp 00000000 08:02 104805321                  /usr/lib64/libz.so.1.2.7
7fb0f7c4b000-7fb0f7e4a000 ---p 00015000 08:02 104805321                  /usr/lib64/libz.so.1.2.7
7fb0f7e4a000-7fb0f7e4b000 r--p 00014000 08:02 104805321                  /usr/lib64/libz.so.1.2.7
7fb0f7e4b000-7fb0f7e4c000 rw-p 00015000 08:02 104805321                  /usr/lib64/libz.so.1.2.7
7fb0f7e4c000-7fb0f7e7b000 r-xp 00000000 08:02 104805327                  /usr/lib64/libk5crypto.so.3.1
7fb0f7e7b000-7fb0f807a000 ---p 0002f000 08:02 104805327                  /usr/lib64/libk5crypto.so.3.1
7fb0f807a000-7fb0f807c000 r--p 0002e000 08:02 104805327                  /usr/lib64/libk5crypto.so.3.1
7fb0f807c000-7fb0f807d000 rw-p 00030000 08:02 104805327                  /usr/lib64/libk5crypto.so.3.1
7fb0f807d000-7fb0f807e000 rw-p 00000000 00:00 0 
7fb0f807e000-7fb0f8081000 r-xp 00000000 08:02 100710526                  /usr/lib64/libcom_err.so.2.1
7fb0f8081000-7fb0f8280000 ---p 00003000 08:02 100710526                  /usr/lib64/libcom_err.so.2.1
7fb0f8280000-7fb0f8281000 r--p 00002000 08:02 100710526                  /usr/lib64/libcom_err.so.2.1
7fb0f8281000-7fb0f8282000 rw-p 00003000 08:02 100710526                  /usr/lib64/libcom_err.so.2.1
7fb0f8282000-7fb0f8357000 r-xp 00000000 08:02 100930549                  /usr/lib64/libkrb5.so.3.3
7fb0f8357000-7fb0f8557000 ---p 000d5000 08:02 100930549                  /usr/lib64/libkrb5.so.3.3
7fb0f8557000-7fb0f8564000 r--p 000d5000 08:02 100930549                  /usr/lib64/libkrb5.so.3.3
7fb0f8564000-7fb0f8567000 rw-p 000e2000 08:02 100930549                  /usr/lib64/libkrb5.so.3.3
7fb0f8567000-7fb0f85b0000 r-xp 00000000 08:02 104805324                  /usr/lib64/libgssapi_krb5.so.2.2
7fb0f85b0000-7fb0f87b0000 ---p 00049000 08:02 104805324                  /usr/lib64/libgssapi_krb5.so.2.2
7fb0f87b0000-7fb0f87b1000 r--p 00049000 08:02 104805324                  /usr/lib64/libgssapi_krb5.so.2.2
7fb0f87b1000-7fb0f87b3000 rw-p 0004a000 08:02 104805324                  /usr/lib64/libgssapi_krb5.so.2.2
7fb0f87b3000-7fb0f8971000 r-xp 00000000 08:02 101190859                  /usr/lib64/libcrypto.so.1.0.1e
7fb0f8971000-7fb0f8b71000 ---p 001be000 08:02 101190859                  /usr/lib64/libcrypto.so.1.0.1e
7fb0f8b71000-7fb0f8b8b000 r--p 001be000 08:02 101190859                  /usr/lib64/libcrypto.so.1.0.1e
7fb0f8b8b000-7fb0f8b97000 rw-p 001d8000 08:02 101190859                  /usr/lib64/libcrypto.so.1.0.1e
7fb0f8b97000-7fb0f8b9b000 rw-p 00000000 00:00 0 
7fb0f8b9b000-7fb0f8bfe000 r-xp 00000000 08:02 101190861                  /usr/lib64/libssl.so.1.0.1e
7fb0f8bfe000-7fb0f8dfd000 ---p 00063000 08:02 101190861                  /usr/lib64/libssl.so.1.0.1e
7fb0f8dfd000-7fb0f8e01000 r--p 00062000 08:02 101190861                  /usr/lib64/libssl.so.1.0.1e
7fb0f8e01000-7fb0f8e08000 rw-p 00066000 08:02 101190861                  /usr/lib64/libssl.so.1.0.1e
7fb0f8e08000-7fb0f8e0c000 r-xp 00000000 08:02 101040885                  /usr/lib64/python2.7/lib-dynload/_hashlib.so
7fb0f8e0c000-7fb0f900b000 ---p 00004000 08:02 101040885                  /usr/lib64/python2.7/lib-dynload/_hashlib.so
7fb0f900b000-7fb0f900c000 r--p 00003000 08:02 101040885                  /usr/lib64/python2.7/lib-dynload/_hashlib.so
7fb0f900c000-7fb0f900d000 rw-p 00004000 08:02 101040885                  /usr/lib64/python2.7/lib-dynload/_hashlib.so
7fb0f900d000-7fb0f900e000 rw-p 00000000 00:00 0 
7fb0f900e000-7fb0f9013000 r-xp 00000000 08:02 104223615                  /usr/lib64/python2.7/lib-dynload/binascii.so
7fb0f9013000-7fb0f9212000 ---p 00005000 08:02 104223615                  /usr/lib64/python2.7/lib-dynload/binascii.so
7fb0f9212000-7fb0f9213000 r--p 00004000 08:02 104223615                  /usr/lib64/python2.7/lib-dynload/binascii.so
7fb0f9213000-7fb0f9214000 rw-p 00005000 08:02 104223615                  /usr/lib64/python2.7/lib-dynload/binascii.so
7fb0f9214000-7fb0f9230000 r-xp 00000000 08:02 101040893                  /usr/lib64/python2.7/lib-dynload/_io.so
7fb0f9230000-7fb0f942f000 ---p 0001c000 08:02 101040893                  /usr/lib64/python2.7/lib-dynload/_io.so
7fb0f942f000-7fb0f9430000 r--p 0001b000 08:02 101040893                  /usr/lib64/python2.7/lib-dynload/_io.so
7fb0f9430000-7fb0f943a000 rw-p 0001c000 08:02 101040893                  /usr/lib64/python2.7/lib-dynload/_io.so
7fb0f943a000-7fb0f947b000 rw-p 00000000 00:00 0 
7fb0f947b000-7fb0f947d000 r-xp 00000000 08:02 101801478                  /usr/lib64/python2.7/lib-dynload/grpmodule.so
7fb0f947d000-7fb0f967c000 ---p 00002000 08:02 101801478                  /usr/lib64/python2.7/lib-dynload/grpmodule.so
7fb0f967c000-7fb0f967d000 r--p 00001000 08:02 101801478                  /usr/lib64/python2.7/lib-dynload/grpmodule.so
7fb0f967d000-7fb0f967e000 rw-p 00002000 08:02 101801478                  /usr/lib64/python2.7/lib-dynload/grpmodule.so
7fb0f967e000-7fb0f9682000 r-xp 00000000 08:02 104223646                  /usr/lib64/python2.7/lib-dynload/timemodule.so
7fb0f9682000-7fb0f9881000 ---p 00004000 08:02 104223646                  /usr/lib64/python2.7/lib-dynload/timemodule.so
7fb0f9881000-7fb0f9882000 r--p 00003000 08:02 104223646                  /usr/lib64/python2.7/lib-dynload/timemodule.so
7fb0f9882000-7fb0f9884000 rw-p 00004000 08:02 104223646                  /usr/lib64/python2.7/lib-dynload/timemodule.so
7fb0f9884000-7fb0f9906000 rw-p 00000000 00:00 0 
7fb0f9906000-7fb0f9909000 r-xp 00000000 08:02 101040881                  /usr/lib64/python2.7/lib-dynload/_functoolsmodule.so
7fb0f9909000-7fb0f9b08000 ---p 00003000 08:02 101040881                  /usr/lib64/python2.7/lib-dynload/_functoolsmodule.so
7fb0f9b08000-7fb0f9b09000 r--p 00002000 08:02 101040881                  /usr/lib64/python2.7/lib-dynload/_functoolsmodule.so
7fb0f9b09000-7fb0f9b0a000 rw-p 00003000 08:02 101040881                  /usr/lib64/python2.7/lib-dynload/_functoolsmodule.so
7fb0f9b0a000-7fb0f9b0e000 r-xp 00000000 08:02 104223618                  /usr/lib64/python2.7/lib-dynload/cStringIO.so
7fb0f9b0e000-7fb0f9d0d000 ---p 00004000 08:02 104223618                  /usr/lib64/python2.7/lib-dynload/cStringIO.so
7fb0f9d0d000-7fb0f9d0e000 r--p 00003000 08:02 104223618                  /usr/lib64/python2.7/lib-dynload/cStringIO.so
7fb0f9d0e000-7fb0f9d10000 rw-p 00004000 08:02 104223618                  /usr/lib64/python2.7/lib-dynload/cStringIO.so
7fb0f9d10000-7fb0f9d22000 r-xp 00000000 08:02 104223617                  /usr/lib64/python2.7/lib-dynload/cPickle.so
7fb0f9d22000-7fb0f9f22000 ---p 00012000 08:02 104223617                  /usr/lib64/python2.7/lib-dynload/cPickle.so
7fb0f9f22000-7fb0f9f23000 r--p 00012000 08:02 104223617                  /usr/lib64/python2.7/lib-dynload/cPickle.so
7fb0f9f23000-7fb0f9f24000 rw-p 00013000 08:02 104223617                  /usr/lib64/python2.7/lib-dynload/cPickle.so
7fb0f9f24000-7fb0f9f65000 rw-p 00000000 00:00 0 
7fb0fa026000-7fb0fa0e5000 r-xp 00000000 08:02 703222                     /usr/lib/python2.7/site-packages/numpy/core/umath.so
7fb0fa0e5000-7fb0fa2e5000 ---p 000bf000 08:02 703222                     /usr/lib/python2.7/site-packages/numpy/core/umath.so
7fb0fa2e5000-7fb0fa2e6000 r--p 000bf000 08:02 703222                     /usr/lib/python2.7/site-packages/numpy/core/umath.so
7fb0fa2e6000-7fb0fa2ec000 rw-p 000c0000 08:02 703222                     /usr/lib/python2.7/site-packages/numpy/core/umath.so
7fb0fa2ec000-7fb0fa32f000 rw-p 00000000 00:00 0 
7fb0fa32f000-7fb0fa340000 r-xp 00000000 08:02 104223620                  /usr/lib64/python2.7/lib-dynload/datetime.so
7fb0fa340000-7fb0fa53f000 ---p 00011000 08:02 104223620                  /usr/lib64/python2.7/lib-dynload/datetime.so
7fb0fa53f000-7fb0fa540000 r--p 00010000 08:02 104223620                  /usr/lib64/python2.7/lib-dynload/datetime.so
7fb0fa540000-7fb0fa544000 rw-p 00011000 08:02 104223620                  /usr/lib64/python2.7/lib-dynload/datetime.so
7fb0fa544000-7fb0fa559000 r-xp 00000000 08:02 102392267                  /usr/lib64/libgcc_s-4.8.5-20150702.so.1
7fb0fa559000-7fb0fa758000 ---p 00015000 08:02 102392267                  /usr/lib64/libgcc_s-4.8.5-20150702.so.1
7fb0fa758000-7fb0fa759000 r--p 00014000 08:02 102392267                  /usr/lib64/libgcc_s-4.8.5-20150702.so.1
7fb0fa759000-7fb0fa75a000 rw-p 00015000 08:02 102392267                  /usr/lib64/libgcc_s-4.8.5-20150702.so.1
7fb0fa75a000-7fb0fa795000 r-xp 00000000 08:02 100936027                  /usr/lib64/libquadmath.so.0.0.0
7fb0fa795000-7fb0fa994000 ---p 0003b000 08:02 100936027                  /usr/lib64/libquadmath.so.0.0.0
7fb0fa994000-7fb0fa995000 r--p 0003a000 08:02 100936027                  /usr/lib64/libquadmath.so.0.0.0
7fb0fa995000-7fb0fa996000 rw-p 0003b000 08:02 100936027                  /usr/lib64/libquadmath.so.0.0.0
7fb0fa996000-7fb0faab5000 r-xp 00000000 08:02 100936029                  /usr/lib64/libgfortran.so.3.0.0
7fb0faab5000-7fb0facb5000 ---p 0011f000 08:02 100936029                  /usr/lib64/libgfortran.so.3.0.0
7fb0facb5000-7fb0facb6000 r--p 0011f000 08:02 100936029                  /usr/lib64/libgfortran.so.3.0.0
7fb0facb6000-7fb0facb8000 rw-p 00120000 08:02 100936029                  /usr/lib64/libgfortran.so.3.0.0
7fb0facb8000-7fb0fb712000 r-xp 00000000 08:02 67246515                   /usr/lib64/atlas/libtatlas.so.3.10
7fb0fb712000-7fb0fb911000 ---p 00a5a000 08:02 67246515                   /usr/lib64/atlas/libtatlas.so.3.10
7fb0fb911000-7fb0fb916000 r--p 00a59000 08:02 67246515                   /usr/lib64/atlas/libtatlas.so.3.10
7fb0fb916000-7fb0fb91f000 rw-p 00a5e000 08:02 67246515                   /usr/lib64/atlas/libtatlas.so.3.10
7fb0fb91f000-7fb0fba2d000 rw-p 00000000 00:00 0 
7fb0fba2d000-7fb0fbba2000 r-xp 00000000 08:02 703221                     /usr/lib/python2.7/site-packages/numpy/core/multiarray.so
7fb0fbba2000-7fb0fbda2000 ---p 00175000 08:02 703221                     /usr/lib/python2.7/site-packages/numpy/core/multiarray.so
7fb0fbda2000-7fb0fbda4000 r--p 00175000 08:02 703221                     /usr/lib/python2.7/site-packages/numpy/core/multiarray.so
7fb0fbda4000-7fb0fbdb1000 rw-p 00177000 08:02 703221                     /usr/lib/python2.7/site-packages/numpy/core/multiarray.so
7fb0fbdb1000-7fb0fbdc3000 rw-p 00000000 00:00 0 
7fb0fbdc3000-7fb0fbdca000 r-xp 00000000 08:02 104223628                  /usr/lib64/python2.7/lib-dynload/math.so
7fb0fbdca000-7fb0fbfc9000 ---p 00007000 08:02 104223628                  /usr/lib64/python2.7/lib-dynload/math.so
7fb0fbfc9000-7fb0fbfca000 r--p 00006000 08:02 104223628                  /usr/lib64/python2.7/lib-dynload/math.so
7fb0fbfca000-7fb0fbfcc000 rw-p 00007000 08:02 104223628                  /usr/lib64/python2.7/lib-dynload/math.so
7fb0fbfcc000-7fb0fbfcf000 r-xp 00000000 08:02 101040887                  /usr/lib64/python2.7/lib-dynload/_heapq.so
7fb0fbfcf000-7fb0fc1ce000 ---p 00003000 08:02 101040887                  /usr/lib64/python2.7/lib-dynload/_heapq.so
7fb0fc1ce000-7fb0fc1cf000 r--p 00002000 08:02 101040887                  /usr/lib64/python2.7/lib-dynload/_heapq.so
7fb0fc1cf000-7fb0fc1d1000 rw-p 00003000 08:02 101040887                  /usr/lib64/python2.7/lib-dynload/_heapq.so
7fb0fc1d1000-7fb0fc1db000 r-xp 00000000 08:02 104223626                  /usr/lib64/python2.7/lib-dynload/itertoolsmodule.so
7fb0fc1db000-7fb0fc3da000 ---p 0000a000 08:02 104223626                  /usr/lib64/python2.7/lib-dynload/itertoolsmodule.so
7fb0fc3da000-7fb0fc3db000 r--p 00009000 08:02 104223626                  /usr/lib64/python2.7/lib-dynload/itertoolsmodule.so
7fb0fc3db000-7fb0fc3e0000 rw-p 0000a000 08:02 104223626                  /usr/lib64/python2.7/lib-dynload/itertoolsmodule.so
7fb0fc3e0000-7fb0fc3e6000 r-xp 00000000 08:02 101040873                  /usr/lib64/python2.7/lib-dynload/_collectionsmodule.so
7fb0fc3e6000-7fb0fc5e5000 ---p 00006000 08:02 101040873                  /usr/lib64/python2.7/lib-dynload/_collectionsmodule.so
7fb0fc5e5000-7fb0fc5e6000 r--p 00005000 08:02 101040873                  /usr/lib64/python2.7/lib-dynload/_collectionsmodule.so
7fb0fc5e6000-7fb0fc5e8000 rw-p 00006000 08:02 101040873                  /usr/lib64/python2.7/lib-dynload/_collectionsmodule.so
7fb0fc5e8000-7fb0fc5f1000 r-xp 00000000 08:02 101801483                  /usr/lib64/python2.7/lib-dynload/operator.so
7fb0fc5f1000-7fb0fc7f0000 ---p 00009000 08:02 101801483                  /usr/lib64/python2.7/lib-dynload/operator.so
7fb0fc7f0000-7fb0fc7f1000 r--p 00008000 08:02 101801483                  /usr/lib64/python2.7/lib-dynload/operator.so
7fb0fc7f1000-7fb0fc7f3000 rw-p 00009000 08:02 101801483                  /usr/lib64/python2.7/lib-dynload/operator.so
7fb0fc7f3000-7fb0fc7f8000 r-xp 00000000 08:02 104223638                  /usr/lib64/python2.7/lib-dynload/stropmodule.so
7fb0fc7f8000-7fb0fc9f7000 ---p 00005000 08:02 104223638                  /usr/lib64/python2.7/lib-dynload/stropmodule.so
7fb0fc9f7000-7fb0fc9f8000 r--p 00004000 08:02 104223638                  /usr/lib64/python2.7/lib-dynload/stropmodule.so
7fb0fc9f8000-7fb0fc9fa000 rw-p 00005000 08:02 104223638                  /usr/lib64/python2.7/lib-dynload/stropmodule.so
7fb0fc9fa000-7fb0fca01000 r-xp 00000000 08:02 104223612                  /usr/lib64/python2.7/lib-dynload/_struct.so
7fb0fca01000-7fb0fcc00000 ---p 00007000 08:02 104223612                  /usr/lib64/python2.7/lib-dynload/_struct.so
7fb0fcc00000-7fb0fcc01000 r--p 00006000 08:02 104223612                  /usr/lib64/python2.7/lib-dynload/_struct.so
7fb0fcc01000-7fb0fcc03000 rw-p 00007000 08:02 104223612                  /usr/lib64/python2.7/lib-dynload/_struct.so
7fb0fcc03000-7fb0fcc0a000 r-xp 00000000 08:02 100710625                  /usr/lib64/libffi.so.6.0.1
7fb0fcc0a000-7fb0fce09000 ---p 00007000 08:02 100710625                  /usr/lib64/libffi.so.6.0.1
7fb0fce09000-7fb0fce0a000 r--p 00006000 08:02 100710625                  /usr/lib64/libffi.so.6.0.1
7fb0fce0a000-7fb0fce0b000 rw-p 00007000 08:02 100710625                  /usr/lib64/libffi.so.6.0.1
7fb0fce0b000-7fb0fce25000 r-xp 00000000 08:02 101040877                  /usr/lib64/python2.7/lib-dynload/_ctypes.so
7fb0fce25000-7fb0fd024000 ---p 0001a000 08:02 101040877                  /usr/lib64/python2.7/lib-dynload/_ctypes.so
7fb0fd024000-7fb0fd025000 r--p 00019000 08:02 101040877                  /usr/lib64/python2.7/lib-dynload/_ctypes.so
7fb0fd025000-7fb0fd029000 rw-p 0001a000 08:02 101040877                  /usr/lib64/python2.7/lib-dynload/_ctypes.so
7fb0fd029000-7fb103550000 r--p 00000000 08:02 34398790                   /usr/lib/locale/locale-archive
7fb103550000-7fb103706000 r-xp 00000000 08:02 100664204                  /usr/lib64/libc-2.17.so
7fb103706000-7fb103906000 ---p 001b6000 08:02 100664204                  /usr/lib64/libc-2.17.so
7fb103906000-7fb10390a000 r--p 001b6000 08:02 100664204                  /usr/lib64/libc-2.17.so
7fb10390a000-7fb10390c000 rw-p 001ba000 08:02 100664204                  /usr/lib64/libc-2.17.so
7fb10390c000-7fb103911000 rw-p 00000000 00:00 0 
7fb103911000-7fb103a12000 r-xp 00000000 08:02 100664212                  /usr/lib64/libm-2.17.so
7fb103a12000-7fb103c11000 ---p 00101000 08:02 100664212                  /usr/lib64/libm-2.17.so
7fb103c11000-7fb103c12000 r--p 00100000 08:02 100664212                  /usr/lib64/libm-2.17.so
7fb103c12000-7fb103c13000 rw-p 00101000 08:02 100664212                  /usr/lib64/libm-2.17.so
7fb103c13000-7fb103c15000 r-xp 00000000 08:02 100671132                  /usr/lib64/libutil-2.17.so
7fb103c15000-7fb103e14000 ---p 00002000 08:02 100671132                  /usr/lib64/libutil-2.17.so
7fb103e14000-7fb103e15000 r--p 00001000 08:02 100671132                  /usr/lib64/libutil-2.17.so
7fb103e15000-7fb103e16000 rw-p 00002000 08:02 100671132                  /usr/lib64/libutil-2.17.so
7fb103e16000-7fb103e19000 r-xp 00000000 08:02 100664210                  /usr/lib64/libdl-2.17.so
7fb103e19000-7fb104018000 ---p 00003000 08:02 100664210                  /usr/lib64/libdl-2.17.so
7fb104018000-7fb104019000 r--p 00002000 08:02 100664210                  /usr/lib64/libdl-2.17.so
7fb104019000-7fb10401a000 rw-p 00003000 08:02 100664210                  /usr/lib64/libdl-2.17.so
7fb10401a000-7fb104030000 r-xp 00000000 08:02 100664326                  /usr/lib64/libpthread-2.17.so
7fb104030000-7fb104230000 ---p 00016000 08:02 100664326                  /usr/lib64/libpthread-2.17.so
7fb104230000-7fb104231000 r--p 00016000 08:02 100664326                  /usr/lib64/libpthread-2.17.so
7fb104231000-7fb104232000 rw-p 00017000 08:02 100664326                  /usr/lib64/libpthread-2.17.so
7fb104232000-7fb104236000 rw-p 00000000 00:00 0 
7fb104236000-7fb1043ae000 r-xp 00000000 08:02 104223592                  /usr/lib64/libpython2.7.so.1.0
7fb1043ae000-7fb1045ae000 ---p 00178000 08:02 104223592                  /usr/lib64/libpython2.7.so.1.0
7fb1045ae000-7fb1045af000 r--p 00178000 08:02 104223592                  /usr/lib64/libpython2.7.so.1.0
7fb1045af000-7fb1045ed000 rw-p 00179000 08:02 104223592                  /usr/lib64/libpython2.7.so.1.0
7fb1045ed000-7fb1045fc000 rw-p 00000000 00:00 0 
7fb1045fc000-7fb10461d000 r-xp 00000000 08:02 100664197                  /usr/lib64/ld-2.17.so
7fb10464b000-7fb10474f000 rw-p 00000000 00:00 0 
7fb104780000-7fb104807000 rw-p 00000000 00:00 0 
7fb10481b000-7fb10481d000 rw-p 00000000 00:00 0 
7fb10481d000-7fb10481e000 r--p 00021000 08:02 100664197                  /usr/lib64/ld-2.17.so
7fb10481e000-7fb10481f000 rw-p 00022000 08:02 100664197                  /usr/lib64/ld-2.17.so
7fb10481f000-7fb104820000 rw-p 00000000 00:00 0 
7fff62543000-7fff62562000 rwxp 00000000 00:00 0                          [stack]
7fff62562000-7fff62564000 rw-p 00000000 00:00 0 
7fff625ef000-7fff625f1000 r-xp 00000000 00:00 0                          [vdso]
ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]
```

work0 says:

``` shell
E tensorflow/core/distributed_runtime/master_session.cc:1086] Cleanup partition error: Unavailable: {""created"":""@1476415738.601085137"",""description"":""OS Error"",""errno"":104,""file"":""external/grpc/src/core/lib/iomgr/tcp_posix.c"",""file_line"":229,""grpc_status"":14,""os_error"":""Connection reset by peer"",""syscall"":""recvmsg""}
INFO:tensorflow:About to execute sync_clean_up_op!
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors.UnavailableError'>, {""created"":""@1476415738.601085137"",""description"":""OS Error"",""errno"":104,""file"":""external/grpc/src/core/lib/iomgr/tcp_posix.c"",""file_line"":229,""grpc_status"":14,""os_error"":""Connection reset by peer"",""syscall"":""recvmsg""}
```

and worker1:

``` shell
Traceback (most recent call last):
  File ""/export/wangqingze/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/imagenet_distributed_train.py"", line 65, in <module>
    tf.app.run()
  File ""/export/wangqingze/tensorflow/_python_build/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/export/wangqingze/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/imagenet_distributed_train.py"", line 61, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File ""/export/wangqingze/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/inception_distributed_train.py"", line 279, in train
    loss_value, step = sess.run([train_op, global_step])
  File ""/export/wangqingze/tensorflow/_python_build/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/export/wangqingze/tensorflow/_python_build/tensorflow/python/client/session.py"", line 915, in _run
    feed_dict_string, options, run_metadata)
  File ""/export/wangqingze/tensorflow/_python_build/tensorflow/python/client/session.py"", line 965, in _do_run
    target_list, options, run_metadata)
  File ""/export/wangqingze/tensorflow/_python_build/tensorflow/python/client/session.py"", line 985, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.UnavailableError: {""created"":""@1476415738.601603924"",""description"":""OS Error"",""errno"":104,""file"":""external/grpc/src/core/lib/iomgr/tcp_posix.c"",""file_line"":229,""grpc_status"":14,""os_error"":""Connection reset by peer"",""syscall"":""recvmsg""}
```
# configuration

centos 7
both inception model and tensorflow build from source, i.e. tensorflow is 0.11.rc, in fact the inception must be modified in order to run, reference https://github.com/tensorflow/models/pull/520
"
4950,Slim namespace has non-slim symbols,"[tensorflow/contrib/slim/**init**.py](https://github.com/tensorflow/tensorflow/blob/754048a0453a04a761e112ae5d99c149eb9910dd/tensorflow/contrib/slim/__init__.py) makes symbols from unrelated namespaces available in its own.

``` py
from tensorflow.contrib.framework.python.ops.arg_scope import *
from tensorflow.contrib.framework.python.ops.variables import *
from tensorflow.contrib.layers.python.layers import *
from tensorflow.contrib.layers.python.layers.initializers import *
from tensorflow.contrib.layers.python.layers.regularizers import *
```

This makes it difficult for users to reference names canonically. For example #4887 where a user said `tf.contrib.slim.arg_scope` instead of `tf.contrib.framework.arg_scope`.

We almost certainly want to refactor this namespace so it only exports symbols belonging to slim.

PTAL @sguada
"
4944,Tensorflow GPU installation fails due to Bazel build ,"I've been trying to install tensorflow with GPU support using these steps:
http://www.nvidia.com/object/gpu-accelerated-applications-tensorflow-installation.html

This is the error message that I'm getting when I try to run the bazel build command for building the tensorflow pip package (with the --config-cuda flag set):

`bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`

i get :  
    `The specified --crosstool_top '//third_party/gpus/crosstool:crosstool' is not a valid cc_toolchain_suite rule`

What's strange is that if i remove the --config=cuda flag, I don't get the error message while building and I'm able to install tensorflow successfully - but without GPU support.
"
4943,error building tensorflow example for ios,"Hi,
I am trying build the ios app detailed in https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/

but it fails with:

**checking whether we are cross compiling... configure: error: in `/projects/tensorflow/tensorflow/tensorflow/contrib/makefile/downloads/protobuf':
configure: error: cannot run C compiled programs.
If you meant to cross compile, use`--host'.
See `config.log' for more details**

system details;
macos sierra, 10.12

brew config output: Any pointers will be appreciated.

MacBook-Pro:tensorflow $ brew config
HOMEBREW_VERSION: 1.0.6
ORIGIN: https:/
HEAD: 35ee2831086e923e7fcaf75fb440b01312e3f9c5
Last commit: 7 days ago
Core tap ORIGIN: https:/
Core tap HEAD: 80f18defefc814d60d3799e58835cbeffc8e93c8
Core tap last commit: 2 hours ago
HOMEBREW_PREFIX: /usr/local
HOMEBREW_REPOSITORY: /usr/local/Homebrew
HOMEBREW_CELLAR: /usr/local/Cellar
HOMEBREW_BOTTLE_DOMAIN: https:/
CPU: quad-core 64-bit broadwell
Homebrew Ruby: 2.0.0-p648
Clang: 8.0 build 800
Git: 2.8.4 => /Applications/Xcode.app/Contents/Developer/usr/bin/git
Perl: /usr/bin/perl
Python: /usr/bin/python
Ruby: /usr/bin/ruby => /System/Library/Frameworks/Ruby.framework/Versions/2.0/usr/bin/ruby
Java: 1.8.0_60
macOS: 10.12-x86_64
Xcode: 8.0
CLT: 8.0.0.0.1.1472435881
X11: N/A
"
4940,Tensorflow and emscripten,"Any plans to add the build chain for emscripten?
At this time there is this attempt https://github.com/tomasreimers/tensorflow-emscripten, but a official supported would be awesome!
"
4939,System hangs while training,"Hi everyone,

I am trying to train model for handwritten digits. My data consists of images, each of size 80X80. So I get 6400 features as inputs. 
While trying to train model as per code used in https://www.kaggle.com/kakauandme/digit-recognizer/tensorflow-deep-nn, my systems hangs after 200 iterations with training accuracy 0.06.

Why is this happening? I don't get any errors. My system just freezes.
Also, how do I set pooling and convolution layers parameters? 

PS: I'm not using GPU. 
"
4938,A bug on embedding_attention_seq2seq when output_projection is None?,"When I use embedding_attention_seq2seq without giving an `output_projection` argument, I experienced that the program crashes by a memory allocation error, even when the model ran fine in other libraries or my own implementation of attention seq2seq.
I didn't suffer this problem when I give an `output_projection` argument to the function explicitly.

I suspect it occurs by the following fact: when `output_projection` is None, it wraps the `cell` with `OutputProjectionWrapper`) in `embedding_attention_seq2seq`. This wrapped `cell` emits output whose dimension matches the number of decoder symbols.
Then the wrapped `cell` variable is passed to `embedding_attention_decoder`, and to `attention_decoder`.
Here, in the `attention_decoder` function, the awkward memory allocation happens.
1) Since the `output_size` argument is None, it is set to `cell.output_size`, which is identical to the number of decoder symbols. (line 576)
2) `cell_output` of line 650 has dimensions proportional to the number of decoder symbols.
3) Thus, in line 660, it creates a very large matrix whose size is proportional to the square of the number of decoder symbols.

According to the paper the implementation is referencing, the attention mechanism should not depend on the number of decoder symbols.
So I think the implementation is somewhat wrong and should be corrected by passing the `cell` without wrapping an `OutputProjectionWrapper` and then performing projection afterwards.

If it is truly a bug and no one is working now, I will submit a pull request since it can be easily fixed, IMO.
"
4937,Build iOS sample failed,"After I run the tensorflow/contrib/makefile/build_all_ios.sh command,
I got the messages bellow:

echo 'protoc not found at 
~/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc. Build it first.'
protoc not found at ~/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc. Build it first.

I check the protobuf-host directory. This folder contains nothing, how can I solve this?
Do I miss any steps?
Thanks!
"
4935,Does Distributed TensorFlow support Infiniband?,"Based on stackoverflow, the answer is no.

If it is no, does TF have plans to support Infiniband?

http://stackoverflow.com/questions/39184496/does-distributed-tensorflow-support-infiniband-interconnections-out-of-the-box
"
4934,How to get word alignment in attention_seq2seq in Translate.py?,"Hi, 
I'm wondering if i get the word alignment probability in the seq2seq model for language translation.

Thanks a lot! 
Stephen
"
4933,I want to write a while_loop in while_loop. Does anyone know how write it correctly or have some examples?,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
"
4932,Distributed inception stuck at tf.initialize_all_variables(),"I'm running distributed training of Inception but its behavior is unpredictable and time to time the _**chief**_ node stuck at (I found out the line through adding logs for every line):

```
tensorflow/tensorflow/python/training/session_manager.py:233
sess.run(init_op, feed_dict=init_feed_dict)
```

The `init_op` is assigned to `tf.initialize_all_variables()` in Inception distributed training. As I mentioned, the behavior is random and it only happens time to time.

Has anyone else has this issues?

I'm running the latest version of TF compiled from source + cuda 7.5 + cudnn 5.1.3
"
