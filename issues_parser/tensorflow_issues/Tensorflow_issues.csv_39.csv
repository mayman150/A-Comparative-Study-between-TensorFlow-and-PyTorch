Issue Number,Issue Title,Issue Body
30371,Bad inference on mobilenet quantized graph,"Hi! I'm having some trouble about quantization on ssd_mobilenet_v1, doing inferences on raspberry Pi 3. I have trained this model using 2007voc dataset with the following comand:

```bash
python /models/research/object_detection/legacy/train.py \
		--train_dir $TRAIN_DIR \
		--pipeline_config_path ""$TRAIN_DIR/pipeline.config""
```
And params '{""batch_size"":8,""learning_rate"":0.003}'.
To generate both frozen and quantized graph, i use the following comand:

```bash
/tensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
		--in_graph=""$TRAIN_DIR/frozen_inference_graph.pb"" \
		--out_graph=""$TRAIN_DIR/quantized_graph.pb"" \
		--inputs='image_tensor' \
		--outputs=MobilenetV1/Predictions/Reshape_1 \
		--transforms='
		quantize_weights'
```

Doing inferences using just the quantized graph, the result is really good. The model predict almost everything, with good bouding boxes. But, when i do inferences using the quantized graph, the bouding boxes look like this:
![my2](https://user-images.githubusercontent.com/23393117/60616312-8c45e180-9da7-11e9-9328-77d62e71b144.png)

I know the inference time is not equals when we compare both models. And i also know the mAP is note the same, but it is suposed to be that bad?

### Process information
- **The main process you can find [here](https://medium.com/nanonets/how-to-easily-detect-objects-with-deep-learning-on-raspberrypi-225f29635c74)**
- **I use for train:**
- Linux 16.04
- Core i7-4770s
- 16GB Ram
- **I use for Inference:**
- Raspberry Pi3

"
30367,tf.test.is_gpu_available() raises error instead of returning False,"

**System information**

python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
v1.12.1-5259-ge703239 2.0.0-dev20190629


nvcc --version
```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130
```

**Describe the current behavior**

The code snippet below raises an error instead
of printing something

```
import tensorflow as tf
from tensorflow import keras
print(""tf version {}"".format(tf.__version__))
if tf.test.is_gpu_available():
    print(tf.test.gpu_device_name())
else:
    print(""TF cannot find GPU"")
```
Produces
```
tf version 2.0.0-dev20190629
---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
<ipython-input-8-b9f80ad1b5e1> in <module>
     10 from tensorflow import keras
     11 print(""tf version {}"".format(tf.__version__))
---> 12 if tf.test.is_gpu_available():
     13     print(tf.test.gpu_device_name())
     14 else:

~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/test_util.py in is_gpu_available(cuda_only, min_cuda_compute_capability)
   1388 
   1389   try:
-> 1390     for local_device in device_lib.list_local_devices():
   1391       if local_device.device_type == ""GPU"":
   1392         if (min_cuda_compute_capability is None or

~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/client/device_lib.py in list_local_devices(session_config)
     39   return [
     40       _convert(s)
---> 41       for s in pywrap_tensorflow.list_devices(session_config=session_config)
     42   ]

~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py in list_devices(session_config)
   2203     return ListDevicesWithSessionConfig(session_config.SerializeToString())
   2204   else:
-> 2205     return ListDevices()
   2206 
   2207 

InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable

```

**Describe the expected behavior**

It should print ""GeForce RTX 2080 with Max-Q Design""
(as PyTorch does).

**Code to reproduce the issue**

See above
"
30366,get_variable style tf.Variable initialization,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.x
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Currently, tf.Variable requires passing in an initial value for the variable. It's often much more useful to pass in a shape and initializer. It'd be great if there was a convenience function that made this easy to do. tf.get_variable did this, but it requires a namescope to be specified, which is no longer desirable.
**Will this change the current api? How?**
Barely - it will simply add an additional way to initialize variables.
**Who will benefit with this feature?**
Almost everyone using TF.
**Any Other info.**
"
30361,Error when computing Jacobian in eager mode,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux version 3.10.0-957.10.1.el7.x86_64 (mockbuild@x86-040.build.eng.bos.redhat.com) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC) )
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary pip install
- TensorFlow version (use command below): v1.13.1-0-g6612da8951 1.13.1
- Python version: 3.6.4
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A (CPU)
- GPU model and memory: N/A (CPU)

**Describe the current behavior**
Error occurs when trying to compute the Jacobian in the following code

**Describe the expected behavior**
<tf.Tensor: id=XXX, shape=(2, 1), dtype=float32, numpy=array([[1.], [1.]], dtype=float32)>

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import tensorflow as tf
tf.enable_eager_execution()

with tf.GradientTape() as g:
    x  = tf.constant([1.0])
    g.watch(x)
    y = tf.concat([x,x], axis=0)

g.jacobian(y, x)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Additional info: the expected behavior occurs when creating the `GradientTape` with persistent=True and replacing the last line of code with `g.jacobian(y, x, experimental_use_pfor=False)`. However, that workaround is extremely slow with real data.

Log of the code that reproduces the issue:
```python
AttributeError Traceback (most recent call last)
in ()
9 # y = tf.concat([y,y], axis=0)
10
---> 11 g.jacobian(y, x)

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in jacobian(self, target, sources, unconnected_gradients, parallel_iterations, experimental_use_pfor)
1021 try:
1022 output = pfor_ops.pfor(loop_fn, target_size,
-> 1023 parallel_iterations=parallel_iterations)
1024 except ValueError as err:
1025 six.reraise(

/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py in pfor(loop_fn, iters, parallel_iterations)
149 if context.executing_eagerly():
150 f = function.defun(f)
--> 151 return f()
152
153

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py in call(self, *args, **kwargs)
862 def call(self, *args, **kwargs):
863 """"""Calls a graph function specialized to the inputs.""""""
--> 864 graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
865 return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access
866

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
1174 self._input_signature,
1175 autograph=self._autograph,
-> 1176 arg_names=arg_names),
1177 self._function_attributes)
1178 if self._input_signature:

/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, add_control_dependencies, arg_names, op_return_value)
446 tf_decorator.rewrap(python_func, original_func, converted_func)
447
--> 448 func_outputs = python_func(*func_args, **func_kwargs)
449
450 # invariant: func_outputs contains only Tensors, IndexedSlices,

/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py in f()
146 """"""
147 def f():
--> 148 return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
149 if context.executing_eagerly():
150 f = function.defun(f)

/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py in _pfor_impl(loop_fn, iters, parallel_iterations)
157 with ops.name_scope(""loop_body""):
158 loop_var = array_ops.placeholder(dtypes.int32, shape=[])
--> 159 loop_fn_outputs = loop_fn(loop_var)
160 new_ops = set(ops.get_default_graph().get_operations()) - existing_ops
161 iters = ops.convert_to_tensor(iters)

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in loop_fn(i)
1011 self._pop_tape()
1012 return self.gradient(y, flat_sources,
-> 1013 unconnected_gradients=unconnected_gradients)
1014
1015 try:

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)
944 flat_sources,
945 output_gradients=output_gradients,
--> 946 unconnected_gradients=unconnected_gradients)
947
948 if not self._persistent:

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, unconnected_gradients)
70 sources,
71 output_gradients,
---> 72 compat.as_str(unconnected_gradients.value))

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)
129 return [None] * num_inputs
130
--> 131 return grad_fn(mock_op, *out_grads)
132
133

/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py in _ConcatGradV2(op, grad)
220 def _ConcatGradV2(op, grad):
221 return _ConcatGradHelper(
--> 222 op, grad, start_value_index=0, end_value_index=-1, dim_index=-1)
223
224

/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py in _ConcatGradHelper(op, grad, start_value_index, end_value_index, dim_index)
115 out_grads = array_ops.split(grad, sizes, non_neg_concat_dim)
116 else:
--> 117 if constant_op.is_constant(concat_dim):
118 # If concat_dim is a constant defined in a different context,
119 # then we duplicate it in the current context to avoid passing it

/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in is_constant(tensor_or_op)
293 def is_constant(tensor_or_op):
294 if isinstance(tensor_or_op, ops.Tensor):
--> 295 op = tensor_or_op.op
296 else:
297 op = tensor_or_op

/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in op(self)
925 def op(self):
926 raise AttributeError(
--> 927 ""Tensor.op is meaningless when eager execution is enabled."")
928
929 @Property

AttributeError: Tensor.op is meaningless when eager execution is enabled.
```"
30360,Error when computing jacobian in eager mode,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux version 3.10.0-957.10.1.el7.x86_64 (mockbuild@x86-040.build.eng.bos.redhat.com) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC) )
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary pip install
- TensorFlow version (use command below): v1.13.1-0-g6612da8951 1.13.1
- Python version: 3.6.4
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A (CPU)
- GPU model and memory: N/A (CPU)

**Describe the current behavior**
Error occurs when trying to compute the Jacobian in the following code

**Describe the expected behavior**
<tf.Tensor: id=XXX, shape=(2, 1), dtype=float32, numpy=array([[1.], [1.]], dtype=float32)>

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import tensorflow as tf
tf.enable_eager_execution()

with tf.GradientTape() as g:
    x  = tf.constant([1.0])
    g.watch(x)
    y = tf.concat([x,x], axis=0)

g.jacobian(y, x)
```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Additional info: the expected behavior occurs when creating the `GradientTape` with `persistent=True` and replacing the last line of code with `g.jacobian(y, x, experimental_use_pfor=False)`. However, that workaround is extremely slow with real data.

Log of the code that reproduces the issue:
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-9-16331645f7bb> in <module>()
      9 #     y = tf.concat([y,y], axis=0)
     10 
---> 11 g.jacobian(y, x)

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in jacobian(self, target, sources, unconnected_gradients, parallel_iterations, experimental_use_pfor)
   1021       try:
   1022         output = pfor_ops.pfor(loop_fn, target_size,
-> 1023                                parallel_iterations=parallel_iterations)
   1024       except ValueError as err:
   1025         six.reraise(

/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py in pfor(loop_fn, iters, parallel_iterations)
    149   if context.executing_eagerly():
    150     f = function.defun(f)
--> 151   return f()
    152 
    153 

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
    862   def __call__(self, *args, **kwargs):
    863     """"""Calls a graph function specialized to the inputs.""""""
--> 864     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
    865     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
    866 

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   1174                 self._input_signature,
   1175                 autograph=self._autograph,
-> 1176                 arg_names=arg_names),
   1177             self._function_attributes)
   1178         if self._input_signature:

/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, add_control_dependencies, arg_names, op_return_value)
    446         tf_decorator.rewrap(python_func, original_func, converted_func)
    447 
--> 448       func_outputs = python_func(*func_args, **func_kwargs)
    449 
    450       # invariant: `func_outputs` contains only Tensors, IndexedSlices,

/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py in f()
    146   """"""
    147   def f():
--> 148     return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    149   if context.executing_eagerly():
    150     f = function.defun(f)

/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py in _pfor_impl(loop_fn, iters, parallel_iterations)
    157   with ops.name_scope(""loop_body""):
    158     loop_var = array_ops.placeholder(dtypes.int32, shape=[])
--> 159     loop_fn_outputs = loop_fn(loop_var)
    160   new_ops = set(ops.get_default_graph().get_operations()) - existing_ops
    161   iters = ops.convert_to_tensor(iters)

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in loop_fn(i)
   1011       self._pop_tape()
   1012       return self.gradient(y, flat_sources,
-> 1013                            unconnected_gradients=unconnected_gradients)
   1014 
   1015     try:

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)
    944         flat_sources,
    945         output_gradients=output_gradients,
--> 946         unconnected_gradients=unconnected_gradients)
    947 
    948     if not self._persistent:

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, unconnected_gradients)
     70       sources,
     71       output_gradients,
---> 72       compat.as_str(unconnected_gradients.value))

/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)
    129     return [None] * num_inputs
    130 
--> 131   return grad_fn(mock_op, *out_grads)
    132 
    133 

/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py in _ConcatGradV2(op, grad)
    220 def _ConcatGradV2(op, grad):
    221   return _ConcatGradHelper(
--> 222       op, grad, start_value_index=0, end_value_index=-1, dim_index=-1)
    223 
    224 

/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py in _ConcatGradHelper(op, grad, start_value_index, end_value_index, dim_index)
    115       out_grads = array_ops.split(grad, sizes, non_neg_concat_dim)
    116     else:
--> 117       if constant_op.is_constant(concat_dim):
    118         # If concat_dim is a constant defined in a different context,
    119         # then we duplicate it in the current context to avoid passing it

/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in is_constant(tensor_or_op)
    293 def is_constant(tensor_or_op):
    294   if isinstance(tensor_or_op, ops.Tensor):
--> 295     op = tensor_or_op.op
    296   else:
    297     op = tensor_or_op

/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in op(self)
    925   def op(self):
    926     raise AttributeError(
--> 927         ""Tensor.op is meaningless when eager execution is enabled."")
    928 
    929   @property

AttributeError: Tensor.op is meaningless when eager execution is enabled.
"
30359,TensorFlow C binding for Raspberry Pi,"**System information**
- TensorFlow version (you are using): 1.13.1
- Are you willing to contribute it (Yes/No): yes, at least as a tester

**Describe the feature and the current behavior/state.**
I asked on [StackOverflow if there was a TensorFlow C binding for ARM/RaspberryPi](https://stackoverflow.com/questions/56837317/how-can-i-get-a-tensorflow-c-binding-for-raspberry-pi) but I got no answer after many days. 

I couldn't find anything on the website, so I suspect this is not yet available? 

If it is just a matter that you don't distribute the binaries, I have no troubles to compile it myself if I have the instructions and if it is known to work. But I haven't found anything confirming that either. 

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
All language bindings that use the C library and want to run on any ARM board

**Any Other info.**
"
30357,[TF 1.14 Keras] probably bug in network._map_graph_network,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Both OS-X and Ubuntu
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 1.14.0 binary
- TensorFlow version (use command below): 1.14
- Python version: 3.6.
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
I have a CNN model that works well with tensorflow==1.13.1 (building the network, training the network and predicting from the network), but after the update to tensorflow==1.14.0 I'm getting following exception:

```
ValueError: Graph disconnected: cannot obtain value for tensor Tensor(""dropout_1/cond/Merge:0"", shape=(?, 160, 160, 16), dtype=float32) at layer ""concatenate"". The following previous layers were accessed without issue: ['net_input', 'initial_conv2D', 'batch_normalization', 'activation', 'conv2d', 'dropout']
```

**Other info / logs**
After debugging and going through the implementation of `network._map_graph_network` it seems to me that there is either some bug (significantly changed behaviour between tensorflow==1.13.1 and tensorflow 1.14.0) in the graph disconnections checking.
When I run the code with tensorflow==1.13.1 the tensorboard graph looks as follows:
![Screenshot 2019-07-03 at 16 36 37](https://user-images.githubusercontent.com/1810839/60600754-134b8780-9db1-11e9-811f-7f36afdc4a77.png)
From this I'm not sure why layer dropout_1 (conditional dropout) is checked in the concatenate layer? I assume that droupout should have been checked there?"
30356,Compiling custom GPU operation on Microsoft Windows 10,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Microsoft Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.12.3
- Python version: 3.5.0
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 0.17.2
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: 9
- GPU model and memory: NVIDIA Quadro P100



**Describe the problem**
I've been trying to get a custom operation working with a Windows version of TensorFlow GPU version from the guide: https://www.tensorflow.org/guide/extend/op#compiling_the_kernel_for_the_gpu_device


**Provide the exact sequence of commands / steps that you executed before running into the problem**

1. Clone the repository:

```powershell
git clone https://github.com/tensorflow/tensorflow.git 
```

I put my C++ implementation of sqrt_kernels.cc, sqrt.h, and sqrt_kernels.cu.cc in tensorflow\tensorflow\core\user_ops


**sqrt_kerenls.cc**
```c++
#if GOOGLE_CUDA
#define EIGEN_USE_GPU
#endif

#include ""sqrt.h""
#include <math.h>
#include ""tensorflow/core/framework/op_kernel.h""

using namespace tensorflow;

using CPUDevice = Eigen::ThreadPoolDevice;
using GPUDevice = Eigen::GpuDevice;

// CPU specialization of actual computation
template <typename T>
struct SqrtFunctor<CPUDevice, T>{

    void operator()(const CPUDevice& d, int size, const T* in, T* out){
        for(int i = 0; i < size; ++i){
            out[i] = sqrt(in[i]);
        }
    }
};

//Opkernel definition
//template paramter T is datatype of tensors

template <typename Device, typename T>
class SqrtOp : public OpKernel {
    public:
     explicit SqrtOp(OpKernelConstruction* context) : OpKernel(context) {}

     void Compute(OpKernelContext* context) override {

         const Tensor& input_tensor = context->input(0);

         Tensor* output_tensor = NULL;

         OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(), &output_tensor));

         OP_REQUIRES(context, input_tensor.NumElements() <= tensorflow:kint32max, errors::InvalidArgument(""Too many elements in tensor""));

         SqrtFunctor<Device, T>(){
             context->eigen_device<Device>(),
             static_cast<int>(input_tensor.NumElements()),
             input_tensor.flat<T>().data(),
             output_tensor->flat<T>().data());
         }
     }

};

//Register the Kernels
#define REGISTER_CPU(T)                     \
 REGISTER_KERNEL_BUILDER(                   \
        Name(""Sqrt"").Device(DEVICE_CPU).TypeConstraint<T>(""T""), \
        SqrtOp<CPUDevice, T>);
 REGISTER_CPU(float);
 REGISTER_CPU(int32);

#ifdef GOOGLE_CUDA
#define REGISTER_GPU(T)
 extern template struct SqrtFunctor<GPUDevice, T>;   \
REGISTER_KERNEL_BUILDER(
    Name(""Sqrt"").Device(DEVICE_GPU).TypeConstraint<T>(""T""), \
    SqrtOp<GPUDevice, T>);
REGISTER_GPU(float);
REGISTER_GPU(int32);
#endif
}
}
```

**sqrt_kenels.cu.cc**
```c++
#if GOOGLE_CUDA

#define EIGEN_USE_GPU

#include ""sqrt.h""
#include ""tensorflow/core/util/cuda_kernel_helper.h""


using namespace tensorflow;

using GPUDevice = Eigen::GpuDevice;

template <typename T>

__global__ void SqrtCudaKernel(const int size, const T* in, T* out){

    for(int i = blockIdx.x * blockDim.x + threadIdx.x; i < size; i += blockDim.x * gridDim.x){

        out[i] = sqrt(ldg(in + i));
    }
}

template <typename T>
struct SqrtFunctor<GPUDevice, T> {
    void operator()(const GPUDevice& d, int size, const T* in, T* out){

        int block_count = 1024;
        int thread_per_block = 20;

        SqrtCudaKernel<T> <<<block_count, thread_per_block, 0, d.stream()>>>(size,in,out);

    }
};

template struct SqrtFunctor<GPUDevice, float>;
template struct SqrtFunctor<GPUDevice, int32>;
}
}

#endif
```
**sqrt.h**

```c++
#ifndef SQRT_H_
#define SQRT_H_

namespace tensorflow {

namespace functor{


template <typename Device, typename T>

struct SqrtFunctor{
    void operator()(const Device&d, int size, const T* in, T* out);
};

#if GOOGLE_CUDA

template <typename Eigen::GpuDevice, typename T>
struct SqrtFunctor{
    void operator()(const Eigen::GpuDevice & d, int size, const T* in, T* out);
};
#endif

}

}

#endif
```

2. Afterwards I configure and built the tensorflow library by using bazel:

```powershell
python ./configure.py
```

3.  This is where I get my error after running this command:

```powershell
nvcc -std=c++11 -c -o cuda_op_kernel.cu.o cuda_op_kernel.cu.cc \
  ${TF_CFLAGS[@]} -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC
nvcc warning : The -std=c++11 flag is not supported with the configured host compiler. Flag will be ignored.
sqrt_kernels.cu.cc
cl : Command line warning D9002 : ignoring unknown option '-fPIC'
sqrt_kernels.cu.cc
C://Users//alayu//AppData//Local//Programs//Python//Python35//lib//site-packages//tensorflow//include\third_party/eigen3/unsupported/Eigen/CXX11/Tensor(1): fatal error C1083: Cannot open include file: 'unsupported/Eigen/CXX11/Tensor': No such file or directory
```

I found the file ""unsupported/Eigen/CXX11/Tensor'"" in the path that it said it couldn't find it in, so I don't know what the error could be. Does nvcc require a specific gcc version? If it requires me to downgrade, I had originally used cygwin to install the latest version and it doesn't seem like they include older versions in their installer.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30355,[TF 2.0 keras] tf.keras.Concatenate Graph Disconnected when concatenating non-sequentially,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary, pip install 
- TensorFlow version (use command below): tensorflow-gpu==2.0.0-beta1
- Python version: 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Describe the current behavior**
Error arises during Concatenate when I run the following code:

```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Conv2D, Concatenate

inputs = keras.Input(shape=(256,256,3))
x  = Conv2D(16,3, padding='same',activation='relu')(inputs)
x_list = [x]
for i in range(3):
    x = Conv2D(16,3, padding='same',activation='relu')(x)
    x_list.append(x)
    x = Concatenate(3)(x_list)

model = keras.Model(inputs=inputs, outputs=x)
model.summary()
```

`ValueError: Graph disconnected: cannot obtain value for tensor Tensor(""conv2d_31/Identity:0"", shape=(None, 256, 256, 16), dtype=float32) at layer ""concatenate_8"". The following previous layers were accessed without issue: ['input_9', 'conv2d_29', 'conv2d_30']`

This issue does not occur in a Tensorflow 1.X environment, only TF 2.0

**Describe the expected behavior**
Now the Concatenate function works properly when using a sequential model. That is, if I swap in ""for i in range(1):"" rather than ""for i in range(3):"" above, the code executes cleanly. However, the non-sequential repeated Concatenation in the loop leaves the  a Graph disconnected error.

Furthermore, the error is also eliminated when using tf.concat, so the following code also executes cleanly.

```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Conv2D, Concatenate

inputs = keras.Input(shape=(256,256,3))
x  = Conv2D(16,3, padding='same',activation='relu')(inputs)
x_list = [x]
for i in range(3):
    x = Conv2D(16,3, padding='same',activation='relu')(x)
    x_list.append(x)
    x = tf.concat(x_list, 3)

model = keras.Model(inputs=inputs, outputs=x)
model.summary()
```

Therefore, I do have a working alternative, but there does appear to be an issue with the keras Concatenate function"
30352,tensorflow.python.framework.errors_impl.NotFoundError,"I have built an LSTM model and try to run that with python flask.

tensorflow.python.framework.errors_impl.NotFoundError: Container localhost does not exist. (Could not find resource: localhost/embedding/embeddings)
	 [[{{node embedding/embedding_lookup}}]]
here is the image of error.

![screencapture-127-0-0-1-5002-predict-2019-07-03-18_18_18](https://user-images.githubusercontent.com/26489408/60592830-0cc40c80-9dbf-11e9-82a5-48ec7c835205.png)

"
30350,How to get model predictions on all classes after applying Transfer Learning in TF2.0?,"I have been following [transfer learning with TFHub](https://www.tensorflow.org/beta/tutorials/images/hub_with_keras) to implement transfer learning in my model for text classification. In the example, I do not understand how to get probabilities for all the classes (1000 classes before + 5 classes after implementing transfer learning). At the end of the tutorial, they only show predictions on the 5 classes on which the model was re-trained, but I want to have probabilities also on the 1000 classes. I can not find any documentation or explanation on how to achieve this. If anyone has any ideas or some useful links, please feel free to share. THANK YOU!
This was my main question.

**About model, where I want to implement this idea of transfer learning.**
I have a text dataset of 8000 classes, since the data size is too big so it can not be loaded into the RAM of my machine. So I want to train on small-small sizes of data i.e. 4000 classes and 4000 classes. I trained my model freshly on 4000 classes first, the learned model gives me good results. Now I want to retrain the saved model on the rest 4000 classes using Transfer Learning (I am also open to any other way), but after doing a lot of google searches seems like it is impossible to retrain a model on new classes, at least in text classification. If you have read this part and have some suggestions or ideas please share them, I will be very thankful. "
30349,Using pre trained tflite model on android,"Hello,
I have been trying to use your pre trained .tflite model on android app. Its giving me the following error:
java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite tensor with type FLOAT32 and a Java object of type [I (which is compatible with the TensorFlowLite type INT32)
This is when I use the command tfLite.runForMultipleInputsOutputs(inputArray, outputScoresNames); to run the model
If I use tfLite.run(inputs, outputScores); to run the model, it executes without error but always outputs only the first character in the list.
Could anyone help me with this error??
Thanks in advance."
30348,TensorFlow 1.14 artifacts on Maven Central?,The latest version of [tensorflow](https://mvnrepository.com/artifact/org.tensorflow/tensorflow) and [tensorflow-android](https://mvnrepository.com/artifact/org.tensorflow/tensorflow-android) artifacts is 1.13.1. Will version 1.14.0 be published?
30347,Can tensorflow support alluxio as storage filesystem?,"helloï¼Œ
   As a storage middle tier, alluxio can mount file systems such as hdfs, nfs, etc., while providing efficient caching capabilities. If tensorflow supports reading data directly from alluxio, it would be very beneficial."
30346,tf.keras.datasets not batched correctly,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code: yes
- OS Platform and Distribution Linux Mint 19
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1
- Python version: 3.6

**Describe the current behavior**
Using the return values of `tf.keras.datasets.Cifar10` in `model.fit` seems to process the entire dataset in one batch, independent of the given batch size.

**Describe the expected behavior**
Both versions should take the same amount of time.

**Code to reproduce the issue**
```
from tensorflow import keras

(x, y), _ = keras.datasets.cifar10.load_data()
x = (x / 255.0).reshape(x.shape[0], -1)

model = keras.Sequential([keras.layers.Dense(10)])

# commenting out these lines result in way slower training
x = x[0:10]
y = y[0:10]

model.compile(""sgd"", ""sparse_categorical_crossentropy"")
model.fit(x, y, epochs=1, batch_size=1, steps_per_epoch=10)

```

**Other info / logs**
The example as written:
```
10/10 [==============================] - 0s 5ms/step - loss: 7.4634
```

and with the marked lines commented out:
```
10/10 [==============================] - 8s 786ms/step - loss: 5.7648
```"
30345,Keras Reshape Layer in Functional API Seems Bugged,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux 5.1.15 kernel
- TensorFlow installed from (source or binary): Arch repository
- TensorFlow version (use command below): 1.14.0
- Python version: 3.7.3
- CUDA/cuDNN version: N/A, using CPU
- GPU model and memory: N/A

**Describe the current behavior**
I am getting the following error: Input to reshape is a tensor with 24576 values, but the requested shape has 1536

**Describe the expected behavior**
This sample code should run.
Editing out the skip connection makes the code run fine.
Do note that I have successfully used the Reshape functionality just fine in straight feedforward models. For some reason, this bug crops up when using Reshape in a skip connection as shown in the sample code below.

**Code to reproduce the issue**
```
import tensorflow as tf
import numpy as np

def Model():
    
    x = tf.keras.layers.Input((4,4,3)) # 4x4 image with 3 channels
    y = tf.keras.layers.Conv2DTranspose(3, 4, 2, padding='same') (x) # Creates a 8x8 images with 3 channels by upsampling with stride 2
    
    linear = tf.keras.layers.Dense(8*8*3) (x) # Linear transformation of the input
    linear = tf.keras.layers.Reshape([8, 8, 3]) (linear) # Reshapes the output of the linear transformation to the same shape as the upsampled image
    y = tf.keras.layers.Add() ([y, linear]) # adds them together
    
    return tf.keras.models.Model(inputs=x, outputs=y)

# model
model = Model()

# input data
array_range = np.random.randn(128, 4, 4,  3).astype(np.float32)
dataset = tf.data.Dataset.from_tensor_slices(array_range).batch(8)
iterator = dataset.make_one_shot_iterator()
next_element = iterator.get_next()
dataset_output = model(next_element)

# session
sess = tf.Session()
sess.run(tf.global_variables_initializer())

# evaluate
print(sess.run(dataset_output))
print(sess.run(dataset_output))
```

**Other info / logs**
```
runfile('/home/jaap/Dropbox/Python Projects/Code/Preprocessing/testing.py', wdir='/home/jaap/Dropbox/Python Projects/Code/Preprocessing')
Traceback (most recent call last):

  File ""<ipython-input-20-0a014c5b096e>"", line 1, in <module>
    runfile('/home/jaap/Dropbox/Python Projects/Code/Preprocessing/testing.py', wdir='/home/jaap/Dropbox/Python Projects/Code/Preprocessing')

  File ""/usr/lib/python3.7/site-packages/spyder_kernels/customize/spydercustomize.py"", line 827, in runfile
    execfile(filename, namespace)

  File ""/usr/lib/python3.7/site-packages/spyder_kernels/customize/spydercustomize.py"", line 110, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""/home/jaap/Dropbox/Python Projects/Code/Preprocessing/testing.py"", line 40, in <module>
    print(sess.run(dataset_output))

  File ""/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)

  File ""/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)

  File ""/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)

  File ""/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)

InvalidArgumentError: Input to reshape is a tensor with 24576 values, but the requested shape has 1536
	 [[node model_8/reshape_8/Reshape (defined at /home/jaap/Dropbox/Python Projects/Code/Preprocessing/testing.py:33) ]]

Original stack trace for 'model_8/reshape_8/Reshape':
  File ""/usr/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.7/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/usr/lib/python3.7/site-packages/spyder_kernels/console/__main__.py"", line 11, in <module>
    start.main()
  File ""/usr/lib/python3.7/site-packages/spyder_kernels/console/start.py"", line 310, in main
    kernel.start()
  File ""/usr/lib/python3.7/site-packages/ipykernel/kernelapp.py"", line 505, in start
    self.io_loop.start()
  File ""/usr/lib/python3.7/site-packages/tornado/platform/asyncio.py"", line 132, in start
    self.asyncio_loop.run_forever()
  File ""/usr/lib/python3.7/asyncio/base_events.py"", line 539, in run_forever
    self._run_once()
  File ""/usr/lib/python3.7/asyncio/base_events.py"", line 1775, in _run_once
    handle._run()
  File ""/usr/lib/python3.7/asyncio/events.py"", line 88, in _run
    self._context.run(self._callback, *self._args)
  File ""/usr/lib/python3.7/site-packages/tornado/ioloop.py"", line 758, in _run_callback
    ret = callback()
  File ""/usr/lib/python3.7/site-packages/tornado/stack_context.py"", line 300, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/lib/python3.7/site-packages/tornado/gen.py"", line 1233, in inner
    self.run()
  File ""/usr/lib/python3.7/site-packages/tornado/gen.py"", line 1147, in run
    yielded = self.gen.send(value)
  File ""/usr/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 365, in process_one
    yield gen.maybe_future(dispatch(*args))
  File ""/usr/lib/python3.7/site-packages/tornado/gen.py"", line 326, in wrapper
    yielded = next(result)
  File ""/usr/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 272, in dispatch_shell
    yield gen.maybe_future(handler(stream, idents, msg))
  File ""/usr/lib/python3.7/site-packages/tornado/gen.py"", line 326, in wrapper
    yielded = next(result)
  File ""/usr/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 542, in execute_request
    user_expressions, allow_stdin,
  File ""/usr/lib/python3.7/site-packages/tornado/gen.py"", line 326, in wrapper
    yielded = next(result)
  File ""/usr/lib/python3.7/site-packages/ipykernel/ipkernel.py"", line 294, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/usr/lib/python3.7/site-packages/ipykernel/zmqshell.py"", line 536, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 2848, in run_cell
    raw_cell, store_history, silent, shell_futures)
  File ""/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 2874, in _run_cell
    return runner(coro)
  File ""/usr/lib/python3.7/site-packages/IPython/core/async_helpers.py"", line 67, in _pseudo_sync_runner
    coro.send(None)
  File ""/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3049, in run_cell_async
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3220, in run_ast_nodes
    if (yield from self.run_code(code, result)):
  File ""/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3296, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-20-0a014c5b096e>"", line 1, in <module>
    runfile('/home/jaap/Dropbox/Python Projects/Code/Preprocessing/testing.py', wdir='/home/jaap/Dropbox/Python Projects/Code/Preprocessing')
  File ""/usr/lib/python3.7/site-packages/spyder_kernels/customize/spydercustomize.py"", line 827, in runfile
    execfile(filename, namespace)
  File ""/usr/lib/python3.7/site-packages/spyder_kernels/customize/spydercustomize.py"", line 110, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)
  File ""/home/jaap/Dropbox/Python Projects/Code/Preprocessing/testing.py"", line 33, in <module>
    dataset_output = model(next_element)
  File ""/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 634, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 751, in call
    return self._run_internal_graph(inputs, training=training, mask=mask)
  File ""/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 893, in _run_internal_graph
    output_tensors = layer(computed_tensors, **kwargs)
  File ""/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 634, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""/usr/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py"", line 467, in call
    (array_ops.shape(inputs)[0],) + self.target_shape)
  File ""/usr/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 7715, in reshape
    ""Reshape"", tensor=tensor, shape=shape, name=name)
  File ""/usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/usr/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()
```
"
30343, convolution VS correlation convolution ,"
I think the 

> tensorflow.nn.conv2d 

use the correlation convolution, but i need convolution in my layer. So do you have any advice?
"
30342,{Deeplab}{mobile}using deeplab on mobile,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):macOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:iPhone6+
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.12.0
- Python version:3.7
- Bazel version (if compiling from source):0.27.0
- GCC/Compiler version (if compiling from source):Nan
- CUDA/cuDNN version:Nan
- GPU model and memory:Nan

**Describe the current behavior**
Deeplab does not predict correctly on ios application
**Describe the expected behavior**
real-time fast and good detection 

**Other info / logs**
Hi, i have trained deeplab on my custom dataset(400*300) with 513 as crop size and during the test it detects for crop with crop size 3041 (the reason is that my data are iris images and the model used for iris detection on face images) .
now what I need is to integrate my model on ios application, i was able to successfully convert the model to tflite with GPU delegate but i notice that on mobile the crop size that i should use to get a good a fast detection is 257 but my problem that my model does not detect with 257 as crop size i need to use 3041 
does any on have an idea what should i do ??

"
30341,session still referable after sess.close(),"From my intuition, a session will be removed from memory once a close() method is called. However, you can still refer to a session even after explicitly closing it. Here is a little example:

```
import tensorflow as tf

sess = tf.Session()
print(sess)
sess.close()
print(sess)
```

Above code gives me such result:

`<tensorflow.python.client.session.Session object at 0x00000000029E9DD8>
<tensorflow.python.client.session.Session object at 0x00000000029E9DD8>`

My question is, since a session is not supposed to be reopened, what's the point of preserving it in memory? Is it that the closed session is ready for reopening or is it because it's just a reference and occupys no resource so it makes no difference wether or not the session is removed?"
30332,TensofflowLite on Andoid: Didn't find op for builtin opcode 'CONV_2D' version '2',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, I am using custom Flutter plugin for Firebase Custom model
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsun S10 / Emulator
- TensorFlow installed from (source or binary): tf-nightly
- TensorFlow version (use command below): 1.14
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Android library fails to load InceptionV3 model converted to TFLite.
```E/CustomCompatChecker(15099): The model is INCOMPATIBLE. It may contain unrecognized custom ops, or not FlatBuffer format: java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Didn't find op for built-in opcode 'CONV_2D' version '2'```
**Describe the expected behavior**
Model loaded. Simple models, or not optimized work. 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
1. Convert TF InceptionV3 to TFLite (with optimization for size)
2. Load model to Android device - fails sometimes not finding a matching model or the error above.
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30331,"Tensorflow2 tf.train.Checkpoint(), tf.train,CheckpointManager.save() got ValueError:substring not found","Hello.
I'm the beginner using tensorflow2. So could you help me a little?
Could you let me know how to save the model weight as ckpt files?

I just try to save the weight like below

#################################################################
optimizer = tf.keras.optimizers.Adam(FLAGS.lr)
loss_object =tf.losses.sparse_categorical_crossentropy
ckpt = tf.train.Checkpoint(step=tf.Variable(0), optimizer=optimizer, model=model)
manager = tf.train.CheckpointManager(ckpt, './tf_ckpts/', max_to_keep=3)

def train_one_step(data, label, model, optimizer):
    with tf.GradientTape() as tape:
        pred, end_points= model(data)
        loss = loss_object
        ckpt.step.assign_add(1)
        if int(ckpt.step) % 10 == 0:
            save_path = manager.save()
            print (""Saved checkpoint for step {}: {}"".format(int(ckpt.step), save_path))

loss, pred, label = train_one_step(train_data, train_label, model, optimizer)

but I have the error like below. Do you happen to know the reason?!
Thank you in advance.

File """", line 1, in
runfile('/home/kevin/Downloads/3D/pointnet2/tf2_train.py', wdir='/home/kevin/Downloads/3D/pointnet2')

File ""/home/kevin/anaconda3/lib/python3.6/site-packages/spyder/utils/site/sitecustomize.py"", line 705, in runfile
execfile(filename, namespace)

File ""/home/kevin/anaconda3/lib/python3.6/site-packages/spyder/utils/site/sitecustomize.py"", line 102, in execfile
exec(compile(f.read(), filename, 'exec'), namespace)

File ""/home/kevin/Downloads/3D/pointnet2/tf2_train.py"", line 188, in
train(train_dataset)

File ""/home/kevin/Downloads/3D/pointnet2/tf2_train.py"", line 173, in train
loss, accuracy = train_one_epoch(MODEL, optimizer, train_dataset)

File ""/home/kevin/Downloads/3D/pointnet2/tf2_train.py"", line 151, in train_one_epoch
loss, pred, label = train_one_step(train_data, train_label, model, optimizer)

File ""/home/kevin/Downloads/3D/pointnet2/tf2_train.py"", line 98, in train_one_step
save_path = ckpt.save(model)

File ""/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py"", line 1840, in save
file_path = self.write(""%s-%d"" % (file_prefix, checkpoint_number))

File ""/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py"", line 1770, in write
output = self._saver.save(file_prefix=file_prefix)

File ""/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py"", line 1106, in save
file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)

File ""/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py"", line 1046, in _save_cached_when_graph_building
object_graph_tensor=object_graph_tensor)

File ""/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py"", line 1014, in _gather_saveables
feed_additions) = self._graph_view.serialize_object_graph()

File ""/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/graph_view.py"", line 381, in serialize_object_graph
trackable_objects, path_to_root)

File ""/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/graph_view.py"", line 355, in _serialize_gathered_objects
object_map=object_map))

File ""/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/graph_view.py"", line 264, in _add_attributes_to_object_graph
[maybe_saveable], convert_variable_to_tensor=False)

File ""/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py"", line 270, in op_list_to_dict
set_var = names_to_saveables.setdefault(var._shared_name, var)

File ""/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 1087, in _shared_name
return self.name[:self.name.index("":"")]

ValueError: substring not found

"
30330,tf.keras.utils.multi_gpu_model use only one GPU when using sequential model,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):1.14
- Are you willing to contribute it (Yes/No):No



**Describe the feature and the current behavior/state.**
The tf.keras.utils.multi_gpu_model doesn't work well with sequential model. Only one GPU is working.
**Will this change the current api? How?**
No

**Who will benefit with this feature?**
Everyone who use keras with multi-gpu system.

**Any Other info.**"
30329,ImportError: /lib64/libc.so.6: version `GLIBC_2.15' not found on importing Keras,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30324,Memory leak in eager mode when creating keras model in loop,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: not tested
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-5259-ge703239 1.15.0-dev20190629
- Python version: 3.7.3
- Bazel version (if compiling from source): not compiled from source
- GCC/Compiler version (if compiling from source): not compiled from source
- CUDA/cuDNN version: using CPU
- GPU model and memory: using CPU

**Describe the current behavior**

In eager execution, when creating a `tf.keras.Sequential` model inside a loop and discarding it immediately, the memory increases over time. The following code shows this by printing the used memory at each iteration.

```python
import psutil
import tensorflow as tf

tf.compat.v1.enable_eager_execution()

for _ in range(100):
    tf.keras.Sequential([tf.keras.layers.Dense(3000, input_dim=3000)])
    print(psutil.virtual_memory().used / 2 ** 30)
```

Output:

```
1.0170440673828125
1.0506706237792969
1.0841865539550781
1.1179122924804688
[...]
4.285423278808594
4.318950653076172
4.35223388671875
```

The same result happens when using the Functional API or Model subclassing API. Adding `tf.keras.backend.clear_session()` in the loop solves the leak in all cases like in graph mode. To see this effect better, one should additionally use `gc.collect()` in the loop.

**Describe the expected behavior**

While adding `tf.keras.backend.clear_session()` to the loop helps, this should not be necessary because in eager execution there is no graph to clear, which according to the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session) seems to be the only thing this function does:

> Destroys the current TF graph and creates a new one.

Therefore it is also suprising that this function helps at all during eager execution. The expected behavior is that there is no memory leak even without `tf.keras.backend.clear_session()`. 

**Code to reproduce the issue**
Code is in description above.

**Other info / logs**
Nothing here."
30321,tensorflow 2.0 keras multi_gpu_model only utilizing one GPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary, pip install
- TensorFlow version (use command below): tensorflow-gpu==2.0.0-beta1
- Python version: 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: cudatoolkit 10.0.130, cudnn 7.6.0
- GPU model and memory: 4x NVIDIA GeForce GTX 1080 Ti

**Describe the current behavior**
When using multi_gpu_model (i.e., tf.keras.utils.multi_gpu_model) in tensorflow 2.0 to distribute a job across multiple gpus (4), only one gpu appears to be used. That is when monitoring the GPU usage only one GPU shows substantial dedicated GPU memory usage and GPU utility. 

**Describe the expected behavior**
Each of the 4 GPUs should indicate that memory is being copied to the device and processed.

**Code to reproduce the issue**
While my issue arises with custom code using model.fit_generator, I was able to replicate the issue using model.fit with documentation code provided at https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/utils/multi_gpu_model

```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import Xception
from tensorflow.keras.utils import multi_gpu_model
import numpy as np

num_samples = 1000
height = 224
width = 224
num_classes = 1000

# Instantiate the base model (or ""template"" model).
# We recommend doing this with under a CPU device scope,
# so that the model's weights are hosted on CPU memory.
# Otherwise they may end up hosted on a GPU, which would
# complicate weight sharing.
with tf.device('/cpu:0'):
    model = Xception(weights=None,
                     input_shape=(height, width, 3),
                     classes=num_classes)

# Replicates the model on 8 GPUs.
# This assumes that your machine has 8 available GPUs.
parallel_model = multi_gpu_model(model, gpus=4) # gpus changed to 4
parallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

# Generate dummy data.
x = np.random.random((num_samples, height, width, 3))
y = np.random.random((num_samples, num_classes))

parallel_model.summary()
# This `fit` call will be distributed on 8 GPUs.
# Since the batch size is 256, each GPU will process 32 samples.
parallel_model.fit(x, y, epochs=20, batch_size=16) #batch_sized changed to 16
```

"
30319,TensorFlow does not work without tcmalloc in some cases (boosted trees).,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.4
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A
- **TensorFlow installed from (source or binary)**: binary from pip
- **TensorFlow version (use command below)**: v1.14.0-rc1-22-gaf24dc91b5 1.14.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: 

  1. launch jupyter notebook,
  2. download tutorial from google colab (https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/estimators/boosted_trees.ipynb),
  3. run the notebook.



### Describe the problem


Hi, I'm currently learning TensorFlow from the tutorials of the TF site.

But, during exercise in the tutorial (https://www.tensorflow.org/tutorials/estimators/boosted_trees), I got a strange error.

TensorFlow was constantly crashed with the code, although it was provided from official site. I tried both jupyter notebook and plain python code.

So I googled the problem a little bit, and found that there's a workaround (https://github.com/tensorflow/tensorflow/issues/6968), i.e.,

```bash
sudo apt install libtcmalloc-minimal4
export LD_PRELOAD=""/usr/lib/libtcmalloc_minimal.so.4""
```

And then the code worked flawlessly.

However, this leaves another questions, and these are what I really wonder;

1. does this problem happen to some boundary cases like mine? Perhaps I am missing some configurations. I'll be glad to let me know.

2. if not, that is, `tcmalloc` is necessary for the TensorFlow, and considering that `tcmalloc` is not distributed with the every default linux (for example, ubuntu) installations, might be there a better way to evade this situation?



### Source code / logs


Before applying the `tcmalloc` package, jupyter kernel died with this message,

```
Kernel Restarting

The kernel appears to have died. It will restart automatically.
```

Here is some snippet of the log message.


```
*** Error in `/home/sungjin/.virtualenvs/boost/bin/python3': malloc(): memory corruption (fast): 0x00007fe0e804d6d0 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7fe1f56097e5]
```



"
30317,tf.nn.depthwise_conv2d does not preserve number of channels,"edit: _**you can skip reading this post, go to the next one directly**_

**System information**

- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from: pip
- TensorFlow version (use command below): 1.13.1
- Python version: 1.13.1
- CUDA/cuDNN version: 10
- GPU model and memory: RTX 2080 Ti

**Describe the current behavior**
if I  look at the tensor before and after the depthwise_conv2d:
```
ic| x: <tf.Tensor 'fusion/upsample/transpose_1:0' shape=(?, 128, ?, ?) dtype=float32>
ic| x: <tf.Tensor 'fusion/dwconv1/BatchToSpaceND:0' shape=(?, ?, ?, ?) dtype=float32>
```

**Describe the expected behavior**
if I  look at the tensor before and after the depthwise_conv2d the channel number should be preserved, and look something like this:
```
ic| x: <tf.Tensor 'fusion/upsample/transpose_1:0' shape=(?, 128, ?, ?) dtype=float32>
ic| x: <tf.Tensor 'fusion/transpose_1:0' shape=(?, 128, ?, ?) dtype=float32>
```

so IMO depthwise_conv2d with dilations  and NCHW it's loosing the information about number of channels 

**Code to reproduce the issue**

because tf.layers.depthwise_conv2d is not implemented, I implemented this:

```
def _depthwise_conv2d(self, tensor, kernel_size, strides, rate=[1, 1], name='dwconv'):
    """"""Problem: doesn't support channel first + dilations""""""
    c = self._n_channels(tensor)
    filter_shape = [kernel_size[0], kernel_size[1], c, 1]
    filter = tf.get_variable(name + ""/filter"", shape=filter_shape, dtype=tf.float32)
    strides = [1, 1, strides[0], strides[1]]
    tensor = tf.nn.depthwise_conv2d(tensor, filter, strides, padding='SAME',
                                    rate=rate, name=name, data_format='NCHW')
    return tensor
```
this works:
```
x = self._depthwise_conv2d(x, (3, 3), (1, 1), name='dwconv2')
```
but this does not:
(the difference is dilations or specifically dilations + NCHW data format)
```
x = self._depthwise_conv2d(x, (3, 3), (1, 1), [4, 4], name='dwconv1')
```

is gives following error on the batch_norm which follows the depthwise_conv2d
```
    x = tf.layers.batch_normalization(x, self.caxis, training=self.training)
  File ""~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""~/.local/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py"", line 313, in batch_normalization
    return layer.apply(inputs, training=training)
  File ""~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1227, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""~/.local/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 530, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File ""~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 538, in __call__
    self._maybe_build(inputs)
  File ""~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1603, in _maybe_build
    self.build(input_shapes)
  File ""~/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/normalization.py"", line 306, in build
    input_shape)
ValueError: ('Input has undefined `axis` dimension. Input shape: ', TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(None)]))
```



"
30316,The docs are unscrollable with JavaScript disabled,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/stack

## Description of issue (what needs changing):

```css
body[pending] {
	overflow: hidden;
}
```

should be removed.

### Clear description
JS is considered harmful, so the docs should be usable without JS.

The same problem is present in Android and Fuchsia docs.
"
30315,TFlite conversion of Conv1D with dilation !=1,"

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tensorflow==2.0.0-beta1
- Python version: python3


**Describe the current behavior**
After converting a Conv1D op to tensorflow lite the interpreter cannot allocate tensors:

` tensorflow/lite/kernels/space_to_batch_nd.cc:96 NumDimensions(op_context.input) != kInputDimensionNum (3 != 4)Node number 0 (SPACE_TO_BATCH_ND) failed to prepare.
`


**Describe the expected behavior**
Tflite model should be able to load and execute.

**Code to reproduce the issue**

```
!pip install -q tensorflow==2.0.0-beta1

import tensorflow as tf

from tensorflow.keras.models import Model
from tensorflow.keras.layers import *

def get_model():
  input = tf.keras.Input(shape=(10,40))
  
  #No error when dilation rate == 1
  layer = Conv1D(32, (3),dilation_rate =2, padding='same',use_bias=False) (input)
  layer = GlobalMaxPooling1D()(layer)
  output = Dense(2) (layer)

  model = Model(inputs=[input], outputs=[output])
  return model


model = get_model()

converter = tf.lite.TFLiteConverter.from_keras_model(model)

tflite_model = converter.convert()
open(""./trained_model.tflite"", ""wb"").write(tflite_model)


interpreter = tf.lite.Interpreter(model_path=""./trained_model.tflite"")

interpreter.allocate_tensors()
```


**Other info / logs**
The problem does not occur when dilation_rate ==1"
30314,TensorFlow Lite Micro int8 quantization support?,"

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: STM32F746G
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: '1.14.0'
- **Python version**: 3.7.3
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**: 
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: 

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
[feature request] 
.tflite model exported with a tensorflow version > r.1.13 are not compatible anymore with TensorFlow Lite Micro experimental Library. 

Kernels functions has to be updated to support asymetric per-axis quantization. 

Is there any release schedule on this lib?


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
30313,android GpuDelegate: even the simplest tflite converted models seems to run on CPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): tf docker images
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: oneplus5, pixel3, galaxy s10
- TensorFlow installed from (source or binary): various
- TensorFlow version (use command below): 1.12.0, 1.13.1, 1.14.0, 1.15.0-dev20190628, r1.14 source build
- Python version: 3.x
- Bazel version (if compiling from source): 0.25.2
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
tflite converted models seems to always run on cpu despite using gpudelegate, for example the simplest model from https://github.com/tensorflow/tensorflow/issues/30311 runs for hundreds of milliseconds per inference no matter whether cpu or gpudelegate is used, while stock mobilenet_v1 (no quantization, no manual tflite conversion, downloaded tflite model) runs ~80ms per inference on this device when using gpudelegate and 150-300ms on cpu.

**Describe the expected behavior**
tflite to actually use GPU when running conv2d networks

**Code to reproduce the issue**
attached NHW3 model (and script to generate pb and tflite with optimization options, which do not have any effect), this is basically NHW3 input, single tf.layers.conv2d() constant-initialized layer and reduce_sum() for output.

Any hint on debugging this issue?
I tested both jcenter downloaded (0.0.0-nightly branches) and manually built from r1.14 branch tensorflow-lite and tensorflow-lite-gpu.
I used 1.12.0, 1.13.1, 1.14.0, 1.15.0-dev20190628, r1.14 source build tensorflow/tflite with different optimization options with no success.

Could you please show how *exactly* you generated mobilenet_v1 tflite model found in your tutorials, since it works like a charm with gpudelegate: ~80ms per single-image inference on gpu and several hundreds seconds on cpu on sufficiently recent android. Or any hints on how to debug this gpudelegate issue.

[test_model_3channels.tar.gz](https://github.com/tensorflow/tensorflow/files/3350552/test_model_3channels.tar.gz)"
30311,TFLite's DepthwiseConv2D is broken with GpuDelegate for 1-channel input,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): tf docker images
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: oneplus5, pixel3, galaxy s10
- TensorFlow installed from (source or binary): various
- TensorFlow version (use command below):  1.14.0, 1.15.0-dev20190628, r1.14 source build
- Python version: 3.x
- Bazel version (if compiling from source): 0.25.2
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
When using supersimple network consisting of NHWC input, single tf.layers.conv2d() layer (constant initialized) and reduce_sum output, output for C=3 is the same for CPU (host tf and tflite and android tflite) and android GpuDelegate are kind of the same (less than 2% difference). When using C=1 CPU host (tf and tflite) and android on CPU are kind of the same (less than 10% difference), but android GpuDelegate produces drastically different output.

**Describe the expected behavior**
produce kind of the same results for the same models (no matter C=1 or C=3) for CPU host tf and tflite and android tflite on CPU and GpuDelegate.

**Code to reproduce the issue**
Attached archive with broken model generated with 1.15.0-dev20190628 tflite converted with default options (no properties changed) and script to create model and tflite file itself.

**Other info / logs**
I tested tflite both from nightly build from jcenter and local builds from r1.14 branch.
Here are the results when providing 1.224.224.1 image filled with 0.1 value:
cpu host tf: 5677536.5,
cpu host tflite: 6028237.0 (6.2% difference)
android cpu: 6028237
android gpudelegate: 44336.1

[test_model.tar.gz](https://github.com/tensorflow/tensorflow/files/3350494/test_model.tar.gz)

Also, tflite converted models seems to always run on cpu despite using gpudelegate, for example this model runs for hundreds of milliseconds no matter whether cpu or gpudelegate is used, while stock mobilenet_v1 (no quantization) runs ~80ms per inference on this device when using gpudelegate and 150-300ms on cpu.
I will fill another bug report for this though"
30310,[TensorFlow 2.0] Automated naming of keras metric layers is not consistent,"**System information**
- Have I written custom code: **yes**
- OS Platform and Distribution: **Mac OS X 10.14.5**
- TensorFlow installed from: **binary**
- TensorFlow version: **v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1**
- Python version: **3.6.8**
- CUDA/cuDNN version: **don't have a GPU**
- GPU model and memory: **don't have a GPU**

**Describe the current behavior**

The automatic naming of Keras metric layers is not consistent.  Example, if I create two `BinaryAccuracy` metrics:

```python
>>> tf.keras.metrics.BinaryAccuracy().name
'binary_accuracy'
>>> tf.keras.metrics.BinaryAccuracy().name
'binary_accuracy'
```

Whereas, if I create two `Recall` metrics:

```python
>>> tf.keras.metrics.Recall().name
'recall'
>>> tf.keras.metrics.Recall().name
'recall_1'
```

After testing every metric class in `tf.keras.metrics`, I found that the same behavior as `Recall` is produced by the following metrics:

- `AUC`
- `FalseNegatives`
- `FalsePositives`
- `MeanIoU`
- `MeanRelativeError`
- `Precision`
- `Recall`
- `SensitivityAtSpecificity`
- `SpecificityAtSensitivity`
- `TrueNegatives`
- `TruePositives`

**Describe the expected behavior**

Either all the metrics should be created with the exact same name, or they should all have an integer added to the end of the second metric with that name.

**Code to reproduce the issue**

Here's my code that lists all the classes in `tf.keras.metrics` that have different names when instanciated twice:

```python
import tensorflow as tf
import inspect

for name, metric in tf.keras.metrics.__dict__.items():
    if inspect.isclass(metric):  # It's a metric keras layer
        args = ()
        if name == 'MeanIoU':
            args = (2,)
        elif name == 'MeanRelativeError':
            args = ([1],)
        elif name == 'Metric':
            continue
        elif name == 'SensitivityAtSpecificity':
            args = (0.5,)
        elif name == 'SpecificityAtSensitivity':
            args = (0.5,)

        layer_name_0 = metric(*args).name
        layer_name_1 = metric(*args).name

        if layer_name_0 != layer_name_1:  # Two same metrics don't have the same name
            print('-', name)
```"
30309,tf.keras.layers.Conv1DTranspose ?,"This is somewhat related to the issue #8729, which is already solved.
In the issue, tf.nn.conv1d_transpose was requested and implemented in the end.

But the corresponding function in tf.layers or tf.keras is missing.
In other words, there's no function like tf.layers.conv1d_transpose, tf.keras.layers.Conv1DTranspose.

Can you please implement it?
Since there's already tf.nn.conv1d_transpose, I guess it doesn't take so much time to implement it."
30308,XLA Warning,"<!--This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.-->

I am receiving this warning,
```
W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
``` 
in one of my travic ci builds. AFAIK, XLA is going through active development and therefore I prefer not to use, `TF_XLA_FLAGS=--tf_xla_cpu_global_jit`. However, I cannot figure out how to silence this warning, permanently during future builds. If any such technique exists then I would suggest to add that to warning itself. 
Please let me know, if it can be done by manipulating env variables. Thanks. 
"
30307,categorical feature columns usage together with DenseFeatures layers in Keras fails with 1.14,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **MacOS** and **Ubuntu**
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):  1.14 and nightly. **This code works with 2.0.0b1**

**Describe the current behavior**

`feature_column.categorical_column_with_vocabulary_list` does not correctly works with TF 1.14 and nightly when using it together with `tf.keras.layers.DenseFeatures`.

We get the error: 

```Table not initialized.
FailedPreconditionError: Table not initialized.
	 [[{{node sequential/dense_features/x_embedding/hash_table_Lookup/LookupTableFindV2}}]]```
```

**Describe the expected behavior**

Expected to fit the model without errors.

**Code to reproduce the issue**

```
import tensorflow as tf
import numpy as np
tf.__version__

x = np.random.choice(3, 1000)
x = np.reshape(x, newshape=[1000,1])

y = np.random.normal(size = 1000)

fc = tf.feature_column.categorical_column_with_vocabulary_list(""x"",vocabulary_list=[0,1,2,3])
em = tf.feature_column.embedding_column(fc, dimension = 10)

model = tf.keras.Sequential([
  tf.keras.layers.DenseFeatures(feature_columns=[em]),
  tf.keras.layers.Dense(units = 1)
])

model.compile(loss = ""mse"", optimizer = ""adam"")

model.fit(x = {'x': x}, y = y)
```

fails with log:

```
2019-07-02 13:27:03.558149: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-02 13:27:03.575154: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8bb54f5f00 executing computations on platform Host. Devices:
2019-07-02 13:27:03.575169: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-02 13:27:03.615659: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1558] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-02 13:27:03.763974: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at lookup_table_op.cc:809 : Failed precondition: Table not initialized.
FailedPreconditionError: Table not initialized.
	 [[{{node sequential/dense_features/x_embedding/hash_table_Lookup/LookupTableFindV2}}]]
```
"
30306,[tf.keras] predict_generator stuck with using use_multiprocessing=True,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian 9.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.14
- Python version: 3.5
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: 10.0
- GPU model and memory: Tesla P100 - 16280MiB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When I use `model.predict_generator` with `use_multiprocessing=True` the code gets stuck.
**Describe the expected behavior**
Ideally the code should not get stuck and all cores should be used for predictions.
**Code to reproduce the issue**

```
from tensorflow.keras.layers import Conv3D, MaxPool3D, Flatten, Dense
from tensorflow.keras.layers import Dropout, Input, BatchNormalization
from tensorflow.keras.layers import AvgPool3D
from tensorflow.keras import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import Sequence
from tensorflow.keras import callbacks
from tensorflow.keras.layers import Concatenate, Add
from tensorflow.keras.estimator import model_to_estimator
from tensorflow.keras.utils import multi_gpu_model
from tensorflow.keras.utils import Sequence
import tensorflow as tf


def build_model(input_shape=(128, 128, 50, 1), n_class=3, multilabel=False):
   
    def spatial_reduction_block(inputs, block_name):
        filters = inputs._shape_as_list()[-1]
        with tf.name_scope(block_name):
            maxpool = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same')(inputs)
            conv_a_0 = Conv3D(filters=filters//4, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding='same', activation='relu')(inputs)
            conv_b_0 = Conv3D(filters=filters, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)
            conv_c_0 = Conv3D(filters=filters, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)

            conv_b_1 = Conv3D(filters=(5*filters)//16, kernel_size=(3, 3, 3), strides=(2, 2, 2), 
                              padding='same', activation='relu')(conv_b_0)
            conv_c_1 = Conv3D(filters=(5*filters)//16, kernel_size=(3, 3, 3), strides=(1, 1, 1), 
                              padding='same', activation='relu')(conv_c_0)
            conv_c_2 = Conv3D(filters=(7*filters)//16, kernel_size=(3, 3, 3), strides=(2, 2, 2), 
                              padding='same', activation='relu')(conv_c_1)

            concat_output = Concatenate()([maxpool, conv_a_0, conv_b_1, conv_c_2])

        return concat_output

    def residual_convolution_block(inputs, block_name):
        filters = inputs._shape_as_list()[-1]
        with tf.name_scope(block_name):
            conv_a_0 = Conv3D(filters=filters//2, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu')(inputs)
            conv_b_0 = Conv3D(filters=filters//2, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)
            conv_c_0 = Conv3D(filters=filters//2, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)

            conv_b_1 = Conv3D(filters=filters//2, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu')(conv_b_0)
            conv_c_1 = Conv3D(filters=filters//2, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu')(conv_c_0)
            conv_c_2 = Conv3D(filters=filters//2, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu')(conv_c_1)

            concat_output = Concatenate()([conv_a_0, conv_b_1, conv_c_2])

            conv_d_0 = Conv3D(filters=filters, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(concat_output)

            add_1 = Add()([conv_d_0, inputs])

        return add_1
    
    if not multilabel:
        activation_fn = 'softmax'
    else:
        activation_fn = 'sigmoid'
    
    inputs = Input(shape=input_shape, name='inputs')
    conv_1 = Conv3D(filters=64, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)
    spatial_reduction_block_1 = spatial_reduction_block(conv_1, 'spatial_reduction_block_1')
    residual_convolution_block_1 = residual_convolution_block(spatial_reduction_block_1, 'residual_convolution_block_1')
    spatial_reduction_block_2 = spatial_reduction_block(residual_convolution_block_1, 'spatial_reduction_block_2')
    residual_convolution_block_2 = residual_convolution_block(spatial_reduction_block_2, 'residual_convolution_block_2')
    conv_2 = Conv3D(filters=512, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(residual_convolution_block_2)
    maxpool_1 = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(conv_2)
    conv_3 = Conv3D(filters=1024, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(maxpool_1)
    maxpool_2 = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(conv_3)
    flatten = Flatten()(maxpool_2)
    dropout_1 = Dropout(rate=0.2)(flatten)
    dense_1 = Dense(512, activation='sigmoid')(dropout_1)
    dropout_2 = Dropout(rate=0.2)(dense_1)
    outputs = Dense(n_class, activation=activation_fn, name='outputs')(dropout_2)
    
    model = Model(inputs=inputs, outputs=outputs)
    return model

model = build_model((128,128,50, 1), 3, False)

class mygenerator(Sequence):
    def __init__(self, x_set, y_set, batch_size, augment=False):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size
        self.augment = augment
    
    def __len__(self):
        return int(np.ceil(len(self.x) / float(self.batch_size)))
    
    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
        
        x = [read_image(filename, self.augment) for filename in batch_x] # read a numpy array named filename
        y = [read_label(label) for label in batch_y]
        
        return np.array(x), np.array(y)

test_generator = mygenerator(X_TEST, Y_TEST, eval_batch_size, augment=False)

preds = model.predict_generator(test_generator, verbose=1, use_multiprocessing=True, steps=eval_steps)

```
**Other info / logs**
NA"
30305,load model.meta and checkpoint and model.data-00000-of-00001 and model.index,"**Tensorflow version:1.12
I have built libtensorflow_cc.so and test it with few examples successfully but when i wanted to transplate my python code below to c++ verison , i failed.**
`import tensorflow as tf
import  numpy as np
from skimage import io, transform
import cv2
#import infer
sess = tf.Session()
new_saver = tf.train.import_meta_graph(r'D:\CNN_test_result_sizhuangzao_model\v2_101_ziji_9\model\model.meta')
new_saver.restore(sess,tf.train.latest_checkpoint(r'D:\CNN_test_result_sizhuangzao_model\v2_101_ziji_9\model'))

graph = tf.get_default_graph()
input_x = graph.get_tensor_by_name(""input:0"")
is_training_x=graph.get_tensor_by_name(""is_training:0"")
#print (sess.run(""input:0""))

jpg_path=r""D:\CNN_test_result_sizhuangzao\chaodacesiji1\pos.txt""
file = open(jpg_path)
lines = file.readlines()
num=0
for line in lines: 
    img0 = io.imread(line.strip())
    l=img0.shape
    k=l[0]
    c=l[1]
    num+=1
    print(num)
    if  c/k<5:
        continue
    img = transform.resize(img0, (48,160, 1))
    feed_dict={input_x:np.reshape(img, [-1, 48, 160, 1]),is_training_x:False}

    prob_op = graph.get_operation_by_name('output')
    out_softmax = graph.get_tensor_by_name(""output:0"")
    img_out_softmax = sess.run(out_softmax,feed_dict)
    prediction_labels = np.argmax(img_out_softmax,1)`

**Here is my c++ version code below and the error information is 'ERROR: RUN failed...Invalid argument: Expects arg[1] to be bool but float is provided ' when i try to run.** 
`#include ""tensorflow/core/framework/graph.pb.h""
#include <tensorflow/core/public/session_options.h>
#include <tensorflow/core/protobuf/meta_graph.pb.h>
#include <fstream>
#include <utility>
#include <vector>
#include <Eigen/Core>
#include <Eigen/Dense>

#include ""tensorflow/cc/ops/const_op.h""
#include ""tensorflow/cc/ops/image_ops.h""
#include ""tensorflow/cc/ops/standard_ops.h""
#include ""tensorflow/core/framework/graph.pb.h""
#include ""tensorflow/core/framework/tensor.h""
#include ""tensorflow/core/graph/default_device.h""
#include ""tensorflow/core/graph/graph_def_builder.h""
#include ""tensorflow/core/lib/core/errors.h""
#include ""tensorflow/core/lib/core/stringpiece.h""
#include ""tensorflow/core/lib/core/threadpool.h""
#include ""tensorflow/core/lib/io/path.h""
#include ""tensorflow/core/lib/strings/stringprintf.h""
#include ""tensorflow/core/platform/env.h""
#include ""tensorflow/core/platform/init_main.h""
#include ""tensorflow/core/platform/logging.h""
#include ""tensorflow/core/platform/types.h""
#include ""tensorflow/core/public/session.h""
#include ""tensorflow/core/util/command_line_flags.h""

using namespace std;
using namespace tensorflow;
using namespace tensorflow::ops;
using tensorflow::Flag;
using tensorflow::Tensor;
using tensorflow::Status;
using tensorflow::string;
using tensorflow::int32;

typedef std::vector<std::pair<std::string, tensorflow::Tensor>> tensor_dict;
using tensorflow::Status;

static Status ReadtheFile(tensorflow::Env* env, const string& filename,Tensor* output) {
  tensorflow::uint64 file_size = 0;
  TF_RETURN_IF_ERROR(env->GetFileSize(filename, &file_size));

  string contents;
  contents.resize(file_size);

  std::unique_ptr<tensorflow::RandomAccessFile> file;
  TF_RETURN_IF_ERROR(env->NewRandomAccessFile(filename, &file));

  tensorflow::StringPiece data;
  TF_RETURN_IF_ERROR(file->Read(0, file_size, &data, &(contents)[0]));
  if (data.size() != file_size) {
    return tensorflow::errors::DataLoss(""Truncated read of '"", filename,
                                        ""' expected "", file_size, "" got "",
                                        data.size());
  }
//  output->scalar<string>()() = data.ToString();
  output->scalar<string>()() = string(data);
  return Status::OK();
}

Status ReadImageFile(const string& file_name, const int input_height,
                               const int input_width, const float input_mean,
                               const float input_std,
                               std::vector<Tensor>* out_tensors) {
  auto root = tensorflow::Scope::NewRootScope();
  using namespace ::tensorflow::ops;

  string input_name = ""file_reader"";
  string output_name = ""normalized"";

  // read file_name into a tensor named input
  Tensor input(tensorflow::DT_STRING, tensorflow::TensorShape());
  TF_RETURN_IF_ERROR(ReadtheFile(tensorflow::Env::Default(), file_name, &input));

  // use a placeholder to read input data
  auto file_reader =Placeholder(root.WithOpName(""input""), tensorflow::DataType::DT_STRING);

  std::vector<std::pair<string, tensorflow::Tensor>> inputs = {{""input"", input},};

  // Now try to figure out what kind of file it is and decode it.
    const int wanted_channels = 1;
    tensorflow::Output image_reader;
	if (tensorflow::str_util::EndsWith(file_name, "".png""))
	{
	  image_reader = DecodePng(root.WithOpName(""png_reader""), file_reader,
							   DecodePng::Channels(wanted_channels));
	}
	else if (tensorflow::str_util::EndsWith(file_name, "".gif""))
	{
	  // gif decoder returns 4-D tensor, remove the first dim
	  image_reader =
		  Squeeze(root.WithOpName(""squeeze_first_dim""),
				  DecodeGif(root.WithOpName(""gif_reader""), file_reader));
	}
	else if (tensorflow::str_util::EndsWith(file_name, "".bmp""))
	{
	  image_reader = DecodeBmp(root.WithOpName(""bmp_reader""), file_reader);
	}
	else
	{
	  // Assume if it's neither a PNG nor a GIF then it must be a JPEG.
	  image_reader = DecodeJpeg(root.WithOpName(""jpeg_reader""), file_reader,
								DecodeJpeg::Channels(wanted_channels));
	}
  // Now cast the image data to float so we can do normal math on it.
  auto float_caster =Cast(root.WithOpName(""float_caster""), image_reader, tensorflow::DT_FLOAT);

  auto dims_expander = ExpandDims(root.WithOpName(""expand""), float_caster, 0);

  float input_max = 255;
  Div(root.WithOpName(""div""),dims_expander,input_max);

  tensorflow::GraphDef graph;
  TF_RETURN_IF_ERROR(root.ToGraphDef(&graph));

  std::unique_ptr<tensorflow::Session> session(
      tensorflow::NewSession(tensorflow::SessionOptions()));
  TF_RETURN_IF_ERROR(session->Create(graph));
//  std::vector<Tensor> out_tensors;
//  TF_RETURN_IF_ERROR(session->Run({}, {output_name + "":0"", output_name + "":1""},
//                                    {}, &out_tensors));
  TF_RETURN_IF_ERROR(session->Run({inputs}, {""div""}, {}, out_tensors));
  return Status::OK();
}

int main()
{
  Session* session;
  Status status = NewSession(SessionOptions(), &session);

  const std::string graph_fn = ""/media/root/Ubuntu311/projects/Ecology_projects/tensorflowtest/model-0617/model.meta"";
  MetaGraphDef graphdef;
  Status status_load = ReadBinaryProto(Env::Default(), graph_fn, &graphdef); //ä»Žmetaæ–‡ä»¶ä¸­è¯»å–å›¾æ¨¡åž‹;
  if (!status_load.ok()) {
        std::cout << ""ERROR: Loading model failed..."" << graph_fn << std::endl;
        std::cout << status_load.ToString() << ""\n"";
        return -1;
  }

  Status status_create = session->Create(graphdef.graph_def()); //å°†æ¨¡åž‹å¯¼å…¥ä¼šè¯Sessionä¸­;
  if (!status_create.ok()) {
        std::cout << ""ERROR: Creating graph in session failed..."" << status_create.ToString() << std::endl;
        return -1;
  }
  cout << ""Session successfully created.Load model successfully!""<< endl;

  // è¯»å…¥é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡åž‹çš„æƒé‡
  const std::string checkpointPath = ""/media/root/Ubuntu311/projects/Ecology_projects/tensorflowtest/model-0617/model"";
  Tensor checkpointPathTensor(DT_STRING, TensorShape());
  checkpointPathTensor.scalar<std::string>()() = checkpointPath;
  status = session->Run(
		  {{ graphdef.saver_def().filename_tensor_name(), checkpointPathTensor },},
		  {},{graphdef.saver_def().restore_op_name()},nullptr);
  if (!status.ok())
  {
	  throw runtime_error(""Error loading checkpoint from "" + checkpointPath + "": "" + status.ToString());
  }
  cout << ""Load weights successfully!""<< endl;
  //read image for prediction...
  string image_path= ""/media/root/Ubuntu311/projects/Ecology_projects/copy/cnn-imgs/AABW.jpg"";
   int input_height =48;
   int input_width=160;
   int input_mean=0;
   int input_std=1;
   std::vector<Tensor> resized_tensors;
   Status read_tensor_status =
       ReadImageFile(image_path, input_height, input_width, input_mean,
                               input_std, &resized_tensors);
   if (!read_tensor_status.ok()) {
     LOG(ERROR) << read_tensor_status;
     cout<<""resing error""<<endl;
     return -1;
   }

   const Tensor& resized_tensor = resized_tensors[0];
   std::cout <<""Read image successfully: ""<< resized_tensor.DebugString()<<endl;

   std::string Input1Name = ""input"";
   std::string Input2Name = ""is_training"";
   vector<std::pair<string, Tensor> > inputs;
   inputs.push_back(std::make_pair(Input1Name, resized_tensor));
   inputs.push_back(std::make_pair(Input2Name, resized_tensor));

   vector<tensorflow::Tensor> outputs;
   string output2=""out_softmax"";
   string output_ = ""output"";
   Status status_run = session->Run(inputs, {output2}, {}, &outputs);
   if (!status_run.ok()) {
       std::cout << ""ERROR: RUN failed...""  << std::endl;
       std::cout << status_run.ToString() << ""\n"";
       return -1;
   }
   //Fetch output value
   std::cout << ""Output tensor size:"" << outputs.size() << std::endl;
   for (std::size_t i = 0; i < outputs.size(); i++) {
       std::cout <<""result: ""<<i<<"" :""<< outputs[i].DebugString()<<endl;
   }
  cout << ""Prediction successfully!""<< endl;`

**Any help will be appreciated.** 
"
30304,"[BUG, iOS] Symbol not found: _clock_gettime ","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **iOS 9.3**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **TESTED on iPhone 6s, iPad Air 2, iPad Mini 4**
- TensorFlow installed from (source or binary): **compiled for iOS using the provided Makefile**
- TensorFlow version (use command below): **1.13**

**Describe the current behavior**

Loading a network using TensorFlow 1.13 compiled for iOS (using the provided Makefile, altered to use `ANDROID_TYPES_FULL` [variable is used in iOS as well, not only on Android!]) in an app running on iOS < 10.0 crashes the application with the following error:

```

dyld: lazy symbol binding failed: Symbol not found: _clock_gettime
  Referenced from: /Users/rhcpfan/Library/Developer/CoreSimulator/Devices/4B733BDB-F1AB-49A4-87D5-3F23C507B599/data/Containers/Bundle/Application/58FB49D0-1330-442A-A46A-8ADADD34EAA2/MyApp.app/MyApp
  Expected in: /Library/Developer/CoreSimulator/Profiles/Runtimes/iOS 9.3.simruntime/Contents/Resources/RuntimeRoot/usr/lib/libSystem.B.dylib

dyld: Symbol not found: _clock_gettime
  Referenced from: /Users/slowhand/Library/Developer/CoreSimulator/Devices/4B733BDB-F1AB-49A4-87D5-3F23C507B599/data/Containers/Bundle/Application/58FB49D0-1330-442A-A46A-8ADADD34EAA2/MyApp.app/MyApp
  Expected in: /Library/Developer/CoreSimulator/Profiles/Runtimes/iOS 9.3.simruntime/Contents/Resources/RuntimeRoot/usr/lib/libSystem.B.dylib

```
"
30303,INTERNAL ERROR: Failed to apply GPUdelegate to custom tflite model,"**System information**
- Have I written custom code: Yes, using a custom tflite model and Android app to run on my devices.
- OS Platform and Distribution: Ubuntu 18.04
- Mobile device if the issue happens on mobile device: Asus zenphone M2, Snapdragon 820, 605 dev-kits.
- TensorFlow installed from: nightly AAR (org.tensorflow:tensorflow-lite:0.0.0-nightly)
- TensorFlow-gpu installed from:  nightly AAR (org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly)
- Python version: 3.6.7
- CUDA/cuDNN version: 10.0
- GPU model and memory: GTX 1060 6GB

**Describe the current behavior**
I've written a simple CNN to count number of fingers, works perfectly on my laptop (both the .h5 and tflite version). When I load the .tflite model on Android it fails saying;

` Caused by: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Prepare: Shader compilation failed: ERROR: 0:6: 'unknown' : not a legal layout qualifier id`

What exactly does this error mean? 

**Describe the expected behavior**
GPUdelegate should load correctly and run inference on my Android devices.

**Code to reproduce the issue**
My custom app is based on the TensorFlow Lite Android image classification example. The model loads and runs fine on CPU. The only difference in the code is the following lines:

```
tfliteOptions = new Interpreter.Options();
gpuDelegate = new GpuDelegate();
tfliteOptions.addDelegate(gpuDelegate);
```

**Other info / logs**
GPUdelegate works fine if I try to run models like MobilenetV2, without any change in code. 
After much googling, [found this on StackOverflow](https://stackoverflow.com/questions/55794791/tensorflow-lite-gpu-delegate-failure)

So, is it an issue with the output layers in my model? I'll include the model graph. 
Please help!


**Traceback:**
```
2019-07-02 10:19:12.153 15591-15613/com.prat96.tflite I/Adreno: ERROR: 0:6: 'unknown' : not a legal layout qualifier id 
    ERROR: 0:6: 'unknown' : Syntax error:  syntax error
    INTERNAL ERROR: no main() function!
    ERROR: 2 compilation errors.  No code generated.
2019-07-02 10:19:12.156 15591-15613/com.prat96.tflite E/AndroidRuntime: FATAL EXCEPTION: pool-1-thread-1
    Process: com.prat96.tflite, PID: 15591
    java.lang.RuntimeException: Error initializing TensorFlow!
        at com.prat96.tflite.MainActivity$3.run(MainActivity.java:133)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
        at java.lang.Thread.run(Thread.java:764)
     Caused by: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Prepare: Shader compilation failed: ERROR: 0:6: 'unknown' : not a legal layout qualifier id 
    ERROR: 0:6: 'unknown' : Syntax error:  syntax error
    INTERNAL ERROR: no main() function!
    ERROR: 2 compilation errors.  No code generated.
    
    Node number 11 (TfLiteGpuDelegate) failed to prepare.
    
        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegate(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:83)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:60)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:224)
        at com.prat96.tflite.TensorFlowImageClassifier.create(TensorFlowImageClassifier.java:57)
        at com.prat96.tflite.MainActivity$3.run(MainActivity.java:126)
        	... 3 more
2019-07-02 10:19:12.168 15591-15613/? I/Process: Sending signal. PID: 15591 SIG: 9
```"
30302,installation isuuse ,"Traceback (most recent call last):
  File ""eg1.py"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\core\framework\graph_pb2.py"", line 7, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""C:\Program Files\Python36\lib\site-packages\google\protobuf\descriptor.py"", line 47, in <module>
    from google.protobuf.pyext import _message
ImportError: DLL load failed: The specified procedure could not be found.
![error](https://user-images.githubusercontent.com/52444630/60493670-ebd8ba00-9cdf-11e9-95e5-c03f9210a8dd.png)

"
30301,[BUG] tf.layers.dropout not working,"To reproduce the issue:
```py
sess = tf.Session()
x = tf.ones([4, 4])
y = tf.layers.dropout(x, 0.5)
sess.run(y)
```

This version works well:
```py
sess = tf.Session()
x = tf.ones([4, 4])
y = tf.nn.dropout(x, 0.5)
sess.run(y)
```

Tensorflow version: 1.13.3
OS:  Ubuntu 18.04"
30297,AttributeError: module 'tensorflow' has no attribute 'matrix_band_part',Tensorflow 2.0.0-alpha0 AttributeError: module 'tensorflow' has no attribute 'matrix_band_part'
30293,[Question] Adding new hardware device support,"Hello, 
I'm developing a tensorflow modification to support a new hardware device and I was curious if there had been any update to the procedure since this issue was first raised in: 
Feature Request: plug-in support for new devices #4359

I'm following along with the documentation provided here
https://github.com/knuedge/tensorflow/blob/36e0cdf04f294bfd51931d4f78e291590ed0d3ec/tensorflow/g3doc/hardware/adding_support/index.md

But it is quite out of date so before I plow ahead I'd like to know that this isn't a solved problem.

Thanks,
Scott
"
30290,@tf.function works the first time I run the code but it fails afterwords on Spyder IDE.,"PROBLEM: the first time I run my custom code (that by the way works as a charm without @tf.function on my training function) on Spyder IDE everything goes smoothly. However if I attempt a second run I get the error reported below and a huge memory leak. I thought it was important for you to know. Thanks for your amazing work and best of lucks.

TensorFlow version: 2.0.0-beta1
Eager execution: True
MacOs

**Code to reproduce the issue**

    @tf.function
    def train(self, X, Y, epochs, batch_size=None):

        iter_data = self.bake_data(X, Y, epochs, batch_size)

        for x, y in iter_data:

            with tf.GradientTape() as tape:
                Y_ = self.forward_step(x)
                loss = self.loss_fun(y_true=y, y_pred=Y_)
                cost = tf.reduce_mean(loss)

            gradients = tape.gradient(cost, self.trainable_vars)
            self.optimizer.apply_gradients(zip(gradients, self.trainable_vars))
            self.loss_history_.append(cost)



    def bake_data(self, X, Y, epochs, batch_size=None):
        data = tf.data.Dataset.from_tensor_slices((X, Y))
        if batch_size is not None:
            data = data.batch(batch_size)
        data = data.repeat(epochs)
        data = data.shuffle(buffer_size=10000)
        return iter(data)

**Other info / logs**
WARNING: Logging before flag parsing goes to stderr.
E0701 21:48:20.707326 4585448896 ag_logging.py:132] Error converting <bound method Model.train of <tensorflow.python.eager.function.TfMethodTarget object at 0x1a3a5020b8>>
Traceback (most recent call last):
  File ""/Users/sm0037/anaconda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 561, in to_graph
    return conversion.convert(entity, program_ctx)
  File ""/Users/sm0037/anaconda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py"", line 314, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""/Users/sm0037/anaconda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py"", line 256, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""/Users/sm0037/anaconda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py"", line 92, in get_factory
    assert self.module_name in sys.modules
AssertionError
W0701 21:48:20.709814 4585448896 ag_logging.py:145] Entity <bound method Model.train of <tensorflow.python.eager.function.TfMethodTarget object at 0x1a3a5020b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Model.train of <tensorflow.python.eager.function.TfMethodTarget object at 0x1a3a5020b8>>: AssertionError: 
"
30289,Creating custom operations for Tensorflow Windows,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Microsoft Windows 10
- ~~Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:~~
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.12.3
- Python version: 3.5.0
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 0.17.2
- GCC/Compiler version (if compiling from source): 7.4.0
- ~~CUDA/cuDNN version: CPU, N/A~~
- ~~GPU model and memory: N/A~~

**Describe the problem**

I've been trying to get a custom operation working with a Windows version of TensorFlow. I've followed the guide:

https://www.tensorflow.org/guide/extend/op#build_a_pip_package_for_your_custom_op

I was able to build correctly, but it seems my custom operation is not recognized still when I try to run a test on it.

It seems to recognize the built-in custom operation tf.user_ops.my_fact, but it does not recognize the user_ops I created: squared_out.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

1. Clone the repository:

```powershell
git clone https://github.com/tensorflow/tensorflow.git 
```

I put my C++ implementation of squared_out.cc in tensorflow\tensorflow\core\user_ops

```c++
#include ""tensorflow/core/framework/op_kernel.h""
#include ""tensorflow/core/framework/op.h""
#include ""tensorflow/core/framework/shape_inference.h""

using namespace tensorflow;

REGISTER_OP(""SquaredOut"")
    .Input(""to_square: int32"")
    .Output(""squared: int32"")
    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext *c) {
        c->set_output(0, c->input(0));
        return Status::OK();
    });


class SquaredOutOp : public OpKernel {

    public:
        explicit SquaredOutOp(OpKernelConstruction* context) : OpKernel(context) {}

        void Compute(OpKernelContext* context) override {

            const Tensor& input_tensor = context->input(0);
            auto input = input_tensor.flat<int32>();

            Tensor* output_tensor = NULL;
            OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(), &output_tensor));

            auto output_flat = output_tensor->flat<int32>();

            const int N = input.size();

            for(int i = 0; i < N; ++i){

                output_flat(i) = input(i) * input(i);

            }
        }
};

REGISTER_KERNEL_BUILDER(Name(""SquaredOut"").Device(DEVICE_CPU), SquaredOutOp);
```
2. Afterwards I configure and built the tensorflow library by using bazel:

```powershell
python ./configure.py
bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
bazel-bin\tensorflow\tools\pip_package\build_pip_package C:/tmp/tensorflow_pkg
```

3. I then installed the .whl that was produced by bazel:

```powershell
pip install C:/tmp/tensorflow_pkg/tensorflow-version-cp35-cp35m-win_amd64.whl
```
4. Finally, I tried to test the newly imported squared_out from user_ops:
```python
import tensorflow as tf
#This works fine with build in fact function
tf.user_ops.fact
```
This returned:
```python
<function my_fact at 0x0000020CE5601048>
```
However, my custom operation doesn't work:
```python
tf.user_ops.squared_out
AttributeError: module 'tensorflow._api.v1.user_ops' has no attribute 'squared_out'
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Do I need to add a python binding for `squared_out` in tensorflow\tensorflow\python\user_ops? 

If so, I'm a little confused on how to do so. "
30287,third_party/repo.bzl file silently failed to apply patch,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Linux Ubuntu 16.04:
- ~Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:~
- TensorFlow installed from (source or binary): source
- TensorFlow version: master branch
- Python version: 3
- ~Installed using virtualenv? pip? conda?:~
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): 5.4.0
- ~CUDA/cuDNN version:~
- ~GPU model and memory:~



**Describe the problem**
[`git apply -v` in bazel scripts](https://github.com/tensorflow/tensorflow/blob/87f2f24f957abb76ad80e16b26b7221ddd277752/third_party/repo.bzl#L69) sliently failed to apply a patch. This cause tensorflow build to fail in an unexpected way.

The reason why `git apply -v` silently failed is due to [`git apply does not work from within the local checkout of an unrelated git repository`](https://stackoverflow.com/questions/24821431/git-apply-patch-fails-silently-no-errors-but-nothing-happens). In my setup, my home directory is a git directory used to sync up local development configuration files, and tensorflow build directory is under my home directory. This makes all tensorflow directories within the local checkout of a git directory (other than the one for project the patch is made for). Thus, at build time, the `_apply_patch()` subroutine will silently fail to apply any patch.

To fix, I will use the same patch command under either windows/linux to use the actual `patch -p1` command rather than `git apply`, ie, use [this line](https://github.com/tensorflow/tensorflow/blob/87f2f24f957abb76ad80e16b26b7221ddd277752/third_party/repo.bzl#L67) only. I didn't submit a PR because I'm not aware of why applying the patch need to branch on different OSes. If there is not a good reason to use `git apply`, I'd suggest to always use `patch -p1` instead.


**Provide the exact sequence of commands / steps that you executed before running into the problem**

1. Place tensorflow root directory into a/any git directory
2. Compile tensorflow
3. Tensorflow compilation failed due to related patch not applied.

~**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.~
"
30286,[TF 2.0] tf.keras.preprocessing.image,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0.0-beta1
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Keras has neat data feeder in ```tf.keras.preprocessing.image.ImageDataGenerator``` that is basically working for Python 2 only because it uses ```PIL``` for images which currently is not available for Python 3.
**Will this change the current api? How?**
It will not change the API, it just makes it work with python 3 (perhaps using pillow)
**Who will benefit with this feature?**
Anyone trying to use Python3 API of TF2.0 
**Any Other info.**
"
30284,CollectiveGatherOpKernel::ComputeAsync always crash when using MultiWorkerMirroredStrategy,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
None
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Centos 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
None
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
1.14
- Python version:
2.7
- Bazel version (if compiling from source):
None
- GCC/Compiler version (if compiling from source):
None
- CUDA/cuDNN version:
None
- GPU model and memory:
None

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
('v1.14.0-rc1-22-gaf24dc91b5', '1.14.0')

**Describe the current behavior**
When I use MultiWorkerMirroredStrategy to train model in multi-worker mode. I always got Error like this: ""check failed: nullptr == ctx->op_kernel().AsAsync() (nullptr vs. 0x7f8f74284010)Use OP_REQUIRES_ASYNC in AsyncOpKernel implementations.""
Then I use gdb to get stack of this crash. it shows that function CollectiveGatherOpKernel:: ComputeAsync use OP_REQUIRES instead of OP_REQUIRES_ASYNC. So I think this is a bug?
**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python
# -*- coding: utf-8 -*-
import tensorflow as tf
import os
import shutil
import json
from multiprocessing import Process
class Features(object):
    @property
    def names(self):
        return ['a', 'b']

    @property
    def names_usedByCols(self):
        return ['a', 'b']
    
    @property
    def col_ids(self):
        return [0, 1]

class Labels(object):
    def __init__(self):
        self._names = ('label',)
        self._dtypes = [tf.int32]
        self._col_ids = [2]

    @property
    def names(self):
        return self._names

    @property
    def dtypes(self):
        return self._dtypes

    @property
    def col_ids(self):
        return self._col_ids

class Generator_RNN(object):
    def __init__(self,
            features,
            labels):
        self._feature_names = features.names_usedByCols
        self._label_names = labels.names
        self._feature_dtypes = {}
        self._feature_shapes = {}
        for i, name in enumerate(self._feature_names):
            self._feature_dtypes[name] = tf.int32
            self._feature_shapes[name] = [None, None]

        self._label_dtypes = {}
        self._label_shapes = {}
        for i, name in enumerate(self._label_names):
            self._label_dtypes[name] = labels.dtypes[i]
            self._label_shapes[name] = [None]
        self._i = 0
        self._f_3 = {'a': [[1, 2, 3],[1, 2, 3],[1, 2, 3],[1, 2, 3]],
                     'b': [[3, 1, 1],[3, 1, 1],[3, 1, 1],[3, 1, 1]]}
        self._l_3 = {'label': [1, 1, 1, 1]}
        self._f_2 = {'a': [[1, 2],[1, 2],[1, 2],[1, 2]],
                     'b': [[3, 1],[3, 1],[3, 1],[3, 1]]}
        self._l_2 = {'label': [0, 0, 0, 0]}

    def _generate_data(self):
        while True:
            yield self._next_batch()

    def _next_batch(self):
        if self._i == 0:
            self._i = 1
            return (self._f_3, self._l_3)
        else:
            self._i = 0
            return (self._f_2, self._l_2)

    def _output_dtypes(self):
        return (self._feature_dtypes, self._label_dtypes)

    def _output_shapes(self):
        return (self._feature_shapes, self._label_shapes)

    def create_dataset(self):
        return tf.data.Dataset.from_generator(
                generator=self._generate_data,
                output_types=self._output_dtypes(),
                output_shapes=self._output_shapes(),
                args=[])

def _dataset():
    generator = Generator_RNN(
                features=Features(),
                labels=Labels())
    return generator.create_dataset()

def _gen_feature_column(name):
    vocabulary_list = [1,2,3]
    feature_column = tf.feature_column.sequence_categorical_column_with_vocabulary_list(
                    key=name,
                    vocabulary_list=vocabulary_list)
    ebeding_dimension = int(len(vocabulary_list) ** 0.25) * 3
    feature_column = tf.feature_column.embedding_column(
            feature_column,
            ebeding_dimension)
    return feature_column

def _my_model_fn(features, labels, mode, params):
    learning_rate = params['learning_rate']
    keep_prob = params['keep_prob']
    n_classes = 2
    dropout_rate = 1-keep_prob
    feature_columns = [_gen_feature_column('a'), _gen_feature_column('b')]
    sequence_input_layer = tf.keras.experimental.SequenceFeatures(feature_columns)
    sequence_input, _ = sequence_input_layer(features)
    sequence_input = tf.nn.dropout(sequence_input, rate=dropout_rate)

    def gen_gru(units, keep_prob):
        gru = tf.compat.v1.nn.rnn_cell.GRUCell(num_units=units, kernel_initializer=tf.compat.v1.orthogonal_initializer)
        gru = tf.compat.v1.nn.rnn_cell.DropoutWrapper(gru, output_keep_prob=keep_prob)
        return gru

    gru_units = [64, 32]
    cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell(
            [gen_gru(units, keep_prob) for units in gru_units]
        )
    dynamic_rnn = tf.keras.layers.RNN(cell)
    outputs = dynamic_rnn(inputs=sequence_input)

    last_gru_units = gru_units[-1]
    dense_layer = tf.keras.layers.Dense(
            units=n_classes,
            activation=tf.nn.relu,
            kernel_initializer=tf.random_normal_initializer(stddev=tf.sqrt(2.0 / (last_gru_units * keep_prob))))
    logits = dense_layer(inputs=outputs)
    loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=labels['label'], logits=logits)
    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)
    train_op = optimizer.minimize(loss, global_step=tf.compat.v1.train.get_global_step())
    spec = tf.estimator.EstimatorSpec(tf.estimator.ModeKeys.TRAIN,
            loss=loss,
            train_op=train_op)
    return spec

def train(task_index, model_dir, max_steps):
    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(
            communication=tf.distribute.experimental.CollectiveCommunication.RING)
    cluster = {'worker': ['localhost:2001', 'localhost:2002']}
    os.environ['TF_CONFIG'] = json.dumps({
        'cluster': cluster,
        'task': {'type': 'worker', 'index': task_index}
    })
    run_config = tf.estimator.RunConfig(
            save_checkpoints_steps=500,
            keep_checkpoint_max=1,
            train_distribute=strategy)
    learning_rate = 1e-6
    keep_prob = 0.75
    estimator_distribute = tf.estimator.Estimator(
            model_fn=_my_model_fn,
            model_dir=model_dir,
            config=run_config,
            params={
                'learning_rate': learning_rate,
                'keep_prob': keep_prob
            })
    train_input_fn = lambda : _dataset()
    train_spec = tf.estimator.TrainSpec(
            input_fn=train_input_fn,
            max_steps=max_steps)
    dummy_spec = tf.estimator.EvalSpec(input_fn=lambda : _dummy_dataset())
    eval_input_fn = lambda : _dataset()
    eval_spec = tf.estimator.EvalSpec(
            input_fn=eval_input_fn)
    print ""Start Training""
    tf.estimator.train_and_evaluate(estimator_distribute, train_spec, dummy_spec)
    print ""Finish Training""

def main(argv):
    model_dir = '/root/test/tf2/model/'
    max_steps = 600
    shutil.rmtree(model_dir)
    os.mkdir(model_dir)
    print 'Clean model dir'
    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)
    print 'Control process %s.' % os.getpid()
    worker_list = []
    for i in range(2):
        worker = Process(target=train, args=(i, model_dir, max_steps))
        print 'Training worker starting'
        worker.start()
        worker_list.append(worker)

    for worker in worker_list:
        worker.join()
    print 'Train end.'

if __name__ == '__main__':
    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)
    tf.compat.v1.app.run()
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30283,[TF 2.0] Minor changes to the 'Load images with tf.data' tutorial + fix image links,"_URL(s) with the issue:_
https://www.tensorflow.org/beta/tutorials/load_data/images

_Description of main issue:_
Pls take a look at JPG/JPEG links in the 'Load images with tf.data' tutorial in the 'Inspect the images' section. When you inspect the site elements they appear to be missing a letter 'g' as in `jpeg` or `jpg`
```
https://www.tensorflow.org/beta/tutorials/load_data/images_files/output_16_0.jpe
https://www.tensorflow.org/beta/tutorials/load_data/images_files/output_16_2.jpe
https://www.tensorflow.org/beta/tutorials/load_data/images_files/output_16_4.jpe
```

_Other minor suggestions:_
Rearrangement of words, fixing some grammar, addition/subtraction of commas/colons/spaces in English and Python for consistency - will submit a PR right away for your review @MarkDaoust @lamberta "
30282,ERROR: no such package 'tensorflow/lite/toco': Unable to determine the local repository for directory /home/devim/tensorflow/tensorflow/lite/toco,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu
- TensorFlow installed from (source or binary): 
- TensorFlow version: 1.12.0
- Python version: 2.7.15
- Installed using virtualenv? pip? conda?: python-pip
- Bazel version (if compiling from source): 0.26.0
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: Using CPU
- GPU model and memory: N/A

Code used:

`bazel run -c opt tensorflow/lite/toco:toco -- --input_file=models/research/object_detection/tflite_graph.pb --output_file=models/research/object_detection/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_values=128 --change_concat_input_ranges=false --allow_custom_ops`

I got this error

INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'run' from /home/devim/tensorflow/.bazelrc:
  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
INFO: Reading rc options for 'run' from /home/devim/tensorflow/.tf_configure.bazelrc:
  Inherited 'build' options: --host_force_python=PY2 --action_env PYTHON_BIN_PATH=/home/devim/venv/bin/python --action_env PYTHON_LIB_PATH=/home/devim/venv/lib/python2.7/site-packages --python_path=/home/devim/venv/bin/python --action_env TF_CONFIGURE_IOS=0
ERROR: Skipping 'tensorflow/lite/toco:toco': no such package 'tensorflow/lite/toco': Unable to determine the local repository for directory /home/devim/tensorflow/tensorflow/lite/toco
WARNING: Target pattern parsing failed.
ERROR: no such package 'tensorflow/lite/toco': Unable to determine the local repository for directory /home/devim/tensorflow/tensorflow/lite/toco
INFO: Elapsed time: 0.092s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
FAILED: Build did NOT complete successfully (0 packages loaded)

The directory tensorflow/lite/toco exists and here is the screenshot.
![Capture](https://user-images.githubusercontent.com/48072621/60449936-b7d59a00-9bf6-11e9-8a12-b5318d93bef3.JPG)

"
30281,tf.read_file memory leak on python3.7,"Hi,
i noticed a memory leak in python3.7. When I used the dataset.map() function to load images, the process died after a few seconds with an OOM exception. After some testing, I could identify tf.read_file() as the source of this issue. Memory was never released, so all files accumulated to multiple GB of memory in seconds and the process crashes.
```python
def load_img(filename: str, label):
    image_byte = tf.read_file(filename)
    ...
    return processed_image, label

def dummy():
     ...
    load_fn = lambda f, l: load_img(f, l)
    ...
    dataset = tf.data.Dataset.from_tensor_slices(...)
                ...
                .map(load_fn, num_parallel_calls=4)
                ...
                

```
Going back to python3.6, there was no memory leak. An attempt to update to TF1.14.0 on pyhton3.7 failed so I could not verify, if the issue is fixed.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7.3
- CUDA/cuDNN version: 10.0
- GPU model and memory:
"
30280,Is there any way to flush GPU memory in TF 2.0?,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 

`
BATCH_SIZE = 64
for j, (train_indices, val_indices) in enumerate(kf.split(datos_random)):
    fold_dir = f'fold_{j}'
    if not os.path.exists(fold_dir):
        os.mkdir(fold_dir)
    train = datos.iloc[train_indices]
    val = datos.iloc[val_indices]   
    metrics = ['accuracy']
    model = build_model(DROPOUT, FC_LAYERS, num_classes=NUM_CLASSES, opt=OPT, metrics=metrics)

    train_datagen =  keras.preprocessing.image.ImageDataGenerator(
        preprocessing_function=preprocess_input,
        horizontal_flip=True,
        vertical_flip=True,
        fill_mode='constant'
        
    )

    val_datagen = keras.preprocessing.image.ImageDataGenerator(
        preprocessing_function=preprocess_input,
    )
    
    train_generator = train_datagen.flow_from_dataframe(
                                          train,
                                          None,
                                          x_col='file',
                                          target_size=(WIDTH, HEIGHT),
                                          y_col=f'Class_cat_{NUM_CLASSES}', 
                                          batch_size=BATCH_SIZE, 
                                          seed=SEED,
                                          has_ext=True,class_mode='categorical')

    validation_generator = val_datagen.flow_from_dataframe(val, 
                                          None, 
                                          x_col='file',
                                          target_size=(WIDTH, HEIGHT),
                                          y_col=f'Class_cat_{NUM_CLASSES}', 
                                          batch_size=BATCH_SIZE,
                                          seed=SEED,
                                          has_ext=True,class_mode='categorical')

    class_list = list(test_generator.class_indices.keys())
    
    history = model.fit_generator(train_generator, 
                        epochs=EPOCHS, 
                        workers=16, 
                        shuffle=True,  
                        verbose=1, 
                        steps_per_epoch=len(train_indices) / BATCH_SIZE,
                        validation_data=validation_generator, 
                        validation_steps=len(val_indices) / BATCH_SIZE
`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.0-9492-g2c319fb415 2.0.0-alpha0
- Python version: 3.6
- CUDA/cuDNN version: 10.1
- GPU model and memory: Titan V, Driver 418.67

**Describe the current behavior**
Model trains good for the first 3-5 folds but it eventually returns a out of memory error.
I've tried deleting the model the end of each iteration also using  `keras.backend.clear_session()` and allow_growth with no avail. I'm also using my second GPU not the Titan V used for display, its alos weird that the error occurs in GPU:0 but I'm using GPU 1 ` os.environ[""CUDA_VISIBLE_DEVICES""]=""1"";`

**Describe the expected behavior**
Need to flush GPU data at each iteration so it won't run out of memory

**Other info / logs**
`---------------------------------------------------------------------------
ResourceExhaustedError                    Traceback (most recent call last)
<timed exec> in <module>

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1513         shuffle=shuffle,
   1514         initial_epoch=initial_epoch,
-> 1515         steps_name='steps_per_epoch')
   1516 
   1517   def evaluate_generator(self,

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)
    255 
    256       is_deferred = not model._is_compiled
--> 257       batch_outs = batch_function(*batch_data)
    258       if not isinstance(batch_outs, list):
    259         batch_outs = [batch_outs]

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)
   1257       else:
   1258         self._make_fit_function()
-> 1259         outputs = self._fit_function(ins)  # pylint: disable=not-callable
   1260 
   1261     if reset_metrics:

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/backend.py in __call__(self, inputs)
   3215         value = math_ops.cast(value, tensor.dtype)
   3216       converted_inputs.append(value)
-> 3217     outputs = self._graph_fn(*converted_inputs)
   3218     return nest.pack_sequence_as(self._outputs_structure,
   3219                                  [x.numpy() for x in outputs])

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
    556       raise TypeError(""Keyword arguments {} unknown. Expected {}."".format(
    557           list(kwargs.keys()), list(self._arg_keywords)))
--> 558     return self._call_flat(args)
    559 
    560   def _filtered_call(self, args, kwargs):

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args)
    625     # Only need to override the gradient in graph mode and when we have outputs.
    626     if context.executing_eagerly() or not self.outputs:
--> 627       outputs = self._inference_function.call(ctx, args)
    628     else:
    629       self._register_gradient()

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args)
    413             attrs=(""executor_type"", executor_type,
    414                    ""config_proto"", config),
--> 415             ctx=ctx)
    416       # Replace empty list with None
    417       outputs = outputs or None

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     64     else:
     65       message = e.message
---> 66     six.raise_from(core._status_to_exception(e.code, message), None)
     67   except TypeError as e:
     68     if any(ops._is_keras_symbolic_tensor(x) for x in inputs):

~/anaconda3/envs/tf2/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

ResourceExhaustedError: OOM when allocating tensor with shape[64,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node block1_conv2_4/Conv2D}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[loss_4/dense_2_loss/categorical_crossentropy/weighted_loss/broadcast_weights/assert_broadcastable/is_valid_shape/else/_45/has_valid_nonscalar_shape/then/_141/has_invalid_dims_0/_44]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
 [Op:__inference_keras_scratch_graph_2925097]`"
30276,Need better documentation for BestExporter,"In the documentation for [BestExporter](https://www.tensorflow.org/api_docs/python/tf/estimator/BestExporter), the example mentioned does not specify how to write a _compare_fn_ .
By default, it takes the _loss_.
How to use it if we were to use custom metrics, that are evaluated in the _model_fn_ ."
30275,why official tensorflow lite android demo faster than building library by myself,"I use the official android demo [here](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android),and run the model I created by myself under device rk3288, the inference cost is about 200ms, but when I build `libtensorflowlite.so` by myself using the command below, it cost almost 500ms, I can't understand the gap. **Does any one know how to build tensorflow-lite c++  library by ourself, and get the same level of performance by official?**

The build command is here:

`bazel build -c opt --crosstool_top=//external:android/crosstool  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cxxopt=""-std=c++11"" --fat_apk_cpu=armeabi-v7a  --config=android_arm //tensorflow/lite:libtensorflowlite.so` "
30274,TFSlim trained 'mobilenetv2' model is giving poor accuracy with is_training='False' (When save and restore the checkpoints),"## The steps I have followed
### 1. I have trained the `MobilenetV2` model using `slim` framework with cifar10 dataset.
#### Run training.
python train_image_classifier.py \
  --train_dir=${TRAIN_DIR} \
  --dataset_name=cifar10 \
  --dataset_split_name=train \
  --dataset_dir=${DATASET_DIR} \
  --model_name=mobilenet_v2 \
  --preprocessing_name=mobilenet_v2 \
  --max_number_of_steps=100000 \
  --batch_size=48 \
  --save_interval_secs=120 \
  --save_summaries_secs=120 \
  --log_every_n_steps=100 \
  --optimizer=adagrad \
  --learning_rate=0.1 \
  --learning_rate_decay_factor=0.1 \
  --num_epochs_per_decay=200 \
  --weight_decay=0.004 \
  --moving_average_decay=0.9999

### 2. After training, I could get a proper accuracy with below evaluation options:
#### Run evaluation.
python eval_image_classifier.py \
  --checkpoint_path=${TRAIN_DIR} \
  --eval_dir=${TRAIN_DIR} \
  --dataset_name=cifar10 \
  --dataset_split_name=test \
  --dataset_dir=${DATASET_DIR} \
  --model_name=mobilenet_v2

### 3. I have saved the checkpoints with `is_training=False` from the `eval_image_classifier.py` itself. Converted the checkpoints to .pb file and then measured the evaluation accuracy. The accuracy is very less.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 18.04
- TensorFlow installed from  binary
- TensorFlow version (use command below):  1.13
- Python version: 3.7.3
- Bazel version (if compiling from source): 24.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
The modem accuracy changed after saving the evaluation graph with `'is_training=False'`

**Describe the expected behavior**
The model should give same accuracy after saving with `'is_training=False'`

**Code to reproduce the issue**
Training with slim framework

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30273,Invalid argument: Expects arg[1] to be bool but float is provided,"**Tensorflow version:1.12 .I want to translate my python code to c++ version and here is my python code below:**
`
import tensorflow as tf
import  numpy as np
from skimage import io, transform
import cv2
#import infer
sess = tf.Session()
new_saver = tf.train.import_meta_graph(r'D:\CNN_test_result_sizhuangzao_model\v2_101_ziji_9\model\model.meta')
new_saver.restore(sess,tf.train.latest_checkpoint(r'D:\CNN_test_result_sizhuangzao_model\v2_101_ziji_9\model'))

graph = tf.get_default_graph()
input_x = graph.get_tensor_by_name(""input:0"")
is_training_x=graph.get_tensor_by_name(""is_training:0"")
#print (sess.run(""input:0""))

jpg_path=r""D:\CNN_test_result_sizhuangzao\chaodacesiji1\pos.txt""
file = open(jpg_path)
lines = file.readlines()
num=0
for line in lines: 
    img0 = io.imread(line.strip())
    l=img0.shape
    k=l[0]
    c=l[1]
    num+=1
    print(num)
    if  c/k<5:
        continue
    img = transform.resize(img0, (48,160, 1))
    feed_dict={input_x:np.reshape(img, [-1, 48, 160, 1]),is_training_x:False}

    prob_op = graph.get_operation_by_name('output')
    out_softmax = graph.get_tensor_by_name(""output:0"")
    img_out_softmax = sess.run(out_softmax,feed_dict)
    prediction_labels = np.argmax(img_out_softmax,1)
`

**Now this is my c++ version below (There is some wrong but i do not know where it is !)**

`
#include ""tensorflow/core/framework/graph.pb.h""
#include <tensorflow/core/public/session_options.h>
#include <tensorflow/core/protobuf/meta_graph.pb.h>
#include <fstream>
#include <utility>
#include <vector>
#include <Eigen/Core>
#include <Eigen/Dense>

#include ""tensorflow/cc/ops/const_op.h""
#include ""tensorflow/cc/ops/image_ops.h""
#include ""tensorflow/cc/ops/standard_ops.h""
#include ""tensorflow/core/framework/graph.pb.h""
#include ""tensorflow/core/framework/tensor.h""
#include ""tensorflow/core/graph/default_device.h""
#include ""tensorflow/core/graph/graph_def_builder.h""
#include ""tensorflow/core/lib/core/errors.h""
#include ""tensorflow/core/lib/core/stringpiece.h""
#include ""tensorflow/core/lib/core/threadpool.h""
#include ""tensorflow/core/lib/io/path.h""
#include ""tensorflow/core/lib/strings/stringprintf.h""
#include ""tensorflow/core/platform/env.h""
#include ""tensorflow/core/platform/init_main.h""
#include ""tensorflow/core/platform/logging.h""
#include ""tensorflow/core/platform/types.h""
#include ""tensorflow/core/public/session.h""
#include ""tensorflow/core/util/command_line_flags.h""

using namespace std;
using namespace tensorflow;
using namespace tensorflow::ops;
using tensorflow::Flag;
using tensorflow::Tensor;
using tensorflow::Status;
using tensorflow::string;
using tensorflow::int32;

typedef std::vector<std::pair<std::string, tensorflow::Tensor>> tensor_dict;
using tensorflow::Status;

static Status ReadtheFile(tensorflow::Env* env, const string& filename,Tensor* output) {
  tensorflow::uint64 file_size = 0;
  TF_RETURN_IF_ERROR(env->GetFileSize(filename, &file_size));

  string contents;
  contents.resize(file_size);

  std::unique_ptr<tensorflow::RandomAccessFile> file;
  TF_RETURN_IF_ERROR(env->NewRandomAccessFile(filename, &file));

  tensorflow::StringPiece data;
  TF_RETURN_IF_ERROR(file->Read(0, file_size, &data, &(contents)[0]));
  if (data.size() != file_size) {
    return tensorflow::errors::DataLoss(""Truncated read of '"", filename,
                                        ""' expected "", file_size, "" got "",
                                        data.size());
  }
//  output->scalar<string>()() = data.ToString();
  output->scalar<string>()() = string(data);
  return Status::OK();
}

Status ReadImageFile(const string& file_name, const int input_height,
                               const int input_width, const float input_mean,
                               const float input_std,
                               std::vector<Tensor>* out_tensors) {
  auto root = tensorflow::Scope::NewRootScope();
  using namespace ::tensorflow::ops;

  string input_name = ""file_reader"";
  string output_name = ""normalized"";

  // read file_name into a tensor named input
  Tensor input(tensorflow::DT_STRING, tensorflow::TensorShape());
  TF_RETURN_IF_ERROR(ReadtheFile(tensorflow::Env::Default(), file_name, &input));

  // use a placeholder to read input data
  auto file_reader =Placeholder(root.WithOpName(""input""), tensorflow::DataType::DT_STRING);

  std::vector<std::pair<string, tensorflow::Tensor>> inputs = {{""input"", input},};

  // Now try to figure out what kind of file it is and decode it.
    const int wanted_channels = 1;
    tensorflow::Output image_reader;
	if (tensorflow::str_util::EndsWith(file_name, "".png""))
	{
	  image_reader = DecodePng(root.WithOpName(""png_reader""), file_reader,
							   DecodePng::Channels(wanted_channels));
	}
	else if (tensorflow::str_util::EndsWith(file_name, "".gif""))
	{
	  // gif decoder returns 4-D tensor, remove the first dim
	  image_reader =
		  Squeeze(root.WithOpName(""squeeze_first_dim""),
				  DecodeGif(root.WithOpName(""gif_reader""), file_reader));
	}
	else if (tensorflow::str_util::EndsWith(file_name, "".bmp""))
	{
	  image_reader = DecodeBmp(root.WithOpName(""bmp_reader""), file_reader);
	}
	else
	{
	  // Assume if it's neither a PNG nor a GIF then it must be a JPEG.
	  image_reader = DecodeJpeg(root.WithOpName(""jpeg_reader""), file_reader,
								DecodeJpeg::Channels(wanted_channels));
	}
  // Now cast the image data to float so we can do normal math on it.
  auto float_caster =Cast(root.WithOpName(""float_caster""), image_reader, tensorflow::DT_FLOAT);

  auto dims_expander = ExpandDims(root.WithOpName(""expand""), float_caster, 0);

  float input_max = 255;
  Div(root.WithOpName(""div""),dims_expander,input_max);

  tensorflow::GraphDef graph;
  TF_RETURN_IF_ERROR(root.ToGraphDef(&graph));

  std::unique_ptr<tensorflow::Session> session(
      tensorflow::NewSession(tensorflow::SessionOptions()));
  TF_RETURN_IF_ERROR(session->Create(graph));
//  std::vector<Tensor> out_tensors;
//  TF_RETURN_IF_ERROR(session->Run({}, {output_name + "":0"", output_name + "":1""},
//                                    {}, &out_tensors));
  TF_RETURN_IF_ERROR(session->Run({inputs}, {""div""}, {}, out_tensors));
  return Status::OK();
}

int main()
{
  Session* session;
  Status status = NewSession(SessionOptions(), &session);

  const std::string graph_fn = ""/media/root/Ubuntu311/projects/Ecology_projects/tensorflowtest/model-0617/model.meta"";
  MetaGraphDef graphdef;
  Status status_load = ReadBinaryProto(Env::Default(), graph_fn, &graphdef); //ä»Žmetaæ–‡ä»¶ä¸­è¯»å–å›¾æ¨¡åž‹;
  if (!status_load.ok()) {
        std::cout << ""ERROR: Loading model failed..."" << graph_fn << std::endl;
        std::cout << status_load.ToString() << ""\n"";
        return -1;
  }

  Status status_create = session->Create(graphdef.graph_def()); //å°†æ¨¡åž‹å¯¼å…¥ä¼šè¯Sessionä¸­;
  if (!status_create.ok()) {
        std::cout << ""ERROR: Creating graph in session failed..."" << status_create.ToString() << std::endl;
        return -1;
  }
  cout << ""Session successfully created.Load model successfully!""<< endl;

  // è¯»å…¥é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡åž‹çš„æƒé‡
  const std::string checkpointPath = ""/media/root/Ubuntu311/projects/Ecology_projects/tensorflowtest/model-0617/model"";
  Tensor checkpointPathTensor(DT_STRING, TensorShape());
  checkpointPathTensor.scalar<std::string>()() = checkpointPath;
  status = session->Run(
		  {{ graphdef.saver_def().filename_tensor_name(), checkpointPathTensor },},
		  {},{graphdef.saver_def().restore_op_name()},nullptr);
  if (!status.ok())
  {
	  throw runtime_error(""Error loading checkpoint from "" + checkpointPath + "": "" + status.ToString());
  }
  cout << ""Load weights successfully!""<< endl;


  //read image for prediction...
  string image_path= ""/media/root/Ubuntu311/projects/Ecology_projects/copy/cnn-imgs/AABW.jpg"";
   int input_height =48;
   int input_width=160;
   int input_mean=0;
   int input_std=1;
   std::vector<Tensor> resized_tensors;
   Status read_tensor_status =
       ReadImageFile(image_path, input_height, input_width, input_mean,
                               input_std, &resized_tensors);
   if (!read_tensor_status.ok()) {
     LOG(ERROR) << read_tensor_status;
     cout<<""resing error""<<endl;
     return -1;
   }

   const Tensor& resized_tensor = resized_tensors[0];
   std::cout <<""Read image successfully: ""<< resized_tensor.DebugString()<<endl;

   std::string Input1Name = ""input"";
   std::string Input2Name = ""is_training"";
   vector<std::pair<string, Tensor> > inputs;
   inputs.push_back(std::make_pair(Input1Name, resized_tensor));
   inputs.push_back(std::make_pair(Input2Name, resized_tensor));

   vector<tensorflow::Tensor> outputs;
   string output2=""out_softmax"";
   string output_ = ""output"";
   Status status_run = session->Run(inputs, {output2}, {}, &outputs);
   if (!status_run.ok()) {
       std::cout << ""ERROR: RUN failed...""  << std::endl;
       std::cout << status_run.ToString() << ""\n"";
       return -1;
   }
   //Fetch output value
   std::cout << ""Output tensor size:"" << outputs.size() << std::endl;
   for (std::size_t i = 0; i < outputs.size(); i++) {
       std::cout <<""result: ""<<i<<"" :""<< outputs[i].DebugString()<<endl;
   }
  cout << ""Prediction successfully!""<< endl;

  return 0;
}
`

I built the c++ version successfully but  the error informations came to me----- "" ERROR: RUN failed...
Invalid argument: Expects arg[1] to be bool but float is provided "". Any help will be much appreciated."
30272,tflite_convert  .h5 to .tflite Init node Conv1/kernel/Assign do esn't exist in graph,"**System information**
- OS Platform and Distribution : Windows 7
- TensorFlow version: tensorflow_gpu-1.14.0
- Python version: 3.7.3 
- CUDA/cuDNN version: 10.1 / 7.6.1
- GPU model and memory: GTX1080Ti / 11GB

**Describe the current behavior**
after transfer learning on tensorflow.keras mobilenet v2 and saved .h5,
*`tflite_convert --keras_model_file=tl_mobilenetv2.h5 --output_file=tl_mobilenetv2.tflite --allow_custom_ops`*

**Describe the Issues**
.tflite is generated, but error message shown:
**E tensorflow/core/grappler/grappler_item_builder.cc:637] Init node Conv1/kernel/Assign doesn't exist in graph**

**Other info / logs**
Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10143 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)
2019-07-01 18:16:28.142672: E tensorflow/core/grappler/grappler_item_builder.cc:637] Init node Conv1/kernel/Assign doesn't exist in graph
"
30271,Failed to load nodelet [/zed/zed_wrapper_node] of type [zed_wrapper/ZEDWrapperNodelet],"hello i have worked with zed camera for long time when i run my zed camera this morning i got this error 

ROS_MASTER_URI=http://localhost:11311

process[zed/zed_wrapper_node-1]: started with pid [2349]
process[zed/zed_state_publisher-2]: started with pid [2350]
[ INFO] [1561980098.631115078]: Initializing nodelet with 4 worker threads.
[ERROR] [1561980100.164477981]: Failed to load nodelet [/zed/zed_wrapper_node] of type [zed_wrapper/ZEDWrapperNodelet] even after refreshing the cache: Failed to load library /home/abanay/catkin_ws/devel/lib//libZEDWrapper.so. Make sure that you are calling the PLUGINLIB_EXPORT_CLASS macro in the library code, and that names are consistent between this macro and your XML. Error string: Could not load library (Poco exception = libnvidia-fatbinaryloader.so.384.130: cannot open shared object file: No such file or directory)
[ERROR] [1561980100.164522687]: The error before refreshing the cache was: Failed to load library /home/abanay/catkin_ws/devel/lib//libZEDWrapper.so. Make sure that you are calling the PLUGINLIB_EXPORT_CLASS macro in the library code, and that names are consistent between this macro and your XML. Error string: Could not load library (Poco exception = libnvidia-fatbinaryloader.so.384.130: cannot open shared object file: No such file or directory)

"
30270,Tensorboard Graph is different when using File Writer as opposed to Tensorboard callback,"The graph generated using tensorboard callback and the graph generated using FileWriter are different. Also, I am not able to retrieve scalar values when using FileWriter. Why is the behaviour different when using FileWriter? What changes should be done in FileWriter to get the graph and results similar to as when tensorboard callbacks are used? I have added the code as well as the tensorboard images.

**System information**
- TF Version: 2.0.0-dev20190527
- TF GIT Version: v1.12.1-2821-gc5b8e15064
- Python Version: 3.6.6

**Using tensorboard callback**
```
import tensorflow as tf
from tensorflow import keras

# Load the data.
fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

# Pre-processing.
train_images = train_images / 255.0
test_images = test_images / 255.0

tb_callback = tf.keras.callbacks.TensorBoard(log_dir=""/tmp/tb_test_1"", histogram_freq=1)  # Create tensorboard callback

def create_model():
    return keras.Sequential([
        keras.layers.Flatten(input_shape=(28, 28)),
        keras.layers.Dense(128, activation=tf.nn.relu),
        keras.layers.Dense(10, activation=tf.nn.softmax)
    ])

model = create_model()
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=1, callbacks=[tb_callback], verbose=1)
```
[Tensorboard Graph](https://ibb.co/B68XFrY)
[Tensorboard Scalar](https://ibb.co/jVphDn8)
**Using File Writer**
```
import tensorflow as tf
from tensorflow import keras

# Load the data.
fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

# Pre-processing.
train_images = train_images / 255.0
test_images = test_images / 255.0

logdir = '/tmp/tb_test_2/'
writer = tf.summary.create_file_writer(logdir)

class MyModel(keras.Model):
    def __init__(self):
        super(MyModel, self).__init__()
        self.flatten = keras.layers.Flatten()
        self.d1 = keras.layers.Dense(128, activation='relu')
        self.d2 = keras.layers.Dense(10, activation='softmax')

    def call(self, x):
        x = self.flatten(x)
        x = self.d1(x)
        return self.d2(x)

model = MyModel()
optimizer = keras.optimizers.Adam(0.1)
loss_fn = keras.losses.SparseCategoricalCrossentropy()

@tf.function
def train_step(inputs, labels, step):
    with tf.GradientTape() as tape:
        predictions = model(inputs)
        pred_loss = loss_fn(labels, predictions)
        tf.summary.scalar(""loss"", pred_loss, step=step, description=None)

    gradients = tape.gradient(pred_loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))

for i in range(5):
    tf.summary.trace_on(graph=True)
    train_step(train_images, train_labels, step=i)
    with writer.as_default():
        tf.summary.trace_export(name=""test_model"", step=i)
        writer.flush()
```
[Tensorboard Graph]( https://ibb.co/Kqhb8Tg)
Tensorboard Scalar is absent.

"
30268,Optimizing the Frozen Graph,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):macOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:Nan
- TensorFlow installed from (source or binary):binary
- TensorFlow version:1.13.0-rc2
- Python version:3.7.2
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):0.27.0
- GCC/Compiler version (if compiling from source):Nan
- CUDA/cuDNN version:Nan
- GPU model and memory:Nan
**Describe the problem**
Optimizing the Frozen Graph using The optimize_for_inference tool
refering to this [tuto](https://heartbeat.fritz.ai/intro-to-machine-learning-on-android-how-to-convert-a-custom-model-to-tensorflow-lite-e07d2d9d50e3)
**Provide the exact sequence of commands / steps that you executed before running into the problem**
`bazel build tensorflow/python/tools:optimize_for_inference && \ bazel-bin/tensorflow/python/tools/optimize_for_inference.py \ --input=/Users/hak/tensorboard/logs/frozen.pb \ --output=/Users/hak/tensorboard/logs/frozen_opt.pb \ --frozen_graph=True \ --input_names=ImageTensor \ --output_names=ReziseBilinear_1`
refer to this 
[link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py)
### trace back 

> INFO: Build completed successfully, 1 total action
> -bash:  bazel-bin/tensorflow/python/tools/optimize_for_inference.py: No such file or directory
> 
Adding that I'm not sure about the input and the output names options
any help??"
30267,How should i use tf.image.draw_bounding_box() when each batch have different bbox_num ?,"The documents show that bboxes' shape is [batch, num_bounding_boxes, 4]. This means every batch have same number of bbox. 
But in detect, each image may have different number of bboxes. Who can tell me how should i do, thanks !
BTW, I use tf.gather_nd() to get bboxes, is there any method to get dimension-aligned bboxes? 


**System information**
- TensorFlow version (you are using): Tensorflow 1.13"
30266,Unable to import  tensorflow,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 Up to date
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary I think
- TensorFlow version: r1.14
- Python version: 3.6.5
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.6.1
- GPU model and memory: GTX 1060 6GB



>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Users\aanan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\platform\self_check.py"", line 75, in preload_check
    ctypes.WinDLL(build_info.cudart_dll_name)
  File ""C:\Users\aanan\AppData\Local\Programs\Python\Python36\lib\ctypes\__init__.py"", line 348, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] The specified module could not be found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\aanan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\aanan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\aanan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 30, in <module>
    self_check.preload_check()
  File ""C:\Users\aanan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\platform\self_check.py"", line 82, in preload_check
    % (build_info.cudart_dll_name, build_info.cuda_version_number))
ImportError: Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive
>>>

Steps I followed. I'm new to Python commands but I should be able to follow.
https://github.com/jvishnuvardhan/Installing-TensorFlow-GPU-on-Windows-10-TF1.12


Should I remove 10.1, or is a parallel installation okay? Additionally, after reading the code, it seems there is a simple missing file or two that is causing this issue. Is my diagnosis correct? If not, please guide. My gratitude in advance.

PS. It appears to me that CUDA 10.0's absence is creating this entire mess. I shall install and report.

PSS. I cannot remove 10.1 for the following reason:
NVIDIAÂ® GPU drivers â€”CUDA 10.0 requires 410.x or higher. CUDAÂ® Toolkit â€”TensorFlow supports CUDA 10.0 **(TensorFlow >= 1._13_.0)** CUPTI ships with the CUDA Toolkit. cuDNN SDK **(>= 7.4.1)**
"
30265,`tf.contrib.layers.recompute_grad` values on recompute different,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro, Version 1809, OS Build 17763.557
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): Tensorflow GPU 1.14.0
- Python version: 3.6.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: CUDA 10.0, cuDNN 7.6.0
- GPU model and memory: NVIDIA Quadro M2000M

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
`recompute_grad` returns `_WRONG_VARS_ERR`

**Describe the expected behavior**
Model trained with `recompute_grad` can perform predictions, as well as to compute specific gradients

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

Please see [StackOverflow 56829378](https://stackoverflow.com/questions/56829378/valueerror-the-variables-used-on-recompute-were-different-than-the-variables-or)

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

To visualize the error, I added print statements to `rev_block_lib.py` to output the recomputed versus original variables. This was the result:

```
ORIGINAL VARIABLES

{<tf.Variable 'fc04/fc04_100000/fc04_100000/kernel:0' shape=(25, 10) dtype=float32>, <tf.Variable 'fc04/fc04_100000/fc04_100000/bias:0' shape=(10,) dtype=float32>}

RECOMPUTE VARIABLES

{<tf.Variable 'gradients/fc04/fc04_100000/IdentityN_grad/fc04_100000/fc04_100001/bias:0' shape=(10,) dtype=float32>, <tf.Variable 'gradients/fc04/fc04_100000/IdentityN_grad/fc04_100000/fc04_100001/kernel:0' shape=(25, 10) dtype=float32>}
```"
30263,[TF2.0]: Skipping optimization due to error while loading function,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0.0-beta1
- Python version: 3.6.0

**Describe the current behavior**
I'm trying to reproduce the results from the tutorial example about ""Text classification with an RNN"" provided by Tensorflow at: [https://www.tensorflow.org/beta/tutorials/text/text_classification_rnn](url)

However, this warning message constantly appears that shows ""skipping optimization due to error while loading function libraries: Invalid argument: ... ""

I tried other optimizers, and LSTM or GRU architectures but nothing changes!

![Untitled](https://user-images.githubusercontent.com/52288474/60402198-595ade00-9b5a-11e9-837f-d60f0518f2d0.jpg)

 
**Code to reproduce the issue**

```ruby
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
print(tf.__version__)
import tensorflow_datasets as tfds

# plot result
import matplotlib.pyplot as plt
def plot_graph(histroy, string):
    plt.plot(histroy.history[string])
    plt.plot(histroy.history['val_' + string])
    plt.xlabel('Epochs')
    plt.ylabel('string')
    plt.legend([string, 'val_'+string])
    plt.show()

# See available datasets
# print(tfds.list_builders())
dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,
                          as_supervised=True)
train_dataset, test_dataset = dataset['train'], dataset['test']
tokenizer = info.features['text'].encoder
# print('Vocabulary size: {}'.format(tokenizer.vocab_size))
# sample_string = 'TensorFlow is cool'
# tokenized_string = tokenizer.encode(sample_string)
# print ('Tokenized string is {}'.format(tokenized_string))
# original_string = tokenizer.decode(tokenized_string)
# print ('The original string: {}'.format(original_string))
# assert original_string == sample_string
# for ts in tokenized_string:
#     print('{} -------> {}'.format(ts, tokenizer.decode([ts])))

BUFFER_SIZE = 10000
BATCH_SIZE = 64
train_dataset = train_dataset.shuffle(BUFFER_SIZE)
train_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)
test_dataset = test_dataset.padded_batch(BATCH_SIZE,test_dataset.output_shapes)

# Build the model
EM_SIZE = 64
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),
    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)),
    tf.keras.layers.Dense(64, activation= 'relu'),
    tf.keras.layers.Dense(1,activation = 'sigmoid')
])
model.compile(loss= 'mse',
            optimizer= 'sgd',
            metrics=['accuracy'])
history = model.fit(train_dataset, epochs = 1, validation_data=test_dataset)
test_loss, test_acc = model.evaluate(test_dataset)
print('Test Loss: {}'.format(test_loss))
print('Test Accuracy: {}'.format(test_acc))
```
It seems that many other users are experiencing similar issues on TF2.0-beta"
30262,Get the number of GPUs used in Tensorflow Distributed in a multi node approach,"I am currently trying to compare Horovod and Tensorflow Distributed API. 

When using using Horovod, I am able to access the total number of GPUs currently used as follows:

```python
import horovod.tensorflow as hvd
size = hvd.size()
```

A similar concept is available when using PyTorch Distributed API:
```python
size = int(os.environ[""WORLD_SIZE""])
```

-----------

I would like to perform the same operation and obtain the number of GPUs currently in use for multi GPUs/nodes with TF Distributed official API.

I can't use `CUDA_VISIBLE_DEVICES` environment variable as it would only work on a single node."
30261,"Colab notebook crashes due to RAM overuse on ""Explore overfitting and underfitting"" tutorial","## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#scrollTo=LqG3MXF5xSjR

## Description of issue (what needs changing):

Notebook crashes on the code block training the baseline model, reporting that all RAM has been consumed.

### Clear description

Users should be able to complete the entire notebook without hitting resource limits

Maybe the model is not defined correctly? This is the summary:

```
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 16)                160016    
_________________________________________________________________
dense_1 (Dense)              (None, 16)                272       
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 17        
=================================================================
Total params: 160,305
Trainable params: 160,305
Non-trainable params: 0
```"
30259,including human ethics inside tensorflow as tf.ethics,"wouldn't it be great to integrate ethics inside tensorflow.like when a baby is born,they get in touch with social norms.as they start to grow up their brain based on social norms/ethics start to react.based on previous norms new norms start to kick off inside brain.

by the way human ethics has an evolution timeline like the biological evolution.it is changing.

"
30256,Tensorflow need a long startup time,"when I run the example on https://www.tensorflow.org/tutorials/
It take around 5 minutes at:
Adding visible gpu devices: 0
before the tensorflow begins to compute. As far as I know a lot of people have this problem since a years age, but there seems to be no effective way to sove the problem.
the only way I know is to compile from source, that is not a good way for a beginner.

My environment is Win10, tensorflow-gpu-2.0-beta1ï¼Œ CUDA 10.0, cuDNN 7.6, python 3.6 and with GTX 850M

When the problem will be fixedï¼Ÿ"
30254,could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED,"Hello,
For a long time now, I've been trying to resolve problem from the header:
could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
I went through all of the similar issues but none of the solutions worked for me.

this log: possibly insufficient driver version: 387.26.0
seems to indicate that I have a bad driver version but for CUDA 9.0 documentation (https://docs.nvidia.com/deploy/cuda-compatibility/index.html#binary-compatibility__table-toolkit-driver) says:
CUDA 9.0 (9.0.76)	>= 384.81
which is lower than I currently have installed (387.26)
I really hope to get some help,
cheers, Kasia

**System information**
Running tensorflow inside singularity container:
https://singularity-hub.org/collections/3092
singularity pull --name eric.img shub://Eric716/tensorflow-gpu-cuda9.0:fullversion
singularity shell --nv eric.img

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
EMI release 3.0 (Monte Bianco)
LSB_VERSION=base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch
Scientific Linux CERN SLC release 6.5 (Carbon)

- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): tensorflow-gpu      1.8.0
Keras               2.2.4
- Python version: Python 3.5.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA Version 9.0.176 / 
cuDNN: 
cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2
#define CUDNN_MAJOR 7
#define CUDNN_MINOR 4
#define CUDNN_PATCHLEVEL 2

nvidia-smi
Driver Version: 387.26
- GPU model and memory:

**Describe the current behavior**
Using TensorFlow backend.
2019-06-30 00:10:58.871234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:0d:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-06-30 00:10:58.871309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2019-06-30 00:10:59.318801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-30 00:10:59.318875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2019-06-30 00:10:59.318897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2019-06-30 00:10:59.320282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8007 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:0d:00.0, compute capability: 3.7)
2019-06-30 00:11:00.116849: E tensorflow/stream_executor/cuda/cuda_dnn.cc:455] could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2019-06-30 00:11:00.380252: E tensorflow/stream_executor/cuda/cuda_dnn.cc:463] possibly insufficient driver version: 387.26.0
2019-06-30 00:11:00.380342: F tensorflow/core/kernels/conv_ops.cc:713] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) 
Aborted



**Code to reproduce the issue**
import numpy as np
from keras.models import Input, Model
from keras.layers import Conv1D
from keras.optimizers import *
import keras.backend as K


def conv_model(input_size=(256, 1)):
    cfg = K.tf.ConfigProto(gpu_options={'allow_growth': True, 'per_process_gpu_memory_fraction': 0.7})
    K.set_session(K.tf.Session(config=cfg))

    inputs = Input(input_size)
    conv = Conv1D(1, 3, padding='same')(inputs)
    model = Model(inputs=inputs, outputs=conv)
    model.compile(optimizer=Adam(lr=2e-4), loss='binary_crossentropy', metrics=['accuracy'])
    return model


if __name__ == '__main__':
    num_epochs = 300
    model = conv_model()
    input_batch = np.array([np.concatenate([[[0]]*100, [[1]]*56, [[0]]*100])])

    for epoch in range(num_epochs):
        loss, acc = model.train_on_batch(input_batch, input_batch)
        print('loss: {}, acc: {}'.format(loss, acc))

"
30253,Problem Passing Tensor Attr to Custom Op in Eager Execution Mode,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Windows 10:
- TensorFlow installed from binary:
- TensorFlow version 1.14:
- Python version 3.7:
- CUDA/cuDNN version 10:

I am defining a new custom Op in C++, which takes in a single attribute of type tensor and a single input tensor variable. A stripped version of the Op code is below:

    #include ""tensorflow/core/framework/op.h""
    #include ""tensorflow/core/framework/op_kernel.h""
    
    using namespace tensorflow;
    
    REGISTER_OP(""DoStuff"")
        .Attr(""attr: tensor = { dtype: DT_FLOAT }"")
        .Input(""in: float"")
        .Output(""out: float"");
    
    class DoStuffOp : public OpKernel {
    public:
        explicit DoStuffOp(OpKernelConstruction *context) : OpKernel(context) {
            OP_REQUIRES_OK(context, context->GetAttr(""attr"", &attr_));
            // ...
        }
    
        void Compute(OpKernelContext *context) override {
            // ...
        }
    
    private:
        Tensor attr_;
    };
    
    REGISTER_KERNEL_BUILDER(Name(""DoStuff"").Device(DEVICE_CPU), DoStuffOp);

I can compile the Op into a .so file fine. Now, the following code runs.

    import tensorflow as tf
    dostufflib = tf.load_op_library('build/do_stuff.so')
    sess = tf.InteractiveSession() 

    sample_in = np.random.rand(3,3)
    sample_in_t = tf.convert_to_tensor(sample_in, dtype=np.float32)
    sample_atrr = np.zeros([3,3], dtype=np.float32)
    sample_attr_t = tf.contrib.util.make_tensor_proto(sample_atrr)

    Y = dostufflib.do_stuff(in=sample_in_t, attr=sample_attr_t)

However, if I try to use eager execution mode i.e.

    import tensorflow as tf
    tf.compat.v1.enable_eager_execution()
    dostufflib = tf.load_op_library('build/do_stuff.so')
    
    sample_in = np.random.rand(3,3)
    sample_in_t = tf.convert_to_tensor(sample_in, dtype=np.float32)
    sample_atrr = np.zeros([3,3], dtype=np.float32)
    sample_attr_t = tf.contrib.util.make_tensor_proto(sample_atrr)
    
    Y = dostufflib.do_stuff(in=sample_in_t, attr=sample_attr_t)

I get the following error,

    tensorflow.python.framework.errors_impl.UnimplementedError: Attr sample_locs has unhandled type 6
"
30252,TPU Outfeed Dequeue Many,"I have an application that is bottlenecked by waiting for elements to be dequeued from the TPU. Is there any way to dequeue many from the outfeed in a single operation?

Right now my program runs two threads in parallel:
  1. a computation followed by an outfeed_enqueue
  2. a outfeed_dequeue that collects elements from the outfeed and acts on them

for Thread 1. I can execute the op ~30 times for every dequeue in Thread 2. So ideally, I'd like to dequeue the 30 batches that are sitting in my outfeed queue instead of a single batch at a time. Is there a way to do this?

I'm running TF 1.13 (although I'm sure TF 1.14 would be fine too)."
30251,tf.keras.experimental.export_saved_model in multi-gpu mode doesn't work,"I use TF 2.0. Currently, `tf.keras.experimental.export_saved_model` doesn't work in multi-gpu mode, i.e when model is declarated in `strategy.scope()`. I got the following error:

```
File .../tensorflow/python/ops/variables.py"", line 514, in synchronization
    raise NotImplementedError
``` 

I tried the next code:

```
tf.keras.experimental.export_saved_model(
    model, file_path,
    serving_only=True,
    input_signature=[tf.TensorSpec(shape=[None, None, None, 3], dtype=tf.float32)]
)
```"
30250,How to maintain the FIFOQueue when training,"Hi, I want to use FIFOQueue to keep K elements in training process.
```python
    input_tensor = tf.placeholder(tf.float32, shape=[None, 224, 224, 3], name='x')
    model = SEVGGModel(input_tensor, input_tensor)
    print(model.output_feature, model.output_feature_map, model.output_feature_norm)
    import os
    os.environ[""CUDA_VISIBLE_DEVICES""] = ""3""
    sess = tf.Session()
    sess.run(tf.initialize_all_variables())
    # coord = tf.train.Coordinator()
    # threads = tf.train.start_queue_runners(coord=coord, sess=sess)

    print(sess.run(model.last_ele_queue.size()))
    print('ref is ', model.last_ele_queue.queue_ref)
    with tf.control_dependencies([model.enqueue_op]):
        # output_tensor = tf.cond(
        #     tf.equal(model.last_ele_queue.size(), 0),
        #     lambda: 0.,
        #     lambda: model.last_ele_queue.dequeue_many(30)
        # )
        loss_tensor = model.build_loss(True)
    for i in range(100):
        feed_dict = {
            input_tensor: np.random.random([30, 224, 224, 3]) * i
        }
        # sess.run(model.enqueue_op, feed_dict=feed_dict)  ## with or without
        print(i, sess.run(model.last_ele_queue.size()))
        _, loss_value = sess.run([model.enqueue_op, loss_tensor], feed_dict=feed_dict)
        # print(np.shape(values), np.max(values), np.min(values))
        print('loss_value ', loss_value)
    print(sess.run(model.last_ele_queue.size()))
```
the loss value can be see as the sum of all elements in Queue and the feed_dict is the element in the Queue..
I found when I use the code sess.run(model.enqueue_op, feed_dict=feed_dict), I think the loss value should be double. But the result is not. The result of with or without this line are same.

So can you help me explain it?

Thanks you!"
30249,.tflite converted model (from .h5 file) not working as expected,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, custom model to count fingers, but the TFLite converter code is same as example scripts provided in API docs.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: All android devices using TFlite example app (replaced the sample models with my custom tflite model)
- TensorFlow installed from (source or binary): pip installed tensorflow-gpu AND tf-nightly-gpu
- TensorFlow version (use command below): Tried on 1.14, 1.13, 1.14-nightly, 2.0.0-beta1
- Python version: 3.6.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: Cuda 10.0
- GPU model and memory: GTX 1060 6GB

**Describe the current behavior**
I've trained a simple CNN to count number of fingers held up. The model works really well (~99% accuracy on test images). Now, I'm trying to deploy this model on the edge by converting the saved model (.h5 file) to a .tflite file.

Using tf.lite.TFLiteConverter.from_keras_model_file(), it converts and gives me a .tflite file with this error:
`tensorflow/core/grappler/grappler_item_builder.cc:637] Init node conv2d/kernel/Assign doesn't exist in graph`

Now, when I load this tflite file and try to make predictions on the same input images, it always predicts 'ZERO' which is the first class label and with probability = 0.003922. The rest of the classes are always 0.00, I get the same results when loading my tflite model in the Android Image classification example app from Tensorflow repo's.

**Describe the expected behavior**
I expect my .tflite model to behave the same as my Tensorflow .h5 model. But it always predicts 
the first class label with the same probability score. 
I've tried converting to .tflite with TF-gpu versions 1.14, 1.13, nightly 1.14 and TF-2.0.0-beta1
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
**My custom model:**
```
redacted
```

**Code I used to convert to .tflite:** 

```
import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_keras_model_file(""fingers_latest.h5"")
tflite_model = converter.convert()
open(""fingers_latest.tflite"", ""wb"").write(tflite_model)
```


**Code to load and test the .tflite model:**

```
import tensorflow as tf
import tkinter as tk
from tkinter import filedialog
import PIL
from PIL import Image
import numpy as np
import time

# DEF. PARAMETERS
img_row, img_column = 256, 256
num_channel = 3
num_batch = 1
input_mean = 0
input_std = 255
floating_model = False

path_1 = r""./models/fingers_latest.tflite""
labels_path = ""./models/labels.txt""

def load_labels(filename):
    my_labels = []
    input_file = open(filename, 'r')
    for l in input_file:
        my_labels.append(l.strip())
    return my_labels

interpreter = tf.lite.Interpreter(path_1)
interpreter.allocate_tensors()

# obtaining the input-output shapes and types
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print(input_details, '\n', output_details)

# file selection window for input selection
root = tk.Tk()
root.withdraw()
file_path = filedialog.askopenfilename()
input_img = Image.open(file_path)
input_img = input_img.resize((img_row, img_column))
input_img = np.expand_dims(input_img, axis=0)

input_img = (np.float32(input_img) - input_mean) / input_std

interpreter.set_tensor(input_details[0]['index'], input_img)

# running inference
interpreter.invoke()

output_data = interpreter.get_tensor(output_details[0]['index'])
results = np.squeeze(output_data)

top_k = results.argsort()[-5:][::-1]
labels = load_labels(labels_path)
for i in top_k:
    print('{0:08.6f}'.format(float(results[i] / 255.0)) + "":"", labels[i]) 
```


Why does this tflite model not work as expected? Am I missing something during the conversion or using operations that aren't supported in TFlite? Please help!

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

[My .h5 model and a test file, if you would like to try it yourself](https://drive.google.com/drive/folders/1_jiRqHgRUyV5YBNcDPKPtZMGjUpkf8sC)"
30248,tf.io.write_file not working in tf.function decorated function,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2 and Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-beta1
- Python version: 3.7

**Describe the current behavior**
`tf.io.write_file` creates file in eager execution but produces no output file when decorated with `@tf.function`.

**Describe the expected behavior**
`tf.io.write_file` should create an output file whether or not being decorated with `@tf.function`.

**Code to reproduce the issue**
```python
import tensorflow as tf

@tf.function
def writeJPEG_graph(img_decoded, filename):
    out = tf.cast(img_decoded, tf.uint8)
    out = tf.image.encode_jpeg(out, quality=100)
    tf.io.write_file(filename, out)
    
def writeJPEG_eager(img_decoded, filename):
    out = tf.cast(img_decoded, tf.uint8)
    out = tf.image.encode_jpeg(out, quality=100)
    tf.io.write_file(filename, out)

img = tf.fill([256,256,3], 127) # example gray image
writeJPEG_graph(img, ""./tfwrite_graph.jpg"") # ""tfwrite_graph.jpg"" not created
writeJPEG_eager(img, ""./tfwrite_eager.jpg"") # ""tfwrite_eager.jpg"" created
```"
30246,The shared library of C++ API lacks of operation symbols on windows.,"
**System information**
- Windows 10 1809:
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.14.0
- Python version: 3.7.3
- Bazel version (if compiling from source):  0.25.2
- GCC/Compiler version (if compiling from source): visual studio 2017

**Describe the problem**
I tried to build the [label image c++ demo](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/main.cc) and I got lots of linking error which cannot find the tf operation symbols. Such as:
Severity	Code	Description	Project	File	Line	Suppression State
Error	LNK2001	unresolved external symbol ""public: __cdecl tensorflow::ops::Subtract::Subtract(class tensorflow::Scope const &,class tensorflow::Input,class tensorflow::Input)"" (??0Subtract@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@1@Z)	tf1.14.0	D:\ProgrammingAndStudy\C++_proj\tf1.14.0\tf1.14.0\main.obj	1	


**Provide the exact sequence of commands / steps that you executed before running into the problem**
I build the tensorflow 1.14.0 C++ API through the MSYS2 shell after some configeration. 
Although I configured using vs2019 here, but it seems useless. Bazel still choosing the vs2017.
export MSYS_NO_PATHCONV=1
export MSYS2_ARG_CONV_EXCL=""*"" 
export PATH=""/C/Users/yueji/AppData/Local/Programs/Python/Python37"":$PATH
alias python='winpty python.exe'
export PATH=""/C/machine learning dlls"":$PATH
set BAZEL_VS=""C:\Program Files (x86)\Microsoft Visual Studio\2019\Community""
set BAZEL_VC=""C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC""

And then, I compiled the tf1.14.0 through
bazel build --config=opt //tensorflow:tensorflow_cc
bazel build --config=opt //tensorflow:tensorflow_framework

Finally, I got two libs and two dlls. They are located in C:\Users\user_name\_bazel_yueji\dvw6l3y3\execroot\org_tensorflow\bazel-out\x64_windows-opt\bin\tensorflow
tensorflow.dll.if.lib, tensorflow_framework.dll.if.lib
tensorflow_cc.dll, tensorflow_framework.dll

I configured my vs projects to make sure the headers are properly included, and linked these two libs. 
However there are lots of lnk2001 errors are reported.

**Any other info / logs**
It's a part of error file.

Severity	Code	Description	Project	File	Line	Suppression State
Error	LNK2001	unresolved external symbol ""public: __cdecl tensorflow::ops::Subtract::Subtract(class tensorflow::Scope const &,class tensorflow::Input,class tensorflow::Input)"" (??0Subtract@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@1@Z)	tf1.14.0	D:\ProgrammingAndStudy\C++_proj\tf1.14.0\tf1.14.0\main.obj	1	
Error	LNK2001	unresolved external symbol ""public: __cdecl tensorflow::ops::Squeeze::Squeeze(class tensorflow::Scope const &,class tensorflow::Input)"" (??0Squeeze@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@@Z)	tf1.14.0	D:\ProgrammingAndStudy\C++_proj\tf1.14.0\tf1.14.0\main.obj	1	
Error	LNK2001	unresolved external symbol ""public: __cdecl tensorflow::ops::DecodeGif::DecodeGif(class tensorflow::Scope const &,class tensorflow::Input)"" (??0DecodeGif@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@@Z)	tf1.14.0	D:\ProgrammingAndStudy\C++_proj\tf1.14.0\tf1.14.0\main.obj	1	
Error	LNK2001	unresolved external symbol ""public: __cdecl tensorflow::ops::TopK::TopK(class tensorflow::Scope const &,class tensorflow::Input,class tensorflow::Input)"" (??0TopK@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@1@Z)	tf1.14.0	D:\ProgrammingAndStudy\C++_proj\tf1.14.0\tf1.14.0\main.obj	1	

"
30242,tensorflow ,
30235,`xla.compile` + `tf.function` lose information about compile-time constants,"**System information**
- TensorFlow version (use command below): 1.14

**Describe the current behavior**

In Eager mode, when a function is compiled with `xla.compile`, any constant arguments are auto-cast to Tensors, but these Tensors don't appear to reflect the fact that they are constant. Certain ops, like `tf.range` are sensitive to constant inputs due to the need for static shapes.

In effect, the following code raises an error:

```
import tensorflow as tf

tf.enable_eager_execution()

@tf.function
def bad(count):
  return tf.range(count)

xla.compile(bad, (3,))
```
```
InvalidArgumentError: Argument to function must be a compile-time constant, but unable to resolve argument value to a constant.
	This error might be occurring with the use of xla.compile. If it is not necessary that every Op be compiled with XLA, an alternative is to use auto_jit with OptimizerOptions.global_jit_level = ON_2 or the environment variable TF_XLA_FLAGS=""tf_xla_auto_jit=2"" which will attempt to use xla to compile as much of the graph as the compiler is able to.
	 [[{{node cluster}}]] [Op:__inference_xla_compile_wrapper_196]
```

Whereas this code works:

```
import tensorflow as tf

tf.enable_eager_execution()

@tf.function
def good():
  return tf.range(3)

xla.compile(good, ())
```
```
[<tf.Tensor: id=157, shape=(3,), dtype=int32, numpy=array([0, 1, 2], dtype=int32)>]
```

**Describe the expected behavior**

The two snippets of code above should be equivalent, that is, they should both run successfully.
"
30234,How to calculate gradients for meta learning loop?,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): TF 2.0.0-dev20190628
- Python version: 3.6.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10.0
- GPU model and memory: 


**Describe the current behavior**
I want to compute the gradients of a loss function with respect to a model (in order to do meta-learning) and use those gradients to define the same model with new weights. I get None as the values of the model when  I use Input layers.

**Describe the expected behavior**
I was expecting it to work the same whether I define my input layer as an Input layer or as tf.random.uniform() tensor.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Flatten, Dense, Input


with tf.GradientTape() as t:
    model = tf.keras.models.Sequential(
        (
            Conv2D(filters=64, kernel_size=3, activation='relu'),
            Conv2D(filters=64, kernel_size=3, activation='relu'),
            Conv2D(filters=64, kernel_size=3, activation='relu'),
            Conv2D(filters=64, kernel_size=3, activation='relu'),
            Flatten(),
            Dense(10, activation='softmax'),
        )
    )

    train_inputs = Input(shape=(28, 28, 1))
    train_labels = Input(shape=(10, ))

    # train_inputs = tf.random.uniform(shape=(1, 28, 28, 1), dtype=tf.float32)
    # train_labels = tf.random.uniform(shape=(1, 10), dtype=tf.float32)

    train_outputs = model(train_inputs)
    loss = tf.losses.categorical_crossentropy(train_labels, train_outputs)

d_weights = t.gradient(loss, model.trainable_weights)
print(d_weights)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

If I uncomment those two lines d_weights is calculated and printed. When they are commented I get this error:

2019-06-28 14:27:30.352043: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-28 14:27:30.386438: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2208000000 Hz
2019-06-28 14:27:30.387394: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2f99b30 executing computations on platform Host. Devices:
2019-06-28 14:27:30.387417: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
Traceback (most recent call last):
  File ""/home/siavash/programming/meta-learning-framework/models.py"", line 27, in <module>
    d_weights = t.gradient(loss, model.trainable_weights)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py"", line 1001, in gradient
    unconnected_gradients=unconnected_gradients)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/imperative_grad.py"", line 76, in imperative_grad
    compat.as_str(unconnected_gradients.value))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py"", line 666, in _ones
    return _fast_fill(value, shape, dtype)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py"", line 621, in _fast_fill
    constant_op.constant(shape, dtype=dtypes.int32),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py"", line 246, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py"", line 254, in _constant_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py"", line 115, in convert_to_eager_tensor
    return ops.EagerTensor(value, handle, device, dtype)
ValueError: TypeError: object of type 'Tensor' has no len()"
30233,Make saver.restore work with tf.keras.layers when using tf.estimator to save model checkpoints,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):1.14
- Are you willing to contribute it (Yes/No):



**Describe the feature and the current behavior/state.**
 How do I  convert a saved tensorflow estimator model to a Keras model? (either by using the check pointed weights or the saved model) It is possible to convert a compiled Keras model to an estimator instance but it would be great if there is a clean way to convert an estimator saved model back to a keras model without having to manually copy weights. 

**Will this change the current api? How?**
Not sure

**Who will benefit with this feature?**
Will help folks using tf estimators to train and save model checkpoints and restore them directly when a tf.keras model is instantiated.

**Any Other info.**
"
30232,Tensorflow Lite conversion misshapes bias vector of FullyConnected,"**System information**
- Have I written custom code: tflite converter code is straight from an example script
- OS Platform and Distribution: Mac OS 10.14.5
- TensorFlow installed from: `pip install tf-nightly` and `pip install tensorflow`
- TensorFlow version:
tested on  `v1.12.1-5178-gbafa0371c8 1.15.0-dev20190628` and `v1.13.0-rc2-5-g6612da8951 1.13.1`
- Python version: 3.6.5

**Describe the current behavior**
TFLite converter incorrectly shapes the bias for FullyConnected operators.
Specifically in my test case (see attached model below), in the original freeze graph model, `MatMul_6` takes a product of 32x12 matrix and 12x1 vector then `add_7` adds a 32x1 vector to it as a bias. The converted TFLite model puts these two operations together into a FullyConnected op, and somehow its bias `MatMul_6_bias` is incorrectly shaped as a single-element vector. Consequently, the inference result of this TFLite model is incorrect.

**Describe the expected behavior**
The bias vectors should be shaped as they were in the original freeze graph model.

**Code to reproduce the issue**
[tflite_bias_shape_issue.zip](https://github.com/tensorflow/tensorflow/files/3340234/tflite_bias_shape_issue.zip)
This zip file contains debug.pb (TF freeze graph model) and debug.tflite (TFLite converted model from frozen model). The conversion code is taken straight from the document:
```
import tensorflow as tf
graph_def_file = ""debug.pb""
input_arrays = [""input""]
output_arrays = [""Reshape_1""]
converter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays)
tflite_model = converter.convert()
open(""debug.tflite"", ""wb"").write(tflite_model)
```
The model has extra operators in the beginning (Sub, Div, Gather) just because I did not have time to rebuild the bare minimal test case but I think it is already simple enough."
30229,ReorderAxes in TFLite,"**System information**
- OS Platform and Distribution: Ubuntu
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): TF 2.0-beta1


**Provide the text output from tflite_convert**

```
2019-06-28 19:47:44.325579: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reciprocal
2019-06-28 19:47:44.342432: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 211 operators, 317 arrays (0 quantized)
2019-06-28 19:47:44.345471: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 211 operators, 317 arrays (0 quantized)
2019-06-28 19:47:44.354646: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 153 operators, 279 arrays (0 quantized)
2019-06-28 19:47:44.358004: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 150 operators, 273 arrays (0 quantized)
2019-06-28 19:47:44.361223: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 150 operators, 273 arrays (0 quantized)
2019-06-28 19:47:44.363593: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 150 operators, 273 arrays (0 quantized)
2019-06-28 19:47:44.367975: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 55296128 bytes, theoretical optimal value: 33177600 bytes.
2019-06-28 19:47:44.369169: E tensorflow/lite/toco/toco_tooling.cc:462] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. 
If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). 
Here is a list of builtin operators you are using: ABS, ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, DIV, EXPAND_DIMS, FULLY_CONNECTED, GREATER, LEAKY_RELU, LOGICAL_NOT, MAXIMUM, MEAN, MINIMUM, MUL, NEG, PACK, POW, RESHAPE, RESIZE_BILINEAR, SHAPE, STRIDED_SLICE, SUB, SUM, TANH, TILE, TRANSPOSE. 
Here is a list of operators for which you will need custom implementations: ReorderAxes.
```
"
30227,tf.keras.layers.RNN calls the cell using the first timestep of the timeseries twice,"Trying to develop an internal attention module for Lummetry.AI deep learning team, I experienced a possible bug in working with tf.keras.layers.RNN. The problem comes from calling the first timestep of the given timeseries twice. I'm using as a RNN cell, for debugging scopes, the class defined in the example given at https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN

```python
import tensorflow as tf
import numpy as np
tf.enable_eager_execution()

class MinimalRNNCell(tf.keras.layers.Layer):

    def __init__(self, units, **kwargs):
        self.units = units
        self.state_size = units
        super(MinimalRNNCell, self).__init__(**kwargs)

    def build(self, input_shape):
        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),
                                      initializer='uniform',
                                      name='kernel')
        self.recurrent_kernel = self.add_weight(
            shape=(self.units, self.units),
            initializer='uniform',
            name='recurrent_kernel')
        self.built = True

    def call(self, inputs, states):
        prev_output = states[0]
        h = K.dot(inputs, self.kernel)
        output = h + K.dot(prev_output, self.recurrent_kernel)
        print(""Call {}"".format(inputs)) 
        return output, [output]

if __name__ == ""__main__"":
    inp = np.array([2, 3, 4, 1, 2, 3, 0, 1]).reshape(2,2,2).astype(np.float32)
    minimal_cell = MinimalRNNCell(32)
    rnn_lyr = tf.keras.layers.RNN(minimal_cell, return_sequences=True)
    rnn_lyr(tf.Variable(inp)) 
    # This call outputs: 
    # Call: [[2. 3.]
    #   [2. 3.]]
    # Call: [[2. 3.]
    #   [2. 3.]]
    # Call: [[4. 1.]
    #   [0. 1.]]
```

Can someone explain if there is something that I am missing, or if it really is a bug?

Thanks!
"
30226,tensorflow:libtensorflow_cc.so fails to build for --cpu=armeabi-v7a,"- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04.3
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: current master branch(28.06.2019)
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.24.1
- **GCC/Compiler version (if compiling from source)**:7.4.0 
- **CUDA/cuDNN version**:Not Used
- **GPU model and memory**:
- **Exact command to reproduce**:
bazel build -c opt //tensorflow:libtensorflow_cc.so --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=armeabi-v7a --verbose_failures --cxxopt=""-DTENSROFLOW_DISABLE_META"" --jobs 8 --copt=""-funsafe-math-optimizations"" --copt=""-ftree-vectorize"" --copt=""-fomit-frame-pointer"" --copt=-DNO_LOCAL_MEM --copt=-DEIGEN_DONT_VECTORIZE_SYCL --copt=-DMDB_USE_ROBUST=0 --cxxopt=""-fPIC"" --cxxopt=""-std=c++11""


### Describe the problem
Trying to compile //tensorflow:libtensorflow_cc.so for armeabi-v7a and/or for arm64-v8a, both failing with the output:
**ERROR: ../tensorflow/tensorflow/cc/saved_model/BUILD:40:1: no such target '//tensorflow/core:saved_model_portable_proto': target 'saved_model_portable_proto' not declared in package 'tensorflow/core' defined by ../tensorflow/tensorflow/core/BUILD and referenced by '//tensorflow/cc/saved_model:reader**
"
30224,May need more packages in Anaconda 2019.3 in win 10 1903,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10 64-bit 1903**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): `.whl`
- TensorFlow version: **1.14.0**
- Python version: **3.7.3 (from Anaconda 2019.3)**
- Installed using virtualenv? pip? conda?: **pip**
- Bazel version (if compiling from source): no
- GCC/Compiler version (if compiling from source): no
- CUDA/cuDNN version: no
- GPU model and memory: no GPU (IntelÂ® UHD Graphics 630)



**Describe the problem**

I need to install tensorflow in an offline environment. So I installed Anaconda 2019.3. And downloaded tensorflow .whl file (`tensorflow-1.14.0-cp37-cp37m-win_amd64.whl`). As the `tensorflow/tools/pip_package/setup.py ` file said, other packages were needed. Here I quote,
```
REQUIRED_PACKAGES = [
    'absl-py >= 0.7.0',
    'astor >= 0.6.0',
    'gast >= 0.2.0',
    'google_pasta >= 0.1.6',
    'keras_applications >= 1.0.8',
    'keras_preprocessing >= 1.0.5',
    'numpy >= 1.14.5, < 2.0',
    'opt_einsum >= 2.3.2',
    'six >= 1.10.0',
    'protobuf >= 3.6.1',
    'tensorboard >= 1.14.0, < 1.15.0',
    'tensorflow_estimator >= 1.14.0rc0, < 1.15.0rc0',
    'termcolor >= 1.1.0',
    'wrapt >= 1.11.1',
]
```
But actually, this list was not enough.
`markdown >= 2.6.8` was required by `tensorboard == 1.14.0`. 
`grpcio >= 1.8.6` was required by `tensorflow == 1.14.0`.
And, `setuptools >= 41.0.0` was required by `tensorflow == 1.14.0`, since `setuptools == 40.8.0` in Anaconda 2019.3.


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30223,training code utilize more cpu memory than gpu memory,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source):
- TensorFlow version (1.13.1):
- Python version: 2.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10
- GPU model and memory:Nvidia RTx 2080

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I am using tensorflow 1.13.1 with GPU RTx 2080. I am using reinforcement learning to train the robot in a gazebo platform using ROS. The issue is that it is running in CPU memory rather than GPU memory. It takes a lot of time to train a robot. I attached a screenshot of the nvidia smi which shows that it utilize 1.7Gb only of GPU while use 16Gb of RAM.
**Describe the expected behavior**
![Screenshot 2019-06-28 20:53:03](https://user-images.githubusercontent.com/45818401/60343521-c188b300-99e6-11e9-8715-2b511e40b023.png)


**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30222,SelectV2 and Reciprocal in TFLite,"**System information**
- OS Platform and Distribution: Ubuntu
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): TF 2.0-beta1


**Provide the text output from tflite_convert**

```
2019-06-28 15:22:19.759933: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: SelectV2
2019-06-28 15:22:19.772940: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reciprocal
2019-06-28 15:22:19.772994: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: SelectV2
2019-06-28 15:22:19.774404: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 138 operators, 202 arrays (0 quantized)
2019-06-28 15:22:19.776339: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 138 operators, 202 arrays (0 quantized)
2019-06-28 15:22:19.782519: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 94 operators, 172 arrays (0 quantized)
2019-06-28 15:22:19.784430: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 93 operators, 170 arrays (0 quantized)
2019-06-28 15:22:19.786303: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 93 operators, 170 arrays (0 quantized)
2019-06-28 15:22:19.787673: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 93 operators, 170 arrays (0 quantized)
2019-06-28 15:22:19.790494: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 33226752 bytes, theoretical optimal value: 22118464 bytes.
2019-06-28 15:22:19.791230: W tensorflow/lite/toco/tflite/operator.cc:2654] Op SelectV2 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-06-28 15:22:19.791295: W tensorflow/lite/toco/tflite/operator.cc:2654] Op SelectV2 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-06-28 15:22:19.791385: W tensorflow/lite/toco/tflite/operator.cc:2654] Op SelectV2 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-06-28 15:22:19.791436: W tensorflow/lite/toco/tflite/operator.cc:2654] Op SelectV2 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-06-28 15:22:19.791510: E tensorflow/lite/toco/toco_tooling.cc:462] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. 
If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). 
Here is a list of builtin operators you are using: ABS, ADD, CONCATENATION, CONV_2D, DIV, EXPAND_DIMS, FULLY_CONNECTED, GREATER, LEAKY_RELU, MAXIMUM, MEAN, MINIMUM, MUL, NEG, POW, RESHAPE, RESIZE_BILINEAR, SUB, TANH. 
Here is a list of operators for which you will need custom implementations: SelectV2.
```

**Any other info / logs**

At the beginning, I tried to convert without this ""magic"" line:
```
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
```

And I got almost the same error log, BUT it was additional operation that couldn't be converted. I attached the end of that log:

```
Here is a list of operators for which you will need custom implementations: Reciprocal, SelectV2.
```

As far as understood correctly, `tf.where` doesn't work and it is related to SelectV2, because when I remove line with `tf.where(x > 0, left, right)` everthing is okay. It's strange, because TFLite docs said that `tf.where` should work.

Also, I figured out that `Reciprocal` is linked to `1.0 / x` expression. "
30218,Substitute to keras.backend.get_session(),"Hi. 

Currently, I am exploring the Movidius Neural Compute Stick by Intel along with OpenVINO. For this, I am using `tensorflow` 1.13.1 since it still has `tensorflow.keras.back.get_session()`. Now why `get_session()`. This is because using this function I can easily extract the session from my `tensorflow.keras` model and use that session to generate `.pb` file. This `.pb` file is then supplied to OpenVINO to get the necessary files to run inference on an NCS. 

I am looking for ways to generate the `.pb` file using `tensorflow` 2.0. Following is how I do it using `tensorflow` 1.13.1:

```python
sess = K.get_session()
frozen = tf.graph_util.convert_variables_to_constants(sess,
	sess.graph_def, [model.output.op.name])
graph_io.write_graph(frozen, os.getcwd(), ""inference_graph.pb"", as_text=False)
```

where K is the alias for `tensorflow.keras.backend`.  "
30215,Unexpected `tf.cast` behavior between signed and unsigned integers,"It is tested on Google's own platform `https://colab.research.google.com`:
**System information**
- OS Platform and Distribution: Linux version 4.14.79+ (chrome-bot@swarm-cros-634)
- TensorFlow installed from (source or binary): The platform is provided by Google
- TensorFlow version: 1.14.0-rc1  (also tested on my own machine with TF 1.13.1)
- Python version: 3.6.8

**Describe the current behavior**
Type casting `tf.cast` from `tf.int32` to `tf.uint32` will make the Tensor become 0.

**Describe the expected behavior**
`tf.cast` should not change the bit representation of values.

**Code to reproduce the issue**
```
import tensorflow as tf

c = tf.constant([5, 6, 7, 8, 9, 10], dtype=tf.int32)
d = tf.constant([5, 6, 7, 8, 9, 10], dtype=tf.int32)
x = tf.cast(c, dtype=tf.uint32)
y = tf.cast(c, dtype=tf.uint32)
with tf.Session() as sess:
    x_raw, y_raw = sess.run([x, y])
    print(x_raw.dtype, y_raw.dtype)
    print(x_raw)
    print(y_raw)
    
print(tf.__version__)
```
Running this code gives the result:
```
uint32 uint32
[0 0 0 0 0 0]
[0 0 0 0 0 0]
1.14.0-rc1
```"
30212,error C2280: 'tensorflow::FunctionLibraryDefinition &tensorflow::FunctionLibraryDefinition::operator =(const tensorflow::FunctionLibraryDefinition &)': attempting to reference a deleted function,"**System information**
- OS Platform :   Windows 10 Pro
- TensorFlow version: 2.99
- Python version: Python 3.6.8 :: Anaconda, Inc.
- Installed using virtualenv: conda
- Bazel version :  0.24.1
- MSVC17
- NO CUDA

configuration : 
Please specify the location of python. [Default is C:\Users\zen2_microsoft\Anaconda3\envs\tensorflow-1.13.1-without-mkl\python.exe]:
Found possible Python library paths:
  C:\Users\zen2_microsoft\Anaconda3\envs\tensorflow-1.13.1-without-mkl\lib\site-packages
Please input the desired Python library path to use.  Default is [C:\Users\zen2_microsoft\Anaconda3\envs\tensorflow-1.13.1-without-mkl\lib\site-packages]
Do you wish to build TensorFlow with XLA JIT support? [y/N]: N
No XLA JIT support will be enabled for TensorFlow.
Do you wish to build TensorFlow with ROCm support? [y/N]: N
No ROCm support will be enabled for TensorFlow.
Do you wish to build TensorFlow with CUDA support? [y/N]: N
No CUDA support will be enabled for TensorFlow.
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]:
Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: N

**Describe the problem**
Build fails with below error .
compilation error log :

  C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.12.25827/bin/HostX64/x64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=""redacted"" -D__TIMESTAMP__=""redacted"" -D__TIME__=""redacted"" /Gy /Gw -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX /Fobazel-out/x64_windows-opt/bin/tensorflow/core/grappler/_objs/grappler_item/grappler_item.obj /c tensorflow/core/grappler/grappler_item.cc
Execution platform: @bazel_tools//platforms:host_platform
external/com_google_absl\absl/meta/type_traits.h(141): error C2280: 'tensorflow::FunctionLibraryDefinition &tensorflow::FunctionLibraryDefinition::operator =(const tensorflow::FunctionLibraryDefinition &)': attempting to reference a deleted function
.\tensorflow/core/framework/function.h(334): note: see declaration of 'tensorflow::FunctionLibraryDefinition::operator ='
external/com_google_absl\absl/meta/type_traits.h(121): note: see reference to alias template instantiation 'IsCopyAssignableImpl<tensorflow::FunctionLibraryDefinition>' being compiled
external/com_google_absl\absl/meta/type_traits.h(150): note: see reference to class template instantiation 'absl::type_traits_internal::is_detected<absl::type_traits_internal::IsCopyAssignableImpl,T>' being compiled
        with
        [
            T=tensorflow::FunctionLibraryDefinition
        ]
external/com_google_absl\absl/meta/type_traits.h(432): note: see reference to class template instantiation 'absl::is_copy_assignable<T>' being compiled
        with
        [
            T=tensorflow::FunctionLibraryDefinition
        ]
external/com_google_absl\absl/types/internal/optional.h(173): note: see reference to class template instantiation 'absl::is_trivially_copy_assignable<tensorflow::FunctionLibraryDefinition>' being compiled
tensorflow/core/grappler/grappler_item.cc(118): note: see reference to class template instantiation 'absl::optional<tensorflow::FunctionLibraryDefinition>' being compiled
.\tensorflow/core/framework/function.h(334): note: 'tensorflow::FunctionLibraryDefinition &tensorflow::FunctionLibraryDefinition::operator =(const tensorflow::FunctionLibraryDefinition &)': function was explicitly deleted
external/com_google_absl\absl/meta/type_traits.h(144): error C2280: 'tensorflow::FunctionLibraryDefinition &tensorflow::FunctionLibraryDefinition::operator =(const tensorflow::FunctionLibraryDefinition &)': attempting to reference a deleted function
.\tensorflow/core/framework/function.h(334): note: see declaration of 'tensorflow::FunctionLibraryDefinition::operator ='
external/com_google_absl\absl/meta/type_traits.h(121): note: see reference to alias template instantiation 'IsMoveAssignableImpl<tensorflow::FunctionLibraryDefinition>' being compiled
external/com_google_absl\absl/meta/type_traits.h(155): note: see reference to class template instantiation 'absl::type_traits_internal::is_detected<absl::type_traits_internal::IsMoveAssignableImpl,T>' being compiled
        with
        [
            T=tensorflow::FunctionLibraryDefinition
        ]
external/com_google_absl\absl/types/internal/optional.h(328): note: see reference to class template instantiation 'absl::is_move_assignable<T>' being compiled
        with
        [
            T=tensorflow::FunctionLibraryDefinition
        ]
external/com_google_absl\absl/types/optional.h(120): note: see reference to class template instantiation 'absl::optional_internal::assign_copy_traits<T>' being compiled
        with
        [
            T=tensorflow::FunctionLibraryDefinition
        ]
.\tensorflow/core/framework/function.h(334): note: 'tensorflow::FunctionLibraryDefinition &tensorflow::FunctionLibraryDefinition::operator =(const tensorflow::FunctionLibraryDefinition &)': function was explicitly deleted
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 11024.399s, Critical Path: 6294.48s
INFO: 2398 processes: 2398 local.
FAILED: Build did NOT complete successfully 

Please help me out ."
30211,core dump occurred when run boosted tree classifier demo in official tutorial,"Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz
CentOS Linux release 7.2.1511 (Core)
install from pip
CPU-version
tensorflow                               1.14.0rc1
tensorflow-estimator             1.14.0

Run boosted tree model from [official demo code ](https://www.tensorflow.org/tutorials/estimators/boosted_trees)
`est.train(train_input_fn, max_steps=100)`
If 'max_steps ' set to 100 , core dump occurred.
If 'max_steps ' set to 10, demo code go successful.

I tested the case with tf version 1.13 an another ubuntu docker, issue existed the same.
In tf version 1.10, there is an exception because the implementation of boosted tree does not support numeric columns.

I'm a little confused with the parameter 'max_steps'.  Model trained by SGD, steps refers the times of mini_batch, or something likes 'epoch'.  Optimization algorithm for boosted tree model must compute the entire dataset for both individual tree and tree node split. So what's the param 'steps' and 'max_steps' stand for?"
30208,tf keras base layer issue for input_tensors/output_tensors in 1.14.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10.0.17763
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (use command below): 1.14.0
- Python version: 3.6.8

**Describe the current behavior**
In tensorflow keras, the `input_tensors`, `output_tensors`, `output_shapes` of `class Node` was a list in tensorflow 1.13.1, even if it only contains one tensor. Now the behavior changes in 1.14.0, these variables are a single tensor (not a list any more) if there is one single element. We are developing based on tf keras, then this behavior is not backward compatible .

**Describe the expected behavior**
Can we change them back to list for the single tensor case?

**Code to reproduce the issue**
```python
from tensorflow.python import keras            
model = keras.Sequential()
model.add(keras.layers.Dense(5, input_shape=(4,), activation='sigmoid'))
model.add(keras.layers.Dense(3, input_shape=(5,), use_bias=True))
model.compile('sgd', 'mse')

def extract_inbound_nodes(layer):
     return layer.inbound_nodes if hasattr(layer, 'inbound_nodes') else layer._inbound_nodes

for l_ in model.layers:
   for node_ in extract_inbound_nodes(l_):
       assert isinstance(node_.output_tensors, list)
       assert isinstance(node_.input_tensors, list)
       assert isinstance(node_.output_shapes, list)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30207,Cannot Run Official TF2.0 Example in Official TF2.0 Docker Container,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Docker container tensorflow/tensorflow:2.0.0b1-gpu-py3
- TensorFlow version (use command below): 2.0.0-beta1
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: RTX 2080 Ti

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Running the the official example https://www.tensorflow.org/beta/tutorials/quickstart/advanced in the official container tensorflow/tensorflow:2.0.0b1-gpu-py3 got the following error:

```
> python advanced.py 
2019-06-27 17:09:34.195179: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-06-27 17:09:34.231111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-27 17:09:34.231786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.635
pciBusID: 0000:01:00.0
2019-06-27 17:09:34.232026: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-27 17:09:34.232777: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-27 17:09:34.233391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-27 17:09:34.233576: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-27 17:09:34.234366: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-27 17:09:34.235052: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-27 17:09:34.236947: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-27 17:09:34.237053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-27 17:09:34.237643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-27 17:09:34.238201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-06-27 17:09:34.238443: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-27 17:09:34.323017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-27 17:09:34.324202: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x39cfd60 executing computations on platform CUDA. Devices:
2019-06-27 17:09:34.324217: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2019-06-27 17:09:34.342363: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz
2019-06-27 17:09:34.343364: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3d629c0 executing computations on platform Host. Devices:
2019-06-27 17:09:34.343375: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-27 17:09:34.343534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-27 17:09:34.344103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.635
pciBusID: 0000:01:00.0
2019-06-27 17:09:34.344121: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-27 17:09:34.344128: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-27 17:09:34.344135: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-27 17:09:34.344141: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-27 17:09:34.344147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-27 17:09:34.344153: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-27 17:09:34.344160: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-27 17:09:34.344188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-27 17:09:34.344698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-27 17:09:34.345203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-06-27 17:09:34.345217: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-27 17:09:34.345897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-27 17:09:34.345905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-06-27 17:09:34.345910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-06-27 17:09:34.346029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-27 17:09:34.346619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-27 17:09:34.347293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7784 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-06-27 17:09:35.539500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-27 17:09:35.696347: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-27 17:09:36.203198: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-06-27 17:09:36.209845: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-06-27 17:09:36.209897: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node my_model/conv2d/Conv2D}}]]
	 [[my_model/dense_1/BiasAdd/_6]]
2019-06-27 17:09:36.209959: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node my_model/conv2d/Conv2D}}]]
Traceback (most recent call last):
  File ""advanced.py"", line 84, in <module>
    train_step(images, labels)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 428, in __call__
    return self._stateless_fn(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 1335, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 589, in _filtered_call
    (t for t in nest.flatten((args, kwargs), expand_composites=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 671, in _call_flat
    outputs = self._inference_function.call(ctx, args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 445, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node my_model/conv2d/Conv2D (defined at advanced.py:36) ]]
  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node my_model/conv2d/Conv2D (defined at advanced.py:36) ]]
	 [[my_model/dense_1/BiasAdd/_6]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_step_848]

Errors may have originated from an input operation.
Input Source operations connected to node my_model/conv2d/Conv2D:
 images (defined at advanced.py:84)

Input Source operations connected to node my_model/conv2d/Conv2D:
 images (defined at advanced.py:84)

Function call stack:
train_step -> train_step

```

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30206,API link for r1.13 directs to r1.12 instead,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue: https://www.tensorflow.org/versions/r1.12/api_docs/python/tf

## Description of issue (what needs changing):

The link under API/r1.13 is pointing to r1.12.

The link should point to r1.13 https://www.tensorflow.org/versions/r1.13/api_docs/python/tf
"
30205,"installation fails ""FAILED: Build did NOT complete successfully""","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source 
- TensorFlow version: 1.13
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?:pip 
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: No CUDA support will be enabled for TensorFlow.
- GPU model and memory: 



**Describe the problem**
after I install Bazel and ./configure, I try to run 'bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package', then it gives me error information:

ERROR: /Users/Jianhua/tensorflow/tensorflow/lite/kernels/internal/BUILD:558:1: undeclared inclusion(s) in rule '//tensorflow/lite/kernels/internal:tensor_utils':
this rule is missing dependency declarations for the following files included by 'tensorflow/lite/kernels/internal/tensor_utils.cc':
  'tensorflow/lite/kernels/internal/optimized/sse_tensor_utils.h'
  'tensorflow/lite/kernels/internal/optimized/sse_tensor_utils_impl.h'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 571.490s, Critical Path: 54.09s
INFO: 673 processes: 673 local.
FAILED: Build did NOT complete successfully

**Provide the exact sequence of commands / steps that you executed before running into the problem**

git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow

./configure

bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached."
30204,keras.utils.vis_utils.plot_model() raises TypeError: 'InputLayer' object is not iterable,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.3
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0b1
- Python version: 3.6
- CUDA/cuDNN version: /
- GPU model and memory: GTX 940MX, 430.26

**Describe the current behavior**
Running `keras.utils.vis_utils.plot_model()` on a `tensorflow.python.keras.engine.training.Model` object raises `TypeError: 'InputLayer' object is not iterable`. This problem seems very similar to #24622, where the same issue was reported for Sequential objects.

**Describe the expected behavior**
Save a png image of the model.

**Code to reproduce the issue**
```
import tensorflow as tf
from keras.utils.vis_utils import plot_model

input_2D = tf.keras.Input(shape=(None, None, 3)) # unknown width and length, 3 channels (RGB)
network_2D = tf.keras.layers.Conv2D(
    filters = 128,  # dimensionality of output space
    kernel_size = 5,  # shape of 2D convolution window (5x5)
)(input_2D)

input_3D = tf.keras.Input(shape=(None, None, None, 1)) # unknown width, length and depth, 1 gray channel
network_3D = tf.keras.layers.Conv3D(
    filters = 128,  # dimensionality of output space
    kernel_size = 5,  # shape of 2D convolution window (5x5)
)(input_3D)

network_2D = tf.expand_dims(network_2D, axis=-2)
network_combined = network_2D + network_3D

model_combined = tf.keras.Model(inputs = [input_2D, input_3D], outputs = network_combined)
plot_model(model_combined, to_file='model_combined.png')
```

**Other info / logs**
```Traceback (most recent call last):
  File "".../repo/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3296, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-26-7a3e8204fbca>"", line 19, in <module>
    plot_model(model_combined, to_file='model_combined.png')
  File "".../repo/venv/lib/python3.6/site-packages/keras/utils/vis_utils.py"", line 132, in plot_model
    dot = model_to_dot(model, show_shapes, show_layer_names, rankdir)
  File "".../repo/venv/lib/python3.6/site-packages/keras/utils/vis_utils.py"", line 109, in model_to_dot
    for inbound_layer in node.inbound_layers:
TypeError: 'InputLayer' object is not iterable```
"
30203,Multiple output files for tf.data.experimental.TFRecordWriter,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.14
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
I have a `tf.data.Dataset` that I want to write to tfrecord files. to do this, I currently use `tf.python_io.TFRecordWriter` to do this, but would like to use `tf.data.experimental.TFRecordWriter`, as it would be more efficient to also do the writing as part of the dataset graph execution. The latter has one limitation, however, which stops me from using it. I need to split my dataset between a number of different shards (files). I could achieve this effect by using the shard method to split the dataset into a number of datasets before writing, but since I want to shuffle the dataset before writing it, this is too expensive.

Hence, I would like `tf.data.experimental.TFRecordWriter` to write a single dataset to multiple files.

**Will this change the current api? How?**
One could for instance change the signature to:
```python
tf.data.experimental.TFRecordWriter(
    file_pattern,  # string with format brackets for index, like 'train-shard-{}.tfrecord'
    num_shards=1,
    compression_type=None
)

```

**Who will benefit with this feature?**
Those of us who use tfrecord files as a storage format for our datasets and need options for writing such files efficiently and with flexibility.

**Any Other info.**
"
30201,Why not support LeakyRelu op for C++ Api?,"I try to import my pb file which use LeakyRelu as activation function in VS2015. I find I can't use ""sess->Create(&gdef)"" to import my pb. Error shows :
> Not found: Op type not registered 'LeakyRelu' in binary running on 9BFHO3E5CP3B44C. Make sure the Op and Kernel are registered in the binary running in this process."
30200,sys.version_info conditional for enum34 breaks poetry (and contaminates requires in general),"To prevent enum34 issues such as #15136 a `sys.version_info` conditional was added, as can be seen in the TF source [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py#L101)

As per [PEP508](https://www.python.org/dev/peps/pep-0508/#environment-markers) the recommended way is using environment markers.

Using the old `sys.version_info` method breaks tools such as poetry (see eg [issue 844](https://github.com/sdispater/poetry/issues/844), and the [owner's response](https://github.com/sdispater/poetry/issues/844#issuecomment-458178991))

Specifically this breaks some of our build pipelines that get the enum34 dependency information from PyPi, which is then put into site-packages, contaminating the build and leading to crashes in various interesting ways (eg if pip/python runs from site-packages, it will use enum34 which breaks when `enum.IntFlag` is accessed)

I'm hoping this can be fixed for TensorFlow too, see eg an example [here](https://github.com/confluentinc/confluent-kafka-python/pull/583/commits/4e6250d861c5be23fc45d8d11d2b8f0e8e218ab2)




"
30199,"Gradient returns ""Nan"" values when using triplet loss with similar batches","Hi, 

I am using tf 1.12.0. 
My issue is related to this [one](https://github.com/tensorflow/tensorflow/issues/783). 
It seems that it was closed judging it the benefit are marginal with respect to the effort.
I stumbled on this problem as I was working on my use case. I am not sure how common this is, but I think it deserves a second look. 

I am working on sequence representation learning, and when generating [my triplet loss batches](https://arxiv.org/abs/1703.07737), I end up sometime generating positives that are similar to my anchor. 
This causes the whole gradient to become ""Nan"".
![Screenshot from 2019-06-27 13-03-17](https://user-images.githubusercontent.com/38140485/60261705-d547f280-98dc-11e9-9e5d-e7b84348ff0a.png)

The suggested work around of replacing nan values with zeros post-computation isn't sufficient in this case because in reality not the whole batch gradient is null.
PS: I am generating the sequences randomly, however with relatively small vocabulary size and horizon, generating similar sequences does happen.

For those having the same issue, in my use case, the work around I opted for is to either condition my samples or add a small random noise. 

However I think implementing the discussed ""zero"" solution would be really helpful for future work on sequence representation learning. 

Thanks :) 


"
30198,freeze_graph freeze pb error,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30197,Resnet model Tensorflow facial landmarks (Detect in real time),"Hello,
I worked on a project (CNN facial landmarks [github project](https://github.com/yinguobing/cnn-facial-landmark). 
I set my own dataset and I trained to detect just the eye region.
My question is:
Did can this project ( Resnet Model ) support detection in real time?
If yes, How Tensorflow works to detect in real time?
Thanks"
30196,Signature Issue in Docker image,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Docker - Arch Linux 5.1.15-arch1
- TensorFlow installed from (source or binary): Through docker
- TensorFlow version (use command below): latest
- Python version: 3
- GPU model and memory: GTX 2080, 8 i think?

**Describe the current behavior**
When pulling the docker image `tensorflow/tensorflow:latest-gpu-py3` and running `apt-get update` some signatures fail to fetch and thus the build fails immediately

**Describe the expected behavior**
Should update apt issues

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
This was tested 27/06/2019:  

    cd `mktemp -d`
    echo ""FROM tensorflow/tensorflow:latest-gpu-py3"" > Dockerfile
    echo ""RUN apt-get update"" >> Dockerfile
    docker build .

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Terminal log: https://pastebin.com/EYzFE5wP
"
30195,make tf.image ops support tf.float16 in tensorflow 2.0,"make tf.image ops like tf.image.extract_patches/tf.image.resize to support tf.float16, or at least make them to do implicit cast."
30194,Word2vec only one GPU work (multiple gpu-based),"**I have done a multiple-gpu version word2vec, and I apply `log_device_placement` in the code  which displays some ops has been applied to multiple-gpu:**
```
2019-06-27 00:32:34.536178: I tensorflow/core/common_runtime/placer.cc:874] optimizer_7/gradients/loss_7/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:7
optimizer_6/gradients/loss_6/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:6
2019-06-27 00:32:34.536188: I tensorflow/core/common_runtime/placer.cc:874] optimizer_6/gradients/loss_6/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:6
optimizer_5/gradients/loss_5/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:5
2019-06-27 00:32:34.536202: I tensorflow/core/common_runtime/placer.cc:874] optimizer_5/gradients/loss_5/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:5
optimizer_4/gradients/loss_4/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:4
2019-06-27 00:32:34.536216: I tensorflow/core/common_runtime/placer.cc:874] optimizer_4/gradients/loss_4/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:4
optimizer_3/gradients/loss_3/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:3
2019-06-27 00:32:34.536231: I tensorflow/core/common_runtime/placer.cc:874] optimizer_3/gradients/loss_3/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:3
optimizer_2/gradients/loss_2/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:2
2019-06-27 00:32:34.536246: I tensorflow/core/common_runtime/placer.cc:874] optimizer_2/gradients/loss_2/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:2
optimizer_1/gradients/loss_1/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:1
2019-06-27 00:32:34.536273: I tensorflow/core/common_runtime/placer.cc:874] optimizer_1/gradients/loss_1/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:1
optimizer/gradients/loss/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0
2019-06-27 00:32:34.536288: I tensorflow/core/common_runtime/placer.cc:874] optimizer/gradients/loss/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:0
......
````
____________________________________________________________________
**But the `nvidia-smi` just shows only one gpu work at that time:**
```
`
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |
| 36%   49C    P2    80W / 250W |  10882MiB / 11178MiB |     26%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |
| 29%   39C    P2    56W / 250W |  10631MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 108...  Off  | 00000000:07:00.0 Off |                  N/A |
| 29%   36C    P2    54W / 250W |  10631MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |
| 29%   38C    P2    55W / 250W |  10631MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  GeForce GTX 108...  Off  | 00000000:0C:00.0 Off |                  N/A |
| 29%   38C    P2    55W / 250W |  10631MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  GeForce GTX 108...  Off  | 00000000:0D:00.0 Off |                  N/A |
| 29%   33C    P2    55W / 250W |  10631MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  GeForce GTX 108...  Off  | 00000000:0E:00.0 Off |                  N/A |
| 29%   37C    P2    55W / 250W |  10631MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  GeForce GTX 108...  Off  | 00000000:0F:00.0 Off |                  N/A |
| 29%   36C    P2    54W / 250W |  10663MiB / 11178MiB |      6%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     38130      C   python                                      8987MiB |
|    1     38130      C   python                                     10621MiB |
|    2     38130      C   python                                     10621MiB |
|    3     38130      C   python                                     10621MiB |
|    4     38130      C   python                                     10621MiB |
|    5     38130      C   python                                     10621MiB |
|    6     38130      C   python                                     10621MiB |
|    7     38130      C   python                                     10653MiB |
```
**I attach my source code here:**
```

...
with tf.name_scope('inputs'):
			train_inputs = tf.placeholder(tf.int32, shape=[batch_size])
			train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])
			
		
		upper = 4
		for i in range(0,upper):
			with tf.device(tf.DeviceSpec(device_type=""GPU"", device_index=i)):
				data_size = batch_size / upper
				data_size = int(data_size)
				print(data_size)
				_train_inputs = train_inputs[i * data_size : (i + 1) * data_size]
				_train_labels = train_labels[i * data_size : (i + 1) * data_size]

				
				with tf.name_scope('embeddings'):
					if prev_emb_model == '0': 
						embeddings = tf.Variable(
							tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
					else:
						add_on_emb = tf.random_uniform([vocabulary_size - len(emb), embedding_size], -1.0, 1.0)
						embeddings = tf.concat([emb, add_on_emb], 0)
					embed = tf.nn.embedding_lookup(embeddings, _train_inputs)

				# Construct the variables for the NCE loss
				with tf.name_scope('weights'):
					nce_weights = tf.Variable(
						tf.truncated_normal([vocabulary_size, embedding_size],
											stddev=1.0 / math.sqrt(embedding_size)))
				with tf.name_scope('biases'):
					nce_biases = tf.Variable(tf.zeros([vocabulary_size]))

					# Compute the average NCE loss for the batch.
				# tf.nce_loss automatically draws a new sample of the negative labels each
				# time we evaluate the loss.
				# Explanation of the meaning of NCE loss:
				#   http://mccormickml.com/2016/04/19/waord2vec-tutorial-the-skip-gram-model/
				
				# with tf.device(tf.DeviceSpec(device_type=""GPU"", device_index=0)):
				with tf.name_scope('loss'):
					loss = tf.reduce_mean(
						tf.nn.nce_loss(
							weights=nce_weights,
							biases=nce_biases,
							labels=_train_labels,
							inputs=embed,
							num_sampled=num_sampled,
							num_classes=vocabulary_size))


				# Construct the SGD optimizer using a learning rate of 1.0.
				with tf.name_scope('optimizer'):
					optimizer = tf.train.GradientDescentOptimizer(
						1.0).minimize(loss, colocate_gradients_with_ops=True)


		# Compute the cosine similarity between minibatch examples and all
		# embeddings.
		norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))
		normalized_embeddings = embeddings / norm

		# Add variable initializer.
		init = tf.global_variables_initializer()


	config = tf.ConfigProto(allow_soft_placement=True,log_device_placement=True)
	# config.gpu_options.allow_growth = True
	with tf.Session(graph=graph, config=config) as session:

		#  We must initialize all variables before we use them.
		init.run()
		print('Initialized')
		average_loss = 0

		walks_data = []
		for w in walks:
			for n in w: 
				walks_data.append(n)

		for step in range(args.iter):
			print(step)
			
			batch_inputs, batch_labels = generate_batch(batch_size, 1,
														window_size, walks_data)

			feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}


			_, loss_val = session.run([optimizer, loss],
												feed_dict=feed_dict,
												run_metadata=run_metadata)
			average_loss += loss_val

			if step % 2000 == 0:
			...

		final_embeddings = normalized_embeddings.eval()
```
"
30191,ERROR: Cannot uninstall 'wrapt'. during upgrade,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 19.04 on Sony notebook):
- TensorFlow version:
```
python
Python 3.6.3 |Anaconda, Inc.| (default, Oct 13 2017, 12:02:49) 
[GCC 7.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
/home/ronald/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
>>> print(tf.__version__)
2.0.0-alpha0
```

**Describe the problem**
I try to upgrade to beta1 with:
` install tensorflow==2.0.0-beta1
`
at the end I get:
```
Installing collected packages: wrapt, tensorflow
  Found existing installation: wrapt 1.10.11
ERROR: Cannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.

```
How to fix it?
"
30190,TF 2.0:  tf.GradientTape().gradient() returns None,"I designed my own loss function for my graduate research, it calculates the distance between the histogram of each loss in a batch and normal distribution. I am implementing this loss function in the setting of Tensorflow 2.0 [tutorial](https://www.tensorflow.org/beta/tutorials/eager/custom_training_walkthrough) about Iris flower classification.

I checked my loss value and type, they are same as the one in tutorial, but the `grads` from my `tape.gradient()` is `None`.

This is done in Google Colab with:

`TensorFlow version: 2.0.0-beta1`

`Eager execution: True`

My code block for loss and gradient:
```
def loss(model, x, y):
  y_ = model(x) # y_.shape is (batch_size, 3)
  losses = []
  for i in range(y.shape[0]):
    loss = loss_object(y_true=y[i], y_pred=y_[i])
    losses.append(float(loss))
  dis = get_distance_between_samples_and_distribution(losses, if_plot = 0)
  return tf.convert_to_tensor(dis, dtype=np.float32)

def grad(model, inputs, targets):
  with tf.GradientTape() as tape:
    loss_value = loss(model, inputs, targets)
    tape.watch(model.trainable_variables)
  return loss_value, tape.gradient(loss_value, model.trainable_variables)

loss_value, grads = grad(model, features, labels)
print(""loss_value:"",loss_value)
print(""type(loss_value):"", type(loss_value))
print(""grads:"", grads)
################################################# Output:
loss_value: tf.Tensor(0.21066944, shape=(), dtype=float32)
type(loss_value): <class 'tensorflow.python.framework.ops.EagerTensor'>
grads: [None, None, None, None, None, None]

```
The code in tutorial is:
```
loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

def loss(model, x, y):
  y_ = model(x)
  return loss_object(y_true=y, y_pred=y_)

def grad(model, inputs, targets):
  with tf.GradientTape() as tape:
    loss_value = loss(model, inputs, targets)
    tape.watch(model.trainable_variables)
  return loss_value, tape.gradient(loss_value, model.trainable_variables)

loss_value, grads = grad(model, features, labels)
print(""loss_value:"",loss_value)
print(""type(loss_value):"", type(loss_value))
print(""grads:"", grads)
################################################# Output:
loss_value: tf.Tensor(0.56536925, shape=(), dtype=float32)
type(loss_value): <class 'tensorflow.python.framework.ops.EagerTensor'>
grads: [<tf.Tensor: id=9962, shape=(4, 10), dtype=float32, numpy=
array([[ 0.0000000e+00,  6.5984917e-01,  3.0700830e-01, -7.5234145e-01,
      ......
```
I feel the calculation of my self defined loss should not matter since the data type and shape are same, but in case it does, here is my loss function:
```
def get_distance_between_samples_and_distribution(errors, if_plot = 1, n_bins = 5):
  def get_middle(x):
    xMid = np.zeros(x.shape[0]//2)
    for i in range(xMid.shape[0]):
      xMid[i] = 0.5*(x[2*i]+x[2*i+1])
    return xMid

  bins, edges = np.histogram(errors, n_bins, normed=1)
  left,right = edges[:-1],edges[1:]
  X = np.array([left,right]).T.flatten()
  Y = np.array([bins,bins]).T.flatten()
  X_middle = get_middle(X)
  Y_middle = get_middle(Y)
  distance = []
  for i in range(X_middle.shape[0]):
    dis = np.abs(scipy.stats.norm.pdf(X_middle[i])- Y_middle[i])
    distance.append(dis)
  distance2 = np.power(distance, 2)
  
  return sum(distance2)/len(distance2)
```
**I searched and tried adding `tape.watch()`, checking the indentation of my return as suggested in [issue #29942](https://github.com/tensorflow/tensorflow/issues/29942) but they did not fix this `None` problem. I will very appreciate any suggestion for fixing this. Thanks!**

The definition of class `tf.GradientTape` is [here](https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/eager/backprop.py) 
 "
30188,Different results with the same initial guess,"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow version: v1.14.0-rc1-22-gaf24dc91b5 1.14.0
- Python version: Python 3.6.8

I got different results with a same initial guess. I do not know if this is a bug or how it should be, but let me explain what I saw here since I did not get any answers from [my stack overflow post](https://stackoverflow.com/questions/56729256/tensorflow-completely-different-results-from-a-same-initial-guess). 

The following simple code is adapted from [here](https://databricks.com/tensorflow/training-and-convergence). 
```
import os
os.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""
os.environ[""CUDA_VISIBLE_DEVICES""]=""-1""
import tensorflow as tf
import numpy as np

x = tf.placeholder(""float"")
y = tf.placeholder(""float"")
w = tf.Variable([1.0, 2.0], name=""w"")

y_model = tf.multiply(x, w[0]) + w[1]
error = tf.square(y - y_model)
train_op = tf.train.GradientDescentOptimizer(0.01).minimize(error)

model = tf.global_variables_initializer()

with tf.Session() as session:
    session.run(model)
    print(""Initial guess: "", session.run(w))
    np.random.seed(seed=100)
    for i in range(1000):
        x_value = np.random.rand()
        y_value = x_value * 2 + 6
        session.run(train_op, feed_dict={x: x_value, y: y_value})

    w_value = session.run(w)
    print(""Predicted model: {a:.3f}x + {b:.3f}"".format(a=w_value[0], b=w_value[1]))
```

From the code, I got `Predicted model: 2.221x + 5.882`. However, when I replaced `w` with

```
w_norm = tf.Variable([0.5, 1.0], name = 'w_norm')
w = w_norm*2.0
```
the result was `Predicted model: 2.004x + 5.998` even though it has same initial guess (`[1. 2.]`) and same number of epochs. I wonder that makes this difference. "
30187,Internal error has occurred when executing Firebase ML tasks fails on tensor allocation,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Same error across OnePlus 6 (28) and Sony Xperia (21)
- TensorFlow installed from (source or binary): MLKit for Firebase 
- TensorFlow version (use command below): 'com.google.firebase:firebase-ml-model-interpreter:20.0.0'

Hi there folks, I've been setting up a Firebase MLKit project on Android to perform just simple image classification using a mobilenet model. I have been following the official guide given [here](https://firebase.google.com/docs/ml-kit/android/use-custom-models) for using a custom TF lite model which I have both locally in the android assets folder of my project and also hosted on a test firebase app as 'mobilenet'. The code gets a bitmap from the camera intent and then passes that to the run inference method where I have setup everything as per the guide. However, when it finally begins to run inference it throws an internal firebase ml error as well as some other bits in the stack trace.

The expected behaviour would be that it does indeed run the inference method and successfully prints a joyous ""IT WORKED!!!"". 

Here is my main activity kotilin file:
`package com.example.tflite

import android.content.Intent
import android.graphics.Bitmap
import android.graphics.Color
import androidx.appcompat.app.AppCompatActivity
import android.os.Bundle
import android.provider.MediaStore
import android.util.Log
import android.view.View
import android.widget.ImageView
import android.widget.TextView
import android.widget.Toast
import com.google.firebase.ml.common.FirebaseMLException
import com.google.firebase.ml.common.modeldownload.FirebaseLocalModel
import com.google.firebase.ml.common.modeldownload.FirebaseModelDownloadConditions
import com.google.firebase.ml.common.modeldownload.FirebaseModelManager
import com.google.firebase.ml.common.modeldownload.FirebaseRemoteModel
import com.google.firebase.ml.custom.*

class MainActivity : AppCompatActivity() {

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)
    }

    fun onPressAddImage(view: View) {
        // Dispatch an intent to the media store of the device to capture
        // an image with the requestCode id '1'
        Intent(MediaStore.ACTION_IMAGE_CAPTURE).also { takePictureIntent ->
            takePictureIntent.resolveActivity(packageManager)?.also {
                startActivityForResult(takePictureIntent, 1)
            }
        }
    }

    override fun onActivityResult(requestCode: Int, resultCode: Int, data: Intent?) {
        // Override the MainActivity function to check when a result is returned
        // from any intent - if the requestCode matches then draw the resulting
        // bitmap to the image view
        if (requestCode == 1 && resultCode == RESULT_OK) {
            val imageBitmap = data?.extras?.get(""data"") as Bitmap
            val imageView = findViewById<ImageView>(R.id.imageResult)
            imageView.setImageBitmap(imageBitmap)
            // Pass the bitmap result to the inference method
            runInference(imageBitmap)
        }
    }

    private fun runInference(bitmap: Bitmap) {
        // Scale the bitmap to the input size of the interpreter
        val scaledBitmap = Bitmap.createScaledBitmap(bitmap, 224, 224, true)
        // Create the input tensor of the image for the network
        val batchNum = 0
        val input = Array(1) { Array(224) { Array(224) { FloatArray(3) } } }
        for (x in 0..223) {
            for (y in 0..223) {
                val pixel = scaledBitmap.getPixel(x, y)
                // Normalize channel values to [-1.0, 1.0]. This requirement varies by
                // model. For example, some models might require values to be normalized
                // to the range [0.0, 1.0] instead.
                input[batchNum][x][y][0] = ((Color.red(pixel) - 127) / 255.0f)
                input[batchNum][x][y][1] = ((Color.green(pixel) - 127) / 255.0f)
                input[batchNum][x][y][2] = ((Color.blue(pixel) - 127) / 255.0f)
            }
        }
        // Define the Model download options before we attempt to e.g. that the device is charging and idle
        val conditionsBuilder = FirebaseModelDownloadConditions.Builder().requireWifi()
        val conditions = conditionsBuilder.build()
        // Build a remote model object by specifying the name you assigned the model
        // when you uploaded it in the Firebase console.
        val cloudSource = FirebaseRemoteModel.Builder(""mobilenet"")
            .enableModelUpdates(true)
            .setInitialDownloadConditions(conditions)
            .setUpdatesDownloadConditions(conditions)
            .build()

        // Register the local model too as a fall back in case the latest cannot be registered from Firebase
        val localSource = FirebaseLocalModel.Builder(""mobilenet"") 
            .setAssetFilePath(""mobilenet_float_v2_1.0_299.tflite"")
            .build()

        val manager = FirebaseModelManager.getInstance()
        manager.registerLocalModel(localSource)
        manager.registerRemoteModel(cloudSource)

        // Create the interpreter
        val options = FirebaseModelOptions.Builder()
            .setRemoteModelName(""mobilenet"")
            .setLocalModelName(""mobilenet"")
            .build()

        val interpreter = FirebaseModelInterpreter.getInstance(options)

        val textView = findViewById<TextView>(R.id.textView).apply {
            text = ""loaded""
        }

        manager.downloadRemoteModelIfNeeded(cloudSource)
            .addOnCompleteListener { task ->
                if (task.isSuccessful) {
                    Toast.makeText(
                        this,
                        ""Download remote AutoML model success."",
                        Toast.LENGTH_SHORT
                    )
                        .show()
                } else {
                    val downloadingError =
                        ""Error downloading remote model.""
                    Toast.makeText(this, downloadingError, Toast.LENGTH_SHORT).show()
                }
            }
        // Set the inputs and outputs of the interpreter
        // Set the input and output options of the model
        val interpreterOpts = FirebaseModelInputOutputOptions.Builder()
            .setInputFormat(0, FirebaseModelDataType.FLOAT32, intArrayOf(1, 224, 224, 3))
            .setOutputFormat(0, FirebaseModelDataType.FLOAT32, intArrayOf(1, 1001))
            .build()
        // Add the input to the interpreter and run inference
        val inputs = FirebaseModelInputs.Builder()
            .add(input) // add() as many input arrays as your model requires
            .build()
        interpreter!!.run(inputs, interpreterOpts)
            .addOnSuccessListener { result ->
                val output = result.getOutput<Array<IntArray>>(0)
                val probabilities = output[0]
                val textView = findViewById<TextView>(R.id.textView).apply {
                    text = ""IT WORKED!!!""
                }

            }
            .addOnFailureListener { e ->
                Log.e(""TFLite"", ""Failed: ${e.message}"")
                e.printStackTrace()
            }
    }
}
`

And here is the logcat output from android studio:

`E/TFLite: Failed: Internal error has occurred when executing Firebase ML tasks
W/System.err: com.google.firebase.ml.common.FirebaseMLException: Internal error has occurred when executing Firebase ML tasks
        at com.google.android.gms.internal.firebase_ml.zznn.zza(Unknown Source:36)
        at com.google.android.gms.internal.firebase_ml.zznq.run(Unknown Source:2)
W/System.err:     at android.os.Handler.handleCallback(Handler.java:873)
        at android.os.Handler.dispatchMessage(Handler.java:99)
        at com.google.android.gms.internal.firebase_ml.zzf.dispatchMessage(Unknown Source:6)
        at android.os.Looper.loop(Looper.java:193)
        at android.os.HandlerThread.run(HandlerThread.java:65)
    Caused by: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: Invalid begin and size.Node number 0 (SLICE) failed to prepare.
        at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:136)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:250)
        at com.google.android.gms.internal.firebase_ml.zzpz.runForMultipleInputsOutputs(Unknown Source:4)
        at com.google.android.gms.internal.firebase_ml.zzpr.zza(Unknown Source:85)
        at com.google.android.gms.internal.firebase_ml.zzpr.zza(Unknown Source:125)
        at com.google.android.gms.internal.firebase_ml.zznt.call(Unknown Source:4)
        at com.google.android.gms.internal.firebase_ml.zznn.zza(Unknown Source:30)
    	... 6 more
`

In particular it seems to be failing when allocating the tensors and so could possibly be a memory allocation issue, but not entirely sure:

`Caused by: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: Invalid begin and size.Node number 0 (SLICE) failed to prepare.`

Any help on how to get around this issue would be great and I can't simply use the prebuilt APIs as this is a test for building a custom semantic segmentation model on.

"
30185,Issue facing while converting frozen.pb to xyz.tflite,"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, LESS, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, RANGE, RESHAPE, RESIZE_BILINEAR, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, TILE, TOPK_V2, TRANSPOSE, UNPACK, WHERE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: Enter, Exit, LoopCond, Merge, NonMaxSuppressionV2, Switch, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.


After the above issue, I have added 
    --enable_select_tf_ops \
    --allow_custom_ops
to the script, which I'm using for the conversion of the inference model to TensorFlow lite model. Now my script looks something like this:

tflite_convert \
    --output_file=""frozen_inference_graph.tflite"" \
    --graph_def_file=""frozen_inference_graph.pb"" \
    --input_arrays=""add/y"" \
    --output_arrays=""Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond/Gather"" \
    --enable_select_tf_ops \
    --allow_custom_ops
but after compilif for some time, I again face the error :

2019-06-26 23:09:54.496040: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 6004 nodes (0), 10038 edges (0), time = 567.948ms.
Traceback (most recent call last):
  File ""/usr/local/bin/tflite_convert"", line 10, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/tflite_convert.py"", line 503, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.7/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.7/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/tflite_convert.py"", line 499, in run_main
    _convert_tf1_model(tflite_flags)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/tflite_convert.py"", line 193, in _convert_tf1_model
    output_data = converter.convert()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py"", line 898, in convert
    **converter_kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py"", line 404, in toco_convert_impl
    input_data.SerializeToString())
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py"", line 172, in toco_convert_protos
    ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.
2019-06-26 23:13:47.335610: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.357310: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.358330: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.358381: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3
2019-06-26 23:13:47.358423: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.358456: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3
2019-06-26 23:13:47.358487: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.358518: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3
2019-06-26 23:13:47.358547: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.358580: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.358608: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.358634: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.358667: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.358695: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.358722: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.358757: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.358785: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.358812: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3
2019-06-26 23:13:47.358843: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond
2019-06-26 23:13:47.358881: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.358931: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit
2019-06-26 23:13:47.358966: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit
2019-06-26 23:13:47.359031: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3
2019-06-26 23:13:47.359064: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3
2019-06-26 23:13:47.359114: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3
2019-06-26 23:13:47.359149: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3
2019-06-26 23:13:47.359214: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3
2019-06-26 23:13:47.359251: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3
2019-06-26 23:13:47.359303: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3
2019-06-26 23:13:47.362112: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.362167: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3
2019-06-26 23:13:47.362200: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.362232: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3
2019-06-26 23:13:47.362262: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.362293: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3
2019-06-26 23:13:47.362322: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.362353: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3
2019-06-26 23:13:47.362381: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.362412: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3
2019-06-26 23:13:47.362440: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.362469: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3
2019-06-26 23:13:47.362501: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.362531: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3
2019-06-26 23:13:47.362559: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.362588: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3
2019-06-26 23:13:47.362616: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.362655: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.362683: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.362710: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.362742: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.362769: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.362795: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.362827: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.362855: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.362880: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.362912: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.362941: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.362967: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.363000: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.363026: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.363052: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.363090: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.363117: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3
2019-06-26 23:13:47.363150: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.363177: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.363204: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3
2019-06-26 23:13:47.363236: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.363263: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2019-06-26 23:13:47.363289: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3
2019-06-26 23:13:47.363324: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond
2019-06-26 23:13:47.363368: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.363400: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.363432: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.371058: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3
2019-06-26 23:13:47.371160: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3
2019-06-26 23:13:47.371197: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3
2019-06-26 23:13:47.371837: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3
2019-06-26 23:13:47.371872: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter
2019-06-26 23:13:47.371907: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3
2019-06-26 23:13:47.384637: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.384730: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.384764: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.384797: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.384829: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.384861: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.384893: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.384924: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.384955: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.384986: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385017: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385048: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385080: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385111: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385142: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385173: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385205: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385237: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385268: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385299: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385330: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385361: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385392: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385424: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385455: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385487: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385518: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385549: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385581: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385613: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385644: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385675: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385705: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385737: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385768: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385800: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385831: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385863: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385894: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385925: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385956: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.385987: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386017: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386049: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386080: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386111: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386142: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386173: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386204: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386235: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386266: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386298: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386328: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386360: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386389: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386420: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386451: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386483: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386514: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386545: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386577: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386608: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386639: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386671: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386703: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386734: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386766: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386796: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386827: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386858: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386889: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386920: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386952: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.386983: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387014: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387045: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387091: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387124: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387156: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387188: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387220: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387251: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387283: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387315: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387347: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387378: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387409: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387441: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387472: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.387505: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2
2019-06-26 23:13:47.388923: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size
2019-06-26 23:13:47.389200: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3
2019-06-26 23:13:47.389914: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3
2019-06-26 23:13:47.389951: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3
2019-06-26 23:13:47.389984: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3
2019-06-26 23:13:48.210704: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 4228 operators, 6935 arrays (0 quantized)
2019-06-26 23:13:49.585661: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 3930 operators, 6444 arrays (0 quantized)
2019-06-26 23:13:51.136723: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 3930 operators, 6444 arrays (0 quantized)
2019-06-26 23:13:52.257715: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 3619 operators, 6018 arrays (0 quantized)
2019-06-26 23:13:53.340484: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 3619 operators, 6018 arrays (0 quantized)
2019-06-26 23:13:54.216385: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 3619 operators, 6018 arrays (0 quantized)
2019-06-26 23:13:54.884514: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 256 bytes, theoretical optimal value: 256 bytes.
2019-06-26 23:13:55.190611: E tensorflow/lite/toco/toco_tooling.cc:456] TensorFlow Lite currently doesn't support control flow ops: Enter, Exit, Merge, Switch.
Traceback (most recent call last):
  File ""/usr/local/bin/toco_from_protos"", line 10, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 59, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.7/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.7/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 33, in execute
    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)
Exception: TensorFlow Lite currently doesn't support control flow ops: Enter, Exit, Merge, Switch.

Please help in solving this issue. "
30184,tensorflow.__dict__ and __doc__ had changed after update to 1.14,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):conda-forge
- TensorFlow version (use command below):1.14.0
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

`tensorflow.__dict__` prints out 
```python
{
'_dw_wrapped_module': <module 'tensorflow' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow/lib/python3.6/site-packages/tensorflow/__init__.py'>,
'_dw_module_name': '',
'_dw_deprecated_printed': set(),
'_dw_warning_count': 0,
'__name__': 'tensorflow',
'__doc__': None,
'__package__': None,
'__loader__': None,
'__spec__': None
}
```
and `tensorflow.__doc__` does not print anything.

**Describe the expected behavior**

In 1.13, `__dict__` had a mapping of every tensorflow functions and `__doc__` had printed out `'Bring in all of the public TensorFlow interface into this module.'`

The full log for printing `__dict__` can be seen as below
```
WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

{'__name__': 'tensorflow', '__doc__': 'Bring in all of the public TensorFlow interface into this module.', '__package__': 'tensorflow', '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x7fa13cbef2b0>, '__spec__': ModuleSpec(name='tensorflow', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7fa13cbef2b0>, origin='/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/__init__.py', submodule_search_locations=['/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow']), '__path__': ['/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/api', '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow', '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1'], '__file__': '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/__init__.py', '__cached__': '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/__pycache__/__init__.cpython-36.pyc', '__builtins__': {'__name__': 'builtins', '__doc__': ""Built-in functions, exceptions, and other objects.\n\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices."", '__package__': '', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>), '__build_class__': <built-in function __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in function abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii': <built-in function ascii>, 'bin': <built-in function bin>, 'callable': <built-in function callable>, 'chr': <built-in function chr>, 'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir': <built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function eval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr': <built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in function hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id': <built-in function id>, 'input': <built-in function input>, 'isinstance': <built-in function isinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>, 'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function max>, 'min': <built-in function min>, 'next': <built-in function next>, 'oct': <built-in function oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print': <built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function round>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum': <built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis, 'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>, 'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>, 'classmethod': <class 'classmethod'>, 'complex': <class 'complex'>, 'dict': <class 'dict'>, 'enumerate': <class 'enumerate'>, 'filter': <class 'filter'>, 'float': <class 'float'>, 'frozenset': <class 'frozenset'>, 'property': <class 'property'>, 'int': <class 'int'>, 'list': <class 'list'>, 'map': <class 'map'>, 'object': <class 'object'>, 'range': <class 'range'>, 'reversed': <class 'reversed'>, 'set': <class 'set'>, 'slice': <class 'slice'>, 'staticmethod': <class 'staticmethod'>, 'str': <class 'str'>, 'super': <class 'super'>, 'tuple': <class 'tuple'>, 'type': <class 'type'>, 'zip': <class 'zip'>, '__debug__': True, 'BaseException': <class 'BaseException'>, 'Exception': <class 'Exception'>, 'TypeError': <class 'TypeError'>, 'StopAsyncIteration': <class 'StopAsyncIteration'>, 'StopIteration': <class 'StopIteration'>, 'GeneratorExit': <class 'GeneratorExit'>, 'SystemExit': <class 'SystemExit'>, 'KeyboardInterrupt': <class 'KeyboardInterrupt'>, 'ImportError': <class 'ImportError'>, 'ModuleNotFoundError': <class 'ModuleNotFoundError'>, 'OSError': <class 'OSError'>, 'EnvironmentError': <class 'OSError'>, 'IOError': <class 'OSError'>, 'EOFError': <class 'EOFError'>, 'RuntimeError': <class 'RuntimeError'>, 'RecursionError': <class 'RecursionError'>, 'NotImplementedError': <class 'NotImplementedError'>, 'NameError': <class 'NameError'>, 'UnboundLocalError': <class 'UnboundLocalError'>, 'AttributeError': <class 'AttributeError'>, 'SyntaxError': <class 'SyntaxError'>, 'IndentationError': <class 'IndentationError'>, 'TabError': <class 'TabError'>, 'LookupError': <class 'LookupError'>, 'IndexError': <class 'IndexError'>, 'KeyError': <class 'KeyError'>, 'ValueError': <class 'ValueError'>, 'UnicodeError': <class 'UnicodeError'>, 'UnicodeEncodeError': <class 'UnicodeEncodeError'>, 'UnicodeDecodeError': <class 'UnicodeDecodeError'>, 'UnicodeTranslateError': <class 'UnicodeTranslateError'>, 'AssertionError': <class 'AssertionError'>, 'ArithmeticError': <class 'ArithmeticError'>, 'FloatingPointError': <class 'FloatingPointError'>, 'OverflowError': <class 'OverflowError'>, 'ZeroDivisionError': <class 'ZeroDivisionError'>, 'SystemError': <class 'SystemError'>, 'ReferenceError': <class 'ReferenceError'>, 'BufferError': <class 'BufferError'>, 'MemoryError': <class 'MemoryError'>, 'Warning': <class 'Warning'>, 'UserWarning': <class 'UserWarning'>, 'DeprecationWarning': <class 'DeprecationWarning'>, 'PendingDeprecationWarning': <class 'PendingDeprecationWarning'>, 'SyntaxWarning': <class 'SyntaxWarning'>, 'RuntimeWarning': <class 'RuntimeWarning'>, 'FutureWarning': <class 'FutureWarning'>, 'ImportWarning': <class 'ImportWarning'>, 'UnicodeWarning': <class 'UnicodeWarning'>, 'BytesWarning': <class 'BytesWarning'>, 'ResourceWarning': <class 'ResourceWarning'>, 'ConnectionError': <class 'ConnectionError'>, 'BlockingIOError': <class 'BlockingIOError'>, 'BrokenPipeError': <class 'BrokenPipeError'>, 'ChildProcessError': <class 'ChildProcessError'>, 'ConnectionAbortedError': <class 'ConnectionAbortedError'>, 'ConnectionRefusedError': <class 'ConnectionRefusedError'>, 'ConnectionResetError': <class 'ConnectionResetError'>, 'FileExistsError': <class 'FileExistsError'>, 'FileNotFoundError': <class 'FileNotFoundError'>, 'IsADirectoryError': <class 'IsADirectoryError'>, 'NotADirectoryError': <class 'NotADirectoryError'>, 'InterruptedError': <class 'InterruptedError'>, 'PermissionError': <class 'PermissionError'>, 'ProcessLookupError': <class 'ProcessLookupError'>, 'TimeoutError': <class 'TimeoutError'>, 'open': <built-in function open>, 'quit': Use quit() or Ctrl-D (i.e. EOF) to exit, 'exit': Use exit() or Ctrl-D (i.e. EOF) to exit, 'copyright': Copyright (c) 2001-2018 Python Software Foundation.
All Rights Reserved.

Copyright (c) 2000 BeOpen.com.
All Rights Reserved.

Copyright (c) 1995-2001 Corporation for National Research Initiatives.
All Rights Reserved.

Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.
All Rights Reserved., 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands
    for supporting Python development.  See www.python.org for more information., 'license': Type license() to see the full license text, 'help': Type help() for interactive help, or help(object) for help about object., '_': None}, '_absolute_import': _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0), 16384), '_division': _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192), '_print_function': _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 65536), '_os': <module 'os' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/os.py'>, 'tools': <module 'tensorflow.tools' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/tools/__init__.py'>, 'pywrap_tensorflow': <module 'tensorflow.python.pywrap_tensorflow' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py'>, '_api': <module 'tensorflow._api' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/__init__.py'>, 'app': <module 'tensorflow._api.v1.app' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/app/__init__.py'>, 'autograph': <module 'tensorflow._api.v1.autograph' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/autograph/__init__.py'>, 'bitwise': <module 'tensorflow._api.v1.bitwise' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/bitwise/__init__.py'>, 'lite': <module 'tensorflow._api.v1.lite' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/lite/__init__.py'>, 'compat': <module 'tensorflow._api.v1.compat' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/compat/__init__.py'>, 'data': <module 'tensorflow._api.v1.data' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/data/__init__.py'>, 'debugging': <module 'tensorflow._api.v1.debugging' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/debugging/__init__.py'>, 'distribute': <module 'tensorflow._api.v1.distribute' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/distribute/__init__.py'>, 'distributions': <module 'tensorflow._api.v1.distributions' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/distributions/__init__.py'>, 'dtypes': <module 'tensorflow._api.v1.dtypes' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/dtypes/__init__.py'>, 'errors': <module 'tensorflow._api.v1.errors' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/errors/__init__.py'>, 'experimental': <module 'tensorflow._api.v1.experimental' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/experimental/__init__.py'>, 'feature_column': <module 'tensorflow._api.v1.feature_column' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/feature_column/__init__.py'>, 'gfile': <module 'tensorflow._api.v1.gfile' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/gfile/__init__.py'>, 'graph_util': <module 'tensorflow._api.v1.graph_util' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/graph_util/__init__.py'>, 'image': <module 'tensorflow._api.v1.image' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/image/__init__.py'>, 'initializers': <module 'tensorflow._api.v1.initializers' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/initializers/__init__.py'>, 'io': <module 'tensorflow._api.v1.io' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/io/__init__.py'>, 'keras': <module 'tensorflow._api.v1.keras' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/keras/__init__.py'>, 'layers': <module 'tensorflow._api.v1.layers' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/layers/__init__.py'>, 'linalg': <module 'tensorflow._api.v1.linalg' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/linalg/__init__.py'>, 'logging': <module 'tensorflow._api.v1.logging' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/logging/__init__.py'>, 'losses': <module 'tensorflow._api.v1.losses' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/losses/__init__.py'>, 'manip': <module 'tensorflow._api.v1.manip' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/manip/__init__.py'>, 'math': <module 'tensorflow._api.v1.math' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/math/__init__.py'>, 'metrics': <module 'tensorflow._api.v1.metrics' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/metrics/__init__.py'>, 'nn': <module 'tensorflow._api.v1.nn' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/nn/__init__.py'>, 'profiler': <module 'tensorflow._api.v1.profiler' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/profiler/__init__.py'>, 'python_io': <module 'tensorflow._api.v1.python_io' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/python_io/__init__.py'>, 'quantization': <module 'tensorflow._api.v1.quantization' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/quantization/__init__.py'>, 'queue': <module 'tensorflow._api.v1.queue' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/queue/__init__.py'>, 'ragged': <module 'tensorflow._api.v1.ragged' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/ragged/__init__.py'>, 'random': <module 'tensorflow._api.v1.random' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/random/__init__.py'>, 'resource_loader': <module 'tensorflow._api.v1.resource_loader' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/resource_loader/__init__.py'>, 'saved_model': <module 'tensorflow._api.v1.saved_model' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/saved_model/__init__.py'>, 'sets': <module 'tensorflow._api.v1.sets' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/sets/__init__.py'>, 'signal': <module 'tensorflow._api.v1.signal' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/signal/__init__.py'>, 'sparse': <module 'tensorflow._api.v1.sparse' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/sparse/__init__.py'>, 'spectral': <module 'tensorflow._api.v1.spectral' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/spectral/__init__.py'>, 'strings': <module 'tensorflow._api.v1.strings' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/strings/__init__.py'>, 'summary': <module 'tensorflow._api.v1.summary' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/summary/__init__.py'>, 'sysconfig': <module 'tensorflow._api.v1.sysconfig' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/sysconfig/__init__.py'>, 'test': <module 'tensorflow._api.v1.test' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/test/__init__.py'>, 'train': <module 'tensorflow._api.v1.train' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/train/__init__.py'>, 'user_ops': <module 'tensorflow._api.v1.user_ops' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/user_ops/__init__.py'>, 'version': <module 'tensorflow._api.v1.version' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/version/__init__.py'>, 'import_graph_def': <function import_graph_def at 0x7fa125a6a6a8>, 'AggregationMethod': <class 'tensorflow.python.ops.gradients_impl.AggregationMethod'>, 'Assert': <function should_use_result.<locals>.wrapped at 0x7fa125b9ca60>, 'AttrValue': <class 'tensorflow.core.framework.attr_value_pb2.AttrValue'>, 'ConditionalAccumulator': <class 'tensorflow.python.ops.data_flow_ops.ConditionalAccumulator'>, 'ConditionalAccumulatorBase': <class 'tensorflow.python.ops.data_flow_ops.ConditionalAccumulatorBase'>, 'ConfigProto': <class 'tensorflow.core.protobuf.config_pb2.ConfigProto'>, 'constant_initializer': <class 'tensorflow.python.ops.init_ops.Constant'>, 'DType': <class 'tensorflow.python.framework.dtypes.DType'>, 'DeviceSpec': <class 'tensorflow.python.framework.device.DeviceSpec'>, 'Dimension': <class 'tensorflow.python.framework.tensor_shape.Dimension'>, 'Event': <class 'tensorflow.core.util.event_pb2.Event'>, 'FIFOQueue': <class 'tensorflow.python.ops.data_flow_ops.FIFOQueue'>, 'FixedLenFeature': <class 'tensorflow.python.ops.parsing_ops.FixedLenFeature'>, 'FixedLenSequenceFeature': <class 'tensorflow.python.ops.parsing_ops.FixedLenSequenceFeature'>, 'FixedLengthRecordReader': <class 'tensorflow.python.ops.io_ops.FixedLengthRecordReader'>, 'GPUOptions': <class 'tensorflow.core.protobuf.config_pb2.GPUOptions'>, 'glorot_normal_initializer': <class 'tensorflow.python.ops.init_ops.GlorotNormal'>, 'glorot_uniform_initializer': <class 'tensorflow.python.ops.init_ops.GlorotUniform'>, 'GradientTape': <class 'tensorflow.python.eager.backprop.GradientTape'>, 'Graph': <class 'tensorflow.python.framework.ops.Graph'>, 'GraphDef': <class 'tensorflow.core.framework.graph_pb2.GraphDef'>, 'GraphKeys': <class 'tensorflow.python.framework.ops.GraphKeys'>, 'GraphOptions': <class 'tensorflow.core.protobuf.config_pb2.GraphOptions'>, 'HistogramProto': <class 'tensorflow.core.framework.summary_pb2.HistogramProto'>, 'IdentityReader': <class 'tensorflow.python.ops.io_ops.IdentityReader'>, 'IndexedSlices': <class 'tensorflow.python.framework.ops.IndexedSlices'>, 'InteractiveSession': <class 'tensorflow.python.client.session.InteractiveSession'>, 'LMDBReader': <class 'tensorflow.python.ops.io_ops.LMDBReader'>, 'LogMessage': <class 'tensorflow.core.util.event_pb2.LogMessage'>, 'MetaGraphDef': <class 'tensorflow.core.protobuf.meta_graph_pb2.MetaGraphDef'>, 'NameAttrList': <class 'tensorflow.core.framework.attr_value_pb2.NameAttrList'>, 'NoGradient': <function no_gradient at 0x7fa1260ce598>, 'NotDifferentiable': <function no_gradient at 0x7fa1260ce598>, 'no_gradient': <function no_gradient at 0x7fa1260ce598>, 'NodeDef': <class 'tensorflow.core.framework.node_def_pb2.NodeDef'>, 'ones_initializer': <class 'tensorflow.python.ops.init_ops.Ones'>, 'OpError': <class 'tensorflow.python.framework.errors_impl.OpError'>, 'Operation': <class 'tensorflow.python.framework.ops.Operation'>, 'OptimizerOptions': <class 'tensorflow.core.protobuf.config_pb2.OptimizerOptions'>, 'orthogonal_initializer': <class 'tensorflow.python.ops.init_ops.Orthogonal'>, 'PaddingFIFOQueue': <class 'tensorflow.python.ops.data_flow_ops.PaddingFIFOQueue'>, 'Print': <function Print at 0x7fa1253662f0>, 'PriorityQueue': <class 'tensorflow.python.ops.data_flow_ops.PriorityQueue'>, 'QueueBase': <class 'tensorflow.python.ops.data_flow_ops.QueueBase'>, 'random_normal_initializer': <class 'tensorflow.python.ops.init_ops.RandomNormal'>, 'RandomShuffleQueue': <class 'tensorflow.python.ops.data_flow_ops.RandomShuffleQueue'>, 'random_uniform_initializer': <class 'tensorflow.python.ops.init_ops.RandomUniform'>, 'ReaderBase': <class 'tensorflow.python.ops.io_ops.ReaderBase'>, 'RegisterGradient': <class 'tensorflow.python.framework.ops.RegisterGradient'>, 'RunMetadata': <class 'tensorflow.core.protobuf.config_pb2.RunMetadata'>, 'RunOptions': <class 'tensorflow.core.protobuf.config_pb2.RunOptions'>, 'Session': <class 'tensorflow.python.client.session.Session'>, 'SessionLog': <class 'tensorflow.core.util.event_pb2.SessionLog'>, 'SparseConditionalAccumulator': <class 'tensorflow.python.ops.data_flow_ops.SparseConditionalAccumulator'>, 'SparseFeature': <class 'tensorflow.python.ops.parsing_ops.SparseFeature'>, 'SparseTensor': <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>, 'SparseTensorValue': <class 'tensorflow.python.framework.sparse_tensor.SparseTensorValue'>, 'Summary': <class 'tensorflow.core.framework.summary_pb2.Summary'>, 'SummaryMetadata': <class 'tensorflow.core.framework.summary_pb2.SummaryMetadata'>, 'TFRecordReader': <class 'tensorflow.python.ops.io_ops.TFRecordReader'>, 'Tensor': <class 'tensorflow.python.framework.ops.Tensor'>, 'TensorArray': <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>, 'TensorInfo': <class 'tensorflow.core.protobuf.meta_graph_pb2.TensorInfo'>, 'TensorShape': <class 'tensorflow.python.framework.tensor_shape.TensorShapeV1'>, 'TextLineReader': <class 'tensorflow.python.ops.io_ops.TextLineReader'>, 'truncated_normal_initializer': <class 'tensorflow.python.ops.init_ops.TruncatedNormal'>, 'UnconnectedGradients': <enum 'UnconnectedGradients'>, 'uniform_unit_scaling_initializer': <class 'tensorflow.python.ops.init_ops.UniformUnitScaling'>, 'VarLenFeature': <class 'tensorflow.python.ops.parsing_ops.VarLenFeature'>, 'VariableAggregation': <enum 'VariableAggregation'>, 'VariableScope': <class 'tensorflow.python.ops.variable_scope.VariableScope'>, 'VariableSynchronization': <enum 'VariableSynchronization'>, 'Variable': <class 'tensorflow.python.ops.variables.VariableV1'>, 'variance_scaling_initializer': <class 'tensorflow.python.ops.init_ops.VarianceScaling'>, 'WholeFileReader': <class 'tensorflow.python.ops.io_ops.WholeFileReader'>, 'zeros_initializer': <class 'tensorflow.python.ops.init_ops.Zeros'>, 'abs': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c4ba60>, 'accumulate_n': <function accumulate_n at 0x7fa125c63bf8>, 'acos': <function acos at 0x7fa125e7e048>, 'acosh': <function acosh at 0x7fa125e7e158>, 'add': <function add at 0x7fa125e7e268>, 'add_check_numerics_ops': <function add_check_numerics_ops at 0x7fa1254ffc80>, 'add_n': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c63a60>, 'add_to_collection': <function add_to_collection at 0x7fa1260e0c80>, 'add_to_collections': <function add_to_collections at 0x7fa1260e0e18>, 'all_variables': <function all_variables at 0x7fa125af2d08>, 'angle': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c45ae8>, 'arg_max': <function arg_max at 0x7fa125c4b488>, 'arg_min': <function arg_min at 0x7fa125c4b620>, 'argmax': <function argmax at 0x7fa125c4b7b8>, 'argmin': <function argmin at 0x7fa125c4b9d8>, 'argsort': <function argsort at 0x7fa1250fc0d0>, 'as_dtype': <function as_dtype at 0x7fa1261dfc80>, 'as_string': <function as_string at 0x7fa12579b268>, 'asin': <function asin at 0x7fa125e7ebf8>, 'asinh': <function asinh at 0x7fa125e7ed08>, 'assert_equal': <function assert_equal at 0x7fa1257e1158>, 'assert_greater': <function assert_greater at 0x7fa1257e16a8>, 'assert_greater_equal': <function assert_greater_equal at 0x7fa1257e1840>, 'assert_integer': <function assert_integer at 0x7fa1257e1ea0>, 'assert_less': <function assert_less at 0x7fa1257e1488>, 'assert_less_equal': <function assert_less_equal at 0x7fa1257e1620>, 'assert_near': <function assert_near at 0x7fa1257e1400>, 'assert_negative': <function assert_negative at 0x7fa125847d08>, 'assert_non_negative': <function assert_non_negative at 0x7fa125847f28>, 'assert_non_positive': <function assert_non_positive at 0x7fa1257e10d0>, 'assert_none_equal': <function assert_none_equal at 0x7fa1257e12f0>, 'assert_positive': <function assert_positive at 0x7fa125847e18>, 'assert_proper_iterable': <function assert_proper_iterable at 0x7fa125847bf8>, 'assert_rank': <function assert_rank at 0x7fa1257e1950>, 'assert_rank_at_least': <function assert_rank_at_least at 0x7fa1257e1ae8>, 'assert_rank_in': <function assert_rank_in at 0x7fa1257e1d90>, 'assert_same_float_dtype': <function assert_same_float_dtype at 0x7fa1257e5378>, 'assert_scalar': <function assert_scalar at 0x7fa1257e5488>, 'assert_type': <function assert_type at 0x7fa1257e5048>, 'assert_variables_initialized': <function should_use_result.<locals>.wrapped at 0x7fa125af5840>, 'assign': <function assign at 0x7fa125bac378>, 'assign_add': <function assign_add at 0x7fa125bac2f0>, 'assign_sub': <function assign_sub at 0x7fa125bac268>, 'atan': <function atan at 0x7fa125e7ee18>, 'atan2': <function atan2 at 0x7fa125e7ef28>, 'atanh': <function atanh at 0x7fa125e7f0d0>, 'batch_gather': <function add_dispatch_support.<locals>.wrapper at 0x7fa125dc3048>, 'batch_to_space': <function batch_to_space at 0x7fa125e3e400>, 'batch_to_space_nd': <function batch_to_space_nd at 0x7fa125ef6598>, 'betainc': <function betainc at 0x7fa125e7f598>, 'bincount': <function bincount_v1 at 0x7fa125c63f28>, 'bitcast': <function bitcast at 0x7fa125ef6620>, 'boolean_mask': <function boolean_mask at 0x7fa125e33bf8>, 'broadcast_dynamic_shape': <function broadcast_dynamic_shape at 0x7fa125e2cb70>, 'broadcast_static_shape': <function broadcast_static_shape at 0x7fa125e2ce18>, 'broadcast_to': <function broadcast_to at 0x7fa125ef6d90>, 'case': <function case at 0x7fa125ba69d8>, 'cast': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c45c80>, 'ceil': <function ceil at 0x7fa125e7f9d8>, 'check_numerics': <function check_numerics at 0x7fa125ef6f28>, 'cholesky': <function cholesky at 0x7fa125ac8048>, 'cholesky_solve': <function cholesky_solve at 0x7fa1255446a8>, 'clip_by_average_norm': <function clip_by_average_norm at 0x7fa12550b158>, 'clip_by_global_norm': <function clip_by_global_norm at 0x7fa1254ffea0>, 'clip_by_norm': <function clip_by_norm at 0x7fa1254ffe18>, 'clip_by_value': <function add_dispatch_support.<locals>.wrapper at 0x7fa1254ffd08>, 'colocate_with': <function colocate_with at 0x7fa1260dd9d8>, 'complex': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c45730>, 'concat': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e33b70>, 'cond': <function cond at 0x7fa125ba50d0>, 'conj': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c6b048>, 'container': <function container at 0x7fa1260dd7b8>, 'control_dependencies': <function control_dependencies at 0x7fa1260dd8c8>, 'convert_to_tensor': <function convert_to_tensor at 0x7fa1260c8488>, 'convert_to_tensor_or_indexed_slices': <function convert_to_tensor_or_indexed_slices at 0x7fa1260c87b8>, 'convert_to_tensor_or_sparse_tensor': <function convert_to_tensor_or_sparse_tensor at 0x7fa1260521e0>, 'cos': <function cos at 0x7fa125e00048>, 'cosh': <function cosh at 0x7fa125e00158>, 'count_nonzero': <function count_nonzero at 0x7fa125c562f0>, 'count_up_to': <function count_up_to at 0x7fa125bac510>, 'create_partitioned_variables': <function create_partitioned_variables at 0x7fa125122d08>, 'cross': <function cross at 0x7fa125e002f0>, 'cumprod': <function cumprod at 0x7fa125c6b0d0>, 'cumsum': <function cumsum at 0x7fa125c63ea0>, 'custom_gradient': <function custom_gradient at 0x7fa125409488>, 'decode_base64': <function decode_base64 at 0x7fa12579b400>, 'decode_compressed': <function decode_compressed at 0x7fa1257f3620>, 'decode_csv': <function decode_csv at 0x7fa1253032f0>, 'decode_json_example': <function decode_json_example at 0x7fa1257f3730>, 'decode_raw': <function decode_raw at 0x7fa1257f3840>, 'delete_session_tensor': <function delete_session_tensor at 0x7fa125824a60>, 'depth_to_space': <function depth_to_space at 0x7fa125e3e378>, 'dequantize': <function dequantize at 0x7fa125efca60>, 'deserialize_many_sparse': <function deserialize_many_sparse at 0x7fa1256fa730>, 'device': <function device at 0x7fa1260ced90>, 'diag': <function diag at 0x7fa125efcb70>, 'diag_part': <function diag_part at 0x7fa125efcc80>, 'digamma': <function digamma at 0x7fa125e00620>, 'div': <function div at 0x7fa125c4aa60>, 'div_no_nan': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c4ab70>, 'divide': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c4be18>, 'dynamic_partition': <function dynamic_partition at 0x7fa125d72a60>, 'dynamic_stitch': <function dynamic_stitch at 0x7fa125d72b70>, 'edit_distance': <function edit_distance at 0x7fa125e35d90>, 'einsum': <function einsum at 0x7fa125369510>, 'enable_eager_execution': <function enable_eager_execution at 0x7fa1260e06a8>, 'encode_base64': <function encode_base64 at 0x7fa12579b510>, 'equal': <function equal at 0x7fa125e008c8>, 'erf': <function erf at 0x7fa125e00a60>, 'erfc': <function erfc at 0x7fa125e00b70>, 'executing_eagerly': <function executing_eagerly at 0x7fa1261c6598>, 'exp': <function exp at 0x7fa125e00bf8>, 'expand_dims': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e2c950>, 'expm1': <function expm1 at 0x7fa125e00d90>, 'extract_image_patches': <function extract_image_patches at 0x7fa125efd1e0>, 'extract_volume_patches': <function extract_volume_patches at 0x7fa125efd2f0>, 'eye': <function eye at 0x7fa125544620>, 'fake_quant_with_min_max_args': <function fake_quant_with_min_max_args at 0x7fa125efd488>, 'fake_quant_with_min_max_args_gradient': <function fake_quant_with_min_max_args_gradient at 0x7fa125efd598>, 'fake_quant_with_min_max_vars': <function fake_quant_with_min_max_vars at 0x7fa125efd6a8>, 'fake_quant_with_min_max_vars_gradient': <function fake_quant_with_min_max_vars_gradient at 0x7fa125efdae8>, 'fake_quant_with_min_max_vars_per_channel': <function fake_quant_with_min_max_vars_per_channel at 0x7fa125efdbf8>, 'fake_quant_with_min_max_vars_per_channel_gradient': <function fake_quant_with_min_max_vars_per_channel_gradient at 0x7fa125eff158>, 'fill': <function fill at 0x7fa125eff1e0>, 'fixed_size_partitioner': <function fixed_size_partitioner at 0x7fa125122b70>, 'floor': <function floor at 0x7fa125e00e18>, 'floor_div': <function floor_div at 0x7fa125e00f28>, 'floormod': <function floor_mod at 0x7fa125e010d0>, 'mod': <function floor_mod at 0x7fa125e010d0>, 'floordiv': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c4aae8>, 'foldl': <function foldl at 0x7fa12558d598>, 'foldr': <function foldr at 0x7fa125537840>, 'gather': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e3ed90>, 'gather_nd': <function gather_nd at 0x7fa125eff488>, 'get_collection': <function get_collection at 0x7fa1260e0f28>, 'get_collection_ref': <function get_collection_ref at 0x7fa1260e0ea0>, 'get_default_graph': <function get_default_graph at 0x7fa1260e0950>, 'get_default_session': <function get_default_session at 0x7fa1260ddf28>, 'get_local_variable': <function get_local_variable at 0x7fa125a64a60>, 'get_seed': <function get_seed at 0x7fa126052730>, 'get_session_handle': <function get_session_handle at 0x7fa1258242f0>, 'get_session_tensor': <function get_session_tensor at 0x7fa1258249d8>, 'get_variable': <function get_variable at 0x7fa125a646a8>, 'get_variable_scope': <function get_variable_scope at 0x7fa125a64488>, 'global_norm': <function global_norm at 0x7fa1254fff28>, 'global_variables': <function global_variables at 0x7fa125aeb950>, 'global_variables_initializer': <function global_variables_initializer at 0x7fa125af5268>, 'gradients': <function gradients at 0x7fa12531eea0>, 'greater': <function greater at 0x7fa125e011e0>, 'greater_equal': <function greater_equal at 0x7fa125e012f0>, 'group': <function group at 0x7fa125ba6620>, 'guarantee_const': <function guarantee_const at 0x7fa125eff620>, 'hessians': <function hessians at 0x7fa125323730>, 'histogram_fixed_width': <function histogram_fixed_width at 0x7fa1251b86a8>, 'histogram_fixed_width_bins': <function histogram_fixed_width_bins at 0x7fa1251b8620>, 'identity': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e2c598>, 'identity_n': <function identity_n at 0x7fa125eff840>, 'igamma': <function igamma at 0x7fa125e01598>, 'igammac': <function igammac at 0x7fa125e017b8>, 'imag': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c459d8>, 'initialize_all_tables': <function initialize_all_tables at 0x7fa12518dd08>, 'initialize_all_variables': <function should_use_result.<locals>.wrapped at 0x7fa125af52f0>, 'initialize_local_variables': <function should_use_result.<locals>.wrapped at 0x7fa125af5510>, 'initialize_variables': <function should_use_result.<locals>.wrapped at 0x7fa125af50d0>, 'invert_permutation': <function invert_permutation at 0x7fa125effe18>, 'is_finite': <function is_finite at 0x7fa125e01bf8>, 'is_inf': <function is_inf at 0x7fa125e01d08>, 'is_nan': <function is_nan at 0x7fa125e01e18>, 'is_non_decreasing': <function is_non_decreasing at 0x7fa1257e51e0>, 'is_numeric_tensor': <function is_numeric_tensor at 0x7fa1257e5158>, 'is_strictly_increasing': <function is_strictly_increasing at 0x7fa1257e5268>, 'is_variable_initialized': <function should_use_result.<locals>.wrapped at 0x7fa125af5730>, 'lbeta': <function lbeta at 0x7fa125369400>, 'less': <function less at 0x7fa125e01ea0>, 'less_equal': <function less_equal at 0x7fa125e03048>, 'lgamma': <function lgamma at 0x7fa125e031e0>, 'lin_space': <function lin_space at 0x7fa125e032f0>, 'linspace': <function lin_space at 0x7fa125e032f0>, 'load_file_system_library': <function load_file_system_library at 0x7fa125a931e0>, 'load_library': <function load_library at 0x7fa125a93268>, 'load_op_library': <function load_op_library at 0x7fa125a6a510>, 'local_variables': <function local_variables at 0x7fa125af2d90>, 'local_variables_initializer': <function local_variables_initializer at 0x7fa125af5488>, 'log': <function log at 0x7fa125e03400>, 'log1p': <function log1p at 0x7fa125e03510>, 'log_sigmoid': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c63d08>, 'logical_and': <function logical_and at 0x7fa125e03598>, 'logical_not': <function logical_not at 0x7fa125e036a8>, 'logical_or': <function logical_or at 0x7fa125e037b8>, 'logical_xor': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c40730>, 'make_ndarray': <function MakeNdarray at 0x7fa1260506a8>, 'make_template': <function make_template at 0x7fa1250fc840>, 'make_tensor_proto': <function make_tensor_proto at 0x7fa126050620>, 'map_fn': <function map_fn at 0x7fa1255378c8>, 'matching_files': <function matching_files at 0x7fa125b5b400>, 'matmul': <function matmul at 0x7fa125c63400>, 'matrix_band_part': <function matrix_band_part at 0x7fa125e90510>, 'matrix_determinant': <function matrix_determinant at 0x7fa125ac8b70>, 'matrix_diag': <function matrix_diag at 0x7fa125e90620>, 'matrix_diag_part': <function matrix_diag_part at 0x7fa125e90730>, 'matrix_inverse': <function matrix_inverse at 0x7fa125ac8d90>, 'matrix_set_diag': <function matrix_set_diag at 0x7fa125e90840>, 'matrix_solve': <function matrix_solve at 0x7fa125ac0048>, 'matrix_solve_ls': <function matrix_solve_ls at 0x7fa1255447b8>, 'matrix_square_root': <function matrix_square_root at 0x7fa125ac01e0>, 'matrix_transpose': <function matrix_transpose at 0x7fa125e351e0>, 'matrix_triangular_solve': <function matrix_triangular_solve at 0x7fa125ac0378>, 'maximum': <function maximum at 0x7fa125e03ae8>, 'meshgrid': <function meshgrid at 0x7fa125e35bf8>, 'min_max_variable_partitioner': <function min_max_variable_partitioner at 0x7fa125122ae8>, 'minimum': <function minimum at 0x7fa125e03e18>, 'model_variables': <function model_variables at 0x7fa125af2e18>, 'moving_average_variables': <function moving_average_variables at 0x7fa125af2f28>, 'multinomial': <function multinomial at 0x7fa125ac9400>, 'multiply': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c4bf28>, 'name_scope': <class 'tensorflow.python.framework.ops.name_scope'>, 'negative': <function neg at 0x7fa125e051e0>, 'no_op': <function no_op at 0x7fa125bca8c8>, 'no_regularizer': <function no_regularizer at 0x7fa125adeea0>, 'norm': <function norm at 0x7fa125544bf8>, 'not_equal': <function not_equal at 0x7fa125e052f0>, 'one_hot': <function one_hot at 0x7fa125e3e510>, 'ones': <function ones at 0x7fa125e35840>, 'ones_like': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e35620>, 'op_scope': <function op_scope at 0x7fa1260e5488>, 'pad': <function pad at 0x7fa125e35b70>, 'parallel_stack': <function parallel_stack at 0x7fa125e336a8>, 'parse_example': <function parse_example at 0x7fa125302bf8>, 'parse_single_example': <function parse_single_example at 0x7fa125302e18>, 'parse_single_sequence_example': <function parse_single_sequence_example at 0x7fa125303158>, 'parse_tensor': <function parse_tensor at 0x7fa12580bd90>, 'placeholder': <function placeholder at 0x7fa125e358c8>, 'placeholder_with_default': <function placeholder_with_default at 0x7fa125e35950>, 'polygamma': <function polygamma at 0x7fa125e05488>, 'pow': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c45620>, 'py_func': <function py_func at 0x7fa1257ed400>, 'qr': <function qr at 0x7fa125ac07b8>, 'quantize': <function quantize at 0x7fa125dc3268>, 'quantize_v2': <function quantize_v2 at 0x7fa125dc31e0>, 'quantized_concat': <function quantized_concat at 0x7fa125e9b1e0>, 'random_crop': <function random_crop at 0x7fa125ac92f0>, 'random_gamma': <function random_gamma at 0x7fa125ac9598>, 'random_normal': <function random_normal at 0x7fa125ac9048>, 'random_poisson': <function random_poisson at 0x7fa125ac9620>, 'random_shuffle': <function random_shuffle at 0x7fa125ac9268>, 'random_uniform': <function random_uniform at 0x7fa125ac91e0>, 'range': <function range at 0x7fa125c40b70>, 'rank': <function rank at 0x7fa125e332f0>, 'read_file': <function read_file at 0x7fa125b5b620>, 'real': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c458c8>, 'realdiv': <function real_div at 0x7fa125e1dbf8>, 'reciprocal': <function reciprocal at 0x7fa125e1dd90>, 'reduce_all': <function reduce_all_v1 at 0x7fa125c63048>, 'reduce_any': <function reduce_any_v1 at 0x7fa125c632f0>, 'reduce_join': <function reduce_join at 0x7fa125682ae8>, 'reduce_logsumexp': <function reduce_logsumexp_v1 at 0x7fa125c63598>, 'reduce_max': <function reduce_max_v1 at 0x7fa125c56d08>, 'reduce_mean': <function reduce_mean_v1 at 0x7fa125c560d0>, 'reduce_min': <function reduce_min_v1 at 0x7fa125c56a60>, 'reduce_prod': <function reduce_prod_v1 at 0x7fa125c568c8>, 'reduce_sum': <function reduce_sum_v1 at 0x7fa125c56048>, 'regex_replace': <function add_dispatch_support.<locals>.wrapper at 0x7fa125682840>, 'register_tensor_conversion_function': <function register_tensor_conversion_function at 0x7fa1260c89d8>, 'report_uninitialized_variables': <function should_use_result.<locals>.wrapped at 0x7fa125af5950>, 'required_space_to_batch_paddings': <function required_space_to_batch_paddings at 0x7fa125e3e048>, 'reset_default_graph': <function reset_default_graph at 0x7fa1260e08c8>, 'reshape': <function reshape at 0x7fa125e9be18>, 'reverse': <function reverse_v2 at 0x7fa125e992f0>, 'reverse_v2': <function reverse_v2 at 0x7fa125e992f0>, 'reverse_sequence': <function reverse_sequence at 0x7fa125e3eb70>, 'rint': <function rint at 0x7fa125e11950>, 'roll': <function roll at 0x7fa1253800d0>, 'round': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c45b70>, 'rsqrt': <function rsqrt at 0x7fa125e11b70>, 'saturate_cast': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c45d90>, 'scalar_mul': <function scalar_mul at 0x7fa125c45268>, 'scan': <function scan at 0x7fa125537950>, 'scatter_add': <function scatter_add at 0x7fa125bac620>, 'scatter_div': <function scatter_div at 0x7fa125df6048>, 'scatter_max': <function scatter_max at 0x7fa125df6158>, 'scatter_min': <function scatter_min at 0x7fa125df6268>, 'scatter_mul': <function scatter_mul at 0x7fa125df6378>, 'scatter_nd': <function scatter_nd at 0x7fa125e99400>, 'scatter_nd_add': <function scatter_nd_add at 0x7fa125bac6a8>, 'scatter_nd_sub': <function scatter_nd_sub at 0x7fa125bac7b8>, 'scatter_nd_update': <function scatter_nd_update at 0x7fa125bac598>, 'scatter_sub': <function scatter_sub at 0x7fa125bac730>, 'scatter_update': <function scatter_update at 0x7fa125bac400>, 'searchsorted': <function searchsorted at 0x7fa125dc30d0>, 'segment_max': <function segment_max at 0x7fa125e11d90>, 'segment_mean': <function segment_mean at 0x7fa125e11ea0>, 'segment_min': <function segment_min at 0x7fa125e26048>, 'segment_prod': <function segment_prod at 0x7fa125e26158>, 'segment_sum': <function segment_sum at 0x7fa125e26268>, 'self_adjoint_eig': <function self_adjoint_eig at 0x7fa125544840>, 'self_adjoint_eigvals': <function self_adjoint_eigvals at 0x7fa1255448c8>, 'sequence_mask': <function sequence_mask at 0x7fa125e3e620>, 'serialize_many_sparse': <function serialize_many_sparse at 0x7fa1256fa598>, 'serialize_sparse': <function serialize_sparse at 0x7fa1256fa488>, 'serialize_tensor': <function serialize_tensor at 0x7fa12580bea0>, 'set_random_seed': <function set_random_seed at 0x7fa1260526a8>, 'setdiff1d': <function setdiff1d at 0x7fa125e2cd90>, 'shape': <function shape at 0x7fa125e2cf28>, 'shape_n': <function shape_n at 0x7fa125e330d0>, 'sigmoid': <function sigmoid at 0x7fa125c63c80>, 'sign': <function sign at 0x7fa125e26620>, 'sin': <function sin at 0x7fa125e26730>, 'sinh': <function sinh at 0x7fa125e26840>, 'size': <function size at 0x7fa125e331e0>, 'slice': <function slice at 0x7fa125e33510>, 'sort': <function sort at 0x7fa125122bf8>, 'space_to_batch': <function space_to_batch at 0x7fa125e3e158>, 'space_to_batch_nd': <function space_to_batch_nd at 0x7fa125e99c80>, 'space_to_depth': <function space_to_depth at 0x7fa125e3e268>, 'sparse_add': <function sparse_add at 0x7fa1256e2ea0>, 'sparse_concat': <function sparse_concat at 0x7fa1256e2c80>, 'sparse_fill_empty_rows': <function sparse_fill_empty_rows at 0x7fa1256fa400>, 'sparse_mask': <function sparse_mask at 0x7fa125e33e18>, 'sparse_matmul': <function sparse_mat_mul at 0x7fa125e26950>, 'sparse_maximum': <function sparse_maximum at 0x7fa1256fa8c8>, 'sparse_merge': <function sparse_merge at 0x7fa1256fa268>, 'sparse_minimum': <function sparse_minimum at 0x7fa1256fa950>, 'sparse_placeholder': <function sparse_placeholder at 0x7fa125e35ae8>, 'sparse_reduce_max': <function sparse_reduce_max at 0x7fa1256f68c8>, 'sparse_reduce_max_sparse': <function sparse_reduce_max_sparse at 0x7fa1256f6bf8>, 'sparse_reduce_sum': <function sparse_reduce_sum at 0x7fa1256f6d90>, 'sparse_reduce_sum_sparse': <function sparse_reduce_sum_sparse at 0x7fa1256fa158>, 'sparse_reorder': <function sparse_reorder at 0x7fa1256f6158>, 'sparse_reset_shape': <function sparse_reset_shape at 0x7fa1256fa378>, 'sparse_reshape': <function sparse_reshape at 0x7fa1256f61e0>, 'sparse_retain': <function sparse_retain at 0x7fa1256fa2f0>, 'sparse_segment_mean': <function sparse_segment_mean at 0x7fa125c6b730>, 'sparse_segment_sqrt_n': <function sparse_segment_sqrt_n at 0x7fa125c6b840>, 'sparse_segment_sum': <function sparse_segment_sum at 0x7fa125c6b620>, 'sparse_slice': <function sparse_slice at 0x7fa1256f6378>, 'sparse_softmax': <function sparse_softmax at 0x7fa1256fa840>, 'sparse_split': <function sparse_split at 0x7fa1256f6510>, 'sparse_tensor_dense_matmul': <function sparse_tensor_dense_matmul at 0x7fa1256fa7b8>, 'sparse_tensor_to_dense': <function sparse_tensor_to_dense at 0x7fa1256f6c80>, 'sparse_to_dense': <function sparse_to_dense at 0x7fa1256f6598>, 'sparse_to_indicator': <function sparse_to_indicator at 0x7fa1256fa048>, 'sparse_transpose': <function sparse_transpose at 0x7fa1256fa9d8>, 'split': <function split at 0x7fa125e33f28>, 'sqrt': <function sqrt at 0x7fa125e25378>, 'square': <function square at 0x7fa125e25598>, 'squared_difference': <function squared_difference at 0x7fa125e25730>, 'squeeze': <function squeeze at 0x7fa125e3e8c8>, 'stack': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e337b8>, 'stop_gradient': <function stop_gradient at 0x7fa125e851e0>, 'strided_slice': <function strided_slice at 0x7fa125e33598>, 'string_join': <function string_join at 0x7fa12579bc80>, 'string_split': <function string_split at 0x7fa1256828c8>, 'string_strip': <function string_strip at 0x7fa1257b6840>, 'string_to_hash_bucket_fast': <function string_to_hash_bucket_fast at 0x7fa1257b6a60>, 'string_to_hash_bucket_strong': <function string_to_hash_bucket_strong at 0x7fa1257b6b70>, 'substr': <function substr_deprecated at 0x7fa125682ea0>, 'subtract': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c451e0>, 'svd': <function svd at 0x7fa125544950>, 'tables_initializer': <function tables_initializer at 0x7fa1251b8a60>, 'tan': <function tan at 0x7fa125e259d8>, 'tanh': <function tanh at 0x7fa125e25ae8>, 'tensor_scatter_add': <function tensor_scatter_add at 0x7fa125e85620>, 'tensor_scatter_sub': <function tensor_scatter_sub at 0x7fa125e85730>, 'tensor_scatter_update': <function tensor_scatter_update at 0x7fa125e85840>, 'tensordot': <function tensordot at 0x7fa125c6b8c8>, 'tile': <function tile at 0x7fa125e859d8>, 'timestamp': <function timestamp at 0x7fa125bd9268>, 'to_bfloat16': <function to_bfloat16 at 0x7fa125c4a400>, 'to_complex128': <function to_complex128 at 0x7fa125c4a620>, 'to_complex64': <function to_complex64 at 0x7fa125c4a510>, 'to_double': <function to_double at 0x7fa125c4a0d0>, 'to_float': <function to_float at 0x7fa125c45f28>, 'to_int32': <function to_int32 at 0x7fa125c4a1e0>, 'to_int64': <function to_int64 at 0x7fa125c4a2f0>, 'trace': <function trace at 0x7fa125c636a8>, 'trainable_variables': <function trainable_variables at 0x7fa125af2ea0>, 'transpose': <function transpose at 0x7fa125e350d0>, 'truediv': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c4a8c8>, 'truncatediv': <function truncate_div at 0x7fa125e25d08>, 'truncatemod': <function truncate_mod at 0x7fa125e25e18>, 'truncated_normal': <function truncated_normal at 0x7fa125ac9158>, 'tuple': <function tuple at 0x7fa125ba6730>, 'unique': <function unique at 0x7fa125e33d90>, 'unique_with_counts': <function unique_with_counts at 0x7fa125e33ea0>, 'unravel_index': <function unravel_index at 0x7fa125ea4048>, 'unsorted_segment_max': <function unsorted_segment_max at 0x7fa125e17048>, 'unsorted_segment_mean': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c6b488>, 'unsorted_segment_min': <function unsorted_segment_min at 0x7fa125e17158>, 'unsorted_segment_prod': <function unsorted_segment_prod at 0x7fa125e17268>, 'unsorted_segment_sqrt_n': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c6b598>, 'unsorted_segment_sum': <function unsorted_segment_sum at 0x7fa125e17378>, 'unstack': <function unstack at 0x7fa125e33a60>, 'variable_axis_size_partitioner': <function variable_axis_size_partitioner at 0x7fa1251b8730>, 'variable_op_scope': <function variable_op_scope at 0x7fa125a65158>, 'variable_scope': <class 'tensorflow.python.ops.variable_scope.variable_scope'>, 'variables_initializer': <function variables_initializer at 0x7fa125af5048>, 'verify_tensor_all_finite': <function verify_tensor_all_finite at 0x7fa1254ffbf8>, 'where': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e3e950>, 'while_loop': <function while_loop at 0x7fa125ba6378>, 'write_file': <function write_file at 0x7fa125b6b400>, 'zeros': <function zeros at 0x7fa125e35268>, 'zeros_like': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e35378>, 'zeta': <function zeta at 0x7fa125e176a8>, 'disable_v2_behavior': <function disable_v2_behavior at 0x7fa12577c620>, 'enable_v2_behavior': <function enable_v2_behavior at 0x7fa12577c598>, 'wrap_function': <function wrap_function at 0x7fa1251b81e0>, 'constant': <function constant_v1 at 0x7fa132b8d9d8>, 'QUANTIZED_DTYPES': frozenset({tf.qint8, tf.quint8, tf.qint32, tf.qint8_ref, tf.quint8_ref, tf.qint32_ref, tf.qint16, tf.qint16_ref, tf.quint16_ref, tf.quint16}), 'bfloat16': tf.bfloat16, 'bool': tf.bool, 'complex128': tf.complex128, 'complex64': tf.complex64, 'double': tf.float64, 'float16': tf.float16, 'float32': tf.float32, 'float64': tf.float64, 'half': tf.float16, 'int16': tf.int16, 'int32': tf.int32, 'int64': tf.int64, 'int8': tf.int8, 'qint16': tf.qint16, 'qint32': tf.qint32, 'qint8': tf.qint8, 'quint16': tf.quint16, 'quint8': tf.quint8, 'resource': tf.resource, 'string': tf.string, 'uint16': tf.uint16, 'uint32': tf.uint32, 'uint64': tf.uint64, 'uint8': tf.uint8, 'variant': tf.variant, 'disable_eager_execution': <function disable_eager_execution at 0x7fa1260e0730>, 'init_scope': <function init_scope at 0x7fa1260e0510>, 'dimension_at_index': <function dimension_at_index at 0x7fa1261702f0>, 'dimension_value': <function dimension_value at 0x7fa126170268>, 'disable_v2_tensorshape': <function disable_v2_tensorshape at 0x7fa1261701e0>, 'enable_v2_tensorshape': <function enable_v2_tensorshape at 0x7fa126170158>, 'TensorSpec': <class 'tensorflow.python.framework.tensor_spec.TensorSpec'>, 'COMPILER_VERSION': '4.8.5', '__compiler_version__': '4.8.5', 'CXX11_ABI_FLAG': 0, '__cxx11_abi_flag__': 0, 'GIT_VERSION': ""b'v1.13.1-0-g6612da8951'"", '__git_version__': ""b'v1.13.1-0-g6612da8951'"", 'GRAPH_DEF_VERSION': 27, 'GRAPH_DEF_VERSION_MIN_CONSUMER': 0, 'GRAPH_DEF_VERSION_MIN_PRODUCER': 0, 'MONOLITHIC_BUILD': 0, '__monolithic_build__': 0, 'VERSION': '1.13.1', '__version__': '1.13.1', 'newaxis': None, 'ensure_shape': <function ensure_shape at 0x7fa1257e5400>, 'confusion_matrix': <function confusion_matrix_v1 at 0x7fa12558d268>, 'string_to_number': <function string_to_number at 0x7fa12580bf28>, 'fft': <function fft at 0x7fa126038488>, 'fft2d': <function fft2d at 0x7fa126038598>, 'fft3d': <function fft3d at 0x7fa1260386a8>, 'ifft': <function ifft at 0x7fa1260387b8>, 'ifft2d': <function ifft2d at 0x7fa1260388c8>, 'ifft3d': <function ifft3d at 0x7fa1260389d8>, 'string_to_hash_bucket': <function string_to_hash_bucket at 0x7fa1257b68c8>, 'print': <function print_v2 at 0x7fa125366400>, 'RaggedTensor': <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'>, 'py_function': <function eager_py_func at 0x7fa1257ed268>, 'batch_scatter_update': <function batch_scatter_update at 0x7fa125bac950>, 'AUTO_REUSE': <_ReuseMode.AUTO_REUSE: 1>, 'disable_resource_variables': <function disable_resource_variables at 0x7fa125add048>, 'enable_resource_variables': <function enable_resource_variables at 0x7fa125b04f28>, 'variable_creator_scope': <function variable_creator_scope_v1 at 0x7fa125a65510>, 'get_logger': <function get_logger at 0x7fa126978598>, '_names_with_underscore': ['__version__', '__git_version__', '__compiler_version__', '__cxx11_abi_flag__', '__monolithic_build__'], '__all__': ['AUTO_REUSE', 'AggregationMethod', 'Assert', 'AttrValue', 'COMPILER_VERSION', 'CXX11_ABI_FLAG', 'ConditionalAccumulator', 'ConditionalAccumulatorBase', 'ConfigProto', 'DType', 'DeviceSpec', 'Dimension', 'Event', 'FIFOQueue', 'FixedLenFeature', 'FixedLenSequenceFeature', 'FixedLengthRecordReader', 'GIT_VERSION', 'GPUOptions', 'GRAPH_DEF_VERSION', 'GRAPH_DEF_VERSION_MIN_CONSUMER', 'GRAPH_DEF_VERSION_MIN_PRODUCER', 'GradientTape', 'Graph', 'GraphDef', 'GraphKeys', 'GraphOptions', 'HistogramProto', 'IdentityReader', 'IndexedSlices', 'InteractiveSession', 'LMDBReader', 'LogMessage', 'MONOLITHIC_BUILD', 'MetaGraphDef', 'NameAttrList', 'NoGradient', 'NodeDef', 'NotDifferentiable', 'OpError', 'Operation', 'OptimizerOptions', 'PaddingFIFOQueue', 'Print', 'PriorityQueue', 'QUANTIZED_DTYPES', 'QueueBase', 'RaggedTensor', 'RandomShuffleQueue', 'ReaderBase', 'RegisterGradient', 'RunMetadata', 'RunOptions', 'Session', 'SessionLog', 'SparseConditionalAccumulator', 'SparseFeature', 'SparseTensor', 'SparseTensorValue', 'Summary', 'SummaryMetadata', 'TFRecordReader', 'Tensor', 'TensorArray', 'TensorInfo', 'TensorShape', 'TensorSpec', 'TextLineReader', 'UnconnectedGradients', 'VERSION', 'VarLenFeature', 'Variable', 'VariableAggregation', 'VariableScope', 'VariableSynchronization', 'WholeFileReader', 'abs', 'accumulate_n', 'acos', 'acosh', 'add', 'add_check_numerics_ops', 'add_n', 'add_to_collection', 'add_to_collections', 'all_variables', 'angle', 'app', 'arg_max', 'arg_min', 'argmax', 'argmin', 'argsort', 'as_dtype', 'as_string', 'asin', 'asinh', 'assert_equal', 'assert_greater', 'assert_greater_equal', 'assert_integer', 'assert_less', 'assert_less_equal', 'assert_near', 'assert_negative', 'assert_non_negative', 'assert_non_positive', 'assert_none_equal', 'assert_positive', 'assert_proper_iterable', 'assert_rank', 'assert_rank_at_least', 'assert_rank_in', 'assert_same_float_dtype', 'assert_scalar', 'assert_type', 'assert_variables_initialized', 'assign', 'assign_add', 'assign_sub', 'atan', 'atan2', 'atanh', 'autograph', 'batch_gather', 'batch_scatter_update', 'batch_to_space', 'batch_to_space_nd', 'betainc', 'bfloat16', 'bincount', 'bitcast', 'bitwise', 'bool', 'boolean_mask', 'broadcast_dynamic_shape', 'broadcast_static_shape', 'broadcast_to', 'case', 'cast', 'ceil', 'check_numerics', 'cholesky', 'cholesky_solve', 'clip_by_average_norm', 'clip_by_global_norm', 'clip_by_norm', 'clip_by_value', 'colocate_with', 'compat', 'complex', 'complex128', 'complex64', 'concat', 'cond', 'confusion_matrix', 'conj', 'constant', 'constant_initializer', 'container', 'control_dependencies', 'convert_to_tensor', 'convert_to_tensor_or_indexed_slices', 'convert_to_tensor_or_sparse_tensor', 'core', 'cos', 'cosh', 'count_nonzero', 'count_up_to', 'create_partitioned_variables', 'cross', 'cumprod', 'cumsum', 'custom_gradient', 'data', 'debugging', 'decode_base64', 'decode_compressed', 'decode_csv', 'decode_json_example', 'decode_raw', 'delete_session_tensor', 'depth_to_space', 'dequantize', 'deserialize_many_sparse', 'device', 'diag', 'diag_part', 'digamma', 'dimension_at_index', 'dimension_value', 'disable_eager_execution', 'disable_resource_variables', 'disable_v2_behavior', 'disable_v2_tensorshape', 'distribute', 'distributions', 'div', 'div_no_nan', 'divide', 'double', 'dtypes', 'dynamic_partition', 'dynamic_stitch', 'edit_distance', 'einsum', 'enable_eager_execution', 'enable_resource_variables', 'enable_v2_behavior', 'enable_v2_tensorshape', 'encode_base64', 'ensure_shape', 'equal', 'erf', 'erfc', 'errors', 'executing_eagerly', 'exp', 'expand_dims', 'experimental', 'expm1', 'extract_image_patches', 'extract_volume_patches', 'eye', 'fake_quant_with_min_max_args', 'fake_quant_with_min_max_args_gradient', 'fake_quant_with_min_max_vars', 'fake_quant_with_min_max_vars_gradient', 'fake_quant_with_min_max_vars_per_channel', 'fake_quant_with_min_max_vars_per_channel_gradient', 'feature_column', 'fft', 'fft2d', 'fft3d', 'fill', 'fixed_size_partitioner', 'float16', 'float32', 'float64', 'floor', 'floor_div', 'floordiv', 'floormod', 'foldl', 'foldr', 'gather', 'gather_nd', 'get_collection', 'get_collection_ref', 'get_default_graph', 'get_default_session', 'get_local_variable', 'get_logger', 'get_seed', 'get_session_handle', 'get_session_tensor', 'get_variable', 'get_variable_scope', 'gfile', 'global_norm', 'global_variables', 'global_variables_initializer', 'glorot_normal_initializer', 'glorot_uniform_initializer', 'gradients', 'graph_util', 'greater', 'greater_equal', 'group', 'guarantee_const', 'half', 'hessians', 'histogram_fixed_width', 'histogram_fixed_width_bins', 'identity', 'identity_n', 'ifft', 'ifft2d', 'ifft3d', 'igamma', 'igammac', 'imag', 'image', 'import_graph_def', 'init_scope', 'initialize_all_tables', 'initialize_all_variables', 'initialize_local_variables', 'initialize_variables', 'initializers', 'int16', 'int32', 'int64', 'int8', 'invert_permutation', 'io', 'is_finite', 'is_inf', 'is_nan', 'is_non_decreasing', 'is_numeric_tensor', 'is_strictly_increasing', 'is_variable_initialized', 'keras', 'layers', 'lbeta', 'less', 'less_equal', 'lgamma', 'lin_space', 'linalg', 'linspace', 'lite', 'load_file_system_library', 'load_library', 'load_op_library', 'local_variables', 'local_variables_initializer', 'log', 'log1p', 'log_sigmoid', 'logging', 'logical_and', 'logical_not', 'logical_or', 'logical_xor', 'losses', 'make_ndarray', 'make_template', 'make_tensor_proto', 'manip', 'map_fn', 'matching_files', 'math', 'matmul', 'matrix_band_part', 'matrix_determinant', 'matrix_diag', 'matrix_diag_part', 'matrix_inverse', 'matrix_set_diag', 'matrix_solve', 'matrix_solve_ls', 'matrix_square_root', 'matrix_transpose', 'matrix_triangular_solve', 'maximum', 'meshgrid', 'metrics', 'min_max_variable_partitioner', 'minimum', 'mod', 'model_variables', 'moving_average_variables', 'multinomial', 'multiply', 'name_scope', 'negative', 'newaxis', 'nn', 'no_gradient', 'no_op', 'no_regularizer', 'norm', 'not_equal', 'one_hot', 'ones', 'ones_initializer', 'ones_like', 'op_scope', 'orthogonal_initializer', 'pad', 'parallel_stack', 'parse_example', 'parse_single_example', 'parse_single_sequence_example', 'parse_tensor', 'placeholder', 'placeholder_with_default', 'polygamma', 'pow', 'print', 'profiler', 'py_func', 'py_function', 'python', 'python_io', 'pywrap_tensorflow', 'qint16', 'qint32', 'qint8', 'qr', 'quantization', 'quantize', 'quantize_v2', 'quantized_concat', 'queue', 'quint16', 'quint8', 'ragged', 'random', 'random_crop', 'random_gamma', 'random_normal', 'random_normal_initializer', 'random_poisson', 'random_shuffle', 'random_uniform', 'random_uniform_initializer', 'range', 'rank', 'read_file', 'real', 'realdiv', 'reciprocal', 'reduce_all', 'reduce_any', 'reduce_join', 'reduce_logsumexp', 'reduce_max', 'reduce_mean', 'reduce_min', 'reduce_prod', 'reduce_sum', 'regex_replace', 'register_tensor_conversion_function', 'report_uninitialized_variables', 'required_space_to_batch_paddings', 'reset_default_graph', 'reshape', 'resource', 'resource_loader', 'reverse', 'reverse_sequence', 'reverse_v2', 'rint', 'roll', 'round', 'rsqrt', 'saturate_cast', 'saved_model', 'scalar_mul', 'scan', 'scatter_add', 'scatter_div', 'scatter_max', 'scatter_min', 'scatter_mul', 'scatter_nd', 'scatter_nd_add', 'scatter_nd_sub', 'scatter_nd_update', 'scatter_sub', 'scatter_update', 'searchsorted', 'segment_max', 'segment_mean', 'segment_min', 'segment_prod', 'segment_sum', 'self_adjoint_eig', 'self_adjoint_eigvals', 'sequence_mask', 'serialize_many_sparse', 'serialize_sparse', 'serialize_tensor', 'set_random_seed', 'setdiff1d', 'sets', 'shape', 'shape_n', 'sigmoid', 'sign', 'signal', 'sin', 'sinh', 'size', 'slice', 'sort', 'space_to_batch', 'space_to_batch_nd', 'space_to_depth', 'sparse', 'sparse_add', 'sparse_concat', 'sparse_fill_empty_rows', 'sparse_mask', 'sparse_matmul', 'sparse_maximum', 'sparse_merge', 'sparse_minimum', 'sparse_placeholder', 'sparse_reduce_max', 'sparse_reduce_max_sparse', 'sparse_reduce_sum', 'sparse_reduce_sum_sparse', 'sparse_reorder', 'sparse_reset_shape', 'sparse_reshape', 'sparse_retain', 'sparse_segment_mean', 'sparse_segment_sqrt_n', 'sparse_segment_sum', 'sparse_slice', 'sparse_softmax', 'sparse_split', 'sparse_tensor_dense_matmul', 'sparse_tensor_to_dense', 'sparse_to_dense', 'sparse_to_indicator', 'sparse_transpose', 'spectral', 'split', 'sqrt', 'square', 'squared_difference', 'squeeze', 'stack', 'stop_gradient', 'strided_slice', 'string', 'string_join', 'string_split', 'string_strip', 'string_to_hash_bucket', 'string_to_hash_bucket_fast', 'string_to_hash_bucket_strong', 'string_to_number', 'strings', 'substr', 'subtract', 'summary', 'svd', 'sysconfig', 'tables_initializer', 'tan', 'tanh', 'tensor_scatter_add', 'tensor_scatter_sub', 'tensor_scatter_update', 'tensordot', 'test', 'tile', 'timestamp', 'to_bfloat16', 'to_complex128', 'to_complex64', 'to_double', 'to_float', 'to_int32', 'to_int64', 'tools', 'trace', 'train', 'trainable_variables', 'transpose', 'truediv', 'truncated_normal', 'truncated_normal_initializer', 'truncatediv', 'truncatemod', 'tuple', 'uint16', 'uint32', 'uint64', 'uint8', 'uniform_unit_scaling_initializer', 'unique', 'unique_with_counts', 'unravel_index', 'unsorted_segment_max', 'unsorted_segment_mean', 'unsorted_segment_min', 'unsorted_segment_prod', 'unsorted_segment_sqrt_n', 'unsorted_segment_sum', 'unstack', 'user_ops', 'variable_axis_size_partitioner', 'variable_creator_scope', 'variable_op_scope', 'variable_scope', 'variables_initializer', 'variance_scaling_initializer', 'variant', 'verify_tensor_all_finite', 'version', 'where', 'while_loop', 'wrap_function', 'write_file', 'zeros', 'zeros_initializer', 'zeros_like', 'zeta', '__version__', '__git_version__', '__compiler_version__', '__cxx11_abi_flag__', '__monolithic_build__', 'contrib'], '_component_api_helper': <module 'tensorflow.python.tools.component_api_helper' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/python/tools/component_api_helper.py'>, 'estimator': <module 'tensorflow_estimator.python.estimator.api.estimator' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/api/estimator/__init__.py'>, '_CONTRIB_WARNING': '\nWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\nIf you depend on functionality not listed there, please file an issue.\n', 'contrib': <module 'tensorflow.contrib' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/contrib/__init__.py'>, 'flags': <module 'tensorflow.python.platform.flags' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/python/platform/flags.py'>, '_tf_api_dir': '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1', 'compiler': <module 'tensorflow.compiler' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/compiler/__init__.py'>}
```
**Code to reproduce the issue**
```
import tensorflow
print(tensorflow.__dict__)
print(tensorflow.__doc__)
```

**Other info / logs**
We have been using `tensorflow.__dict__` to look up for the tensorflow functions in rigorous manner, for code generation purposes."
30183,build using cmake failed,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version:1.14.0
- Python version:3.6
- Installed using virtualenv? pip? conda?:virtualenv
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): VS 2105
- CUDA/cuDNN version: 10
- GPU model and memory: GTX Titan X



**Describe the problem**
Missing directory/files: tensorflow/contrib/tpu/ops
**Provide the exact sequence of commands / steps that you executed before running into the problem**
running Cmake 
tensorflow/contrib/cmake/python_modules.txt contains the line but no  tensorflow/contrib/tpu/ops does not exist

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30182,"autograph should handle ""for"" loops over ""range"" in a manner that is compatible with XLA compilation","**System information**
- TensorFlow version (you are using): 1.14
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

Consider the following Python code:
```python
import tensorflow as tf
autograph = tf.contrib.autograph
xla = tf.contrib.compiler.xla

tf.enable_eager_execution()

@tf.function
def bad_loop(x, count):
  for _ in range(count):
    x += 1
  return x

@tf.function
def good_loop(x, count):
  i = 0
  while i < count:
    x += 1
    i += 1
  return x
```

`bad_loop` is the intuitive way to write this loop. However, it fails to compile with xla:
```
>>> xla.compile(bad_loop, [1.0, 3])
InvalidArgumentError: Input 1 to node `StatefulPartitionedCall/range` with op Range must be a compile-time constant.

XLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.
	 [[{{node StatefulPartitionedCall/range}}]]
	This error might be occurring with the use of xla.compile. If it is not necessary that every Op be compiled with XLA, an alternative is to use auto_jit with OptimizerOptions.global_jit_level = ON_2 or the environment variable TF_XLA_FLAGS=""tf_xla_auto_jit=2"" which will attempt to use xla to compile as much of the graph as the compiler is able to.
	 [[cluster]] [Op:__inference_xla_compile_wrapper_166]
```

In contrast, `good_loop` calculates the correct result:
```
>>> xla.compile(good_loop, [1.0, 3])
[<tf.Tensor: id=229, shape=(), dtype=float32, numpy=4.0>]
```

Autograph seems to always convert `range()` into `tf.range()`, even in for loops. This means that XLA can't compile the function. However, the equivalent loop written as a naive `while` loop works.

Ideally, Autograph would detect such uses of `range` in for loops and convert them into the style of `good_loop` automatically, rather than requiring users to do this. This would let us write cleaner code.

**Will this change the current api? How?** No

**Who will benefit with this feature?** Users who want to write normal Python code with Autograph.

**Any Other info.**
"
30181,"Can't cross-compile TFLite ""Minimal"" for Raspberry Pi Zero (armv6 target)","**System information**
- OS Platform and Distribution: Linux Debian 10
- TensorFlow installed from: source
- TensorFlow version: master branch @ a6989c95e336eb9f73ac7dd2920bee76d7e7e49e
- GCC/Compiler version: 8.3.0 (Debian 8.3.0-2)
- Python, Installed using ..., Bazel, CUDA, GPU: n/a

**Background**
Hi,
I've been trying to build a Tensorflow Lite C++ project for the Raspberry Pi Zero. For a simple base, I'm working from the ""minimal"" example provided. Building the Tensorflow Lite static library natively can take upwards of 5-6 hours, and for simplicity I've been trying to cross-compile. However, I haven't yet gotten minimal to compile. Although there's documentation on compiling for armv7 Pi's, I haven't been able to find anything on an armv6 platform.

**Steps I've taken, following the docs [here](https://www.tensorflow.org/lite/guide/build_rpi).**
- Git clone the tf repo
- Run ``download_dependencies.sh``
- Modify ``build_rpi_lib.sh`` to target armv6, i.e. with:
```
CC_PREFIX=arm-linux-gnueabihf- make -j 3 -f tensorflow/lite/tools/make/Makefile TARGET=rpi TARGET_ARCH=armv6
```
- First attempt! Run that build script. It quickly errors out in a few different header, saying `` sorry, unimplemented: Thumb-1 hard-float VFP ABI``. For example:
```
In file included from /usr/arm-linux-gnueabihf/include/c++/8/bits/stl_algobase.h:62,
                 from /usr/arm-linux-gnueabihf/include/c++/8/memory:62,
                 from ./tensorflow/lite/arena_planner.h:18,
                 from tensorflow/lite/arena_planner.cc:15:
/usr/arm-linux-gnueabihf/include/c++/8/ext/type_traits.h: In function â€˜bool __gnu_cxx::__is_null_pointer(std::nullptr_t)â€™:
/usr/arm-linux-gnueabihf/include/c++/8/ext/type_traits.h:162:35: sorry, unimplemented: Thumb-1 hard-float VFP ABI
   __is_null_pointer(std::nullptr_t)
                                   ^
make: *** [tensorflow/lite/tools/make/Makefile:242: /home/cgeary1/tensorflow/tensorflow/lite/tools/make/gen/rpi_armv6/obj/tensorflow/lite/allocation.o] Error 1
```
**- I wonder if I could get away using the traditional ARM instruction set instead of Thumb...** Add``-marm`` to CFLAGS and CXXFLAGS in ``rpi_makefile.inc`` under the armv6 ifeq, then try again. I.e.:
```
  ifeq ($(TARGET_ARCH), armv6)
    CXXFLAGS += \
      -march=armv6 \
      -mfpu=vfp \
      -funsafe-math-optimizations \
      -ftree-vectorize \
      -fPIC \
      -marm

    CFLAGS += \
      -march=armv6 \
      -mfpu=vfp \
      -funsafe-math-optimizations \
      -ftree-vectorize \
      -fPIC \
      -marm

    LDFLAGS := \
      -Wl,--no-export-dynamic \
      -Wl,--exclude-libs,ALL \
      -Wl,--gc-sections \
      -Wl,--as-needed
  endif
```
- Compiles for a little while, and finishes libtensorflow-lite.a !! But it errors out as soon as it moves on to minimal. Complaints look like ``undefined reference to `__atomic_load_8'`` and ``undefined reference to `flatbuffers::ClassicLocale::instance_'``. Relevant log is attached for all the details.
[log.txt](https://github.com/tensorflow/tensorflow/files/3331025/log.txt)

I'm not sure whether I'm doing something wrong, whether there's a bug in the make system, or whether there may be a more intractable problem trying to cross-compile this codebase for the Pi Zero. I'm not really sure what else to try, so for now I'm just working on the Pi.

Edit: I'm not able to try this right now, but I've realized that the flatbuffers error is likely to be solved as in #29806. The __atomic_load_8 error is the one that I can't get past.


"
30180,How to specify shape of input for TFLite model after receiving SavedModel format?,"I use TF 2.0. Let's suppose I have a model that I successfully converted to SavedModel format. I used following code to convert my model in Imperative API (subclassed tf.keras.Model) to SavedModel:

```python
tf.keras.experimental.export_saved_model(
    model, file_path,
    serving_only=True,
    input_signature=[tf.TensorSpec(shape=[None, None, None, 3], dtype=tf.float32)])
```

Now I want to convert my model to TFLite, but I have a problem, because I need to specify all dims except for batch. It's okay, but I want to do it after saving my model in SavedModel format. For example, if I want to do several models with different shapes, this feature is required (e.g, [None, 1280, 720, 3], [None, 600, 600, 3] etc.). 

How can I do it in step where I convert my model to TFLite? I mean in this step (or something like that after receiving SavedModel format):
```python
converter = tf.lite.TFLiteConverter.from_saved_model(file_path)
tflite_model = converter.convert()
```

Maybe I can specify `input_shape` in `convert()` or another way?"
30179,How to add value range constraints for 1-norm of vector?,"In my problem, I want to train some specific vectors which meet several unusual constraints. However, the usual norm constraints in tensorflow cannot be directly used in my problems. The 1-norm of vector I want to train must meet the minimum and maximum values constraints, i.e.
<img src=""http://chart.googleapis.com/chart?cht=tx&chl= 0 \leq \||\mathbf{x}\||^1_1 \leq 2"" style=""border:none;"">. 
As for vector with two elements, the 1-norm constraint means the sum of the absolute values of the two elements must meet the minimum and maximum values constraints.
I hope I have made my problem clear enough for you to understand. "
30178,conv2d_transpose param tensor shapes differ from conv2d shapes,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: Ubuntu 16.04
- Mobile device: Not tested
- TensorFlow installed from: binary
- TensorFlow version: 1.13.1
- Python version: 3.7.3
- Bazel version:
- GCC/Compiler version:
- CUDA/cuDNN version: 10.0/7.3.1
- GPU model and memory: Nvidia, driver 418.56, 11178MiB

**Describe the current behavior**
When training a model which contains conv2d_transpose layers (using the NCHW format), the last 2 dimensions of the layers weight tensor swap when reloading the model. 

Example: 
- after building the model: transpose_layer1 has the weight tensor (3, 3, 63, 61)
- when reloading the model: transpose_layer1 has the weight tensor (3, 3, 61, 63)

After swapping the two dimensions via numpys transpose method the shape (3, 3, 63, 61) is restored and the model successfully trains.

**Describe the expected behavior**
The expected behaviour would be that the last 2 dimensions don't swap which is the case for all conv2d layers. This occurs only in the conv2d_transpose layers.

**Setup to reproduce the issue**
The minimum is a small model which has a conv2d_transpose layer in it in which the last two dimensions differ from each other. After training it on GPU with NCHW data format the described behaviour occurs. 
"
30176,Getting `bad_alloc` in allocateTensors ,"**What I've done:**
I've picked up [one of iOS Tensorflow examples]([https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/ios]) and tried to use my `.tflite` model

**What I expected**:
Loaded model just like in the example.

**What I've got**:
`uncaught exception of type std::bad_alloc` and here are the logs with it:
```
    2019-06-26 15:25:45.414765+0300 Celly[5485:1152189] Initialized TensorFlow Lite runtime.
    Celly(5485,0x1006aebc0) malloc: can't allocate region
    *** mach_vm_map(size=1800945664) failed (error code=3)
    Celly(5485,0x1006aebc0) malloc: *** set a breakpoint in malloc_error_break to debug
    libc++abi.dylib: terminating with uncaught exception of type std::bad_alloc: std::bad_alloc
```


Is there any known workaround or help from documentation or so? Is this problem in the model, so it needs to be optimised or configured appropriately? "
30175,Add link libtensorflow_framework.so => libtensorflow_framework.so.1,"**System information**
- TensorFlow version (you are using): 1.14.0
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

Starting from TensorFlow 1.14.0, the pip packages come with a libtensorflow_framework.so.1 instead of a libtensorflow_framework.so. This breaks the build process of codes that extend tensorflow. Adding a symbolic link libtensorflow_framework.so => libtensorflow_framework.so.1 would greatly help.
"
30174,using deeplab with TensorFlow Lite GPU delegate on ios,"hi, did anyone know how I can use deeplab on ios application with tflite GPU delegate??, because I've searched everywhere but I didn't find anything."
30173,"Keras model doesn't compile for Edge-tpu if Dense layer contains [16, 32, 64, ...] neurons","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow version (use command below): 1.15.0-dev20190626, 2.0-beta1
- Python version: 3

**Describe the current behavior**
Couldn't convert keras model for Edge-tpu when Dense layer consists of [16, 32, 64, 128, 2^n and n>3]  neurons , but work for any other number.
Error:

```
 ERROR: :119 std::abs(input_product_scale - bias_scale) <= 1e-6 * std::min(input_product_scale, bias_scale) was not true.
ERROR: Node number 33 (FULLY_CONNECTED) failed to prepare.
```

**Describe the expected behavior**
Convert keras model for Edge-tpu successfully

**Code to reproduce the issue**
Colab to reproduce issue:
https://colab.research.google.com/drive/1H0L-UioDKHdl6QbT6OtJc5jplzWTi1qB"
30172,How to write the  .bmp images from tensors to disk after resizing ?,"I am trying to read bmp images, resize them and write the image to disk using tensorflow. I have succeeded in reading it but unable to find a way write it to disk. Any idea how to do it ?

Here is the code below:

```
import tensorflow as tf

img_path = ""D:/image01.bmp""

img = tf.read_file(img_path)

img_decode = tf.image.decode_bmp(img, channels=1) # unit8 tensor

IMG_WIDTH = 256

IMG_HEIGHT = 256

img_cast = tf.cast(img_decode,dtype=tf.float32)

img_res = tf.image.resize_bilinear(img_4d, (IMG_HEIGHT, IMG_WIDTH), align_corners=True)
```
The problem is I can't find a ""encode_bmp"" or any bmp related function that can be used to encode the image and save the resized image to disk."
30171,undefined symbol: _ZN10tensorflow7strings6StrCatERKNS0_8AlphaNumES3_ error while importing tensorflow_text,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Kubuntu 18.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0b0
- Python version: Anaconda python 3.7.3
- CUDA/cuDNN version: None
- GPU model and memory: None

**Describe the current behavior**
Error on importing `tensorflow-text` making it impossible to be imported.

**Describe the expected behavior**
Library can be effortlessly imported and used.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

I created a new environment using
```
conda create --name tensorflow python=3.7 numpy matplotlib scikit-learn pandas scipy
conda activate tensorflow
pip install tensorflow-text
```
then, when trying to import `tensorflow_text` the following error appears
```
$ python
Python 3.7.3 (default, Mar 27 2019, 22:11:17) 
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> import tensorflow_text as text
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/kuba/.anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_text/__init__.py"", line 20, in <module>
    from tensorflow_text.python.ops import *
  File ""/home/kuba/.anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_text/python/ops/__init__.py"", line 19, in <module>
    from tensorflow_text.python.ops.greedy_constrained_sequence_op import greedy_constrained_sequence
  File ""/home/kuba/.anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_text/python/ops/greedy_constrained_sequence_op.py"", line 34, in <module>
    gen_constrained_sequence_op = load_library.load_op_library(resource_loader.get_path_to_datafile('_constrained_sequence_op.so'))
  File ""/home/kuba/.anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/load_library.py"", line 61, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)
tensorflow.python.framework.errors_impl.NotFoundError: /home/kuba/.anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_text/python/ops/_constrained_sequence_op.so: undefined symbol: _ZN10tensorflow7strings6StrCatERKNS0_8AlphaNumES3_
>>>
```"
30169,TFLite GPU works slower than CPU,"
I run tflite in Qualcomm 660, for a testï¼Œthere is just a con2d. But when i run it,
cpu costs 30ms  while  cpu costs 130ms.
I don't know why"
30167,Variable sized input doesn't work with dilated convolutional layer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.10**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **v2.0.0-beta0-16-g1d91213fe7** -  **2.0.0-beta1**
- Python version: **3.6**
- CUDA/cuDNN version: **CPU**
- GPU model and memory: **CPU**

**Describe the current behavior**
I have variable sized axis on the input for a dilated conv layer which fails when inputting the second batch(data is padded batch wise). I have tried additional padding both for % dilation_rate == 0 and % 2 == 0 without luck. This allows for some of the layers to work but not all, so it might be a simple calculation I need to figure out what additional padding to use but I cant figure out what this is.

**Describe the expected behavior**
When running without dilation im able to handle the variable sized input. Also the fact that the conv layers with dilation can handle any input as long as its the first I would expect that no additional padding would be needed.

**Code to reproduce the issue**
```
import tensorflow as tf
bs = 5
text_len_1 = 772
text_len_2 = 741
embed_size = 300
in_channels = 1

test_in_1 = tf.random.normal((bs, text_len_1, embed_size, in_channels))
test_in_2 = tf.random.normal((bs, text_len_2, embed_size, in_channels))


dilated_convs = [tf.keras.layers.Conv2D(filters=10, kernel_size=(2, embed_size),
                                                    dilation_rate=(dilation, 1),
                                                    padding='valid')
                             for dilation in range(2, 23)]

for conv in dilated_convs:
    res = conv(test_in_1)

for conv in dilated_convs:
    # Fails here, regardless of test_in_1 or 2 is called first
    res = conv(test_in_2) 
```

**Other info / logs**
```
2019-06-25 13:50:33.329503: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at spacetobatch_op.cc:219 : Invalid argument: padded_shape[0]=741 is not divisible by block_shape[0]=2
Traceback (most recent call last):
  File ""/home/name/anaconda3/envs/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3296, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-59b677f0b758>"", line 1, in <module>
    runfile('/home/name/.PyCharm2019.1/config/scratches/dilated_conv_test.py', wdir='/home/name/.PyCharm2019.1/config/scratches')
  File ""/snap/pycharm-professional/136/helpers/pydev/_pydev_bundle/pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""/snap/pycharm-professional/136/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/home/name/.PyCharm2019.1/config/scratches/dilated_conv_test.py"", line 22, in <module>
    res = conv(test_in_2)
  File ""/home/name/anaconda3/envs/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 712, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/home/name/anaconda3/envs/3.6/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py"", line 196, in call
    outputs = self._convolution_op(inputs, self.kernel)
  File ""/home/name/anaconda3/envs/3.6/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 1078, in __call__
    return self.conv_op(inp, filter)
  File ""/home/name/anaconda3/envs/3.6/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 634, in __call__
    return self.call(inp, filter)
  File ""/home/name/anaconda3/envs/3.6/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 617, in _with_space_to_batch_call
    input=inp, block_shape=dilation_rate, paddings=paddings)
  File ""/home/name/anaconda3/envs/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 9246, in space_to_batch_nd
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: padded_shape[0]=741 is not divisible by block_shape[0]=2 [Op:SpaceToBatchND]
```"
30166,How does Tensorflow convert to TensorflowJS?,"I am working on a conversion of a Java machine learning platform. I am curious on how did TensorFlow manage to transcompile. If so, which toolsets are used?"
30165,TF 2.0 - Put Tensor into some Numpy functions continuously increases memory usage,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): pip package tensorflow==2.0.0-beta1
- TensorFlow version (use command below): v2.0.0-beta0-17-g8e423e3 2.0.0-beta1
- Python version: 3.7.3
- CUDA/cuDNN version: 10.0.0/7.3.1
- GPU model and memory: Titan Xp 11Gb

**Describe the current behavior**
 Memory leak when we put Tensor into some Numpy functions (ex - np.array(), np.zeros_like()). Following attached code continuously increases memory usage.

**Describe the expected behavior**
No memory usage explosion.

**Code to reproduce the issue**
```
import tensorflow as tf
import numpy as np
import time

x = tf.random.normal((1024, 1024))
for i in range(int(1e7)):
    y = np.array(x)
    time.sleep(0.01)
```"
30164,Tensorflow Webpage API tab Link error,"## Description of issue (what needs changing):

The Tensorflow API for 1.13 leads to 1.12 page kindly fix the hyperlink .

### Clear description

The change in the API list can cause confusion

### Request visuals, if applicable
![image](https://user-images.githubusercontent.com/11817160/60156197-98f79200-9809-11e9-846d-c7d2d1471a74.png)
"
30163,Load image tutorials ,You didn't use keras_ds or feature_map_batch in model.fit
30162, tf.keras model.fit calls slow with TPU distribute strategy,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below):1.14
- Python version:3,6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
TPU distribution strategy does not support model.fit_generator, and repeated model.fit calls result in a 50x slowdown presumably because it adds operations to graph. 

**Describe the expected behavior**

**Code to reproduce the issue**

resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)
tf.contrib.distribute.initialize_tpu_system(resolver)
strategy =  tf.distribute.experimental.TPUStrategy(resolver)
with strategy.scope():
    model = ..... ## Your tf.keras model
    model.compile(loss = custom_loss,optimizer ='custom_optimizer)
 
for i in range(num_its):
      data,labels = = next(generator_fn()) 
      model.fit(data,labels)   

     





**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30161,tf.keras.BatchNormalization ignores Mask when calculating Mean/Variance,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.7
- CUDA/cuDNN version: 10
- GPU model and memory: GTX 960M

**Describe the current behavior**
tf.keras.layers.BatchNormalization layers do not take the Mask into account when calculating mean/variance. This results in a Mean biased towards 0 and an inflated Variance when passing in padded samples. This is made worse by the fact that the BatchNormalization layer claims to support masking, yet all it does is pass it through to the next layer. This is an issue in TF 1.13, 1.14 and 2.0b where the implementation is imported straight from Keras.

The result from a toy example:
```
padded mean:		1.5
unpadded mean:		3.0

padded variance:	3.25
unpadded variance:	2.0
```

**Describe the expected behavior**
The Boolean Mask should be used when calculating the Mean and Variance, to ignore any 0's as a result of padded data.

**Code to reproduce the issue**
This example compares the behavior of BatchNorm against a padded and un-padded 1D signal. The resulting Means and Variances come out very different.
```
import tensorflow as tf
import numpy as np

# Mask value of -10
padded_data = np.expand_dims(np.array([[1,2,3,4,5,-10,-10,-10,-10,-10] for _ in range(100)], dtype='float32'), 2)
data = np.expand_dims(np.array([[1,2,3,4,5] for _ in range(100)], dtype='float32'), 2)

def build_padding_model():
    input = tf.keras.layers.Input((10, 1))
    masked = tf.keras.layers.Masking(-10)(input)
    normed = tf.keras.layers.BatchNormalization(momentum=0.01)(masked)
    model = tf.keras.models.Model(input, normed)
    model.compile(""adam"", loss=""mse"")
    return model

def build_model():
    input = tf.keras.layers.Input((5, 1))
    normed = tf.keras.layers.BatchNormalization(momentum=0.01)(input)
    model = tf.keras.models.Model(inputs=input, outputs=normed)
    model.compile(""adam"", loss=""mse"")
    return model

if __name__ =='__main__':
    batch_size = 100
    signal_length = 20

    pad = build_padding_model()
    pad.fit(x=padded_data, y=padded_data, batch_size=10, epochs=5)

    nopad = build_model()
    nopad.fit(x=data, y=data, batch_size=10, epochs=5)

    weights1 = pad.layers[2].get_weights()
    weights2 = nopad.layers[1].get_weights()
    print('\npadded mean:\t\t' + str(weights1[2][0]) + '\nunpadded mean:\t\t' + str(weights2[2][0]) + '\n')
    print('padded variance:\t' + str(weights1[3][0]) + '\nunpadded variance:\t' + str(weights2[3][0]) + '\n')
```"
30160,tensorflow 1.13 build using bazel on windows 10 Problem,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.13
- Python version: 3.7.2
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 0.21.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.5.0
- GPU model and memory: rtx 2070 moblie version (none maxq) 8gb



**Describe the problem**
I have solved all the previous issues while finishing the build those two last errors have appeared please help me with that it's starting to get morally painful here is the output after the second run:

**Any other info / logs**
C:\tensorflow\tensorflow>bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package
WARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:
c:\tensorflow\tensorflow/.bazelrc
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
WARNING: Option 'experimental_shortened_obj_file_path' is deprecated
INFO: Invocation ID: 078842cd-7467-4a1e-8aa2-c216dbc9c091
WARNING: C:/tensorflow/tensorflow/tensorflow/python/BUILD:2986:1: in py_library rule //tensorflow/python:standard_ops: target '//tensorflow/python:standard_ops' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.
WARNING: C:/tensorflow/tensorflow/tensorflow/python/BUILD:77:1: in py_library rule //tensorflow/python:no_contrib: target '//tensorflow/python:no_contrib' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.
WARNING: C:/tensorflow/tensorflow/tensorflow/contrib/metrics/BUILD:16:1: in py_library rule //tensorflow/contrib/metrics:metrics_py: target '//tensorflow/contrib/metrics:metrics_py' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.
WARNING: C:/tensorflow/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: C:/tensorflow/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
WARNING: C:/tensorflow/tensorflow/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.
WARNING: C:/tensorflow/tensorflow/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.
WARNING: C:/tensorflow/tensorflow/tensorflow/contrib/timeseries/python/timeseries/BUILD:356:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries:ar_model: target '//tensorflow/contrib/timeseries/python/timeseries:ar_model' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.
WARNING: C:/tensorflow/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:233:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.
WARNING: C:/tensorflow/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:76:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.
WARNING: C:/tensorflow/tensorflow/tensorflow/contrib/bayesflow/BUILD:17:1: in py_library rule //tensorflow/contrib/bayesflow:bayesflow_py: target '//tensorflow/contrib/bayesflow:bayesflow_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.
WARNING: C:/tensorflow/tensorflow/tensorflow/contrib/gan/BUILD:136:1: in py_library rule //tensorflow/contrib/gan:losses_impl: target '//tensorflow/contrib/gan:losses_impl' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.
WARNING: C:/tensorflow/tensorflow/tensorflow/contrib/BUILD:13:1: in py_library rule //tensorflow/contrib:contrib_py: target '//tensorflow/contrib:contrib_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.
INFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
ERROR: C:/users/moura/_bazel_moura/wvk7snnt/external/protobuf_archive/BUILD:626:1: Linking of rule '@protobuf_archive//:python/google/protobuf/internal/_api_implementation.so' failed (Exit 1120): link.exe failed: error executing command
  cd C:/users/moura/_bazel_moura/wvk7snnt/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1
    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1
    SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE;C:\Program Files (x86)\Windows Kits\10\include\10.0.10240.0\ucrt;C:\Program Files (x86)\Windows Kits\8.1\include\shared;C:\Program Files (x86)\Windows Kits\8.1\include\um;C:\Program Files (x86)\Windows Kits\8.1\include\winrt;
    SET LIB=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\LIB\amd64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.10240.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\8.1\lib\winv6.3\um\x64;
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\BIN\amd64;C:\WINDOWS\Microsoft.NET\Framework64\v4.0.30319;C:\WINDOWS\Microsoft.NET\Framework64\;C:\Program Files (x86)\Windows Kits\8.1\bin\x64;C:\Program Files (x86)\Windows Kits\8.1\bin\x86;;C:\WINDOWS\system32
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Users/moura/AppData/Local/Programs/Python/Python37-32/python.exe
    SET PYTHON_LIB_PATH=C:/Users/moura/AppData/Local/Programs/Python/Python37-32/lib/site-packages
    SET TEMP=C:\Users\moura\AppData\Local\Temp
    SET TF_CUDA_CLANG=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=7.5
    SET TF_CUDA_VERSION=10.1
    SET TF_CUDNN_VERSION=7
    SET TF_NEED_CUDA=1
    SET TF_NEED_OPENCL_SYCL=0
    SET TF_NEED_ROCM=0
    SET TMP=C:\Users\moura\AppData\Local\Temp
  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/link.exe /nologo /DLL /SUBSYSTEM:CONSOLE /MACHINE:X64 @bazel-out/x64_windows-opt/bin/external/protobuf_archive/python/google/protobuf/internal/_api_implementation.so-2.params
Execution platform: @bazel_tools//platforms:host_platform
   Creating library bazel-out/x64_windows-opt/bin/external/protobuf_archive/python/google/protobuf/internal/python/google/protobuf/internal/lib_api_implementation.so.ifso and object bazel-out/x64_windows-opt/bin/external/protobuf_archive/python/google/protobuf/internal/python/google/protobuf/internal/lib_api_implementation.so.exp
api_implementation.o : error LNK2019: unresolved external symbol __imp_PyModule_AddIntConstant referenced in function PyInit__api_implementation
api_implementation.o : error LNK2019: unresolved external symbol __imp_PyModule_Create2 referenced in function PyInit__api_implementation
bazel-out/x64_windows-opt/genfiles/external/local_config_python/python37.lib : warning LNK4272: library machine type 'X86' conflicts with target machine type 'x64'
bazel-out/x64_windows-opt/bin/external/protobuf_archive/python/google/protobuf/internal/_api_implementation.so : fatal error LNK1120: 2 unresolved externals
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 3.046s, Critical Path: 0.15s
INFO: 0 processes.
FAILED: Build did NOT complete successfully
"
30159,Enable SupervisedInputReceiver,"I want to serving a model with SupervisedInputReceiver, but I found this feature is not official supported by tensorflow. Is there replacement for this feature? if no, I suggest to enable this feature.


**System information**
- TensorFlow version (you are using): 1.13.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/export/export.py#L251
this class is not in the related __init__.py, so can't use it officially

**Will this change the current api? How?** I think no.

**Who will benefit with this feature?** who want to serve model with both input/output.
"
30158,No matching distribution found for every version of tensorflow,"I'm trying to install tensorflow-gpu for Windows 10 with the last version of pip and python 3.5.1.
the problem is that whenever i try to install via pip it gives me the error ""No matching distribution found for tensorflow-gpu"", and not only for the gpu version. I get the same error for:
pip install tensorflow
pip install tensorflow-cpu
pip install tensorflow-gpu
pip3 install tensorflow
pip3 install tensorflow-cpu
pip3 install tensorflow-gpu
pip install --upgrade <all of the above>
With the links on the tensorflow site i get ""ERROR: https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.13.1-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform."" I also tried to download the .whl first and then installing from there but got the same Error.

I tried many solutions on stack overflow and github but the result is always the same: no matching distribution or not supported wheel. I'm going crazy..."
30156,Memory Leak with tf.Tensor.getitem in tf.data.Dataset,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX and Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): `pipenv install --pre tensorflow==2.0.0-beta1`
- TensorFlow version (use command below): `2.0.0-beta1`
- Python version: `3.6.8`

**Describe the current behavior**
As described in [tf.slice](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/slice), I tried to use `tf.Tensor.getitem` to perform a slice in a more pythonic way, but ran into memory leaks. 

```python
def map_to_xy_dataset(csv_dataset, params):
    window_size = params[WINDOW_SIZE_KEY]
    window_shift = params[WINDOW_SHIFT_KEY]
    n_workers = tf.data.experimental.AUTOTUNE

    # MEMORY LEAK IN THIS FUNCTION
    def split_xy(window):
        # For X, select all but the last value and flatten
        range_x = tf.shape(window)[1] - 1
        
        # CAUSES MEMORY LEAK 
        x = tf.reshape(window[:, 0:range_x], [-1])


        # Select a single Y value
        # CAUSES MEMORY LEAK
        y = window[0, -1]

        return x, y

    # Turn the csv dataset row x col tensor
    row_dataset = csv_dataset.map(lambda *x: tf.reshape(x, [len(x)]))

    windowed_dataset = row_dataset.window(
        size=window_size, shift=window_shift,
        drop_remainder=True).flat_map(lambda x: x.batch(window_size))

    xy_dataset = windowed_dataset.map(split_xy, num_parallel_calls=n_workers)

    return xy_dataset
```

I have **not** tried to reproduce this behavior with  [tf.slice](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/slice). I will update this issue if I do. 

**Describe the expected behavior**
No memory leaks.

**Code to reproduce the issue**
See above.


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Initial related comment: https://github.com/tensorflow/tensorflow/issues/19049#issuecomment-505585437"
30151,Documentation Page - CSS is messed up,"Bug Description:

## URL(s) with the issue:
https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/package-summary

## Description of issue (what needs changing): Documentation page was unreadable on Safari for Mac. Please see the screenshot. On Subsequent page load it somehow loaded just fine.

### Clear description

See above
<img width=""1494"" alt=""Screen Shot 2019-06-25 at 2 29 37 PM"" src=""https://user-images.githubusercontent.com/395039/60135239-1eba0580-9756-11e9-9094-3430ab265841.png"">


### Correct links

N/A

### Parameters defined

N/A

### Returns defined

N/A

### Raises listed and defined

N/A

### Usage example

See attached screenshot

### Request visuals, if applicable

Yes, see attached screenshot

### Submit a pull request?

No"
30149,"Autograph ""Failed to parse source code"" error when using lambda in for loop","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
MacOSX 10.13.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
VERSION=2.0.0-dev20190625
GIT_VERSION=v1.12.1-4885-g71241a6afd
- Python version:
3.6.8
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
N/A
- GPU model and memory:
N/A

**Describe the current behavior**
I get an autograph error when running the following code (see the full stacktrace below):

```python
import tensorflow as tf
ds = tf.data.Dataset.range(10).window(5, shift=1, drop_remainder=True)
for window in ds.flat_map(lambda window: window.batch(5)):
    print(window.numpy())
```

The error is `ValueError: Failed to parse source code of <function <lambda> at 0x11194c488>`

**Describe the expected behavior**
Everything works fine when I define the dataset on the previous line like this:

```python
import tensorflow as tf
ds = tf.data.Dataset.range(10).window(5, shift=1, drop_remainder=True)
ds = ds.flat_map(lambda window: window.batch(5))
for window in ds:
    print(window.numpy())
```

**Code to reproduce the issue**
See above.

**Other info / logs**
Full stack trace with `AUTOGRAPH_VERBOSITY=10`:

```
2019-06-25 22:24:13.172683: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-25 22:24:13.197405: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa5e8a657c0 executing computations on platform Host. Devices:
2019-06-25 22:24:13.197445: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
Converted call: <function <lambda> at 0x134b81488>
    args: (<_VariantDataset shapes: (), types: tf.int64>,)
    kwargs: {}

Not whitelisted: <method-wrapper '__call__' of function object at 0x134b81488>: default rule
Not whitelisted: <function <lambda> at 0x134b81488>: default rule
Entity <function <lambda> at 0x134b81488> is not cached for key <code object <lambda> at 0x13b5f7ed0, file ""<ipython-input-1-8a83c4c9b193>"", line 4> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x13b641588>, frozenset())
Converting <function <lambda> at 0x134b81488>
WARNING: Logging before flag parsing goes to stderr.
E0625 22:24:13.215670 140735810999168 ag_logging.py:133] Error converting <function <lambda> at 0x134b81488>
Traceback (most recent call last):
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 78, in parse_entity
    return parse_str(source, preamble_len=len(future_features)), source
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 140, in parse_str
    module_node = gast.parse(src)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/gast/gast.py"", line 240, in parse
    return ast_to_gast(_ast.parse(*args, **kwargs))
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/ast.py"", line 35, in parse
    return compile(source, filename, mode, PyCF_ONLY_AST)
  File ""<unknown>"", line 5
    for window in ds.flat_map(lambda window: window.batch(5)):
                                                             ^
SyntaxError: unexpected EOF while parsing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 118, in parse_entity
    return parse_str(source, preamble_len=len(future_features)), source
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 140, in parse_str
    module_node = gast.parse(src)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/gast/gast.py"", line 240, in parse
    return ast_to_gast(_ast.parse(*args, **kwargs))
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/ast.py"", line 35, in parse
    return compile(source, filename, mode, PyCF_ONLY_AST)
  File ""<unknown>"", line 5
    for window in ds.flat_map(lambda window: window.batch(5)):
                                                             ^
SyntaxError: unexpected EOF while parsing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 635, in to_graph
    return conversion.convert(entity, program_ctx)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 322, in convert
    free_nonglobal_var_names)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 240, in _convert_with_cache
    entity, program_ctx)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 441, in convert_entity_to_ast
    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 601, in convert_func_to_ast
    node, source = parser.parse_entity(f, future_features=future_features)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 123, in parse_entity
    ' source to:\n{}\nBut that did not work.'.format(source))
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 66, in raise_parse_failure
    '{}'.format(entity, source, comment))
ValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
for window in ds.flat_map(lambda window: window.batch(5)):
If this is a lambda function, the error may be avoided by creating the lambda in a standalone statement. Tried to strip down the source to:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
for window in ds.flat_map(lambda window: window.batch(5)):
But that did not work.
ERROR: Error converting <function <lambda> at 0x134b81488>
Traceback (most recent call last):
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 78, in parse_entity
    return parse_str(source, preamble_len=len(future_features)), source
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 140, in parse_str
    module_node = gast.parse(src)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/gast/gast.py"", line 240, in parse
    return ast_to_gast(_ast.parse(*args, **kwargs))
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/ast.py"", line 35, in parse
    return compile(source, filename, mode, PyCF_ONLY_AST)
  File ""<unknown>"", line 5
    for window in ds.flat_map(lambda window: window.batch(5)):
                                                             ^
SyntaxError: unexpected EOF while parsing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 118, in parse_entity
    return parse_str(source, preamble_len=len(future_features)), source
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 140, in parse_str
    module_node = gast.parse(src)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/gast/gast.py"", line 240, in parse
    return ast_to_gast(_ast.parse(*args, **kwargs))
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/ast.py"", line 35, in parse
    return compile(source, filename, mode, PyCF_ONLY_AST)
  File ""<unknown>"", line 5
    for window in ds.flat_map(lambda window: window.batch(5)):
                                                             ^
SyntaxError: unexpected EOF while parsing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 635, in to_graph
    return conversion.convert(entity, program_ctx)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 322, in convert
    free_nonglobal_var_names)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 240, in _convert_with_cache
    entity, program_ctx)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 441, in convert_entity_to_ast
    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 601, in convert_func_to_ast
    node, source = parser.parse_entity(f, future_features=future_features)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 123, in parse_entity
    ' source to:\n{}\nBut that did not work.'.format(source))
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 66, in raise_parse_failure
    '{}'.format(entity, source, comment))
ValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
for window in ds.flat_map(lambda window: window.batch(5)):
If this is a lambda function, the error may be avoided by creating the lambda in a standalone statement. Tried to strip down the source to:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
for window in ds.flat_map(lambda window: window.batch(5)):
But that did not work.
Error transforming entity <function <lambda> at 0x134b81488>
Traceback (most recent call last):
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 78, in parse_entity
    return parse_str(source, preamble_len=len(future_features)), source
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 140, in parse_str
    module_node = gast.parse(src)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/gast/gast.py"", line 240, in parse
    return ast_to_gast(_ast.parse(*args, **kwargs))
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/ast.py"", line 35, in parse
    return compile(source, filename, mode, PyCF_ONLY_AST)
  File ""<unknown>"", line 5
    for window in ds.flat_map(lambda window: window.batch(5)):
                                                             ^
SyntaxError: unexpected EOF while parsing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 118, in parse_entity
    return parse_str(source, preamble_len=len(future_features)), source
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 140, in parse_str
    module_node = gast.parse(src)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/gast/gast.py"", line 240, in parse
    return ast_to_gast(_ast.parse(*args, **kwargs))
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/ast.py"", line 35, in parse
    return compile(source, filename, mode, PyCF_ONLY_AST)
  File ""<unknown>"", line 5
    for window in ds.flat_map(lambda window: window.batch(5)):
                                                             ^
SyntaxError: unexpected EOF while parsing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 635, in to_graph
    return conversion.convert(entity, program_ctx)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 322, in convert
    free_nonglobal_var_names)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 240, in _convert_with_cache
    entity, program_ctx)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 441, in convert_entity_to_ast
    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 601, in convert_func_to_ast
    node, source = parser.parse_entity(f, future_features=future_features)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 123, in parse_entity
    ' source to:\n{}\nBut that did not work.'.format(source))
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py"", line 66, in raise_parse_failure
    '{}'.format(entity, source, comment))
ValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
for window in ds.flat_map(lambda window: window.batch(5)):
If this is a lambda function, the error may be avoided by creating the lambda in a standalone statement. Tried to strip down the source to:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
for window in ds.flat_map(lambda window: window.batch(5)):
But that did not work.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 528, in converted_call
    experimental_optional_features=options.optional_features)
  File ""/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 639, in to_graph
    entity, e.__class__.__name__, str(e)))
tensorflow.python.autograph.impl.api.ConversionError: converting <function <lambda> at 0x134b81488>: ValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
for window in ds.flat_map(lambda window: window.batch(5)):
If this is a lambda function, the error may be avoided by creating the lambda in a standalone statement. Tried to strip down the source to:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
for window in ds.flat_map(lambda window: window.batch(5)):
But that did not work.
W0625 22:24:13.223130 140735810999168 ag_logging.py:146] Entity <function <lambda> at 0x134b81488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function <lambda> at 0x134b81488>: ValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
for window in ds.flat_map(lambda window: window.batch(5)):
If this is a lambda function, the error may be avoided by creating the lambda in a standalone statement. Tried to strip down the source to:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
for window in ds.flat_map(lambda window: window.batch(5)):
But that did not work.
WARNING: Entity <function <lambda> at 0x134b81488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function <lambda> at 0x134b81488>: ValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
for window in ds.flat_map(lambda window: window.batch(5)):
If this is a lambda function, the error may be avoided by creating the lambda in a standalone statement. Tried to strip down the source to:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
for window in ds.flat_map(lambda window: window.batch(5)):
But that did not work.
2019-06-25 22:24:13.243343: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1541] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
[0 1 2 3 4]
[1 2 3 4 5]
[2 3 4 5 6]
[3 4 5 6 7]
[4 5 6 7 8]
[5 6 7 8 9]"
30148,[TF 2.0] TPU Estimator cannot function without steps or max_steps,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): No
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): tensorflow==2.0.0b0
- Python version: 3.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:
- TPU: v2.8, TF Nightly.
You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
TPU Estimator Cannot function without steps or max_steps.
When provided, Any value of `max_steps` raises an `IteratorGetNext: End of Sequence Error`. However this error gets handled, and TPU Session Remains active even when there's no more code to execute.
**Describe the expected behavior**
TPU Estimator should run without `steps` or `max_steps` as mentioned in the documentation. It should stop the training process as soon as `tf.errors.OutOfRangeError` Rises.
**More Information (along with Code to Reproduce)**
Related Issue: https://github.com/captain-pool/GSOC/issues/12
Code: https://github.com/captain-pool/GSOC/blob/e7145c8d6c43545c4bcbde3cdd47f7cc53b1490c/E1_TPU_Sample/image_retraining_tpu.py

CC: @vbardiovskyg @srjoglekar246 
"
30144,Converting unsupported operation: TFLite_Detection_PostProcess,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 1.1.2.0


**Provide the text output from tflite_convert**

```
# Copy and paste here
Command:
$ bazel run -c opt tensorflow/lite/toco:toco -- --input_file=/models/research/object_detection/training/output/tflite_graph.pb --output_file=/models/research/object_detection/training/output/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --mean_values=128 --std_values=128 --change_concat_input_ranges=false --allow-custom-ops

Error:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.
We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.

```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30143,.fit method fails with unnamed Input layer whereas training works with a custom function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
- TensorFlow installed from (source or binary): from pip install
- TensorFlow version (use command below): v1.12.1-3259-gf59745a381 2.0.0-beta0
- Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14

**Describe the current behavior**

I use a model written with the Functional API which uses a DenseFeatures layer. The `call` method of the model and a custom training function work well even if the `Input` layer is unnamed, but the `fit` method fails. This forces me to name the `Input` layer the same name as the key of the dictionary given as input. I am note sure if this is intended or not, but as this works with a custom training function I tend to think it may be a bug in the `fit` method.

**Code to reproduce the issue**

Here is a minimal working example reproducing the issue.

```
import tensorflow as tf
print('Using Tensorflow version {} (git version {})'.format(tf.version.VERSION, tf.version.GIT_VERSION))
import numpy as np
from tensorflow.data import Dataset
from tensorflow.feature_column import numeric_column
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import DenseFeatures, Dense
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.optimizers import Adam

def make_model():
    fc1 = numeric_column('fc_name')
    dict_input = {'fc_name': Input(1)}
    
    out = DenseFeatures(fc1)(dict_input)
    out = Dense(5, name='dense_feature1')(out)
    out = Dense(1, name='dense_ouput')(out)
    
    return Model(inputs=dict_input, outputs=out)

array = np.ones((1000,1), dtype=np.float)
array_target = np.ones((1000,1), dtype=np.float)

batch_size = 4
dict_array = {'teddy_bear': array}
input_dataset = Dataset.from_tensor_slices(dict_array).batch(batch_size)
target_dataset = Dataset.from_tensor_slices(array_target).batch(batch_size)
complete_dataset = Dataset.zip((input_dataset, target_dataset)).shuffle(10000)

model = make_model()
#model.summary()
for x, y in complete_dataset.take(1):
    print(model(x))
    
loss_fn = MeanSquaredError()
optimizer = Adam(learning_rate=1e-3)

@tf.function
def train_step(inputs, target):
    with tf.GradientTape() as tape:
        outputs = model(inputs)
        loss = loss_fn(target, outputs)
    grads = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))
    return loss

EPOCHS = 5
loss = 0
for epoch in range(EPOCHS):
    for x, y in complete_dataset:
        loss = train_step(x, y)
    print('Epoch nÂ°{:d}, loss = {:5.4f}'.format(epoch + 1, loss))
for x, y in complete_dataset.take(1):
    print(model(x))
    
model = make_model()
model.summary()
model.compile(optimizer, loss_fn)
model.fit(complete_dataset, epochs=EPOCHS)
for x, y in complete_dataset.take(1):
    print(model(x))
```

The output of which is:

```
Using Tensorflow version 2.0.0-beta0 (git version v1.12.1-3259-gf59745a381)
tf.Tensor(
[[-0.18571138]
 [-0.18571138]
 [-0.18571138]
 [-0.18571138]], shape=(4, 1), dtype=float32)
Epoch nÂ°1, loss = 0.0035
Epoch nÂ°2, loss = 0.0000
Epoch nÂ°3, loss = 0.0000
Epoch nÂ°4, loss = 0.0000
Epoch nÂ°5, loss = 0.0000
tf.Tensor(
[[0.99999917]
 [0.99999917]
 [0.99999917]
 [0.99999917]], shape=(4, 1), dtype=float32)
Model: ""model_1""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
dense_features_1 (DenseFeatu (None, 1)                 0         
_________________________________________________________________
dense_feature1 (Dense)       (None, 5)                 10        
_________________________________________________________________
dense_ouput (Dense)          (None, 1)                 6         
=================================================================
Total params: 16
Trainable params: 16
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5

---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)
    446           if data[x].__class__.__name__ == 'DataFrame' else data[x]
--> 447           for x in names
    448       ]

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in <listcomp>(.0)
    446           if data[x].__class__.__name__ == 'DataFrame' else data[x]
--> 447           for x in names
    448       ]

KeyError: 'input_2'

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<ipython-input-1-d41b98ef4a37> in <module>
     59 model.summary()
     60 model.compile(optimizer, loss_fn)
---> 61 model.fit(complete_dataset, epochs=EPOCHS)
     62 for x, y in complete_dataset.take(1):
     63     print(model(x))

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    641         max_queue_size=max_queue_size,
    642         workers=workers,
--> 643         use_multiprocessing=use_multiprocessing)
    644 
    645   def evaluate(self,

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    692         shuffle=shuffle,
    693         initial_epoch=initial_epoch,
--> 694         steps_name='steps_per_epoch')
    695 
    696   def evaluate(self,

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)
    262 
    263       is_deferred = not model._is_compiled
--> 264       batch_outs = batch_function(*batch_data)
    265       if not isinstance(batch_outs, list):
    266         batch_outs = [batch_outs]

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)
    894     x, y, sample_weights = self._standardize_user_data(
    895         x, y, sample_weight=sample_weight, class_weight=class_weight,
--> 896         extract_tensors_from_dataset=True)
    897 
    898     # If `self._distribution_strategy` is True, then we are in a replica context

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)
   2426           feed_input_shapes,
   2427           check_batch_axis=False,  # Don't enforce the batch size.
-> 2428           exception_prefix='input')
   2429 
   2430     if y is not None:

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)
    449     except KeyError as e:
    450       raise ValueError('No data provided for ""' + e.args[0] + '"". Need data '
--> 451                        'for each key in: ' + str(names))
    452   elif isinstance(data, (list, tuple)):
    453     if isinstance(data[0], (list, tuple)):

ValueError: No data provided for ""input_2"". Need data for each key in: ['input_2']

```
We see on the output that the `call` method of the model works and that the training with  the custom function also works. We also see in the error log that the error is due to the `Input` layer, named `input_2`, not finding the key `input_2` in the dictionaries produced by `complete_dataset`.

Now, in the code above, if we replace the line `dict_input = {'fc_name': Input(1)}` by `dict_input = {'fc_name': Input(1, name='teddy_bear')}`, everything works and the output looks like this:

```
Using Tensorflow version 2.0.0-beta0 (git version v1.12.1-3259-gf59745a381)
tf.Tensor(
[[0.7686093]
 [0.7686093]
 [0.7686093]
 [0.7686093]], shape=(4, 1), dtype=float32)
Epoch nÂ°1, loss = 0.0000
Epoch nÂ°2, loss = 0.0000
Epoch nÂ°3, loss = 0.0000
Epoch nÂ°4, loss = 0.0000
Epoch nÂ°5, loss = 0.0000
tf.Tensor(
[[0.99999994]
 [0.99999994]
 [0.99999994]
 [0.99999994]], shape=(4, 1), dtype=float32)
Model: ""model_1""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
teddy_bear (InputLayer)      [(None, 1)]               0         
_________________________________________________________________
dense_features_1 (DenseFeatu (None, 1)                 0         
_________________________________________________________________
dense_feature1 (Dense)       (None, 5)                 10        
_________________________________________________________________
dense_ouput (Dense)          (None, 1)                 6         
=================================================================
Total params: 16
Trainable params: 16
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
250/250 [==============================] - 1s 2ms/step - loss: 0.0325
Epoch 2/5
250/250 [==============================] - 0s 1ms/step - loss: 3.5115e-14
Epoch 3/5
250/250 [==============================] - 0s 2ms/step - loss: 1.4211e-14
Epoch 4/5
250/250 [==============================] - 0s 1ms/step - loss: 1.4211e-14
Epoch 5/5
250/250 [==============================] - 0s 1ms/step - loss: 1.4211e-14
tf.Tensor(
[[1.0000002]
 [1.0000002]
 [1.0000002]
 [1.0000002]], shape=(4, 1), dtype=float32)
```
"
30141,"""Iterator::Model::Prefetch::Batch::Shuffle::ParallelInterleaveV2"" returned OutOfRange without setting *end_of_sequence","See https://github.com/tensorflow/tensorflow/issues/29060#issuecomment-505539468 for more details 

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX and Linux
- TensorFlow installed from (source or binary): `pipenv install --pre tensorflow==2.0.0-beta1`
- TensorFlow version (use command below): 2.0.0-beta1
- Python version: 3.6.8

**Describe the current behavior**
I'm running into this issue when caching before `interleave`

```python
    filenames_dataset = filenames_dataset.cache(""./some_path"")

    return filenames_dataset.interleave(
        lambda f: map_file_to_xy_dataset(f, predict_task_fn, params),
        cycle_length=params[CYCLE_LENGTH_KEY],
        block_length=params[BLOCK_LENGTH_KEY],
        num_parallel_calls=tf.data.experimental.AUTOTUNE)
```

```
Iterator ""Iterator::Model::Prefetch::Batch::Shuffle::ParallelInterleaveV2"" returned OutOfRange without setting `*end_of_sequence`. This indicates that an error may have occurred. Original message: Attempting to call get_next after iteration should have finished. [Op:IteratorGetNextSync]
```


**Describe the expected behavior**

Able to cache the `filenames_dataset`

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

See above

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

"
30134,Extract result ( prediction ) from tflite android,"I have converted a model with ( .ckpt files ) to .pb frozen model and I will convert this frozen model to tflite model to get it worked on Android device.
In effects, The model is trained using CNN facial landmarks project to get a prediction of eye region by drawing points ( landmarks ) on the contour of the eye like this:

![dsaa](https://user-images.githubusercontent.com/19480228/60110918-3d77c680-976d-11e9-8716-d6121d8c3469.PNG)

**System information**

+ **Tensorflow Version** : 1.13
+ **OS version** : Windows 10 x64
+ **Android studio version** :3.4
+ **Graphic Card**: Nvidia Geforce 840m

My question is how can I extract the points got from logits layer ( last layer )?
Note that I have successfully print the coordinates of points : 
    `
logits = tf.layers.dense(
        inputs=dense1,
        units=80,
        activation=None,
        use_bias=True,
        name=""logits"")
`
 `   predictions_dict = {
        ""name"": features['name'],
        ""logits"": logits  
`
` predictions = estimator.predict(input_fn=_predict_input_fn)
        for _, result in enumerate(predictions):
            img = cv2.imread(result['name'].decode('ASCII') + '.jpg')
            print(result['logits']) # print the landmarks
            marks = np.reshape(result['logits'], (-1, 2)) * IMG_WIDTH
            for mark in marks:
                cv2.circle(img, (int(mark[0]), int(
                    mark[1])), 1, (0, 255, 0), -1, cv2.LINE_AA)
            img = cv2.resize(img, (512, 512))
            cv2.imshow('result', img)`

"
30131,"Unsupported cumsum, cumprod and scatter_nd ops","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): from binary
- TensorFlow version (or github SHA if from source): 1.13.1


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ABS, ADD, CAST, CONCATENATION, EQUAL, EXPAND_DIMS, FULLY_CONNECTED, GATHER, LESS, MEAN, MUL, PACK, PAD, RANGE, REDUCE_MAX, RELU, RESHAPE, RSQRT, SHAPE, SIN, SOFTMAX, SQUARED_DIFFERENCE, SQUEEZE, STRIDED_SLICE, SUB, SUM, TILE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: Cumprod, Cumsum, ScatterNd.
```

**Any other info / logs**

I am trying to convert a transformer model built using [tensor2tensor](https://github.com/tensorflow/tensor2tensor), but the implementation in that repo uses `cumsum`, `cumprod` and `scatter_nd`, which makes it unusable with the TF Lite converter..."
30129,TPU error in eager execution,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow version (use command below): 1.14.0
- Python version: 3.6
- GPU model and memory: N/A


**Describe the current behavior**
InternalError: Failed copying input tensor from /job:worker/replica:0/task:0/device:CPU:0 to /job:worker/replica:0/task:1/device:CPU:0 in order to run ExperimentalAutoShardDataset: Unable to parse tensor proto Additional GRPC error information: {""created"":""@1561473418.214771131"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1

I get the above error when running model.fit . For my input pipeline , I use tf.Records in conjunction with the Dataset API and feed in a batch of numpy arrays as input and labels to the model.fit function.
I am fairly certain that I am not exceeding any tensor memory limits and all my operations are well within the 2Gb limit and all my dtypes are either float32 or int32

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30127,broken image link in recurrent_quickdraw.md,"Description of issue: The image link for quickdraw_model.png is broken in document [recurrent_quickdraw.md](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/sequences/recurrent_quickdraw.md) 

The current source url for the image points to non existent image location.

Url: [recurrent_quickdraw.md](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/sequences/recurrent_quickdraw.md)
"
30126,Memory leaking in tf.data.Dataset in eager mode tensorflow1.12.0,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (MacBook Pro10.14):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (pip install tensorflow-gpu):
- TensorFlow version (1.12.0):
- Python version:3.6.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
At the beginning of the program, the memory is only 190MB. After running for 1 minute, the memory reaches 6GB. Memory leak is very serious

**Describe the expected behavior**

The program should always be the initial state of 190MB without memory leaks.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


class RecordDataset:
    def __init__(self, configs):
        assert(isinstance(configs, dict))
        self.norm_h = 32
        if 'norm_h' in configs:
            self.norm_h = int(configs['norm_h'])
        self.expand_rate = 1.0
        if 'expand_rate' in configs:
            self.expand_rate = float(configs['expand_rate'])
        self.file_list = []
        if 'file_list' in configs:
            self.set_files(configs['file_list'])
        self.num_parallel=4
        if 'num_parallel' in configs:
            self.num_parallel = int(configs['num_parallel'])
        self.batch_size = 32
        if 'batch_size' in configs:
            self.batch_size = int(configs['batch_size'])

        self.max_txtlen = 32
        if 'max_txtlen' in configs:
            self.max_txtlen = int(configs['max_txtlen'])
        self.max_imglen = 1024
        if 'max_imglen' in configs:
            self.max_imglen = int(configs['max_imglen'])
        self.min_imglen = 16
        if 'min_imglen' in configs:
            self.min_imglen = int(configs['min_imglen'])
        self.BUFFER_SIZE = 4096
        if 'BUFFER_SIZE' in configs:
            self.BUFFER_SIZE = int(configs['BUFFER_SIZE'])

        self.char_dict = configs['char_dict']
        self.model_type = configs['model_type']
        self.charset = Charset(self.char_dict, self.model_type)

    def set_files(self, file_list):
        assert(isinstance(file_list, (list, tuple)))
        self.file_list = [file for file in file_list if os.path.isfile(file) and os.path.getsize(file)>0]

    def get_idstr_by_charstr(self, charstr):
        if isinstance(charstr, bytes):
            charstr = charstr.decode('utf-8')
        idxstr = self.charset.get_idxstr_by_charstr(charstr)
        idxlen = len(idxstr.split(','))
        return idxstr, idxlen

    def parse_example(self, serial_example):
        norm_h = self.norm_h
        expand_rate = self.expand_rate
        debug = False

        feat_dict = tf.parse_single_example(serial_example,features={
                                            'img_raw' : tf.FixedLenFeature([], tf.string), \
                                            'height'  : tf.FixedLenFeature([], tf.int64),  \
                                            'width'   : tf.FixedLenFeature([], tf.int64),  \
                                            'channel' : tf.FixedLenFeature([], tf.int64),  \
                                            'img_path': tf.FixedLenFeature([], tf.string), \
                                            'coord'   : tf.FixedLenFeature([], tf.string), \
                                            'label'   : tf.FixedLenFeature([], tf.string)})

        img_raw = feat_dict['img_raw']
        height = feat_dict['height']
        width = feat_dict['width']
        channel = feat_dict['channel']
        img_path = feat_dict['img_path']
        coord = feat_dict['coord']
        img_text = feat_dict['label']
        txt_index, txt_len = tf.py_func(self.get_idstr_by_charstr, [img_text], [tf.string, tf.int64])
        txt_len = tf.to_int32(txt_len)

        coord_val = tf.string_split([coord], ',').values
        coord_val = tf.string_to_number(coord_val, out_type=tf.int32)
        offset_w = coord_val[0]
        offset_h = coord_val[1]
        target_w = coord_val[2] - coord_val[0]
        target_h = coord_val[3] - coord_val[1]

        img_raw = tf.decode_raw(img_raw, tf.uint8)
        orig_img = tf.reshape(img_raw, (height, width, channel))
        crop_img = tf.image.crop_to_bounding_box(orig_img, offset_h, offset_w, target_h, target_w)

        ratio = tf.to_float(norm_h / tf.to_float(target_h))
        norm_w = tf.to_int32(tf.to_float(target_w) * expand_rate * ratio)
        norm_img = tf.image.resize_images(crop_img, (norm_h, norm_w))

        if debug:
            norm_img = tf.cast(norm_img, tf.uint8)
        else:
            # convert RGB-->BGR
            mean = [102.9801, 115.9465, 122.7717]
            norm_img = norm_img[:, :, ::-1]
            norm_img = norm_img - mean
        return img_path, norm_img, img_text, txt_index, txt_len, coord, norm_w

    def filter(self, img_path, norm_img, img_text, txt_index, txt_len, coord, norm_w):
        img_len = tf.cast(norm_w, dtype=tf.int32)
        txt_len = tf.cast(txt_len, dtype=tf.int32)
        txt_len_logical = tf.logical_and(txt_len <= self.max_txtlen, txt_len >= 0)
        img_len_logical = tf.logical_and(img_len <= self.max_imglen,img_len >= self.min_imglen)
        return tf.logical_and(txt_len_logical, img_len_logical)

    def data_reader_v0(self, repeat=0):
        padded_shapes = ([], [self.norm_h, None, 3], [], [], [], [], [])
        padding_values = ('', 0.0, '', '', 0, '', 0)
        dataset = tf.data.TFRecordDataset(self.file_list)
        if repeat != 0:
            dataset = dataset.repeat(repeat)
        dataset = dataset.map(map_func=self.parse_example, num_parallel_calls=self.num_parallel)
        dataset = dataset.padded_batch(self.batch_size, padded_shapes, padding_values)
        return dataset

    def data_reader(self, repeat=0):
        padded_shapes = ([], [self.norm_h, None, 3], [], [], [], [], [])
        padding_values = ('', 0.0, '', '', 0, '', 0)
        fileset = tf.data.Dataset.list_files(self.file_list)
        dataset = fileset.apply(
                    tf.data.experimental.parallel_interleave(
                        lambda filename: tf.data.TFRecordDataset(
                            filename, num_parallel_reads=self.num_parallel),
                        cycle_length=32))

        if repeat != 0:
            dataset = dataset.repeat(repeat)
        else:
            dataset = dataset.repeat()
        dataset = dataset.map(map_func=self.parse_example, num_parallel_calls=self.num_parallel)
        dataset = dataset.filter(self.filter)
        dataset = dataset.cache()
        dataset = dataset.shuffle(self.BUFFER_SIZE).padded_batch(self.batch_size, padded_shapes, padding_values)
        dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)
        #dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)
        return dataset


def RecordDatasetTest():
    tf.enable_eager_execution()

    configs = {}
    configs['norm_h'] = 32
    configs['expand_rate'] = 1.0
    configs['file_list'] = ['tfrecord_dir/tfrecord.list.0', 'tfrecord_dir/tfrecord.list.1']
    configs['num_parallel'] = 4
    configs['batch_size'] = 1
    configs['model_type'] = 'ctc'

    configs['char_dict'] = 'char_dict.lst'
    dataset = RecordDataset(configs)
    dataset = dataset.data_reader()
    total_count = 0
    for line in dataset:
        img_path, norm_img, img_text, txt_index, txt_len, coord, norm_w = line
        norm_img = norm_img + [102.9801, 115.9465, 122.7717]
        image = np.array(norm_img.numpy(), np.uint8)
        img_path = img_path.numpy()
        img_text = img_text.numpy()
        txt_index = txt_index.numpy()
        txt_len = txt_len.numpy()
        total_count = total_count + txt_len
    print(total_count)


if __name__=='__main__':
    RecordDatasetTest()

"
30124,Get input shape in tf.keras.Model (Imperative API),"I use Tensorflow 2.0 and I have a model that was defined in Imperative API. In call method I use something like this:

```python
b, h, w, c = images.shape
k_h, k_w = kernels.shape[2], kernels.shape[3]

images = tf.transpose(images, [1, 2, 0, 3])  # (h, w, b, c)
new_shape = tf.TensorShape([1, h, w, b * c])
images = tf.reshape(images, new_shape)
```

When I train my model with custom loop -- no problem. But I want to porting my model to SavedModel format. I use the following function:

```python
tf.keras.experimental.export_saved_model(
        model, file_path,
        serving_only=True,
        input_signature=[
                tf.TensorSpec(shape=[None, None, None, 3], dtype=tf.float32),
            ]
        )
```

And i got error:

```
TypeError: unsupported operand type(s) for *: 'NoneType' and 'int'
```

Moreover, I can't do it even If I specify shape=[1, None, None, 3], because I got:

```
ValueError: Tried to convert 'shape' to a tensor and failed. Error: Cannot convert a partially known TensorShape to a Tensor: (1, None, None, 3)
```

It means that I can't do reshape at all. But I need it. How can I do it?"
30122,Getting validation steps from dict breaks keras fit TF 2.0.0-beta1,"**System information**
- TensorFlow installed from: pip
- TensorFlow version: 2.0.0-beta1
- Python version: 3.6


**Describe the current behavior**
When calling fit on a Keras model in 2.0.0-beta1 a ` KeyError: 0` is thrown when trying to call fit with validation_data given as a dict (this worked in the alpha)

e.g.
```
mymodel.fit(x = {'input_0' : train_data_type_0, 'input_1':  train_data_type_1}, y = train_labels, 
         validation_data = ({'input_0' : val_data_type_0, 'input_1':  val_data_type_1}, val_labels) )
```
The issue seems to have been introduced [here](https://github.com/tensorflow/tensorflow/commit/25380986954692d947bd230e4f5d3a2d11dd3064), as the line:
`val_samples_or_steps = val_inputs and val_inputs[0].shape[0] or None`
assumes an array will be found and fails for dicts. 

**Describe the expected behaviour**
`val_inputs: Either a list or dictionary of arrays, or a dataset instance.`
"
30121,About `Evaluator` in TF_CONFIG,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): master
- Python version: 2.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 
- GPU model and memory:

**Describe the current behavior**
The `evaluator` in `TF_CONFIG` makes me confused. In `RunConfig` document, I found the `evaluator` should not be in `cluster`. For example, 
```  
cluster = {'chief': ['host0:2222'],
             'ps': ['host1:2222', 'host2:2222'],
             'worker': ['host3:2222', 'host4:2222', 'host5:2222']}
os.environ['TF_CONFIG'] = json.dumps(
      {'cluster': cluster,
       'task': {'type': 'evaluator', 'index': 0}})
```
This means the `evaluator` is not part of training cluster.  So it is not going to be in the `cluster_spec`.
However, in `DistributionStrategy` there is a check to find `evaluator` node in `cluster_spec`. For example, in `tensorflow/python/distribute/multi_worker_util.py`, there is a function named `_validate_cluster_spec`. 
```
  if task_type not in (""chief"", ""worker"", ""evaluator"", ""ps""):
    raise ValueError(
        ""Unrecognized task_type: %r, valid task types are: \""chief\"", ""
        ""\""worker\"", \""evaluator\"" and \""ps\""."" % task_type)

  if task_type and task_type not in cluster_spec:
    raise ValueError(""`task_type` %r not found in cluster_spec."" % task_type)

```
That means if the `task_type` is `evaluator`, it should be in `cluster_spec`. This is inconsistent with what is stated in the document above.  So what should `TF_CONFIG` be like when I want to use `DistributionStrategy` in training and single mode in evaluation? I try many times but failed because of this check. So it is better to give an example about how to construct `TF_CONFIG`. Thanks very much.
@yuefengz @anj-s 
"
30120,Attempt to convert a value (1.0) with an unsupported type (<class 'numpy.float32'>) to a Tensor.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No, I have used the example script from [https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor](url)

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
pip install (binary)
- TensorFlow version (use command below):
2.0.0-beta1
- Python version:
3.6.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
10.0
- GPU model and memory:
GeForce GTX 1050, 4GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I was trying to convert a numpy array to a tensorflow tensor as in the example code.
**Describe the expected behavior**
Should give back tensor (as it works properly in earlier versions)
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
`import numpy as np

def my_func(arg):
  arg = tf.convert_to_tensor(arg, dtype=tf.float32)
  return tf.matmul(arg, arg) + arg

#The following calls are equivalent.
`import numpy as np

def my_func(arg):
  arg = tf.convert_to_tensor(arg, dtype=tf.float32)
  return tf.matmul(arg, arg) + arg

#The following calls are equivalent.
value_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]])) 
value_2 = my_func([[1.0, 2.0], [3.0, 4.0]]) 
value_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32)) `

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
`---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-1-f167d18ea32e> in <module>
      9 value_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))
     10 value_2 = my_func([[1.0, 2.0], [3.0, 4.0]])
---> 11 value_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))

<ipython-input-1-f167d18ea32e> in my_func(arg)
      3 
      4 def my_func(arg):
----> 5   arg = tf.convert_to_tensor(arg, dtype=tf.float32)
      6   return tf.matmul(arg, arg) + arg
      7 

~\Anaconda3\envs\Tensorflow_2_0_Beta\lib\site-packages\tensorflow\python\framework\ops.py in convert_to_tensor_v2(value, dtype, dtype_hint, name)
   1156       name=name,
   1157       preferred_dtype=dtype_hint,
-> 1158       as_ref=False)
   1159 
   1160 

~\Anaconda3\envs\Tensorflow_2_0_Beta\lib\site-packages\tensorflow\python\framework\ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)
   1235 
   1236     if ret is None:
-> 1237       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1238 
   1239     if ret is NotImplemented:

~\Anaconda3\envs\Tensorflow_2_0_Beta\lib\site-packages\tensorflow\python\framework\constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
    303                                          as_ref=False):
    304   _ = as_ref
--> 305   return constant(v, dtype=dtype, name=name)
    306 
    307 

~\Anaconda3\envs\Tensorflow_2_0_Beta\lib\site-packages\tensorflow\python\framework\constant_op.py in constant(value, dtype, shape, name)
    244   """"""
    245   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--> 246                         allow_broadcast=True)
    247 
    248 

~\Anaconda3\envs\Tensorflow_2_0_Beta\lib\site-packages\tensorflow\python\framework\constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    252   ctx = context.context()
    253   if ctx.executing_eagerly():
--> 254     t = convert_to_eager_tensor(value, ctx, dtype)
    255     if shape is None:
    256       return t

~\Anaconda3\envs\Tensorflow_2_0_Beta\lib\site-packages\tensorflow\python\framework\constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
    113     return t
    114   else:
--> 115     return ops.EagerTensor(value, handle, device, dtype)
    116 
    117 

ValueError: Attempt to convert a value (1.0) with an unsupported type (<class 'numpy.float32'>) to a Tensor.
`"
30119,Saver's restore method uses deprecated checkpoint_exists method.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes, I have written custom Python code.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
macOS Mojave 10.14.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
No
- TensorFlow installed from (source or binary):
Binary using pip
- TensorFlow version (use command below):
('v1.9.0-0-g25c197e023', '1.9.0')
- Python version:
Python 3.6.5
- Bazel version (if compiling from source):
NA
- GCC/Compiler version (if compiling from source):
NA
- CUDA/cuDNN version:
NA
- GPU model and memory:
Intel Iris Pro 1536 MB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I try to restore previously saved checkpoint variables and I get a method deprecated error.

**Describe the expected behavior**
I could restore checkpoints.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import os
import tensorflow as tf

graph_path = os.path.join('plant_disease_classification/ckpts/', 'plants-disease-model.meta')
checkpoint_path = os.path.join('plant_disease_classification/ckpts/', 'plants-disease-model')

session = tf.compat.v1.Session()
saver = tf.compat.v1.train.import_meta_graph(graph_path)
# get error on line below
saver.restore(session, checkpoint_path)
# and try this as well same depracation error
saver.restore(session, tf.train.latest_checkpoint('plant_disease_classification/ckpts/'))
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
WARNING: Logging before flag parsing goes to stderr.
W0625 14:28:02.910645 4579825088 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
```"
30118,Op type not registered 'LeakyRelu' in binary running on some PC.,"**Tensorflow version:**
Due to some problems according to the production environment, I only can use the tensorflow 1.9 or 1.10.

**Problem description**
I'm trying to deploy the yolov3 trained model through the c++ api. The trained model are coming from these two repositories, [`tensorflow-yolov3`](https://github.com/YunYang1994/tensorflow-yolov3) and  [`keras-yolo3`](https://github.com/qqwweee/keras-yolo3). 
However, when I was creating the session by using the graph definition, the session create status report that ""Op type not registered 'LeakyRelu' in binary running on my pc"".
`    auto session = std::unique_ptr<tensorflow::Session>();
    session.reset(tensorflow::NewSession(tensorflow::SessionOptions()));
    Status session_create_status = session->Create(graph_def);
    if (!session_create_status.ok())
    {
        throw std::runtime_error(session_create_status.error_message());
    }`

**Operating System Information**
I test my code on both ubuntu 18.04 and Windows10. The error is the same.
**Some research**
I tried to use the tensorflow 1.9 and tensorflow 1.10 at the same time, but the problem is the same. I read the tensorflow api and I found that the tf.nn module has the leaky relu operation but the c++ api does not.
Is there any possibility to add the support of leaky relu throught c++ api on the old version of tensorflow?"
30117,Makefile build broken on macOS,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 10.14.5 (18F203)
- TensorFlow installed from (source or binary): source
- TensorFlow version: 8e423e3d56390671f0d954c90f4fd163ab02a9c1
- Python version: 2.7 (but not building pip package)
- Bazel version (if compiling from source): not used
- GCC/Compiler version (if compiling from source):
```
Apple LLVM version 10.0.1 (clang-1001.0.46.4)
Target: x86_64-apple-darwin18.6.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin
```

**Describe the problem**

I am followin https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile on macOS Mojave.

Running
```
bash tensorflow/contrib/makefile/build_all_linux.sh
```
terminates with the error
```
Undefined symbols for architecture x86_64:
  ""_CFRelease"", referenced from:
      absl::time_internal::cctz::local_time_zone() in time_zone_lookup.o
  ""_CFStringGetCString"", referenced from:
      absl::time_internal::cctz::local_time_zone() in time_zone_lookup.o
  ""_CFStringGetLength"", referenced from:
      absl::time_internal::cctz::local_time_zone() in time_zone_lookup.o
  ""_CFStringGetMaximumSizeForEncoding"", referenced from:
      absl::time_internal::cctz::local_time_zone() in time_zone_lookup.o
  ""_CFTimeZoneCopyDefault"", referenced from:
      absl::time_internal::cctz::local_time_zone() in time_zone_lookup.o
  ""_CFTimeZoneGetName"", referenced from:
      absl::time_internal::cctz::local_time_zone() in time_zone_lookup.o
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
```

May this come from not having XCode installed? I assume the (seemingly missing) Core Foundation libraries are shipped with macOS regardless. But it is listed as a dependency for iOS, so maybe macOS should be mentioned thereabouts as well?

Update: The makefile seems to link the CoreFoundation framework only for iOS, the comment notwithstanding.
https://github.com/tensorflow/tensorflow/blob/2f4121b1a7266aef4007457aa348c5f7f01eb539/tensorflow/contrib/makefile/Makefile#L912

I added
```
ifeq ($(TARGET),OSX)
    HOST_LDOPTS += -framework CoreFoundation
endif
```
and the compilation proceeds at least (can't say whether it will succeed yet)."
30116,Error in training ssd_mobilenet_v1_pets.config for my own dataset,"Hi,
Iam getting this error when i run the command-  python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config


/home/shilpa.j/.local/lib/python3.6/site-packages/tensorflow/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.
  warnings.warn(""Attempting to use a closed FileWriter. ""
Traceback (most recent call last):
  File ""train.py"", line 184, in <module>
    tf.app.run()
  File ""/home/shilpa.j/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/shilpa.j/.local/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/shilpa.j/.local/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/home/shilpa.j/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""train.py"", line 180, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/opt/tensorflow/models/research/object_detection/legacy/trainer.py"", line 416, in train
    saver=saver)
  File ""/home/shilpa.j/.local/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 790, in train
    ignore_live_threads=ignore_live_threads)
  File ""/home/shilpa.j/.local/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py"", line 839, in stop
    ignore_live_threads=ignore_live_threads)
  File ""/home/shilpa.j/.local/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/home/shilpa.j/.local/lib/python3.6/site-packages/six.py"", line 693, in reraise
    raise value
  File ""/home/shilpa.j/.local/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py"", line 257, in _run
    enqueue_callable()
  File ""/home/shilpa.j/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1279, in _single_operation_run
    self._call_tf_sessionrun(None, {}, [], target_list, None)
  File ""/home/shilpa.j/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: image_size must contain 3 elements[4]
         [[{{node cond_1/RandomCropImage/sample_distorted_bounding_box/SampleDistortedBoundingBoxV2}}]]
shilpa.j@Theorem-TrainUP:/opt/tensorflow/models/research/object_detection$
"
30115,Tensorboard embeddings mnist example crashes,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution Windows 10 Pro 64-bit
- TensorFlow installed from binary
- TensorFlow version: b'v1.13.1-0-g6612da8951' 1.13.1
- Python version: 3.6
- CUDA/cuDNN version: 10.0/7.6.0
- GPU model and memory: GeForce GTX 1070 8Mb

**Describe the current behavior**
When attempting to run the following example, https://keras.io/examples/tensorboard_embeddings_mnist/, I get a crash after the first epoch.

I get the following error message:

```
2019-06-25 11:33:16.177546: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at strided_slice_op.cc:308 : Not found: Resource localhost/features_embedding/class tensorflow::Var does not exist.
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\client\session.py"", line 1334, in _do_call
    return fn(*args)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\client\session.py"", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\client\session.py"", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.NotFoundError: Resource localhost/features_embedding/class tensorflow::Var does not exist.
	 [[{{node strided_slice/_assign}}]]
	 [[{{node ReadVariableOp_1}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2018.2.4\helpers\pydev\pydevd.py"", line 1664, in <module>
    main()
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2018.2.4\helpers\pydev\pydevd.py"", line 1658, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2018.2.4\helpers\pydev\pydevd.py"", line 1068, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2018.2.4\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""X:/CoreTech/LTI791_FaceEncoding/Research/Python/Faces/Encoding/Scripts/MNISTExample.py"", line 84, in <module>
    validation_data=(x_test, y_test))
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 880, in fit
    validation_steps=validation_steps)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\engine\training_arrays.py"", line 370, in model_iteration
    callbacks.on_epoch_end(epoch, epoch_logs, mode=mode)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\callbacks.py"", line 251, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\callbacks.py"", line 1204, in on_epoch_end
    K.sess.run(self.assign_embeddings, feed_dict=feed_dict)
AttributeError: module 'tensorflow.python.keras.backend' has no attribute 'sess'
```

This was fixed using the following change set tensorflow/tensorflow@d994300

I now get the following error:

```
Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2018.2.4\helpers\pydev\pydevd.py"", line 1664, in <module>
    main()
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2018.2.4\helpers\pydev\pydevd.py"", line 1658, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2018.2.4\helpers\pydev\pydevd.py"", line 1068, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2018.2.4\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""X:/CoreTech/LTI791_FaceEncoding/Research/Python/Faces/Encoding/Scripts/MNISTExample.py"", line 84, in <module>
    validation_data=(x_test, y_test))
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 880, in fit
    validation_steps=validation_steps)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\engine\training_arrays.py"", line 370, in model_iteration
    callbacks.on_epoch_end(epoch, epoch_logs, mode=mode)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\callbacks.py"", line 251, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\callbacks.py"", line 1204, in on_epoch_end
    sess.run(self.assign_embeddings, feed_dict=feed_dict)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\client\session.py"", line 929, in run
    run_metadata_ptr)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\client\session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\client\session.py"", line 1328, in _do_run
    run_metadata)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\client\session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: Resource localhost/features_embedding/class tensorflow::Var does not exist.
	 [[node strided_slice/_assign (defined at X:/CoreTech/LTI791_FaceEncoding/Research/Python/Faces/Encoding/Scripts/MNISTExample.py:84) ]]
	 [[node ReadVariableOp_1 (defined at X:/CoreTech/LTI791_FaceEncoding/Research/Python/Faces/Encoding/Scripts/MNISTExample.py:84) ]]

Caused by op 'strided_slice/_assign', defined at:
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2018.2.4\helpers\pydev\pydevd.py"", line 1664, in <module>
    main()
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2018.2.4\helpers\pydev\pydevd.py"", line 1658, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2018.2.4\helpers\pydev\pydevd.py"", line 1068, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2018.2.4\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""X:/CoreTech/LTI791_FaceEncoding/Research/Python/Faces/Encoding/Scripts/MNISTExample.py"", line 84, in <module>
    validation_data=(x_test, y_test))
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 880, in fit
    validation_steps=validation_steps)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\engine\training_arrays.py"", line 215, in model_iteration
    mode=mode)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\callbacks.py"", line 106, in configure_callbacks
    callback_list.set_model(callback_model)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\callbacks.py"", line 178, in set_model
    callback.set_model(model)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\keras\callbacks.py"", line 1051, in set_model
    embedding_input)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\ops\state_ops.py"", line 224, in assign
    return ref.assign(value, name=name)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 844, in assign
    shrink_axis_mask=shrink_axis_mask)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\ops\resource_variable_ops.py"", line 1163, in _strided_slice_assign
    shrink_axis_mask=shrink_axis_mask))
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 8576, in resource_strided_slice_assign
    name=name)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\framework\ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""C:\ProgramData\Anaconda2\envs\py36new\lib\site-packages\tensorflow\python\framework\ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

NotFoundError (see above for traceback): Resource localhost/features_embedding/class tensorflow::Var does not exist.
	 [[node strided_slice/_assign (defined at X:/CoreTech/LTI791_FaceEncoding/Research/Python/Faces/Encoding/Scripts/MNISTExample.py:84) ]]
	 [[node ReadVariableOp_1 (defined at X:/CoreTech/LTI791_FaceEncoding/Research/Python/Faces/Encoding/Scripts/MNISTExample.py:84) ]]
```

**Describe the expected behavior**
My aim is to find a working example that allows me to visualize weights/gradients etc in tensorboard. I would expect this example to run multiple epochs saving the embedding layer data to a log file for each epoch so I can visualize it using tensorboard. 

**Code to reproduce the issue**
https://keras.io/examples/tensorboard_embeddings_mnist/

plus the following fix:
tensorflow/tensorflow@d994300

**Other info / logs**
The example works fine if embeddings_freq is set to 0.
"
30114,Illegal instruction (core dumped),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 18.04.02):
- TensorFlow installed from (source or binary):

pip install --upgrade tensorflow==2.0.0-beta1

- Python version:
python3 --version
Python 3.6.8

- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""
Illegal instruction (core dumped)

"
30113,tf.image.encode_png doesn't support 16 bit and inconsistent behavior in eager mode,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tested with 1.9.0, 1.12.0 and 1.14.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Creating a numpy array with uint16 datatype and passing it to tf.image.encode_png() yields different results in eager execution mode. The first time the array is passed it somehow gets transformed to a uint8 array and for the following encodings it works as expected. 

Using a tf.session the uint16 input is always transformed to uint8

**Describe the expected behavior**

Just return a bytestring of a 16bit PNG

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
import numpy as np
import tensorflow as tf
#tf.enable_eager_execution()

np.random.seed(1)
A = np.random.randint(low=0, high=65535, size=100, dtype=np.uint16).reshape(10,10,1)
B = A.copy()
np.allclose(A,B) # is true

# Eager Execution
a_encoded = tf.image.encode_png(A).numpy()
b_encoded = tf.image.encode_png(B).numpy()

print(len(a_encoded),len(b_encoded)) # prints 178 and 278, 278 expected both times
assert(a_encoded == b_encoded) # Fails

# Session Mode
encode_a = tf.image.encode_png(A)
encode_b = tf.image.encode_png(B)

with tf.Session() as sess:
    a_encoded = sess.run(encode_a)
    b_encoded = sess.run(encode_b)

print(len(a_encoded),len(b_encoded)) # prints 178 and 178 but 278 expected 
assert(a_encoded == b_encoded) # True

```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30112,[TF2.0] How to do image data augmentation using Dataset,"Hello everyone,

since TF2.0, it seems that image data augmentation is made more difficult than in 1.x. I admit I am now not able to do such a simple thing as adding random rotation to my pipeline. 

Using Dataset, I `map` my preprocess function to the pipeline. I can perform augmentations available in tf.image, but these are rather limited in range, e.g. I am not happy with rot90. I would like to add a TF->PIL->rotate->TF code, but it always raises exception during eager because obviously the input dimensions are not known.

```
image = tf.io.read_file(path)
image = tf.image.decode_image(image, channels=3)
image = tf.image.random_flip_left_right(image)
image = SOMEHOWROTATE(image, angle)
```

Seems that keras ImageDataGenerator should have been used, but I am not able to integrate it into Dataset pipeline. Previously in TF1, I used py_func in which I was able to convert tensors to pil images and rotate. Anyone can help?

Please do not forward this to stackoverflow, as user base of TF2.0 is very sparse there. It seems to be very difficult to find examples of using TF2.0.

r"
30111,Unable to build tensorflow from source on CentOS,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.6.1810 (Core)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.13.1
- Python version: 3.4.9 and 3.6.6
- Installed using virtualenv? pip? conda?: -
- Bazel version (if compiling from source): 0.26.0 from Vincent Batts (Fedora COPR)
- GCC/Compiler version (if compiling from source): gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
- CUDA/cuDNN version: -
- GPU model and memory: -



**Describe the problem**

Hello everyone,

for my current project I want to use Tensorflow's C API on a cluster running on CentOS. I was able to use the downloaded C API version (from: https://www.tensorflow.org/install/lang_c) on the cluster. However the last version I downloaded (on June 14th) does not support AVX / AVX2. Simultaneously I did the same thing on one cluster node running on Ubuntu. There I built Tensorflow from source, which automatically supported AVX, and therefore decreased the inference time by 66% which is great. I now want to use AVX also on CentOS. However here I am experiencing several issues that I am unable to handle:

__________________________________________________________________________

1) If I want to use the shared libraries (.so) and the header files for the C API that were generated during building Tensorflow from source on Ubuntu my code does not compile. I get the following error message:
```
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::assign(char const*)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::logic_error::logic_error(char const*)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::domain_error::domain_error(char const*)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_replace_aux(unsigned long, unsigned long, unsigned long, char)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow_framework.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::operator>><char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_stringstream()@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::logic_error::logic_error(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::rfind(char, unsigned long) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__exception_ptr::exception_ptr::exception_ptr(void*)@CXXABI_1.3.11'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::invalid_argument::invalid_argument(char const*)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::reserve(unsigned long)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `vtable for std::__cxx11::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::erase(unsigned long, unsigned long)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::find(char, unsigned long) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `powf@GLIBC_2.27'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::substr(unsigned long, unsigned long) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::domain_error::domain_error(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_replace(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::_M_sync(char*, unsigned long, unsigned long)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(unsigned long, unsigned long, char const*, unsigned long) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(unsigned long, unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `VTT for std::__cxx11::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__throw_out_of_range_fmt(char const*, ...)@GLIBCXX_3.4.20'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::underflow_error::underflow_error(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow_framework.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::append(char const*)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::runtime_error::runtime_error(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `__cxa_throw_bad_array_new_length@CXXABI_1.3.8'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::runtime_error::runtime_error(char const*)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::push_back(char)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `expf@GLIBC_2.27'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::underflow_error::underflow_error(char const*)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::logic_error::logic_error(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::overflow_error::overflow_error(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `logf@GLIBC_2.27'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::append(char const*, unsigned long)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::length_error::length_error(char const*)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::basic_ostringstream(std::_Ios_Openmode)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::thread::_M_start_thread(std::unique_ptr<std::thread::_State, std::default_delete<std::thread::_State> >, void (*)())@GLIBCXX_3.4.22'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_erase(unsigned long, unsigned long)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `__cxa_init_primary_exception@CXXABI_1.3.11'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__atomic_futex_unsigned_base::_M_futex_notify_all(unsigned int*)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::thread::_State::~_State()@GLIBCXX_3.4.22'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::rfind(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::logic_error::logic_error(std::logic_error const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_append(char const*, unsigned long)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `typeinfo for std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(unsigned long, unsigned long, char const*) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `VTT for std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::resize(unsigned long, char)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_istringstream()@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::find_last_of(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_mutate(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `vtable for std::__cxx11::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::operator=(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::find_first_of(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::getline<char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, char)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::swap(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__future_base::_State_baseV2::_Make_ready::_M_set()@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::length_error::length_error(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::find_first_not_of(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `typeinfo for std::thread::_State@GLIBCXX_3.4.22'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_assign(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `lgammaf@GLIBC_2.23'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::runtime_error::runtime_error(std::runtime_error const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::runtime_error::runtime_error(std::runtime_error const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(char const*) const@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `vtable for std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_construct(unsigned long, char)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::invalid_argument::invalid_argument(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::logic_error::logic_error(std::logic_error const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::random_device::_M_init(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::out_of_range::out_of_range(char const*)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `VTT for std::__cxx11::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::range_error::range_error(char const*)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::out_of_range::out_of_range(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_create(unsigned long&, unsigned long)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::overflow_error::overflow_error(char const*)@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `vtable for std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `lgamma@GLIBC_2.23'
/home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt64Opt/lib/libtensorflow.so: undefined reference to `std::range_error::range_error(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)@GLIBCXX_3.4.21'
```

Obviously there is an issue with GLIBCXX / GLIBC / CXXABI. The compilation seems to need:
```
GLIBCXX_3.4.20
GLIBCXX_3.4.21
GLIBCXX_3.4.22
GLIBC_2.27
GLIBC_2.23
CXXABI_1.3.11
CXXABI_1.3.8
```

So i checked the available ones, and I get:
```
strings /usr/lib64/libstdc++.so.6 | grep GLIBC

GLIBCXX_3.4
GLIBCXX_3.4.1
GLIBCXX_3.4.2
GLIBCXX_3.4.3
GLIBCXX_3.4.4
GLIBCXX_3.4.5
GLIBCXX_3.4.6
GLIBCXX_3.4.7
GLIBCXX_3.4.8
GLIBCXX_3.4.9
GLIBCXX_3.4.10
GLIBCXX_3.4.11
GLIBCXX_3.4.12
GLIBCXX_3.4.13
GLIBCXX_3.4.14
GLIBCXX_3.4.15
GLIBCXX_3.4.16
GLIBCXX_3.4.17
GLIBCXX_3.4.18
GLIBCXX_3.4.19
GLIBC_2.3
GLIBC_2.2.5
GLIBC_2.14
GLIBC_2.4
GLIBC_2.3.2
```

```
strings /usr/lib64/libstdc++.so.6 | grep CXXABI

CXXABI_1.3
CXXABI_1.3.1
CXXABI_1.3.2
CXXABI_1.3.3
CXXABI_1.3.4
CXXABI_1.3.5
CXXABI_1.3.6
CXXABI_1.3.7
CXXABI_TM_1
```

For comparison reasons I pulled the current official docker image for CentOS and it provided exactly the same CXXABIs and GLIBCs / GLIBCXXs. 
Can I do something to enable the compilation with the version from Ubuntu?
__________________________________________________________________________

2) Assuming that the Ubuntu version will never work on CentOS I decided to go another way and try to build Tensorflow directly on CentOS. The first problem was the unavailability of Bazel for CentOS. Thanks to the support of Vincent Batts who provides unofficial Bazel versions for CentOS I was able to install Bazel 0.26.0 both in my CentOS docker container as well as on the cluster running on CentOS. Entering 

```
bazel version
```

Gives me this on the cluster:
```
WARNING: Output base '/home/elias/.cache/bazel/_bazel_elias/d41d8cd98f00b204e9800998ecf8427e' is on NFS. This may lead to surprising failures and undetermined behavior.
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
Build label: 0.26.0- (@non-git)
Build target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Jun 11 17:32:09 2019 (1560274329)
Build timestamp: 1560274329
Build timestamp as int: 1560274329
```

and this in my docker container:
```
$TEST_TMPDIR defined: output root default is '/tmp/bazel' and max_idle_secs default is '15'.
WARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:
.bazelrc
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by com.google.protobuf.UnsafeUtil (file:/tmp/bazel/_bazel_root/install/3e27460bd3939411a8a3e57865ad7ae0/_embedded_binaries/A-server.jar) to field java.nio.Buffer.address
WARNING: Please consider reporting this to the maintainers of com.google.protobuf.UnsafeUtil
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
Build label: 0.26.0- (@non-git)
Build target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Jun 11 17:32:09 2019 (1560274329)
Build timestamp: 1560274329
Build timestamp as int: 1560274329
```

I am worried about the cluster warning me regarding the NFS, however if do not really know how to solve this. I assume it does not matter where I put bazel on the cluster, as long as it is on the cluster I will always get this error?

However, in both cases I seem to have an installed version of Bazel 0.26.0 which should be able to build Tensorflow from source. Unfortunately building Tensorflow fails, I will describe the exact commands / steps i executed:

1) Installing the requirements
```
yum install -y https://centos7.iuscommunity.org/ius-release.rpm
yum update
yum install -y python36u python36u-libs python36u-devel python36u-pip
pip install -U --user pip six numpy wheel setuptools mock future>=0.17.1
pip install -U --user keras_applications==1.0.6 --no-deps
pip install -U --user keras_preprocessing==1.0.5 --no-deps
```

2) Installing bazel
```
yum install https://copr-be.cloud.fedoraproject.org/results/vbatts/bazel/epel-7-x86_64/00934552-bazel/bazel-0.26.0-2.el7.x86_64.rpm
```

3) Downloading the Tensorflow source code:
```
git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
```

4) Configure the build:
```
./configure
Please specify the location of python. [Default is /usr/bin/python]: default
Please input the desired Python library path to use.  Default is [/usr/lib/python2.7/site-packages]: /usr/lib/python3.6/site-packages
Do you wish to build TensorFlow with XLA JIT support? [Y/n]: n
Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N
Do you wish to build TensorFlow with ROCm support? [y/N]: N
Do you wish to build TensorFlow with CUDA support? [y/N]: N
Do you wish to download a fresh release of clang? (Experimental) [y/N]: N
Do you wish to build TensorFlow with MPI support? [y/N]: y
Please specify the MPI toolkit folder. [Default is /opt/openmpi/3.1.3/gcc]: y
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: default
Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N
```

5) Trying to build according to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/lib_package/README.md
```
bazel test --config opt //tensorflow/tools/lib_package:libtensorflow_test
```

6) ERROR MESSAGE: (There are some german messages, I will provide a fully english version asap)
```
bazel test --config opt //tensorflow/tools/lib_package:libtensorflow_test
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=204
INFO: Reading rc options for 'test' from /tensorflow/.bazelrc:
  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
INFO: Reading rc options for 'test' from /tensorflow/.tf_configure.bazelrc:
  Inherited 'build' options: --host_force_python=PY2 --action_env PYTHON_BIN_PATH=/usr/bin/python --action_env PYTHON_LIB_PATH=/usr/lib/python2.7/site-packages --python_path=/usr/bin/python --action_env TF_CONFIGURE_IOS=0
INFO: Reading rc options for 'test' from /tensorflow/.tf_configure.bazelrc:
  'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium --test_tag_filters=-benchmark-test,-no_oss,-oss_serial --build_tag_filters=-benchmark-test,-no_oss --test_tag_filters=-gpu --build_tag_filters=-gpu
INFO: Found applicable config definition build:opt in file /tensorflow/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true
INFO: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/bazel_tools/tools/build_defs/repo/git.bzl:252:18):
 - /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/bazel_toolchains/repositories/repositories.bzl:37:9
 - /tensorflow/WORKSPACE:36:1
ERROR: An error occurred during the fetch of repository 'io_bazel_rules_docker':
   Traceback (most recent call last):
	File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 234
		_clone_or_update(ctx)
	File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 74, in _clone_or_update
		fail((""error cloning %s:\n%s"" % (ctx....)))
error cloning io_bazel_rules_docker:
+ cd /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external
+ rm -rf /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker
+ git clone '' https://github.com/bazelbuild/rules_docker.git /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker
Too many arguments.

usage: git clone [options] [--] <repo> [<dir>]

    -v, --verbose         be more verbose
    -q, --quiet           be more quiet
    --progress            force progress reporting
    -n, --no-checkout     don't create a checkout
    --bare                create a bare repository
    --mirror              create a mirror repository (implies bare)
    -l, --local           to clone from a local repository
    --no-hardlinks        don't use local hardlinks, always copy
    -s, --shared          setup as shared repository
    --recursive           initialize submodules in the clone
    --recurse-submodules  initialize submodules in the clone
    --template <template-directory>
                          directory from which templates will be used
    --reference <repo>    reference repository
    -o, --origin <name>   use <name> instead of 'origin' to track upstream
    -b, --branch <branch>
                          checkout <branch> instead of the remote's HEAD
    -u, --upload-pack <path>
                          path to git-upload-pack on the remote
    --depth <depth>       create a shallow clone of that depth
    --single-branch       clone only one branch, HEAD or --branch
    --separate-git-dir <gitdir>
                          separate git dir from working tree
    -c, --config <key=value>
                          set config inside the new repository

+ git clone https://github.com/bazelbuild/rules_docker.git /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker
+ git -C /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker reset --hard 251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
+ git -C /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker fetch '' origin 251f6a68b439744094faff800cd029798edf9faa:251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
+ git -C /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker fetch origin 251f6a68b439744094faff800cd029798edf9faa:251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
ERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': Traceback (most recent call last):
	File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 234
		_clone_or_update(ctx)
	File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 74, in _clone_or_update
		fail((""error cloning %s:\n%s"" % (ctx....)))
error cloning io_bazel_rules_docker:
+ cd /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external
+ rm -rf /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker
+ git clone '' https://github.com/bazelbuild/rules_docker.git /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker
Too many arguments.

usage: git clone [options] [--] <repo> [<dir>]

    -v, --verbose         be more verbose
    -q, --quiet           be more quiet
    --progress            force progress reporting
    -n, --no-checkout     don't create a checkout
    --bare                create a bare repository
    --mirror              create a mirror repository (implies bare)
    -l, --local           to clone from a local repository
    --no-hardlinks        don't use local hardlinks, always copy
    -s, --shared          setup as shared repository
    --recursive           initialize submodules in the clone
    --recurse-submodules  initialize submodules in the clone
    --template <template-directory>
                          directory from which templates will be used
    --reference <repo>    reference repository
    -o, --origin <name>   use <name> instead of 'origin' to track upstream
    -b, --branch <branch>
                          checkout <branch> instead of the remote's HEAD
    -u, --upload-pack <path>
                          path to git-upload-pack on the remote
    --depth <depth>       create a shallow clone of that depth
    --single-branch       clone only one branch, HEAD or --branch
    --separate-git-dir <gitdir>
                          separate git dir from working tree
    -c, --config <key=value>
                          set config inside the new repository

+ git clone https://github.com/bazelbuild/rules_docker.git /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker
+ git -C /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker reset --hard 251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
+ git -C /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker fetch '' origin 251f6a68b439744094faff800cd029798edf9faa:251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
+ git -C /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker fetch origin 251f6a68b439744094faff800cd029798edf9faa:251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
ERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': Traceback (most recent call last):
	File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 234
		_clone_or_update(ctx)
	File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 74, in _clone_or_update
		fail((""error cloning %s:\n%s"" % (ctx....)))
error cloning io_bazel_rules_docker:
+ cd /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external
+ rm -rf /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker
+ git clone '' https://github.com/bazelbuild/rules_docker.git /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker
Too many arguments.

usage: git clone [options] [--] <repo> [<dir>]

    -v, --verbose         be more verbose
    -q, --quiet           be more quiet
    --progress            force progress reporting
    -n, --no-checkout     don't create a checkout
    --bare                create a bare repository
    --mirror              create a mirror repository (implies bare)
    -l, --local           to clone from a local repository
    --no-hardlinks        don't use local hardlinks, always copy
    -s, --shared          setup as shared repository
    --recursive           initialize submodules in the clone
    --recurse-submodules  initialize submodules in the clone
    --template <template-directory>
                          directory from which templates will be used
    --reference <repo>    reference repository
    -o, --origin <name>   use <name> instead of 'origin' to track upstream
    -b, --branch <branch>
                          checkout <branch> instead of the remote's HEAD
    -u, --upload-pack <path>
                          path to git-upload-pack on the remote
    --depth <depth>       create a shallow clone of that depth
    --single-branch       clone only one branch, HEAD or --branch
    --separate-git-dir <gitdir>
                          separate git dir from working tree
    -c, --config <key=value>
                          set config inside the new repository

+ git clone https://github.com/bazelbuild/rules_docker.git /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker
+ git -C /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker reset --hard 251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
+ git -C /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker fetch '' origin 251f6a68b439744094faff800cd029798edf9faa:251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
+ git -C /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/io_bazel_rules_docker fetch origin 251f6a68b439744094faff800cd029798edf9faa:251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
INFO: Elapsed time: 4.263s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
FAILED: Build did NOT complete successfully (0 packages loaded)
```

Now I saw here (https://github.com/tensorflow/tensorflow/issues/28824) that adding something to the WORKSPACE file might help. It says: "" managed to fix this by adding the following to the top of my WORKSPACE file: [...] If you do the same, you probably want to ensure you get the latest version here https://github.com/bazelbuild/rules_docker and copy the code snippet from the README instead of from here.""

I now ran ""update_deps.sh"" and added the respective part from here(https://github.com/bazelbuild/rules_docker/blob/master/README.md), now my WORKSPACE file looks like this:

```
workspace(name = ""org_tensorflow"")

load(""@bazel_tools//tools/build_defs/repo:http.bzl"", ""http_archive"", ""http_file"")

http_archive(
    name = ""io_bazel_rules_docker"",
    sha256 = ""3556d4972571f288f8c43378295d84ed64fef5b1a875211ee1046f9f6b4258fa"",
    strip_prefix = ""rules_docker-0.8.0"",
    urls = [""https://github.com/bazelbuild/rules_docker/archive/v0.8.0.tar.gz""],
)

http_archive(
    name = ""io_bazel_rules_closure"",
    sha256 = ""5b00383d08dd71f28503736db0500b6fb4dda47489ff5fc6bed42557c07c6ba9"",
    strip_prefix = ""rules_closure-308b05b2419edb5c8ee0471b67a40403df940149"",
    urls = [
	""http://mirror.tensorflow.org/github.com/bazelbuild/rules_closure/archive/308b05b2419edb5c8ee0471b67a40403df940149.tar.gz"",
        ""https://github.com/bazelbuild/rules_closure/archive/308b05b2419edb5c8ee0471b67a40403df940149.tar.gz"",  # 2019-06-13
    ],
)

# Load tf_repositories() before loading dependencies for other repository so
# that dependencies like com_google_protobuf won't be overridden.
load(""//tensorflow:workspace.bzl"", ""tf_repositories"")
# Please add all new TensorFlow dependencies in workspace.bzl.
tf_repositories()

load(""@io_bazel_rules_closure//closure:defs.bzl"", ""closure_repositories"")

closure_repositories()

load(""//third_party/toolchains/preconfig/generate:archives.bzl"",
     ""bazel_toolchains_archive"")

bazel_toolchains_archive()

load(
    ""@bazel_toolchains//repositories:repositories.bzl"",
    bazel_toolchains_repositories = ""repositories"",
)

bazel_toolchains_repositories()

load(
    ""@io_bazel_rules_docker//repositories:repositories.bzl"",
    container_repositories = ""repositories"",
)

container_repositories()

load(""//third_party/toolchains/preconfig/generate:workspace.bzl"",
     ""remote_config_workspace"")

remote_config_workspace()

# Apple and Swift rules.
http_archive(
    name = ""build_bazel_rules_apple"",
    sha256 = ""23792cd999f97fc97284d1c44cb1324bfdd0bc54aa68ad513fa3705aca3b1f9e"",
    urls = [""https://github.com/bazelbuild/rules_apple/releases/download/0.15.0/rules_apple.0.15.0.tar.gz""],
)  # https://github.com/bazelbuild/rules_apple/releases
http_archive(
    name = ""build_bazel_apple_support"",
    sha256 = ""7356dbd44dea71570a929d1d4731e870622151a5f27164d966dda97305f33471"",
    urls = [""https://github.com/bazelbuild/apple_support/releases/download/0.6.0/apple_support.0.6.0.tar.gz""],
)  # https://github.com/bazelbuild/apple_support/releases
http_archive(
    name = ""bazel_skylib"",
    sha256 = ""2ef429f5d7ce7111263289644d233707dba35e39696377ebab8b0bc701f7818e"",
    urls = [""https://github.com/bazelbuild/bazel-skylib/releases/download/0.8.0/bazel-skylib.0.8.0.tar.gz""],
)  # https://github.com/bazelbuild/bazel-skylib/releases
http_archive(
    name = ""build_bazel_rules_swift"",
    sha256 = ""9efe9699e9765e6b4a5e063e4a08f6b163cccaf0443f775d935baf5c3cd6ed0e"",
    urls = [""https://github.com/bazelbuild/rules_swift/releases/download/0.9.0/rules_swift.0.9.0.tar.gz""],
)  # https://github.com/bazelbuild/rules_swift/releases
http_archive(
    name = ""com_github_apple_swift_swift_protobuf"",
    type = ""zip"",
    strip_prefix = ""swift-protobuf-1.5.0/"",
    urls = [""https://github.com/apple/swift-protobuf/archive/1.5.0.zip""],
)  # https://github.com/apple/swift-protobuf/releases
http_file(
    name = ""xctestrunner"",
    executable = 1,
    urls = [""https://github.com/google/xctestrunner/releases/download/0.2.7/ios_test_runner.par""],
)  # https://github.com/google/xctestrunner/releases
# Use `swift_rules_dependencies` to fetch the toolchains. With the
# `git_repository` rules above, the following call will skip redefining them.
load(""@build_bazel_rules_swift//swift:repositories.bzl"", ""swift_rules_dependencies"")
swift_rules_dependencies()

# We must check the bazel version before trying to parse any other BUILD
# files, in case the parsing of those build files depends on the bazel
# version we require here.
load(""//tensorflow:version_check.bzl"", ""check_bazel_version_at_least"")
check_bazel_version_at_least(""0.19.0"")

load(""//third_party/android:android_configure.bzl"", ""android_configure"")
android_configure(name=""local_config_android"")
load(""@local_config_android//:android.bzl"", ""android_workspace"")
android_workspace()

# If a target is bound twice, the later one wins, so we have to do tf bindings
# at the end of the WORKSPACE file.
load(""//tensorflow:workspace.bzl"", ""tf_bind"")
tf_bind()

http_archive(
    name = ""inception_v1"",
    build_file = ""//:models.BUILD"",
    sha256 = ""7efe12a8363f09bc24d7b7a450304a15655a57a7751929b2c1593a71183bb105"",
    urls = [
	""http://storage.googleapis.com/download.tensorflow.org/models/inception_v1.zip"",
        ""http://download.tensorflow.org/models/inception_v1.zip"",
    ],
)

http_archive(
    name = ""mobile_ssd"",
    build_file = ""//:models.BUILD"",
    sha256 = ""bddd81ea5c80a97adfac1c9f770e6f55cbafd7cce4d3bbe15fbeb041e6b8f3e8"",
    urls = [
	""http://storage.googleapis.com/download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_android_export.zip"",
        ""http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_android_export.zip"",
    ],
)

http_archive(
    name = ""mobile_multibox"",
    build_file = ""//:models.BUILD"",
    sha256 = ""859edcddf84dddb974c36c36cfc1f74555148e9c9213dedacf1d6b613ad52b96"",
    urls = [
	""http://storage.googleapis.com/download.tensorflow.org/models/mobile_multibox_v1a.zip"",
        ""http://download.tensorflow.org/models/mobile_multibox_v1a.zip"",
    ],
)

http_archive(
    name = ""stylize"",
    build_file = ""//:models.BUILD"",
    sha256 = ""3d374a730aef330424a356a8d4f04d8a54277c425e274ecb7d9c83aa912c6bfa"",
    urls = [
	""http://storage.googleapis.com/download.tensorflow.org/models/stylize_v1.zip"",
        ""http://download.tensorflow.org/models/stylize_v1.zip"",
    ],
)

http_archive(
    name = ""speech_commands"",
    build_file = ""//:models.BUILD"",
    sha256 = ""c3ec4fea3158eb111f1d932336351edfe8bd515bb6e87aad4f25dbad0a600d0c"",
    urls = [
	""http://storage.googleapis.com/download.tensorflow.org/models/speech_commands_v0.01.zip"",
        ""http://download.tensorflow.org/models/speech_commands_v0.01.zip"",
    ],
)
```
However, now my error looks like this:

```
bazel test --config opt //tensorflow/tools/lib_package:libtensorflow_test
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=204
INFO: Reading rc options for 'test' from /home/tensorflow/.bazelrc:
  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
INFO: Reading rc options for 'test' from /home/tensorflow/.tf_configure.bazelrc:
  Inherited 'build' options: --host_force_python=PY2 --action_env PYTHON_BIN_PATH=/usr/bin/python --action_env PYTHON_LIB_PATH=/usr/lib/python2.7/site-packages --python_path=/usr/bin/python --action_env TF_CONFIGURE_IOS=0
INFO: Reading rc options for 'test' from /home/tensorflow/.tf_configure.bazelrc:
  'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium --test_tag_filters=-benchmark-test,-no_oss,-oss_serial --build_tag_filters=-benchmark-test,-no_oss --test_tag_filters=-gpu --build_tag_filters=-gpu
INFO: Found applicable config definition build:opt in file /home/tensorflow/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/98bd3f3dfbd0725c619a9932413c587d/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 29, in <module>
    from builtins import bytes  # pylint: disable=redefined-builtin
ImportError: No module named builtins
INFO: Call stack for the definition of repository 'local_config_git' which is a git_configure (rule definition at /home/tensorflow/third_party/git/git_configure.bzl:63:17):
 - /home/tensorflow/tensorflow/workspace.bzl:71:5
 - /home/tensorflow/WORKSPACE:26:1
ERROR: An error occurred during the fetch of repository 'local_config_git':
   Traceback (most recent call last):
	File ""/home/tensorflow/third_party/git/git_configure.bzl"", line 61
		_fail(result.stderr)
	File ""/home/tensorflow/third_party/git/git_configure.bzl"", line 14, in _fail
		fail((""%sGit Configuration Error:%s %...)))
Git Configuration Error: Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/98bd3f3dfbd0725c619a9932413c587d/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 29, in <module>
    from builtins import bytes  # pylint: disable=redefined-builtin
ImportError: No module named builtins

ERROR: /home/tensorflow/tensorflow/core/BUILD:2810:1: no such package '@local_config_git//': Traceback (most recent call last):
	File ""/home/tensorflow/third_party/git/git_configure.bzl"", line 61
		_fail(result.stderr)
	File ""/home/tensorflow/third_party/git/git_configure.bzl"", line 14, in _fail
		fail((""%sGit Configuration Error:%s %...)))
Git Configuration Error: Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/98bd3f3dfbd0725c619a9932413c587d/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 29, in <module>
    from builtins import bytes  # pylint: disable=redefined-builtin
ImportError: No module named builtins

 and referenced by '//tensorflow/core:version_info_gen'
ERROR: /home/tensorflow/tensorflow/core/BUILD:2810:1: no such package '@local_config_git//': Traceback (most recent call last):
	File ""/home/tensorflow/third_party/git/git_configure.bzl"", line 61
		_fail(result.stderr)
	File ""/home/tensorflow/third_party/git/git_configure.bzl"", line 14, in _fail
		fail((""%sGit Configuration Error:%s %...)))
Git Configuration Error: Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/98bd3f3dfbd0725c619a9932413c587d/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 29, in <module>
    from builtins import bytes  # pylint: disable=redefined-builtin
ImportError: No module named builtins

 and referenced by '//tensorflow/core:version_info_gen'
ERROR: /home/tensorflow/tensorflow/core/BUILD:2810:1: no such package '@local_config_git//': Traceback (most recent call last):
	File ""/home/tensorflow/third_party/git/git_configure.bzl"", line 61
		_fail(result.stderr)
	File ""/home/tensorflow/third_party/git/git_configure.bzl"", line 14, in _fail
		fail((""%sGit Configuration Error:%s %...)))
Git Configuration Error: Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/98bd3f3dfbd0725c619a9932413c587d/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 29, in <module>
    from builtins import bytes  # pylint: disable=redefined-builtin
ImportError: No module named builtins

 and referenced by '//tensorflow/core:version_info_gen'
ERROR: Analysis of target '//tensorflow/tools/lib_package:libtensorflow_test' failed; build aborted: no such package '@local_config_git//': Traceback (most recent call last):
	File ""/home/tensorflow/third_party/git/git_configure.bzl"", line 61
		_fail(result.stderr)
	File ""/home/tensorflow/third_party/git/git_configure.bzl"", line 14, in _fail
		fail((""%sGit Configuration Error:%s %...)))
Git Configuration Error: Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/98bd3f3dfbd0725c619a9932413c587d/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 29, in <module>
    from builtins import bytes  # pylint: disable=redefined-builtin
ImportError: No module named builtins

INFO: Elapsed time: 48.450s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (141 packages loaded, 7475 targets configured)
FAILED: Build did NOT complete successfully (141 packages loaded, 7475 targets configured)
```
However I am getting further than before I think. 
My git version is: 2.16.5

PS: if it helps I can provide my CentOS docker image where I try to get this done!
__________________________________________________________________________

3) Alternative: Would it be possible for the development team to provide the C API libraries and headers (like here: https://www.tensorflow.org/install/lang_c) with AVX support? I would hope that if you compile it I may be able to run it also on CentOS, or is that improbable?

Thanks in advance!"
30110,PYYAML not found,"Running ```yaml_string = model.to_yaml()``` on mac is giving me this error :
```
Traceback (most recent call last):
  File ""check-keras.py"", line 197, in <module>
    yaml_string = model.to_yaml()
  File ""/Users/vipulsharma/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/network.py"", line 1560, in to_yaml
    'Requires yaml module installed (`pip install pyyaml`).')
ImportError: Requires yaml module installed (`pip install pyyaml`)
```
When I run pip install, it says that the package already exists.
```
Vipuls-MacBook-Air:Keras vipulsharma$ pip install pyyaml
Requirement already satisfied: pyyaml in /Users/vipulsharma/Library/Python/2.7/lib/python/site-packages (5.1.1)
```

So I figured in the above terminal output
``` File ""/Users/vipulsharma/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/network.py"", line 1560,``` 

This version of Python is different than the version here :
```Requirement already satisfied: pyyaml in /Users/vipulsharma/Library/Python/2.7/lib/python/site-packages (5.1.1)```

So I tried installing yaml in 
```/Users/vipulsharma/Library/Python/3.7/lib/python/site-packages/```

 by doing a 
```pip install --target=/Users/vipulsharma/Library/Python/3.7/lib/python/site-packages/ pyyaml```

 It installed yaml in  ```/Users/vipulsharma/Library/Python/3.7/lib/python/site-packages/```  successfully, but when I run my Python file it gives me the same error.

How am I supposed to convert it to Yaml?"
30109,Using keras.layers.BatchNormalization inside keras.layers.TimeDistributed causes bad validation loss/accuracy,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): tensorflow-gpu 1.13.1
- Python version: 3.6.7
- CUDA/cuDNN version: v10
- GPU model and memory: GTX 980M

**Describe the current behavior**
Using BatchNorm inside a TimeDistributed layer results in poor validation performance. A model trained and validated on identical data can reach 100% train accuracy but never reach that when validating against the same sample. Removing the Batchnorm layer resolves the issue.

See the training results from a toy example:
```
500/500 loss: 1.6910 - sparse_categorical_accuracy: 0.2400 - val_loss: 1.7292 - val_sparse_categorical_accuracy: 0.2000
Epoch 2/100

500/500 loss: 1.2619 - sparse_categorical_accuracy: 0.5600 - val_loss: 1.6112 - val_sparse_categorical_accuracy: 0.2000
Epoch 3/100

500/500 loss: 0.9130 - sparse_categorical_accuracy: 0.9200 - val_loss: 1.5113 - val_sparse_categorical_accuracy: 0.2000
Epoch 4/100

500/500  loss: 0.6420 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4297 - val_sparse_categorical_accuracy: 0.2000
Epoch 5/100
...
...
...
500/500 loss: 8.2955e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1042 - val_sparse_categorical_accuracy: 0.2000
Epoch 100/100
```

**Describe the expected behavior**
When training and validating on an identical sample, the model should get the same accuracy during both training and validation. To eliminate the possibility that this is caused by a difference between the running mean/variance and the batchwise mean/variance, a very small value of BatchNorm Momentum was trialed. It was observed that modifying Momentum appears to have no effect. BatchNorm should not affect a model's ability to make good predictions.

**Code to reproduce the issue**
The following code shows the issue. Run it a few times and watch the validation accuracy/loss.
```
from tensorflow import keras
import tensorflow as tf
import numpy as np
import random

time_steps = 5
sample_width = 20
kernel_size = 3
num_filters = 5
num_classes = 5

def build_graph():
    with tf.name_scope(""SequenceProcess""):
        sequence_input = keras.layers.Input(shape=(time_steps, sample_width))

        with tf.name_scope(""TimeDistributed""):
            sample_input = keras.layers.Input(shape=(sample_width,))

            conv = keras.layers.Reshape([sample_width, 1])(sample_input)
            conv = keras.layers.BatchNormalization(momentum=0.01)(conv)
            conv = keras.layers.Conv1D(num_filters, kernel_size, padding='same')(conv)
            encoded_sample = keras.layers.Reshape((num_filters * sample_width,))(conv)

            sample_model = keras.models.Model(sample_input, encoded_sample)

        processed_samples = keras.layers.TimeDistributed(sample_model)(sequence_input)
        fc = keras.layers.Dense(num_classes, activation='softmax')(processed_samples)

        sequence_model = keras.models.Model(sequence_input, fc)
        sequence_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])

    return sequence_model

def generate_data():
    steps = []
    for i in range(time_steps):
        sample_data = np.random.rand(sample_width)
        steps.append(sample_data)
    steps = np.array(steps)

    labels = []
    for i in range(time_steps):
        label = random.randint(0, num_classes - 1)
        labels.append([label])
    labels = np.array(labels)

    input_data = []
    input_labels = []

    for i in range(1000):
        input_data.append(steps)
        input_labels.append(labels)

    return np.array(input_data), np.array(input_labels)

if __name__ == '__main__':
    data, labels = generate_data()
    model = build_graph()
    model.fit(data, labels, 10, 100, validation_split= 0.5)
```
"
30108,CPU memory is not released after calling sess.run and closing session,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): not sure
- TensorFlow version (use command below): v1.13.1-0-g6612da8
- Python version: 3.7.3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10.0
- GPU model and memory: Tesla V100, 16130MiB

**Describe the current behavior**
I observed increase of cpu memory usage (and not releasing memory) when fetching big tensors with `sess.run` from gpu and also not releasing cpu memory when closing session and resetting graph.

I attached example and memory profiler logs. I tested 3 situations:
1) Create two variables on gpu and fetch them in one `sess.run` call: memory increases by 1057MiB and is not released after closing session and resetting graph)
2) Create two variables on gpu and fetch them one by one with `sess.run` call: memory increases by 528MiB and is not released after closing session and resetting graph)
3) Create two variables on Ñpu and fetch them: memory isnâ€™t increased and released after closing session.

**Describe the expected behavior**
Memory is released after `sess.run` and closing session, like in case 3 above but for gpu.

**Code to reproduce the issue**
https://gist.github.com/fgvbrt/7e9163267e1bc1fc501916125e09cd6d

**Other info / logs**
Logs with run commands for 3 situation above:
[profile.txt](https://github.com/tensorflow/tensorflow/files/3323401/profile.txt)
"
30105,Dataset.cache() Followed by Dataset.zip() Throws AlreadyExistsError,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX Mojave 10.14.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): `pipenv install --pre tensorflow==2.0.0-beta1`
- TensorFlow version (use command below): `2.0.0-beta1`
- Python version: 3.6.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

`1v2.0.0-beta0-16-g1d91213fe7`

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

1. Cache a dataset
2. Derive other datasets from it
3. Zip the derived datasets into a single dataset
4. See cache error

```
AlreadyExistsError: There appears to be a concurrent caching iterator running - cache lockfile already exists
```

**Describe the expected behavior**
Only cache the dataset once and not throw an error.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
import tensorflow as tf


def map_file_to_xy_dataset(filename, params):
    # Generate a dataset from the filename
    csv_dataset = tf.data.experimental.CsvDataset(...)

    # Cache at unique file location (i.e filename)
    cached_dataset = csv_dataset.cache(...)

    # Generate x dataset (all but id column)
    x_dataset = cached_dataset.map(lambda *x: x[0:-1])

    # Generate y dataset (last column of each file)
    y_dataset = cached_dataset.map(lambda *x: x[-1])

    # ZIP the X, Y datasets 
    # This will throw AlreadyExistsError 
    xy_dataset = tf.data.Dataset.zip((x_dataset, y_dataset))

    return xy_dataset


def generate_dataset():
    filenames_dataset = tf.data.Dataset.list_files(data_glob)

    dataset = filenames_dataset.flat_map(map_file_to_xy_dataset)

    return dataset


```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30100,nccl.reduce_sum() throws an error,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes script for testing nccl.reduce_sum, attached below.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.13.1
- Python version: Python 3.6
- CUDA/cuDNN version: 10.1 / 7
- GPU model and memory: v100 16Gb

**Describe the current behavior**
nccl.reduce_sum() throws and error about feed_devices or fetch_devices not being found in the graph. nccl.all_reduce() works.

**Describe the expected behavior**
Expect to get a reduced tensor. 

**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow.python.ops import nccl_ops as nccl


with tf.device('/gpu:0'):
    a = tf.constant([1,2,3,4,5], dtype=tf.float32)

with tf.device('/gpu:1'):
    b = tf.constant([6,7,8,9,10], dtype=tf.float32)


with tf.device('/gpu:0'):
    c = nccl.reduce_sum([a, b])

sess = tf.Session()
print(sess.run(c)) 
```

**Other info / logs**
```
ubuntu@ip-172-31-26-69:~/tensorpack/examples/ResNet$ python test_nccl.py
2019-06-24 20:41:57.077685: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-24 20:41:57.803050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-24 20:41:57.828402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-24 20:41:57.841325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-24 20:41:57.852582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-24 20:41:57.853980: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4a9c130 executing computations on platform CUDA. Devices:
2019-06-24 20:41:57.854028: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2019-06-24 20:41:57.854053: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0
2019-06-24 20:41:57.854077: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0
2019-06-24 20:41:57.854101: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0
2019-06-24 20:41:57.860344: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300060000 Hz
2019-06-24 20:41:57.865200: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4bbd9f0 executing computations on platform Host. Devices:
2019-06-24 20:41:57.865270: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-24 20:41:57.866085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:1b.0
totalMemory: 15.75GiB freeMemory: 6.38GiB
2019-06-24 20:41:57.866225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 1 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:1c.0
totalMemory: 15.75GiB freeMemory: 3.71GiB
2019-06-24 20:41:57.866329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 2 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:1d.0
totalMemory: 15.75GiB freeMemory: 3.71GiB
2019-06-24 20:41:57.866442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 3 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:1e.0
totalMemory: 15.75GiB freeMemory: 6.68GiB
2019-06-24 20:41:57.866498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0, 1, 2, 3
2019-06-24 20:41:57.872295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-24 20:41:57.872370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 1 2 3
2019-06-24 20:41:57.872395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N Y Y Y
2019-06-24 20:41:57.872413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   Y N Y Y
2019-06-24 20:41:57.872425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   Y Y N Y
2019-06-24 20:41:57.872440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   Y Y Y N
2019-06-24 20:41:57.872826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6203 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)
2019-06-24 20:41:57.873247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 3496 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)
2019-06-24 20:41:57.873562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 3498 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1d.0, compute capability: 7.0)
2019-06-24 20:41:57.873856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 6496 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)
Traceback (most recent call last):
  File ""/home/ubuntu/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1334, in _do_call
    return fn(*args)
  File ""/home/ubuntu/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/home/ubuntu/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensor NcclReduce:0, specified in either feed_devices or fetch_devices was not found in the Graph

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test_nccl.py"", line 17, in <module>
    print(sess.run(c))
  File ""/home/ubuntu/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 929, in run
    run_metadata_ptr)
  File ""/home/ubuntu/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/ubuntu/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1328, in _do_run
    run_metadata)
  File ""/home/ubuntu/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensor NcclReduce:0, specified in either feed_devices or fetch_devices was not found in the Graph
```"
30099,deeplab on ios+real time segmentation,"i tried to implement deeplab model on ios but what i got is very slow capture 
ios:12.3.1
iphone:6+
xcode:10.1
i tried to improve the fps by:
desiredFrameRate = 30
```
captureDevice.activeVideoMinFrameDuration = CMTimeMake(1, Int32(desiredFrameRate))
 captureDevice.activeVideoMaxFrameDuration = CMTimeMake(1, Int32(desiredFrameRate))
```
i have changed desiredFrameRate to 60 and 240 but i got an error

> uncaught exception of type NSException

did anyone know how i can improve my result"
30097,[TF 2.0 API Docs] tf.image.extract_glimpse,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/extract_glimpse

## Description of issue (what needs changing):

### Raises listed and defined

Raises are not listed and defined

### Usage example

No usage example is given

### Pull Request

https://github.com/tensorflow/tensorflow/pull/30098"
30096,Keras load_model fails to load models with BatchNormalization layer when saved in non-eager mode,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 
tf version = 2.0.0-dev20190622
tf git version = v1.12.1-4759-g9856697d8b
- Python version: 3.6.4
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
This issue is very similar to #3628, but it only happens in non-eager mode in TF 2.0.
You can save a model (having batch norm layer) in **non-eager mode** successfully. However, you cannot load the model in any mode.  Load model fails with:
```
ValueError: Node 'AssignMovingAvg/sub/x' expects to be colocated with unknown node 'bn_layer/moving_mean'
```
Seems like the model is not saved correctly.

**Describe the expected behavior**
Save model should produce a correct SavedModel in non-eager mode so that it can be loaded later.

**Code to reproduce the issue**
```python

import tensorflow as tf

tf.compat.v1.disable_eager_execution()

## model architecture
input_layer = tf.keras.Input(shape=(28, 28, 1), name='image_input')
layer = tf.keras.layers.ZeroPadding2D(padding=(3, 3), name='initial_padding')(input_layer)
# add convolutional layer
layer = tf.keras.layers.Conv2D(
    filters=16,
    kernel_size=8,
    padding='same',
    name='conv_layer'
)(layer)
# batch normalization
layer = tf.keras.layers.BatchNormalization(axis=3, name='bn_layer')(layer)
# activation
layer = tf.keras.layers.Activation('relu', name='activation_layer')(layer)
# down sample
net = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(layer)
# flatten
net = tf.keras.layers.Flatten(name='flatten_layer')(net)
# dense layer with ReLU-activation.
net = tf.keras.layers.Dense(64, activation='relu', name='dense_layer')(net)
# dropout layer
net = tf.keras.layers.Dropout(0.2, name='dropout_layer')(net)
# last fully-connected / dense layer with softmax-activation so it can be used for classification.
output_layer = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(net)
# creating the model
model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='test1')

# loading data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
# add channel to x; also divide by 255 to normalize the data
x_train = x_train.reshape(60000, 28, 28, 1)#.astype('float32') / 255
x_test = x_test.reshape(10000, 28, 28, 1)#.astype('float32') / 255

# create the training dataset
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
# shuffle, batch and prefetch for optimizing io reads
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64).prefetch(1024)
# create the validation dataset.
val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
# batch and prefetch for optimizing io reads
val_dataset = val_dataset.batch(64).prefetch(1024)

# compile the model
model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='rmsprop',
    metrics=['accuracy']
)

# fit the model
history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=2,
    steps_per_epoch=50
)

# the returned ""history"" object holds a record of the loss values and metric values during training
print('\nhistory dict:', history.history)

model.save('mnist_model')

del model
# recreate the exact same model purely from the file:
model = tf.keras.models.load_model('mnist_model')
```

**Other info / logs**
```
WARNING: Logging before flag parsing goes to stderr.
W0624 13:37:50.545702 140736272085888 deprecation.py:506] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1624: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2019-06-24 13:37:51.383301: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-24 13:37:51.398677: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f90837c85b0 executing computations on platform Host. Devices:
2019-06-24 13:37:51.398709: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-24 13:37:51.728750: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1541] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
W0624 13:37:52.842435 140736272085888 deprecation.py:323] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:460: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Apply a constraint manually following the optimizer update step.
Train on 50 steps, validate on 157 steps
Epoch 1/2
50/50 [==============================] - 4s 73ms/step - loss: 1.8029 - accuracy: 0.5256 - val_loss: 0.5635 - val_accuracy: 0.8345
Epoch 2/2
50/50 [==============================] - 3s 58ms/step - loss: 0.6426 - accuracy: 0.7937 - val_loss: 0.4020 - val_accuracy: 0.8787

history dict: {'loss': [1.8028993177413941, 0.6426236051321029], 'accuracy': [0.525625, 0.79375], 'val_loss': [0.563538867861602, 0.40199054775249426], 'val_accuracy': [0.8345, 0.8787]}
2019-06-24 13:38:02.261349: W tensorflow/python/util/util.cc:268] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
Traceback (most recent call last):
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py"", line 427, in import_graph_def
    graph._c_graph, serialized, options)  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: Node 'AssignMovingAvg/sub/x' expects to be colocated with unknown node 'bn_layer/moving_mean'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""error_showcase_graph.py"", line 71, in <module>
    model = tf.keras.models.load_model('mnist_model')
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py"", line 142, in load_model
    return saved_model_load.load(filepath, compile)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 86, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py"", line 506, in load_internal
    export_dir)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 102, in __init__
    super(KerasObjectLoader, self).__init__(*args, **kwargs)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py"", line 111, in __init__
    meta_graph.graph_def.library))
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/function_deserialization.py"", line 301, in load_function_def_library
    copy, copy_functions=False)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/framework/function_def_to_graph.py"", line 64, in function_def_to_graph
    importer.import_graph_def(graph_def, name="""")
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py"", line 431, in import_graph_def
    raise ValueError(str(e))
ValueError: Node 'AssignMovingAvg/sub/x' expects to be colocated with unknown node 'bn_layer/moving_mean'
```
"
30094,Tensorboard callback with histogram_freq=1 crashes after one epoch in non-eager mode ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):
tf version = 2.0.0-dev20190622
tf git version = v1.12.1-4759-g9856697d8b
- Python version: 3.6.4
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
Calling the Keras ```fit``` function in non-eager mode fails after one epoch, if specifying a tensorboard callback which has ```histogram_freq=1```. 

**Describe the expected behavior**
I think the ```fit``` function should continue training without crashing.

**Code to reproduce the issue**
```python

import tensorflow as tf

tf.compat.v1.disable_eager_execution()

# model architecture
inputs = tf.keras.Input(shape=(784,), name='flattened_image')
x = tf.keras.layers.Dense(64, activation='relu')(inputs)
x = tf.keras.layers.Dense(64, activation='relu')(x)
outputs = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(x)
# creating the model
model = tf.keras.Model(inputs=inputs, outputs=outputs, name='test1')

# loading data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train = x_train.reshape(60000, 784).astype('float32') / 255
x_test = x_test.reshape(10000, 784).astype('float32') / 255

# create the training dataset
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
# shuffle, batch and prefetch for optimizing io reads
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64).prefetch(1024)
# create the validation dataset.
val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
# batch and prefetch for optimizing io reads
val_dataset = val_dataset.batch(64).prefetch(1024)

# compile the model
model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='rmsprop',
    metrics=['accuracy'],
)

tensorboard_callback = tf.keras.callbacks.TensorBoard(
    log_dir='./tensorboard_logs/',
    # enabling histogram will crash the learninig in non-eager mode
    histogram_freq=1, # every epoch
    write_images=True, # visualize model weights in image form
    update_freq='batch', # this can be 'epoch' to make training faster (less logs)
)

# fit the model
history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    callbacks=[tensorboard_callback],
    epochs=2,
    steps_per_epoch=50
)

# the returned ""history"" object holds a record of the loss values and metric values during training
print('\nhistory dict:', history.history)
```

**Other info / logs**
Here is the stack trace...
```
WARNING: Logging before flag parsing goes to stderr.
W0624 13:13:30.813938 140736272085888 deprecation.py:506] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1624: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2019-06-24 13:13:34.039928: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-24 13:13:34.055276: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fda14c310d0 executing computations on platform Host. Devices:
2019-06-24 13:13:34.055294: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-24 13:13:35.799524: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1541] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
W0624 13:13:43.409096 140736272085888 deprecation.py:323] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:460: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Apply a constraint manually following the optimizer update step.
Train on 50 steps, validate on 157 steps
Epoch 1/2
30/50 [=================>............] - ETA: 0s - loss: 1.3660 - accuracy: 0.6500  Traceback (most recent call last):
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py"", line 570, in read_variable_op
    ""dtype"", dtype)
tensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""error_showcase_tb.py"", line 50, in <module>
    steps_per_epoch=50
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 669, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py"", line 669, in fit
    steps_name='steps_per_epoch')
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py"", line 444, in model_iteration
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py"", line 296, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py"", line 1612, in on_epoch_end
    self._log_weights(epoch)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py"", line 1691, in _log_weights
    weight = K.get_value(weight)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 3016, in get_value
    return x.numpy()
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 580, in numpy
    return self.read_value().numpy()
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 633, in read_value
    value = self._read_variable_op()
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 611, in _read_variable_op
    self._dtype)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py"", line 575, in read_variable_op
    resource, dtype=dtype, name=name, ctx=_ctx)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py"", line 613, in read_variable_op_eager_fallback
    attrs=_attrs, ctx=_ctx, name=name)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py"", line 71, in quick_execute
    raise e
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py"", line 61, in quick_execute
    num_outputs)
TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: dense/kernel:0
```"
30093,Compiling protos for Golang,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version: v1.14.0
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the problem** I'm trying to compile the protos using `protoc` so I can import the MetaGraph Go struct. Some of the protos (tensorflow/core/protobuf/saved_object_graph.proto, tensorflow/core/protobuf/trackable_object_graph.proto, tensorflow/core/protobuf/struct.proto) that are depended on lack `option go _package`, so `protoc` generates Go files with different package names (ending in protobuf and tensorflow) in the same directory, making both packages non-importable. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
1. `protoc` on all protos in tensorflow/core/lib/core/
2. `protoc` on all protos in tensorflow/core/framework/
3. `protoc` on protos in tensorflow/core/protobuf: saver.proto, struct.proto, trackable_object_graph.proto, saved_object_graph.proto, meta_graph.proto, saved_model.proto

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30092,AttributeError: module 'tensorflow._api.v2.train' has no attribute 'FtrlOptimizer',"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/LinearClassifier

## Description of issue (what needs changing):

`FtrlOptimizer` is not accessible from `tf.train`:

```python
# Or estimator using the FTRL optimizer with regularization.
estimator = LinearClassifier(
    feature_columns=[categorical_column_a,
                     categorical_feature_a_x_categorical_feature_b],
    optimizer=tf.train.FtrlOptimizer(
      learning_rate=0.1,
      l1_regularization_strength=0.001
    )
    ### should be optimizer=tf.keras.optimizers.Ftrl(...)
)

> AttributeError: module 'tensorflow._api.v2.train' has no attribute 'FtrlOptimizer'
```

### Clear description

N/A

### Correct links

N/A

### Parameters defined

N/A

### Returns defined

N/A

### Raises listed and defined

N/A

### Usage example

N/A

### Request visuals, if applicable

N/A

### Submit a pull request?

N/A
"
30091,"Cannot reuse the self.Dense() defined in __init__(self) in call(self, x)","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-beta1
- Python version:  Python 3.5.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When I define the following:
```
class MNISTModel(Model):
    def __init__(self):
        super(MNISTModel, self).__init__()
        self.conv1 = Conv2D(32, (3, 3), input_shape=(28, 28, 1))
        self.activ = Activation('relu')
        self.flatt = Flatten()
        self.dense = Dense(200) #Here I want to reuse this Dense() layer
        self.dense1 = Dense(200) #However, I need to re-define the same layer again to use in call()
        self.dens2 = Dense(10)
```
**Describe the expected behavior**
I think that we only need to define the self.Dense(200) only once, but we can reuse it in the  def call(self, x)
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.data import Dataset
from tensorflow.keras import datasets, Model, losses, optimizers, metrics
from tensorflow.keras.layers import Dense, Flatten, Conv2D, Activation, MaxPooling2D


class MNISTModel(Model):
    def __init__(self):
        super(MNISTModel, self).__init__()
        self.conv1 = Conv2D(32, (3, 3), input_shape=(28, 28, 1))
        self.activ = Activation('relu')
        self.conv2 = Conv2D(32, (3, 3))
        self.maxpo = MaxPooling2D(pool_size=(2, 2))
        self.conv3 = Conv2D(64, (3, 3))
        self.flatt = Flatten()
        self.dense = Dense(200)
        self.dense1 = Dense(200)
        self.dens2 = Dense(10)

    def call(self, x):
        x = self.conv1(x)
        x = self.activ(x)
        x = self.conv2(x)
        x = self.activ(x)
        x = self.maxpo(x)

        x = self.conv3(x)
        x = self.activ(x)
        x = self.conv3(x)
        x = self.activ(x)
        x = self.maxpo(x)

        x = self.flatt(x)
        x = self.dense(x)
        x = self.activ(x)
        x = self.dense1(x)
        x = self.activ(x)
        return self.dens2(x)


(train_data, train_labels), (test_data, test_labels) = datasets.mnist.load_data()
train_data, test_data = train_data / 255.0, test_data / 255.0
train_data = train_data[..., tf.newaxis]
test_data = test_data[..., tf.newaxis]
print(train_data.shape, test_data.shape, type(train_data))
train_data = Dataset.from_tensor_slices(
    (train_data, train_labels)).shuffle(60000).batch(128)
test_data = Dataset.from_tensor_slices((test_data, test_labels)).batch(128)


model = MNISTModel()
loss_object = losses.SparseCategoricalCrossentropy()
optimizer = optimizers.Adam()

train_loss = metrics.Mean(name='train_loss')
train_accuracy = metrics.SparseCategoricalAccuracy(name='train_accuracy')
test_loss = metrics.Mean(name='test_loss')
test_accuracy = metrics.SparseCategoricalAccuracy(name='test_accuracy')


@tf.function
def train_step(images, labels):
    with tf.GradientTape() as tape:
        logits = model(images)
        loss_value = loss_object(labels, logits)
    grads = tape.gradient(loss_value, model.trainable_variables)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))
    train_loss(loss_value)
    train_accuracy(labels, logits)


@tf.function
def test_step(images, labels):
    logits = model(images)
    tloss_value = loss_object(labels, logits)
    test_loss(tloss_value)
    test_accuracy(labels, logits)


EPOCHS = 5

for epoch in range(EPOCHS):
    for images, labels in train_data:
        train_step(images, labels)

    for test_images, test_labels in test_data:
        test_step(test_images, test_labels)

    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'
    print (template.format(epoch + 1, train_loss.result(), train_accuracy.result()
                           * 100, test_loss.result(), test_accuracy.result() * 100))
```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30089,TypeError: Generator object is not an iterator,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home 64bit
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.12.0
- Python version: Anaconda 3.7
- GPU model and memory: GTX 1050 2GB
Edit: With tensorflow CPU (tf version: 1.14), same issue occurs.

When I'm trying to do model.fit(), memoryerror occurs, resulting in using fit_generator. 
For fit_generator, since my input is a custom 512D embedding from a previous model, I wrote my custom generator function, but while running it, following error occurs:

```
Traceback (most recent call last):
  File ""neural.py"", line 244, in <module>
    model.fit_generator(mygenerator(neural_network_x_1, neural_network_x_2, neural_network_y), steps_per_epoch= 25,epochs=100)
  File ""C:\Users\chinm\AppData\Local\conda\conda\envs\tensorflow_gpuenv\lib\site-packages\keras\legacy\interfaces.py"", line 91, in wrapper
    return func(*args, **kwargs)
  File ""C:\Users\chinm\AppData\Local\conda\conda\envs\tensorflow_gpuenv\lib\site-packages\keras\engine\training.py"", line 1418, in fit_generator
    initial_epoch=initial_epoch)
  File ""C:\Users\chinm\AppData\Local\conda\conda\envs\tensorflow_gpuenv\lib\site-packages\keras\engine\training_generator.py"", line 181, in fit_generator
    generator_output = next(output_generator)
  File ""C:\Users\chinm\AppData\Local\conda\conda\envs\tensorflow_gpuenv\lib\site-packages\keras\utils\data_utils.py"", line 709, in get
    six.reraise(*sys.exc_info())
  File ""C:\Users\chinm\AppData\Local\conda\conda\envs\tensorflow_gpuenv\lib\site-packages\six.py"", line 693, in reraise
    raise value
  File ""C:\Users\chinm\AppData\Local\conda\conda\envs\tensorflow_gpuenv\lib\site-packages\keras\utils\data_utils.py"", line 685, in get
    inputs = self.queue.get(block=True).get()
  File ""C:\Users\chinm\AppData\Local\conda\conda\envs\tensorflow_gpuenv\lib\multiprocessing\pool.py"", line 670, in get
    raise self._value
  File ""C:\Users\chinm\AppData\Local\conda\conda\envs\tensorflow_gpuenv\lib\multiprocessing\pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""C:\Users\chinm\AppData\Local\conda\conda\envs\tensorflow_gpuenv\lib\site-packages\keras\utils\data_utils.py"", line 626, in next_sample
    return six.next(_SHARED_SEQUENCES[uid])
TypeError: 'mygenerator' object is not an iterator

```
The generator class mentioned below is in the order as mentioned in: https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence

```
from tensorflow.python.keras.utils.data_utils import Sequence
class mygenerator(Sequence):
    def __init__(self, x_set_1, x_set_2, y_set, batch_size = 16):
        self.x1, self.x2, self.y = x_set_1, x_set_2, y_set
        self.batch_size = batch_size
        self.len_data = 0

    def __len__(self):
        return int(np.ceil(len(self.y) / float(self.batch_size)))

    def __getitem__(self, idx):
        batch_x1 = self.x1[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_x2 = self.x2[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]

        # read your data here using the batch lists, batch_x and batch_y
        xi = [item for item in batch_x1] 
        xj = [item for item in batch_x2] 
        yi = [item for item in batch_y]
        return np.asarray([xi, xj], yi)

model.fit_generator(mygenerator(neural_network_x_1, neural_network_x_2, neural_network_y), steps_per_epoch= 25,epochs=100)

```"
30088,"When I run ./minimal, the error message is minimal <tflite model>. Where is the tflite model","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:armv7l platform
- TensorFlow installed from (source or binary):source
- TensorFlow version:remotes/origin/r1.13
- Python version:N/A
- Installed using virtualenv? pip? conda?:git
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):arm-linux-gnueabihf-g++
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A



**Describe the problem**
I have compiled tensoflow-lite on ubuntu and successfully generated libtensorflow-lite.a and minimal, how should I test them on the Raspberry Pi? When I run ./minimal, the error message is minimal <tflite model>. Where is the tflite model, please help me, 3Q

**Provide the exact sequence of commands / steps that you executed before running into the problem**
# ./minimal 
minimal <tflite model>

# ./minimal benchmark
benchmark-lib.a  benchmark_model  
root@am57xx-evm:~/app_virtual# ./minimal benchmark_model 
Model provided has model identifier '', should be 'TFL3'

Error at tensorflow/lite/examples/minimal/minimal.cc:49

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
As above..."
30087,Multiple duplicate tflite android example projects,"### Description:
There are two examples for ""tflite image classification on android"" on the Tensorflow repo which achieve the same thing. They both have almost identical code but slight differences(In UI and in code).

**Example A:** https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android
**Example B:** https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/java

I would like to know which one is supposed to be used, and whether they can be merged so that this confusion is avoided?

### Example of a difference:

- In example A we do **not** create a NNAPI Delegate

https://github.com/tensorflow/examples/blob/156a12782a06f085adeb6b352c2763648cece066/lite/examples/image_classification/android/app/src/main/java/org/tensorflow/lite/examples/classification/tflite/Classifier.java#L179

- But in example B we do create an NNAPI Delegate

https://github.com/tensorflow/tensorflow/blob/e8ad5b0552a03e5d065a8f302dd0c0e0ae6b3925/tensorflow/lite/java/demo/app/src/main/java/com/example/android/tflitecamerademo/ImageClassifier.java#L186"
30086,How to make the Checkpoint store moments and other relevant variables in tf.train Optimizers.,"I encountered a problem when my code stopped for some reason on my machine, so I had to restart my code and continue the training process by loading the latest checkpoint file. I found that the performance is not consistent before and after the checkpoint that I loaded and the performance dropped a lot. So, since my code uses tf.train.AdamOptimizer, I guess that the checkpoint doesn't store the moment vectors and the gradients in the previous steps, and when I load the checkpoint the moment vectors are initialized as zeros. Am I correct? Is there any method that can help store relevant vectors for the Adamopotimizer in the checkpoints so that if my machine is down again, restarting from the latest checkpoint will not influence anything? Thanks! "
30085,Default values not listed for hyperparameters in tfp ExponentiatedQuadratic class,"## URL(s) with the issue:

https://www.tensorflow.org/probability/api_docs/python/tfp/positive_semidefinite_kernels/ExponentiatedQuadratic

## Description of issue (what needs changing):

List default values for hyperparameters `amplitude` and `length_scale` that are used when a kernel is created with default values, as suggested [here](https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/GaussianProcess#examples):

```
tfd = tfp.distributions
psd_kernels = tfp.positive_semidefinite_kernels

# Define a kernel with default parameters.
kernel = psd_kernels.ExponentiatedQuadratic()
```

### Parameters defined

Default values for `amplitude` and `length_scale` are not listed (apart from a keyword 'None')."
30078,TensorFlow Keras API not importing properly,"**System information**
- Have I written custom code: No
- OS Platform and Distribution: Linux Ubuntu 18.0
- TensorFlow installed from (source or binary): binary (from pip)
- TensorFlow version: I've tried 1.5, 1.10, 1.14 & 2.0 `tensorflow` and `tensorflow-gpu` binaries
- Python version: 3.6.8
- GPU model and memory: GTX 1060 3GB

**Describe the current behavior**

When I try to import `tf.keras` or `tf.python.keras`, I get `AttributeError: module 'tensorflow' has no attribute 'keras'`. I have tried various versions of tensorflow and tensorflow-gpu installed via pip. Using version 1.14 of tensorflow-gpu, it worked, however none of the submodules were available; I checked using `dir(keras)` and the module was completely empty.

**Describe the expected behavior**

It should import fine, I've copied code directly from the official tensorflow keras getting started guides.

**Code to reproduce the issue**

```python3
# works fine
import tensorflow as tf
# none of the following work; they all produce variants of the aforementioned error
from tensorflow.keras import layers
from tensorflow import keras
from tensorflow.python.keras import layers
from tensorflow.python.keras.layers import Dense
from tensorflow.python import keras
```"
30074,model = MyModel()  model1 = model works fine but model1 = MyModel() notworking ( means model and model1are not same)!!,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30073,model = MyModel() #model1 = MyModel() model1 = model,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30072,Can build tflite with xcode ?,"I build tflite with https://www.tensorflow.org/lite/guide/build_ios and set not optimizing code for debug code in tflite 
Though can hit breakpoint and step by step to debug sources but has some messy so i want build tflite from source with xcode
"
30071,Classifying Handwritten Digits with TF.Learn - Machine Learning(jupyter notebook on docker),"---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1333     try:
-> 1334       return fn(*args)
   1335     except errors.OpError as e:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1318       return self._call_tf_sessionrun(
-> 1319           options, feed_dict, fetch_list, target_list, run_metadata)
   1320 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)
   1406         self._session, options, feed_dict, fetch_list, target_list,
-> 1407         run_metadata)
   1408 

InvalidArgumentError: tensor_name = linear//weight; shape in shape_and_slice spec [1,10] does not match the shape stored in checkpoint: [784,10]
	 [[{{node save/RestoreV2}}]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py in restore(self, sess, save_path)
   1275         sess.run(self.saver_def.restore_op_name,
-> 1276                  {self.saver_def.filename_tensor_name: save_path})
   1277     except errors.NotFoundError as err:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    928       result = self._run(None, fetches, feed_dict, options_ptr,
--> 929                          run_metadata_ptr)
    930       if run_metadata:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1151       results = self._do_run(handle, final_targets, final_fetches,
-> 1152                              feed_dict_tensor, options, run_metadata)
   1153     else:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1327       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1328                            run_metadata)
   1329     else:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1347       message = error_interpolation.interpolate(message, self._graph)
-> 1348       raise type(e)(node_def, op, message)
   1349 

InvalidArgumentError: tensor_name = linear//weight; shape in shape_and_slice spec [1,10] does not match the shape stored in checkpoint: [784,10]
	 [[node save/RestoreV2 (defined at <ipython-input-56-0354ba381638>:2) ]]

Caused by op 'save/RestoreV2', defined at:
  File ""/opt/conda/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/opt/conda/lib/python3.7/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py"", line 505, in start
    self.io_loop.start()
  File ""/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py"", line 148, in start
    self.asyncio_loop.run_forever()
  File ""/opt/conda/lib/python3.7/asyncio/base_events.py"", line 539, in run_forever
    self._run_once()
  File ""/opt/conda/lib/python3.7/asyncio/base_events.py"", line 1775, in _run_once
    handle._run()
  File ""/opt/conda/lib/python3.7/asyncio/events.py"", line 88, in _run
    self._context.run(self._callback, *self._args)
  File ""/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py"", line 690, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File ""/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py"", line 743, in _run_callback
    ret = callback()
  File ""/opt/conda/lib/python3.7/site-packages/tornado/gen.py"", line 781, in inner
    self.run()
  File ""/opt/conda/lib/python3.7/site-packages/tornado/gen.py"", line 742, in run
    yielded = self.gen.send(value)
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 357, in process_one
    yield gen.maybe_future(dispatch(*args))
  File ""/opt/conda/lib/python3.7/site-packages/tornado/gen.py"", line 209, in wrapper
    yielded = next(result)
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 267, in dispatch_shell
    yield gen.maybe_future(handler(stream, idents, msg))
  File ""/opt/conda/lib/python3.7/site-packages/tornado/gen.py"", line 209, in wrapper
    yielded = next(result)
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 534, in execute_request
    user_expressions, allow_stdin,
  File ""/opt/conda/lib/python3.7/site-packages/tornado/gen.py"", line 209, in wrapper
    yielded = next(result)
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py"", line 294, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py"", line 536, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 2848, in run_cell
    raw_cell, store_history, silent, shell_futures)
  File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 2874, in _run_cell
    return runner(coro)
  File ""/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py"", line 67, in _pseudo_sync_runner
    coro.send(None)
  File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3049, in run_cell_async
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3214, in run_ast_nodes
    if (yield from self.run_code(code, result)):
  File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3296, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-56-0354ba381638>"", line 2, in <module>
    print (""Predicted %d, Label: %d"" % (classifier.predict(test_data[0]), test_labels[0]))
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 574, in new_func
    return func(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 574, in new_func
    return func(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py"", line 539, in predict
    as_iterable=as_iterable)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 574, in new_func
    return func(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py"", line 574, in predict_classes
    as_iterable=as_iterable)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 670, in predict
    iterate_batches=iterate_batches)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 974, in _infer_model
    config=self._session_config))
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session
    return self._sess_creator.create_session()
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 562, in create_session
    self._scaffold.finalize()
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 217, in finalize
    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 604, in _get_saver_or_default
    saver = Saver(sharded=True, allow_empty=True)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 832, in __init__
    self.build()
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 844, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 881, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 507, in _build_internal
    restore_sequentially, reshape)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 385, in _AddShardedRestoreOps
    name=""restore_shard""))
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 332, in _AddRestoreOps
    restore_sequentially)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 580, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 1572, in restore_v2
    name=name)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

InvalidArgumentError (see above for traceback): tensor_name = linear//weight; shape in shape_and_slice spec [1,10] does not match the shape stored in checkpoint: [784,10]
	 [[node save/RestoreV2 (defined at <ipython-input-56-0354ba381638>:2) ]]


During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-56-0354ba381638> in <module>
      1 # here's one it gets right
----> 2 print (""Predicted %d, Label: %d"" % (classifier.predict(test_data[0]), test_labels[0]))
      3 display(0)

/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    572                   func.__module__, arg_name, arg_value, 'in a future version'
    573                   if date is None else ('after %s' % date), instructions)
--> 574       return func(*args, **kwargs)
    575 
    576     doc = _add_deprecated_arg_value_notice_to_docstring(

/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    572                   func.__module__, arg_name, arg_value, 'in a future version'
    573                   if date is None else ('after %s' % date), instructions)
--> 574       return func(*args, **kwargs)
    575 
    576     doc = _add_deprecated_arg_value_notice_to_docstring(

/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py in predict(self, x, input_fn, batch_size, outputs, as_iterable)
    537           input_fn=input_fn,
    538           batch_size=batch_size,
--> 539           as_iterable=as_iterable)
    540     return super(LinearClassifier, self).predict(
    541         x=x,

/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    572                   func.__module__, arg_name, arg_value, 'in a future version'
    573                   if date is None else ('after %s' % date), instructions)
--> 574       return func(*args, **kwargs)
    575 
    576     doc = _add_deprecated_arg_value_notice_to_docstring(

/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py in predict_classes(self, x, input_fn, batch_size, as_iterable)
    572         batch_size=batch_size,
    573         outputs=[key],
--> 574         as_iterable=as_iterable)
    575     if as_iterable:
    576       return _as_iterable(preds, output=key)

/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    505                 'in a future version' if date is None else ('after %s' % date),
    506                 instructions)
--> 507       return func(*args, **kwargs)
    508 
    509     doc = _add_deprecated_arg_notice_to_docstring(

/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in predict(self, x, input_fn, batch_size, outputs, as_iterable, iterate_batches)
    668         outputs=outputs,
    669         as_iterable=as_iterable,
--> 670         iterate_batches=iterate_batches)
    671 
    672   def get_variable_value(self, name):

/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in _infer_model(self, input_fn, feed_fn, outputs, as_iterable, iterate_batches)
    972               checkpoint_filename_with_path=checkpoint_path,
    973               scaffold=infer_ops.scaffold,
--> 974               config=self._session_config))
    975       if not as_iterable:
    976         with mon_sess:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py in __init__(self, session_creator, hooks, stop_grace_period_secs)
    932     super(MonitoredSession, self).__init__(
    933         session_creator, hooks, should_recover=True,
--> 934         stop_grace_period_secs=stop_grace_period_secs)
    935 
    936 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py in __init__(self, session_creator, hooks, should_recover, stop_grace_period_secs)
    646         stop_grace_period_secs=stop_grace_period_secs)
    647     if should_recover:
--> 648       self._sess = _RecoverableSession(self._coordinated_creator)
    649     else:
    650       self._sess = self._coordinated_creator.create_session()

/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py in __init__(self, sess_creator)
   1120     """"""
   1121     self._sess_creator = sess_creator
-> 1122     _WrappedSession.__init__(self, self._create_session())
   1123 
   1124   def _create_session(self):

/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py in _create_session(self)
   1125     while True:
   1126       try:
-> 1127         return self._sess_creator.create_session()
   1128       except _PREEMPTION_ERRORS as e:
   1129         logging.info('An error was raised while a session was being created. '

/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py in create_session(self)
    803       """"""Creates a coordinated session.""""""
    804       # Keep the tf_sess for unit testing.
--> 805       self.tf_sess = self._session_creator.create_session()
    806       # We don't want coordinator to suppress any exception.
    807       self.coord = coordinator.Coordinator(clean_stop_exception_types=[])

/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py in create_session(self)
    569         init_op=self._scaffold.init_op,
    570         init_feed_dict=self._scaffold.init_feed_dict,
--> 571         init_fn=self._scaffold.init_fn)
    572 
    573 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/session_manager.py in prepare_session(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)
    279         wait_for_checkpoint=wait_for_checkpoint,
    280         max_wait_secs=max_wait_secs,
--> 281         config=config)
    282     if not is_loaded_from_checkpoint:
    283       if init_op is None and not init_fn and self._local_init_op is None:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/session_manager.py in _restore_checkpoint(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)
    193 
    194     if checkpoint_filename_with_path:
--> 195       saver.restore(sess, checkpoint_filename_with_path)
    196       return sess, True
    197 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py in restore(self, sess, save_path)
   1310       # We add a more reasonable error message here to help users (b/110263146)
   1311       raise _wrap_restore_error_with_msg(
-> 1312           err, ""a mismatch between the current graph and the graph"")
   1313 
   1314   @staticmethod

InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

tensor_name = linear//weight; shape in shape_and_slice spec [1,10] does not match the shape stored in checkpoint: [784,10]
	 [[node save/RestoreV2 (defined at <ipython-input-56-0354ba381638>:2) ]]

Caused by op 'save/RestoreV2', defined at:
  File ""/opt/conda/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/opt/conda/lib/python3.7/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py"", line 505, in start
    self.io_loop.start()
  File ""/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py"", line 148, in start
    self.asyncio_loop.run_forever()
  File ""/opt/conda/lib/python3.7/asyncio/base_events.py"", line 539, in run_forever
    self._run_once()
  File ""/opt/conda/lib/python3.7/asyncio/base_events.py"", line 1775, in _run_once
    handle._run()
  File ""/opt/conda/lib/python3.7/asyncio/events.py"", line 88, in _run
    self._context.run(self._callback, *self._args)
  File ""/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py"", line 690, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File ""/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py"", line 743, in _run_callback
    ret = callback()
  File ""/opt/conda/lib/python3.7/site-packages/tornado/gen.py"", line 781, in inner
    self.run()
  File ""/opt/conda/lib/python3.7/site-packages/tornado/gen.py"", line 742, in run
    yielded = self.gen.send(value)
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 357, in process_one
    yield gen.maybe_future(dispatch(*args))
  File ""/opt/conda/lib/python3.7/site-packages/tornado/gen.py"", line 209, in wrapper
    yielded = next(result)
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 267, in dispatch_shell
    yield gen.maybe_future(handler(stream, idents, msg))
  File ""/opt/conda/lib/python3.7/site-packages/tornado/gen.py"", line 209, in wrapper
    yielded = next(result)
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 534, in execute_request
    user_expressions, allow_stdin,
  File ""/opt/conda/lib/python3.7/site-packages/tornado/gen.py"", line 209, in wrapper
    yielded = next(result)
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py"", line 294, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py"", line 536, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 2848, in run_cell
    raw_cell, store_history, silent, shell_futures)
  File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 2874, in _run_cell
    return runner(coro)
  File ""/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py"", line 67, in _pseudo_sync_runner
    coro.send(None)
  File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3049, in run_cell_async
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3214, in run_ast_nodes
    if (yield from self.run_code(code, result)):
  File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3296, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-56-0354ba381638>"", line 2, in <module>
    print (""Predicted %d, Label: %d"" % (classifier.predict(test_data[0]), test_labels[0]))
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 574, in new_func
    return func(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 574, in new_func
    return func(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py"", line 539, in predict
    as_iterable=as_iterable)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 574, in new_func
    return func(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py"", line 574, in predict_classes
    as_iterable=as_iterable)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 670, in predict
    iterate_batches=iterate_batches)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 974, in _infer_model
    config=self._session_config))
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session
    return self._sess_creator.create_session()
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 562, in create_session
    self._scaffold.finalize()
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py"", line 217, in finalize
    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 604, in _get_saver_or_default
    saver = Saver(sharded=True, allow_empty=True)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 832, in __init__
    self.build()
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 844, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 881, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 507, in _build_internal
    restore_sequentially, reshape)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 385, in _AddShardedRestoreOps
    name=""restore_shard""))
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 332, in _AddRestoreOps
    restore_sequentially)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 580, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 1572, in restore_v2
    name=name)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

InvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

tensor_name = linear//weight; shape in shape_and_slice spec [1,10] does not match the shape stored in checkpoint: [784,10]
	 [[node save/RestoreV2 (defined at <ipython-input-56-0354ba381638>:2) ]]
"
30070,AttributeError: module 'tensorflow' has no attribute 'set_random_seed',"tf2.0

    tf.set_random_seed(self._seed)
AttributeError: module 'tensorflow' has no attribute 'set_random_seed'"
30069,Support Sparse Tensors in py_function,"- TensorFlow version (you are using): 2.0.0b0
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
Currently, sparse tensors don't seem to be supported as inputs to `py_function`. Attempting to pass one results in an error like ""`TypeError: Tensors in list passed to 'input' of 'EagerPyFunc' Op have types [<NOT CONVERTIBLE TO TENSOR>] that are invalid.`"". Example:

    def dataset_map_sparse_test():
        input_data_sparse = tf.SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])
        input_data_dense = tf.sparse.to_dense(input_data_sparse)
    
        ds_dense = tf.data.Dataset.from_tensor_slices(input_data_dense)
        ds_sparse = tf.data.Dataset.from_tensor_slices(input_data_sparse)

        def inner_fn(*input):
            return input

        def outer_fn(*input_data):
            return tf.py_function(
                inner_fn,
                input_data,
                (tf.int32,))

        # this works
        ds_dense_mapped = ds_dense.map(outer_fn)
        print(next(iter(ds_dense_mapped)))

        # this results in the error specified above
        ds_sparse_mapped = ds_sparse.map(outer_fn)
        print(next(iter(ds_sparse_mapped)))

**Will this change the current api? How?**
Yes. The `inp` parameter of `py_function` currently accepts a list of `Tensor` objects; this change would broaden it to accept either `Tensor`s or `SparseTensor`s. (Possibly `_TensorLike`s?)

**Who will benefit with this feature?**
Anyone wishing to pass sparse tensors to a `py_function`-wrapped function. There are situations where this wrapping is necessary; for example, functions passed to `Dataset.map` cannot perform certain operations unless the function is wrapped using `py_function`.

**Any Other info.**
"
30068,Device getting slower when running tensorflow c++,"Dear all, I have encountered a problem that tensorflow inference time is getting slower. 

Situation:

Our device is used in the production line and tensorflow prediction is one of the module in the whole project. Since in production line the device is operating for a very long time (24 hours non-stop), after a few days (probably 3-5 days) we can feel that the device is getting slower and tensorflow inference time is about 2-3 times as usual. We suspect it was caused by GPU memory leak or some other issues. May I ask has anyone encountered such problem? How should I do with this situation?

Environment:

OS: Windows 10 (64 bits)
CPU: I7 - 6th Generation
GPU: Nvidia GTX 1050 Ti
TF Version: r1.4
CMake build with VS 2015
"
30066, How to configure c++ tensorflow1.13 environment under vs2015 compiler?, how to configure c++ tensorflow1.13 environment under vs2015 compiler?
30065,No such package 'tensorflow/contrib/android': BUILD file not found on package path,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
- TensorFlow installed from (source or binary): source
- TensorFlow version: last version from Github
- Python version: 3.6
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.26
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0/7.4
- GPU model and memory: Nivida Geforce 840m



**Describe the problem**

I try to use this tool for building .so file using this command line:
> bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so  --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cxxopt=-std=c++11  --cpu=armeabi-v7a

But I get this error :
> ERROR: Skipping '//tensorflow/contrib/android:libtensorflow_inference.so': no such package 'tensorflow/contrib/android': BUILD file not found on package path
WARNING: Target pattern parsing failed.
ERROR: no such package 'tensorflow/contrib/android': BUILD file not found on package path
INFO: Elapsed time: 0.543s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)

How can I solve it?
Thanks"
30064,Deploy .pb frozen model in Android mobile,"Hello,
I have worked on iris detection ( in the human eye ) in the real-time project using deep learning. So I have used a CNN model based on facial landmarks detection using Tensorflow GPU version with regression predict and I have modified the number of points to get only the iris region, 
I have now .ckpt files trained the model with 146 000 steps and I have tried to freeze the model but I'm not sure that the process of the freeze is correct or no.
I get a .pb file with size 28 Mo.
I want to deploy and use this .pb file into an Android application to detect the iris region by drawing the landmarks on it.
How can I use a .pb file for Android application?
How can I extract the prediction from .pb file in the Android application?
Thanks
"
30063,Tensorflow Bitcast - float32 to int32 to float32?,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): ('v1.10.1-0-g4dcfddc5d1', '1.10.1')
- Python version: 2.7.12
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CPU
- GPU model and memory: 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Based off of the network, found at, 
https://www.easy-tensorflow.com/tf-tutorials/convolutional-neural-nets-cnns/cnn1
and after some additional modifications, I added layers before and after each convolutional layer that bitcasts the initial tf.float32 to a tf.int32 and back to a tf.float32. This resulted in a average accuracy loss of 5% compared to passing the tensor through the layer unmodified 

**Describe the expected behavior**
Based off of the documentation:
> tf.bitcast ( input, type, name=None )
> Given a tensor _input_, this operation returns a tensor that has the same buffer data as _input_ with datatype _type_.

I expected that a change and return to the original data type, without modifying the buffer data would not cause that amount of decrease to the network's accuracy.  

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

`
import tensorflow as tf
import numpy as np

old_v = tf.logging.get_verbosity()
tf.logging.set_verbosity(tf.logging.ERROR)

from tensorflow.examples.tutorials.mnist import input_data

#Image / Class Information
img_h = img_w = 28  # MNIST images are 28x28
img_size_flat = img_h * img_w  # 28x28=784, the total number of pixels
n_classes = 10  # Number of classes, one class per digit
n_channels = 1

 #Numpy Number Type
npNumberType = np.float32


def load_data(mode='train'):
    mnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)
    if mode == 'train':
        x_train, y_train, x_valid, y_valid = mnist.train.images, mnist.train.labels, \
                                             mnist.validation.images, mnist.validation.labels
        x_train, _ = reformat(x_train, y_train)
        x_valid, _ = reformat(x_valid, y_valid)
        return x_train, y_train, x_valid, y_valid
    elif mode == 'test':
        x_test, y_test = mnist.test.images, mnist.test.labels
        x_test, _ = reformat(x_test, y_test)
    return x_test, y_test


def reformat(x, y):
    img_size, num_ch, num_class = int(np.sqrt(x.shape[-1])), 1, len(np.unique(np.argmax(y, 1)))
    dataset = x.reshape((-1, img_size, img_size, num_ch)).astype(npNumberType)
    labels = (np.arange(num_class) == y[:, None]).astype(npNumberType)
    return dataset, labels


def randomize(x, y):
    permutation = np.random.permutation(y.shape[0])
    shuffled_x = x[permutation, :, :, :]
    shuffled_y = y[permutation]
    return shuffled_x, shuffled_y


def get_next_batch(x, y, start, end):
    x_batch = x[start:end]
    y_batch = y[start:end]
    return x_batch, y_batch


x_train, y_train, x_valid, y_valid = load_data(mode='train')
print(""Size of:"")
print(""- Training-set:\t\t{}"".format(len(y_train)))
print(""- Validation-set:\t{}"".format(len(y_valid)))

def padding (x, name):
    dtypecast = tf.bitcast(x, tf.int32)
    return tf.bitcast(dtypecast, tf.float32, name=name)

#TensorFlow Number Format
tfGraphNumberType = tf.float32
rngseed = 1234

for runs in range(1, 2, 1):
    tf.reset_default_graph()
    tf.set_random_seed(rngseed)
    np.random.seed(rngseed)

    with tf.name_scope('Input'):
        x = tf.placeholder(tfGraphNumberType, shape=[None, img_h, img_w, n_channels], name='X')
        y = tf.placeholder(tfGraphNumberType, shape=[None, n_classes], name='Y')

    padding0 = padding(x, 'Pad0')

    # 1st Convolutional Layer
    filter_size1 = 5  # Convolution filters are 5 x 5 pixels.
    num_filters1 = 16  # There are 16 of these filters.
    stride1 = 1  # The stride of the sliding window

    with tf.variable_scope('conv1'):
        num_in_channel = padding0.get_shape().as_list()[-1]
        W = tf.get_variable('W', dtype=tfGraphNumberType,
                            shape=[filter_size1, filter_size1, num_in_channel, num_filters1],
                            initializer=tf.truncated_normal_initializer(stddev=0.01,seed=rngseed))
        tf.summary.histogram('weight', W)
        b = tf.get_variable('b', dtype=tfGraphNumberType,
                            initializer=tf.constant(0., shape=[num_filters1], dtype=tfGraphNumberType))
        tf.summary.histogram('bias', b)
        layer = tf.nn.conv2d(padding0, W, strides=[1, stride1, stride1, 1], padding=""SAME"")
        layer += b
        conv1 = tf.nn.relu(layer)

    shape = conv1.get_shape().as_list()[-1]
    padding1 = padding(conv1, 'Pad1')
    pool1 = tf.nn.max_pool(padding1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=""SAME"", name='pool1')

    # 2nd Convolutional Layer
    filter_size2 = 5  # Convolution filters are 5 x 5 pixels.
    num_filters2 = 32  # There are 32 of these filters.
    stride2 = 1  # The stride of the sliding window

    with tf.variable_scope('conv2'):
        num_in_channel = pool1.get_shape().as_list()[-1]
        W = tf.get_variable('W', dtype=tfGraphNumberType,
                            shape=[filter_size2, filter_size2, num_in_channel, num_filters2],
                            initializer=tf.truncated_normal_initializer(stddev=0.01, seed=rngseed))
        tf.summary.histogram('weight', W)
        b = tf.get_variable('b', dtype=tfGraphNumberType,
                            initializer=tf.constant(0., shape=[num_filters2], dtype=tfGraphNumberType))
        tf.summary.histogram('bias', b)
        layer = tf.nn.conv2d(pool1, W, strides=[1, stride2, stride2, 1], padding=""SAME"")
        layer += b
        conv2 = tf.nn.relu(layer)

    padding2 = padding(conv2, 'Pad2')
    pool2 = tf.nn.max_pool(padding2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=""SAME"", name='pool2')

    with tf.variable_scope('Flatten_layer'):
        layer_shape = pool2.get_shape()
        num_features = layer_shape[1:4].num_elements()
        layer_flat = tf.reshape(pool2, [-1, num_features])

    # Fully-connected layer.
    h1 = 128  # Number of neurons in fully-connected layer.

    with tf.variable_scope('FC1'):
        in_dim = layer_flat.get_shape()[1]
        W = tf.get_variable('W', dtype=tfGraphNumberType,
                            shape=[in_dim, h1],
                            initializer=tf.truncated_normal_initializer(stddev=0.01, seed=1234))
        tf.summary.histogram('weight', W)
        b = tf.get_variable('b', dtype=tfGraphNumberType,
                            initializer=tf.constant(0., shape=[h1], dtype=tfGraphNumberType))
        tf.summary.histogram('bias', b)

        layer = tf.matmul(layer_flat, W)
        layer += b
        fc1 = tf.nn.relu(layer)

    with tf.variable_scope('OUT'):
        in_dim = fc1.get_shape()[1]
        W = tf.get_variable('W', dtype=tfGraphNumberType,
                            shape=[in_dim, n_classes],
                            initializer=tf.truncated_normal_initializer(stddev=0.01, seed=rngseed))
        tf.summary.histogram('weight', W)
        b = tf.get_variable('b', dtype=tfGraphNumberType,
                            initializer=tf.constant(0., shape=[n_classes], dtype=tfGraphNumberType))
        tf.summary.histogram('bias', b)

        output_logits = tf.matmul(fc1, W)
        output_logits += b

    # Training Variables
    logs_path = ""./logs""  # path to the folder that we want to save the logs for Tensorboard
    lr = 0.001  # The optimization initial learning rate
    epochs = 5  # Total number of training epochs
    batch_size = 100  # Training batch size
    display_freq = 50  # Frequency of displaying the training results
    tfOutputNumberType = tf.float32

    with tf.variable_scope('Train'):
        with tf.variable_scope('Loss'):
            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_logits), name='loss')
        tf.summary.scalar('loss', loss)
        with tf.variable_scope('Optimizer'):
            optimizer = tf.train.AdamOptimizer(learning_rate=lr, name='Adam-op').minimize(loss)
        with tf.variable_scope('Accuracy'):
            correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1), name='correct_pred')
            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tfOutputNumberType), name='accuracy')
        tf.summary.scalar('accuracy', accuracy)
        with tf.variable_scope('Prediction'):
            cls_prediction = tf.argmax(output_logits, axis=1, name='predictions')

    # Number of training iterations in each epoch
    num_tr_iter = int(len(y_train) / batch_size)

    # Initialize the variables
    init = tf.global_variables_initializer()
    # Merge all summaries
    merged = tf.summary.merge_all()

    sess = tf.InteractiveSession()
    sess.run(init)
    global_step = 0
    summary_writer = tf.summary.FileWriter(logs_path, sess.graph)

    print('R: {}'.format(runs))
    for epoch in range(epochs):
        #print('Training epoch: {}'.format(epoch + 1))
        x_train, y_train = randomize(x_train, y_train)
        for iteration in range(num_tr_iter):
            global_step += 1
            start = iteration * batch_size
            end = (iteration + 1) * batch_size
            x_batch, y_batch = get_next_batch(x_train, y_train, start, end)

            # Run optimization op (backprop)
            feed_dict_batch = {x: x_batch, y: y_batch}
            sess.run(optimizer, feed_dict=feed_dict_batch)

            if iteration % display_freq == 0:
                # Calculate and display the batch loss and accuracy
                loss_batch, acc_batch, summary_tr = sess.run([loss, accuracy, merged],
                                                             feed_dict=feed_dict_batch)
                summary_writer.add_summary(summary_tr, global_step)

                print(""I:{0:3d}:\t L={1:.2f},\tA={2:.01%}"".
                      format(iteration, loss_batch, acc_batch))


        # Run validation after every epoch
        feed_dict_valid = {x: x_valid, y: y_valid}
        loss_valid, acc_valid = sess.run([loss, accuracy], feed_dict=feed_dict_valid)

        print(""M:{0}\tE:{1}\tF\tA:{2:.01%}"".
              format(runs, epoch + 1, acc_valid))


    # Test the network when training is done
    x_test, y_test = load_data(mode='test')
    feed_dict_test = {x: x_test, y: y_test}
    loss_test, acc_test = sess.run([loss, accuracy], feed_dict=feed_dict_test)
    print('---------------------------------------------------------')
    print(""Test loss: {0:.2f}, test accuracy: {1:.01%}"".format(loss_test, acc_test))
    print('---------------------------------------------------------')

    # close the session after you are done with testing
    sess.close()
`

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I attached a spreadsheet file with the results of training with different datatypes and my expectations. I apoplgize for any mistakes or missing information. Thank you.
[Bitcast Logs.xlsx](https://github.com/tensorflow/tensorflow/files/3318652/Bitcast.Logs.xlsx)

"
30061,Method mentioned in documentation is missing: tf.keras.preprocessing.text.tokenizer_from_json,"**System information**
- TensorFlow version: v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1

**Describe the current behavior**
Error raised when attempting to call `tf.keras.preprocessing.text.tokenizer_from_json`:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
----> 1 tf.keras.preprocessing.text.tokenizer_from_json

AttributeError: module 'tensorflow.python.keras.api._v2.keras.preprocessing.text' has no attribute 'tokenizer_from_json'
```

**Describe the expected behavior**
I expect this method to be callable per the documentation of `tf.keras.preprocessing.text.Tokenizer.to_json` (below), which says we can use `keras.preprocessing.text.tokenizer_from_json(json_string)` to load a tokenizer.

Otherwise, there's no obvious way to use the output of `Tokenizer.to_json` to restore a tokenizer.

```
Signature: tf.keras.preprocessing.text.Tokenizer.to_json(self, **kwargs)
Docstring:
Returns a JSON string containing the tokenizer configuration.
To load a tokenizer from a JSON string, use
`keras.preprocessing.text.tokenizer_from_json(json_string)`.

# Arguments
    **kwargs: Additional keyword arguments
        to be passed to `json.dumps()`.

# Returns
    A JSON string containing the tokenizer configuration.
```
**Code to reproduce the issue**
```python3
json_string = tf.keras.preprocessing.text.Tokenizer().to_json()
tf.keras.preprocessing.text.tokenizer_from_json(json_string)
```"
30060,arm-none-eabi-g++: error: tensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//lib/gcc/arm-none-eabi/7.3.1/thumb/v7e-m/fpv4-sp/hard/crtbegin.o: No such file or directory tensorflow/lite/experimental/micro/examples/micro_speech/Makefile.inc:372: recipe for target 'tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/micro_speech' failed make: *** [tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/micro_speech] Error 1,"arm-none-eabi-g++: error: tensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded//lib/gcc/arm-none-eabi/7.3.1/thumb/v7e-m/fpv4-sp/hard/crtbegin.o: No such file or directory
tensorflow/lite/experimental/micro/examples/micro_speech/Makefile.inc:372: recipe for target 'tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/micro_speech' failed
make: *** [tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/micro_speech] Error 1"
30059,Eager execution gradients for Grad CAM,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat Enterprise 7, Windows 10 Education
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.13.1
- **Python version**: 3.7.3
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: 10.1, 7.4
- **GPU model and memory**: RTX 2080, 8GB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I have been struggling with this for a few days and finally decided this was an issue worthy of submission here because it deals directly with documentation. I am trying to use TensorFlow eager execution to visualize gradient class activation maps for images, but I'm absolutely stuck on how to compute the gradient between two layers of a sequential model.

The core of the question is how to implement [this](http://www.hackevolve.com/where-cnn-is-looking-grad-cam/) in TensorFlow with eager execution. This seems like it should be simple to do (considering it's almost verbatim an example from _Deep Learning with Python_  by FranÃ§ois Chollet), but I cannot find any documentation regarding it.

I posted this to StackOverflow in the hopes that somebody might be able to point me in the right direction, but so far no luck: https://stackoverflow.com/questions/56711640/tensorflow-eager-execution-compute-gradient-between-two-layers-of-a-sequential

One line, in particular, has me stumped:

```python
grads = K.gradients(class_output, last_conv_layer.output)[0]
```

I understand that it is finding the gradients between the last convolutional layer and the output for the particular class. However, I cannot figure out how to accomplish this using `GradientTape`, since (a) both are tensors and not variables, and (b) one is not directly derived from the other (their feature maps already exist, so without a graph they are effectively independent).

The obvious steps are reproducing the first part with Eager execution.

```python
import numpy as np
import cv2
import tensorflow as tf
tf.enable_eager_execution()

model = tf.keras.models.load_model(""model.h5"")
print(type(model))
# tensorflow.python.keras.engine.sequential.Sequential

from dataset import prepare_dataset
_, ds, _, _, _, _ = prepare_dataset() # ds is a tf.data.Dataset
print(type(ds))
# tensorflow.python.data.ops.dataset_ops.DatasetV1Adapter

it = train_ds.make_one_shot_iterator()
img, label = it.get_next()
print(type(img), img.shape)
# <class 'tensorflow.python.framework.ops.EagerTensor'> (192, 192, 3)

print(type(label), label.shape)
# <class 'tensorflow.python.framework.ops.EagerTensor'> (2,)

img = np.expand_dims(img, axis=0)
print(img.shape)
# (1, 192, 192, 3)

predictions = model.predict(img)
print(predictions)
# array([[0.9711799 , 0.02882008]], dtype=float32)

class_idx = np.argmax(predictions[0])
print(class_idx)
# 0

class_output = model.output[:, class_idx]
print(model.output, class_output)
# Tensor(""Softmax:0"", shape=(?, 2), dtype=float32) Tensor(""strided_slice_5:0"", dtype=float32)

last_conv_layer = model.get_layer('conv2d_33') # the last conv layer

""""""
Now, the fun part: how do I compute the gradient of class_output with respect to
the output of the last convolutional layer?
""""""
```

One attempt is using reduce_sum and multiply to get the desired gradient (ignore the `class_output` step):

```python
with tf.GradientTape() as tape: 
    print(label)
    # tf.Tensor([1. 0.], shape=(2,), dtype=float32)
    y_c = tf.reduce_sum(tf.multiply(model.output, label))
    print(y_c)
    # Tensor(""Sum_4:0"", shape=(), dtype=float32)
    last_conv_layer = model.get_layer('activation_6')

grad = tape.gradient(y_c, last_conv_layer.output)
```

However, `grad` is `None` in this setup.

I am unclear on where to go from here. Any help is appreciated."
30057,tensorflow docker images with python3.6 as default version,"Since many repo using python 3.6 as default version, so recommend using python3.6 as default version for tensorflow docker images.
"
30056,multi-gpu training: tf.compat.v1.scatter_sub() operation throws exception,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
    - Extended from the stock example
    - https://www.tensorflow.org/beta/tutorials/distribute/keras
    - Working example is attached to this bug report
- OS Platform and Distribution
    - Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
    - No
- TensorFlow installed from (source or binary):
    - Binary
- TensorFlow version (use command below):
    - 2.0.0-beta1
- Python version:
    - Python 3.5.2
- Bazel version (if compiling from source):
    - N/A (0.23.2)
- GCC/Compiler version (if compiling from source):
    - N/A (5.4.0 20160609)
- CUDA/cuDNN version:
    - 10.0.130/7.4.1
- GPU model and memory:
    - 4x Titan Xp (12Gb) (Standalong, no SLI connections)

**Describe the current behavior**
```
tf.compat.v1.scatter_sub does not support multi-gpu training.

    AttributeError: 'Tensor' object has no attribute '_lazy_read'

    is thrown in the tf.compat.v1.scatter_sub() operation.

There is no equivalent scatter_* operations in tf.compat.v2 module.
```

**Describe the expected behavior**
tf.compat.v1.scatter_sub or equivalent scatter_* operations should support multi-gpu training.


**Code to reproduce the issue**
1. The script attached is used to train a model using multiple GPUs.
  * The code is modified from the stock example for quick experiment.
    * https://www.tensorflow.org/beta/tutorials/distribute/keras

**Other info / logs**
```
WARNING: Logging before flag parsing goes to stderr.
W0622 23:56:34.418763 140543953778432 cross_device_ops.py:1164] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:1,/job:localhost/replica:0/task:0/device:GPU:0
Number of devices: 2
Traceback (most recent call last):
  File ""center_loss_mnist.py"", line 326, in <module>
    run(0.0001)
  File ""center_loss_mnist.py"", line 259, in run
    final_output, side_output = my_model(main_input, aux_input)
  File ""center_loss_mnist.py"", line 119, in my_model
    side = CenterLossLayer(alpha=0.5, name='centerlosslayer')([x, labels])
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 662, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py"", line 169, in wrapper
    raise e.ag_error_metadata.to_exception(type(e))
AttributeError: in converted code:

    center_loss_mnist.py:179 call  *
        new_centers = tf.compat.v1.scatter_sub(self.centers, x[1], delta_centers)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/state_ops.py:535 scatter_sub
        return ref._lazy_read(gen_resource_variable_ops.resource_scatter_sub(  # pylint: disable=protected-access
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/distribute/values.py:381 __getattr__
        return getattr(self.get(), name)

    AttributeError: 'Tensor' object has no attribute '_lazy_read'
```

** Run the script using the following command
```
export CUDA_VISIBLE_DEVICES=""0""
python3 center_loss_mnist.py
```

** Save the following script as ""center_loss_mnist.py""

```python

from datetime import datetime
from tensorflow.keras import backend as K
from tensorflow.keras import initializers
from tensorflow.keras import losses
from tensorflow.keras import optimizers
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Layer
from tensorflow.keras.layers import MaxPool2D
from tensorflow.keras.layers import PReLU
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
import math
import numpy as np
import os
import shutil
import tensorflow as tf

### parameters
batch_size = 64
epochs = 10
weight_decay = 0.0005

def init_gpus(soft_device_placement=True, log_device_placement=False, create_virtual_devices=False, memory_limit=4096):

    tf.config.set_soft_device_placement(soft_device_placement)    
    tf.debugging.set_log_device_placement(log_device_placement)

    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        # If there is only one GPU, create two logical virtual devices for developing
        # on a machine with only one GPU installed
        try:
            # Create 2 virtual GPUs on each physical GPU with the given memory_limit GPU memory
            if create_virtual_devices and len(gpus) == 1:
                tf.config.experimental.set_virtual_device_configuration(
                    gpus[0],
                    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096),
                     tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]
                )

            else:
                # Currently, memory growth needs to be the same across GPUs
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)

        except RuntimeError as e:
            # Memory growth must be set before GPUs have been initialized
            print(e)

        # print out physical and logical GPUs
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")

    else:
        print(""No visible GPU is detected..."")

def prelu(x, name='default'):
    if name == 'default':
        return PReLU(alpha_initializer=initializers.Constant(value=0.25))(x)
    else:
        return PReLU(alpha_initializer=initializers.Constant(value=0.25), name=name)(x)

def center_loss(y_true, y_pred):
    """"""Center loss based on the paper ""A Discriminative Feature Learning Approach for Deep Face Recognition""
       (http://ydwen.github.io/papers/WenECCV16.pdf)
       Lc = 1/2 sum(|| xi - ci||)
    """"""
    return 0.5 * K.sum(y_pred, axis=0)

### model
def my_model(x, labels):
    # x = BatchNormalization()(x)
    #
    x = Conv2D(filters=32, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = prelu(x)

    x = Conv2D(filters=32, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = prelu(x)

    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)
    #
    x = Conv2D(filters=64, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = prelu(x)

    x = Conv2D(filters=64, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = prelu(x)

    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)
    #
    x = Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = prelu(x)

    x = Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = prelu(x)

    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)
    x = Dropout(0.25)(x)
    #
    x = Flatten()(x)
    x = Dense(2, kernel_regularizer=l2(weight_decay))(x)
    x = prelu(x, name='side_out')
    #
    main = Dense(10, activation='softmax', name='main_out', kernel_regularizer=l2(weight_decay))(x)
    side = CenterLossLayer(alpha=0.5, name='centerlosslayer')([x, labels])
    return main, side

# Function for decaying the learning rate.
# You can define any decay function you need.
def lr_schedule(epoch):
    if epoch <= 5:
        learning_rate = 1e-3

    elif epoch <= 10:
        learning_rate = 1e-4

    else:
        learning_rate = 1e-5

    tf.summary.scalar('learning_rate', data=learning_rate, step=epoch)
    return learning_rate

class CenterLossLayer(Layer):

    def __init__(self, alpha=0.5, **kwargs):
        super().__init__(**kwargs)
        self.alpha = alpha

    def build(self, input_shape):
        self.centers = self.add_weight(
            name='centers',
            shape=(10, 2),
            initializer='uniform',
            trainable=False
        )

        super().build(input_shape)

    def call(self, x):
        """"""This is where the layer's logic lives.
        Arguments:
            inputs: Input tensor, or list/tuple of input tensors.
            **kwargs: Additional keyword arguments.
        Returns:
            A tensor or list/tuple of tensors.
        """"""
        features = x[0]
        labels = K.reshape(x[1], [-1])

        # get the tensor as specified in the label
        # the centers might repeate depending on the label index
        centers_batch = K.gather(self.centers, labels)

        unique_label, unique_idx, unique_count = tf.unique_with_counts(labels)
        appear_times = K.gather(unique_count, unique_idx)
        appear_times = K.reshape(appear_times, [-1, 1])
        #
        # center_loss_alfa default 0.5
        delta_centers = centers_batch - features
        delta_centers = delta_centers / tf.cast((1 + appear_times), tf.float32)
        delta_centers = self.alpha * delta_centers

        # scatter_sub does not support multi-gpu training, there is no equivalent operation 
        new_centers = tf.compat.v1.scatter_sub(self.centers, x[1], delta_centers)

        self.add_update((self.centers, new_centers), x)
        self.result = K.sum(K.square(features - centers_batch), axis=1, keepdims=True)
        return self.result

    def compute_output_shape(self, input_shape):
        return K.int_shape(self.result)

def empty_dir(folder):
    """"""
    Empty a folder recursively.
    """"""
    for file in os.listdir(folder):
        file_path = os.path.join(folder, file)
        if os.path.isfile(file_path):
            print(""Remove file: {}"".format(file_path))
            os.remove(file_path)
        else:
            empty_dir(file_path)
            print(""Remove folder: {}"".format(file_path))
            os.rmdir(file_path)

def build_empty_dir(folder, root_dir=os.getcwd()):
    base_dir = os.path.join(root_dir, folder)
    os.makedirs(base_dir, exist_ok=True)
    empty_dir(os.path.join(root_dir, folder))

    return base_dir

""""""
unset CUDA_VISIBLE_DEVICES

export CUDA_VISIBLE_DEVICES=""0""
python3 center_loss_mnist.py
""""""

### run model
def run(lambda_centerloss):

    init_gpus(
        log_device_placement=False,
        create_virtual_devices=True
    )
    
    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())
    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())
    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce())
    strategy = tf.distribute.MirroredStrategy()
    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))

    ### get data
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    # normalize to 0..1
    x_train, x_test = x_train/255, x_test/255
    x_train = np.float32(x_train);
    x_test  = np.float32(x_test)

    y_train = np.int32(y_train)
    y_test = np.int32(y_test)

    # reshape to matrix
    x_train = x_train.reshape((-1, 28, 28, 1))
    x_test = x_test.reshape((-1, 28, 28, 1))

    ### compile
    main_input = Input((28, 28, 1))
    aux_input = Input((), dtype='int32')

    # Training using Multi-GPUs
    # 
    # tf.compat.v1.scatter_sub does not support multi-gpus training
    # with strategy.scope():
    #
    # The following exception with be thrown.
    #
    # AttributeError: 'Tensor' object has no attribute '_lazy_read'

    # comment out the following line for the training to run successfully
    with strategy.scope():
        final_output, side_output = my_model(main_input, aux_input)
        model = Model(inputs=[main_input, aux_input], outputs=[final_output, side_output])
        model.compile(
            optimizer='adam',
            loss=[losses.sparse_categorical_crossentropy, center_loss],
            metrics=['accuracy'],
            loss_weights=[1, lambda_centerloss]
        )
        model.summary()

    ### create the log directory
    log_dir = '/tmp/logs/' + datetime.strftime(datetime.now(), '%Y%m%d-%H%M%S')
    build_empty_dir(log_dir)

    # Initialize the file_writer for logging summary
    # create the file_writer to save events for Tensorboard
    summary_log_dir = log_dir + '/train'
    file_writer = tf.summary.create_file_writer(summary_log_dir)
    file_writer.set_as_default()    

    tb_callback = TensorBoard(log_dir=log_dir)

    # https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/LearningRateScheduler
    lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)

    ### fit
    dummy1 = np.zeros((x_train.shape[0], 1), dtype=int)
    dummy2 = np.zeros((x_test.shape [0], 1), dtype=int)

    #
    print('model.input[0].shape = ', model.input[0].shape)
    print('model.get_layer(\'side_out\').output.shape = ', model.get_layer('side_out').output.shape)
    #
    model.fit(
        [x_train, y_train],     # inputs =[main_input, aux_input]
        [y_train, dummy1 ],     # outputs=[final_output, side_output]
        batch_size=batch_size,
        epochs=epochs,
        verbose=1,
        validation_data=([x_test, y_test], [y_test, dummy2]),
        callbacks=[tb_callback, lr_callback]
    )
    # validation
    reduced_model = Model(inputs=model.input[0], outputs=model.get_layer('main_out').output)
    reduced_model.compile(
        loss='sparse_categorical_crossentropy',
        optimizer=tf.keras.optimizers.Adam(),
        metrics=['accuracy']
    )
    # evaluate
    eval_loss, eval_acc = reduced_model.evaluate(
        x=x_test,
        y=y_test,
        batch_size=batch_size
    )
    print('\nEval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))
    ### run training and val sets
    reduced_model = Model(inputs=model.input[0], outputs=model.get_layer('side_out').output)

    feats = reduced_model.predict(x_train)

    ### done
    K.clear_session()
    return

###
if __name__ == '__main__':
    run(0.0001)

```"
30052,"ValueError: Arguments and signature arguments do not match -- when using dataset api, keras functional api and checkpoints callback (tf2.0)","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.13.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): GIT_VERSION='v1.12.1-4759-g9856697d8b' TF_VERSION='2.0.0-dev20190622'
- Python version: 3.6.4
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
Calling the ```fit``` function on a Keras model, when specifying a Dataset and a ```ModelCheckpoint``` callback, will crash after the first epoch with this error:
```ValueError: Arguments and signature arguments do not match```.
The error happens only when specifying both the training Dataset and validation Dataset.
The error happens because of the checkpoint callback.

**Describe the expected behavior**
The model should not crash, continue training and successfully save the checkpoints.

**Code to reproduce the issue**
```python

import tensorflow as tf

# model architecture
inputs = tf.keras.Input(shape=(784,), name='flattened_image')
x = tf.keras.layers.Dense(64, activation='relu')(inputs)
x = tf.keras.layers.Dense(64, activation='relu')(x)
outputs = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs, name='error_showcase')

# loading mnist data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train = x_train.reshape(60000, 784).astype('float32') / 255
x_test = x_test.reshape(10000, 784).astype('float32') / 255

# create the training dataset
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
# shuffle, batch and prefetch
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64).prefetch(1024)
# create the validation dataset.
val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
# shuffle, batch and prefetch
val_dataset = val_dataset.batch(64).prefetch(1024)

# compile the model
model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='rmsprop',
    metrics=['accuracy']
)

# defining checkpoint callback
checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    './checkpoints/',
    monitor='val_accuracy',
    verbose=1,
    save_best_only=True,
    mode='max'
)

# fit the model
history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=5,
    callbacks=[checkpoint_callback],
)

print('\nhistory dict:', history.history)
```

**Other info / logs**
```
2019-06-22 18:30:17.760500: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-22 18:30:17.777440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8d2bb0de30 executing computations on platform Host. Devices:
2019-06-22 18:30:17.777463: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
Epoch 1/5
WARNING: Logging before flag parsing goes to stderr.
W0622 18:30:18.333158 140736272085888 deprecation.py:323] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1251: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0622 18:30:18.374418 140736272085888 deprecation.py:323] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:460: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Apply a constraint manually following the optimizer update step.
2019-06-22 18:30:18.583083: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1541] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
911/938 [============================>.] - ETA: 0s - loss: 0.3021 - accuracy: 0.9133  
Epoch 00001: val_accuracy improved from -inf to 0.94660, saving model to ./checkpoints/
2019-06-22 18:30:20.643797: W tensorflow/python/util/util.cc:268] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
W0622 18:30:20.653870 140736272085888 deprecation.py:506] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1775: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
938/938 [==============================] - 2s 3ms/step - loss: 0.2972 - accuracy: 0.9147 - val_loss: 0.1739 - val_accuracy: 0.9466
Epoch 2/5
Traceback (most recent call last):
  File ""error_showcase_ckpt.py"", line 46, in <module>
    callbacks=[checkpoint_callback],
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 669, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py"", line 695, in fit
    steps_name='steps_per_epoch')
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py"", line 265, in model_iteration
    batch_outs = batch_function(*batch_data)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 939, in train_on_batch
    outputs = self.train_function(ins)  # pylint: disable=not-callable
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 3483, in __call__
    outputs = self._graph_fn(*converted_inputs)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 583, in __call__
    return self._call_flat(args, self.captured_inputs)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 685, in _call_flat
    outputs = self._inference_function.call(ctx, args)
  File ""/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 436, in call
    (len(args), len(list(self.signature.input_arg))))
ValueError: Arguments and signature arguments do not match: 19 20 
```
"
30050,Composing layers using functools in TF 2.0 gives error,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **YES**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **CentOS 7**
- TensorFlow installed from (source or binary): **SOURCE**
- TensorFlow version (use command below): 2.0.0-beta1
- Python version: 3.6.7
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): 4.8.5
- CUDA/cuDNN version: 10.0/7.4
- GPU model and memory: Nvidia V100 (32 GB)


**Describe the current behavior**
During eager execution, python lists are wrapped by TF 2.0 as `<class 'tensorflow.python.training.tracking.data_structures.ListWrapper'>`
I see a weird issue with this data structure when using function composition to build a custom keras layer. The code for the layer is as follows. When called, it gives the error as ` TypeError: reduce() arg 2 must support iteration`. I have checked that the second argument to `reduce()` is indeed a generic iterable with an `__iter__` method. 

Is using function compositions using `functools` package an issue in TF2.0 ?


```
import tensorflow as tf
import functools
from collections.abc import Iterable


# TODO Check for correctness of the model implementation
class Unit3D(tf.keras.layers.Layer):
    def __init__(self, output_channels,
                 kernel_shape=(1, 1, 1),
                 stride=(1, 1, 1),
                 activation_fn='relu',
                 use_batch_norm=True,
                 use_bias=False,
                 is_training=False,
                 name='unit_3d'):
        super(Unit3D, self).__init__(name=name)
        self._output_channels = output_channels
        self._kernel_shape = kernel_shape
        self._stride = stride
        self._activation = activation_fn
        self._use_batch_norm = use_batch_norm
        self._use_bias = use_bias
        self._is_training = is_training
        self._pipeline = []
        self._pipeline.append(tf.keras.layers.Conv3D(
            filters=self._output_channels,
            kernel_size=self._kernel_shape,
            strides=self._stride,
            padding='same',
            use_bias=self._use_bias,
            data_format='channels_first'
        )
        )
        if self._use_batch_norm:
            bn = tf.keras.layers.BatchNormalization(
                axis=1,
                fused=False,
            )
            bn = functools.partial(bn, training=self._is_training)
            self._pipeline.append(bn)

        if self._activation is not None:
            self._pipeline.append(tf.keras.layers.Activation(
                activation=self._activation
            )
            )

        print(isinstance(self._pipeline, Iterable))
        print(type(self._pipeline))
        self._pipeline = lambda x: functools.reduce(lambda f, g: g(f), self._pipeline, x)

    def call(self, input):
        return self._pipeline(input)
```

**Describe the expected behavior** 
Function composition should be working properly.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import tensorflow as tf
from nets.i3d import Unit3D

model = Unit3D(output_channels=64, kernel_shape=[7,7,7],
               is_training=True)

input = tf.keras.backend.random_uniform(shape=(1,3,64,224,224),
                                        dtype=tf.float32)
output = model(input)

```
**Other info / logs**
```
2019-06-22 22:09:52.578799: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
<class 'tensorflow.python.training.tracking.data_structures._ListWrapper'>
Traceback (most recent call last):
  File ""/Users/meetukme/PycharmProjects/KineticsNet/main.py"", line 7, in <module>
    out = net(input)
  File ""/Users/meetukme/anaconda3/envs/slim2.0/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 660, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/Users/meetukme/PycharmProjects/KineticsNet/nets/i3d.py"", line 52, in call
    return self._pipeline(input)
  File ""/Users/meetukme/PycharmProjects/KineticsNet/nets/i3d.py"", line 47, in <lambda>
    a = lambda x : functools.reduce(lambda f, g: g(f), self._pipeline, x)
TypeError: reduce() arg 2 must support iteration

Process finished with exit code 1
```
"
30047,How much memory is required to build tensorflow from sources?,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 VM
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: latest
- Python version: 2.7.12
- Installed using virtualenv? pip? conda?: No
- Bazel version (if compiling from source): 0.21
- GCC/Compiler version (if compiling from source): 4.8.5
- CUDA/cuDNN version: ROCm 2.5
- GPU model and memory: ROCm gfx803 gfx900



**Describe the problem**
Building tensorflow fails running out of memory LLVM compile stage. Tried VM with
4GB and 8GB, still fails to complete compilation of tensorflow - runs out of memory.
What is the memory requirement for building tensorflow?

**Provide the exact sequence of commands / steps that you executed before running into the problem**
build_rocm script of r1.3-rocm release
./configure (configure for ROCm)
bazel build --config=rocm --config=opt //tensorflow/tools/pip_package:build_pip_package


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
LLVM Out of Memory
is the error message"
30046,input_fn recall hook for estimator api,"**System information**
- TensorFlow version (you are using): 1.10 < 2.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

Currently estimators are trained using either:

```python
estimator.train(...)
estimator.train_and_evaluate(...)    # internally calls self.train
```

Following the `tf.estimator.Estiamtor` [source code](https://github.com/tensorflow/estimator/blob/33e13754b0deebe7cc5006c49c53d246b6ff1dec/tensorflow_estimator/python/estimator/estimator.py) we see that `.train` calls `_train_model` that calls `_train_model_default`

[Line 1183](https://github.com/tensorflow/estimator/blob/33e13754b0deebe7cc5006c49c53d246b6ff1dec/tensorflow_estimator/python/estimator/estimator.py#L1183) has:

```python
# ...
features, labels, input_hooks = (self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))
# ...
```

prior to calling `_train_with_estimator_spec`

with the features and labels from the `tf.data.Dataset` returned by the `input_fn` wrapped into an `EstimatorSpec`. 

So it seems that per epoch / per batch updates to the `tf.data.Dataset` is not possible without very careful construction of the dataset.

It would be nice to be able to have the `input_fn` have the ability to be recalled and possibly updated depending on estimator stated (e.g. depending on `step`)


**Will this change the current api? How?**

It _shouldn't_ change the current estimator api.
It may add some extra interfaces to the api (e.g. a decorator for the `input_fn` that passes `_step`, `_recall_on_batch`)

**Who will benefit with this feature?**

Users with data that requires run-time generation / variation 


**Any Other info.**

e.g. this kind of logic should be possible
```python
def input_fn(..., _step, _epoch):

    if _step > n:
        return tf.data.Dataset(...)
    return tf.data.Dataset(...)
```

"
30045,ParseSequenceExample should return Ragged Tensor or have an option for this,"**System information**
- TensorFlow version (you are using): 1.14r
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
Right now, ParseSequenceExample returns sparse tensors. Instead, it should return Ragged tensors. This causes issues with our molecular dynamics project because padded tensors contain zeros which are misinterpreted as extra atoms in simulation. As a workaround we have to make lists of tensors, which interrupts training. Will try another approach by mapping twice

Sequence Examples are suited to make Ragged tensors because they both address the same variable-length issue

**Will this change the current api? How?**
dataset = tf.data.TFRecordDataset(files)
dataset = dataset.batch(batch_size=BATCH_SIZE)
dataset = dataset.map(parse_function) 
```
def parse_function(batch):
    ... define batch features ...
    return parse_sequence_example(batch, ragged=True, context_features=context_features, sequence_features=sequence_features)
```
**Who will benefit with this feature?**
people who don't want to pause training to postprocess data coming out of TFRecordDataset 

**Any Other info.**
it would be nice to return a tuple of ragged tensors for each sequence feature. context features can remain as tensors

Happy to try workarounds but it's hard to share our code as it requires making a special proteins dataset of TFRecords"
30044,weight NCHW2NHWC,"Hiï¼ŒI know that if I want to change the tensor from NCHW to NHWC is simply use transpos((0,2,3,1)) will,but my question is what if I want to change the weight of network trained using NCHW to NHWC,is using  transpos((0,2,3,1)) on the the weight will work too?I just want to know.Thanks if anyone can helpï¼"
30042,Installation documentation and mac wheels,"## URL(s) with the issue:

https://www.tensorflow.org/install/pip

## Description of issue (what needs changing):

### Clear description

There are no binary wheels for tensorflow 1.14 for mac (should be [here](https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.14.0-py3-none-any.whl)) and the documentation page still points to 1.13.

Is 1.14 still considered unstable? Was the wheel generation and documentation update simply forgotten? Or is it normal that it takes a couple of days after the release?
"
30041,The api 'tf.data.experimental.CsvDataset' performs very slow in test.,"**System info.**
 - cuda: 10.1
 - python: 3.6.6
 - tensorflow: 1.13.1
 - gpu: Quadro P5000

**Test Data.**
Csv dataset with 430 columns (all in floats), the first 429 columns as features and the last column as labels. There are totally 1928 classes and 57909 instances. 

**Problem.**
I test the speed of the csv readers, api ```tf.data.experimental.CsvDataset``` and the common method ```tf.placeholder()```. Here is the code:

with ```tf.data.experimental.CsvDataset```:
```
def parse_data(x, n_classes):
    x = tf.convert_to_tensor(x)
    return x[:-1], tf.one_hot(indices=tf.cast(x[-1], tf.int32), depth=n_classes)

if __name__=='__main__':
    dataset_train = tf.data.experimental.CsvDataset('/home/david/Dataset/timit/test.csv', [tf.float32] * 430,
                                                    header=False,
                                                    field_delim=' ')
    dataset_train = dataset_train.map(lambda *x_: parse_data(x_, 1928))
    dataset_train = dataset_train.batch(128)
    dataset_train = dataset_train.prefetch(1)
    iterator = dataset_train.make_initializable_iterator()

    x_in, y = iterator.get_next()

    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x_in)
    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x)
    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x)
    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x)
    logits = tf.layers.Dense(units=1928, activation=None)(x)

    loss = tf.losses.softmax_cross_entropy(y, logits)
    optimizer = tf.train.AdamOptimizer()
    optimizer.minimize(loss)

    sess = tf.Session()
    sess.run(tf.global_variables_initializer())
    sess.run(iterator.initializer)
    running_loss = 0.0
    time_last = time.time()
    epoch = 0
    i = 0
    while True:
        try:
            running_loss += sess.run(loss)  # , feed_dict={x: data, y: labels})
            if (i + 1) % 5 == 0:
                print('\r[epoch: %2d, batch: %5d, time: %5f] loss: %.3f' % (
                    epoch + 1, i + 1, time.time() - time_last, running_loss / i), end=' ')
                time_last = time.time()
            i += 1
        except tf.errors.OutOfRangeError:
            pass
```

with ```tf.placeholder```:
```
if __name__ == '__main__':
    x_in = tf.placeholder(shape=[128, 429], dtype=tf.float32)
    y_in = tf.placeholder(shape=[128], dtype=tf.int32)
    y = tf.one_hot(y_in, depth=1928)

    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x_in)
    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x)
    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x)
    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x)
    logits = tf.layers.Dense(units=1928, activation=None)(x)

    loss = tf.losses.softmax_cross_entropy(y, logits)
    optimizer = tf.train.AdamOptimizer()
    optimizer.minimize(loss)

    sess = tf.Session()
    sess.run(tf.global_variables_initializer())

    w = pd.read_csv('/home/david/Dataset/timit/test.csv', header=None, delim_whitespace=True).values

    for epoch in range(23):
        running_loss = 0.0
        time_last = time.time()
        i = 0
        indexes = np.random.permutation(w.shape[0])
        w_ = w[indexes, :]
        while True:
            if i * 128 + 128 > w.shape[0]:
                break
            running_loss += sess.run(loss,
                                     feed_dict={x_in: w_[i * 128:i * 128 + 128, :-1],
                                                y_in: w_[i * 128:i * 128 + 128, -1]})
            if (i + 1) % 5 == 0:
                print('\r[epoch: %2d, batch: %5d, time: %5f] loss: %.3f' % (
                    epoch + 1, i + 1, time.time() - time_last, running_loss / i), end=' ')
                time_last = time.time()
            i += 1
```

**Result (Time for training five batches).**
 - ```tf.placeholder``` method: 0.013263s
 - ```tf.data.experimental.CsvDataset``` method: 1.382647s

**Problem.**
 - Api ```tf.data.experimental.CsvDataset``` is so slow in the above test. I guess it is partly because that ```tf.data.experimental.CsvDataset``` do io operations before each batch to extract data from csv file. Is this ture, or there are other reasons?

 - However, it is too slow comparing to ```tf.placeholder```. Is there any chance for improvement? How can I set the ```tf.data.experimental.CsvDataset ```api to load all csv data at the very beginning?

 - Or can I say that ```tf.data.experimental.CsvDataset``` is implemented only for the csv dataset that is too big to store in the memory? Because the time cost seems like intolerable.

"
30040,Dimensions check in BinaryCrossEntropy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary):Binary
- TensorFlow version (use command below):2.0.0-beta1
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
Suppose we build a model for binary classification problem and we want to use `BinaryCrossEntropy` loss provided in `tf.keras.losses`. Here is an example:
```python
import numpy as np
import tensorflow as tf

y_true = np.array([[1.], [1.], [1.], [0.], [1.], [0.], [0.], [1.], [1.], [0.]]).astype(np.float32)
y_pred = np.array([[0.], [0.], [0.], [1.], [1.], [0.], [0.], [1.], [0.], [1.]]).astype(np.float32)

print(y_true.shape, y_pred.shape) # prints (10, 1) (10, 1)

# loss function
bce = tf.keras.losses.BinaryCrossentropy()

# Case1:
print(bce(y_true, y_pred).numpy())  # prints 9.23662 correctly

# Case2:
print(bce(np.squeeze(y_true), y_pred).numpy()) # prints 8.006299
```

**Describe the expected behavior**
When the `dimensions` of `y_true` and `y_pred` are different, in that case the loss function should raise an error for `dimension` mismatch or the model will fail **silently** and no one would be ab;e to debug it until unless they are aware of this behavior 

**Code to reproduce the issue**
Check above 

"
30039,Tensorflow per_process_gpu_memory_fraction used more memory than specified,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch linux 5.1.12
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): [Arch Linux repository](https://www.archlinux.org/packages/community/x86_64/python-tensorflow-cuda/) 
- TensorFlow version (use command below): 1.14.0-rc1
- Python version: 3.7.3 
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1.168
- GPU model and memory: Quadro M2200, 4043 MB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Tensorflow allocates more memory than specified. When running multiple processes sharing the same GPU can cause one process to have out of memory exception. For example, I specified it to use no more than 50% of GPU memory. However, it actually allocates ~52% memory as in the screenshot.

![image](https://user-images.githubusercontent.com/11804383/59959367-68051d80-94e8-11e9-9e95-688f66049599.png)

**Describe the expected behavior**
I would expect it to allocate no more than 50% memory. In my case, it would be <=2021.5 MB.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
import tensorflow as tf

gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)

with tf.compat.v1.Session(
        config=tf.ConfigProto(gpu_options=gpu_options)) as sess:
    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
    c = tf.matmul(a, b)
    while True:
        sess.run(c)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30038,Generated a .tflite file with 0kb,"

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 1.14.0. also tried with 1.12 and 1.13
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: Using CPU
- GPU model and memory:

**Describe the current behavior**
Generated a sample.tflite file with 0kb

**Describe the expected behavior**
Should generate a good .tflite file

**Code to reproduce the issue**
bazel run -c opt tensorflow/lite/toco:toco -- --input_file=C:/tensorflow1/models/research/object_detection/sample_tflite_graph.pb --output_file=C:/tensorflow1/models/research/object_detection/sample_detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_values=128 --change_concat_input_ranges=false --default_ranges_min=0 --default_ranges_max=6 --allow_custom_ops 


**Other info / logs**
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Options provided by the client:
  Inherited 'build' options: --python_path=C:/ProgramData/Anaconda3/envs/tensorflow1/python.exe
INFO: Reading rc options for 'run' from c:\tensorflow1\models\research\object_detection\tensorflow\.bazelrc:
  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
INFO: Reading rc options for 'run' from c:\tensorflow1\models\research\object_detection\tensorflow\.tf_configure.bazelrc:
  Inherited 'build' options: --action_env PYTHON_BIN_PATH=C:/ProgramData/Anaconda3/envs/tensorflow1/python.exe --action_env PYTHON_LIB_PATH=C:/tensorflow1/models/research/slim --python_path=C:/ProgramData/Anaconda3/envs/tensorflow1/python.exe --config monolithic --copt=-w --host_copt=-w --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --verbose_failures --distinct_host_configuration=false --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:monolithic in file c:\tensorflow1\models\research\object_detection\tensorflow\.bazelrc: --define framework_shared_object=false
INFO: Analyzed target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
Target //tensorflow/lite/toco:toco up-to-date:
  bazel-bin/tensorflow/lite/toco/toco.exe
INFO: Elapsed time: 3.214s, Critical Path: 0.01s
INFO: 0 processes.
INFO: Build completed successfully, 1 total action
INFO: Running command line: bazel-bin/tensorflow/lite/toco/toco.exe '--input_file=C:/tensorflow1/models/research/object_detection/sample_tflite_graph.pb' '--output_file=C:/tensorflow1/models/research/object_detection/sample_detect.tflite' '--input_shapes=1,300,300,3' '--input_arrays=normalized_input_image_tensor' '--output_arrays='\''TFLite_Detection_PostProcess'\'','\''TFLite_Detection_PostProcess:1'\'','\''TFLite_Detection_PostProcess:2'\'','\''TFLite_Detection_PostProcess:3'\''' '--inference_type=QUANTIZED_UINT8' '--mean_values=128' '--std_values=128' '--change_concat_input_ranges=false' '-INFO: Build completed successfully, 1 total action
2019-06-22 00:08:48.443379: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TFLite_Detection_PostProcess
2019-06-22 00:08:48.469603: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TFLite_Detection_PostProcess
2019-06-22 00:08:48.563540: F tensorflow/lite/toco/tooling_util.cc:918] Check failed: GetOpWithOutput(model, output_array) Specified output array ""'TFLite_Detection_PostProcess'"" is not produced by any op in this graph. Is it a typo? This should not happen. If you trigger this error please send a bug report (with code to reporduce this error), to the TensorFlow Lite team.
"
30037,InvalidArgumentError (see above for traceback): Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero,"python 3.6
Ubuntu 16.04.6 LTS
tensorflow '1.13.1'
```
feat_width = 2048
gpu_num = 8

def create_cnn_model(feat_width, data_format='channels_last'):
   model = tf.keras.Sequential()
   model.add(
      tf.keras.layers.Conv2D(
        filters = 32,
        kernel_size  = (1,2),
        strides = (1,2),
        data_format = data_format,
        padding = 'same',
        activation='relu',
        input_shape = (2,feat_width,1)))
    model.add(
      tf.keras.layers.Conv2D(
        filters = 10,
        kernel_size  = (2,2),
        data_format = data_format,
        padding = 'same',
        activation = 'relu'))
    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 1), data_format=data_format))
    model.add(tf.keras.layers.Flatten(data_format=data_format))
    model.add(tf.keras.layers.Dense(units=10, activation='relu'))
    model.add(tf.keras.layers.Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))
    return model

def serving_input_fn():
        """"""Build the serving inputs.""""""
        inputs = {}
        inputs[keras_model.input_names[0]] = tf.placeholder(shape=(None, 2,feat_width,1), dtype=tf.float32)

        return tf.estimator.export.build_raw_serving_input_receiver_fn(inputs)

strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=gpu_num)
estimator_config = tf.estimator.RunConfig(
        model_dir='../../model',
        tf_random_seed=0,
        save_summary_steps=256,
        save_checkpoints_steps=10000,
        train_distribute=strategy,
        keep_checkpoint_max=64,
        log_step_count_steps=256)

keras_model = create_cnn_model(feat_width)
keras_model = tf.keras.utils.multi_gpu_model(keras_model, gpus=gpu_num)
keras_model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])
estimator = tf.keras.estimator.model_to_estimator(keras_model=keras_model,config=estimator_config)
tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
```

using
```
 tf.contrib.predictor.from_saved_model(export_dir)
```
to do inference:
```
predictor =  tf.contrib.predictor.from_saved_model(export_dir=export_dir)
feed_tensor = list(predictor.feed_tensors.keys())[0]
fetch_tensor = list(predictor.fetch_tensors.keys())[0]
feat = np.random.rand(2*feat_width)
feat = np.reshape(feat,[ 2, feat_width, 1])
Y = predictor({feed_tensor: [feat]})
r = Y[fetch_tensor]
```
fails for multi gpu with error
```
InvalidArgumentError (see above for traceback): Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero
	 [[node sequential_1/flatten/Reshape ]]
	 [[node dense_2_1/concat ]]
```
if I don't use multi gpu the inference code works.
"
30036,"Can TensorFlow's ""predict"" be used in C++?","I am very new to TensorFlow and this may be a silly question, and I hope this is the right place to ask it. I have been searching for a rnn-library that I can use with C++ and was hoping TensorFlow could work for me. What I am wondering about is:

**Can I train and save a keras model in python, and then load the model by using C++, and then use the loaded model to do predictions (in C++)?**

I just wanted to make sure, or figure out, if this is possible before I started working on, and learn more about TensorFlow, or if I should keep looking for other C++ libraries."
30035,TF 2.0 tensor.numpy() inside of map() functions,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0.0b1
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Currently, there is no way to get a numpy array from a tensor during graph execution, even if it is well defined. Specifically I am working with a funciton to map to a dataset, where I would like to get the np array from the tensor, however with eager execution disabled (due to static graph execution) it is not possible. There does not appear to be a workaround because the normal workaround in static cases is the py_func() function but that can only return tensors, defeating the purpose in this case.

**Will this change the current api? How?**
No significant changes beyond adding a method that would allow for numpy arrays to be returned during a map function. It would likely have to be specific because there are a number of times that one could improperly use this outside of a use case like dataset.map

**Who will benefit with this feature?**
developers working with custom datasets which require custom mapped functions to interact with other libraries that expect numpy arrays. Definitely a larger number of the research community could make use of this than hobbyist to be sure.

**Any Other info.**
"
30034,bazel 0.26.1 git rules break on Windows,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (build 18912.1001)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: master
- Python version: 2.7
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

The default git worker rules from bazel 0.26.1 actually assume bash.  However, Windows 10 with WSL will provide a bash that is a redirection to the default WSL installation.  This is both difficult to track down as well as behaves incorrectly when trying to build TensorFlow for Windows.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

`bazel --config=opt --config=v2 build //tensorflow:...`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30029,Autoconversion to Tensor in functions,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 19.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary, pip
- TensorFlow version (use command below):1.14.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
calling certain functions with non-Tensors (but convertible to) fails, since the object is not converted to a tensor. The function actually only expect Tensors.

e.g. `tf.math.real(1.0)` fails because `1.` has no attribute dtype (which it will only have after the conversion to a tensor).

**Describe the expected behavior**
(My understanding goes that:) functions that take Tensors, such as `tf.math.real`, can also take anything that can be converted to a Tensor, such as Python floats or objects with a registered conversion function. Namely,
```
tf.math.real(tf.convert_to_tensor(something))
tf.math.real(something)
```
are _equivalent_.

I would expect `tf.math.real(1.)` to return the real part of the tensor `tf.convert_to_tensor(1.)`.

This causes a big problem with the (actual beautiful!) registration of conversion functions. The code contains only a minimal example.

Am I mistaken with the expected behavior? And if so, this may could be made clear in the docs, that _only_ Tensors are taken vs Tensor-like objects. E.g. the docs of `tf.math.round` and `tf.math.real` leave no clue in which to use tensors and in which Tensor-like objects.

**Code to reproduce the issue**
short version
```
real_python = tf.math.real(1.)  # <- fails
```
but of course also fails for any custom defined Tensor-like object
```
from tensorflow.python import ops

class MyTensor():
    def _dense_var_to_tensor(self, dtype, name, as_ref):
        return tf.constant(42, dtype=dtype)


def _dense_var_to_tensor(var, dtype=None, name=None, as_ref=False):
    return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)


ops.register_tensor_conversion_function(MyTensor, _dense_var_to_tensor)

my_t1 = MyTensor()
t1 = tf.convert_to_tensor(my_t1)  # <- works
square = tf.math.round(my_t1)  # <- works
real_python = tf.math.real(1.)  # <- fails
real = tf.math.real(my_t1)  # <- fails
```

"
30028,Python package is missing ModuleSpec in tensorflow.__spec__ in tf 1.14.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux-4.9.125-linuxkit-x86_64-with-Ubuntu-18.04-bionic
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): preinstalled in docker image
- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5 1.14.0
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

In TF 1.14.0 the module spec in `tensorflow.__spec__` is None:
```
>>> import tensorflow
>>> print(tensorflow.__spec__)
None
```

**Describe the expected behavior**

This is different from tf 1.13.1 where it works as expected:
```
>>> import tensorflow
>>> print(tensorflow.__spec__)
ModuleSpec(name='tensorflow', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7f038cfc3cf8>, origin='/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py', submodule_search_locations=['/usr/local/lib/python3.5/dist-packages/tensorflow'])
```

Missing spec causes some problems, e.g. pkgutil now fails when trying to find tensorflow. Note that the first call to `find_loader` is successful, it only fails *after* tensorflow is imported:
```
Python 3.6.8 (default, Jan 14 2019, 11:02:34) 
[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import pkgutil
>>> pkgutil.find_loader('tensorflow')
<_frozen_importlib_external.SourceFileLoader object at 0x7f62372c7160>
>>> import tensorflow
>>> pkgutil.find_loader('tensorflow')
Traceback (most recent call last):
  File ""/usr/lib/python3.6/pkgutil.py"", line 490, in find_loader
    spec = importlib.util.find_spec(fullname)
  File ""/usr/lib/python3.6/importlib/util.py"", line 102, in find_spec
    raise ValueError('{}.__spec__ is None'.format(name))
ValueError: tensorflow.__spec__ is None

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/lib/python3.6/pkgutil.py"", line 496, in find_loader
    raise ImportError(msg.format(fullname, type(ex), ex)) from ex
ImportError: Error while finding loader for 'tensorflow' (<class 'ValueError'>: tensorflow.__spec__ is None)
```

**Code to reproduce the issue**
See above

**Other info / logs**

I've tested this using official tf docker image (tensorflow/tensorflow:1.14.0-py3) and also using python docker image (python:3.6) with tensorflow installed with pip."
30026,error while converting MobileNet SSD tflite_graph.pb file to tflite format using tflite_convert ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.0
- Python version:3.6.5
- Bazel version (if compiling from source):  None
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: none 
- GPU model and memory: none

I am trying to convert a pretrained mobilenetSSD to tflite for deployment which is available in tensorflow detection model zoo.

**Code to reproduce the issue**
tflite_convert   --graph_def_file=ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync_2018_07_18/tflite_graph.pb    --output_file=ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync_2018_07_18/optimized_graph.lite   --input_format=TENSORFLOW_GRAPHDEF   --output_format=TFLITE   --input_shape=1,${224},${224},3   --input_array=input   --output_array=final_result   --inference_type=FLOAT   --input_data_type=FLOAT


**Other info / logs**
Traceback (most recent call last):
  File ""/home/yash/anaconda3/envs/conversion/bin/tflite_convert"", line 10, in <module>
    sys.exit(main())
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py"", line 503, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py"", line 499, in run_main
    _convert_tf1_model(tflite_flags)
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py"", line 193, in _convert_tf1_model
    output_data = converter.convert()
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 904, in convert
    **converter_kwargs)
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/python/convert.py"", line 373, in toco_convert_graph_def
    input_data.SerializeToString())
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/python/convert.py"", line 172, in toco_convert_protos
    ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.
2019-06-21 03:51:18.946551: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TFLite_Detection_PostProcess
2019-06-21 03:51:18.970221: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TFLite_Detection_PostProcess
2019-06-21 03:51:18.994542: F tensorflow/lite/toco/tooling_util.cc:918] Check failed: GetOpWithOutput(model, output_array) Specified output array ""final_result"" is not produced by any op in this graph. Is it a typo? This should not happen. If you trigger this error please send a bug report (with code to reporduce this error), to the TensorFlow Lite team.
Fatal Python error: Aborted

Current thread 0x00007f9444831740 (most recent call first):
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 33 in execute
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/absl/app.py"", line 251 in _run_main
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/absl/app.py"", line 300 in run
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40 in run
  File ""/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 59 in main
  File ""/home/yash/anaconda3/envs/conversion/bin/toco_from_protos"", line 10 in <module>
Aborted (core dumped)

"
30025,"Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.","Version : tensorflow-gpu==2.0.0-beta1
OS : Ubuntu 18.04 LTS

`W0621 10:32:12.746317 139752995510080 util.py:64] Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.`

not something important but do you know how to remove this warning?

I already included 
`import os
import tensorflow as tf
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'`"
30024,"Many Keras.applications (e.g. ResNet-101, ResNeXt) missing from default TensorFlow-gpu installation of 1.10 (through 1.14)","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.10
- Python version: 3.5
- CUDA/cuDNN version: V8.0.61
- GPU model and memory: Tesla P100-PCIE, 12193MiB

A lot of the listed [Keras applications](https://keras.io/applications/) are missing from TensorFlow-gpu installations of 1.10 through 1.14. This might as well be a feature request to include those.

I installed TensorFlow 1.10 through 1.14, and all installations are missing some [Keras applications](https://keras.io/applications/), like ResNet-101, ResNext, etc. I copied the files from the [Keras applications GitHub repository](https://github.com/keras-team/keras-applications/tree/master/keras_applications), and simply pasted them in `site-packages/tensorflow/python/keras/applications/`. However, this results in the following error:

```
Traceback (most recent call last):
  File ""myscript.py"", line 2, in <module>
    import tensorflow as tf
  File ""tensorflow/__init__.py"", line 53, in <module>
    from tensorflow import keras
  File ""tensorflow/keras/__init__.py"", line 13, in <module>
    from tensorflow.keras import applications
  File ""tensorflow/keras/applications/__init__.py"", line 8, in <module>
    from tensorflow.keras.applications import densenet
  File ""tensorflow/keras/applications/densenet/__init__.py"", line 14, in <module>
    from tensorflow.python.keras.applications import DenseNet121
ImportError: cannot import name 'DenseNet121'
```

This led me to discover another Keras applications folder: `site-packages/tensorflow/keras/applications/`. What is the difference between the two applications folders? Why does not TensorFlow install all applications out-of-the-box? How can I use those applications anyways (preferably without installing Keras separately)?"
30023,Running tensorflow in Spyder,"An error ocurred while starting the kernel
2019óˆšªóˆš¹ 18:22:35.571373: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019óˆšªóˆš¹ 18:22:36.757865: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1392] Found device 0 with properties: 
name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705
pciBusID: 0000:01:00.0
totalMemory: 6.00GiB freeMemory: 4.97GiB
2019óˆšªóˆš¹ 18:22:36.775030: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1471] Adding visible gpu devices: 0
2019óˆšªóˆš¹ 18:22:38.426283: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019óˆšªóˆš¹ 18:22:38.432187: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:958] 0 
2019óˆšªóˆš¹ 18:22:38.436114: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:971] 0: N 
2019óˆšªóˆš¹ 18:22:38.441378: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4736 MB memory) â€‘> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)"
30021,tf.keras.layers.BatchNormalization API does not fully support masking,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): TF 1.13.1
- Python version: 3.6.7
- CUDA/cuDNN version: 
- GPU model and memory:

**Describe the current behavior**
Trying to apply a mask when calling a BatchNormalization layer fails with:
*TypeError: call() got an unexpected keyword argument 'mask'*

**Describe the expected behavior**
Masking should be supported:
https://github.com/tensorflow/tensorflow/blob/93dd14dce2e8751bcaab0a0eb363d55eb0cc5813/tensorflow/python/keras/layers/normalization.py#L188

If a layer supports masking, it should be a kwarg to __call__. Until all layers support masking, it's not practical to only support masking via an upstream layer. A Masking Layer can't always be inserted into a model because downstream convolution layers don't support it at all. Feeding the mask into the call of a recurrent layer is the only workaround to combine Convolution, LSTM and masking, and it would be great if it worked the same way for BatchNorm:
```encoded = keras.layers.LSTM(10)(input, mask=input_mask)```.

**Code to reproduce the issue**
```
from tensorflow import keras

def Works():
    input = keras.layers.Input(shape=(None, 1))
    masked_input = keras.layers.Masking(-1)(input)
    normalized = keras.layers.BatchNormalization(epsilon=1.1e-5)(masked_input)

def DoesntWork():
    input = keras.layers.Input(shape=(None, 1))
    mask = keras.layers.Masking(-1).compute_mask(input)
    normalized = keras.layers.BatchNormalization(epsilon=1.1e-5)(input, mask=mask)

if __name__ == '__main__':
    Works()
```
"
30020,tf.cond leads to memory leak?,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): conda
- TensorFlow version (use command below): Tf=1.13.1
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: TITAN RTX 24G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
```python
2019-06-25 10:59:25.073825: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_34339
2019-06-25 10:59:25.073932: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_34340
2019-06-25 10:59:25.073977: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_34395
2019-06-25 10:59:25.074019: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_34396
2019-06-25 10:59:25.074057: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_34482
2019-06-25 10:59:25.074136: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_34483
2019-06-25 10:59:25.074170: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_34568
2019-06-25 10:59:25.074219: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_34569
2019-06-25 10:59:25.074256: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_34568_rewritten
2019-06-25 10:59:25.074353: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_34569_rewritten
2019-06-25 10:59:25.074425: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_34568_grad_34687
2019-06-25 10:59:25.074600: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_34569_grad_34755
2019-06-25 10:59:25.074654: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_34482_rewritten
2019-06-25 10:59:25.074817: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_34483_rewritten
2019-06-25 10:59:25.074884: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_34482_grad_34822
2019-06-25 10:59:25.075129: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_34483_grad_34926
2019-06-25 10:59:25.075177: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_34395_grad_34994
2019-06-25 10:59:25.075268: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_34396_grad_35015
2019-06-25 10:59:25.075303: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_34339_grad_35033
2019-06-25 10:59:25.075362: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_34340_grad_35044
```
**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
30017,Tensorflow restore model and retrain - valueerror : Duplicate node name in graph,"I am trying to restore the trained model and retrain it with some additional operations.

I have 2 python files, lets say

train.py - To train and save the model
retrain.py - Load the trained model, add new elements in graph and retrain

**train.py**

```
def train():
    # 1 NN
    Xinp1 = tf.placeholder(""float"", [None, 2], name=""Xinp1"")
    Xhidden1 = tf.layers.dense(Xinp1, units=16 , 
                kernel_initializer=tf.initializers.he_uniform(), 
                activation=tf.nn.relu, name=""X_hidden1"")
    Xout = tf.layers.dense(X_hidden5, units=1, 
 kernel_initializer=tf.initializers.he_uniform(),activation=tf.nn.sigmoid, name=""X_out"")

    Xout1 = tf.identity(Xout, name=""Xout1"")

    #2 NN
    Xinp2 = tf.placeholder(""float"", [None, 2], name=""Xinp2"")
    Xhidden2 = tf.layers.dense(Xinp2, units=16 , 
                kernel_initializer=tf.initializers.he_uniform(), 
                activation=tf.nn.relu, name=""X_hidden2"")
    Xout = tf.layers.dense(X_hidden2, units=1, 
kernel_initializer=tf.initializers.he_uniform(),activation=tf.nn.sigmoid, name=""X_out"")

    Xout2 = tf.identity(Xout, name=""Xout2"")

    Xout1_label = tf.placeholder(""float"", [None,1], name=""Xout1_label"")
    Xout2_label = tf.placeholder(""float"", [None,1],name=""Xout2_label"")


    learning_rate = 1e-2
    # Define loss and optimizer
    loss_op1 = tf.losses.absolute_difference(Xout1_label, Xout1)
    loss_op2 = tf.losses.absolute_difference(Xout2_label, Xout2)



    # debug gradients
    trainables = tf.trainable_variables()
    print (""trainables"", trainables)
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=0.1)

    train_op1 = optimizer.minimize(loss_op1)
    train_op2 = optimizer.minimize(loss_op2)

    with tf.Session() as sess:
          sess.run(tf.global_variables_initializer())
          saver = tf.train.Saver()
          for _ in range(100):
               _, c1, summary = sess.run([train_op1, loss_op1, merged_summary_op], feed_dict={
            Xinp1: X1,
            Xinp2: X2,
            Xout1_label: X1label,
            Xout2_label: X2label
            })    
               _, c2, summary = sess.run([train_op2, loss_op2, merged_summary_op], feed_dict={
            Xinp1: X1,
            Xinp2: X2,
            Xout1_label: X1label,
            Xout2_label: X2label
            })        
          saver.save(sess, 'Model/trained.ckpt')
          sess.close()
```

As an output, I got following files

1. checkpoint
2. trained.ckpt.data-00000-of-00001
3. trained.ckpt.index
4. trained.ckpt.meta

**retrain.py**

```
def retrain():
     with tf.Session() as sess:
           saver = tf.train.import_meta_graph('Model/trained.ckpt.meta')
           saver.restore(sess, 'Model/trained.ckpt')
           graph = tf.get_default_graph()
           Xinp1 = graph.get_tensor_by_name('Xinp1:0')
           Xout1 = graph.get_tensor_by_name('Xout1:0')
           Xinp2 = graph.get_tensor_by_name('Xinp2:0')
           Xout2 = graph.get_tensor_by_name('Xout2:0') 

           # I want to add some additional nodes
           T1 = tf.placeholder(""float"", [None, 1], name=""T1"")
           T2 = tf.placeholder(""float"", [None, 1], name=""T2"")
           Add1 = tf.add(tf.multiply(Xout1, tf.subtract(T1, T2)), T2, name=""Add1_out"")

           T3 = tf.placeholder(""float"", [None, 1], name=""T3"")
           Add2 = tf.multiply(tf.multiply(T3,tf.subtract(Add1, 300)),tf.multiply(radial_length,0.000001), name=""Add2_out"")

           Addlabel = tf.placeholder(""float"", [None, 1], name=""Addlabel"")

           loss_op = tf.losses.mean_squared_error(Addlabel, Add2)

           # debug gradients
           trainables = tf.trainable_variables()
           print (""trainables"", trainables)
           optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=0.1)
           train_op = optimizer.minimize(loss_op)

           sess.run(tf.global_variables_initializer())
           #training starts
           # Here I except weights of 1 NN and 2 NN are learned during the training
           for _ in range(100):
               _, c, summary = sess.run([train_op, loss_op, merged_summary_op], feed_dict={
               Xinp1 : NewX1,
               Xinp2 : NewX2,
               T1 : T1inp,
               T2 : T2inp,
               T3 : T3inp,
               Addlabel : Addtarget               
                }) 
```

I am expecting the retrain.py to adjust the weights associated with 1 NN and 2 NN during the training.

But instead while running the retrain.py, I am getting the following error
```
Traceback (most recent call last):
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1659, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Duplicate node name in graph: 'X_hidden1/kernel/Adam'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/itmsec/Documents/tipclearance/src/TTG_tensorflowv14.py"", line 493, in <module>
    restore_and_retrain(BDD)
  File ""/home/itmsec/Documents/tipclearance/src/TTG_tensorflowv14.py"", line 244, in restore_and_retrain
    train_op = optimizer.minimize(loss_op)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 413, in minimize
    name=name)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 595, in apply_gradients
    self._create_slots(var_list)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/adam.py"", line 135, in _create_slots
    self._zeros_slot(v, ""m"", self._name)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 1153, in _zeros_slot
    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py"", line 183, in create_zeros_slot
    colocate_with_primary=colocate_with_primary)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py"", line 157, in create_slot_with_initializer
    dtype)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py"", line 65, in _create_slot_var
    validate_shape=validate_shape)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 1479, in get_variable
    aggregation=aggregation)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 1220, in get_variable
    aggregation=aggregation)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 547, in get_variable
    aggregation=aggregation)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 499, in _true_getter
    aggregation=aggregation)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 911, in _get_single_variable
    aggregation=aggregation)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 213, in __call__
    return cls._variable_v1_call(*args, **kwargs)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 176, in _variable_v1_call
    aggregation=aggregation)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 155, in <lambda>
    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 2495, in default_variable_creator
    expected_shape=expected_shape, import_scope=import_scope)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 217, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 1395, in __init__
    constraint=constraint)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 1509, in _init_from_args
    name=name)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py"", line 79, in variable_op_v2
    shared_name=shared_name)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 1425, in variable_v2
    shared_name=shared_name, name=name)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1823, in __init__
    control_input_ops)
  File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1662, in _create_c_op
    raise ValueError(str(e))
ValueError: Duplicate node name in graph: 'X_hidden1/kernel/Adam'
```"
30015,building error on win7 with VS2015: ADD_LIBRARY for library tf_contrib_tpu_ops without any source files ,"System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win7 X64
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): source
TensorFlow version:1.13.1
Python version:3.6
Installed using virtualenv? pip? conda?:conda
Bazel version (if compiling from source):cmake
GCC/Compiler version (if compiling from source):vs 2015
CUDA/cuDNN version:no cuda
GPU model and memory:no gpu
Describe the problem
when I use cmake GUI config TF, it show me the folowing error message:
""You have called ADD_LIBRARY for library tf_contrib_tpu_ops without any source files. This typically indicates a problem with your CMakeLists.txt file
CMake Error at tf_python.cmake:217 (message):
Python module not found: tensorflow/contrib/tpu/ops""
I think the problem is all the source files were moved to ""tensorflow/core/tpu"", do you have idea how to change the path from ""tensorflow/contrib/tpu/ops"" to ""tensorflow/core/tpu""? or how to block the tpu module in config file?
many thanks~
Provide the exact sequence of commands / steps that you executed before running into the problem"
30010,Tensorflow2.0beta is not fit to pycharm,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (win10 professional):
- Mobile device (no)
- TensorFlow installed from (pip):
- TensorFlow version:2.0.0beta1
- Python version:3.7.3
- Installed using virtualenv? pip? conda?:conda env
- Bazel version (if compiling from source):no
- GCC/Compiler version (if compiling from source):no
- CUDA/cuDNN version: 10.0 and 7.6.0
- GPU model and memory: GTX 1060 Max-Q 6GB



**I run some template code with virtual environment created by conda , and successed. But when I used PyCharm , it failed with error saying 
`Traceback (most recent call last):
  File ""E:\Anaconda\envs\tf2.0b\lib\site-packages\tensorflow\python\platform\self_check.py"", line 75, in preload_check
    ctypes.WinDLL(build_info.cudart_dll_name)
  File ""E:\Anaconda\envs\tf2.0b\lib\ctypes\__init__.py"", line 356, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] æ‰¾ä¸åˆ°æŒ‡å®šçš„æ¨¡å—ã€‚

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""E:/CODE/py/gpucheck/test.py"", line 1, in <module>
    import tensorflow as tf
  File ""E:\Anaconda\envs\tf2.0b\lib\site-packages\tensorflow\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""E:\Anaconda\envs\tf2.0b\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""E:\Anaconda\envs\tf2.0b\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 30, in <module>
    self_check.preload_check()
  File ""E:\Anaconda\envs\tf2.0b\lib\site-packages\tensorflow\python\platform\self_check.py"", line 82, in preload_check
    % (build_info.cudart_dll_name, build_info.cuda_version_number))
ImportError: Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive
`
I don`t know how to solve this problem . I have already changed the Python`s path , which was installed before the Anaconda. 
**


"
30009,TensorFlow 1.14 docker images lacking,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.

---

There doesn't seem to be any docker images published along side the resent tf 1.14 release. Is this intentional, or can we expect them in the near future?"
30007,Tensorflow Lite Micro fails to build for embedded targets due to dependencing on gemmlowp,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 420473f1fb
- GCC/Compiler version (if compiling from source): arm-none-eabi-g++ 7.3.1




**Describe the problem**
Building Tensorflow Lite Micro fails when building for the bluepill target, due to an unmet dependency.

The problem seems to be caused by the fact that tensorflow/lite/kernels/internal/common.h includes tensorflow/lite/kernels/internal/optimized/cpu_check.h. 

tensorflow/lite/kernels/internal/common.h is in turn included by the kernels in Tensorflow Lite Micro.

This adds gemmlowp as a dependency, which causes Tensorflow Lite Micro to not build when building for eg Cortex-M3 in the bluepill case.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
$ make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=bluepill test

**Any other info / logs**
`
In file included from tensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp/public/../internal/dispatch_gemm_shape.h:23,
                 from tensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp/public/gemmlowp.h:19,
                 from ./tensorflow/lite/kernels/cpu_backend_context.h:21,
                 from ./tensorflow/lite/kernels/internal/optimized/cpu_check.h:18,
                 from ./tensorflow/lite/kernels/internal/common.h:25,
                 from tensorflow/lite/experimental/micro/kernels/depthwise_conv.cc:18:
tensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp/public/../internal/multi_thread_gemm.h: In member function 'void gemmlowp::BlockingCounter::Wait()':
tensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp/public/../internal/multi_thread_gemm.h:203:14: error: 'std::this_thread' has not been declared
         std::this_thread::sleep_for(std::chrono::milliseconds(1));
`

Full error log:
[errorlog.txt](https://github.com/tensorflow/tensorflow/files/3310477/errorlog.txt)"
30005,TensorFlow/examples The gesture_classification Install Dependencies FAIL,"As the picture shows
<img width=""1102"" alt=""èž¢å¹•å¿«ç…§ 2019-06-20 ä¸‹åˆ8 20 45"" src=""https://user-images.githubusercontent.com/28727682/59848978-11d59480-9399-11e9-8dc0-3025be7e51c3.png"">"
30004,a writing error in tf.contrib.data.map_and_batch,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/contrib/data/map_and_batch

## Description of issue (what needs changing):

Args document of this API:

> num_parallel_calls: (Optional.) A tf.int32 scalar tf.Tensor, representing the number of elements to process in parallel. If not specified, batch_size * num_parallel_batches elements will be processed in **parallel**.

the last word should be `sequential` rather than `parallel` 
 "
30003,FlexAudioSpectrogram ops is not supported by the tflite interpreter,"When I run a model converted from speech command demo using lite Interpreter, the error is:
Traceback (most recent call last):
  File ""/home/yuan/anaconda3/envs/TFLite/lib/python3.7/threading.py"", line 917, in _bootstrap_inner
    self.run()
  File ""/home/yuan/tensorflow-master/tensorflow/examples/speech_commands/audio/audio_processor_lite.py"", line 41, in run
    self._interpreter.allocate_tensors()
  File ""/home/yuan/anaconda3/envs/TFLite/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter.py"", line 198, in allocate_tensors
    return self._interpreter.AllocateTensors()
  File ""/home/yuan/anaconda3/envs/TFLite/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py"", line 106, in AllocateTensors
    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
RuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you invoke the Flex delegate before inference.Node number 0 (FlexAudioSpectrogram) failed to prepare.
But the model provided by speech command android demo works  well. (https://github.com/tensorflow/examples/blob/master/lite/examples/speech_commands/android/README.md)"
30002,[TF 2.0 API Docs] `tf.keras.callbacks.LearningRateScheduler`,"TensorFlow version: 2.0 (beta1)

#### Doc links:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/LearningRateScheduler
https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/callbacks.py

#### Description:
The definition should be expanded for clarity and better user experience. Instead of a one short sentence - ""Learning rate scheduler."" - maybe try:
```
Learning rate scheduler which can be used to adjust the learning rate over time. Any function can be defined, such as a decay function that states which decay rate to use after a certain number of epochs or batches. Then this custom function can be passed as the `schedule` parameter in the `LearningRateSchuler` callback. 
```
Alternatively, a description from the ""Distributed Training with Keras"" [tutorial](https://www.tensorflow.org/beta/tutorials/distribute/keras), linked in the API doc, can also be used:
```
Learning Rate Scheduler: Using this callback, you can schedule the learning rate to change after every epoch/batch.
```
#### Example:
The word ""Example"" is missing before the example.

#### Raises/Returns:
Should be added.


For improvement suggestions of other `tf.keras.callbacks` classes see #29958 "
30001,TensorFlow 1.3 build fails with OpenMPI,"**System information**
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.3.1
- Python version: 3.5.2
- Installed using virtualenv? pip? conda?: git
- Bazel version (if compiling from source): 0.4.5
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version: 8.0/6
- GPU model and memory: none (explained below) and 8GB

**Describe the problem**
Building TensorFlow 1.3 leads to an error when MPI support is enabled:

```
In file included from ./tensorflow/contrib/mpi/mpi_utils.h:27:0,
                 from tensorflow/contrib/mpi/mpi_utils.cc:18:
./third_party/mpi/mpi.h:2673:41: fatal error: openmpi/ompi/mpi/cxx/mpicxx.h: No such file or directory
compilation terminated.
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```bash
git clone git@github.com:tensorflow/tensorflow.git
cd tensorflow
git checkout v1.3.1
./configure # enable HDFS, CUDA and MPI support, full output in the next section
bazel build -s --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```


**Any other info / logs**
The full build output is [there](https://drive.google.com/file/d/19g1oVyPUf1AfRwHBrpMJx5T1o9ZHc7hK/view?usp=sharing).

I am building TensorFlow in a VM for another system that has a CUDA-compatible GPU. That is why I have installed CUDA and enabled CUDA support, despite the VM not having access to my laptop's GPU (GTX 1050).

This is the output of `./configure`, including my choices (I enabled HDFS, CUDA and MPI support):
```
...........
You have bazel 0.4.5 installed.
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3
Found possible Python library paths:
  /usr/lib/python3/dist-packages
  /usr/local/lib/python3.5/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]

Using python library path: /usr/lib/python3/dist-packages
Do you wish to build TensorFlow with MKL support? [y/N]
No MKL support will be enabled for TensorFlow
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]:
Do you wish to use jemalloc as the malloc implementation? [Y/n]
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] y
Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]
No XLA support will be enabled for TensorFlow
Do you wish to build TensorFlow with VERBS support? [y/N]
No VERBS support will be enabled for TensorFlow
Do you wish to build TensorFlow with OpenCL support? [y/N]
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] y
CUDA support will be enabled for TensorFlow
Do you want to use clang as CUDA compiler? [y/N]
nvcc will be used as CUDA compiler
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]:
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:
Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]:
Please specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 6.2
Do you wish to build TensorFlow with MPI support? [y/N] y
MPI support will be enabled for TensorFlow
Please specify the MPI toolkit folder. [Default is /usr]: /usr/lib/openmpi
Configuration finished
```

I have installed `libopenmpi-dev`."
30000,"clock_gettime undefined , build on centos6.6, gcc 4.9 ï¼ˆbuild static libï¼‰","centos 6.6
gcc 4.9
build  static lib of tensorflow
use:  ./tensorflow/contrib/makefile/build_all_linux.sh 

"
29999,"If variable has huge size, where this variable is located when serveral parameter servers.","I have tried to model data using two-layered(linear, w*x + b) neural network using custom tf.estimate.Estimator and distribution strategy(default? train_distribution=None), and then an input feature dimension is so huge(almost > 100K).
If I have [300, 128] layered with biased term, it could be as following:
1st layer: w1 variable will be 100K> x 300(float32), b1 = [1]
2nd layer: w2 variable will be 300 x 128(float32) b2 = [1]

Finally, my question is that w1 is so big size, where is w1 variable located? Is the w1 variable spread equally with other parameter servers or located in one parameter server.

Thank you for reading even my poor english, in advance.

"
29997,libtensorflow_jni.so: libcudnn.so.7: cannot open shared object file: No such file or directory,"tensorflow version=1.8.0
java=1.8.0
cuda=9.1
cudnn=7

**I used java to call the GPU when I reported the following error:**

java.lang.UnsatisfiedLinkError: /tomcat/temp/tensorflow_native_libraries-1561013286760-0/libtensorflow_jni.so: libcudnn.so.7: cannot open shared object file: No such file or directory

```
        <dependency>
            <groupId>org.tensorflow</groupId>
            <artifactId>tensorflow</artifactId>
            <exclusions>
                <exclusion>
                    <groupId>org.tensorflow</groupId>
                    <artifactId>libtensorflow_jni</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.tensorflow</groupId>
            <artifactId>libtensorflow_jni_gpu</artifactId>
        </dependency>
```

when delete as follows. This program prompts that the GPU cannot be found, forcing the CPU
```
            <exclusions>
                <exclusion>
                    <groupId>org.tensorflow</groupId>
                    <artifactId>libtensorflow_jni</artifactId>
                </exclusion>
            </exclusions>
```
Can you help me? Thanks a lot.

"
29996,TF2 - apparent memory leak when running dataset ops eagerly,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX
- TensorFlow installed from (source or binary): 2.0.0beta
- TensorFlow version (use command below): v1.12.1-3259-gf59745a381 2.0.0-beta0
- Python version: 3.6.8

**Describe the current behavior**
When using the function `tf.autograph.to_graph`, I see a memory leak which I don't see if I use the annotation `@tf.function`

**Describe the expected behavior**
There should not be a memory leak.

**Code to reproduce the issue**
```python
import os
import psutil
import numpy as np

import tensorflow as tf

process = psutil.Process(os.getpid())


# @tf.function
def train_epoch(model, p_data):
    for real_inputs in p_data:
        model * real_inputs


train_epoch = tf.autograph.to_graph(train_epoch)

data = np.random.normal(0., 1., [10000, 2])
p_data = tf.data.Dataset.from_tensor_slices(data).batch(32)

model = tf.Variable([1., 1.], dtype=tf.float64)

for i in range(5000):
    train_epoch(model, p_data)

    if i % 50 == 0:
        print(process.memory_info().rss)
```
"
29995,does the java api have used mkl to get more performance on cpu?,does the java api have used mkl to get more performance on cpu?
29992, module 'tensorflow' has no attribute 'init_scope',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29990,TensorflowJS converter cannot convert tf_saved_model to tfjs_model,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MAC OS 
- TensorFlow installed from (source or binary): binray
- TensorFlow version (use command below): 1.14.0
- TensorFlowJS version: 1.2.1
- Python version: 3.6

When I using `tensorflowjs_converter` to convert a `tf_saved_model` to `tfjs_graph_model` it gives the errors as below:

```
2019-06-20 10:05:21.636174: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-06-20 10:05:21.636291: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2019-06-20 10:05:21.636529: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-20 10:05:21.648066: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-06-20 10:05:21.648092: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.004ms.
2019-06-20 10:05:21.648098: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.
Traceback (most recent call last):
  File ""~/anaconda3/bin/tensorflowjs_converter"", line 10, in <module>
    sys.exit(main())
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflowjs/converters/converter.py"", line 556, in main
    strip_debug_ops=FLAGS.strip_debug_ops)
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py"", line 285, in convert_tf_saved_model
    concrete_func)
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 203, in convert_variables_to_constants_v2
    tensor_util.make_tensor_proto(value))
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 466, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 368, in _AssertCompatible
    raise TypeError(""List of Tensors when single Tensor expected"")
TypeError: List of Tensors when single Tensor expected
```

After debugging the source, I found that the inputs for `_AssertCompatible(values, dtype)` are: `values=Tensor(""StatefulPartitionedCall_1:0"", shape=(768, 1024), dtype=float32)` and `dtype=None`

The comments in the source indicate that the type of `values` is not supported!


"
29989,Segmentation fault when saving checkpoints with saveable Dataset Iterator,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7.6.1810
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.8
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: None
- GPU model and memory: None

- tf.version: 'v1.13.1-0-g6612da8951' 1.13.1

**Describe the current behavior**

Segmentation fault in saving an initializable dataset iterator when entering the tf.train.MonitoredSession context manager.

**Describe the expected behavior**

The initializable iterator is saved and restored properly, behaving the same with the one shot iterator.

**Code to reproduce the issue**
```python
""""""Illustrate saveable dataset iterator
""""""
import tensorflow as tf

DATASET_SIZE = 4
SAVE_STEPS = 2
TRAIN_STEP = 3
CHECKPOINT_DIR = '/tmp/tf_dataset_saveable'

def test_saveable():
    """"""test saveable""""""
    graph = tf.Graph()
    with graph.as_default():
        dataset = tf.data.Dataset.range(DATASET_SIZE).repeat()
#        dataset_iterator = dataset.make_one_shot_iterator()
        dataset_iterator = dataset.make_initializable_iterator()
        dataset_init = dataset_iterator.initializer
        data = dataset_iterator.get_next()

        saveable = tf.contrib.data.make_saveable_from_iterator(dataset_iterator)
        tf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, saveable)

        global_step = tf.train.get_or_create_global_step()
        inc_global_step = tf.assign_add(global_step, 1)  # critical

        saver = tf.train.Saver()
        checkpoint_dir = CHECKPOINT_DIR
        scaffold = tf.train.Scaffold(saver=saver)
        checkpoint_hook = tf.train.CheckpointSaverHook(
            checkpoint_dir=checkpoint_dir,
            save_steps=SAVE_STEPS, scaffold=scaffold)

        hooks = [checkpoint_hook]
        session_creator = tf.train.ChiefSessionCreator(
            scaffold=scaffold, checkpoint_dir=checkpoint_dir)
        with tf.train.MonitoredSession(
                session_creator=session_creator, hooks=hooks) as mon_sess:
            gstep = mon_sess.run(global_step)
            if not gstep:
                mon_sess.run(dataset_init)
            for _ in range(TRAIN_STEP):
                print(mon_sess.run([global_step, data]))
                mon_sess.run(inc_global_step)

if __name__ == '__main__':
    test_saveable()
```
**Other info / logs**
```console
(tf-1.13-py3) [huwh1@huwh1-centos worksync]$ python tf_dataset_saveable.py 
WARNING:tensorflow:From /home/huwh1/virtualenv/tf-1.13-py3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From tf_dataset_saveable.py:20: make_saveable_from_iterator (from tensorflow.contrib.data.python.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.make_saveable_from_iterator(...)`.
2019-06-20 10:43:20.947675: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-20 10:43:20.951984: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz
2019-06-20 10:43:20.952497: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3f10ca0 executing computations on platform Host. Devices:
2019-06-20 10:43:20.952539: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Segmentation fault (core dumped)
(tf-1.13-py3) [huwh1@huwh1-centos worksync]$ 
```"
29988,Tensorflow Distributed Learning Tutorial Code not working on localhost,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave Version 10.14.5 (Darwin-18.6.0-x86_64-i386-64bit)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-beta1
- Python version: 3.7.3
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
I have used the exact same code from the Tensorflow 2.0 Distributed Training Tutorial as in [https://www.tensorflow.org/beta/tutorials/distribute/multi_worker_with_estimator](url). The model does not run on localhost and the code returns an error with **""Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.""**
The same error was reported here: #27562 but the fix says to use ""localhost"" which I have already done and the model still won't run. Moreover, removing TF_CONFIG allows the model to run perfectly fine but adding it is what causes the error. 

**Describe the expected behavior**
The model runs as described in the tutorial.

**Code to reproduce the issue**
### Run the code below in a local machine:


```
from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow_datasets as tfds
import tensorflow as tf
import os
import json

BUFFER_SIZE = 10000
BATCH_SIZE = 64

def input_fn(mode, input_context=None):
    datasets, info = tfds.load(name='mnist',
                                with_info=True,
                                as_supervised=True)
    mnist_dataset = (datasets['train'] if mode == tf.estimator.ModeKeys.TRAIN else
                     datasets['test'])

    def scale(image, label):
        image = tf.cast(image, tf.float32)
        image /= 255
        return image, label

    if input_context:
        mnist_dataset = mnist_dataset.shard(input_context.num_input_pipelines,
                                            input_context.input_pipeline_id)
    return mnist_dataset.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)


NUM_WORKERS = 1
IP_ADDRS = ['localhost']
PORTS = [12345]

os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': ['%s:%d' % (IP_ADDRS[w], PORTS[w]) for w in range(NUM_WORKERS)]
    },
    'task': {'type': 'worker', 'index': 0}
})

LEARNING_RATE = 1e-4

def model_fn(features, labels, mode):
    model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
      tf.keras.layers.MaxPooling2D(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(10, activation='softmax')
    ])
    logits = model(features, training=False)

    if mode == tf.estimator.ModeKeys.PREDICT:
        predictions = {'logits': logits}
        return tf.estimator.EstimatorSpec(labels=labels, predictions=predictions)

    optimizer = tf.compat.v1.train.GradientDescentOptimizer(
      learning_rate=LEARNING_RATE)
    loss = tf.keras.losses.SparseCategoricalCrossentropy(
      from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(labels, logits)
    loss = tf.reduce_sum(loss) * (1. / BATCH_SIZE)
    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(mode, loss=loss)

    return tf.estimator.EstimatorSpec(
      mode=mode,
      loss=loss,
      train_op=optimizer.minimize(
          loss, tf.compat.v1.train.get_or_create_global_step()))

strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

config = tf.estimator.RunConfig(train_distribute=strategy)

classifier = tf.estimator.Estimator(
    model_fn=model_fn, config=config)
eval_result = tf.estimator.train_and_evaluate(
    classifier,
    train_spec=tf.estimator.TrainSpec(input_fn=input_fn),
    eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)
)

print(eval_result)

```

**Other info / logs**
```
2019-06-19 18:52:26.920506: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-19 18:52:26.922213: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12345}
2019-06-19 18:52:26.922707: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:12345
WARNING: Logging before flag parsing goes to stderr.
W0619 18:52:26.923428 4497626560 cross_device_ops.py:1164] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:worker/replica:0/task:0/device:CPU:0
W0619 18:52:26.926181 4497626560 estimator.py:1811] Using temporary folder as model directory: /var/folders/g1/9kky40_94s9_5qckppqs5fs9w56_br/T/tmp6x4api2p
W0619 18:52:26.928005 4497626560 distribute_coordinator.py:829] `eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
W0619 18:52:26.928821 4497626560 cross_device_ops.py:1164] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:worker/replica:0/task:0/device:CPU:0
W0619 18:52:26.929581 4497626560 cross_device_ops.py:1164] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:worker/replica:0/task:0/device:CPU:0
W0619 18:52:27.373800 123145474756608 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1340: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0619 18:52:27.378234 4497626560 monitored_session.py:347] Collective ops may deadlock with `save_checkpoints_secs` please use `save_checkpoint_steps` instead. Clearing `save_checkpoint_secs` and setting `save_checkpoint_steps` to 1000 now.
None
2019-06-19 18:52:37.840780: W tensorflow/core/common_runtime/eager/context.cc:232] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
```"
29984,`vectorized_map` does not support `IndexedSlices`,"I am trying to use `tf.vectorized_map`. But, in my network, I have some weights for `tf.nn.embedding_lookup`. I find when one tries to get the gradient, the gradients for `embedding` parts become `IndiceSlices`. 

When the code meets this: `                batch_grad = tf.vectorized_map(lambda x: tf.gradients(x, network_variables), loss)
`, it is stuck there and have the error.

```
    batch_grad = tf.vectorized_map(lambda x: tf.gradients(x, network_variables), loss)
  File ""/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py"", line 338, in vectorized_map
    return pfor(loop_fn, batch_size)
  File ""/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py"", line 164, in pfor
    return f()
  File ""/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py"", line 161, in f
    return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
  File ""/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py"", line 214, in _pfor_impl
    outputs.append(converter.convert(loop_fn_output))
  File ""/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/pfor.py"", line 1175, in convert
    output = self._convert_helper(y)
  File ""/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/pfor.py"", line 1208, in _convert_helper
    assert isinstance(y, ops.Tensor), y
AssertionError: IndexedSlices(indices=Tensor(""compute_gradients/loop_body/gradients/predict_actions/network/embeddings/embedding_lookup_grad/Reshape_1:0"", shape=(?,), dtype=int32), values=Tensor(""compute_gradients/loop_body/gradients/predict_actions/network/embeddings/embedding_lookup_grad/Reshape:0"", shape=(?, 10), dtype=float32), dense_shape=Tensor(""compute_gradients/loop_body/gradients/predict_actions/network/embeddings/embedding_lookup_grad/Cast:0"", shape=(2,), dtype=int32))
```

I think the error here is because `IndexedSlices` is not `tf.Tensor`. Then, how can I still use this `tf.vectorized_map`?
"
29983,use 'while_loop' leads to OOM,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- TensorFlow version (use command below): tensorflow-gpu 1.14.0
- Python version: python 3.7
- GPU model and memory: 4 x GTX2080

### My issue 
I use `while_loop` in the main graph. Every time I feed a batch size of dataset, say Mnist into the graph. Does `while_loop` lead to creating newer graph every epoch I train this model? Here is the error reported about OOM. 

```
2019-06-19 16:34:07.703179: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at batch_matmul_op_impl.h:635 : Resource exhausted: OOM when allocating tensor with shape[128,8070,8070] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
Traceback (most recent call last):
  File ""/home/yue/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/home/yue/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/home/yue/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[128,8070,8070] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[{{node loop_body_7/MatMul/pfor/MatMul}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""neural_network_1.py"", line 212, in <module>
    sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})
  File ""/home/yue/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""/home/yue/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/yue/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)
  File ""/home/yue/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[128,8070,8070] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[node loop_body_7/MatMul/pfor/MatMul (defined at neural_network_1.py:119) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

```

Does anyone have idea about how to solve this OOM issue?
"
29980,error saving file while using tf.data.experimental.TFRecordWriter at https://www.tensorflow.org/beta/tutorials/load_data/tf_records#writing_a_tfrecord_file,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
python notebook using python v3.7.

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-beta
[tfrecord-example-with-tfdata.ipynb.zip](https://github.com/tensorflow/tensorflow/files/3307947/tfrecord-example-with-tfdata.ipynb.zip)


- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: Deep learning VM available on GCP 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I am following the tutorial at https://www.tensorflow.org/beta/tutorials/load_data/tf_records#writing_a_tfrecord_file


**Describe the expected behavior**
I should be able to save the file. 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
See attached python notebook

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29978,Build failed after upgrading protobuf from 3.7.1 to 3.8.0,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: latest
- Python version: 3.6.2
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.26
- GCC/Compiler version (if compiling from source): LLVM version 10.0.1 (clang-1001.0.46.4)
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the problem**

After upgrading protobuf from 3.7.1 to 3.8.0, the bazel build failed. 

If reverting the upgrade commit(https://github.com/tensorflow/tensorflow/commit/508f76b1d9925304cedd56d51480ec380636cb82), the build works well.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

`bazel test //tensorflow/core/kernels/data:range_dataset_op_test`


**Any other info / logs**
```
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=192
INFO: Reading rc options for 'test' from /Users/fei/Documents/Github/tensorflow/.bazelrc:
  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
INFO: Reading rc options for 'test' from /Users/fei/Documents/Github/tensorflow/.tf_configure.bazelrc:
  Inherited 'build' options: --action_env PYTHON_BIN_PATH=/Users/fei/venv-py/tf-src/bin/python --action_env PYTHON_LIB_PATH=/Users/fei/venv-py/tf-src/lib/python3.6/site-packages --python_path=/Users/fei/venv-py/tf-src/bin/python --action_env TF_CONFIGURE_IOS=0
INFO: Reading rc options for 'test' from /Users/fei/Documents/Github/tensorflow/.tf_configure.bazelrc:
  'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium --test_tag_filters=-benchmark-test,-no_oss,-oss_serial --build_tag_filters=-benchmark-test,-no_oss --test_tag_filters=-gpu,-nomac,-no_mac --build_tag_filters=-gpu,-nomac,-no_mac
INFO: Build option --runs_per_test has changed, discarding analysis cache.
INFO: Analyzed target //tensorflow/core/kernels/data:range_dataset_op_test (1 packages loaded, 7713 targets configured).
INFO: Found 1 test target...
ERROR: /private/var/tmp/_bazel_fei/5dc7b372a7c45427ff30500d3e22fe26/external/com_google_protobuf/BUILD:106:1: C++ compilation of rule '@com_google_protobuf//:protobuf_lite' failed (Exit 1)
external/com_google_protobuf/src/google/protobuf/arena.cc:53:13: error: use of undeclared identifier 'LifecycleId'
std::atomic<LifecycleId> ArenaImpl::lifecycle_id_generator_;
            ^
1 error generated.
Target //tensorflow/core/kernels/data:range_dataset_op_test failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1.726s, Critical Path: 0.74s
INFO: 0 processes.
FAILED: Build did NOT complete successfully

FAILED: Build did NOT complete successfully
```

cc: @angersson "
29977,"Distributed Tensorflow error: Check failed: DeviceNameUtils::ParseFullName(new_base, &parsed_name)","
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**: 
- **TensorFlow version (use command below)**: 1.13.1 (PC) 1.6.0-rc0(RP)
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
Trying to run a distributed tensorflow example on CPU from:

https://github.com/tmulc18/Distributed-TensorFlow-Guide/blob/master/Distributed-Setup/dist_setup.py

Commands to run the example can be found at:

https://github.com/tmulc18/Distributed-TensorFlow-Guide/blob/master/Distributed-Setup/run.sh

It works fine when I run it on single platform (PC-PC or laptop-laptop or RP-RP) or multiple platforms with same architecture (PC-laptop, both x86 or RP-RP, both arm64). But a combination of arm64 and x86 fails from arm64 side with the following error:
```bash
2019-06-15 01:20:35.179745: F tensorflow/core/common_runtime/renamed_device.cc:27] Check failed: DeviceNameUtils::ParseFullName(new_base, &parsed_name) 
```

### Source code / logs
Note that in your code, the IPs need to be set accordingly.
The command for PC is:
```bash
python dist_setup.py --job_name ""worker"" --task_index 0
```
The output:
```bash
2019-06-14 18:20:35.040413: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-14 18:20:35.070714: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3593265000 Hz
2019-06-14 18:20:35.071281: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4c9ce60 executing computations on platform Host. Devices:
2019-06-14 18:20:35.071303: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-14 18:20:35.072829: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job ps -> {0 -> 10.1.1.2:2222}
2019-06-14 18:20:35.072861: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223}
2019-06-14 18:20:35.074703: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:2223
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-06-14 18:20:35.178858: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session 3634afcffbd6cc2d with config: 
2019-06-14 18:20:45.214939: W tensorflow/core/distributed_runtime/master_session.cc:1363] Timeout for closing worker session
2019-06-14 18:20:55.218267: I tensorflow/core/distributed_runtime/master.cc:267] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2019-06-14 18:21:05.218392: I tensorflow/core/distributed_runtime/master.cc:267] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2019-06-14 18:21:15.218519: I tensorflow/core/distributed_runtime/master.cc:267] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
```
The command for RP is:
```bash
python dist_setup.py --job_name ""ps"" --task_index 0
```
The output:
```bash
/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py:33: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from tensorflow.python.framework import fast_tensor_util
2019-06-15 01:19:54.226102: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-06-15 01:19:54.226278: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> 10.1.1.1:2223}
2019-06-15 01:19:54.227740: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2222
2019-06-15 01:20:35.179745: F tensorflow/core/common_runtime/renamed_device.cc:27] Check failed: DeviceNameUtils::ParseFullName(new_base, &parsed_name) 
Aborted
```
The source code(from github):
```bash
""""""Simple example with one parameter server and one worker.
Author: Tommy Mulc
""""""


from __future__ import print_function
import tensorflow as tf
import argparse
import time
import os


FLAGS = None
log_dir = '/logdir'

def main():
	# Distributed Baggage
	cluster = tf.train.ClusterSpec({
        'ps':['localhost:2222'],
        'worker':['localhost:2223']
        }) #lets this node know about all other nodes
	if FLAGS.job_name == 'ps': #checks if parameter server
		server = tf.train.Server(cluster,
          job_name=""ps"",
          task_index=FLAGS.task_index)
		server.join()
	else:
		is_chief = (FLAGS.task_index == 0) #checks if this is the chief node
		server = tf.train.Server(cluster,
          job_name=""worker"",
          task_index=FLAGS.task_index)

		# Graph
		with tf.device('/cpu:0'):
			a = tf.Variable(tf.truncated_normal(shape=[2]),dtype=tf.float32)
			b = tf.Variable(tf.truncated_normal(shape=[2]),dtype=tf.float32)
			c=a+b

			target = tf.constant(100.,shape=[2],dtype=tf.float32)
			loss = tf.reduce_mean(tf.square(c-target))
		
			opt = tf.train.GradientDescentOptimizer(.0001).minimize(loss)

    # Session
    # Monitored Training Session
		sess = tf.train.MonitoredTrainingSession(
          master=server.target,
          is_chief=is_chief)
		for i in range(1000):
			if sess.should_stop(): break
			sess.run(opt)
			if i % 10 == 0:
				r = sess.run(c)
				print(r)
			time.sleep(.1)
		sess.close()

if __name__ == '__main__':
	parser = argparse.ArgumentParser()
	# Flags for defining the tf.train.ClusterSpec
	parser.add_argument(
    	""--job_name"",
    	type=str,
    	default="""",
    	help=""One of 'ps', 'worker'""
    )
  # Flags for defining the tf.train.Server
	parser.add_argument(
    	""--task_index"",
    	type=int,
    	default=0,
    	help=""Index of task within the job""
    )
	FLAGS, unparsed = parser.parse_known_args()
	main()
```"
29975,Batch size on different worker could be different?,"I want to use Tensorflow for training in a distributed environment. But current Allreduce framework requires that both the tensor dimensions and batch size should the same among all the workers. I want to know if Tensorflow supports different workers have different batch size in the same batch, but their tensor size is still the same.
"
29974,custom filter,I want to build custom filter with tf.nn.conv2d 
29973,bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>
Hello Tensorflow team
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 64bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA
- TensorFlow installed from (source or binary):Don't know
- TensorFlow version:1.13.1
- Python version:3.6.5
- Installed using virtualenv? pip? conda? :pip
- Bazel version (if compiling from source):0.22
- GCC/Compiler version (if compiling from source):Don't know
- CUDA/cuDNN version:NA
- GPU model and memory:NA



**Describe the problem**
I am following the commands Build from source on Windows and got stuck

C:\Users\DELL\tensorflow>bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
WARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:
c:\users\dell\tensorflow/tools/bazel.rc
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/DELL/Miniconda3/python.exe
INFO: Reading rc options for 'build' from c:\users\dell\tensorflow\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=C:/Users/DELL/Miniconda3/python.exe --action_env PYTHON_LIB_PATH=C:/Users/DELL/Miniconda3/lib/site-packages --python_path=C:/Users/DELL/Miniconda3/python.exe --action_env TF_NEED_OPENCL_SYCL=0 --action_env TF_NEED_CUDA=0 --action_env TF_DOWNLOAD_CLANG=0 --define grpc_no_ares=true --strip=always --config monolithic --copt=-w --host_copt=-w --verbose_failures
ERROR: Config value monolithic is not defined in any .rc file
INFO: Invocation ID: 0388987f-5098-402f-afd1-3cf7ab4f3e40


**Provide the exact sequence of commands / steps that you executed before running into the problem**
I installed Msys2 
 then used pacman -S git patch unzip
set path as C:\msys64\usr\bin\bash.exe for BAZEL_SH
I installed  Visual C++ Build Tools 2015
git clone https://github.com/tensorflow/tensorflow.git 
cd tensorflow
git checkout r1.9
python ./configure.py
bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
I tried many ways to resolve this but can't find the solution please help me out and if possible please make video for this

"
29972,AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode',"I am using tensorflow on python 3.7, Ubuntu 16.04. The code which throws the above mentioned error is written below. It is based on the following [code](https://www.tensorflow.org/guide/datasets#applying_arbitrary_python_logic_with_tfpy_func). I am getting this error on both tensorflow 1.13 as well as 2.0.0-beta1

I have a dataset folder containing millions of data pair of the form (image,timeseries). The timeseries is in numpy format. I want to use np.load() function to load the data. But the filename is in string tensor format. np.load() does not accept tensorflow.python.framework.ops.EagerTensor

	import tensorflow as tf
	import numpy as np
	import imageio

	#tf.enable_eager_execution()    # use this line if using tensorflow 1.13

	imageio.imwrite('data.jpg', np.random.rand(256,256,3))
	np.save('data.npy',np.ones(1024))

	def load(image_file,timeseries_file):
	  image = tf.io.read_file(image_file)
	  image = tf.image.decode_jpeg(image)
	  timeseries = np.load(timeseries_file.decode())
	  timeseries = tf.convert_to_tensor(timeseries, np.float32)
	  image = tf.cast(image, tf.float32)
	  timeseries = tf.cast(timeseries, tf.float32)
	  return image, timeseries

	image_files = ['data.jpg']
	timeseries_files = ['data.npy']
	train_dataset = tf.data.Dataset.from_tensor_slices((image_files, timeseries_files))
	train_dataset = train_dataset.map(
	    lambda image_file, timeseries_file: tuple(tf.py_function(
	        load, [image_file, timeseries_file], [tf.float32, tf.float32])))
	for x in train_dataset.take(1):
		print(x)"
29971,Backpropogation error with tf.math.top_k,"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  
No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04
- TensorFlow installed from (source or binary):
Source
- TensorFlow version (use command below):
1.13
- Python version:
3.5.7 (Also reproduced with 3.6)
- CUDA/cuDNN version:
10.1
- GPU model and memory:
Quadro P3000

**Describe the current behavior**
When the input argument in tf.math.top_k losses is a tensor of shape [0, 0], backpropogation fails on the reshape step. 

**Describe the expected behavior**
There should be no backprop on collecting 0 elements from tensor with 0 values. 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Trying to perform Online Hard Example Mining with two lists of losses of shape [None, None] (Batch, num_losses)
When there are either zero positive examples or zero negative examples, trips the error on the backprop step even though there should be no backprop for a selection of zero elements or a tensor of zero elements
```
(placeholders/ setup)
positive_class_examples = tf.gather_nd(classification_losses, positive_class_indices)
negative_class_examples = tf.gather_nd(classification_losses, negative_class_indices)
num_pos_examples = tf.shape(positive_class_examples)[0]
num_neg_examples = tf.math.maximum(256 - num_pos_examples, 0)
top_negative_losses, top_negative_loss_indices = tf.math.top_k(negative_class_examples, k=num_neg_examples)
balanced_top_classification_losses = tf.concat([positive_class_examples, top_negative_losses], axis=-1)
...
(optimizer creation with prior code included)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
Traceback (most recent call last):
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1334, in _do_call
    return fn(*args)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero
	 [[{{node gradients/balance_positive_and_negative_examples/TopKV2_grad/Reshape}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  <Redacted>
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 929, in run
    run_metadata_ptr)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1328, in _do_run
    run_metadata)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero
	 [[node gradients/balance_positive_and_negative_examples/TopKV2_grad/Reshape (defined at train.py:177) ]]

Caused by op 'gradients/balance_positive_and_negative_examples/TopKV2_grad/Reshape', defined at:
  <Redacted>
    train_op = optimizer.minimize(loss)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 403, in minimize
    grad_loss=grad_loss)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 512, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py"", line 664, in gradients
    unconnected_gradients)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py"", line 965, in _GradientsHelper
    lambda: grad_fn(op, *out_grads))
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py"", line 420, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py"", line 965, in <lambda>
    lambda: grad_fn(op, *out_grads))
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py"", line 1002, in _TopKGrad
    ind_2d = array_ops.reshape(op.outputs[1], array_ops.stack([-1, ind_lastdim]))
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 7179, in reshape
    ""Reshape"", tensor=tensor, shape=shape, name=name)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

...which was originally created as op 'balance_positive_and_negative_examples/TopKV2', defined at:
  <Redacted>
  File ""train.py"", line 127, in balance_positive_and_negative_examples
    top_negative_losses, top_negative_loss_indices = tf.math.top_k(negative_class_examples, k=num_neg_examples)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 3084, in top_k
    return gen_nn_ops.top_kv2(input, k=k, sorted=sorted, name=name)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 8401, in top_kv2
    ""TopKV2"", input=input, k=k, sorted=sorted, name=name)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

InvalidArgumentError (see above for traceback): Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero
	 [[node gradients/balance_positive_and_negative_examples/TopKV2_grad/Reshape (defined at train.py:177) ]]
```
"
29970,Tensorflow installe using GPU but it is using only CPU,"I have installed tensorflow from source using bazel on ubuntu 16.xx

tensorflow version 1.11.0
bazel 0.18.0rc6
python 2.7.11
cuda 9.2 (j'utilse celle dans dossier /home/ahmed/tmp/cuda-9.2)
cudnn 7.1.4
nccl 2.4.2

the build sucessfull , the installation is also OK.
However, the tensorflow does'nt use GPU.

Whe I run : 

import tensorflow as tf
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))

**2019-06-19 17:49:28.775658: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: UNKNOWN ERROR (-1)
2019-06-19 17:49:28.775751: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] retrieving CUDA diagnostic information for host: ubuntu-Precision-Tower-7910
2019-06-19 17:49:28.775770: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:170] hostname: ubuntu-Precision-Tower-7910
2019-06-19 17:49:28.775831: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:194] libcuda reported version is: Invalid argument: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""
2019-06-19 17:49:28.775898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:198] kernel reported version is: 396.54.0
Device mapping: no known devices.
2019-06-19 17:49:28.777666: I tensorflow/core/common_runtime/direct_session.cc:291] Device mapping:**


Wed Jun 19 17:54:39 2019
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 396.54                 Driver Version: 396.54                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:04:00.0  On |                  N/A |
| 28%   49C    P8    19W / 250W |    180MiB / 11177MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  TITAN Xp            Off  | 00000000:05:00.0 Off |                  N/A |
| 23%   33C    P8    16W / 250W |      2MiB / 12196MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1385      G   /usr/lib/xorg/Xorg                           137MiB |
|    0      2744      G   compiz                                        41MiB |
+-----------------------------------------------------------------------------+
"
29969,ModuleNotFoundError: No module named 'tensorflow_model_optimization',Occurs when attempting to import tensorflow_model_optimization. Running tf-nightly-gpu 1.14. Installed tensorflow_model_optimization package as well.
29968,Many context switches / Many threads even if threading is limited,"**System information**
- Have I written custom code: No (https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/quickstart/beginner.ipynb)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux OpenSuse Leap 15.0
- TensorFlow installed from (source or binary): pip package tensorflow==2.0.0-beta1
- TensorFlow version (use command below): v2.0.0-beta0-16-g1d91213
- Python version: 3.7.3 
- GPU model and memory: CPU only

**Describe the current behavior**
If you limit the number of threads with tf.set_inter_op_parallelism_threads(NUM_THREADS) and tf.set_intra_op_parallelism_threads(NUM_THREADS) tensorflow creates a threadpool with more threads than NUM_THREADS and runs maximal NUM_THREADS causing high amount of context switches, which is delaying execution.

**Describe the expected behavior**
Create maximal NUM_THREADS and limit context switches.

**Code to reproduce the issue**
```python
from __future__ import absolute_import, division, print_function, unicode_literals
!pip install -q tensorflow==2.0.0-beta1
import tensorflow as tf
NUM_THREADS=2
tf.config.threading.set_inter_op_parallelism_threads(NUM_THREADS)
tf.config.threading.set_intra_op_parallelism_threads(NUM_THREADS)
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(x_train, y_train, epochs=100)
```


"
29966,GPU docs don't show how to test your install,"https://www.tensorflow.org/install/gpu 

how do you test your install to make sure everything went OK?"
29965,"""mean_squared_error"" gives incorrect results in conjunction with sample weights","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7.3

There is a difference between passing the string `""mean_squared_error""` or passing `tf.keras.losses.mean_squared_error` as loss function in conjunction with sample weights.

```python
import numpy as np
import tensorflow as tf

def test_loss_function(loss_function):
    print(""Testing {}"".format(loss_function))

    layer = tf.keras.layers.Input(shape=(1,))
    model = tf.keras.Model(inputs=layer, outputs=layer)

    model.compile(optimizer='adam',
                  loss=loss_function)

    weights = np.array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])
    model.evaluate(np.zeros(10), np.ones(10), sample_weight=weights)

test_loss_function('mean_squared_error')
test_loss_function(tf.keras.losses.mean_squared_error)
```

Output:

```
Testing mean_squared_error
10/10 [==============================] - 0s 4ms/sample - loss: 0.5000
Testing <function mean_squared_error at 0x7f657d0d6a60>
10/10 [==============================] - 0s 2ms/sample - loss: 1.0000
```"
29964,Different metrics and loss values in model.fit and model.evaluate for the same batch of data,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.14.0
- Python version: 3.6.8
- CUDA/cuDNN version: cuda 10.0, cudnn 7.5.1
- GPU model and memory: NVIDIA GeForce RTX 2070

**Describe the current behavior**

When performing the evaluation on a model I get values for metrics and loss that differ from those obtained at the last training epoch. 

The code and the output is given [below](#issuecomment-504010990).

**Describe the expected behavior**

Because the batch of data is the same and the metrics computed are the same, I expect to get exactly the same values.
"
29963,TypeError: moments_v2() got an unexpected keyword argument 'keep_dims',TypeError: moments_v2() got an unexpected keyword argument 'keep_dims'
29962,"I'm using tensorflow 2.0 beta, and trainings stop in the middle with an error""Could not flush events file."" I believe this is something internal as the training stops at different points in the training, and I trained for 100 epochs once before (and I started to have this issue without any change in code).","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29961,tf.contrib.layers.group_norm() Error: Failed to convert object,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux  CentOS 3.10.0-693.2.2.el7.x86_64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): b'v1.13.1-0-g6612da8951' 1.13.1
- Python version: python3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
- CUDA/cuDNN version: cuda-10.0, cudnn-7.6
- GPU model and memory: 16G(Nvidia-P100)

this is the repost from:[issues](29636)"
29959,ValueError: The channel dimension of the inputs should be defined. Found `None`.,"`ngf = 64
nz = 100
nc = 3
b_size = 128
def create_generator():
  noise_input = layers.Input(shape = (nz,), batch_size=b_size)#TODO: maybe change the datatype
  inter = tf.reshape(noise_input, tf.convert_to_tensor([-1, 1,1, nz])) 
  x = layers.Conv2DTranspose(filters=ngf*8, kernel_size=(4,4), strides=(1,1), padding='valid', bias_initializer=weights_initializer, use_bias=False, )(inter)
  x = layers.BatchNormalization(-1)(x)
  x = layers.ReLU()(x)
  
  x = layers.Conv2DTranspose(filters=ngf*4, kernel_size=(4,4), strides=(2,2), padding='same', bias_initializer=weights_initializer, use_bias=False)(x)
  x = layers.BatchNormalization(-1)(x)
  x = layers.ReLU()(x)
  
  #Now unshared layers begin
  #the zeroth generator
  g0 = layers.Conv2DTranspose(filters=ngf*2, kernel_size=(4,4), strides=(2,2), padding='same', bias_initializer=weights_initializer, use_bias=False)(x)
  g0 = layers.BatchNormalization(-1)(g0)
  g0 = layers.ReLU()(g0)
  
  g0 = layers.Conv2DTranspose(filters=ngf, kernel_size=(4,4), strides=(2,2), padding='same', bias_initializer=weights_initializer, use_bias=False)(g0)
  g0 = layers.BatchNormalization(-1)(g0)
  g0 = layers.ReLU()(g0)
  
  g0 = layers.Conv2DTranspose(filters=nc, kernel_size=(4,4), strides=(2,2), padding='same', bias_initializer=weights_initializer, use_bias=False, activation ='tanh')(g0)
  
  #the first generator
  g1 = layers.Conv2DTranspose(filters=ngf*2, kernel_size=(4,4), strides=(2,2), padding='same', bias_initializer=weights_initializer, use_bias=False)(x)
  g1 = layers.BatchNormalization(-1)(g1)
  g1 = layers.ReLU()(g1)
  
  g1 = layers.Conv2DTranspose(filters=ngf, kernel_size=(4,4), strides=(2,2), padding='same', bias_initializer=weights_initializer, use_bias=False)(g1)
  g1 = layers.BatchNormalization(-1)(g1)
  g1 = layers.ReLU()(g1)
  
  g1 = layers.Conv2DTranspose(filters=nc, kernel_size=(4,4), strides=(2,2), padding='same', bias_initializer=weights_initializer, use_bias=False, activation ='tanh')(g1)
  
  #the second generator
  g2 = layers.Conv2DTranspose(filters=ngf*2, kernel_size=(4,4), strides=(2,2), padding='same', bias_initializer=weights_initializer, use_bias=False)(x)
  g2 = layers.BatchNormalization(-1)(g2)
  g2 = layers.ReLU()(g2)
  
  g2 = layers.Conv2DTranspose(filters=ngf, kernel_size=(4,4), strides=(2,2), padding='same', bias_initializer=weights_initializer, use_bias=False)(g2)
  g2 = layers.BatchNormalization(-1)(g2)
  g2 = layers.ReLU()(g2)
  
  g2 = layers.Conv2DTranspose(filters=nc, kernel_size=(4,4), strides=(2,2), padding='same', bias_initializer=weights_initializer, use_bias=False, activation ='tanh')(g2)
  
  
  output = layers.concatenate([g0, g1, g2], axis = 0)
  
  return models.Model(inputs = [noise_input], outputs = [output])`


Getting the error 

---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

<ipython-input-12-1b6405bf3d1f> in <module>()
----> 1 gnet = create_generator()

3 frames

<ipython-input-9-ee1d9a68741d> in create_generator()
      6   noise_input = layers.Input(shape = (nz,), batch_size=b_size)#TODO: maybe change the datatype
      7   inter = tf.reshape(noise_input, tf.convert_to_tensor([-1, 1,1, nz]))
----> 8   x = layers.Conv2DTranspose(filters=ngf*8, kernel_size=(4,4), strides=(1,1), padding='valid', bias_initializer=weights_initializer, use_bias=False, )(inter)
      9   x = layers.BatchNormalization(-1)(x)
     10   x = layers.ReLU()(x)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    614           # Build layer if applicable (if the `build` method has been
    615           # overridden).
--> 616           self._maybe_build(inputs)
    617 
    618           # Wrapping `call` function in autograph to allow for dynamic control

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in _maybe_build(self, inputs)
   1964         # operations.
   1965         with tf_utils.maybe_init_scope(self):
-> 1966           self.build(input_shapes)
   1967       # We must set self.built since user defined build functions are not
   1968       # constrained to set self.built.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py in build(self, input_shape)
    749       channel_axis = -1
    750     if input_shape.dims[channel_axis].value is None:
--> 751       raise ValueError('The channel dimension of the inputs '
    752                        'should be defined. Found `None`.')
    753     input_dim = int(input_shape[channel_axis])

ValueError: The channel dimension of the inputs should be defined. Found `None`."
29958,[TF 2.0 API Docs] `tf.keras.callbacks` (sub)classes,"TensorFlow version: 2.0 (beta1)

#### (Sub)classes of `tf.keras.callbacks`:
`BaseLogger`, `History`, `Callback`, `CSVLogger`, `ModelCheckpoint`, `ProgbarLogger`, `RemoteMonitor`, `TensorBoard` and `TerminateOnNaN`:

#### Summary:
Since `tf.keras.callbacks` are important for monitoring models during training, the API docs require extra attention imo.

Examples - to add - see below
Descriptions - to be defined better - see below (especially the `Callback` custom class)
Returns/raises - to add for better UX when needed

#### Suggested improvements: 

- _Missing examples_: one example per (sub)class would be enough for good UX and a link to a tutorial presents an extra step for a user. E.g. a short example inside the docs similar to the ones in `EarlyStopping` ([link](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/EarlyStopping)), `ReduceLROnPlateau` ([link](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau)) or `LambdaCallback` ([link](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/LambdaCallback))

Note: `ModelCheckpoint` and `TensorBoard` have links to tutorials which have examples. `BaseLogger` and `History` are applied by default but that may not help understand them better.

Example of a `Custom` callback from @fchollet Deep Learning with Python book:
```python
class ActivationLogger(keras.callbacks.Callback):
    def set_model(self, model):
        self.model = model # Called by the parent model before training, to inform the callback of what model will be calling it
        layer_outputs = [layer.output for layer in model.layers]
        self.activations_model = keras.models.Model(model.input, layer_outputs) # Model instance that returns the activations of every layer

    def on_epoch_end(self, epoch, logs=None):
        if self.validation_data is None:
                raise RuntimeError('Requires validation_data.')
        validation_sample = self.validation_data[0][0:1] # Obtains the first input sample of the validation data
        activations = self.activations_model.predict(validation_sample)
        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'w') # Saves arrays to disk
        np.savez(f, activations)
        f.close()
```

Example of a `TensorBoard` callback from @fchollet Deep Learning with Python book:
```python
callbacks = [
    keras.callbacks.TensorBoard(
        log_dir='my_log_dir', # Location of log files
        histogram_freq=1, # Records activation histogram every 1 epoch
        embeddings_freq=1, # Records embedding data every 1 epoch
    )
]

history = model.fit(x_train, y_train, 
                epochs=20, 
                batch_size=128, 
                validation_split=0.2, 
                callbacks=callbacks)

# Browse to http://localhost:6006 and look at your model training
...
```

- _Descriptions_: to be defined better if needed. Recommend to use the following Medium post  which has quite decent descriptions of each `callback`: https://medium.com/singlestone/keras-callbacks-monitor-and-improve-your-deep-learning-205a8a27e91c

Note: Mention in the `EarlyStopping` and `ModelCheckpoint` descriptions that they are/should be both typically used together (see `callbacks_list` example from @fchollet with 2 callbacks passed into `model.fit` below) to stop training when improvement stops and save the current best model during training (`save_best_only=True`):

```python
# A list of 2 or more callbacks that can be passed into `model.fit`
callbacks_list = [
        keras.callbacks.EarlyStopping(
                monitor='acc',
                patience=1,
        ),
        
        keras.callbacks.ModelCheckpoint( # Saves the current weights after every epoch
                filepath='my_model.h5',
                monitor='val_loss',
                save_best_only=True, # These two arguments mean you wonâ€™t overwrite the model file unless val_loss has improved
        )
]

model.compile(optimizer='rmsprop',
                loss='binary_crossentropy',
                metrics=['acc'])

model.fit(x, y,
                epochs=10,
                batch_size=32,
                callbacks=callbacks_list,
                validation_data=(x_val, y_val)
                )
```

- _Returns/Raises_: to be defined/defined better if needed

#### Doc links:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/BaseLogger
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/History
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/Callback
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/CSVLogger
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/ModelCheckpoint
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/ProgbarLogger
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/RemoteMonitor
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/TensorBoard
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/TerminateOnNaN"
29957,Filling up shuffle buffer (this may take a while): 9544 of 10000,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Windows 10 x64
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.13.1
- Python version:3.6
- CUDA/cuDNN version:10.0/7.4
- GPU model and memory: Nvidia Geforce 840m / 4.00 Go


I used CNN facial landmarks for training my own dataset , when I start training I get some lines :
> I tensorflow/core/kernels/data/shuffle_dataset_op.cc:101] Filling up shuffle buffer (this may take a while): 7024 of 10000
2019-06-19 12:02:24.102469: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:101] Filling up shuffle buffer (this may take a while): 9544 of 10000

I want to know, are those lines meaning errors?
Thanks."
29956,TensorflowJS cannot be installed properly,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- MAC OS:
- TensorFlowJS version (1.2.1):
- Python version 3.6:

After installed `pip install tensorflowjs==1.2.1`
I use `tensorflowjs_converter --help` it gives the errors:
```
WARNING: Logging before flag parsing goes to stderr.
W0619 17:05:26.072402 140736116396928 __init__.py:309] Limited tf.compat.v2.summary API due to missing TensorBoard installation.
W0619 17:05:26.101637 140736116396928 __init__.py:336] Limited tf.summary API due to missing TensorBoard installation.
Traceback (most recent call last):
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow_hub/tf_v1.py"", line 30, in <module>
    from tensorflow_estimator import estimator
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/__init__.py"", line 8, in <module>
    from tensorflow_estimator._api.v2 import estimator
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/_api/v2/estimator/__init__.py"", line 31, in <module>
    from tensorflow_estimator.python.estimator.estimator_lib import BinaryClassHead
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/__init__.py"", line 25, in <module>
    import tensorflow_estimator.python.estimator.estimator_lib
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator_lib.py"", line 67, in <module>
    from tensorflow_estimator.python.estimator.tpu.tpu_estimator import TPUEstimator
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 86, in <module>
    from tensorflow_estimator.python.estimator.tpu import _tpu_estimator_embedding
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/_tpu_estimator_embedding.py"", line 32, in <module>
    from tensorflow.python.tpu import feature_column_v2 as tpu_fc_v2
ImportError: cannot import name 'feature_column_v2'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""~/anaconda3/bin/tensorflowjs_converter"", line 6, in <module>
    from tensorflowjs.converters.converter import main
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflowjs/__init__.py"", line 21, in <module>
    from tensorflowjs import converters
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflowjs/converters/__init__.py"", line 24, in <module>
    from tensorflowjs.converters.tf_saved_model_conversion_v2 import convert_tf_saved_model
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py"", line 38, in <module>
    import tensorflow_hub as hub
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow_hub/__init__.py"", line 30, in <module>
    from tensorflow_hub.estimator import LatestModuleExporter
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow_hub/estimator.py"", line 25, in <module>
    from tensorflow_hub import tf_utils
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow_hub/tf_utils.py"", line 28, in <module>
    from tensorflow_hub import tf_v1
  File ""~/anaconda3/lib/python3.6/site-packages/tensorflow_hub/tf_v1.py"", line 32, in <module>
    from tensorflow import add_to_collection
ImportError: cannot import name 'add_to_collection'
```"
29955,Create a low-level python tutorial for tf 2,"## Description of issue (what needs changing):

It is unclear how to translate the following code to tf 2:

```python
%matplotlib inline
import tensorflow as tf
from matplotlib import pyplot as plt
from tqdm.auto import tqdm, trange
import numpy as np

tf.compat.v1.disable_eager_execution()

y = np.array([[10., 1.], [6., 3.], [-1, 7]])
x = np.array([[4., 15.], [1., 1.], [-7, 1]])
trajs = [[] for j in range(y.shape[0])]

g = tf.compat.v1.Graph()
with g.as_default():
	sess = tf.compat.v1.Session(graph=g)
	
	yT = tf.compat.v1.placeholder(tf.float64)
	xT = tf.compat.v1.Variable(x, trainable=True)

	elementWiseLoss = tf.compat.v1.reduce_sum((yT - xT)**2, axis=1)
	loss = tf.compat.v1.reduce_sum(elementWiseLoss)
	opt = tf.compat.v1.train.AdamOptimizer(0.1).minimize(loss)
	init = tf.compat.v1.global_variables_initializer()
	
	sess.run(init)
	epochs = 300
	for i in trange(epochs):
		_, lossR, x, elR = sess.run([opt, loss, xT, elementWiseLoss], feed_dict={yT: y})
		if not i % 10:
			for j in range(y.shape[0]):
				trajs[j].append([*x[j], elR[j]])

print(""x"", x)
print(""y"", y)
print(""y - x"", y - x)
trajs = np.array(trajs)
for i, m in enumerate([""o"", ""+"", ""*""]):
	plt.scatter(trajs[i, :, 0], trajs[i, :, 1], marker=m, c=trajs[i, :, 2], cmap=""rainbow"", label=str(i))
plt.legend()
plt.grid()
plt.colorbar()
plt.show()
```

The solution:
```python
%matplotlib inline
import tensorflow as tf
from matplotlib import pyplot as plt
from tqdm.auto import tqdm, trange
import numpy as np

y = np.array([[10., 1.], [6., 3.], [-1, 7]])
x = np.array([[4., 15.], [1., 1.], [-7, 1]])
trajs = [[] for j in range(y.shape[0])]


yT = tf.Variable(y)
xT = tf.Variable(x)

@tf.function
def elementWiseLoss():
	return tf.reduce_sum((yT - xT)**2, axis=1)

@tf.function
def loss():
	return tf.reduce_sum(elementWiseLoss())

optr = tf.optimizers.Adam(0.1)

epochs = 300
for i in trange(epochs):
	optr.minimize(loss, [xT])
	lossR = loss().numpy()
	x = xT.numpy()
	elR = elementWiseLoss().numpy()
	if not i % 10:
		for j in range(yT.shape[0]):
			trajs[j].append([*xT[j], elR[j]])

print(""x"", x)
print(""y"", y)
print(""y - x"", y - x)
trajs = np.array(trajs)
for i, m in enumerate([""o"", ""+"", ""*""]):
	plt.scatter(trajs[i, :, 0], trajs[i, :, 1], marker=m, c=trajs[i, :, 2], cmap=""rainbow"", label=str(i))
plt.legend()
plt.grid()
plt.colorbar()
plt.show()
```

### Clear description

It would be nice to have a tutorial page containing both v1-style solution and v2-style one.

"
29954,TFLite Macro README instructions don't build. ,"The README.md file at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/README.md

indicates that a make call with test keyword will run all tests:
```
make -f tensorflow/lite/experimental/micro/tools/make/Makefile test
```
But this results in a syntax error:

```
~/tensorflow$ make -f tensorflow/lite/experimental/micro/tools/make/Makefile test
/bin/sh: 1: [[: not found
tensorflow/lite/experimental/micro/tools/make/download_and_extract.sh ""http://mirror.tensorflow.org/github.com/google/flatbuffers/archive/v1.11.0.tar.gz"" ""02c64880acb89dbd57eebacfd67200d8"" tensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers 
downloading http://mirror.tensorflow.org/github.com/google/flatbuffers/archive/v1.11.0.tar.gz
tensorflow/lite/experimental/micro/tools/make/download_and_extract.sh: line 84: curl: command not found
tensorflow/lite/experimental/micro/tools/make/Makefile:198: recipe for target 'tensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers' failed
make: *** [tensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers] Error 127
```

In both my systems (Ubuntu 18.04 on WSL and Virtualmachine) make is defaulted to /bin/sh and not /bin/bash therefore `[[` is not interpreted. 

It is not an issue, but still, I thought the makefile would just work (TM). Many others might also, since it is indicated in README.
I the same line is available in the upcoming TinyML book, that is how I ran it.  
@petewarden 

![ezgif com-optimize (4)](https://user-images.githubusercontent.com/551129/59755686-a8fef700-9288-11e9-85aa-527d5d6d78e1.gif)
"
29953,Which license must be provided with my application when using the tensorflow C API?,"I am developing a commercial application that uses the tensorflow C API. At all kinds of places, for example, https://github.com/tensorflow/tensorflow/blob/master/LICENSE, I found that tensorflow uses the Apache License 2.0. However, when I downloaded the C API from https://www.tensorflow.org/install/lang_c (https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-1.13.1.zip) it came with a huge LICENSE file that lists many 3rd party libraries.

Which license do I need to distribute with my application? Do I need to add the Apache License 2.0 for tensorflow or do I need to add the content of the LICENSE file that came with the C API?"
29952,Error when using tf.keras.backend.function() in 1.14.0-rc0/1.14.0,"```
def input_derivative(model, x, goal):
  """""" Calculate derivatives wrt the intputs """"""
  y_true = Input(shape=(10,))
  ce = categorical_crossentropy(y_true, model.output)
  grad_ce = tf.keras.backend.gradients(ce, model.inputs)
  func = tf.keras.backend.function(model.inputs + [y_true], grad_ce)
  output = func([x, goal])
  return output
```

Here is my code try to calculate gradients.
It is work in tensorflow1.13.1
but get error message at tensorflow1.14.0-rc0 like the following
```
InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: Expected size[0] in [0, 0], but got 1
	 [[{{node softmax_cross_entropy_with_logits/Slice_1}}]]
	 [[gradients/conv2d/Conv2D_grad/Conv2DBackpropInput/_101]]
  (1) Invalid argument: Expected size[0] in [0, 0], but got 1
	 [[{{node softmax_cross_entropy_with_logits/Slice_1}}]]
0 successful operations.
0 derived errors ignored.
```"
29951,Segmentation fault when using cpp custom op in tf.data.Dataset.map in tensorflow2.0,"It seems if I have cpp custom op in a python function and I pass the python function to tf.data.Dataset.map it will crush.
If I only call this python function outside, It will be ok.
I've spend a whole afternoon to find the bug. I'm really mad about this bug.

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux ubuntu 18.04
TensorFlow installed from (source or binary):binary
TensorFlow version (use command below): 2.0b1
Python version:3.6
CUDA/cuDNN version:10/7.4
GPU model and memory:7.5/24gb

```

import tensorflow as tf
import pdb
extr_module = tf.load_op_library('./build/libextr_module.so')
res = extr_module.test_bug() # ok

def aaa(filename):
    res = extr_module.test_bug() # Segmentation fault (core dumped)

    return tf.zeros([1], tf.float32)
    
dataset = tf.data.TextLineDataset(['aaa']).map(aaa)

```
```
#include ""tensorflow/core/framework/op_kernel.h""
#include ""tensorflow/core/framework/register_types.h""
#include ""tensorflow/core/framework/tensor.h""
#include ""tensorflow/core/framework/tensor_shape.h""
#include ""tensorflow/core/framework/register_types.h""
#include ""tensorflow/core/framework/op.h""
#include ""tensorflow/core/framework/shape_inference.h""
#include ""tensorflow/core/util/work_sharder.h""

#include <iostream>
#include <cmath>

using namespace tensorflow;

REGISTER_OP(""TestBug"")
    .Output(""dummy: float"")
    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
        c->set_output(0, c->MakeShape({1}));
        return Status::OK();
    });

class TestBugOp : public OpKernel
{
public:
explicit TestBugOp(OpKernelConstruction* context)
        : OpKernel(context)
{

}

void Compute(OpKernelContext* context) override
{
    Tensor* dummy = NULL;
    OP_REQUIRES_OK(context, context->allocate_output(0, {1},
                                                     &dummy));
}
};

REGISTER_KERNEL_BUILDER(
  Name(""TestBug"").Device(DEVICE_CPU),
  TestBugOp
);
```
```

CMAKE_MINIMUM_REQUIRED(VERSION 2.8)
PROJECT(extr_module)


# compiler flags
SET(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -std=c++11 -O2 ${OpenMP_CXX_FLAGS} -Wall -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DGOOGLE_CUDA=1"")

# TensorFlow dependencies
EXECUTE_PROCESS(COMMAND python3 -c ""import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'; import tensorflow as tf; print(tf.sysconfig.get_include(), end='', flush=True)""  OUTPUT_VARIABLE TF_INC)

EXECUTE_PROCESS(COMMAND python3 -c ""import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'; import tensorflow as tf; print(tf.sysconfig.get_lib(), end='', flush=True)""  OUTPUT_VARIABLE TF_LIB)


MESSAGE(STATUS ""Found TF_INC: "" ${TF_INC})
#MESSAGE(STATUS ""Found TF_INC_EXTERNAL: "" ${TF_INC}/external/nsync/public)
MESSAGE(STATUS ""Found TF_LIB: "" ${TF_LIB})


INCLUDE_DIRECTORIES(${TF_INC})
#INCLUDE_DIRECTORIES(${TF_INC}/external/nsync/public)
LINK_DIRECTORIES(${TF_LIB})


ADD_LIBRARY(extr_module SHARED
  testbug.cc
)

TARGET_LINK_LIBRARIES(extr_module tensorflow_framework)
```"
29950,[TF 2.0/1.14 API Docs] `tf.keras.callbacks` - broken links to source,"##### Description:
`tf.keras.callbacks` TF r2.0 and r1.14 docs state that it's defined in an `__init__.py` but the links are broken (404): 

There is no link to `__init__.py` in TF 1.13 stable (1.14 too? since it's just been released)
https://www.tensorflow.org/api_docs/python/tf/keras/callbacks

- URL(s) with the issue (404):
r2.0: https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/python/keras/api/_v2/keras/callbacks/__init__.py
r1.14: https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/api/_v1/keras/callbacks/__init__.py

- Link to the documentation entry:
r2.0: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks
r1.14: https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/callbacks
"
29949,Warning printing to stdout instead of stderr,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu Linux 19.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.0-rc2
- Python version: 3.7
- CUDA/cuDNN version: 7.0
- GPU model and memory: Titan X GTI 12GB

**Describe the current behavior**
When importing from tf.contrib a warning is raised to do with the sunsetting of tf.contrib, as expected.
However unlike every other error in tensorflow, it is written to STDOUT instead of STDERR.
This causes critical problems for applications that require STDOUT to transfer data.

**Describe the expected behavior**
It is expected the warning is written to STDERR.

**Code to reproduce the issue**
```python3
import tensorflow as tf
print(tf.contrib.image.connected_components)
```

**Other info / logs**
The following warning is printed:                                                                                                                                                                         
```
WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.                                                                                                 
For more information, please see:                                                                                                                                              
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md                                                                                        
  * https://github.com/tensorflow/addons                                                                                                                                       
If you depend on functionality not listed there, please file an issue.                 
```"
29948,TF2.0beta distribute.MirroredStrategy hangs causing 100% GPU,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- I run the code provided in the tutorial https://www.tensorflow.org/beta/tutorials/distribute/keras

== check python ===================================================
python version: 3.6.7
python branch: 
python build version: ('default', 'Feb 28 2019 09:07:38')
python compiler version: GCC 7.3.0
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: #1 SMP Thu Nov 29 14:49:43 UTC 2018
os release version: 3.10.0-957.1.3.el7.x86_64
os platform: Linux-3.10.0-957.1.3.el7.x86_64-x86_64-with-centos-7.6.1810-Core
linux distribution: ('CentOS Linux', '7.6.1810', 'Core')
linux os distribution: ('centos', '7.6.1810', 'Core')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='monod33.mbb.ki.se', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64', processor='x86_64')
architecture: ('64bit', '')
machine: x86_64


== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy                    1.16.4              
protobuf                 3.8.0               
tensorflow-datasets      1.0.2               
tensorflow-gpu           2.0.0b1             
tensorflow-metadata      0.13.0              

== check for virtualenv =========================================
False


- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
No
- TensorFlow installed from (source or binary):
binary (pip)
- TensorFlow version (use command below):
- Python version:
2.0.0b1 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
cuda 10.0/cuDNN 7
- GPU model and memory:
4x Nvidia 1080Ti 11GB (MSI GeForce GTX) 

**Describe the current behavior**
- Training on one GPUs works fine
- All GPUs are recognized
- When I select multiple GPUs example: `strategy = tf.distribute.MirroredStrategy(devices=[""/device:GPU:0"",""/device:GPU:1""])` the processing hang and the GPUs are stuck at 100%

code output hangs at:
```
2019-06-19 09:03:44.971843: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-06-19 09:03:44.992837: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-19 09:03:46.143152: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
```
nvidia-smi output
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.93       Driver Version: 410.93       CUDA Version: 10.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:1A:00.0 Off |                  N/A |
| 29%   38C    P2    73W / 250W |  10883MiB / 11178MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:1B:00.0 Off |                  N/A |
| 29%   35C    P2    73W / 250W |  10883MiB / 11178MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 108...  Off  | 00000000:88:00.0 Off |                  N/A |
| 29%   28C    P8     8W / 250W |    157MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX 108...  Off  | 00000000:89:00.0 Off |                  N/A |
| 29%   26C    P8     8W / 250W |    157MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory ||  GPU       PID   Type   Process name                             Usage      |
|=============================================================================||    0    195955      C   ...processing/anaconda3/envs/tf/bin/python 10873MiB |
|    1    195955      C   ...processing/anaconda3/envs/tf/bin/python 10873MiB ||    2    195955      C   ...processing/anaconda3/envs/tf/bin/python   147MiB |
|    3    195955      C   ...processing/anaconda3/envs/tf/bin/python   147MiB |+-----------------------------------------------------------------------------+

**Describe the expected behavior**
Run the training in parallel

**Code to reproduce the issue**
Code provided in the tutorial: https://www.tensorflow.org/beta/tutorials/distribute/keras for TF2.0 Beta
**Other info / logs**
output when running the code
``` python
2019-06-19 09:03:37.964465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:1a:00.0
2019-06-19 09:03:37.967415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:1b:00.0
2019-06-19 09:03:37.970349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:88:00.0
2019-06-19 09:03:37.973263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:89:00.0
2019-06-19 09:03:37.973368: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-19 09:03:37.973414: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-19 09:03:37.973455: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-19 09:03:37.973538: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-19 09:03:37.973578: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-19 09:03:37.973618: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-19 09:03:37.973679: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-19 09:03:37.995237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-06-19 09:03:37.998940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:1a:00.0
2019-06-19 09:03:38.001616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:1b:00.0
2019-06-19 09:03:38.004343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:88:00.0
2019-06-19 09:03:38.007065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:89:00.0
2019-06-19 09:03:38.007148: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-19 09:03:38.007219: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-19 09:03:38.007257: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-19 09:03:38.007293: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-19 09:03:38.007356: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-19 09:03:38.007393: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-19 09:03:38.007448: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-19 09:03:38.027019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-06-19 09:03:38.027513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-19 09:03:38.027550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-06-19 09:03:38.027578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y Y Y 
2019-06-19 09:03:38.027603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N Y Y 
2019-06-19 09:03:38.027627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   Y Y N Y 
2019-06-19 09:03:38.027651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   Y Y Y N 
2019-06-19 09:03:38.041771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce G$X 1080 Ti, pci bus id: 0000:1a:00.0, compute capability: 6.1)
2019-06-19 09:03:38.044220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10470 MB memory) -> physical GPU (device: 1, name: GeForce G$X 1080 Ti, pci bus id: 0000:1b:00.0, compute capability: 6.1)
2019-06-19 09:03:38.046649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10470 MB memory) -> physical GPU (device: 2, name: GeForce G$X 1080 Ti, pci bus id: 0000:88:00.0, compute capability: 6.1)
2019-06-19 09:03:38.049078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10470 MB memory) -> physical GPU (device: 3, name: GeForce G$X 1080 Ti, pci bus id: 0000:89:00.0, compute capability: 6.1)
2019-06-19 09:03:38.287085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:1a:00.0
2019-06-19 09:03:38.288567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:1b:00.0
2019-06-19 09:03:38.290048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:88:00.0
2019-06-19 09:03:38.291505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:89:00.0
2019-06-19 09:03:38.291560: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-19 09:03:38.291573: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-19 09:03:38.291586: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-19 09:03:38.291599: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-19 09:03:38.291611: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-19 09:03:38.291623: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-19 09:03:38.291635: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-19 09:03:38.302880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-06-19 09:03:38.303091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-19 09:03:38.303106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-06-19 09:03:38.303116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y Y Y 
2019-06-19 09:03:38.303126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N Y Y 
2019-06-19 09:03:38.303134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   Y Y N Y 
2019-06-19 09:03:38.303143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   Y Y Y N 
2019-06-19 09:03:38.314925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:1a:
00.0, compute capability: 6.1)
2019-06-19 09:03:38.317831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:1 with 10470 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:1b:
00.0, compute capability: 6.1)
2019-06-19 09:03:38.320690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:2 with 10470 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:88:
00.0, compute capability: 6.1)
2019-06-19 09:03:38.323571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:3 with 10470 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:89:
00.0, compute capability: 6.1)
Train on None steps
Epoch 1/12
2019-06-19 09:03:44.971843: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CP
U, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_
FLAGS=--xla_hlo_profile.
2019-06-19 09:03:44.992837: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-19 09:03:46.143152: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
```

Thanks for the help!"
29947,For loop as 'unknown type' Tensorflow dimensions,"I want to use the shape (size) of a tf.where for the bound of a for-loop using Tensorflow in Pycharm. 
However, when I try to do this, 
I get the error: **'Tensor' object cannot be interpreted as an integer.**

How can I solve this problem?
**How can I get the size of idxCut to use a for-loop?**

**Development contents.**
1. Find the index (idxCut) corresponding to the threshold in the data.
2. Check whether data corresponding to idxCut is TPR.

I want to find the TPR (Turning Point Ratio) about idxCut in the data using a for-loop.
I used a for-loop to obtain the TPR between idx, idx-1 and idx + 1.
I want to find data[idx] is higher than the others data[idx-1, idx+1].

Here's my code:

> def funCalculate(data):
>     ### Cut-off Threshold
>     idxCut = tf.where(data > cutoff)
>     idxCut = tf.squeeze(idxCut)   # The size of idxCut is always variable.
> 
>     ### Compute by the size of idxCut
>     valueCut = []
>     for ii in range(0, tf.shape(idxCut)[0]):
>         v1 = tf.where(data[idxCut[ii]] > data[idxCut[ii] - 1], 1, 0)
>         v2 = tf.where(data[idxCut[ii]] > data[idxCut[ii] + 1], 1, 0)
>         v3 = tf.where(v1 + v2 > 1, 1, 0)
>         valueCut.append(v3)
>     return valueCut

"
29946,How to make remote worker load custom op?,"I write a custom op and compile it to .so file. When I use it in to train model locally, it works fine. But when I use it to run in standalone mode, worker server alway tells me OP not registered, because the worker server started before, it have not load my custom op.

So is there anyway I can do to tell remote worker to load lib dynamic like tf.load_op_library in local mode?"
29945,build for Windows always fail,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 (try cmake and bazel,not work)
- TensorFlow installed from (source or binary):
- TensorFlow version:2.0.0 or 1.14
- Python version:3.7.3
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):0.25
- GCC/Compiler version (if compiling from source):vs 2019
- CUDA/cuDNN version:no
- GPU model and memory:no use



build all fail,I followed the official documentation.However, it cannot be executed successfully.Some files cannot be downloaded or otherwise.
Please help me:
* Tell me how to build c api
* Give me the file for tensorflow.lib and tensorflow.dll.

thank you very much!"
29944,[TF 2.0] tf.keras.optimizers.Adam,"**System information**
- TensorFlow version: 2.0.0-dev20190618
- Python version: 3.6

**Describe the current behavior**
I am trying to minimize a function using tf.keras.optimizers.Adam.minimize() and I am getting a TypeError

**Describe the expected behavior**
First, in the TF 2.0 docs, it says the loss can be callable taking no arguments which returns the value to minimize. whereas the type error reads ""'tensorflow.python.framework.ops.EagerTensor' object is not callable"", which is not exactly the correct TypeError, it might be for some. 

But the main issue is, I know I can do the same optimization by using GradientTape but I don't understand why I should or why the minimize() is not working. A similar issue I found related to this is linked: (https://github.com/tensorflow/tensorflow/issues/28068) and a stack overflow solution for how you can solve a similar problem using gradient tape for reference: (https://stackoverflow.com/questions/55060736/tensorflow-2-api-regression-tensorflow-python-framework-ops-eagertensor-object).

**Code to reproduce the issue**

```
import tensorflow as tf
import numpy as np

N  = 1000                               # Number of samples
n  = 4                                  # Dimension of the optimization variable
np.random.seed(0) 
X = tf.Variable(np.random.randn(n, 1))  # Variables will be tuned by the optimizer
C = tf.constant(np.random.randn(N, n))  # Constants will not be tuned by the optimizer
D = tf.constant(np.random.randn(N, 1))

def f_batch_tensorflow(x, A, B):
    e = tf.matmul(A, x) - B
    return tf.reduce_sum(tf.square(e))

fx = f_batch_tensorflow(X, C, D)
print(fx)

adam_opt = tf.keras.optimizers.Adam()
optimizer = adam_opt.minimize(fx, X)
print(optimizer)
```

**Other info / logs**
Following is the error  I am getting:

```
TypeError                                 Traceback (most recent call last)
<ipython-input-20-225de189a3ff> in <module>()
      7 
      8 adam_opt = tf.keras.optimizers.Adam()
----> 9 optimizer = adam_opt.minimize(fx, X)
     10 print(optimizer)

1 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in _compute_gradients(self, loss, var_list, grad_loss)
    347       if not callable(var_list):
    348         tape.watch(var_list)
--> 349       loss_value = loss()
    350     if callable(var_list):
    351       var_list = var_list()

TypeError: 'tensorflow.python.framework.ops.EagerTensor' object is not callable
```
"
29943,Segmentation Fault for GetAttr function using tensorflow2.0 framework ,"get a Segmentation Fault for GetAttr function using tensorflow2.0 framework 

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux ubuntu 18.04
TensorFlow installed from (source or binary):binary
TensorFlow version (use command below):2.0b1
Python version:3.6
CUDA/cuDNN version:10/7.4
GPU model and memory:7.4/24gb"
29942,`tf.GradientTape.gradient` returns `None` when `sources` is a tensor (not a variable),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (see below)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04
- TensorFlow installed from (source or binary): pip (tf-nightly-gpu)
- TensorFlow version (use command below): v1.12.1-3447-g5a0f1bbfb7 1.14.1-dev20190606
- Python version: 3.6.8 (anaconda)
- CUDA/cuDNN version: 10/7
- GPU model and memory: GTX 1050-ti

**Describe the current behavior**
`tf.GradientTape.gradient` is inconsistent with its documentation and `tf.gradients` when computing gradients with respect to tensors. It returns `None` rather than the partial derivative.

**Describe the expected behavior**
Behave as per `tf.gradients`.

**Code to reproduce the issue**
```python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf

x0 = tf.get_variable('x0', shape=(), dtype=tf.float32)
x1 = tf.constant(3.)
x = x0 + x1
# x = tf.constant(3.0)
y = tf.constant(4.0)
with tf.GradientTape() as tape:
    z = x + y
    tape_grad = tape.gradient(z, x)
    print(tape_grad)  # None
tf_grad, = tf.gradients(z, x)

with tf.Session() as sess:
    print(sess.run(tf_grad))  # 1
```"
29937,Iterator restoring hangs with `inter_op_parallelism_threads=1`,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes; I have included a small example file below.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): `b'v1.13.1-0-g6612da8951' 1.13.1`
- Python version: 3.6.8
- CUDA/cuDNN version: 10.1.168/7.6.0.64 (installed via pacman)
- GPU model and memory: Quadro P2000

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
If I set `inter_op_parallelism_threads=1` when I configure a session, I am unable to restore an Iterator from a basic `tensorflow_datasets` dataset; the restore operation hangs.

**Describe the expected behavior**
If the iterator can run with `inter_op_parallelism_threads=1` then it should also be able to restore without issue.

**Code to reproduce the issue**
```
import tensorflow as tf
import numpy as np
import tensorflow_datasets as tfds
from sys import stderr

# save/restore an iterator from a toy dataset
mnist = tfds.image.MNIST()
mnist.download_and_prepare()
ds = mnist.as_dataset()[""train""]
ds = ds.map(lambda x: x[""image""])

# # Can't reproduce the issue using interleave/map/prefetch
# ds = tf.data.Dataset.range(10)  # using this dataset makes it not hang
# ds = ds.interleave(lambda x: tf.data.Dataset.from_tensors(x),
#         cycle_length=64, num_parallel_calls=tf.data.experimental.AUTOTUNE)
# ds = ds.map(lambda x: x, num_parallel_calls=tf.data.experimental.AUTOTUNE)
# ds = ds.prefetch(tf.data.experimental.AUTOTUNE)

i = ds.make_one_shot_iterator()

# create the operation
next_item = i.get_next()

# create the savable and the saver
saveable = tf.data.experimental.make_saveable_from_iterator(i)
saver = tf.train.Saver({'iterator':saveable})

# create a session config
config = tf.ConfigProto(
    inter_op_parallelism_threads=1, # this line makes saver.restore() hang.
                                    # Also, 2 works fine, only 1 is a problem
)

with tf.Session(config=config) as sess:
    # print the first five elements with a checksum
    print('first five', file=stderr)
    for _ in range(5):
        image = sess.run(next_item)
        print(np.sum(image*image), file=stderr)

    # save the iterator
    saver.save(sess, 'chkpt')

    # restore the iterator
    print('restoring', file=stderr)
    saver.restore(sess, 'chkpt')

    # (this line never prints:)
    print('done restoring', file=stderr)


    print('second five', file=stderr)
    for _ in range(5):
        # print the second five elements with a checksum
        image = sess.run(next_item)
        print(np.sum(image*image), file=stderr)
```

**Other info / logs**
Runtime output:
```
WARNING:tensorflow:From /home/rb/.virtualenvs/pedl/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING: Logging before flag parsing goes to stderr.
W0618 16:01:19.861267 140558393956032 deprecation.py:323] From /home/rb/.virtualenvs/pedl/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-06-18 16:01:19.945928: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-18 16:01:19.965483: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2905000000 Hz
2019-06-18 16:01:19.966181: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d1be28d870 executing computations on platform Host. Devices:
2019-06-18 16:01:19.966199: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
first five
13301
9638
11128
11245
11787
restoring
WARNING:tensorflow:From /home/rb/.virtualenvs/pedl/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W0618 16:01:20.062302 140558393956032 deprecation.py:323] From /home/rb/.virtualenvs/pedl/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
```
(now the process hangs indefinitely)
"
29936,Unresolved reference from tensorflow.python,"**System information**
- Have I written custom code:No
- OS Platform and Distribution:Ubuntu 18.04.2
- TensorFlow installed from:binary
- TensorFlow version:tf-nightly-gpu 1.14.1.dev20190617
- Python version:3.7
- CUDA/cuDNN version:10.0
- GPU model and memory:rtx 2070 8gb

**Describe the current behavior**
cannot import anything from tensorflow.python. 
**Describe the expected behavior**
In tensorflow version 1.13 it works
**Code to reproduce the issue**
from tensorflow.python import tf2 and i get Unresolved reference"
29932,Continue training with pre trained model,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Windows 10 x64
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):1.13.1
- Python version:3.6
- CUDA/cuDNN version:10/7.4
- GPU model and memory:Nvidia GeForce 840m / 4.00 Go

I cloned a CNN facial landmarks project from Github, this repo can be used to detect facial with 68 landmarks ( 68 for x coordinates and 68 for y coordinates). I have a pre-trained model "" frozen_inference_graph.pb""
I used this project to trained my own dataset to detect iris region in the human eye, so I prepared my dataset to be used for training by CNN.
My problem is that the iris annotated with 40 landmarks ( 40 for x coordinates and 40 for y coordinates) and the pre-trained model is trained with 68 landmarks ( number of logits 136 (68+68 )).

![redd](https://user-images.githubusercontent.com/19480228/59718798-3441a380-921b-11e9-91c2-a760102760cc.PNG)

I tried to train my model from scratch, but I didn't get good results:
![iriss](https://user-images.githubusercontent.com/19480228/59718868-5a674380-921b-11e9-8b3c-efb4766c875f.PNG)

I want to continue training with this pre-trained model but I get this error:
> InvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:
Assign requires shapes of both tensors to match. lhs shape= [1024,80] rhs shape= [1024,136]`

So it was very clear that my problem is in the number of points ( landmarks ) that are not compatibles ( 80 for iris landmarks and 136 for facial landmarks ) .
I need to know it can be possible to modify the frozen model .pb and what about the transfer learning? and how to use it?


"
29931,Dataset.map(tf.keras.applications.vgg16.preprocess_input) -> AttributeError: 'Tensor' object has no attribute '_datatype_enum',"### System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes. Small error-reproducing script provided below
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or binary): Binary (Python 3.6)
TensorFlow version (use command below): 2.0, nightly installed 6/18/19
Bazel version (if compiling from source):
CUDA/cuDNN version: CPU only
GPU model and memory:
Exact command to reproduce: python map_bug.py, script provided below

### Describe the problem

Just installed nightly to make sure this hadn't been caught yet--I am trying to do some map() operations on a dataset, nothing fancy. If I build only one dataset in a script, it works fine. If I do it twice, however--for instance, make a train and hold-out set using the same operations--I get this mysterious error message. Pretty sure this cannot be intended behavior.

### Source code / logs

Originally this was done in a large project. But I did a bit of work and whittled it down to the following script, which just uses MNIST to reproduce the error:

```
import tensorflow as tf
from tensorflow.keras import datasets
import numpy as np
BATCH_SIZE = 128


def size_image_for_vgg(image):
    return tf.image.resize(image, [224, 224])


if __name__ == '__main__':
    # punch up mnist
    (train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()
    train_images = train_images.reshape((60000, 28, 28, 1)).astype(np.float32) / 255.0
    test_images = test_images.reshape((10000, 28, 28, 1)).astype(np.float32) / 255.0

    # Now create a dataset
    im_ds = tf.data.Dataset.from_tensor_slices(train_images)
    label_ds = tf.data.Dataset.from_tensor_slices(train_labels)
    im_ds_t = tf.data.Dataset.from_tensor_slices(test_images)
    label_ds_t = tf.data.Dataset.from_tensor_slices(test_labels)

    # If this block is commented out, the block below it will NOT throw any error
    # do some normal Dataset operations on test and train data like we're getting ready to fit a model
    im_ds = im_ds.map(size_image_for_vgg, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    im_ds = im_ds.map(tf.keras.applications.vgg16.preprocess_input, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    train_ds = tf.data.Dataset.zip((im_ds, label_ds))
    train_ds = train_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=1000))
    train_ds = train_ds.batch(batch_size=BATCH_SIZE)

    im_ds_t = im_ds_t.map(size_image_for_vgg, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    # TODO throws error if you do it a second time?
    im_ds_t = im_ds_t.map(tf.keras.applications.vgg16.preprocess_input, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    test_ds = tf.data.Dataset.zip((im_ds_t, label_ds_t))
    test_ds = test_ds.batch(batch_size=BATCH_SIZE)
```

### Stack trace

Traceback (most recent call last):
File ""map_bug.py"", line 33, in
im_ds_t = im_ds_t.map(tf.keras.applications.vgg16.preprocess_input, num_parallel_calls=tf.data.experimental.AUTOTUNE)
File ""/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 1141, in map
self, map_func, num_parallel_calls, preserve_cardinality=True)
File ""/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3320, in init
**flat_structure(self))
File ""/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py"", line 4141, in parallel_map_dataset
preserve_cardinality=preserve_cardinality, name=name, ctx=_ctx)
File ""/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py"", line 4224, in parallel_map_dataset_eager_fallback
_attr_Targuments, other_arguments = _execute.convert_to_mixed_eager_tensors(other_arguments, _ctx)
File ""/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py"", line 210, in convert_to_mixed_eager_tensors
types = [t._datatype_enum() for t in v] # pylint: disable=protected-access
File ""/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py"", line 210, in
types = [t._datatype_enum() for t in v] # pylint: disable=protected-access
AttributeError: 'Tensor' object has no attribute '_datatype_enum'"
29929,How to connect two neural networks in tensorflow using graphs?,"Im stetting up a system capable of recognizing faces using python and tensorflow.

I want to recognize two things. ""Person"" for unknown people and ""Name of the person"" with known people (Previously train the tag in the model).

For that reason I need to implement 2 neural networks.

The first one is going to recognize faces among all the objects (example chair, desk, ..) and the second one is going to classify that frame with the face and check for the label taking in consideration all the known faces for the model. (previously trained)

so, in order to solved something like this I knows that I need two neural networks and the output of the first one is going to be the input of the second. But I just dont known how can I connect this two neural networks using the graph files. (Created in the training process)

Right now I can train my model, get the graph file and use that in the recognition process. But I cant mixed the two neural networks or how to add the output of the first model into the input of the second model

```
with detection_graph.as_default():
    with tf.Session(graph=detection_graph) as sess:
        while True:
            # Read frame from camera
            ret, image_np = cap.read()
            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
            image_np_expanded = np.expand_dims(image_np, axis=0)
            # Extract image tensor
            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')
            # Extract detection boxes
            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')
            # Extract detection scores
            scores = detection_graph.get_tensor_by_name('detection_scores:0')
            # Extract detection classes
            classes = detection_graph.get_tensor_by_name('detection_classes:0')
            # Extract number of detectionsd
            num_detections = detection_graph.get_tensor_by_name(
                'num_detections:0')
            # Actual detection.
            (boxes, scores, classes, num_detections) = sess.run(
                [boxes, scores, classes, num_detections],
                feed_dict={image_tensor: image_np_expanded})
            # Visualization of the results of a detection.
            vis_util.visualize_boxes_and_labels_on_image_array(
                image_np,
                np.squeeze(boxes),
                np.squeeze(classes).astype(np.int32),
                np.squeeze(scores),
                category_index,
                use_normalized_coordinates=True,
                line_thickness=8)

            # Display output
            cv2.imshow('object detection', cv2.resize(image_np, (800, 600)))

            if cv2.waitKey(25) & 0xFF == ord('q'):
                cv2.destroyAllWindows()
                break
```
detection_graph is the model (reference to the graph file in memory)

The previous code works fine running one model (graph file) But I want to integrate a second neural network. (add the output of the first in the input of the second one). Any idea how can I do something like this? I dont see anything like this in the documentation

"
29927,link tensorflow1.13.1 static library failed  (gcc 4.9.3),"In file included from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/eigen/unsupported/Eigen/CXX11/Tensor:120:0,
                 from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/tensorflow/core/framework/tensor.h:21,
                 from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/tensorflow/core/public/session.h:24,
                 from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/src/L2/Algorithm_ctrinterest/nn_raw.h:17,
                 from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/src/L2/Algorithm_ctrinterest/nnso_raw.h:9,
                 from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/src/L2/Algorithm_ctrinterest/model.cpp:2:
/home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorBlock.h: In static member function â€˜static void Eigen::internal::TensorBlockIO<Scalar, StorageIndex, NumDims, Layout, BlockRead>::Copy(const Block&, StorageIndex, const Dimensions&, const Dimensions&, const Scalar*, Scalar*)â€™:
/home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorBlock.h:393:63: error: the value of â€˜jâ€™ is not usable in a constant expression
         if (++block_iter_state[j].count < block_iter_state[j].size) {
                                                               ^
/home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorBlock.h:392:16: note: â€˜int jâ€™ is not const
       for (int j = 0; j < num_squeezed_dims; ++j) {
                ^
/home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorBlock.h:393:35: error: parse error in template argument list
         if (++block_iter_state[j].count < block_iter_state[j].size) {
                                   ^
/home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorBlock.h: In static member function â€˜static void Eigen::internal::TensorBlockCwiseUnaryIO<UnaryFunctor, StorageIndex, OutputScalar, NumDims, Layout>::Run(const UnaryFunctor&, const Dimensions&, const Dimensions&, OutputScalar*, Eigen::array<StorageIndex, NumDims>&, const InputScalar*)â€™:
/home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorBlock.h:604:21: error: parse error in template argument list
         if (++state.count < state.size) {
                     ^
/home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorBlock.h: In static member function â€˜static void Eigen::internal::TensorBlockCwiseBinaryIO<BinaryFunctor, StorageIndex, OutputScalar, NumDims, Layout>::Run(const BinaryFunctor&, const Dimensions&, const Dimensions&, OutputScalar*, Eigen::array<StorageIndex, NumDims>&, const LeftScalar*, Eigen::array<StorageIndex, NumDims>&, const RightScalar*)â€™:
/home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorBlock.h:758:21: error: parse error in template argument list
         if (++state.count < state.size) {
                     ^
In file included from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/eigen/unsupported/Eigen/CXX11/Tensor:143:0,
                 from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/tensorflow/core/framework/tensor.h:21,
                 from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/tensorflow/core/public/session.h:24,
                 from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/src/L2/Algorithm_ctrinterest/nn_raw.h:17,
                 from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/src/L2/Algorithm_ctrinterest/nnso_raw.h:9,
                 from /home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/src/L2/Algorithm_ctrinterest/model.cpp:2:
/home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h: In member function â€˜void Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::block(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::OutputTensorBlock*) constâ€™:
/home/cuijg/Documents/computer_so/xuhuanwen/so_cmake/src/publiclib-lite/third_party/tensorflow_1.13.1/static_lib/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:319:35: error: parse error in template argument list
         if (++block_iter_state[i].count < block_iter_state[i].size) {
                                   ^
CMakeFiles/so_cmake.dir/build.make:153: recipe for target 'CMakeFiles/so_cmake.dir/src/src/L2/Algorithm_ctrinterest/model.cpp.o' failed
make[3]: *** [CMakeFiles/so_cmake.dir/src/src/L2/Algorithm_ctrinterest/model.cpp.o] Error 1
CMakeFiles/Makefile2:72: recipe for target 'CMakeFiles/so_cmake.dir/all' failed
make[2]: *** [CMakeFiles/so_cmake.dir/all] Error 2
CMakeFiles/Makefile2:84: recipe for target 'CMakeFiles/so_cmake.dir/rule' failed
make[1]: *** [CMakeFiles/so_cmake.dir/rule] Error 2
Makefile:118: recipe for target 'so_cmake' failed
make: *** [so_cmake] Error 2"
29926,How can I get the instance-wise gradient?,"
**System information**
- TensorFlow version (you are using): Tensorflow 1.1.13



**Describe the feature and the current behavior/state.**

Hi, Does anyone know whether tensorflow could provide instance-wise gradient? To be more precise, I mean say the loss is not a scalar, just the size of (N, 1). This is cross entropy loss before one use `tf.reduce_mean`. I wonder how could I get the gradient for each instance in each batch. This means eventually, the shape of the gradient is supposed to be (N, num_of_thetas). I think the currently `tf.gradient` can not do this, right?


"
29923,Code Using FeatureColumn W/ Keras Functional API works for 2.0.0-alpha0 But is broken for 2.0.0-beta1,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Y
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary):Source
- TensorFlow version (use command below):2.0.0-beta1
- Python version:3.5
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
This is related to the closed issue https://github.com/tensorflow/tensorflow/issues/27416.
The code snippet below feeds feature columns to Keras models built from functional API. The code works fine for Tensorflow 2.0.0-alpha0 but brakes for Tensorflow 2.0.0-beta1 with the following error message:

49 validation examples
61 test examples
Traceback (most recent call last):
File ""/tmp/zeppelin_pyspark-5282677307998123760.py"", line 326, in 
exec(code)
File """", line 44, in 
File ""/usr/lib/envs/env-1923-ver-2635-a-4.2.9-py-3.5.3/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 662, in call
outputs = call_fn(inputs, *args, **kwargs)
File ""/usr/lib/envs/env-1923-ver-2635-a-4.2.9-py-3.5.3/lib/python3.5/site-packages/tensorflow/python/autograph/impl/api.py"", line 166, in wrapper
), args, kwargs)
File ""/usr/lib/envs/env-1923-ver-2635-a-4.2.9-py-3.5.3/lib/python3.5/site-packages/tensorflow/python/autograph/impl/api.py"", line 340, in converted_call
if inspect_utils.isbuiltin(f):
File ""/usr/lib/envs/env-1923-ver-2635-a-4.2.9-py-3.5.3/lib/python3.5/site-packages/tensorflow/python/autograph/pyct/inspect_utils.py"", line 84, in isbuiltin
if f in six.moves.builtins.dict.values():
File ""/usr/lib/envs/env-1923-ver-2635-a-4.2.9-py-3.5.3/lib/python3.5/site-packages/pandas/core/generic.py"", line 1478, in nonzero
.format(self.class.name))
ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
File ""/tmp/zeppelin_pyspark-5282677307998123760.py"", line 333, in 
raise Exception(traceback.format_exc())
Exception: Traceback (most recent call last):
File ""/tmp/zeppelin_pyspark-5282677307998123760.py"", line 326, in 
exec(code)
File """", line 44, in 
File ""/usr/lib/envs/env-1923-ver-2635-a-4.2.9-py-3.5.3/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 662, in call
outputs = call_fn(inputs, *args, **kwargs)
File ""/usr/lib/envs/env-1923-ver-2635-a-4.2.9-py-3.5.3/lib/python3.5/site-packages/tensorflow/python/autograph/impl/api.py"", line 166, in wrapper
), args, kwargs)
File ""/usr/lib/envs/env-1923-ver-2635-a-4.2.9-py-3.5.3/lib/python3.5/site-packages/tensorflow/python/autograph/impl/api.py"", line 340, in converted_call
if inspect_utils.isbuiltin(f):
File ""/usr/lib/envs/env-1923-ver-2635-a-4.2.9-py-3.5.3/lib/python3.5/site-packages/tensorflow/python/autograph/pyct/inspect_utils.py"", line 84, in isbuiltin
if f in six.moves.builtins.dict.values():
File ""/usr/lib/envs/env-1923-ver-2635-a-4.2.9-py-3.5.3/lib/python3.5/site-packages/pandas/core/generic.py"", line 1478, in nonzero
.format(self.class.name))
ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().



**Describe the expected behavior**
The code snippet is expected to work.

Or please help point out what needs to be changed to make it work.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
from __future__ import absolute_import, division, print_function

import numpy as np
import pandas as pd

#!pip install tensorflow==2.0.0-alpha0
import tensorflow as tf

from tensorflow import feature_column
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split

URL = 'https://storage.googleapis.com/applied-dl/heart.csv'
dataframe = pd.read_csv(URL)
dataframe.head()

train, test = train_test_split(dataframe, test_size=0.2)
train, val = train_test_split(train, test_size=0.2)
print(len(train), 'train examples')
print(len(val), 'validation examples')
print(len(test), 'test examples')

# A utility method to create a tf.data dataset from a Pandas Dataframe
def df_to_dataset(dataframe, shuffle=True, batch_size=32):
  dataframe = dataframe.copy()
  labels = dataframe.pop('target')
  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))
  ds = ds.batch(batch_size)
  return ds

batch_size = 5 # A small batch sized is used for demonstration purposes
train_ds = df_to_dataset(train, batch_size=batch_size)
val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)
test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)

age = feature_column.numeric_column(""age"")

feature_columns = []
feature_layer_inputs = {}

# numeric cols
for header in ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca']:
  feature_columns.append(feature_column.numeric_column(header))
  feature_layer_inputs[header] = tf.keras.Input(shape=(1,), name=header)

# bucketized cols
age_buckets = feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])
feature_columns.append(age_buckets)

# indicator cols
thal = feature_column.categorical_column_with_vocabulary_list(
      'thal', ['fixed', 'normal', 'reversible'])
thal_one_hot = feature_column.indicator_column(thal)
feature_columns.append(thal_one_hot)
feature_layer_inputs['thal'] = tf.keras.Input(shape=(1,), name='thal', dtype=tf.string)

# embedding cols
thal_embedding = feature_column.embedding_column(thal, dimension=8)
feature_columns.append(thal_embedding)

# crossed cols
crossed_feature = feature_column.crossed_column([age_buckets, thal], hash_bucket_size=1000)
crossed_feature = feature_column.indicator_column(crossed_feature)
feature_columns.append(crossed_feature)

batch_size = 32
train_ds = df_to_dataset(train, batch_size=batch_size)
val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)
test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)

feature_layer = tf.keras.layers.DenseFeatures(feature_columns)
feature_layer_outputs = feature_layer(feature_layer_inputs)

x = layers.Dense(128, activation='relu')(feature_layer_outputs)
x = layers.Dense(64, activation='relu')(x)

baggage_pred = layers.Dense(1, activation='sigmoid')(x)

model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=baggage_pred)

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.fit(train_ds)
```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29922,Defun and function input_signatures don't accept variables as input,"Defun and function input_signatures don't accept variables as input. To bypass this, we have to explicitly convert tf.Variables to tf.Tensors
**System information**
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below): 1.13.1

**Code to reproduce the issue**
```
import tensorflow as tf

tf.enable_eager_execution()

@tf.contrib.eager.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])
def identity(x):
  return x

a = tf.Variable(())
print(identity(a.read_value()))
print(identity(a))
```

This fails on the second call:
```
ValueError: When input_signature is provided, all inputs to the Python function must be Tensors.
```"
29921,Tf.app.flags implicit parsing potentially causes crash with exception,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution:
Linux Fedora 30
- TensorFlow installed from:
binary
- TensorFlow version:
1.13.1
- Python version:
3.7.3
- CUDA version
10.0
- GPU Model
NVIDIA TITAN V Black

**Describe the current behavior**

The -h, -help, -helpshort, and -helpfull arguments may cause exceptions to be triggered as opposed to displaying flags, default values, and programmer-provided information. This seems to occur when the `tf.app.flags` abseil wrapper attempts to use implicit parsing.

**Describe the expected behavior**

When any value of -h, -help, -helpshort, -helpfull are provided as arguments to scripts using `tf.app.flags`, the help list should appear.

**Code to reproduce the issue**
```python
''' mwe.py: displays tensorflow --help argument issue '''
from tensorflow import app
app.flags.DEFINE_string('myflag', 'Default', 'Help output')
FLAGS = app.flags.FLAGS
global_string = ""This string causes the abseil wrapper to begin processing the {0} flag"".format(FLAGS.myflag)
def main(_):
  print(""This string causes TF to race the abseil parsing process, which kills the help menu using string %s"" % FLAGS.myflag)
if __name__ == '__main__':
  app.run(main)
```

**Other info / logs**
The below bash script uses the above code to display the issue. Notably, using abseil's app.flags will NOT cause the exception to occur with the same source code.
```bash
python mwe.py --help
sed -i 's/global_string/#global_string/g' mwe.py
python mwe.py --help
```

This is related to issue #28581. After elaborating on the issue and not receiving a response, I have opened this new issue. If further information is required, please let me know how I may assist you."
29919,TF=GPU 2.0.0b TF Transform missing AUTOTUNE on import,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): POSIX
- TensorFlow version: 2.0.0b-gpu
- Python version: 3.6.7
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: 
- GPU model and memory: Tesla T4



**Describe the problem**
Attempted to use TFX, specifically TF Transform, however when importing TF Transform it throws the error that AUTOTUNE is unknown.

`!pip install tensorflow_transform`
`import tensorflow_transform as tft`

**Any other info / logs**
AttributeError: module 'tensorflow.python.data.experimental.ops.optimization' has no attribute 'AUTOTUNE'
For the full log see the attached file

[TF_Transform_Import_Error.txt](https://github.com/tensorflow/tensorflow/files/3302615/TF_Transform_Import_Error.txt)
"
29918,22794,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
29917,[TensorFlow 2.0] Taking a slice of a Keras Input layer gives a tensor with unknown shape,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Mac OS X 10.14.5**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1**
- Python version: **3.6.8**
- CUDA/cuDNN version: **don't have a GPU**
- GPU model and memory: **don't have a GPU**

**Describe the current behavior**

If I create an input layer with Keras and take a slice of it, the slice has unknown shape:

```python
>>> inputs = tf.keras.Input((10, 10))
>>> inputs.shape
TensorShape([None, 10, 10])
>>> slice = inputs[:,:,:5]
>>> slice.shape
TensorShape(None)
```

This is a problem when I want to use this slice in something else, e.g. here with a softmax:

```python
>>> tf.keras.activations.softmax(slice)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""[path_to_my_env]/lib/python3.6/site-packages/tensorflow/python/keras/activations.py"", line 66, in softmax
    elif ndim > 2:
TypeError: '>' not supported between instances of 'NoneType' and 'int'
```

**Describe the expected behavior**

I'd expect `slice` to have shape `TensorShape([None, 10, 5])`.

**Code to reproduce the issue**

```python
import tensorflow as tf

inputs = tf.keras.Input((10, 10))
assert inputs.shape.as_list() == [None, 10, 10]  # This works
assert inputs[:,:,:5].shape.as_list() == [None, 10, 5]  # Raises ValueError
```"
29916,Second order gradient of tf.contrib.eager.function is broken,"When using 2nd order gradients (i.e. Nested GradientTape) we cannot utilize @tf.defun and @tf.function.

**System information**
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below): 1.13.1

```
Traceback (most recent call last):
  File ""test_defun.py"", line 14, in <module>
    print(meta_tape.gradient(a2, a))
  File ""/home/felipe.such/uber/generative_learning/env/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py"", line 946, in gradient
    unconnected_gradients=unconnected_gradients)
  File ""/home/felipe.such/uber/generative_learning/env/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py"", line 72, in imperative_grad
    compat.as_str(unconnected_gradients.value))
  File ""/home/felipe.such/uber/generative_learning/env/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py"", line 127, in _gradient_function
    grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access
  File ""/home/felipe.such/uber/generative_learning/env/lib/python3.6/site-packages/tensorflow/python/framework/registry.py"", line 94, in lookup
    ""%s registry has no entry for: %s"" % (self._name, name))
LookupError: gradient registry has no entry for: StatefulPartitionedCall
```


**Code to reproduce the issue**

```
import tensorflow as tf

tf.enable_eager_execution()

@tf.contrib.eager.function
def leaky_relu(x, alpha=0.1):
  return tf.maximum(tf.minimum(0.0, alpha * x), x)

a = tf.Variable(())
with tf.GradientTape() as meta_tape:
  with tf.GradientTape() as tape:
    x = leaky_relu(a)
  a2 = tape.gradient(x, a) + a
print(meta_tape.gradient(a2, a))
```"
29914, No OpKernel was registered to support Op 'TensorArrayWriteV3',"I'm trying to perform the inference on a pre-trained model that I imported into the assets folder.

When I make inference I get the following error:

`java.lang.IllegalArgumentException: No OpKernel was registered to support Op TensorArrayWriteV3' used by {{node map_4/while/TensorArrayWrite/TensorArrayWriteV3}}with these attrs: [T=DT_UINT8, _class=[""loc:@map_4/while/convert_image""]]
`
"
29913,ModuleNotFoundError: No module named '_pywrap_tensorflow',"Hello all,

I am trying to import tensorflow but it shows the following error. 

`ModuleNotFoundError: No module named '_pywrap_tensorflow'`

I have already tried to add the MSVC140.DLL file from [ttps://www.dll-files.com/msvcp140.dll.html]( https://www.dll-files.com/msvcp140.dll.html)  it still shows the stated error. 

OS: Windows 10
Python version: 3.6.4
Conda version: 4.6.14
PIP version: 19.1.1
GPU: AMD Radeon R540x
Command used to install tensorflow: `conda install tensorflow `  ; `pip install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.12.0-py3-none-any.whl` which I got from this link [https://stackoverflow.com/questions/38896424/tensorflow-not-found-using-pip](https://stackoverflow.com/questions/38896424/tensorflow-not-found-using-pip)

I don't use CUDA services and am using only CPU support.

```
(base) (picktolight) F:\Internship\Nokia_work>python
Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""F:\Internship\Nokia_work\picktolight\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""F:\Internship\Nokia_work\picktolight\lib\imp.py"", line 297, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""F:\Internship\Nokia_work\picktolight\lib\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""F:\Internship\Nokia_work\picktolight\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""F:\Internship\Nokia_work\picktolight\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ModuleNotFoundError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""F:\Internship\Nokia_work\picktolight\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""F:\Internship\Nokia_work\picktolight\lib\site-packages\tensorflow\python\__init__.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""F:\Internship\Nokia_work\picktolight\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""F:\Internship\Nokia_work\picktolight\lib\imp.py"", line 297, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""F:\Internship\Nokia_work\picktolight\lib\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""F:\Internship\Nokia_work\picktolight\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""F:\Internship\Nokia_work\picktolight\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ModuleNotFoundError: No module named '_pywrap_tensorflow'


Failed to load the native TensorFlow runtime.
```
Also, I am getting the error using cmd. 
![image](https://user-images.githubusercontent.com/31880143/59679060-836fe000-91eb-11e9-9b24-d962049753f1.png)

**Any help will be greatly appreciated.** 
 **Thanks a lot!**
"
29911,Input_signature of a tf.function decorator crashes when using multiple GPUs with MirroredStrategy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux 7.6.1810
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: /
- TensorFlow installed from (source or binary): pip binary
- TensorFlow version (use command below): tensorflow-gpu 2.0.0-beta0
- Python version: 3.6.8
- Bazel version (if compiling from source): /
- GCC/Compiler version (if compiling from source): / 
- CUDA/cuDNN version: 10.0.130 / 7.6.0
- GPU model and memory: Tesla P100-SXM2-16GB

**Describe the current behavior**
Tensorflow crashes when checking the input_signature of a tf.function decorator when using multiple GPUs in a MirroredStrategy. A ValueError is generated cause a PerReplica object cannot be converted to a Tensor (see the log below). Below you can find the minimum code needed to reproduce the error. The code runs just fine when I only utilize one GPU `strategy = tf.distribute.MirroredStrategy(devices=[""/gpu:0""])`. Furthermore, if the optional argument input_signature is discarded (only using `@tf.function()`) the error disappears too (again using multiple GPUs). Hence, the specific combination of input_signature and multiple GPUs causes the problem (which I need for performance reasons in my work).

**Describe the expected behavior**
The code below won't generate any errors.

**Code to reproduce the issue**
```
import tensorflow as tf
import numpy as np
        
strategy = tf.distribute.MirroredStrategy(devices=[""/gpu:0"", ""/gpu:1""])
    
with strategy.scope():
    dataset = tf.data.Dataset.from_tensor_slices(np.ones([100, 12]).astype(np.float32))
    dataset = dataset.batch(4)
    dataset = strategy.experimental_distribute_dataset(dataset)
    
    def compute(input_data):
        return tf.reduce_sum(input_data, [1])
    
    @tf.function(input_signature = (tf.TensorSpec([None, 12], tf.float32),))
    def distributed_run(input_data):
        return strategy.experimental_run_v2(compute, args = (input_data,))

    for x in dataset:
        output = distributed_run(x)
        print(output)
```

**Other info / logs**

> Traceback (most recent call last):
>   File ""/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1216, in _convert_inputs_to_signature
>     value, dtype_hint=spec.dtype)
>   File ""/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1100, in convert_to_tensor
>     return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
>   File ""/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1158, in convert_to_tensor_v2
>     as_ref=False)
>   File ""/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1237, in internal_convert_to_tensor
>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
>   File ""/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 305, in _constant_tensor_conversion_function
>     return constant(v, dtype=dtype, name=name)
>   File ""/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 246, in constant
>     allow_broadcast=True)
>   File ""/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 254, in _constant_impl
>     t = convert_to_eager_tensor(value, ctx, dtype)
>   File ""/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 115, in convert_to_eager_tensor
>     return ops.EagerTensor(value, handle, device, dtype)
> ValueError: Attempt to convert a value (PerReplica:{
>   0 /job:localhost/replica:0/task:0/device:GPU:0: <tf.Tensor: id=107, shape=(2, 12), dtype=float32, numpy=
> array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
>        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>,
>   1 /job:localhost/replica:0/task:0/device:GPU:1: <tf.Tensor: id=108, shape=(2, 12), dtype=float32, numpy=
> array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
>        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>
> }) with an unsupported type (<class 'tensorflow.python.distribute.values.PerReplica'>) to a Tensor.
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""issue2.py"", line 19, in <module>
>     output = distributed_run(x)
>   File ""/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 432, in __call__
>     *args, **kwds)
>   File ""/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1169, in canonicalize_function_inputs
>     self._flat_input_signature)
>   File ""/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1222, in _convert_inputs_to_signature
>     (str(inputs), str(input_signature)))
> ValueError: When input_signature is provided, all inputs to the Python function must be convertible to tensors.Inputs ((PerReplica:{
>   0 /job:localhost/replica:0/task:0/device:GPU:0: <tf.Tensor: id=107, shape=(2, 12), dtype=float32, numpy=
> array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
>        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>,
>   1 /job:localhost/replica:0/task:0/device:GPU:1: <tf.Tensor: id=108, shape=(2, 12), dtype=float32, numpy=
> array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
>        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>
> },)), input_signature((TensorSpec(shape=(None, 12), dtype=tf.float32, name=None),))."
29910,Android performance: CPU affinity,"**System information**
- Mobile device: **Xiaomi A2 (8 core)**
- TensorFlow installed from (source or binary): **source**
- TensorFlow version (use command below): **master** at [6cf83ea] (2019/06/17)

**Describe the current behavior**

The `benchmark_model` that we run on the device performs very differently when we choose CPU affinity. E.g. average inference time (32 bit, CPU only) for our custom .tflite model is 172ms for taskset=ff, 143ms for taskset=f0, and 281ms taskset=0f. We used num_threads=8, i.e. much more threads that we have cores available. When we increase num_threads=12, inference time further decreases. The change of min times is even more impressive: 125ms for ff, 114ms for f0, and 211ms for 0f. And 105ms for f0 with 12 threads, i.e. 3 threads per CPU. Further increasing num_threads does not deliver visible improvements.

Note that we have no control on the actual number of threads used by interpreter->Invoke(), and their CPU affinity. 

**Describe the expected behavior**

I would expect the _interpreter_ to choose the optimal threading model. The [document](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark#reducing-variance-between-runs-on-android) reads:

> Reducing variance between runs on Android.
> When running benchmarks on these phones there can be significant variance between different runs of the benchmark.

While benchmarks are nice, our real necessity is to run TFLite optimally in our app. But we cannot control thread CPU affinity or the _interpreter_?

But even if we could setup the _interpreter_ threading configuration beyond the generic _""Set the number of threads available to the interpreter""_,  across multiple devices, choosing the optimal taskset is beyond the capabilities of most development teams. This cannot be done by analyzing the cpuinfo: on our A2 development phone, all 8 cores are declared [almost](https://github.com/tensorflow/tensorflow/issues/29910#issuecomment-503589179) equal:

```
Processor       : AArch64 Processor rev 4 (aarch64)
processor       : 0
BogoMIPS        : 38.40
Features        : fp asimd evtstrm aes pmull sha1 sha2 crc32
CPU implementer : 0x51
CPU architecture: 8
CPU variant     : 0xa
CPU part        : 0x801
CPU revision    : 4

processor       : 1
BogoMIPS        : 38.40
Features        : fp asimd evtstrm aes pmull sha1 sha2 crc32
CPU implementer : 0x51
CPU architecture: 8
CPU variant     : 0xa
CPU part        : 0x801
CPU revision    : 4

processor       : 2
BogoMIPS        : 38.40
Features        : fp asimd evtstrm aes pmull sha1 sha2 crc32
CPU implementer : 0x51
CPU architecture: 8
CPU variant     : 0xa
CPU part        : 0x801
CPU revision    : 4

processor       : 3
BogoMIPS        : 38.40
Features        : fp asimd evtstrm aes pmull sha1 sha2 crc32
CPU implementer : 0x51
CPU architecture: 8
CPU variant     : 0xa
CPU part        : 0x801
CPU revision    : 4

processor       : 4
BogoMIPS        : 38.40
Features        : fp asimd evtstrm aes pmull sha1 sha2 crc32
CPU implementer : 0x51
CPU architecture: 8
CPU variant     : 0xa
CPU part        : 0x800
CPU revision    : 2

processor       : 5
BogoMIPS        : 38.40
Features        : fp asimd evtstrm aes pmull sha1 sha2 crc32
CPU implementer : 0x51
CPU architecture: 8
CPU variant     : 0xa
CPU part        : 0x800
CPU revision    : 2

processor       : 6
BogoMIPS        : 38.40
Features        : fp asimd evtstrm aes pmull sha1 sha2 crc32
CPU implementer : 0x51
CPU architecture: 8
CPU variant     : 0xa
CPU part        : 0x800
CPU revision    : 2

processor       : 7
BogoMIPS        : 38.40
Features        : fp asimd evtstrm aes pmull sha1 sha2 crc32
CPU implementer : 0x51
CPU architecture: 8
CPU variant     : 0xa
CPU part        : 0x800
CPU revision    : 2

Hardware        : Qualcomm Technologies, Inc SDM660

```
Maybe I am missing something, but I see here no clue that the performance of **f0** will be so much different from **0f**.

The dynamic optimization should be performed once in a while, because the load on the device may change, either in the same process, or because of other processes/apps running along our app.

It could be useful to persist these findings, so that next time interpreter starts, it could have a reasonable starting point. I am not sure if this info is relevant for specific .tflite model, or for any model. In our experiments, the we only used similar FCNN networks, and their performance was effected by taskset just the same."
29909,tf.meshgrid high variance in computational time,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: --
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.10
- Python version: 3.5
- Bazel version (if compiling from source): ----
- GCC/Compiler version (if compiling from source): ----
- CUDA/cuDNN version: CUDA 9.0, Cudnn, 7.1
- GPU model and memory: GTX 1080 ti, 10GB

**Describe the current behavior**
Running ``tf.meshgrid(tf.range(A), tf.range(B), tf.range(C), tf.range(D), indexing='ij')`` with the same amount of resulting elements can have high variations, for example sometimes 1 second, sometimes up to 8 seconds).

**Describe the expected behavior**
I expect this operation to be quicker, as (AFAIK) it is needed for any complex operations involving tf.scatter_nd and other element gathering ops.

**Code to reproduce the issue**
Run this code, ``a_s`` and ``b_s`` are set to always multiply to 1000. I see performance going from 0.9 seconds up to 45 seconds on this test, even for the same values.
```
import numpy as np
import tensorflow as tf
import time

A = tf.placeholder(dtype=tf.int32)
B = tf.placeholder(dtype=tf.int32)
C = 20
D = 5000

with tf.device('/gpu:0'):
  ii, bb, kk, _ = tf.meshgrid(tf.range(A), tf.range(B), tf.range(C), tf.range(D), indexing='ij')

sess = tf.Session()
with sess.as_default():

    times = []

    print(""Starting Testing"")

    for d in range(100):
      time_start = time.time()
      a_s = np.random.randint(20, 60)
      b_s = 1000 // a_s
      _, _, _ = sess.run(fetches=[ii, bb, kk], feed_dict={A: a_s,
                                                          B: b_s})
      times.append(time.time() - time_start)
      print(str(times[-1]) + "" "" + str(a_s) + "" "" + str(b_s))

    print(""--- Finished ---"")
    print(""Max time: "" + str(max(times)))
    print(""Min time: "" + str(min(times)))
    print(""Avg time: "" + str(sum(times)/len(times)))
```

**Other info / logs**
Here's an example log extract from the program above (the first value is the time, the second and third the values of A and B respectively):
```
Starting Testing
1.203284502029419 40 25
1.083801031112671 51 19
1.024698257446289 51 19
1.0535898208618164 42 23
1.0363869667053223 56 17
1.1064929962158203 30 33
1.0818214416503906 59 16
1.1742267608642578 43 23
1.172206163406372 31 32
1.2406136989593506 32 31
1.1510748863220215 38 26
1.073162317276001 22 45
1.0849990844726562 55 18
1.0694386959075928 33 30
1.0990991592407227 20 50
1.2687609195709229 24 41
1.1231935024261475 50 20
2.591834783554077 49 20
1.5073127746582031 35 28
1.062272548675537 26 38
2.6493754386901855 27 37
1.137765645980835 30 33
1.0350470542907715 59 16
1.0511572360992432 25 40
1.0805590152740479 55 18
1.0525894165039062 42 23
2.4179093837738037 53 18
1.0785531997680664 42 23
1.0189356803894043 45 22
7.864070892333984 57 17
```


I'm using this in a large system based on the Transformer, where this is used together with tf.scatter_nd. I've attached the corresponding timeline, the meshgrid op is called ``output/rec/output_prob/meshgrid``
[timeline.trace.tar.gz](https://github.com/tensorflow/tensorflow/files/3300969/timeline.trace.tar.gz)

"
29908,Cannot authenticate in CoLab with tensorfow 2.0.0-beta1,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CoLab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-beta1
- Python version: 3.6.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
google.colab.auth.authenticate_user() will fail with tensorflow 2.0.0-beta1

**Describe the expected behavior**

**Code to reproduce the issue**
!pip install -q tensorflow==2.0.0-beta1
from google.colab import auth
auth.authenticate_user()

**Other info / logs**

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-4-e9280defa4ea> in <module>()
     25 
     26 from google.colab import auth
---> 27 auth.authenticate_user()
     28 
     29 prepared_record_paths = tf.io.gfile.glob(training_data)

/usr/local/lib/python3.6/dist-packages/google/colab/auth.py in authenticate_user(clear_output)
    154       with tf.compat.v1.Session('grpc://{}'.format(colab_tpu_addr)) as sess:
    155         with open(_get_adc_path()) as auth_info:
--> 156           tf.contrib.cloud.configure_gcs(
    157               sess, credentials=_json.load(auth_info))
    158   if _check_adc():

AttributeError: module 'tensorflow' has no attribute 'contrib'"
29907,"""Node 'Const' is not unique"" Using C++ api on windows to freeze graph","I use *FreezeSavedModel* fucntion in source code https://github.com/tensorflow/tensorflow/blob/v1.12.0/tensorflow/cc/tools/freeze_saved_model.cc to freeze graph, and use tensorflow::WriteBinaryProto to export pb file. it report an error: ""Node 'Const' is not unique"". Then I check code in *FreezeSavedModel* fucntion, I find out in function *ConvertVariableToConstant*(https://github.com/tensorflow/tensorflow/blob/v1.12.0/tensorflow/cc/tools/freeze_saved_model.cc#L149),   after running 
```
 const_node->set_op(""Const"");
```
the op and name and device of const_node all are set to ""Const"". And I check the address of member op_, name_, device_ of const_node, they are all the same.

Similarly, if you run`const_node->set_name(variable_node.name());` , the op and name and device of const_node all are set to name of this variable_node.

**System information**
- Windows 10
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v1.12.0
- Bazel version (if compiling from source): bazel 0.15
- CUDA/cuDNN version: 10/7
- GPU: 1050ti

I use vs2015 update3 to compile tensorflow and add some msvc symbols manually.
"
29906,why are there so many  function as parameter that passed into in python code ?,"why are there so many  functions as parameter that be passed into another function in Python code ?
It's hard to understand it !"
29905,tensorflow-gpu==2.0.0-beta1 AND tf-nightly-gpu-2-0-preview 2.0.0.dev20190607 fail with errors on windows 64 ,"When installing tensorflow on windows 64 Home edition (with GPU enabled for tensorflow ) - I get the following two errors (with both tensorflow beta and the nightly preview )

ERROR: tensorflow-gpu 2.0.0b1 has requirement tb-nightly<1.14.0a20190604,>=1.14.0a20190603, but you'll have tb-nightly 1.15.0a20190617 which is incompatible.
ERROR: tfp-nightly 0.8.0.dev20190617 has requirement cloudpickle==1.1.1, but you'll have cloudpickle 1.2.1 which is incompatible.

ERROR: tf-nightly-gpu-2-0-preview 2.0.0.dev20190607 has requirement tb-nightly<1.15.0a0,>=1.14.0a0, but you'll have tb-nightly 1.15.0a20190617 which is incompatible.
ERROR: tfp-nightly 0.8.0.dev20190617 has requirement cloudpickle==1.1.1, but you'll have cloudpickle 1.2.1 which is incompatible.

**System information**
- Windows 10 64 bit Home edition with NVidia GPU
- TensorFlow installed from (source or binary): 
- TensorFlow version: tf-nightly-gpu-2.0-preview=tf_nightly_gpu_2.0_preview-2.0.0.dev20190607
AND
tensorflow-gpu==2.0.0-beta1
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: pip install inside a newly created env using virtualenv
- CUDA/cuDNN version: CUDA - cuda_10.1.168_425.25_win10 , cuDNN - cudnn-10.1-windows10-x64-v7.6.0.64
- GPU model and memory: GEForce GTX 1050 Ti, 8 GB

**Describe the problem**
Getting 2 errors on trying to install tf-nightly-gpu-2.0-preview / tensorflow-gpu==2.0.0-beta1. 

ERROR: tf-nightly-gpu-2-0-preview 2.0.0.dev20190607 has requirement tb-nightly<1.15.0a0,>=1.14.0a0, but you'll have tb-nightly 1.15.0a20190617 which is incompatible.
ERROR: tfp-nightly 0.8.0.dev20190617 has requirement cloudpickle==1.1.1, but you'll have cloudpickle 1.2.1 which is incompatible. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I am trying to install tensorflow 2.0 beta / tf-nightly on my windows machine using pip install inside a virtual environment.

Commands -
1. python -m pip install --upgrade pip setuptools virtualenv
2. virtualenv <python path> env
3. Activate the environment
4. python -m pip install --upgrade -r requirements.txt
requirements.txt - Contains the following
```
##### Core scientific packages
jupyter==1.0.0
matplotlib==3.0.3
numpy==1.16.2
pandas==0.24.1
scipy==1.1.0

##### Machine Learning packages
scikit-learn==0.20.3

# Optional: the XGBoost library is only used in the ensemble learning chapter.
xgboost==0.82

##### TensorFlow-related packages

# Replace tensorflow with tensorflow-gpu if you want GPU support. If so,
# you need a GPU card with CUDA Compute Capability 3.5 or higher support, and
# you must install CUDA, cuDNN and more: see tensorflow.org for the detailed
# installation instructions.

#tf-nightly-2.0-preview
#tensorflow-gpu==2.0.0-beta1
tf-nightly-gpu-2.0-preview

#tensorboard
tb-nightly

#tensorflow-datasets
tfds-nightly

tensorflow-hub

# Optional: only used in chapter 13.
#tensorflow-transform==0.13.0

# Optional: only used in chapter 16.
# At the present (April 2019) the TF Addons library is only available on Linux
# So uncomment this line if you are using Linux.
#tensorflow-addons

# Optional: the TF Agents library is only needed in chapter 18
tf-agents-nightly

# Optional: the TF Serving API library is just needed for chapter 19.
tensorflow-serving-api

##### Image manipulation
imageio==2.5.0
Pillow==5.4.1
scikit-image==0.14.2

##### Reinforcement Learning library

# OpenAI gym is only needed in chapter 18.
# There are a few dependencies you need to install first, check out:
# https://github.com/openai/gym#installing-everything
gym[atari]==0.10.9

##### Additional utilities

# Joblib is a set of tools to provide lightweight pipelining
joblib==0.13.2

# May be useful with Pandas for complex ""where"" clauses (e.g., Pandas
# tutorial).
numexpr==2.6.9

# Optional: these libraries can be useful in chapter 3, exercise 4.
nltk==3.4
urlextract==0.9

# Needed in chapter 19.
requests==2.22.0

# Optional: nice utility to diff Jupyter Notebooks.
#nbdime==1.0.5

# Optional: tqdm displays nice progress bars, ipywidgets for tqdm's notebook support
tqdm==4.31.1
ipywidgets==7.4.2
```

"
29904,"The parameter M is a placeholder type variable. M's dimension is [None, 4]. Because the dimension information is None, it is impossible to use None as a cyclic variable.","The parameter M is a placeholder type variable. M's dimension is [None, 4]. Because the dimension information is None, it is impossible to use None as a cyclic variable. I need to use None dimension to extract four coordinate information, and then deduct this area from the feature map. What should I do? Thank you very much."
29903,Output of tf.train.piecewise_constant  function returns a TypeError,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7.3
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: 10.0/7.1
- GPU model and memory: Nvidia 2080 8GB

**Describe the current behavior**
We are trying to write a multi-step decay function in Tensorflow using tf.train.piecewise_constant() as suggested [here](https://stackoverflow.com/a/47174243/5079359). 

However, when we tried running the code, it returned a TypeError. It returns the same error even when lr() is used.

**Describe the expected behavior**
Tensorflow documentation for tf.train.piecewise_constant states that:

""When eager execution is enabled, this function returns a function which in turn returns the decayed learning rate Tensor""

**Code to reproduce the issue**
```
import tensorflow as tf
tf.enable_eager_execution()
import numpy as np

def conv3x3(out_planes, data_format ='channels_last',  stride=1, padding='same', dilation=1, name = None,use_bias = False):
    """"""3x3 convolution with padding""""""
    return  tf.keras.layers.Conv2D(filters = out_planes, kernel_size = 3,data_format= data_format,
                                   strides=(stride, stride), padding='same', use_bias=use_bias,
                                   dilation_rate = (dilation,dilation) , kernel_initializer=tf.initializers.he_normal(),name = name)


def conv1x1(out_planes,data_format ='channels_last', padding = 'same', stride=1):
    """"""1x1 convolution""""""
    return tf.keras.layers.Conv2D(filters = out_planes, kernel_size = 1, strides=(stride, stride),data_format= data_format,
                                  padding=padding, use_bias=False, kernel_initializer=tf.initializers.he_normal())

class BasicBlock(tf.keras.Model):
    expansion = 1

    def __init__(self, planes=1, stride=1, data_format= 'channels_last', downsample=None,  dilation=(1, 1), residual=True, key=None, stage = None):
        super(BasicBlock, self).__init__()
        self.data_format = data_format
        bn_axis = 1 if self.data_format == 'channels_first' else 3
        self.conv1 = conv3x3(out_planes= planes, stride = stride, padding='same' ,
                             data_format = self.data_format, dilation=dilation[0], name = '{}_{}_conv0'.format(key,stage))

        self.bn1 = tf.keras.layers.BatchNormalization(axis=bn_axis, name = '{}_{}_BN0'.format(key,stage))

        self.conv2 = conv3x3(out_planes =planes, padding='same',
                             data_format = self.data_format, dilation=dilation[0],name = '{}_{}_conv1'.format(key,stage))

        self.bn2 = tf.keras.layers.BatchNormalization(axis=bn_axis,name = '{}_{}_BN1'.format(key,stage))

        self.downsample = downsample
        self.relu = tf.keras.layers.ReLU(name = '{}_{}_Relu'.format(key,stage))
        self.stride = stride
        self.residual = residual

    def get_config(self):
        base_config = {}
        base_config['conv1'] = self.conv1.get_config()
        base_config['bn1'] = self.bn1.get_config()
        base_config['conv2'] = self.conv2.get_config()
        base_config['bn2'] = self.bn2.get_config()
        if self.downsample is not None:
            base_config['downsample'] = self.downsample.get_config()
        return base_config


    def call(self, inputs, training=None):
        residual = inputs
        out = self.conv1(inputs)
        out = self.bn1(out,training = training)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            residual = self.downsample(inputs)
        if self.residual:
            out += residual
        out = self.relu(out)
        return out


class Bottleneck(tf.keras.Model):
    expansion = 4

    def __init__(self, planes, stride=1, data_format = 'channels_last',downsample=None,dilation=(1, 1)):
        super(Bottleneck, self).__init__()

        bn_axis = 1 if data_format == 'channels_first' else 3
        self.conv1 = conv1x1(planes, data_format = data_format)
        self.bn1 = tf.keras.layers.BatchNormalization(axis=bn_axis)
        self.relu = tf.keras.layers.ReLU()
        self.conv2 = conv3x3(planes, stride, padding= 'same', bias=False,  data_format = data_format, dilation=dilation[1])
        self.bn2 = tf.keras.layers.BatchNormalization(axis=bn_axis)
        self.conv3 =conv1x1( planes * 4, data_format = data_format, )
        self.bn3 =  tf.keras.layers.BatchNormalization(axis=bn_axis) # nn.BatchNorm2d(planes * self.expansion)
        self.downsample = downsample
        self.stride = stride

    def get_config(self):
        base_config = {}
        base_config['conv1'] = self.conv1.get_config()
        base_config['bn1'] = self.bn1.get_config()
        base_config['conv2'] = self.conv2.get_config()
        base_config['bn2'] = self.bn2.get_config()
        base_config['conv3'] = self.conv3.get_config()
        base_config['bn3'] = self.bn3.get_config()
        if self.downsample is not None:
            base_config['downsample'] = self.downsample.get_config()
        return base_config



    def call(self, inputs, training=None):
        identity = inputs
        out = self.conv1(inputs)
        out = self.bn1(out,training = training)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out,training = training)
        out = tf.nn.relu(out)
        out = self.conv3(out)
        out = self.bn3(out,training = training)
        if self.downsample is not None:
            identity = self.downsample(inputs)
        out += identity
        out = self.relu(out)
        return out

class pooling (tf.keras.Model):
    def __init__(self, pool_size, stride = None, data_format='channels_last'):
        super(pooling, self).__init__()
        self.pool_size = pool_size
        self.data_format = data_format
        if stride is None:
            self.stride =self.pool_size
        else:
            self.stride = stride


    def call(self, inputs):
        return tf.layers.average_pooling2d(inputs, strides =self.stride, pool_size = self.pool_size, data_format = self.data_format)


class DRN(tf.keras.Model):
    def __init__(self, block, layers, data_format='channels_last', num_classes=7,channels=(16, 32, 64, 128, 256, 512, 512, 512),
                 out_map=False, out_middle=False, pool_size=28, arch='D'):
        super(DRN, self).__init__()
        self.inplanes = channels[0]
        self.out_map = out_map
        self.out_dim = channels[-1]
        self.out_middle = out_middle
        self.arch = arch
        self.poolsize = pool_size
        self.data_format = data_format
        self.bn_axis = 1 if data_format == 'channels_first' else 3

        self.conv0 = tf.keras.layers.Conv2D(filters=channels[0], kernel_size=7, strides=1,  padding='same',
                                               use_bias=False, data_format = self.data_format, kernel_initializer=tf.initializers.he_normal(), name ='L0_conv0' )
        self.bn0 = tf.keras.layers.BatchNormalization(axis=self.bn_axis,name ='L0_BN0')
        self.relu0 = tf.keras.layers.ReLU(name ='L0_Relu0')


        if arch == 'C':
            self.layer1 = self._make_layer(block = BasicBlock, planes = channels[0], blocks = layers[0], stride=1, data_format = self.data_format, key='CL1')
            self.layer2 = self._make_layer(block = BasicBlock, planes =  channels[1], blocks = layers[1], stride=2, data_format = self.data_format, key='CL2')
        elif arch == 'D':
            self.layer1 = self._make_conv_layers(channels = channels[0],convs = layers[0], stride=1, data_format = self.data_format, key='DL1')
            self.layer2 = self._make_conv_layers(channels = channels[1],convs = layers[1], stride=2, data_format = self.data_format, key='DL2')


        self.layer3 = self._make_layer(block = block, planes = channels[2], blocks = layers[2], stride=2, data_format = self.data_format, key='L3')
        self.layer4 = self._make_layer(block = block, planes = channels[3], blocks = layers[3], stride=2, data_format = self.data_format, key='L4')
        self.layer5 = self._make_layer(block = block, planes = channels[4], blocks = layers[4], dilation=2, new_level=False, data_format = self.data_format, key='L5')
        self.layer6 = None if layers[5] == 0 else self._make_layer(block, channels[5], layers[5], dilation=4, new_level=False, data_format = self.data_format, key='L6')

        if arch == 'C':
            self.layer7 = None if layers[6] == 0 else self._make_layer(BasicBlock, channels[6], layers[6], dilation=2, new_level=False, residual=False, data_format = self.data_format, key='CL7')
            self.layer8 = None if layers[7] == 0 else self._make_layer(BasicBlock, channels[7], layers[7], dilation=1, new_level=False, residual=False, data_format = self.data_format, key='CL8')
        elif arch == 'D':
            self.layer7 = None if layers[6] == 0 else self._make_conv_layers(channels[6], layers[6], dilation=2, data_format = self.data_format, key='DL7')
            self.layer8 = None if layers[7] == 0 else self._make_conv_layers(channels[7], layers[7], dilation=1, data_format = self.data_format, key='DL8')

        if num_classes > 0:
            self.avgpool = tf.keras.layers.GlobalAveragePooling2D(data_format = self.data_format)
            self.fc = tf.keras.layers.Dense(units=num_classes)


    def _make_layer(self, block, planes, blocks, stride=1,dilation=1, new_level=True, data_format = 'channels_last', residual=True, key=None):
        assert dilation == 1 or dilation % 2 == 0
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = tf.keras.Sequential([conv1x1(out_planes = planes * block.expansion,stride = stride, data_format = data_format),
                      tf.keras.layers.BatchNormalization(axis=self.bn_axis)], name = 'downsample')


        layers = []
        layers.append(block(planes= planes, stride =  stride, downsample = downsample, dilation=(1, 1) if dilation == 1 else (
                dilation // 2 if new_level else dilation, dilation), data_format=data_format, residual=residual, key = key, stage = '0'))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(planes, residual=residual,dilation=(dilation, dilation), data_format=data_format, key = key, stage = i))
        return tf.keras.Sequential(layers, name = key)


    def _make_conv_layers(self, channels, convs, stride=1, dilation=1 ,data_format = 'channels_last', key = None):
        modules = []
        for i in range(convs):
            modules.extend([
                conv3x3(out_planes= channels, stride=stride if i == 0 else 1,
                          padding= 'same' , use_bias=False, dilation=dilation,  data_format = data_format,name ='{}_{}_Conv'.format(key,i)),
                tf.keras.layers.BatchNormalization(axis=self.bn_axis,name ='{}_{}_BN'.format(key,i)),
                tf.keras.layers.ReLU(name ='{}_{}_Relu'.format(key,i))])
            self.inplanes = channels
        return tf.keras.Sequential(modules,name=key)


    def call(self, x, training=None):
        x = self.conv0(x)
        x = self.bn0(x,training = training)
        x = self.relu0(x)
        x = self.layer1(x,training = training)
        x = self.layer2(x,training = training)
        x = self.layer3(x,training = training)
        x = self.layer4(x,training = training)
        x = self.layer5(x,training = training)

        if self.layer6 is not None:
            x = self.layer6(x,training = training)

        if self.layer7 is not None:
            x = self.layer7(x)
        if self.layer8 is not None:
            x = self.layer8(x)
        if self.out_map:
            x = self.fc(x)
        else:
            x = self.avgpool(x)
            x = self.fc(x)
        return x

def loss(logits, labels):
  return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))

def make_scheduler(policy, init_lr, n_step_epoch, global_step):
    total_steps= n_step_epoch * 10 #10 epochs
    milestones = policy.split('_')
    milestones.pop(0)
    milestones = list(map(lambda x: int(x), milestones))
    boundaries = np.multiply(milestones,n_step_epoch)
    values = [init_lr] + [init_lr/(0.1**-i) for i in  range(1,len(milestones)+1)]
    learning_rate = tf.train.piecewise_constant(global_step, boundaries, values)
    return learning_rate


def train(model, optimizer, step_counter ):
  """"""Trains model on `dataset` using `optimizer`.""""""
  
  for (batch, i) in enumerate(range(10)):
      print('Training Loop {}'.format(i))
      images = tf.random.uniform((4, 224, 224,3))
      labels = tf.constant(np.random.randint(4, size=4))
      with tf.contrib.summary.record_summaries_every_n_global_steps(10, global_step=step_counter):
          with tf.GradientTape() as tape:
            logits = model(images, training=True)
            loss_value = loss(logits, labels)
          grads = tape.gradient(loss_value, model.variables)
          optimizer.apply_gradients(zip(grads, model.variables), global_step=step_counter)


def test(model):
  """"""Perform an evaluation of `model` on the examples from `dataset`.""""""
  for  i in (range(10)):
    images = tf.random.uniform((4, 225, 225,3))
    logits = model(images, training=False)
    print(logits)

def main():
    model =  DRN(BasicBlock, [1, 1, 2, 2, 2, 2, 1, 1], arch='C',num_classes = 4)
    device = '/gpu:0'
    step_counter = tf.train.get_or_create_global_step()
    lr = make_scheduler(policy='multistep_2_5',init_lr=0.1,n_step_epoch = 10,global_step= step_counter)
    optimizer = tf.train.MomentumOptimizer(lr,momentum=0.5)
    
    with tf.device(device):
        for _ in range(10):
           train(model, optimizer,step_counter)
           print(optimizer._lr_t)
           test(model)

if __name__ == '__main__':
  main()

```

**Other info / logs**

>File ""<ipython-input-1-666c765cdffd>"", line 1, in <module>
    runfile('/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug/stackoverflow.py', wdir='/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug')

>  File ""/home/srijith/anaconda3/lib/python3.7/site-packages/spyder_kernels/customize/spydercustomize.py"", line 709, in runfile
    execfile(filename, namespace)

 > File ""/home/srijith/anaconda3/lib/python3.7/site-packages/spyder_kernels/customize/spydercustomize.py"", line 108, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

 > File ""/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug/stackoverflow.py"", line 311, in <module>
    main()

 > File ""/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug/stackoverflow.py"", line 305, in main
    train(model, optimizer,step_counter)

>  File ""/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug/stackoverflow.py"", line 284, in train
    optimizer.apply_gradients(zip(grads, model.variables), global_step=step_counter)

 > File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/optimizer.py"", line 598, in apply_gradients
    self._prepare()

>  File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/momentum.py"", line 87, in _prepare
    learning_rate = learning_rate()

>  File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/learning_rate_decay_v2.py"", line 171, in decayed_lr
    boundaries = ops.convert_n_to_tensor(boundaries)

 > File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1273, in convert_n_to_tensor
    as_ref=False)

 > File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1228, in internal_convert_n_to_tensor
    raise TypeError(""values must be a list."")

>TypeError: values must be a list.

The code works as expected when we provide a constant learning rate. Is there something that we are missing?"
29902,InvalidArgumentError (see above for traceback): max_x must be larger than min_x,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: **NO**
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: **Ubuntu 14.04**
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NO
- **TensorFlow installed from (source or binary)**: Source 
- **TensorFlow version (use command below)**: **r.12**
- **Python version**: **2.7.12**
- **Bazel version (if compiling from source)**: **0.15.0**
- **GCC/Compiler version (if compiling from source)**: None
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
I have reinforcement learning model which I am trying to Quantize using transform_graph. Transform graph generates quantized graph but this quantized graph returns an error while running.
Error: Max_x for QuantizedAdd must be larger than min_x.

Reinforcement Learning model runs OK without quantization. I tried converting to tflite, but tflite doesn't support some of the ops used in the RL model.

Is there a workaround for max_x and min_x checks. 

### Source code / logs
InvalidArgumentError (see above for traceback): max_x must be larger than min_x.
         [[Node: add_1/eightbit = QuantizedAdd[T1=DT_QUINT8, T2=DT_QUINT8, Toutput=DT_QINT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](add_1_eightbit/truediv/quantize, add_eightbit/add_1/y/quantize, add_1_eightbit/truediv/quantize:1, add_1_eightbit/truediv/quantize:2, add_eightbit/add_1/y/quantize:1, add_eightbit/add_1/y/quantize:2)]]
         [[Node: add_1/_97 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_312_add_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]] "
29898,Need example of mixed precision in eager execution mode,"https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/train/experimental/enable_mixed_precision_graph_rewrite

https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/train/experimental/MixedPrecisionLossScaleOptimizer

https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/mixed_precision/experimental/LossScaleOptimizer

I have tried all of them. None of them worked for me in eager mode. Could you provide some examples?"
29897,[TF 2.0 API Docs] tf.sets.difference,"## System Information

TensorFlow version: 2.0

## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/sets/difference

## Description of issue (what needs changing):

### Raises listed and defined

Raises not listed and defined.
Every method has a way that it can be mishandled, maybe when a wrong parameter or wrong order of parameters is/are passed in ( e.g, in this case, two sets `a` and `b` in which the last elements don't match) will raise an error.

### Request visuals, if applicable

No visuals

### Submit a pull request?

No
"
29896,Keras Colab TPU Error when compiling and fitting a pre-trained model in 1.14,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 1.14
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When doing transfer learning using pre-trained keras model (Xception per say) with the imagenet weights and adding a classification layer there is an error when fitting. If you use no weights there is no error during fitting, but if you fine tune the model, re-compile it and fit again the same error pops.

**Describe the expected behavior**
No error, it was working in 1.13. 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
The easiest way to reproduce the problem is using the official notebook : 
https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/fashion_mnist.ipynb
and re-compiling and fitting a second time 

```
import os

resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.contrib.distribute.initialize_tpu_system(resolver)
strategy = tf.contrib.distribute.TPUStrategy(resolver)

with strategy.scope():
  model = create_model()
  model.compile(
      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
      loss='sparse_categorical_crossentropy',
      metrics=['sparse_categorical_accuracy'])

model.fit(
    x_train.astype(np.float32), y_train.astype(np.float32),
    epochs=17,
    steps_per_epoch=60,
    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),
    validation_freq=17
)

##This part was added##
print('Fine tuning')

with strategy.scope():
  model.compile(
      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
      loss='sparse_categorical_crossentropy',
      metrics=['sparse_categorical_accuracy'])

model.fit(
    x_train.astype(np.float32), y_train.astype(np.float32),
    epochs=17,
    steps_per_epoch=60,
    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),
    validation_freq=17
)


model.save_weights('./fashion_mnist.h5', overwrite=True)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
And it leads to this error
W0617 21:41:40.701483 140301503657856 tpu_strategy_util.py:56] TPU system %s has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.
Epoch 1/17
60/60 [==============================] - 5s 81ms/step - loss: 1.0900 - sparse_categorical_accuracy: 0.6855
Epoch 2/17
60/60 [==============================] - 1s 24ms/step - loss: 0.5287 - sparse_categorical_accuracy: 0.8202
Epoch 3/17
60/60 [==============================] - 2s 25ms/step - loss: 0.4317 - sparse_categorical_accuracy: 0.8518
Epoch 4/17
60/60 [==============================] - 1s 25ms/step - loss: 0.3728 - sparse_categorical_accuracy: 0.8692
Epoch 5/17
60/60 [==============================] - 1s 25ms/step - loss: 0.3453 - sparse_categorical_accuracy: 0.8776
Epoch 6/17
60/60 [==============================] - 1s 24ms/step - loss: 0.3080 - sparse_categorical_accuracy: 0.8898
Epoch 7/17
60/60 [==============================] - 1s 24ms/step - loss: 0.2892 - sparse_categorical_accuracy: 0.8954
Epoch 8/17
60/60 [==============================] - 1s 24ms/step - loss: 0.2641 - sparse_categorical_accuracy: 0.9044
Epoch 9/17
60/60 [==============================] - 1s 25ms/step - loss: 0.2485 - sparse_categorical_accuracy: 0.9093
Epoch 10/17
60/60 [==============================] - 1s 24ms/step - loss: 0.2337 - sparse_categorical_accuracy: 0.9135
Epoch 11/17
60/60 [==============================] - 1s 25ms/step - loss: 0.2236 - sparse_categorical_accuracy: 0.9170
Epoch 12/17
60/60 [==============================] - 1s 25ms/step - loss: 0.2081 - sparse_categorical_accuracy: 0.9232
Epoch 13/17
60/60 [==============================] - 1s 25ms/step - loss: 0.1962 - sparse_categorical_accuracy: 0.9281
Epoch 14/17
60/60 [==============================] - 2s 25ms/step - loss: 0.1816 - sparse_categorical_accuracy: 0.9318
Epoch 15/17
60/60 [==============================] - 1s 24ms/step - loss: 0.1717 - sparse_categorical_accuracy: 0.9355
Epoch 16/17
60/60 [==============================] - 1s 24ms/step - loss: 0.1666 - sparse_categorical_accuracy: 0.9375
Epoch 17/17
10/10 [==============================] - 7s 720ms/step
10/10 [==============================] - 7s 720ms/step
60/60 [==============================] - 13s 216ms/step - loss: 0.1535 - sparse_categorical_accuracy: 0.9424 - val_loss: 0.2364 - val_sparse_categorical_accuracy: 0.9235
Fine tuning
Epoch 1/17

NotFoundErrorTraceback (most recent call last)
<ipython-input-5-ca82800c4c4f> in <module>()
     33     steps_per_epoch=60,
     34     validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),
---> 35     validation_freq=17
     36 )
     37 

7 frames
/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training.pyc in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    647             steps_per_epoch=steps_per_epoch,
    648             validation_steps=validation_steps,
--> 649             validation_freq=validation_freq)
    650 
    651     batch_size = self._validate_or_infer_batch_size(

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training_distributed.pyc in fit_distributed(model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq)
    126         steps_per_epoch=steps_per_epoch,
    127         validation_steps=validation_steps,
--> 128         validation_freq=validation_freq)
    129   else:
    130     return training_arrays.fit_loop(

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training_distributed.pyc in experimental_tpu_fit_loop(model, dataset, epochs, verbose, callbacks, initial_epoch, steps_per_epoch, val_dataset, validation_steps, validation_freq)
    412         prev_step_count = step_count
    413       try:
--> 414         _, outputs = K.batch_get_value([train_op, output_tensors])
    415       except errors.OutOfRangeError:
    416         logging.warning('Your dataset iterator ran out of data; '

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/backend.pyc in batch_get_value(tensors)
   3008     raise RuntimeError('Cannot get value inside Tensorflow graph function.')
   3009   if tensors:
-> 3010     return get_session(tensors).run(tensors)
   3011   else:
   3012     return []

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    948     try:
    949       result = self._run(None, fetches, feed_dict, options_ptr,
--> 950                          run_metadata_ptr)
    951       if run_metadata:
    952         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1171     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1172       results = self._do_run(handle, final_targets, final_fetches,
-> 1173                              feed_dict_tensor, options, run_metadata)
   1174     else:
   1175       results = []

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1348     if handle is None:
   1349       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1350                            run_metadata)
   1351     else:
   1352       return self._do_call(_prun_fn, handle, feeds, fetches)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1368           pass
   1369       message = error_interpolation.interpolate(message, self._graph)
-> 1370       raise type(e)(node_def, op, message)
   1371 
   1372   def _extend_graph(self):

NotFoundError: From /job:worker/replica:0/task:0:
Resource worker/batch_normalization_3_1/moving_mean/replica_7/N10tensorflow3VarE does not exist.
	 [[node TPUReplicateMetadata_5 (defined at <ipython-input-5-ca82800c4c4f>:35) ]]

Original stack trace for u'TPUReplicateMetadata_5':
  File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py"", line 477, in start
    ioloop.IOLoop.instance().start()
  File ""/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 450, in _handle_events
    self._handle_recv()
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 480, in _handle_recv
    self._run_callback(callback, msg)
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 432, in _run_callback
    callback(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 235, in dispatch_shell
    handler(stream, idents, msg)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py"", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-5-ca82800c4c4f>"", line 35, in <module>
    validation_freq=17
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 649, in fit
    validation_freq=validation_freq)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training_distributed.py"", line 128, in fit_distributed
    validation_freq=validation_freq)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training_distributed.py"", line 367, in experimental_tpu_fit_loop
    initial_loop_values=initial_loop_values)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/distribute/distribute_lib.py"", line 1501, in experimental_run_steps_on_iterator
    initial_loop_values)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py"", line 416, in _experimental_run_steps_on_iterator
    replicate_outputs = rewrite_fn()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py"", line 397, in rewrite_fn
    replicate_outputs = tpu.replicate(run_fn, replicate_inputs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/tpu/tpu.py"", line 592, in replicate
    maximum_shapes=maximum_shapes)[1]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/tpu/tpu.py"", line 854, in split_compile_and_replicate
    num_replicas=num_replicas, use_tpu=use_tpu, **metadata_kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_tpu_ops.py"", line 6039, in tpu_replicate_metadata
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()"
29891,compiling a file for the coral tpu,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
I am using custom code
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
os: Windows
os kernel version: 10.0.17763
os release version: 10
os platform: Windows-10-10.0.17763-SP0
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
the coral tpu kinda
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
b'v1.13.1-0-g6612da8951' 1.13.1
- Python version:
python version: 3.7.3
python branch: v3.7.3
python build version: ('v3.7.3:ef4ec6ed12', 'Mar 25 2019 22:22:05')
python compiler version: MSC v.1916 64 bit (AMD64)
python implementation: CPython
- Bazel version (if compiling from source):NA
- GCC/Compiler version (if compiling from source):NA
- CUDA/cuDNN version:  release 10.0, V10.0.130
- GPU model and memory: NVIDIA TITAN RTX

**Describe the current behavior**
I trained a model with quantization aware training, froze the model and converted the file to a tflite file and then when trying to compile the file one the coral tpu website it fails to compile.

When I print out the tensors of the tfilte file I get:
```
[{'name': 'output', 'index': 3, 'shape': array([2, 1]), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0)}]
[{'name': 'A', 'index': 0, 'shape': array([2, 1]), 'dtype': <class 'numpy.uint8'>, 'quantization': (1.0, 0)}, {'name': 'activation', 'index': 1, 'shape': array([2, 2]), 'dtype': <class 'numpy.ui
nt8'>, 'quantization': (0.0235294122248888, 0)}, {'name': 'mult_bias', 'index': 2, 'shape': array([2]), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0470588244497776, 0)}, {'name': 'output
', 'index': 3, 'shape': array([2, 1]), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0)}, {'name': 'output/dimension', 'index': 4, 'shape': array([], dtype=int32), 'dtype': <class 'numpy
.int32'>, 'quantization': (0.0, 0)}, {'name': 'weights_quant/FakeQuantWithMinMaxVars/transpose', 'index': 5, 'shape': array([2, 1]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0470588244
497776, 128)}]
{'name': 'A', 'index': 0, 'shape': array([2, 1]), 'dtype': <class 'numpy.uint8'>, 'quantization': (1.0, 0)}
{'name': 'activation', 'index': 1, 'shape': array([2, 2]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0235294122248888, 0)}
{'name': 'mult_bias', 'index': 2, 'shape': array([2]), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0470588244497776, 0)}
{'name': 'output', 'index': 3, 'shape': array([2, 1]), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0)}
{'name': 'output/dimension', 'index': 4, 'shape': array([], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0)}
{'name': 'weights_quant/FakeQuantWithMinMaxVars/transpose', 'index': 5, 'shape': array([2, 1]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0470588244497776, 128)}
```

Some of the tensors aren't being converted into uint8 and I'm not exactly sure how that is supposed to happen (I assume that is the reason the file won't compile.)
**Describe the expected behavior**
I am expecting that I can get a custom model to work on the coral tpu. (I'm assuming I'm doing something a bit wrong but I am having so much trouble figuring out what I'm doing wrong)
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
import tensorflow as tf

shape_a = (2, 1)
shape_b = (1, 2)

a = tf.placeholder(dtype=tf.float32, shape=shape_a, name=""A"")
y = tf.placeholder(tf.int64, shape=(None), name=""y"")

b = tf.Variable(tf.truncated_normal((1, 2), name=""weight""))

c = tf.matmul(a, b, name=""mult"")

act = tf.nn.relu(c, name=""activation"")

xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=act)
loss = tf.reduce_mean(xentropy, name=""loss"")

output = tf.argmax(act, axis=1, name=""output"")

# Call the eval rewrite which rewrites the graph in-place with
# FakeQuantization nodes and fold batchnorm for eval.
g = tf.get_default_graph()
tf.contrib.quantize.create_eval_graph(input_graph=g)

#quant aware testing
g = tf.get_default_graph()
tf.contrib.quantize.create_training_graph(input_graph=g)

learning_rate = 0.01

with tf.name_scope(""train""):
    optimizer = tf.train.AdamOptimizer(learning_rate)
    training_op = optimizer.minimize(loss, var_list=[b])



init = tf.global_variables_initializer()

#handles different tensorboard runs
now = datetime.utcnow().strftime(""%Y%m%d%H%M%S"")
root_logdir = ""tf_logs""
logdir = ""mat_mul/{}/run-{}"".format(root_logdir, now)
logdir_later = ""mat_mul_later/{}/run-{}"".format(root_logdir, now)
checkpoint_dir = ""./mat_mul/saveCKPT""

with tf.Session() as sess:
    init.run()
    print(sess.run(training_op, feed_dict={a: [[1.0], [2.5]], y: [1, 0]}))
    print(sess.run(act, feed_dict={a: [[1.0], [2.5]]}))
    print(sess.run(output, feed_dict={a: [[1.0], [2.5]]}))
    file_writer = tf.summary.FileWriter(logdir)
    file_writer.add_graph(tf.get_default_graph())
    file_writer.flush()

    saver = tf.train.Saver()
    saver.save(sess, checkpoint_dir)


    frozen_graph = tf.graph_util.convert_variables_to_constants(sess, tf.graph_util.remove_training_nodes(tf.get_default_graph().as_graph_def()), [""output""])

    output_graph = ""mat_mul/frozen_graph""
    with tf.gfile.GFile(output_graph, ""wb"") as f:
        f.write(frozen_graph.SerializeToString())

    converter = tf.lite.TFLiteConverter.from_frozen_graph(output_graph, [""A""], [""output""])
    converter.inference_type = tf.lite.constants.QUANTIZED_UINT8
    input_arrays = converter.get_input_arrays()
    converter.quantized_input_stats = {input_arrays[0]: (0., 1.)}  # mean, std_dev

    tflite_model = converter.convert()
    open(""simple_mat_mult.tflite"", ""wb"").write(tflite_model)

    file_writer = tf.summary.FileWriter(logdir_later)
    file_writer.add_graph(tf.graph_util.remove_training_nodes(tf.get_default_graph().as_graph_def()))
    file_writer.flush()
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29890,[TF 2.0 API Docs] tf.keras.backend.count_params,"## System Information
Tensorflow version 2.9

## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/backend/count_params

## Description of issue (what needs changing):

### Clear description
The description is not clear, no details on how to use this symbol

### Raises listed and defined
No errors have been defined 

### Request visuals, if applicable
No visuals? an example using arrays could be represented in visual form for clarification

### Submit a pull request?
No
"
29887,TensorFlow Lite Op Request,"**System information**
- OS Platform and Distribution: (macOS Mojave 10.14.4)
- TensorFlow installed from: (pip3)
- TensorFlow version (or github SHA if from source): '1.13.1'


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, LOGISTIC, MAX_POOL_2D, MUL, PACK, PAD, RELU, RESHAPE, RESIZE_BILINEAR, SHAPE, STRIDED_SLICE, SUB, TILE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: GatherNd, NonMaxSuppressionV3, ScatterNd, Size, Where.
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.6/bin/toco_from_protos"", line 10, in <module>
    sys.exit(main())
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 59, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 33, in execute
    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, LOGISTIC, MAX_POOL_2D, MUL, PACK, PAD, RELU, RESHAPE, RESIZE_BILINEAR, SHAPE, STRIDED_SLICE, SUB, TILE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: GatherNd, NonMaxSuppressionV3, ScatterNd, Size, Where.




Process finished with exit code 1

```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29886,XLA builds with NCCL even when it is disabled,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.14/master
- Python version: 3.6
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): Linaro 7.4.0
- CUDA/cuDNN version: 10.0
- GPU model and memory: Jetson Xavier



**Describe the problem**
Build fails when NCCL is disabled. XLA's build file builds NCCL with the `if_cuda` conditional (https://github.com/tensorflow/tensorflow/blob/v1.14.0-rc1/tensorflow/compiler/xla/service/gpu/BUILD#L359), but should be using `if_nccl` instead (https://github.com/tensorflow/tensorflow/blob/v1.14.0-rc1/tensorflow/core/kernels/BUILD#L210).


**Provide the exact sequence of commands / steps that you executed before running into the problem**
Trying to build TensorFlow with CUDA support but with NCCL disabled (--config=cuda and --config=nonccl bazel options) causes this issue.
"
29885,https://www.tensorflow.org/guide/using_tpu 2.0b,"## URL(s) with the issue:
https://www.tensorflow.org/guide/using_tpu

## Description of issue (what needs changing):

Needs to be completely redone

### Clear description

Everything is wrong and examples do not work

"
29884,get_next() doesn't block mapped function for datasets made from a generator,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux AMI
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0.0-beta0
- Python version: 3.6.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 7.2.1
- CUDA/cuDNN version: V9.0.176
- GPU model and memory:

**Describe the current behavior**
I am generating a dataset using `from_dataset` that involves copying and decrypting data at read time, which takes some time to process. Once the files are copied the filenames are yielded by the generator function so they can be read in a reading function that I am trying to map. However, the reading code doesn't get blocked by the copy operation, and tries to operate on garbage data containing `args_0:0` before the generator function has actually run and yielded a filename.

Additionally, when I add additional non-tensorflow code inside of my mapped function, that code only gets executed the first time it is called. This might be me not understanding the intended behavior of the `map` function, but making it so that file reads can happen correctly in a map function would be useful in cases like this.

**Describe the expected behavior**
The code in the function passed as an argument to .map() should not be run until the generator has yielded a value for it to operate on, or an input argument for map allowing this behavior to be specified should be added. If this is actually the intended behavior, that should be made more clear in the documentation for .map()

**Code to reproduce the issue**
```
import tensorflow as tf
import time

def process(x):
    print(x)
    print(""test"")
    return x+1

def get_next_batch_sleep():
    while True:
        time.sleep(10)
        yield(1)

ds = tf.data.Dataset.from_generator(get_next_batch_sleep,output_types=(tf.int64))
ds = ds.map(process)
it = ds.make_one_shot_iterator()
for i in range(5):
    print(it.get_next())
```

This will immediately output
```
Tensor(""args_0:0"", dtype=int64)
test
```
And then output every 10 seconds
`tf.Tensor(2, shape=(), dtype=int64)`
"
29883,always_record_summaries in tf 2.0,I can't find `tf.summary.always_record_summaries` or `do_always_record_summaries` in tensorflow 2.0. Where can I find it?
29881,The call method of DenseFeatures and SequenceFeatures use deprecated attribute _num_buckets,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
- TensorFlow installed from (source or binary): from pip install
- TensorFlow version (use command below): v1.12.1-3259-gf59745a381 2.0.0-beta0
- Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14

**Describe the current behavior**

By simply calling the `call` method of `DenseFeatures` and `SequenceFeatures` defined with `categorical_column_with_identity` and `sequence_categorical_column_with_identity` feature columns (along with `embedding_column`), we get warnings that the deprecated attributes `_num_buckets` are used (instead of the non-deprecated `num_buckets` I guess).

Also note, on the code example below, that a third warning about a deprecated method, `add_dispatch_support.<locals>.wrapper` arises. I do not understand it but there are instructions for updating given in the warning, see the code below.

**Describe the expected behavior**

I think that we should not get warnings about deprecated objects when we are not calling any deprecated method, attribute, etc. I think that somewhere in the code of the `call` method of `DenseFeatures` and `SequenceFeatures` there is a use of `_num_buckets` that should be replaced by `num_buckets`. Following the updating instructions about the third warning may be enough to get rid of it.

**Code to reproduce the issue**

```
import numpy as np
import tensorflow as tf
from tensorflow.feature_column import categorical_column_with_identity, embedding_column, \
                                            sequence_categorical_column_with_identity
from tensorflow.keras.layers import DenseFeatures
from tensorflow.keras.experimental import SequenceFeatures

#print(tf.version.GIT_VERSION, tf.version.VERSION)

nb_features = 10
emb_dim = 3

fc = categorical_column_with_identity('feature1', nb_features)
emb_fc = embedding_column(fc, emb_dim)
layer = DenseFeatures(emb_fc)

seq_fc = sequence_categorical_column_with_identity('feature2', nb_features)
emb_seq_fc = embedding_column(seq_fc, emb_dim)
seq_layer = SequenceFeatures(emb_seq_fc)

data1 = np.array(range(nb_features))
batch_size, sequence_length = 2, 5
raw_data2 = np.array(range(nb_features))
data2 = np.reshape(raw_data2, (batch_size, sequence_length))

dict_data = {'feature1': data1, 'feature2': data2}
print(layer(dict_data))
print(seq_layer(dict_data))
```
produces the following three warnings:

```
WARNING: Logging before flag parsing goes to stderr.
W0617 19:19:42.823884 140735678825344 deprecation.py:323] From /Users/myusername/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:3040: IdentityCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
W0617 19:19:42.827694 140735678825344 deprecation.py:323] From /Users/myusername/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2655: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0617 19:19:42.833320 140735678825344 deprecation.py:323] From /Users/myusername/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:3040: SequenceCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
```"
29879,SequenceFeatures layer requires a SparseTensor... only to convert it to a regular Tensor,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
- TensorFlow installed from (source or binary): from pip install
- TensorFlow version (use command below): v1.12.1-3259-gf59745a381 2.0.0-beta0
- Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14

**Describe the current behavior**

When I call a `SequenceFeatures` layer on a dense tensor, like a tensor produced with numpy, a `TypeError` is raised because `SequenceFeatures` `call` method expects a `SparseTensor` as input. When looking at the log it appears that the function producing the `TypeError` is `sparse_tensor_to_dense`. So, `SequenceFeatures` does expect a `SparseTensor`, only to convert it to a dense `Tensor`, and fails if given a `Tensor` that is already dense.

**Describe the expected behavior**

I think `SequenceFeatures` `call` should accepts dense `Tensor` objects and just don't try to convert them from sparse to dense.

**Code to reproduce the issue**

```
import numpy as np
import tensorflow as tf
from tensorflow.feature_column import sequence_numeric_column
from tensorflow.keras.experimental import SequenceFeatures

#print(tf.version.GIT_VERSION, tf.version.VERSION)

seq_fc = sequence_numeric_column('feature1')
seq_layer = SequenceFeatures(seq_fc)

batch_size, sequence_length = 3, 5
raw_data = np.array(range(batch_size * sequence_length), dtype=np.float32)
data = np.reshape(raw_data, (batch_size, sequence_length))

dict_data = {'feature1': data}
seq_layer(dict_data)
```
This produces the following error log:

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-5-aa46f578fa6e> in <module>
      1 dict_data = {'feature1': data}
----> 2 seq_layer(dict_data)

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    710           with base_layer_utils.autocast_context_manager(
    711               input_list, self._mixed_precision_policy.should_cast_variables):
--> 712             outputs = self.call(inputs, *args, **kwargs)
    713           self._handle_activity_regularization(inputs, outputs)
    714           self._set_mask_metadata(inputs, outputs, input_masks)

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/feature_column/sequence_feature_column.py in call(self, features)
    138       with ops.name_scope(column.name):
    139         dense_tensor, sequence_length = column.get_sequence_dense_tensor(
--> 140             transformation_cache, self._state_manager)
    141         # Flattens the final dimension to produce a 3D Tensor.
    142         output_tensors.append(self._process_dense_tensor(column, dense_tensor))

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/feature_column/sequence_feature_column.py in get_sequence_dense_tensor(self, transformation_cache, state_manager)
    553     sp_tensor = transformation_cache.get(self, state_manager)
    554     dense_tensor = sparse_ops.sparse_tensor_to_dense(
--> 555         sp_tensor, default_value=self.default_value)
    556     # Reshape into [batch_size, T, variable_shape].
    557     dense_shape = array_ops.concat(

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py in sparse_tensor_to_dense(sp_input, default_value, validate_indices, name)
   1447     TypeError: If `sp_input` is not a `SparseTensor`.
   1448   """"""
-> 1449   sp_input = _convert_to_sparse_tensor(sp_input)
   1450 
   1451   return gen_sparse_ops.sparse_to_dense(

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py in _convert_to_sparse_tensor(sp_input)
     66     return sparse_tensor.SparseTensor.from_value(sp_input)
     67   if not isinstance(sp_input, sparse_tensor.SparseTensor):
---> 68     raise TypeError(""Input must be a SparseTensor."")
     69   return sp_input
     70 

TypeError: Input must be a SparseTensor.
```

**Workaround**

Converting the input to sparse before calling `SequenceFeatures` does make the code work:

```
import numpy as np
import tensorflow as tf
from tensorflow.feature_column import sequence_numeric_column
from tensorflow.keras.experimental import SequenceFeatures

#print(tf.version.GIT_VERSION, tf.version.VERSION)

seq_fc = sequence_numeric_column('feature1')
seq_layer = SequenceFeatures(seq_fc)

batch_size, sequence_length = 3, 5
raw_data = np.array(range(batch_size * sequence_length), dtype=np.float32)
data = np.reshape(raw_data, (batch_size, sequence_length))

#####
# convert the input tensor in a sparse tensor
zero = tf.constant(0, dtype=tf.float32)
where = tf.not_equal(data, zero)
indices = tf.where(where)
values = tf.gather_nd(data, indices)
sparse = tf.SparseTensor(indices, values, data.shape)
dict_data_but_sparse = {'feature1': sparse}
#####

seq_layer(dict_data_but_sparse)
```

correctly outputs the following:

```
(<tf.Tensor: id=367, shape=(3, 5, 1), dtype=float32, numpy=
 array([[[ 0.],
         [ 1.],
         [ 2.],
         [ 3.],
         [ 4.]],
 
        [[ 5.],
         [ 6.],
         [ 7.],
         [ 8.],
         [ 9.]],
 
        [[10.],
         [11.],
         [12.],
         [13.],
         [14.]]], dtype=float32)>,
 <tf.Tensor: id=355, shape=(3,), dtype=int64, numpy=array([5, 5, 5])>)
```"
29878,How can I activate Tensorflow's XLA for the C API?,"- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.13.1
- Python version: 3.6
- Installed using virtualenv? pip? conda?: -
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: -
- GPU model and memory: - 

I have built Tensorflow from source and I am using it's C API. So far everything works good, I am also using AVX / AVX2. My Tensorflow build from source was also built with XLA support. I now would like to also activate XLA (accelerated linear algebra) as I hope that it will once again increase the performance / speed during inference.

If I start my run right now I get this message:

```
2019-06-17 16:09:06.753737: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1541] 
(One-time warning): Not using XLA:CPU for cluster because envvar 
TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that
envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass
--vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or 
set the envvar XLA_FLAGS=--xla_hlo_profile.
```

On the official XLA homepage (https://www.tensorflow.org/xla/jit) I found this information about how to turn on jit on a session level:

```
# Config to turn on JIT compilation
config = tf.ConfigProto()
config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1
sess = tf.Session(config=config)
```

Here (https://github.com/tensorflow/tensorflow/issues/13853) it was explained how to set the TF_SetConfig in the C API. I was able to limit to one core before using the output of this Python code:

```
config1 = tf.ConfigProto(device_count={'CPU':1})
serialized1 = config1.SerializeToString()
print(list(map(hex, serialized1)))
```

I implemented it as follows:

```
uint8_t intra_op_parallelism_threads = maxCores; // for operations that can be parallelized internally, such as matrix multiplication 
uint8_t inter_op_parallelism_threads = maxCores; // for operations that are independent in your TensorFlow graph because there is no directed path between them in the dataflow graph
uint8_t config[]={0x10,intra_op_parallelism_threads,0x28,inter_op_parallelism_threads};
TF_SetConfig(sess_opts,config,sizeof(config),status);
```

Therefore I thought this would help out for the XLA activation:
```
config= tf.ConfigProto()
config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1
output = config.SerializeToString()
print(list(map(hex, output)))
```

Implementation this time:

```
uint8_t config[]={0x52,0x4,0x1a,0x2,0x28,0x1};
TF_SetConfig(sess_opts,config,sizeof(config),status);
```

However XLA still seems to be deactivated. Can somebody help me out with this issue? Or, if you once again have a loot at the warning:

```
2019-06-17 16:09:06.753737: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1541] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
```

Does that mean I have to set XLA_FLAGS during the build?

I build Tensorflow using these configurations:

```
    Please specify the location of python. [Default is /usr/bin/python]: default
    -Please input the desired Python library path to use. Default is [/usr/local/lib/python2.7/dist-packages]: default
    Do you wish to build TensorFlow with XLA JIT support? [Y/n]: Y
    Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N
    Do you wish to build TensorFlow with ROCm support? [y/N]: N
    Do you wish to build TensorFlow with CUDA support? [y/N]: N
    Do you wish to download a fresh release of clang? (Experimental) [y/N]: N
    Do you wish to build TensorFlow with MPI support? [y/N]: y
    Please specify the MPI toolkit folder. [Default is /usr]: default
    Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: default
    Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N
```

Thanks in advance!

Edit: moreover after some reading I am still not sure about when I should use XLA JIT and when I should use XLA AOT. It would be great if somebody could give me a recommendation about that!

Edit 2: I just read here (https://www.tensorflow.org/xla/jit):
```
# Config to turn on JIT compilation
config = tf.ConfigProto()
config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1
sess = tf.Session(config=config)
______________________________________
Note: Turning on JIT at the session level will not result in operations being compiled for the CPU. JIT compilation for CPU operations must be done via the manual method documented below.
```

So - no surprise my command did not do anything. Instead it is suggested to use the manual method:
```
    jit_scope = tf.contrib.compiler.jit.experimental_jit_scope

    x = tf.placeholder(np.float32)
    with jit_scope():
      y = tf.add(x, x)  # The ""add"" will be compiled with XLA.
```
However I do not know how to do this using the C API, as I do not have single operations like add, instead I just have the TF_SessionRun(...)-command."
29877,TFRecord guide doesn't show how to serialize and parse tensors,"## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/beta/tutorials/load_data/tf_records#creating_a_tfexample_message
https://www.tensorflow.org/tutorials/load_data/tf_records

## Description of issue (what needs changing):
the TFRecord docs don't show how to serialize and parse tensors to a TFRecord. It's a minimal example with a bunch of strings, integers, and floats. How do you include tensor features in a tf.train.Example ?

The whole tf.train / tf.io / tf.data thing feels scattered and full of unnecessary boilerplate. Why are Examples Features, Feature in train, but then then we have to write a bunch of boilerplate tf.io functions like **_float_value _byte_value** to make the actual features? All I want to do is make a TFRecord with a bunch of tensors of different shapes in each entry. 

### Clear description

All of this stuff should be simplified and put into tf.data... Tf.io feels pointless since tf.data is meant to do the same thing. 

Why can't the tensorflow guide to TFRecord tell us how to write tensor data to a TFRecord and read it with TFData? 

Why do we need to write so much boilerplate to add features to tf.train.Example?

Why is Data IO spread out over four separate modules (train, io, dtypes, and data) ?"
29876,CUDA_ERROR_NOT_INITIALIZED error when using Multiple GPUs with multiprocessing,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1,13
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10, cuDNN 7.7
- GPU model and memory: 2x NVIDIA Tesla T4, 16GB GDDR5

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Hello, I am trying to parallelize a machine learning algorithm by using multiprocessing for my TensorFlow session. This way, I can delegate one GPU for each process (and it doesn't allocate all of the memory and combine the two GPUs into one at the beginning.) However, my methods are currently yielding a CUDA_ERROR_NOT_INITIALIZED. 

**Describe the expected behavior** Each multiprocessing Process should be only able to see one GPU and be forced to use that: however, neither are being detected.

**Code to reproduce the issue**
```
import multiprocessing

class AlignProcess (multiprocessing.Process):
    def __init__(self, gpu ):
        multiprocessing.Process.__init__(self)
        self.gpu = gpu
      
def run(self):
    if self.gpu is not None:
        os.environ[""CUDA_VISIBLE_DEVICES""]=str(self.gpu - 1)

        import tensorflow as tf 
        session = tf.Session()
        session.run(tf.global_variables_initializer())
        session.close()


# Later on in code

AlignProcess(1).start()
```

**Other info / logs**

```
Using cuDNN version 7600 on context None
Mapped name None to device cuda: Tesla T4 (0000:00:04.0)
INFO:root:Working on recording /home/user/program/media/recordings/6.wav
Running source separation for recording: /home/user/program/media/recordings/6.wav
Testing...
WARNING:tensorflow:From /home/user/program/src/align/wavenet/Models/UnetAudioSeparator.py:99: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv1d instead.
WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-06-17 14:05:59.513204: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-06-17 14:05:59.518744: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000170000 Hz
2019-06-17 14:05:59.519588: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55ebf146ee30 executing computations on platform Host. Devices:
2019-06-17 14:05:59.519622: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-17 14:05:59.623164: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NOT_INITIALIZED: initialization error
2019-06-17 14:05:59.623244: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: wavenet-base-2gpu-t4-4
2019-06-17 14:05:59.623251: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: wavenet-base-2gpu-t4-4
2019-06-17 14:05:59.623412: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:192] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
2019-06-17 14:05:59.623465: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:196] kernel reported version is: 418.67.0
Num of variables64
WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
INFO:tensorflow:Restoring parameters from /home/user/program/src/align/wavenet/../../models_english/wavenet_full_44KHz/full_44KHz-236118
Using cuDNN version 7600 on context None
Pre-trained model restored for song prediction
Mapped name None to device cuda: Tesla T4 (0000:00:04.0)
INFO:root:Working on recording /home/user/program/media/recordings/7.wav
Running source separation for recording: /home/user/program/media/recordings/7.wav
Testing...
WARNING:tensorflow:From /home/user/program/src/align/wavenet/Models/UnetAudioSeparator.py:99: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv1d instead.
WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-06-17 14:06:04.528660: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-06-17 14:06:04.551547: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000170000 Hz
2019-06-17 14:06:04.552053: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55ebf3709e10 executing computations on platform Host. Devices:
2019-06-17 14:06:04.552076: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-17 14:06:04.670544: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NOT_INITIALIZED: initialization error
2019-06-17 14:06:04.670736: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: wavenet-base-2gpu-t4-4
2019-06-17 14:06:04.670788: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: wavenet-base-2gpu-t4-4
2019-06-17 14:06:04.670981: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:192] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
2019-06-17 14:06:04.671078: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:196] kernel reported version is: 418.67.0
Num of variables64
WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
INFO:tensorflow:Restoring parameters from /home/user/program/src/align/wavenet/../../models_english/wavenet_full_44KHz/full_44KHz-236118
Pre-trained model restored for song prediction

```
"
29874,I think Windows performance might be poor due to WDDM? tensorflow-gpu,"So personally I have very poor performance on windows when it comes to object detection. Doesn't matter if I build from source, pip, conda etc, it's about 5-10x slower on windows vs linux. 

I see sporadic reports across tensorflow and pytorch stating similar things. Some bugs confirmed, but with no follow up. 

I'm hoping someone on this project has access to a non consumer nvidia card. I think that's the titan series. None of the geforce cards will work (thanks nvidia). I ask you to do any of the object detection api tutorials, or even any custom implementation.  Test it on linux, then the same on windows. 

I'm hyper confident you will find a significant discrepancy between the two. Then enable TCC on your non consumer card, and see if the performance then becomes similar. 

I'm basing my assumption on this:
https://stackoverflow.com/questions/19944429/cuda-performance-penalty-when-running-in-windows

"
29872,[TF 2.0] categorical_column_with_vocabulary_list no longer usable with tf.functiion,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, slightly
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Fedora 30
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1
- Python version: 3.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

The initialization of the lookup table fails with:
```    
    TypeError: An op outside of the function building code is being passed
    a ""Graph"" tensor. It is possible to have Graph tensors
    leak out of the function building context by including a
    tf.init_scope in your function building code.
    For example, the following function will fail:
      @tf.function
      def has_init_scope():
        my_constant = tf.constant(1.)
        with tf.init_scope():
          added = my_constant * 2
    The graph tensor has name: dense_features/kind_embedding/kind_lookup/Const:0
```

**Describe the expected behavior**

As with v2.0.0-alpha.0, feature columns with constant vocabulary lists should be usable in tf.function graphs. 

**Code to reproduce the issue**

```py
import tensorflow as tf
import tensorflow.feature_column as fc

COLUMNS = [
  fc.embedding_column(
    fc.categorical_column_with_vocabulary_list('kind', ['a', 'b', 'c']),
    2
  )
]

feature_layer = tf.keras.layers.DenseFeatures(COLUMNS, trainable=False)

features = {
  'kind': tf.constant(['a', 'a', 'b', 'b', 'c', 'c']),
}

@tf.function
def func(features):
  return feature_layer(features)

func(features)
```
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**

<details>
<summary>Traceback</summary>
<pre>
Traceback (most recent call last):
  File ""bug.py"", line 21, in <module>
    print(func(features))
  File "".../venv/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py"", line 416, in __call__
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File "".../venv/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py"", line 359, in _initialize
    *args, **kwds))
  File "".../venv/lib/python3.5/site-packages/tensorflow/python/eager/function.py"", line 1360, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File "".../venv/lib/python3.5/site-packages/tensorflow/python/eager/function.py"", line 1648, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "".../venv/lib/python3.5/site-packages/tensorflow/python/eager/function.py"", line 1541, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "".../venv/lib/python3.5/site-packages/tensorflow/python/framework/func_graph.py"", line 716, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "".../venv/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py"", line 309, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "".../venv/lib/python3.5/site-packages/tensorflow/python/framework/func_graph.py"", line 706, in wrapper
    raise e.ag_error_metadata.to_exception(type(e))
TypeError: in converted code:

    bug.py:19 func  *
        return feature_layer(features)
    .../venv/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py:667 __call__
        outputs = call_fn(inputs, *args, **kwargs)
    .../venv/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column_v2.py:473 call  *
        tensor = column.get_dense_tensor(transformation_cache,
    .../venv/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column_v2.py:3123 get_dense_tensor
        transformation_cache, state_manager)
    .../venv/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column_v2.py:3714 get_sparse_tensors
        transformation_cache.get(self, state_manager), None)
    .../venv/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2562 get
        transformed = column.transform_feature(self, state_manager)
    .../venv/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column_v2.py:3692 transform_feature
        return self._transform_input_tensor(input_tensor)
    .../venv/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column_v2.py:3686 _transform_input_tensor
        name='{}_lookup'.format(self.key)).lookup(input_tensor)
    .../venv/lib/python3.5/site-packages/tensorflow/python/ops/lookup_ops.py:1388 index_table_from_tensor
        table = StaticHashTableV1(init, default_value)
    .../venv/lib/python3.5/site-packages/tensorflow/python/ops/lookup_ops.py:284 __init__
        super(StaticHashTable, self).__init__(default_value, initializer)
    .../venv/lib/python3.5/site-packages/tensorflow/python/ops/lookup_ops.py:174 __init__
        self._init_op = self._initialize()
    .../venv/lib/python3.5/site-packages/tensorflow/python/ops/lookup_ops.py:177 _initialize
        return self._initializer.initialize(self)
    .../venv/lib/python3.5/site-packages/tensorflow/python/ops/lookup_ops.py:424 initialize
        self._values)
    .../venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_lookup_ops.py:785 lookup_table_import_v2
        table_handle, keys, values, name=name, ctx=_ctx)
    .../venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_lookup_ops.py:820 lookup_table_import_v2_eager_fallback
        attrs=_attrs, ctx=_ctx, name=name)
    .../venv/lib/python3.5/site-packages/tensorflow/python/eager/execute.py:71 quick_execute
        raise e
    .../venv/lib/python3.5/site-packages/tensorflow/python/eager/execute.py:61 quick_execute
        num_outputs)

    TypeError: An op outside of the function building code is being passed
    a ""Graph"" tensor. It is possible to have Graph tensors
    leak out of the function building context by including a
    tf.init_scope in your function building code.
    For example, the following function will fail:
      @tf.function
      def has_init_scope():
        my_constant = tf.constant(1.)
        with tf.init_scope():
          added = my_constant * 2
    The graph tensor has name: dense_features/kind_embedding/kind_lookup/Const:0
</pre>
</details>

This bug was likely introduced by https://github.com/tensorflow/tensorflow/commit/2f0b7b1c2f5638a157af76383bd5a42bd3cc2938#diff-0972bc0b553e347b626ce302457971dfR383

Somewhat related issue https://github.com/tensorflow/tensorflow/issues/27086
"
29871,TF 2.0 Upgrade Script: Unable to handle the @ operator for matrix multiplication,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.0.0-beta1
- Python version: 3.7.3

**Describe the current behavior**
Running the tf_upgrade_v2 script with a file containing the @ operator results in an exception (see below).


**Code to reproduce the issue**
Using the file tmp.py with the following content:

import numpy as np
def mul(a, b):
     z = a @ b

Then run: 
 .\tf_upgrade_v2.exe --infile ""C:\any\path\tmp.py"" --outfile ""C:\another\path\tmp.py""

**Other info / logs**

Traceback (most recent call last):
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 1194, in visit
    super(AstAnnotator, self).visit(node)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 132, in visit
    super(BaseVisitor, self).visit(node)
  File ""C:\Program Files\Python37\lib\ast.py"", line 262, in visit
    return visitor(node)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 47, in wrapped
    f(self, node, *args, **kwargs)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 690, in visit_BinOp
    op_symbol = ast_constants.NODE_TYPE_TO_TOKENS[type(node.op)][0]
KeyError: <class '_ast.MatMult'>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Program Files\Python37\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""C:\Program Files\Python37\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\pzobel\PycharmProjects\TF2_0_Beta_Test\venv\Scripts\tf_upgrade_v2.exe\__main__.py"", line 9, in <module>
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\tensorflow\tools\compatibility\tf_upgrade_v2_main.py"", line 139, in main
    args.input_file, output_file, upgrade)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\tensorflow\tools\compatibility\tf_upgrade_v2_main.py"", line 40, in process_file
    upgrader.process_file(in_filename, out_filename)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\tensorflow\tools\compatibility\ast_edits.py"", line 900, in process_file
    temp_file)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\tensorflow\tools\compatibility\ast_edits.py"", line 960, in process_opened_file
    self.update_string_pasta("""".join(lines), in_filename))
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\tensorflow\tools\compatibility\ast_edits.py"", line 916, in update_string_pasta
    t = pasta.parse(text)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\__init__.py"", line 25, in parse
    annotator.visit(t)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 1194, in visit
    super(AstAnnotator, self).visit(node)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 132, in visit
    super(BaseVisitor, self).visit(node)
  File ""C:\Program Files\Python37\lib\ast.py"", line 262, in visit
    return visitor(node)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 47, in wrapped
    f(self, node, *args, **kwargs)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 220, in visit_Module
    self.generic_visit(node)
  File ""C:\Program Files\Python37\lib\ast.py"", line 270, in generic_visit
    self.visit(item)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 1194, in visit
    super(AstAnnotator, self).visit(node)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 132, in visit
    super(BaseVisitor, self).visit(node)
  File ""C:\Program Files\Python37\lib\ast.py"", line 262, in visit
    return visitor(node)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 95, in wrapped
    f(self, node, *args, **kwargs)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 411, in visit_FunctionDef
    self.visit(stmt)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 1194, in visit
    super(AstAnnotator, self).visit(node)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 132, in visit
    super(BaseVisitor, self).visit(node)
  File ""C:\Program Files\Python37\lib\ast.py"", line 262, in visit
    return visitor(node)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 47, in wrapped
    f(self, node, *args, **kwargs)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 530, in visit_Assign
    self.visit(node.value)
  File ""c:\users\pzobel\pycharmprojects\tf2_0_beta_test\venv\lib\site-packages\pasta\base\annotate.py"", line 1196, in visit
    raise AnnotationError(e)
pasta.base.annotate.AnnotationError: <class '_ast.MatMult'>
"
29870,"Use Tensorflow like Numpy, disable gradients entirely","I thought about using tensorflow for occasions where I have used numpy so far.

Most of the time gradients take up the most memory when doing ""NN"" things with tensorflow.  I was wondering if Tensorflow (v 2.0) always collects gradients in the background, even when I don't  use them.

And if that is the case, if there is a way to disable gradients entirely in order to conserve memory.

Does Tensorflow v2 only compute/store intermediate gradients when using operations inside `tf.GradientTape`? Or does tf.GradientTape just ""record"" or ""map"" to them?

I didn't think this is a Stackoverflow issue, as if this is indeed the case it might be a feature request."
29869,Bug in tf.einsum - Returns different values from np.einsum for identical parameters,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Binary (Anaconda)
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7.3
- CUDA/cuDNN version: 10.0/7.6.0
- GPU model and memory: NVIDIA Titan X (Pascal), 12 GB

**Describe the current behavior**

`tf.einsum` returns buggy values compared to `np.einsum` for identical parameters. Here is the current output (please find code below):

```
np: 8.610251426696777
tf: 0.0
```

Please also note that the same code works as expected when running on the CPU. It also works correctly on the GPU in TF 1.12.0, CUDA/cuDNN 9.0/7.3.1 and Python 3.6.8.

**Describe the expected behavior**

Here is the expected output:

```
np: 8.610251426696777
tf: 8.610251426696777
```

**Code to reproduce the issue**

```
from __future__ import (
    absolute_import,
    division,
    print_function
)

import tensorflow as tf
import numpy as np

tf.enable_eager_execution()

einsum_string = ""bijk,bijk->bij""

# load values
S_h_numpy = np.load(""./S_h.npy"")
S_h = tf.convert_to_tensor(S_h_numpy, dtype=tf.float32)

h_numpy = np.load(""./h.npy"")
h = tf.convert_to_tensor(
    h_numpy,
    dtype=tf.float32
)

# perform einsum
ht_S_h_numpy = np.einsum(einsum_string, h_numpy, S_h_numpy)
ht_S_h = tf.einsum(einsum_string, h, S_h)

print(""np: {np_val}\ntf: {tf_val}"".format(
    np_val=ht_S_h_numpy[2, 191, 191],
    tf_val=ht_S_h[2, 191, 191],
))
```

**Other info / logs**

Here are the input tensors used in the example: [input_tensors.zip](https://github.com/tensorflow/tensorflow/files/3296468/input_tensors.zip).

The tensors are of shape (4, 192, 192, 2). I could not choose a smaller example because the buggy values appear only in part of the second and all of the following batch items. The bug therefore seems to be connected to the size of the input.

"
29868,Typo in Tensorflow Core 2.0b's Advanced Tutorial=>Loading data=>Building an image input pipeline,"## URL(s) with the issue:
https://www.tensorflow.org/beta/tutorials/load_data/images#load_and_format_the_images

## Description of issue (what needs changing):
Under ""Load and format the images"" section, the original code below fails to run since it uses a variable `img_path`, which should be `image_path` instead.

```python
import matplotlib.pyplot as plt

image_path = all_image_paths[0]
label = all_image_labels[0]

plt.imshow(load_and_preprocess_image(img_path))
plt.grid(False)
plt.xlabel(caption_image(img_path))
plt.title(label_names[label].title())
print()
```

### Clear description
This is a simple typo and needs to be fixed.

### Correct links
Not related.

### Parameters defined
Not related.

### Returns defined
Not related.

### Raises listed and defined
Not related.

### Usage example
Not related.

### Request visuals, if applicable
Not related.

### Submit a pull request?
Not this time.
"
29867,tf.range with tf.constant(int32) limit and dtype=tf.float32 fails,"Tensorflow Version: tf-nightly-gpu-2.0-preview==2.0.0.dev20190611 or CPU equivalent (linux)

Also tested on: tf-nightly-2.0-preview==2.0.0.dev20190607 (windows)

Try running the following two:

```python
tf.range(tf.constant(102), dtype=tf.float32) # FAILS
tf.range(102, dtype=tf.float32) # WORKS
```

The first one fails with
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-2-145c4a277289> in <module>
----> 1 tf.range(tf.constant(102), dtype=tf.float32)

c:\progams\miniconda\envs\tf2-preview-cpu\lib\site-packages\tensorflow\python\ops\math_ops.py in range(start, limit, delta, dtype, name)
   1317   with ops.name_scope(name, ""Range"", [start, limit, delta]) as name:
   1318     start = ops.convert_to_tensor(start, dtype=dtype, name=""start"")
-> 1319     limit = ops.convert_to_tensor(limit, dtype=dtype, name=""limit"")
   1320     delta = ops.convert_to_tensor(delta, dtype=dtype, name=""delta"")
   1321 

c:\progams\miniconda\envs\tf2-preview-cpu\lib\site-packages\tensorflow\python\framework\ops.py in convert_to_tensor(value, dtype, name, preferred_dtype, dtype_hint)
   1098   preferred_dtype = deprecation.deprecated_argument_lookup(
   1099       ""dtype_hint"", dtype_hint, ""preferred_dtype"", preferred_dtype)
-> 1100   return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
   1101 
   1102 

c:\progams\miniconda\envs\tf2-preview-cpu\lib\site-packages\tensorflow\python\framework\ops.py in convert_to_tensor_v2(value, dtype, dtype_hint, name)
   1156       name=name,
   1157       preferred_dtype=dtype_hint,
-> 1158       as_ref=False)
   1159 
   1160 

c:\progams\miniconda\envs\tf2-preview-cpu\lib\site-packages\tensorflow\python\framework\ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)
   1178       if dtype is not None:
   1179         dtype = dtypes.as_dtype(dtype)
-> 1180         value = _TensorTensorConversionFunction(value, dtype=dtype)
   1181       return value
   1182     else:

c:\progams\miniconda\envs\tf2-preview-cpu\lib\site-packages\tensorflow\python\framework\ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)
   1034     raise ValueError(
   1035         ""Tensor conversion requested dtype %s for Tensor with dtype %s: %r"" %
-> 1036         (dtype.name, t.dtype.name, str(t)))
   1037   return t
   1038 tensor_conversion_registry.register_tensor_conversion_function(

ValueError: Tensor conversion requested dtype float32 for Tensor with dtype int32: 'tf.Tensor(102, shape=(), dtype=int32)'
```"
29866,Limited tf.compat.v2.summary API due to missing TensorBoard installation.,"I came across this warning after updating to the las nightly release.
Any idea on how to fix it?"
29865,Keras fit with mixed dataset/ndarray data results in batch_size arg error,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 & macOS 10.14.5
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.14.0-rc0-55-g1b365ca304 1.14.0-rc1
- Python version: 3.6.8 & 3.7.2
- CUDA/cuDNN version: none
- GPU model and memory: none

**Describe the current behavior**

Combining tf.data.Dataset with tf.keras.Model fails since 1.14.0rc0 when using a dataset for training but a numpy array for validation data. Logs with errors for both 1.14 and 1.13 below.

**Describe the expected behavior**

Being able to use a dataset only for training but a numpy array for validation data.

**Code to reproduce the issue**

```Python
import tensorflow as tf
import numpy as np

data = np.random.randn(1000, 10)
targets = np.random.randn(1000, 1)
ds = tf.data.Dataset.from_tensor_slices(data).batch(32)

model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(32, input_dim=10))
model.add(tf.keras.layers.Dense(32))
model.add(tf.keras.layers.Dense(1))

model.compile(optimizer=""rmsprop"", loss=""mse"")
model.fit(ds, steps_per_epoch=10, validation_data=(data, targets), batch_size=32)
```

**Other info / logs**

**Behaviour using 1.14.0rc1:**

Without `batch_size=32` set:

```Bash
% python bug.py
[...]
1/10 [==>...........................] - ETA: 1s - loss: 2.3122
Traceback (most recent call last):
  File ""tensorflow_bug.py"", line 14, in <module>
    model.fit(ds, steps_per_epoch=10, validation_data=(data, targets))
  File ""/Users/ahoereth/repos/AutoECG/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 780, in fit
    steps_name='steps_per_epoch')
  File ""/Users/ahoereth/repos/AutoECG/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 409, in model_iteration
    steps_name='validation_steps')
  File ""/Users/ahoereth/repos/AutoECG/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 335, in model_iteration
    batches = make_batches(num_samples_or_steps, batch_size)
  File ""/Users/ahoereth/repos/AutoECG/.venv/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 493, in make_batches
    num_batches = int(np.ceil(size / float(batch_size)))
TypeError: float() argument must be a string or a number, not 'NoneType'
```

With `batch_size=32` set:

```Bash
% python tensorflow_bug.py
[...]
Traceback (most recent call last):
  File ""tensorflow_bug.py"", line 14, in <module>
    model.fit(ds, steps_per_epoch=10, validation_data=(data, targets), batch_size=32)
  File ""/Users/ahoereth/repos/AutoECG/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 652, in fit
    batch_size, steps_per_epoch, x)
  File ""/Users/ahoereth/repos/AutoECG/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 1873, in _validate_or_infer_batch_size
    raise ValueError('The `batch_size` argument must not be specified when'
ValueError: The `batch_size` argument must not be specified when using dataset as an input.
```

**Behaviour using 1.13.1:**

Without `batch_size=32` set:

```Bash
% python bug.py
[...]
1/10 [==>...........................] - ETA: 2s - loss: 3.0703
Traceback (most recent call last):
  File ""tensorflow_bug.py"", line 14, in <module>
    model.fit(ds, steps_per_epoch=10, validation_data=(data, targets))
  File ""/Users/ahoereth/repos/AutoECG/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 880, in fit
    validation_steps=validation_steps)
  File ""/Users/ahoereth/repos/AutoECG/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 364, in model_iteration
    validation_in_fit=True)
  File ""/Users/ahoereth/repos/AutoECG/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 301, in model_iteration
    batches = make_batches(num_samples_or_steps, batch_size)
  File ""/Users/ahoereth/repos/AutoECG/.venv/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 488, in make_batches
    num_batches = int(np.ceil(size / float(batch_size)))
TypeError: float() argument must be a string or a number, not 'NoneType'
```

With `batch_size=32` set:

```Bash
% python bug.py
[...]
10/10 [==============================] - 0s 21ms/step - loss: 1.0369 - val_loss: 1.1500
```"
29864,tflite invoke function crash,"I came cross a strange issues only occurred on HuaWei Phone. 
For phone infomation with this image.
![image](https://user-images.githubusercontent.com/17869361/59587579-26572a00-9118-11e9-8b20-67a14a5c8f08.png)

At first time run inference no crash, It is always crash at second time. below is crash info.
![image](https://user-images.githubusercontent.com/17869361/59587879-e3498680-9118-11e9-8fe6-bf97e2e2301b.png)

Below is processed crash info with ndk-stack, but unable to locate in tensorflow source as build tflite from source with no debug symbols and i do not know how to build with debug symbol
![image](https://user-images.githubusercontent.com/17869361/59588620-9a92cd00-911a-11e9-9fb9-ba68baa06f52.png)

I have tried many methods for building tflite with debug symbol but not successed
For example
1ã€ bazel build -c dbg --strip=never --compilation_mode=dbg --per_file_copt=//tensorflow/lite/.*\.cc@-g,-O0  //tensorflow/lite:libtensorflowLite.so --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cxxopt=""-std=c++11""
with -c dbg --strip=never  --compilation_mode=dbg

![image](https://user-images.githubusercontent.com/17869361/59588889-345a7a00-911b-11e9-9424-c3cfcdd87d99.png)
Crash occurred at 62 line
It crashed at second time only on HuaWei Phone. Other phones and ios has no crash.


ps:This issue finally crashed at 277 line with below image
![image](https://user-images.githubusercontent.com/17869361/59751454-217aad80-92b3-11e9-8a98-155da7e58c92.png)

I guess the bias_data address is unavaible
![image](https://user-images.githubusercontent.com/17869361/59751423-10ca3780-92b3-11e9-971c-99ec5e074624.png)
"
29863,Error when using unique_with_counts function. ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

On Windows Subsystem for Linux. Python 3.6.7. Tensorflow 1.13.1.
Code:
```
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=0)
print(X_train.shape)
print(X_test.shape)
x = tf.placeholder(float, shape=X_train.shape)
y = tf.placeholder(float, shape=X_test.shape[1:])
computeL0Dist = tf.count_nonzero(x - y, axis=[1])
find_k_closest_tr_products = tf.contrib.framework.argsort(computeL0Dist, direction='ASCENDING')
find_labels_k_closest_tr_products = tf.gather(y_train, find_k_closest_tr_products[0:paramk])
print('SHAPE', find_labels_k_closest_tr_products.shape)
find_u_labels, find_idex, find_counts = tf.unique_with_counts(find_labels_k_closest_tr_products)
find_predicted_label = tf.gather(find_u_labels, tf.argmax(find_counts))
```
Error:
```
(49, 1611)
(49, 1611)

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

2019-06-17 11:51:40.240971: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-17 11:51:40.248082: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1800000000 Hz
2019-06-17 11:51:40.250639: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x377c490 executing computations on platform Host. Devices:
2019-06-17 11:51:40.252480: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Traceback (most recent call last):
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1334, in _do_call
    return fn(*args)
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1317, in _run_fn
    self._extend_graph()
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1352, in _extend_graph
    tf_session.ExtendSession(self._session)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'UniqueWithCounts' used by {{node UniqueWithCounts}}with these attrs: [T=DT_BOOL, out_idx=DT_INT32]
Registered devices: [CPU, XLA_CPU]
Registered kernels:
  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT32]

         [[{{node UniqueWithCounts}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""knn.py"", line 101, in <module>
    predicted_label = sess.run([find_predicted_label], feed_dict={x:X_train, y:X_test[i_te_p]})
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 929, in run
    run_metadata_ptr)
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1328, in _do_run
    run_metadata)
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'UniqueWithCounts' used by node UniqueWithCounts (defined at knn.py:91) with these attrs: [T=DT_BOOL, out_idx=DT_INT32]
Registered devices: [CPU, XLA_CPU]
Registered kernels:
  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT32]

         [[node UniqueWithCounts (defined at knn.py:91) ]]

Caused by op 'UniqueWithCounts', defined at:
  File ""knn.py"", line 91, in <module>
    find_u_labels, find_idex, find_counts = tf.unique_with_counts(find_labels_k_closest_tr_products)
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 1450, in unique_with_counts
    return gen_array_ops.unique_with_counts(x, out_idx, name)
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 10543, in unique_with_counts
    ""UniqueWithCounts"", x=x, out_idx=out_idx, name=name)
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'UniqueWithCounts' used by node UniqueWithCounts (defined at knn.py:91) with these attrs: [T=DT_BOOL, out_idx=DT_INT32]Registered devices: [CPU, XLA_CPU]
Registered kernels:
  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT32]

         [[node UniqueWithCounts (defined at knn.py:91) ]]
```

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29862,[TF 2.0] Converting keras model to estimator ignores data-types,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
ProductName:	Mac OS X
ProductVersion:	10.14.2
BuildVersion:	18C54
- TensorFlow installed from (source or binary): pip install ...
- TensorFlow version (use command below): v1.12.1-3259-gf59745a381 2.0.0-beta0
- Python version: 3.6.8

**Describe the current behavior**
When converting Keras model to estimator it converts all integer inputs to floats or doubles.
This will result in data-type errors in the converted estimator.  

I am not entirely sure if this is a bug or ""feature"" because this function is indeed called in the conversion: https://github.com/tensorflow/estimator/blob/c956dd32561bac645a1cd870d3c8cfe8e9fe969b/tensorflow_estimator/python/estimator/keras.py#L62

However, this is blocking using integer-inputs in the converted estimator.

**Describe the expected behavior**
Input-data-types are preserved when converting keras-model to estimator.

**Code to reproduce the issue**
Small example to reproduce the issue:

```
import numpy as np
import tensorflow as tf
from tensorflow.python.keras import layers
from tensorflow.python.keras.estimator import model_to_estimator_v2

x_shape = (3,)
n_class = 5
batch_size = 10

x = layers.Input(shape=x_shape, name=""x"", dtype=tf.int64)

class StupidLayer(layers.Layer):
    def build(self, input_shape):
        self.y = tf.random.poisson(
            lam=10, shape=(batch_size,) + x_shape, dtype=tf.int64
        )
        super().build(input_shape)

    def call(self, inputs, **kwargs):
        return tf.cast(inputs * self.y, tf.float32)

y = StupidLayer()(x)

model = tf.keras.Model(inputs=x, outputs=y)

X = np.random.randint(50, size=(batch_size,) + x_shape, dtype=""int64"")

model.compile(optimizer=""sgd"", loss=""categorical_crossentropy"")
model.predict(X)

tf_estimator = model_to_estimator_v2(keras_model=model)
next(tf_estimator.predict(lambda: X))
```

Because input is converted to float, last line results in 
```
TypeError: Input 'y' of 'Mul' Op has type int64 that does not match type float32 of argument 'x'.
```
"
29861,attention_ocr,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
29860,[TF 2.0 API Docs] tf.keras.layers.GRU,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRU#properties

### Clear description

Initialising float variables using 0. rather than 0.0

dropout=0.,
recurrent_dropout=0.,

### Parameters defined
   
 time_major Argument not documented.

### Raises listed and defined
No

### Usage example
No"
29859,[TF 2.0 API Docs] tf.errors.DeadlineExceededError,"## System Information
Tensorflow version: 2.0

## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/errors/DeadlineExceededError

## Description of issue (what needs changing):

### Clear description
The description could be better; needs more content for clarification

### Usage example
No usage example defined  

### Submit a pull request?
No
"
29858,[TF 2.0 API Docs] tf.dynamic_stitch,"## System Information
Tensorflow version: 2.0

## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/dynamic_stitch

## Description of issue (what needs changing):

### Raises listed and defined
No errors have been defined

### Submit a pull request?
"
29857,How tf.image.extract_image_patches works ? ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04
- TensorFlow installed from (source or binary): Anaconda for 1.13.1 and Pip for TF 2 Beta
- TensorFlow version (use command below): TF 1.13.1 and TF 2 Beta
- Python version: 3.6.8
- CUDA/cuDNN version: CUDA 10 / cuDNN 7.6
- GPU model and memory: GTX 1080 , 11GB

**Describe the current behavior**
I want to extract a large gray scale image from (1250 x 1250) to patches (512 x 512). So I tried to run tf.image.extract_image_patches on both versions: [TF 1.13.1](https://www.tensorflow.org/api_docs/python/tf/image/extract_image_patches) and [TF 2 Beta](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/extract_patches) follow this [tutorial](https://github.com/lixiangchun/mynotebook/blob/master/machine_learning/Extract%20image%20patches.md).
My parameters:
```
my_input_image # shape = ( batch , size_x, size_y)
my_input_image = tf.expand_dims(my_input_image ,-1)  #add 1 more ""depth"" channel as the last axis 
ksizes = [1, 512, 512, 1] #size of output patch
strides = [1, 256, 256, 1] # Stride
rates = [1, 1, 1, 1]  #Rate
padding='SAME' # I want to have zero padding when the stride go out of my_input_image 

image_patches = tf.image.extract_patches(input_big_pic, ksizes, strides, rates, padding)


image_patches.shape  # => TensorShape([125, 5, 5, 262144]) . Why we have 5 pictures in a row?

patch1 = image_patches[0,0,0,] # Get the 1st patch
patch1 = tf.reshape(patch1, [512, 512, 1]) # Reshape to the correct shape
patch1 = tf.squeeze(patch1) # Remove the depth channel
plt.imshow(patch1)
```

 tf.image.extract_patches will output a matrix image patches 5x5. 
The zero paddings = 143 on each edge.
I don't understand why we have 5 pictures in a row?  
How tf.image.extract_patches works ?



**Describe the expected behavior**
It should be 4x4 matrix image patches with zero paddings = 15 on each edge.
Denote **n** is the number of stride steps.
The number image patchs = **n** + 1

Input_size = 1250
Output_size= 512
Stride = 256
Padding: 

We have an equation: 
`2*Padding + Input_size = n*Stride + Output`        **(1)**
We don't know how many zero padding we need. So:
`Input_size <= n*Stride + Output`
`1250 <= n*256 + 512`
Then 2.88 <= **n** . 
We choose the nearest interger **n** = 3.
**(1)** => zero padding = 15

Will will have 4x4 matrix image patches with zero paddings = 15 on each edge.

Please correct me if my calculation is wrong.
"
29856,tf.keras.layers.UpSampling2D(interpolation='bilinear') has a smearing defect on the right & bottom edges,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I've provided a link to a Colab notebook demonstrating the issue below, comparing keras upsampling to what it should look like with a correct implementation as seen in tf.image.resize.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-beta0-16-g1d91213fe7
- Python version: 3
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Upsampling using tf.keras.layers.UpSampling2D() results in unnatural smearing of the right and bottom edges of the image.  This problem is amplified when the upsampling is repeated.

**Describe the expected behavior**
Keras layers should use sensible default behaviour and not have this smearing issue.  This causes serious problems for autoencoders, GANs, and cost months of time.  Correct behaviour is seen with tf.image.resize(o, size=size, method=tf.image.ResizeMethod.BILINEAR).  Keras upsampling should use this as the default instead of the current defective behaviour.  Note: In TensorFlow 1.x, the tf.image.resize method had an 'align_corners' parameter that toggled between defective and proper behaviour and was set to False (defective behaviour) by default.  In TensorFlow 2, this parameter has been removed and the correct behaviour (align_corners=True behaviour) is now the default.  The keras layer should follow the same path.

**Code to reproduce the issue**
Here is a Colab notebook that demonstrates the issue:
https://colab.research.google.com/drive/1rgCzJcMo4DN_9_hutr9l2vSrTRPfcd6K

**Other info / logs**
"
29855,[TF 2.0 API Docs] https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/MaxPool1D,1.	The parameters pool_function and input_spec in https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/pooling.py#L59 where not defined the documentation https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/MaxPool1D and no return where defined.
29854,[TF 2.0 API Docs] tf.dynamic_partition,"## System information
Tensorflow version: 2.0

## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/dynamic_partition

## Description of issue (what needs changing):

### Raises listed and defined
No errors have been defined

### Submit a pull request?
Yes
"
29853,[TF 2.0 API Docs] tf.div_no_nan,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/div_no_nan

## Description of issue (what needs changing):

The web page corresponding to the link does not exist. Error 404

### Correct links

The link is not correct. The page doesn't exist
"
29852,[TF 2.0 API Docs] Documentation describes non existing symbol,"https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/debugging/check_numerics

This link gives a description of a symbol in a module which is supposed to be at https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/python/ops

But the module doesn't seem to exist"
29851,[TF 2.0 API Docs] tf.data.experimental.unbatch,"## System information
Tensorflow version: 2.0

## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/unbatch

## Description of issue (what needs changing):
The description needs more content, as no description has been provided for the available functions.
No recommendations have been given on when and when not to use this symbol

### Parameters defined
No parameters have been defined

### Raises listed and defined
No errors defined

### Request visuals, if applicable
No visuals, the content will be clarified if visuals are provided

### Others
This symbol is deprecated, am not sure if this review will  still be useful

### Submit a pull request?
No
"
29850,[TF 2.0 API Docs] tf.data.experimental.rejection_resample,"## System  Information
Tensorflow version: 2.0

## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/rejection_resample

## Description of issue (what needs changing):
No recommendations of when and when not to use this symbol have been provided.
The description is not clear, it needs more content

### Raises listed and defined
No raises listed

### Usage example
No usage example has been provided

### Request visuals, if applicable
No visuals, but they will be very useful if present

### Submit a pull request? 
No"
29849,[TF 2.0 API Docs] tf.debugging.assert_type,"## URL with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/debugging/assert_type

## Description of issue (what needs changing):

The API symbol doesn't contain a complete, self-contained, coherent, appropriately formatted, and well-documented usage example code sample and the return values aren't defined

### Usage example

No usage example

### Returns defined

The return values aren't defined
"
29848,[TF 2.0 API Docs] tf.data.experimental.prefetch_to_device,"## URL with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/prefetch_to_device

## Description of issue (what needs changing):

The API symbol doesn't contain a complete, self-contained, coherent, appropriately formatted, and well-documented code sample.

### Usage example

No usage example"
29847,[TF 2.0 API Docs] tf.errors.ResourceExhaustedError,"## URL with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/errors/ResourceExhaustedError

## Description of issue (what needs changing):

The API symbol doesn't contain a complete, self-contained, coherent, appropriately formatted, and well-documented code sample.

### Usage example

No usage example"
29846,[TF 2.0 API Docs] tf.errors.ResourceExhaustedError,"## URL with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/errors/ResourceExhaustedError

## Description of issue (what needs changing):

The API symbol doesn't contain a complete, self-contained, coherent, appropriately formatted, and well-documented code sample.

### Usage example

No usage example?"
29845,Build issue  Bazel,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: MacOS Mojave 10.14.5
- TensorFlow installed from (source or binary): binary
- TensorFlow version:2.0.0-beta1 
- Python version:3.6
- Installed using virtualenv? pip? conda?:No
- Bazel version (if compiling from source):0.26.1
- GCC/Compiler version (if compiling from source):4.2.1
- CUDA/cuDNN version:No
- GPU model and memory: 4G ram



**Describe the problem**
I face these errors so what's solution ? 
```
Kotozs-MacBook-Air-6:tensorflow kotoz$ ./configure 
WARNING: Running Bazel server needs to be killed, because the startup options are different.
WARNING: Waiting for server process to terminate (waited 5 seconds, waiting at most 60)
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
You have bazel 0.26.1 installed.
Please specify the location of python. [Default is /usr/local/opt/python@2/bin/python2.7]: /usr/local/opt/python@3/bin/python3.6


Found possible Python library paths:
  /usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages
Please input the desired Python library path to use.  Default is [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages]

Do you wish to build TensorFlow with XLA JIT support? [y/N]: N
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: N
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: N
No CUDA support will be enabled for TensorFlow.

Do you wish to download a fresh release of clang? (Experimental) [y/N]: N
Clang will not be downloaded.

Do you wish to build TensorFlow with MPI support? [y/N]: N
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N
Not configuring the WORKSPACE for Android builds.

Do you wish to build TensorFlow with iOS support? [y/N]: N
No iOS support will be enabled for TensorFlow.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=gdr         	# Build with GDR support.
	--config=verbs       	# Build with libverbs support.
	--config=ngraph      	# Build with Intel nGraph support.
	--config=numa        	# Build with NUMA support.
	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
	--config=v2          	# Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
	--config=noaws       	# Disable AWS S3 filesystem support.
	--config=nogcp       	# Disable GCP support.
	--config=nohdfs      	# Disable HDFS support.
	--config=noignite    	# Disable Apache Ignite support.
	--config=nokafka     	# Disable Apache Kafka support.
	--config=nonccl      	# Disable NVIDIA NCCL support.
Configuration finished
Kotozs-MacBook-Air-6:tensorflow kotoz$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=89
INFO: Reading rc options for 'build' from /Users/kotoz/Downloads/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
INFO: Reading rc options for 'build' from /Users/kotoz/Downloads/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/local/opt/python@3/bin/python3.6 --action_env PYTHON_LIB_PATH=/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages --python_path=/usr/local/opt/python@3/bin/python3.6 --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:opt in file /Users/kotoz/Downloads/tensorflow/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true
INFO: Call stack for the definition of repository 'local_config_python' which is a python_configure (rule definition at /Users/kotoz/Downloads/tensorflow/third_party/py/python_configure.bzl:346:20):
 - /Users/kotoz/Downloads/tensorflow/tensorflow/workspace.bzl:69:5
 - /Users/kotoz/Downloads/tensorflow/WORKSPACE:94:1
ERROR: An error occurred during the fetch of repository 'local_config_python':
   Traceback (most recent call last):
	File ""/Users/kotoz/Downloads/tensorflow/third_party/py/python_configure.bzl"", line 344
		_create_local_python_repository(repository_ctx)
	File ""/Users/kotoz/Downloads/tensorflow/third_party/py/python_configure.bzl"", line 296, in _create_local_python_repository
		_get_numpy_include(repository_ctx, python_bin)
	File ""/Users/kotoz/Downloads/tensorflow/third_party/py/python_configure.bzl"", line 276, in _get_numpy_include
		_execute(repository_ctx, [python_bin, ""-c"",...""], <2 more arguments>)
	File ""/Users/kotoz/Downloads/tensorflow/third_party/py/python_configure.bzl"", line 56, in _execute
		_fail(""\n"".join([error_msg.strip() if ... """"]))
	File ""/Users/kotoz/Downloads/tensorflow/third_party/py/python_configure.bzl"", line 27, in _fail
		fail((""%sPython Configuration Error:%...)))
Python Configuration Error: Problem getting numpy include path.
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ModuleNotFoundError: No module named 'numpy'
Is numpy installed?
INFO: Call stack for the definition of repository 'jpeg' which is a third_party_http_archive (rule definition at /Users/kotoz/Downloads/tensorflow/third_party/repo.bzl:206:28):
 - /Users/kotoz/Downloads/tensorflow/third_party/jpeg/workspace.bzl:6:5
 - /Users/kotoz/Downloads/tensorflow/tensorflow/workspace.bzl:45:5
 - /Users/kotoz/Downloads/tensorflow/tensorflow/workspace.bzl:73:5
 - /Users/kotoz/Downloads/tensorflow/WORKSPACE:94:1
INFO: Call stack for the definition of repository 'pcre' which is a tf_http_archive (rule definition at /Users/kotoz/Downloads/tensorflow/third_party/repo.bzl:126:19):
 - /Users/kotoz/Downloads/tensorflow/tensorflow/workspace.bzl:449:5
 - /Users/kotoz/Downloads/tensorflow/WORKSPACE:94:1
ERROR: /Users/kotoz/Downloads/tensorflow/third_party/py/numpy/BUILD:11:1: no such package '@local_config_python//': Traceback (most recent call last):
	File ""/Users/kotoz/Downloads/tensorflow/third_party/py/python_configure.bzl"", line 344
		_create_local_python_repository(repository_ctx)
	File ""/Users/kotoz/Downloads/tensorflow/third_party/py/python_configure.bzl"", line 296, in _create_local_python_repository
		_get_numpy_include(repository_ctx, python_bin)
	File ""/Users/kotoz/Downloads/tensorflow/third_party/py/python_configure.bzl"", line 276, in _get_numpy_include
		_execute(repository_ctx, [python_bin, ""-c"",...""], <2 more arguments>)
	File ""/Users/kotoz/Downloads/tensorflow/third_party/py/python_configure.bzl"", line 56, in _execute
		_fail(""\n"".join([error_msg.strip() if ... """"]))
	File ""/Users/kotoz/Downloads/tensorflow/third_party/py/python_configure.bzl"", line 27, in _fail
		fail((""%sPython Configuration Error:%...)))
Python Configuration Error: Problem getting numpy include path.
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ModuleNotFoundError: No module named 'numpy'
Is numpy installed?
 and referenced by '//third_party/py/numpy:headers'
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed
INFO: Elapsed time: 14.536s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (143 packages loaded, 3114 targets configur\
ed)
    Fetching @local_config_xcode; fetching 7s
Kotozs-MacBook-Air-6:tensorflow kotoz$ 
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached."
29844,tf.image.decode_and_crop_jpeg parameter crop_window changed,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/io/decode_and_crop_jpeg

## Description of issue :
Documentation of parameter type - crop_window

### Clear description
The type of parameter is list of int and in the documentation it says:

>     crop_window: A `Tensor` of type `int32`.

"
29843,beta-1: tf.keras.layers.Conv2D with dilation_rate > 1 returns tensor with shape None,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): tensorflow-gpu==2.0.0-beta1 colab
- TensorFlow version (use command below):tensorflow-gpu==2.0.0-beta1
- Python version: pip3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: colab
- GPU model and memory:


**Describe the current behavior**
if tf.keras.layers.Conv2D is used with dilation_rate param > 1 it returns tensors with shape None!
"
29842,native python logging broken with TF 1.14,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9.0 stretch
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): v1.12.1-2376-gf5ce1c00d4 1.14.0-rc0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0/7.6
- GPU model and memory: NVIDIA Titan X (Pascal) 12Gb

**Describe the current behavior**
logging from the python's standard library stopped working in TF 1.14. Log file is not created and the output supposed to be written there is instead redirected to the stdout, which results in each logging message appear twice in the console.

**Describe the expected behavior**
When run on TF 1.12 , log.txt is created and the logging is being recorded correctly.

**Code to reproduce the issue**

```python
import logging
import tensorflow as tf


def main(_):
    FORMAT = '%(asctime)-15s %(message)s'
    logging.basicConfig(filename='log.txt', filemode='w',
                        datefmt='%Y-%m-%d %H:%M:%S',
                        level=logging.INFO, format=FORMAT)
    console = logging.StreamHandler()
    console.setLevel(logging.INFO)
    logging.getLogger('').addHandler(console)

    sess = tf.Session()

    logging.info(""test write"")


if __name__ == '__main__':
    tf.app.run()
```

This yields the following output:

```
2019-06-16 17:54:24.047410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10711 MB memory) -> physical GPU (device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1)
I0616 17:54:24.051054 140454010144128 test_logging.py:15] test write
test write
```

Notice that `test write` appears twice in the output. And log.txt is not created. When run with TF 1.12 this code snippets behaves as expected."
29841,tf.keras.layers.Conv3DTranspose ignores dilation_rate parameter,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): N/A
- TensorFlow version (use command below): 1.13
- Python version: Any
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

 `Conv3DTranspose` layer ignores `dilation_rate` parameter. The shape of the output tensor stays the same regardless of the `dilation_rate` parameter.

**Describe the expected behavior**

 `Conv3DTranspose` should behave like `Conv2DTranspose` and handle dilated transposed convolution. Note that `Conv3D` handles dilated convolutions all right.

**Code to reproduce the issue**

    import tensorflow as tf
    import numpy as np
    from tensorflow.keras.layers import Conv3DTranspose

    sess = tf.Session()
    x = tf.placeholder(tf.float32, shape=(None,3,3,3,1))
    layer = Conv3DTranspose(filters=1, kernel_size=3, dilation_rate=2)
    result = layer(x)
    sess.run(tf.global_variables_initializer())
    output = sess.run(result, {x:np.ones((2,3,3,3,1))})

    ## Expected output shape = (2,7,7,7,1)
    ## Actual output shape = (2,5,5,5,1)

**Other info / logs**
The problematic code seems to be here:
https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/keras/layers/convolutional.py#L890
"
29840,Bigger Than Memory ops should automatically fallback to RAM and/or Disc in tf-gpu,"**System information**
- TensorFlow version (you are using): 1.14rc 
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
We built an Atomic Transformer with Keras, and if we try to simulate too many atoms, like a big antibody or enzyme with 50,000 atoms, or a big metabolic network in system biology, it crashes because the GPU memory of the 1070ti fills up and there is no backup plan for when that happens. 

I believe this is an issue for many many advanced uses of TF because we sometimes need to process ""BIG DATA"" larger than the VRAM and Dask is the ONLY available option, and Dask is often extremely slow and still crashes, plus we have to convert tensors into dask arrays, it's a huge hassle. Just imagine TF-GPU intelligently predicted memory usage and used cpu/ram/drive resources as needed.

Obviously, this should print performance warnings in the console, and would be slower, but at least there should be some option for tf-gpu to try to keep working in cases where the workload doesn't fit in VRAM

**Will this change the current api? How?**
TF-GPU would either automatically scale beyond GPU / TPU memory, or there would be some way to tell it to do this in a python script. Like tf.enable_larger_than_memory() 

**Who will benefit with this feature?**
Everyone who pushes TF-GPU to the breaking point

**Any Other info.**
UBUNTU 16.04 NVIDIA GTX 1070Ti "
29839,TPU train_on_batch stride size error,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.5
- GPU model and memory: TPU v3-8

**Describe the current behavior**

Code and data which **runs fine on CPU**, _throws error on TPU_. This only happens if I use train_on_batch instead of fit.

I have 2 versions of same model. One is with fit with 2 loops and with **train_on_batch** with 3 loops (epoch, day worth of data, batch within day)

train_on_batch throws error: `slice index 0 of dimension 0 out of bounds. for 'strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.`

0111 data is label provided in y2. and the size of 4 is correct. Why is computed input tensor is size 3 I don't understand. It looks like a bug very much.

Model
```
model = tf.keras.Sequential()
model.add(layers.LSTM(neurons, input_shape=(window_size, inputs_n), return_sequences=True)) 
model.add(layers.LSTM(neurons))
model.add(layers.Dense(outputs_n, activation='sigmoid'))

opt = tf.train.AdamOptimizer(0.001)

model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])
 
tpu_model = tf.contrib.tpu.keras_to_tpu_model(model, 
        strategy=tf.contrib.tpu.TPUDistributionStrategy(
            tf.contrib.cluster_resolver.TPUClusterResolver(tpu = [TPU_ADDRESS1])))
```
Shapes
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_input (InputLayer)      (None, 1024, 7)           0         
_________________________________________________________________
lstm (LSTM)                  (None, 1024, 128)         69632     
_________________________________________________________________
lstm_1 (LSTM)                (None, 128)               131584    
_________________________________________________________________
dense (Dense)                (None, 4)                 516       
=================================================================
```
Training:
```
for epoch in epochs:
    for d in days : 
        # get arrays for the day
        features = np.asarray(d[1])[:,2:9].astype(dtype = 'float32')
        labels = np.asarray(d[1])[:, 9:13].astype(dtype = 'int32')
        
        X,y = split_sequence(features, labels_buy, window_size)

        # train 
        for slide in range(window_size):
            try:
                x1, y1 = X[slide], y[slide]
                x2, y2 = x1.reshape(1,1024,7), y1.reshape(1, 4)
                H = tpu_model.train_on_batch(x2,y2)
            except Exception as e:
                print('** train exception **', e)
                continue
```
**Describe the expected behavior**

train_on_batch trains without exception
"
29838,Error using OpenMPI together with self-compiled version of Tensorflow,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): from source
- TensorFlow version: 1.13.1
- Python version: Bazel used 2.7 as default, however I have also access to 3.6
- Installed using virtualenv? pip? conda?: -
- Bazel version (if compiling from source): 0.26
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: -
- GPU model and memory: - (no GPU)


**Describe the problem**
I am using Tensorflow's C API within a C++ simulation software for fluid dynamics (OpenFOAM). So far I used the standard C API available here (https://www.tensorflow.org/install/lang_c). Everything worked well, both doing my computations on one core as well as using OpenMPI to parallelize the fluid dynamics part. As I wanted to speed up my inference I wanted to try out AVX / AVX2 support, as my CPU supports AVX / AVX2. To do so I compiled Tensorflow from source:
1) Installation of Bazel 0.26.1
2) clone from Github: git clone https://github.com/tensorflow/tensorflow.git
3) cd tensorflow -> ./configure
4) I chose these steps for configuration:
- Please specify the location of python. [Default is /usr/bin/python]: default
-Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]: default
- Do you wish to build TensorFlow with XLA JIT support? [Y/n]: Y
- Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N
- Do you wish to build TensorFlow with ROCm support? [y/N]: N
- Do you wish to build TensorFlow with CUDA support? [y/N]: N
- Do you wish to download a fresh release of clang? (Experimental) [y/N]: N
- Do you wish to build TensorFlow with MPI support? [y/N]: y
- Please specify the MPI toolkit folder. [Default is /usr]: default
- Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: default
- Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N
5) Test: bazel test --config opt //tensorflow/tools/lib_package:libtensorflow_test
6) Build: bazel build --config opt //tensorflow/tools/lib_package:libtensorflow
7) Included the header files and linked the libraries

Unfortunately, although everything seemed to be fine, I get an error. As I mentioned, using the standard C API downloaded from the homepage everything was fine. Now i can still to my computations if i do not parallelize my fluid dynamics software. However if I run my fluid dynamics simulation in parallel, this happens:
`
[node134:18796] *** Process received signal ***

[node134:18796] Signal: Segmentation fault (11)

[node134:18796] Signal code: Address not mapped (1)

[node134:18796] Failing at address: (nil)

[node134:18796] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x3ef20)[0x7fec1c96ff20]

[node134:18796] [ 1] /home/elias/OpenFOAM/elias-4.1/platforms/linux64GccDPInt32Opt/lib/libtensorflow_framework.so(hwloc_bitmap_and+0x14)[0x7fec01c21534]

[node134:18796] [ 2] /usr/lib/x86_64-linux-gnu/libopen-pal.so.20(opal_hwloc_base_filter_cpus+0x380)[0x7febe59d6b80]

[node134:18796] [ 3] /usr/lib/x86_64-linux-gnu/openmpi/lib/openmpi/mca_ess_pmi.so(+0x2b4e)[0x7febe4902b4e]

[node134:18796] [ 4] /usr/lib/x86_64-linux-gnu/libopen-rte.so.20(orte_init+0x22e)[0x7febe5c2a1de]

[node134:18796] [ 5] /usr/lib/x86_64-linux-gnu/libmpi.so.20(ompi_mpi_init+0x30e)[0x7febffdbc27e]

[node134:18796] [ 6] /usr/lib/x86_64-linux-gnu/libmpi.so.20(MPI_Init+0x6b)[0x7febffddd2ab]

[node134:18796] [ 7] /opt/OpenFOAM/OpenFOAM-4.1/platforms/linux64GccDPInt32Opt/lib/openmpi-system/libPstream.so(_ZN4Foam8UPstream4initERiRPPc+0x1f)[0x7fec1c72843f]

[node134:18796] [ 8] /opt/OpenFOAM/OpenFOAM-4.1/platforms/linux64GccDPInt32Opt/lib/libOpenFOAM.so(_ZN4Foam7argListC1ERiRPPcbbb+0x719)[0x7fec1db36ed9]

[node134:18796] [ 9] tabulatedCombustionFoam(+0x279b8)[0x55fe6eb489b8]

[node134:18796] [10] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xe7)[0x7fec1c952b97]

[node134:18796] [11] tabulatedCombustionFoam(+0x30a0a)[0x55fe6eb51a0a]

[node134:18796] *** End of error message ***`

I do not think that my code has any errors, as with the C API I downloaded directly from the Tensorflow homepage everything worked fine. More probably it seems to be a collision between OpenMPI called from Tensorflow and OpenMPI called from OpenFOAM (the fluid dynamics software). Moreover the run crashes immediately after I start the simulation and far before it reaches my own code.

My questions:
1) Is there a procedure I can follow to get rid of the bug?
2) What would I have to do to reproduce exactly the version of the C API that one can download from your homepage? Because as mentioned using this version everything worked fine. Can I find out where the precompiled C API looks for openmpi? Or can you tell me the path?
3) From this post (https://www.cfd-online.com/Forums/openfoam-solving/133913-problems-running-openfoam-2-3-parallel.html) I learned that OpenFOAM uses an own OpenMPI version, however this one worked perfectly fine together with my initial Tensorflow C API stuff that i downloaded. Can you maybe define what the correct MPI toolkit path must contain? Then I could possibly use the one also used by OpenFOAM.
"
29837,Tensorflow for Kotlin Multiplatform,"Currently Tensorflow supports [Javascript](https://www.tensorflow.org/js), [Java](https://www.tensorflow.org/install/lang_java), and [C](https://www.tensorflow.org/install/lang_c). These are all the target programming languages of [Kotlin Multiplatform](https://kotlinlang.org/docs/reference/multiplatform.html). Therefore, it would be theoretically possible to port Tensorflow to be a Kotlin Multiplatform Library by just reusing the existing APIs. 
Are there any plans for this? If not, what do you think about the idea?"
29835,GPU Support - Shared Object Exclusion ,"[UPDATE]:  This issue is about Maven artifact organization / dependency management and documentation.  

**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04.2 LTS
- TensorFlow installed from Maven, version 1.13.1
- TensorFlow version: 1.13.1
- Python version: 3.6.7
- Installed using virtualenv
- CUDA/cuDNN version:  NVIDIA-SMI 418.43       Driver Version: 418.43       CUDA Version: 10.1
- GPU model and memory: 4xNvidia 1080Ti, 

**Describe the problem**

I have created a TensorFlow model in Python and saved it to the disk using the standard method:

    builder = tf.saved_model.builder.SavedModelBuilder(model_directory) 
    builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.SERVING]) 
    builder.save(False)

Next I am loading the model in Java:

    SavedModelBundle savedModelBundle = SavedModelBundle.loader(modelDir)
        .withTags(""serve"")
        .withConfigProto(
            ConfigProto.newBuilder()
                .setGpuOptions(
                    GPUOptions.newBuilder()
                        .setPerProcessGpuMemoryFraction(1.0).build())
                .setLogDevicePlacement(true)
                .build().toByteArray())
        .load();
    Session session = savedModelBundle.session();

In my pom.xml I have

    <dependency>
        <groupId>org.tensorflow</groupId>
        <artifactId>tensorflow</artifactId>
        <version>${tensorflow.version}</version>
    </dependency>
    <dependency>
        <groupId>org.tensorflow</groupId>
        <artifactId>proto</artifactId>
        <version>${tensorflow.version}</version>
    </dependency>
    <dependency>
        <groupId>org.tensorflow</groupId>
        <artifactId>libtensorflow_jni_gpu</artifactId>
        <version>${tensorflow.version}</version>
    </dependency>

However, this fails to use my GPU's on startup

    2019-06-15 23:48:38.130731: I tensorflow/compiler/xla/service/service.cc:150] 
        XLA service 0x7fbfc4656e10 executing computations on platform Host. Devices:
    2019-06-15 23:48:38.130768: I tensorflow/compiler/xla/service/service.cc:158]   
        StreamExecutor device (0): <undefined>, <undefined>
        Device mapping:
            /job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device
    2019-06-15 23:48:38.131168: I tensorflow/core/common_runtime/direct_session.cc:317]    
       Device mapping:
        /job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device

Please advise on how to use GPU with SaveModelBundle.  "
29832,Using TF estimator with tf.data fetched from tfds,"

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.00-beta
- Python version: 3.7
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA


**Describe the current behavior**

I am trying to use a pre-made estimator with a dataset fetched from tensorflow_dataset. I have followed the steps from the guide, but it gives an error:

```
RuntimeError: Attempting to capture an EagerTensor without building a function.
```

I have also looked at this other issue ([issue #24592](https://github.com/tensorflow/tensorflow/issues/24592)) but the solution provided there does not apply to me.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

I am trying to use the pre-made estimator `tf.estimator.DNNClassifier` to use on the MNIST dataset. I load the dataset from `tensorflow_dataset`.

I pursue the following four steps: first building the dataset pipeline and defining the input function:

```python
## Step 1
mnist, info = tfds.load('mnist', with_info=True)

ds_train_orig, ds_test = mnist['train'], mnist['test']

def train_input_fn(dataset, batch_size):
    dataset = dataset.map(lambda x:({'image-pixels':tf.reshape(x['image'], (-1,))}, 
                                    x['label']))
    return dataset.shuffle(1000).repeat().batch(batch_size)
```

Then, in step 2, I define the feature column with a single key, and shape 784:

```python
## Step 2:
image_feature_column = tf.feature_column.numeric_column(key='image-pixels',
                                                        shape=(28*28))

image_feature_column
NumericColumn(key='image-pixels', shape=(784,), default_value=None, dtype=tf.float32, normalizer_fn=None)
```

Step 3, I instantiated the estimator as follows:

```python
## Step 3:
dnn_classifier = tf.estimator.DNNClassifier(
    feature_columns=image_feature_column,
    hidden_units=[16, 16],
    n_classes=10)
```

And finally, step 4 using the estimator by calling the `.train()` method:

```python
## Step 4:
dnn_classifier.train(
    input_fn=lambda:train_input_fn(ds_train_orig, batch_size=32),
    #lambda:iris_data.train_input_fn(train_x, train_y, args.batch_size),
    steps=20)
```
"
29831,ImportError: Could not find 'cudart64_.dll'.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro (Build 17763)
- TensorFlow installed from (source or binary): Source
- TensorFlow version: v2.0.0-beta1
- Python version: Python 3.6.8 (Anaconda)
- Installed using virtualenv? pip? conda?: Conda
- Bazel version (if compiling from source): 0.26.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0, 7.3
- GPU model and memory: GTX 1080, 8gb

**Describe the problem**
I get the following error during build:

ERROR: C:/tools/tensorflow/tensorflow/python/keras/api/BUILD:46:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v2 failed (Exit 1): bash.exe failed: error executing command
  cd C:/users/cover/_bazel_cover/cchquwgb/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0

â€¦ bunch of stuff â€¦ thenâ€¦

Execution platform: @bazel_tools//platforms:host_platform
Traceback (most recent call last):
  File ""\\?\C:\Users\Cover\AppData\Local\Temp\Bazel.runfiles_edzmzyvw\runfiles\org_tensorflow\tensorflow\python\platform\self_check.py"", line 75, in preload_check
    ctypes.WinDLL(build_info.cudart_dll_name)
  File ""C:\Users\Cover\anaconda3\envs\tf2fast\lib\ctypes\__init__.py"", line 348, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] The specified module could not be found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""\\?\C:\Users\Cover\AppData\Local\Temp\Bazel.runfiles_sfe42hqk\runfiles\org_tensorflow\tensorflow\python\tools\api\generator\create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""\\?\C:\Users\Cover\AppData\Local\Temp\Bazel.runfiles_sfe42hqk\runfiles\org_tensorflow\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""\\?\C:\Users\Cover\AppData\Local\Temp\Bazel.runfiles_sfe42hqk\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 30, in <module>
    self_check.preload_check()
  File ""\\?\C:\Users\Cover\AppData\Local\Temp\Bazel.runfiles_sfe42hqk\runfiles\org_tensorflow\tensorflow\python\platform\self_check.py"", line 82, in preload_check
    % (build_info.cudart_dll_name, build_info.cuda_version_number))
ImportError: Could not find 'cudart64_.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA  from this URL: https://developer.nvidia.com/cuda-90-download-archive
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 379.181s, Critical Path: 375.70s
INFO: 572 processes: 572 local.
FAILED: Build did NOT complete successfully

All of my paths to CUDA are included in %PATH% and I've ensured cudart64_100.dll is located in a directory in my path.  Its interesting that the error doesn't include the correct name of the file.


**Provide the exact sequence of commands / steps that you executed before running into the problem**
![image](https://user-images.githubusercontent.com/33430083/59557596-815f1480-8f92-11e9-84a6-a794cbbfc7e5.png)
*Using python 3.6.8 instead of 3.7 as above

I'm using all defaults for configure.py, aside from setting cuda to yes, and my compute capability to 6.1.

bazel build --config=v2 --config=mkl --config==cuda -c opt //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29829,Segmentation fault using tf.lite.TFLiteConverter with representative_dataset,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 2.0beta1
- **Python version**: 3.6.8
- **Bazel version (if compiling from source)**:  0.24.1
- **GCC/Compiler version (if compiling from source)**: 7.4.0
- **CUDA/cuDNN version**: 10.0
- **GPU model and memory**: GTX2080TI 11 GB
- **Exact command to reproduce**:

### Describe the problem
I am trying to quantize (post-training) my model, using a representative dataset as explained in the latest documentation. I tried to build the representative dataset by loading some relevant PNGs from a folder. But I get a segmentation fault error when I set the representative dataset (no error if I do not set it or use mnist as dataset).

### Source code / logs
This works:

```
mnist_train, _ = tf.keras.datasets.mnist.load_data()
images = tf.cast(mnist_train[0], tf.float32)/255.0
mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)
def representative_data_gen():
  for input_value in mnist_ds.take(100):
    yield [input_value]

tf.logging.set_verbosity(tf.logging.INFO)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_quant_model = converter.convert()
```

This doesn't (SEGFAULT):

```
train = []
files = glob.glob ('/myPath/data/images/test/*.png')

for myFile in files:
    image = cv2.imread (myFile)
    train.append (image)
train = np.array(train,dtype='float32') #as mnist
images = tf.cast(train[0], tf.float32)/255.0
my_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)
    
def representative_data_gen():
  for input_value in my_ds.take(100):
    yield [input_value]    

tf.logging.set_verbosity(tf.logging.INFO)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_quant_model = converter.convert()
```

Output:

```
....
2019-06-15 20:40:32.261287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-15 20:40:32.261634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10246 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
W0615 20:40:32.319736 140096456644416 deprecation_wrapper.py:118] From quantize.py:47: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

Fatal Python error: Segmentation fault

Current thread 0x00007f6abf885740 (most recent call first):
  File ""/usr/tf2/lib/python3.6/site-packages/tensorflow/lite/python/optimize/calibrator.py"", line 51 in __init__
  File ""/usr/tf2/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 197 in _calibrate_quantize_model
  File ""/usr/tf2/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 922 in convert
  File ""quantize.py"", line 50 in <module>

Segmentation fault (core dumped)
```


If I use ciphar instead of mnist as representative dataset I also get the same SEGFAULT.

```cifar_train, _ = tf.keras.datasets.cifar10.load_data()
images = tf.cast(cifar_train[0], tf.float32) / 255.0
cifar_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)
def representative_data_gen():
  for input_value in cifar_ds.take(100):
    yield [input_value]`

Any ideas? Thank you.
"
29828,Having problem modifying sample_distorted_bounding_box,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: r1.14
- Python version: 3.5
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source): 0.25.2
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 9.0/7.0
- GPU model and memory:



**Describe the problem**

Hi all. I am trying to modify the behavior of tf.image.sample_distorted_bounding_box so I digged into sample_distorted_bounding_box_op.cc and made some changes including several lines of `cout << ""Hi"" << endl;` for logging. Then I recompiled this library using `bazel build //tensorflow/core/kernels/sample_distorted_bounding_box_op`. However when I reran tf.image.sample_distorted_bounding_box, it seems nothing changed. May I know what else should I do to modify the TensorFlow built-in api?

Thanks in advance!


"
29826,Can't import Tensorflow GPU 2.0 beta on Win 7: DLL load failed with error code -1073741795,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Win 7 SP1**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**
- TensorFlow installed from (source or binary): **Binary**
- TensorFlow version: **2.0 GPU Beta**
- Python version: **3.6.8**
- Installed using virtualenv? pip? conda?: **pip with no virtualenv**
- Bazel version (if compiling from source): **N/A**
- GCC/Compiler version (if compiling from source): **N/A**
- CUDA/cuDNN version: **10.0**
- GPU model and memory: **Geforce GTX 1050, 2GB memory**


**Describe the problem**
I am trying to install Tensorflow 2.0 GPU beta but it fails to download a DLL when trying to import the library.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

- Installed latest NVIDIA drivers
- Installed CUDA Toolkit 10.0 (Sept 2018)
- Installed cuDNN v7.6.0 (May 20, 2019), for CUDA 10.0
- Made sure that the following path are in the PATH variable:
```
SET PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;%PATH%
SET PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\extras\CUPTI\libx64;%PATH%
SET PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\include;%PATH%
SET PATH=C:\tools\cuda\bin;%PATH%
```
- Installed Tensorflow:
```
pip install tensorflow-gpu==2.0.0-beta1
```
- Ran Python in command line and tried to import Tensorflow:
```
Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Program Files\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Program Files\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed with error code -1073741795

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Program Files\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Program Files\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed with error code -1073741795
```

**Any other info / logs**

Screenshots of my CUDA folders:
![cuda_bin_folder](https://user-images.githubusercontent.com/31602326/59554008-3e3d7b00-8f6b-11e9-8018-a52c0052192e.png)
![cuda_cupti_folder](https://user-images.githubusercontent.com/31602326/59554011-45648900-8f6b-11e9-83b8-d7ac84670695.png)
![cuda_include_path](https://user-images.githubusercontent.com/31602326/59554014-47c6e300-8f6b-11e9-9170-0400c4004478.png)
![cudnn_folder](https://user-images.githubusercontent.com/31602326/59554016-4a293d00-8f6b-11e9-8da2-8a8a6952b564.png)
![cudnn64_7](https://user-images.githubusercontent.com/31602326/59554039-9d02f480-8f6b-11e9-95de-c1738edc9ddd.png)
"
29825,Shape change during TPU training,"Once I start train my model on TPU v3-8 I get this output and model start recompiling and continue train with different shape:
```
INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(128, 1024, 7), dtype=tf.float32, name='lstm_input_10'), TensorSpec(shape=(128, 4), dtype=tf.float32, name='dense_target_30')]
INFO:tensorflow:Overriding default placeholder.
INFO:tensorflow:Remapping placeholder for lstm_input
INFO:tensorflow:Started compiling
INFO:tensorflow:Finished compiling. Time elapsed: 5.74567985534668 secs
INFO:tensorflow:Setting weights on TPU model.
 9216/11126 [=======================>......] - ETA: 4s - loss: nan - categorical_accuracy: 0.0250INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(110,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(110, 1024, 7), dtype=tf.float32, name='lstm_input_10'), TensorSpec(shape=(110, 4), dtype=tf.float32, name='dense_target_30')]
INFO:tensorflow:Overriding default placeholder.
INFO:tensorflow:Remapping placeholder for lstm_input
INFO:tensorflow:Started compiling
INFO:tensorflow:Finished compiling. Time elapsed: 8.460586786270142 secs
```

Compare shapes before train kicks in and after:
```
INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(128, 1024, 7), dtype=tf.float32, name='lstm_input_10'), TensorSpec(shape=(128, 4), dtype=tf.float32, name='dense_target_30')]
INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(110,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(110, 1024, 7), dtype=tf.float32, name='lstm_input_10'), TensorSpec(shape=(110, 4), dtype=tf.float32, name='dense_target_30')]
```
Model shapes:
```
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_input (InputLayer)      (None, 1024, 7)           0         
_________________________________________________________________
lstm (LSTM)                  (None, 1024, 256)         270336    
_________________________________________________________________
dropout (Dropout)            (None, 1024, 256)         0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 256)               525312    
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense (Dense)                (None, 4)                 1028      
=================================================================
```

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9
- TensorFlow installed from (source or binary): 1.13.1
- Python version: 3.5
- GPU model and memory: TPU v3-8

**Describe the current behavior**

shapes change from 128 to 110 during first few batches training

**Describe the expected behavior**

shapes don't change

"
29824,tf.reduce_max returns wrong value,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04.2 LTS**
- TensorFlow installed from (source or binary): **source**
- TensorFlow version (use command below): **1.12.2**
- Python version: **3.6.7**
- Bazel version (if compiling from source): **0.17.2**
- GCC/Compiler version (if compiling from source): **gcc version 7.3.0 (Ubuntu 7.3.0-27ubuntu1~18.04)**
- CUDA/cuDNN version: **no gpu**
- GPU model and memory: **no gpu**

**The current behavior**
I have implemented a computation graph, consisting of a custom keras layer _GaussianSimilaritiesLayer_ and a _tf.reduce_max_ function. You can find the code below.

```
import tensorflow as tf
import numpy as np


class GaussianSimilaritiesLayer(tf.keras.layers.Layer):
    def __init__(self, reference_values, covariance_matrix):
        super(GaussianSimilaritiesLayer, self).__init__()
        self._reference_values = tf.convert_to_tensor(np.vstack(reference_values).astype(np.float32))
        self._cov_inv = tf.convert_to_tensor(covariance_matrix.astype(np.float32))

    def call(self, inputs):
        diffs = self._reference_values - inputs
        A = tf.matmul(diffs, self._cov_inv)
        B = tf.multiply(A, diffs)
        dist = tf.reduce_sum(B, axis=1)
        exp_arg = -0.5 * dist
        # return 1 * tf.math.exp(exp_arg)  # call() returns desired value
        return tf.math.exp(exp_arg)  # call() returns wrong value


class Potential:
    def __init__(self, session, demonstrations, covariance_matrix):
        self._in = tf.keras.layers.Input(shape=(3,))
        similarities = GaussianSimilaritiesLayer(demonstrations,
                                                 covariance_matrix)(self._in)
        max_similarity = tf.keras.layers.Lambda(tf.reduce_max)(similarities)

        self._model = tf.keras.Model(inputs=[self._in],
                                     outputs=[max_similarity])
        self._session = session

    def __call__(self, s):
        return self._model.output.eval(session=self._session, feed_dict={
            self._in: s
        })


if __name__ == '__main__':

    with tf.Session() as sess:
        sa_demonstrations = [np.array([1, 2, 3], dtype=np.float32),
                             np.array([4, 5, 6], dtype=np.float32)]
        covariance_matrix = np.array([[1, 0, 0],
                                    [0, 2, 0],
                                    [0, 0, 3]], dtype=np.float32)
        phi = Potential(sess, sa_demonstrations, covariance_matrix)
        sample_s = np.array([1, 2, 2.7], dtype=np.float32)
        print(phi([sample_s]))
```
When `GaussianSimilaritiesLayer.call` return statement looks like below

```        return tf.math.exp(exp_arg) ```

the script outputs:

> -0.13499996

This is the value of `exp_arg` from `GaussianSimilaritiesLayer.call`. The function should return e^-0.13499996.

**The expected behavior**
When `GaussianSimilaritiesLayer.call` return statement looks like below

```        return 1 * tf.math.exp(exp_arg) ```

the script outputs:

> 0.87371594

which is the desired value."
29823,Using a `tf.Tensor` as a Python `bool` is not allowed,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): official site
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory:


**Describe the current behavior**
I built a custom activation function in Keras' and call tf functions. When I call the custom function, I encountered error:

  TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.

The line of code where the error happened is this one
`  inputs = tf.where(orig > 0 and orig <= 0.25, 0.25 / (1+K.exp(-self.sharp*((inputs-0.125)/0.5))), inputs)`
**Describe the expected behavior**
I tested all variables, all of them are tf.Tensor
**Code to reproduce the issue**
`import tensorflow as tf

class QPWCX(Layer):


    def __init__(self, sharp=100, **kwargs):
        super(QPWCX, self).__init__(**kwargs)
        self.supports_masking = True
        self.sharp = K.cast_to_floatx(sharp)

    def call(self, inputs):
        orig = inputs
        inputs = tf.where(orig <= 0, tf.zeros_like(inputs), inputs)
        inputs = tf.where(orig > 0 and orig <= 0.25, 0.25 / (1+K.exp(-self.sharp*((inputs-0.125)/0.5))), inputs)
        inputs = tf.where(orig > 0.25 and orig <= 0.5, 0.25 / (1+K.exp(-self.sharp*((inputs-0.5)/0.5))) + 0.25, inputs)
        inputs = tf.where(orig > 0.5 and orig <= 0.75, 0.25 / (1+K.exp(-self.sharp*((inputs-0.75)/0.5))) + 0.5, inputs)
        return K.where(orig > 0.75, 1, inputs)


    def get_config(self):
        config = {'sharp': float(self.sharp)}
        base_config = super(QPWCX, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))

    def compute_output_shape(self, input_shape):
        return input_shape
`

"
29822,[TF 2.0 API Docs] tf.estimator.SessionRunHook,"URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/SessionRunHook
Description of issue (what needs changing):
Clear description

Yes clear description
Correct links

The link to the source code correct.
Parameters defined

All parameters defined and formatted correctly.
Returns defined

Return values are defined.
Raises listed and defined

No raises listed and defined.
Usage example

No usage examples provided
Request visuals, if applicable

No visuals included"
29821,[TF 2.0 API Docs] tf.estimator.StepCounterHook,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/SessionRunHook

## Description of issue (what needs changing):

### Clear description

Yes clear description

### Correct links

The link to the source code correct.

### Parameters defined

All parameters defined and formatted correctly.

### Returns defined
Return values are defined.

### Raises listed and defined
No raises listed and defined.

### Usage example

No usage examples provided

### Request visuals, if applicable

No visuals included


"
29820,framework api int64 compatible problem,"It seems tensorflow have compatible problem for Shard and int64
```
auto job = [&](int64 start, int64 limit)
{
            for (int64 i = start; i<limit; i++)
            {
                std::cout << start << std::endl; // Segmentation fault (core dumped)
            }
};

auto job = [&](int64 start, int64 limit)
{
            for (int i=0; i<4; i++)
            {
                std::cout << start << std::endl; // ok
            }
};

const DeviceBase::CpuWorkerThreads& worker_threads = *(context->device()->tensorflow_cpu_worker_threads());
const int64_t shard_cost = 10000;
Shard(worker_threads.num_threads, worker_threads.workers,
              (int64)4, shard_cost, job);

```
system info:
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux ubuntu 18.04
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.13 v1.13.1-0-g6612da8951
- Python version:3.5
- CUDA/cuDNN version:10/7.5
- GPU model and memory:7.5/24gb

"
29819,Internal Compiler Error cross-compiling v2.0.0-beta0 for Raspberry Pi,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
```
Build container: Ubuntu 14.04
Docker version: 18.09.2 (Docker engine) / 2.0.0.3 (31259) (Docker Desktop for Mac)
Host platform: macOS 10.14.4 (Mojave)
```
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
```
Build target: Raspberry Pi B, ARMv7l
```
- TensorFlow installed from (source or binary): Source (instructions taken from https://www.tensorflow.org/install/source_rpi)
- TensorFlow version: `v2.0.0-beta0`
- Python version: Python 3.4 
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source):
```
(via `build_raspberry_pi.sh`)
https://github.com/raspberrypi/tools/blob/master/arm-bcm2708/arm-rpi-4.9.3-linux-gnueabihf/bin/arm-linux-gnueabihf-gcc

https://github.com/tensorflow/tensorflow/blob/v2.0.0-beta0/tensorflow/tools/ci_build/pi/build_raspberry_pi.sh#L60
```
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the problem**

I'm seeing an internal compiler error when compiling `tensorflow/core/kernels/data/experimental/stats_dataset_ops.cc`. Full log is attached as `v2.0.0-beta0-build.log`

I also noticed this build process is using the `gnu11` dialect, where the preferred dialect in `tensorflow/core/kernels` and other modules is c++11. 

```bash
INFO: From Compiling tensorflow/core/kernels/data/experimental/stats_dataset_ops.cc:
cc1plus: warning: command line option '-std=gnu11' is valid for C/ObjC but not for C++
ERROR: /workspace/tensorflow/core/kernels/BUILD:3301:1: C++ compilation of rule '//tensorflow/core/kernels:matrix_square_root_op' failed (Exit 4): arm-linux-gnueabihf-gcc failed: error executing command
  (cd /Users/ljohnson/repos/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_ljohnson/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH='' \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF_CONFIGURE_IOS=0 \
  /Users/ljohnson/repos/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_ljohnson/eab0d61a99b6696edb3d2aff87b585e8/external/arm_compiler/bin/arm-linux-gnueabihf-gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -DRASPBERRY_PI -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -isystem /usr/include/arm-linux-gnueabihf -isystem /usr/include/python3.4 -isystem /usr/include/ -MD -MF bazel-out/armeabi-opt/bin/tensorflow/core/kernels/_objs/matrix_square_root_op/matrix_square_root_op.pic.d '-frandom-seed=bazel-out/armeabi-opt/bin/tensorflow/core/kernels/_objs/matrix_square_root_op/matrix_square_root_op.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DTF_USE_SNAPPY -iquote . -iquote bazel-out/armeabi-opt/genfiles -iquote bazel-out/armeabi-opt/bin -iquote external/com_google_absl -iquote bazel-out/armeabi-opt/genfiles/external/com_google_absl -iquote bazel-out/armeabi-opt/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/armeabi-opt/genfiles/external/eigen_archive -iquote bazel-out/armeabi-opt/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/armeabi-opt/genfiles/external/local_config_sycl -iquote bazel-out/armeabi-opt/bin/external/local_config_sycl -iquote external/nsync -iquote bazel-out/armeabi-opt/genfiles/external/nsync -iquote bazel-out/armeabi-opt/bin/external/nsync -iquote external/gif_archive -iquote bazel-out/armeabi-opt/genfiles/external/gif_archive -iquote bazel-out/armeabi-opt/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/armeabi-opt/genfiles/external/jpeg -iquote bazel-out/armeabi-opt/bin/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/armeabi-opt/genfiles/external/protobuf_archive -iquote bazel-out/armeabi-opt/bin/external/protobuf_archive -iquote external/zlib_archive -iquote bazel-out/armeabi-opt/genfiles/external/zlib_archive -iquote bazel-out/armeabi-opt/bin/external/zlib_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/armeabi-opt/genfiles/external/com_googlesource_code_re2 -iquote bazel-out/armeabi-opt/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/armeabi-opt/genfiles/external/farmhash_archive -iquote bazel-out/armeabi-opt/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/armeabi-opt/genfiles/external/fft2d -iquote bazel-out/armeabi-opt/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/armeabi-opt/genfiles/external/highwayhash -iquote bazel-out/armeabi-opt/bin/external/highwayhash -iquote external/double_conversion -iquote bazel-out/armeabi-opt/genfiles/external/double_conversion -iquote bazel-out/armeabi-opt/bin/external/double_conversion -iquote external/snappy -iquote bazel-out/armeabi-opt/genfiles/external/snappy -iquote bazel-out/armeabi-opt/bin/external/snappy -iquote external/hwloc -iquote bazel-out/armeabi-opt/genfiles/external/hwloc -iquote bazel-out/armeabi-opt/bin/external/hwloc -isystem external/eigen_archive -isystem bazel-out/armeabi-opt/genfiles/external/eigen_archive -isystem bazel-out/armeabi-opt/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/armeabi-opt/genfiles/external/nsync/public -isystem bazel-out/armeabi-opt/bin/external/nsync/public -isystem external/gif_archive/lib -isystem bazel-out/armeabi-opt/genfiles/external/gif_archive/lib -isystem bazel-out/armeabi-opt/bin/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/armeabi-opt/genfiles/external/protobuf_archive/src -isystem bazel-out/armeabi-opt/bin/external/protobuf_archive/src -isystem external/zlib_archive -isystem bazel-out/armeabi-opt/genfiles/external/zlib_archive -isystem bazel-out/armeabi-opt/bin/external/zlib_archive -isystem external/farmhash_archive/src -isystem bazel-out/armeabi-opt/genfiles/external/farmhash_archive/src -isystem bazel-out/armeabi-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/armeabi-opt/genfiles/external/double_conversion -isystem bazel-out/armeabi-opt/bin/external/double_conversion -isystem external/hwloc/hwloc -isystem bazel-out/armeabi-opt/genfiles/external/hwloc/hwloc -isystem bazel-out/armeabi-opt/bin/external/hwloc/hwloc -isystem external/hwloc/include -isystem bazel-out/armeabi-opt/genfiles/external/hwloc/include -isystem bazel-out/armeabi-opt/bin/external/hwloc/include '-march=armv7-a' '-mfpu=neon-vfpv4' '-std=gnu11' '-DS_IREAD=S_IRUSR' '-DS_IWRITE=S_IWUSR' -O3 -fno-tree-pre -U__GCC_HAVE_SYNC_COMPARE_AND_SWAP_1 -U__GCC_HAVE_SYNC_COMPARE_AND_SWAP_2 -U__GCC_HAVE_SYNC_COMPARE_AND_SWAP_8 -funsafe-math-optimizations -ftree-vectorize -fomit-frame-pointer -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' -DTENSORFLOW_MONOLITHIC_BUILD -pthread -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -no-canonical-prefixes -fno-canonical-system-headers -c tensorflow/core/kernels/matrix_square_root_op.cc -o bazel-out/armeabi-opt/bin/tensorflow/core/kernels/_objs/matrix_square_root_op/matrix_square_root_op.pic.o)
Execution platform: @bazel_tools//platforms:host_platform
cc1plus: warning: command line option '-std=gnu11' is valid for C/ObjC but not for C++
arm-linux-gnueabihf-gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See <http://gcc.gnu.org/bugs.html> for instructions.
INFO: Elapsed time: 43029.508s, Critical Path: 986.76s
INFO: 3265 processes: 3265 local.
FAILED: Build did NOT complete successfully
```


**Provide the exact sequence of commands / steps that you executed before running into the problem**

```bash
git checkout v2.0.0-beta0 \
CI_DOCKER_EXTRA_PARAMS=""-e CI_BUILD_PYTHON=python3 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.4"" \
    tensorflow/tools/ci_build/ci_build.sh PI-PYTHON3 \
    tensorflow/tools/ci_build/pi/build_raspberry_pi.sh > v2.0.0-beta0-build.log
```

[v2.0.0-beta0-build001.log](https://github.com/tensorflow/tensorflow/files/3292954/v2.0.0-beta0-build001.log)"
29818,Having problem to use the Reshape in Keras,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-beta0
- Python version: 3.6.8
- CUDA/cuDNN version: 10.0
- GPU model and memory: GeForce GTX 750 Ti


**Describe the current behavior**
When using Reshape layer of Keras and -1 is used to infer the shape, the output shape is incorrect.

**Describe the expected behavior**


**Code to reproduce the issue**
`from tensorflow.python.keras.layers import Input, Lambda, Conv2D, Reshape, TimeDistributed`
`from tensorflow.python.keras.models import *`
`import tensorflow.keras as keras`

`a = Input(shape=(12,), dtype = 'int32')`
`# a.shape == (None, 12)`
`d = Reshape((-1, 2, 2))(a)`
`# actual resultï¼š d.shape == (None, None, 2, 2)`
`# expected resultï¼š d.shape == (None, 3, 2, 2)`

"
29816,Sess.run() leads to unexpected memory leaky in CPU version,"Hi~

A simplest example is shown as below:
```
graph = tf.Graph()

sess = tf.InteractiveSession(graph=graph)

with graph.as_default_graph():
       # Here is my code build the model
       model  = Model(inputs=,outputs=)

# frozen graph to avoid any other ops adding to the graph
graph.finalize()

# prepare test data
img = np.ones(model.input_shape)

# run session in loop
while True:
      sess.run(model.output,feed_dict={model.input:img}
     # Here is my code for watching memory state:
      print(psutil.Process(os.getpid()).memory_info().rss)
``` 

And the result of `psutil` shows the process memory usage increases after each iteration and could not collected by gc in python. I eagerly wonder why this phenomena appears and how to solve it.

Thanks a lot!"
29808,FeatureColumn - implement many-to-one categorical column,"- TensorFlow version (you are using): 2.0.0b0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
Currently, categorical column class numbers can be assigned sequentially based on a list or one-input-per-line file. It would be useful to support situations where groups of possible input values are known to be equivalent, and so should have the same class number. This feature could be implemented via a `categorical_column_with_vocabulary_dict` function that accepts a dictionary mapping input values to class numbers, rather than a list or file.

**Will this change the current api? How?**
Yes; it would add a `categorical_column_with_vocabulary_dict` function.

**Who will benefit with this feature?**
People using non-normalized input data where multiple possible inputs can be equivalent will benefit.

**Any Other info.**"
29806,TensorFlow Lite: undefined reference to `flatbuffers::ClassicLocale::instance_',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: r1.13
- Python version: 3.5
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**
I was following the [instructions](https://www.tensorflow.org/lite/guide/build_rpi) to crosscompile TensorFlow Lite for my Raspberry Pi. I got the error messages showing the undefined reference to flatbuffers. 
I believe all the dependencies for Lite are downloaded by the `download_dependencies.sh` script, but I do not have Bazel installed. Is Bazel necessary for compiling TensorFlow Lite?


**Any other info / logs**
```
/home/user/GitRepo/tensorflow/tensorflow/lite/tools/make/gen/rpi_armv7l/lib/libtensorflow-lite.a(while.o): In function `tflite::ops::custom::while_kernel::Init(TfLiteContext*, char const*, unsigned int)':
while.cc:(.text+0x1648): undefined reference to `flatbuffers::ClassicLocale::instance_'
/home/user/GitRepo/tensorflow/tensorflow/lite/tools/make/gen/rpi_armv7l/lib/libtensorflow-lite.a(audio_spectrogram.o): In function `tflite::ops::custom::audio_spectrogram::Init(TfLiteContext*, char const*, unsigned int)':
audio_spectrogram.cc:(.text+0xe0c): undefined reference to `flatbuffers::ClassicLocale::instance_'
/home/user/GitRepo/tensorflow/tensorflow/lite/tools/make/gen/rpi_armv7l/lib/libtensorflow-lite.a(detection_postprocess.o): In function `tflite::ops::custom::detection_postprocess::Init(TfLiteContext*, char const*, unsigned int)':
detection_postprocess.cc:(.text+0x211c): undefined reference to `flatbuffers::ClassicLocale::instance_'
/home/user/GitRepo/tensorflow/tensorflow/lite/tools/make/gen/rpi_armv7l/lib/libtensorflow-lite.a(detection_postprocess.o): In function `flexbuffers::Reference::AsInt64() const':
detection_postprocess.cc:(.text._ZNK11flexbuffers9Reference7AsInt64Ev[_ZNK11flexbuffers9Reference7AsInt64Ev]+0x264): undefined reference to `flatbuffers::ClassicLocale::instance_'
/home/user/GitRepo/tensorflow/tensorflow/lite/tools/make/gen/rpi_armv7l/lib/libtensorflow-lite.a(if.o): In function `tflite::ops::custom::if_kernel::Init(TfLiteContext*, char const*, unsigned int)':
if.cc:(.text+0xf8c): undefined reference to `flatbuffers::ClassicLocale::instance_'
/home/user/GitRepo/tensorflow/tensorflow/lite/tools/make/gen/rpi_armv7l/lib/libtensorflow-lite.a(mfcc.o):mfcc.cc:(.text+0x118c): more undefined references to `flatbuffers::ClassicLocale::instance_' follow
collect2: error: ld returned 1 exit status
tensorflow/lite/tools/make/Makefile:267: recipe for target '/home/user/GitRepo/tensorflow/tensorflow/lite/tools/make/gen/rpi_armv7l/bin/minimal' failed
make: *** [/home/user/GitRepo/tensorflow/tensorflow/lite/tools/make/gen/rpi_armv7l/bin/minimal] Error 1
make: *** Waiting for unfinished jobs....
```
"
29804,Inconsistency between names in the conv 1d operations and no support for 'causal' padding,"only tf.keras.layers.Conv1D supports padding 'causal', and it is very important for time series research, however in

tf.python.ops.conv1d
input: (batch_size, dim1size, dim2size, ... , channels_in)
filters: (filter_size, channels_in, channels_out)

Also this function behaves as expected, setting a op node according to the math and predicting an output Tensor of predictable shape.

tf.keras.layers.Conv1D
input: (batch_size, steps, input_dim)
filter: size of 1D filter
output: (batch_size, new_steps, filters) 

These are non usual names for the mathematical definition of convolution. Is ""steps"" the size of the time series ? new_steps the relation of the filter size with the input_dim ? are filters the channel output size ? 

Seems incompatible with the former that follows closely the mathematical definition and also expands for multi-channel like the 2D case. Also, is desirable to use causal padding with tf.python.ops.conv1d, without having to add extraneous functions by hand to the code.

thank you, pls have your appreciation.

"
29801,Keras Callbacks documentation for on_train_batch_end vs the actual code of ModelCheckpoint,"## URL(s) with the issue:

[https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/Callback#on_train_batch_end](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/Callback#on_train_batch_end)


## Description of issue (what needs changing):

### Parameters defined

The parameter section of `on_train_batch_end` reads, in part,

> `logs`: dict. Metric results for this batch

So the `logs` argument is expected to only contain metrics when this method is called. This is what I assumed when I coded my own custom training function.

This is different than the `logs` argument which is expected by `on_train_batch_begin` for example, which is:

> `logs`: dict. Has keys `batch` and `size` representing the current batch number and the size of the batch.

Now if we look at [the code](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/callbacks.py) of `ModelCheckpoint`, we see that is has an `on_batch_end` method (which is called by `on_train_batch_end`) which calls the `size` key of `logs`. This is line 950:
`self._samples_seen_since_last_saving += logs.get('size', 1)`

So the documentation of `on_train_batch_end` is not correct as to what is the dict expected by the method. And this has an impact when we want to create custom training functions that work well with Keras Callbacks."
29800,"Keras Dropout layer behaviour in test mode seems to be ""do nothing"" instead of weight scaling inference rule","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
- TensorFlow installed from (source or binary): from pip install
- TensorFlow version (use command below): v1.12.1-3259-gf59745a381 2.0.0-beta0
- Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14

**Describe the expected behavior**

The weight scaling inference rule is a rule described in [the deep learning book by Goodfellow et al., section 7.12, page 260](https://www.deeplearningbook.org/contents/regularization.html) which consists in, in test or predict mode, multiplying the weights by 1 minus the dropout rate, ""to balance for the fact that more units are active than at training time"", to quote [the TF 2 tutorial about overfitting, section ""Add dropout""](https://www.tensorflow.org/beta/tutorials/keras/overfit_and_underfit), implying that the rule is applied to the Keras `Dropout` layer.

**Describe the current behavior**

I have found no trace of this scaling down of the weights in the code of the `Dropout` Keras layer. In [the actual code](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/core.py), we can see for example, at the end of the `call` method,
```
output = tf_utils.smart_cond(training,
    dropped_inputs,
    lambda: array_ops.identity(inputs))
```
so if `training == False`, the `Dropout` is just the identity.

My first thought was that I was missing something that was hidden elsewhere, maybe in the `fit`, `evaluate` and `predict` method of class `Model`. But then I read [the transformer tutorial](https://www.tensorflow.org/beta/tutorials/text/transformer#evaluate) where custom `evaluate` and `translate` functions are used instead of the methods of class `Model`, along with some `Dropout` layers. And it seems to confirm that calling a `Dropout` layer with `training == False` does not implement the weight scaling inference rule.

**Dropout as a Wrapper for other layers ?**

On the other hand, as a `Dropout` layer is not linked to any set of weights, it seems difficult to implement the weight scaling inference rule as is. Shouldn't `Dropout` be a subclass of `Wrapper` instead of `Layer`, allowing it to be feeded with a layer with some weights, and then applying the dropout to the outputs of this layer in training mode, while scaling down its weights in test and predict mode ?

"
29799,Could we have F1 Score and F-Scores in TF 2.0?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): TF 2.0 alpha
- Are you willing to contribute it (Yes/No): Unlikely. I am going to try to build a workaround, but I've never contributed to TF and probably wouldn't be able to figure out the right way to put together code you'd want in master...I will post any useful code I come up with though if allowed.


**Describe the feature and the current behavior/state.**
I would like to be able to do 'model.compile(..., metrics=['F1'])
Or even 'model.compile(..., metrics=['FX']) for an arbitrary float X.
I'm guessing we don't currently have it because it's not in Keras?

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
F1 score and F-scores are relatively common in evaluating classification algorithms.

**Any Other info.**
I see a related request, seemingly for TF 1.x, in 
https://github.com/tensorflow/tensorflow/issues/28207
but I don't know if it went anywhere.

https://en.wikipedia.org/wiki/F1_score
"
29798,AttributeError: 'Sequential' object has no attribute 'target_tensors',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.0-rc0
- Python version: 3.6.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

Example works fine with tensorflow 1.13.1.

import os
import tensorflow as tf
from tensorflow.keras import datasets, layers, models

(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()
train_images = train_images.reshape((60000, 28, 28, 1))
test_images = test_images.reshape((10000, 28, 28, 1))
train_images, test_images = train_images / 255.0, test_images / 255.0
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

tpu_model = tf.contrib.tpu.keras_to_tpu_model(model,
          strategy=tf.contrib.tpu.TPUDistributionStrategy(
          tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
        ))
tpu_model.fit(train_images, train_labels, epochs=5)

When using tensorflow 1.14.0-rc1, I got following error:

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-8-73ec4b0d99a3> in <module>()
      1 tpu_model = tf.contrib.tpu.keras_to_tpu_model(model,
      2           strategy=tf.contrib.tpu.TPUDistributionStrategy(
----> 3           tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
      4         ))
      5 tpu_model.fit(train_images, train_labels, epochs=5)

2 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in __init__(self, cpu_model, strategy)
   1426           self._cpu_model.sample_weight_mode,
   1427           self._cpu_model._compile_weighted_metrics,
-> 1428           self._cpu_model.target_tensors,
   1429       )
   1430 

AttributeError: 'Sequential' object has no attribute 'target_tensors'"
29797,No library found under: /usr/lib64/stubs/libcuda.so,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 30
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: master 
- Python version: 3.7
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 0.26.0
- GCC/Compiler version (if compiling from source): 7.4
- CUDA/cuDNN version: 10.1
- GPU model and memory: Nvidia Quadro 2200M 4G

After problems with manually installed nvidia drivers, I've switched to using the nvidia packages from negativo17 (https://github.com/negativo17/nvidia-driver), and I get the below error when building TF. As per this issue

https://github.com/negativo17/cuda/issues/18

there are no stubs in the packages. Does the build absolutely need the stubs, or is there a workaround (e.g., some local modification I could make to the `bazel` config)?

Many thanks in advance!!

```
Starting local Bazel server and connecting to it...
WARNING: The following configs were expanded more than once: [cuda, using_cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=190
INFO: Reading rc options for 'build' from /home/key/code/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
INFO: Reading rc options for 'build' from /home/key/code/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/home/key/anaconda3/envs/0613/bin/python --action_env PYTHON_LIB_PATH=/home/key/anaconda3/envs/0613/lib/python3.7/site-packages --python_path=/home/key/anaconda3/envs/0613/bin/python --config=xla --action_env CUDA_TOOLKIT_PATH=/usr --action_env TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0 --action_env GCC_HOST_COMPILER_PATH=/home/key/MYBUILDS/GCC7/bin/gcc --config=cuda --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:xla in file /home/key/code/tensorflow/.tf_configure.bazelrc: --define with_xla_support=true
INFO: Found applicable config definition build:cuda in file /home/key/code/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /home/key/code/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:opt in file /home/key/code/tensorflow/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true
INFO: Found applicable config definition build:cuda in file /home/key/code/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /home/key/code/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Call stack for the definition of repository 'local_config_cuda' which is a cuda_configure (rule definition at /home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl:1268:18):
 - /home/key/code/tensorflow/tensorflow/workspace.bzl:63:5
 - /home/key/code/tensorflow/WORKSPACE:94:1
ERROR: An error occurred during the fetch of repository 'local_config_cuda':
   Traceback (most recent call last):
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1266
		_create_local_cuda_repository(repository_ctx)
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1033, in _create_local_cuda_repository
		_find_libs(repository_ctx, cuda_config)
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 608, in _find_libs
		_find_cuda_lib(""cuda"", repository_ctx, cpu_value, (cu...), ...)
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 589, in _find_cuda_lib
		find_lib(repository_ctx, [(""%s/%s"" % (based...))], ...)))
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 566, in find_lib
		auto_configure_fail((""No library found under: "" + "",...)))
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 325, in auto_configure_fail
		fail((""\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: No library found under: /usr/lib64/stubs/libcuda.so
ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1266
		_create_local_cuda_repository(repository_ctx)
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1033, in _create_local_cuda_repository
		_find_libs(repository_ctx, cuda_config)
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 608, in _find_libs
		_find_cuda_lib(""cuda"", repository_ctx, cpu_value, (cu...), ...)
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 589, in _find_cuda_lib
		find_lib(repository_ctx, [(""%s/%s"" % (based...))], ...)))
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 566, in find_lib
		auto_configure_fail((""No library found under: "" + "",...)))
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 325, in auto_configure_fail
		fail((""\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: No library found under: /usr/lib64/stubs/libcuda.so
WARNING: Target pattern parsing failed.
ERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1266
		_create_local_cuda_repository(repository_ctx)
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1033, in _create_local_cuda_repository
		_find_libs(repository_ctx, cuda_config)
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 608, in _find_libs
		_find_cuda_lib(""cuda"", repository_ctx, cpu_value, (cu...), ...)
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 589, in _find_cuda_lib
		find_lib(repository_ctx, [(""%s/%s"" % (based...))], ...)))
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 566, in find_lib
		auto_configure_fail((""No library found under: "" + "",...)))
	File ""/home/key/code/tensorflow/third_party/gpus/cuda_configure.bzl"", line 325, in auto_configure_fail
		fail((""\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: No library found under: /usr/lib64/stubs/libcuda.so

```

"
29795,Protobuf converter for backwards compatibility,"
**System information**
- TensorFlow version (you are using): 1.3.0 / 1.13.1
- Are you willing to contribute it (Yes/No): yes

**Describe the feature and the current behavior/state.**
Situation: I need to develop a CNN for a system which only has tensorflow 1.3.0. Since that version doesn't come with keras, I simply create a model using tensorflow 1.13.1 and save it as a protobuf file. Then, I import the protobuf file in tensorflow 1.3.0

Expected result: I can import the protobuf file also in tensorflow 1.3.0, since I didn't use any new features

Actual result: I get an error similar to https://github.com/tensorflow/tensorflow/issues/17628

**Proposed solution: Can we write a converter, which tries to translate protobufs file generated from newer tensorflow versions to ones which can be read in older versions?**

**Will this change the current api? How?**
This could be an additional script, but would not change existing code

**Who will benefit with this feature?**
Anybody who has to develop models for systems running old tensorflow versions

**Any Other info.**
In order to start one would need an overview of how the protobuf file generation (from graph_defs) has developed in each tensorflow version. Is there any such overview available?
"
29794,Convert Keras to tflite,"I tried converting my keras file to tflite file .But facing below issue 

java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 30000 bytes and a ByteBuffer with 602112 bytes.

**used below code in colab**

from tensorflow.contrib import lite
converter = lite.TFLiteConverter.from_keras_model_file( 'plano.h5')
tfmodel = converter.convert()
open (""plano_tensor_colab.tflite"" , ""wb"") .write(tfmodel)

New to tensor flow .Please help how to convert keras to tensorflowlite."
29793,latest stable tensorflow which is compatible with cuda 9,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 1.12.2
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 9
- GPU model and memory:



**Describe the problem**
I want to know which is the last known stable version which is compatible with cuda 9. Iwant to use lateset tensorflow code which has a bug fix but i am not able to do coz that is not compatible with cuda 9. I cant upgrade to cuda 10, it will break others old model architecture. 


**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29792,Tensorflow lite: micro_vision is missing person_detect_model_data.cc,"Micro vision demo of the Tensorflow Lite is missing model file `person_detect.tflite` as well as `person_detect_model_data.cc` due to which it can't be compiled.

Tensorflow repo info:
```
commit b5102aa41000068787f56a25c3fd48f7d9a80f42 (HEAD -> master, origin/master, origin/HEAD)
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Jun 14 02:39:21 2019 -0700

    Remove absl::bit_casts of non-trivially-copyable Eigen types, and replace them with a new, extensible xla::BitCast call. The latter does everything absl::bit_cast does, but additionally can be specialized to support non-trivial types.
    
    PiperOrigin-RevId: 253194104
```
"
29791,AttributeError: 'KerasTPUModel' object has no attribute '_ckpt_saved_epoch',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.0-rc1
- Python version: 3.6.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

Code is running in Colab and was working fine with tensorflow 1.13.1.
Colab was updated to tensorflow 1.14.0-rc1 today apparently which is causing the regression.
Running tpu_model.fit for a TPU model that was generated with tf.contrib.tpu.keras_to_tpu_model, I get:

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-9-bbab49a84214> in <module>()
     14 
     15 print(datetime.now())
---> 16 history = tpu_model.fit(train_dataset_fn, epochs=nb_epochs, steps_per_epoch=total_samples // batch_size, validation_data=val_dataset_fn, validation_steps=batch_size) # , verbose=2)
     17 print(datetime.now())

3 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in configure_callbacks(callbacks, model, do_validation, batch_size, epochs, steps_per_epoch, samples, verbose, count_mode, mode)
    118   callback_list.model.stop_training = False
    119   # pylint: disable=protected-access
--> 120   if callback_list.model._ckpt_saved_epoch is not None:
    121     # The attribute `_ckpt_saved_epoch` is supposed to be None at the start of
    122     # training (it should be made None at the end of successful multi-worker

AttributeError: 'KerasTPUModel' object has no attribute '_ckpt_saved_epoch'"
29790,Do you have a 3Ddata of crop_and_resize function implementation?,"Do you have a 3Ddata of crop_and_resize function implementation? DATA of shape `[batch, depth, image_height, image_width, channel]`.  If not, are the crop_and_resize implementations of 2D detailed? As long as I know the implementation details of 2D, I can realize the application of 3D.
"
29789,Runtime parameters passed to input_fn for tf.estimator ,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.10+ < 2
- Are you willing to contribute it (Yes/No): yes



**Describe the feature and the current behavior/state.**
Currently, to my knowledge, if one uses `tf.estimator.TrainSpec` / `tf.estimator.EvalSpec` the argument ""`input_fn`"" takes a function for producing either an iterator or something that returns a tuple of `(features, labels)`. However there does not seem to be a way to add epoch based variation to the dataset. 

It would be nice if TF would  automatically pass runtime parameters to this function e.g. via

```python
def input_fn(files:list, params:dict, _runtime_params:dict=None):
    # access to epoch via _runtime_params[""epoch""]
``` 

While the use of epoch specific inputs during training will introduce a bottle neck it can be sometimes necessary.


**Will this change the current api? How?**

It will not break existing code. It will simply allow the user to have epoch / step specific control over the input function (e.g. if they want to upsample an underrepresented class from the last 200 epochs)

**Who will benefit with this feature?**
everyone who uses estimators

**Any Other info.**
"
29788,"Install from pip, run test and results in ""illegal instruction"" for tensorflow-gpu","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOs 7.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip per https://www.tensorflow.org/install/pip
- TensorFlow version: 1.11.0
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:  cuda9.0 and cudnn7.0
- GPU model and memory: Tesla P100

**Describe the problem**
when i  import tensorflowï¼Œthe error as followï¼š
illegal instruction
i don't know whyï¼Œplease help me.
"
29786,Why does tensorflow occupy different gpu memory for the same inference process on different gpu card?,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes, my code is similar to examples/label_image.cc in c++ with *.pb(frozen model)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):centos7.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: sorry, I dont't know
- TensorFlow installed from (source or binary): source, just compile the c++ api library
- TensorFlow version (use command below):v1.13.1
- Python version:python2.7
- Bazel version (if compiling from source):0.21.0
- GCC/Compiler version (if compiling from source):4.8.5
- CUDA/cuDNN version:10.0/7.5
- GPU model and memory: p40(24G * 4), v100(24G*8)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**


when I run the inference process (video action recognition with I3D, the input shape (32 * 224 * 224 * 3)) on different card, I got following infomation:

(1) on p40, on device:0, it occupy 4235MiB memory(the available free memory is still about 6G), some other process have been existing on the same card;

(2) on p40, on device:1, it occupy 8300MiB, only the I3D inference model is running on the card

(3) on v100, on device:0, it only occupy about 1G memory,  only the I3D inference model is running on the card


And where is the relative code with allocator in tensorflow ? 

And I want to know clearly the gpu memory allocator mechanism, than you very much!

And I set allow_growth = true in my c++ inference program, and I set CUDA_VISIBLE_DEVICE to the current device id at each running!

Thank you!

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29785,Cannot build the code including stream_executor/rng.h on Windows,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 x64
- TensorFlow installed from (source or binary):source
- TensorFlow version (use command below):1.14-rc0
- Python version:3.6
- Bazel version (if compiling from source):0.26.0

**Describe the current behavior**
I cannot build the code including stream_executor/rng.h on Visual Studio 2015 as following.
```
tensorflow/compiler/jit/graphcycles/graphcycles.cc(62): note: see reference to class template instantiation 'tensorflow::OrderedSet<tensorflow::int32>' being compiled
ERROR: D:/a/1/s/tensorflow/tensorflow/stream_executor/BUILD:102:1: C++ compilation of rule '//tensorflow/stream_executor:kernel' failed (Exit 2): cl.exe failed: error executing command 
  cd D:/a/1/b/execroot/org_tensorflow
  SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\ATLMFC\INCLUDE;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\ucrt;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.6.1\include\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\winrt;
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\BIN\amd64;C:\windows\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\IDE;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\Tools;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\Program Files (x86)\Windows Kits\10\bin\x86;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.6.1 Tools\x64\;;C:\windows\system32
    SET PWD=/proc/self/cwd
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\VSSADM~1\AppData\Local\Temp
    SET TF_DOWNLOAD_CLANG=0
    SET TF_NEED_CUDA=0
    SET TF_NEED_OPENCL_SYCL=0
    SET TF_NEED_ROCM=0
    SET TMP=C:\Users\VSSADM~1\AppData\Local\Temp
  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=""redacted"" -D__TIMESTAMP__=""redacted"" -D__TIME__=""redacted"" /Gy /Gw /arch:AVX /Fobazel-out/x64_windows-opt/bin/tensorflow/stream_executor/_objs/kernel/kernel.obj /c tensorflow/stream_executor/kernel.cc
Execution platform: @bazel_tools//platforms:host_platform
.\tensorflow/stream_executor/rng.h(66): error C2589: 'constant': illegal token on right side of '::'
.\tensorflow/stream_executor/rng.h(66): error C2059: syntax error: '::'
.\tensorflow/stream_executor/rng.h(72): error C2589: 'constant': illegal token on right side of '::'
.\tensorflow/stream_executor/rng.h(72): error C2059: syntax error: '::'
Target //tensorflow/compiler/aot:tfcompile failed to build
```

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
bazel build -c opt --color=yes --config=monolithic --verbose_failures //tensorflow/compiler/aot:tfcompile
```

It seems that two odd newline character was mixed into [rng.h](https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/stream_executor/rng.h#L64) as follows.
```
  virtual bool DoPopulateRandGaussian(Stream *stream, float mean, float stddev,
                                      DeviceMemory<float> *v) {
    LOG(ERROR)
        << ""platform's random number generator does not support gaussian"";
    return false;
  }
  virtual bool DoPopulateRandGaussian(Stream *stream, double mean,
                                      double stddev, DeviceMemory<double> *v) {
    LOG(ERROR)
        << ""platform's random number generator does not support gaussian"";
    return false;
  }
```

This issue is critical for us.
Would you like to modify the code?"
29784,Cannot use object loaded by tf.saved_model.load() to create Keras model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
MacOSX 10.13.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
VERSION='2.0.0-dev20190613'
GIT_VERSION='v1.12.1-4034-gb81b902c37'
- Python version:
3.6.8
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
N/A
- GPU model and memory:
N/A

**Describe the current behavior**
The Keras code example in the documentation for the `tf.saved_model.load()` function raises an exception:

```python
model = tf.keras.Model(...)
tf.saved_model.save(model, path)
imported = tf.saved_model.load(path)
outputs = imported(inputs)
```

**Describe the expected behavior**
I expect it to work as advertised. ;-)

**Code to reproduce the issue**
Here's the full code (I tried to add as little as I could):

```python
import tensorflow as tf
from tensorflow import keras
import numpy as np

path = ""my_saved_model""
X_train = np.random.rand(100, 5)
y_train = np.random.rand(100, 1)

model = keras.models.Sequential([keras.layers.Dense(1, input_shape=[5])])
model.compile(loss=""mse"", optimizer=""sgd"")
model.fit(X_train, y_train)

tf.saved_model.save(model, path)

imported = tf.saved_model.load(path)

inputs = keras.layers.Input(shape=[5])
outputs = imported(inputs) # Raises _SymbolicException (see stacktrace below) <<<!!!
model = keras.Model(inputs=[inputs], outputs=[outputs])
```

**Stacktrace**
Here's the full stacktrace:

```python
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     60                                                op_name, inputs, attrs,
---> 61                                                num_outputs)
     62   except core._NotOkStatusException as e:

TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: input_1:0

During handling of the above exception, another exception occurred:

_SymbolicException                        Traceback (most recent call last)
<ipython-input-1-304bb0c5e2fc> in <module>
     16
     17 inputs = keras.layers.Input(shape=[5])
---> 18 outputs = imported(inputs) # Raises _SymbolicException <<<<<<<<<<<<<<!!!
     19 model = keras.Model(inputs=[inputs], outputs=[outputs])

~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py in _call_attribute(instance, *args, **kwargs)
    399
    400 def _call_attribute(instance, *args, **kwargs):
--> 401   return instance.__call__(*args, **kwargs)
    402
    403

~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    431               *args, **kwds)
    432       # If we did not create any variables the trace we have is good enough.
--> 433       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
    434
    435     def fn_with_cond(*inner_args, **inner_kwds):

~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)
    600          if isinstance(t, (ops.Tensor,
    601                            resource_variable_ops.ResourceVariable))),
--> 602         self.captured_inputs)
    603
    604   def _call_flat(self, args, captured_inputs):

~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs)
    682     # Only need to override the gradient in graph mode and when we have outputs.
    683     if context.executing_eagerly() or not self.outputs:
--> 684       outputs = self._inference_function.call(ctx, args)
    685     else:
    686       self._register_gradient()

~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args)
    451             attrs=(""executor_type"", executor_type,
    452                    ""config_proto"", config),
--> 453             ctx=ctx)
    454       # Replace empty list with None
    455       outputs = outputs or None

~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     68   except TypeError as e:
     69     if any(ops._is_keras_symbolic_tensor(x) for x in inputs):
---> 70       raise core._SymbolicException
     71     raise e
     72   # pylint: enable=protected-access

_SymbolicException:
```

**Other info**
I can actually call the `imported` object with tensors, as long as I pass the `training` argument:

```python
>>> imported(tf.random.uniform([10, 5]), training=False)
<tf.Tensor: id=780, shape=(10, 1), dtype=float32, numpy=
array([[-0.7474083 ],
       [-0.25788566],
       [-0.48218375],
       [-0.60376763],
       [-1.4071536 ],
       [-0.45902687],
       [-0.07063864],
       [-0.9497912 ],
       [ 0.03344992],
       [-0.33686087]], dtype=float32)>
```

However, I cannot pass it the `inputs` tensor:

```
>>> imported(inputs, training=False)
...
~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     68   except TypeError as e:
     69     if any(ops._is_keras_symbolic_tensor(x) for x in inputs):
---> 70       raise core._SymbolicException
     71     raise e
     72   # pylint: enable=protected-access

_SymbolicException:
```"
29783,Lazy ExponentialMovingAverage for embedding matrix with sparse gradients,"Currently ExponentialMovingAverage is only designed for small Variables without sparse gradient(https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/training/moving_averages.py#L89). 

Directly calling ""ema.apply(trainable_vars)"" for embedding matrix is significantly slow. Would anyone provide a solution for sparse gradient in somewhat lazy manner?

Similar questions: https://github.com/pytorch/pytorch/issues/1285
"
29782,How to build Dockerfile.ubuntu  for tensorflow-gpu,"How to build Dockerfile.ubuntu  for tensorflow-gpu
ubuntu16.04
tensorflow-gpu1.12.0

I have  nvidia-docker  Dockerfile.ubuntu"
29781,[TF 2.0] tf.hessians,"**System information**
- TensorFlow version: '2.0.0-dev20190612'
- Python version: 3.6.7

**Describe the current behavior**
When you run tf.hessians you get a not supported when eager execution is enabled. Use tf.GradientTape instead Error but Hessians is not implemented in GradientTape.

**Describe the expected behavior**
I am linking the TF 2.0 API doc issue which was opened to fix the API doc to specify you can't use the tf.hessians with eager mode. (https://github.com/tensorflow/tensorflow/issues/29271). So just wanted to make sure someone is working on a Hessians attribute for GradientTape.

**Code to reproduce the issue**
In Eager Mode:
```
f = 100*(y - x**2)**2 + (1 - x)**2
x = tf.Variable([1., 1.])
hessian_matrix = tf.hessians(f, x)

RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.
```

Trying with GradientTape:

```
with tf.GradientTape() as t:
    out = f
dy_dx = t.hessians(out, x)

AttributeError: 'GradientTape' object has no attribute 'hessians'
```

"
29780,a4b3c41 breaks 2019-06-13 nightly build,"The following part of CL a4b3c41775b52d5a2d3d10c8f2f46f645e6f9a5d:

```
diff --git a/tensorflow/compiler/xla/debug_options_flags.cc b/tensorflow/compiler/xla/debug_options_flags.cc
index 5238b01075..8212c1e9b4 100644
--- a/tensorflow/compiler/xla/debug_options_flags.cc
+++ b/tensorflow/compiler/xla/debug_options_flags.cc
@@ -17,6 +17,10 @@ limitations under the License.

 #include <mutex>  // NOLINT(build/c++11): only using std::call_once, not mutex.
 #include <vector>
+
+#include ""absl/container/flat_hash_map.h""
+#include ""absl/container/node_hash_map.h""
+#include ""absl/strings/str_format.h""
 #include ""absl/strings/str_split.h""
 #include ""tensorflow/compiler/xla/debug_options_parsers.h""
 #include ""tensorflow/compiler/xla/parse_flags_from_env.h""
@@ -58,9 +62,42 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {
   return opts;
 }

+static std::once_flag flags_init;
 static DebugOptions* flag_values;
 static std::vector<tensorflow::Flag>* flag_objects;
-static std::once_flag flags_init;
+
+// Maps pass -> initial fuel values (parsed when AllocateFlags was run).
+static absl::flat_hash_map<string, int64>* initial_fuel;
+
+// Maps pass -> whether fuel was ever consumed for that pass.
+static absl::node_hash_map<string, std::atomic<bool>>* fuel_ever_consumed;
+
+// Maps pass -> remaining fuel.
+//
+// All threads start off using this global fuel pool, but ResetThreadLocalFuel()
+// switches them to a thread-local fuel pool.
+static absl::node_hash_map<string, std::atomic<int64>>* global_fuel;
+
+// If we're using thread-local fuel, this stores it.
+static thread_local absl::optional<
+    absl::node_hash_map<string, std::atomic<int64>>>
+    thread_fuel;  // NOLINT (global variable with nontrivial destructor)
+
+// Logs a warning if a pass's fuel was never consumed, on the theory that this
+// may be a typo in the flag value.  Called atexit.
+static void WarnIfFuelWasNeverConsumed() {
+  CHECK(fuel_ever_consumed != nullptr);
+  for (const auto& kv : *fuel_ever_consumed) {
+    absl::string_view pass = kv.first;
+    bool was_consumed = kv.second;
+    if (!was_consumed) {
+      LOG(ERROR) << absl::StreamFormat(
+          ""Compiler fuel for \""%s\"" was never consumed. This may be a typo in ""
+          ""the --xla_fuel flag you passed."",
+          pass);
+    }
+  }
+}

 // Allocates flag_values and flag_objects; this function must not be called more
 // than once - its call done via call_once.
```

Breaks nightly build as `std::atomic<int64>` cannot be used in `absl::flat_hash_map`:

```
ERROR: /tensorflow_src/tensorflow/compiler/xla/BUILD:840:1: C++ compilation of rule '//tensorflow/compiler/xla:debug_options_flags' failed (Exit 1)
In file included from tensorflow/compiler/xla/debug_options_flags.cc:25:0:
./tensorflow/compiler/xla/debug_options_parsers.h: In function 'bool xla::parse_xla_reduce_precision_option(xla::HloReducePrecisionOptions*, std::__cxx11::string)':
./tensorflow/compiler/xla/debug_options_parsers.h:108:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     for (int i = 0; i < HloOpcodeCount(); i++) {
                     ~~^~~~~~~~~~~~~~~~~~
./tensorflow/compiler/xla/debug_options_parsers.h:115:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
       for (int i = 0; i < HloOpcodeCount(); i++) {
                       ~~^~~~~~~~~~~~~~~~~~
In file included from /usr/include/x86_64-linux-gnu/c++/6/bits/c++allocator.h:33:0,
                 from /usr/include/c++/6/bits/allocator.h:46,
                 from /usr/include/c++/6/vector:61,
                 from ./tensorflow/compiler/xla/debug_options_flags.h:19,
                 from tensorflow/compiler/xla/debug_options_flags.cc:16:
/usr/include/c++/6/ext/new_allocator.h: In instantiation of 'void __gnu_cxx::new_allocator<_Tp>::construct(_Up*, _Args&& ...) [with _Up = std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> >; _Args = {const std::pair<const std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::atomic<long long int> >&}; _Tp = std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> >]':
external/com_google_absl/absl/memory/memory.h:574:5:   required from 'static decltype (a.construct((forward<Args>)(absl::allocator_traits::construct_impl::args)...)) absl::allocator_traits<Alloc>::construct_impl(int, A&, Args&& ...) [with A = std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> > >; Args = {std::pair<const std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::atomic<long long int> >*&, const std::pair<const std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::atomic<long long int> >&}; Alloc = std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> > >; decltype (a.construct((forward<Args>)(absl::allocator_traits::construct_impl::args)...)) = void]'
external/com_google_absl/absl/memory/memory.h:536:19:   required from 'static void absl::allocator_traits<Alloc>::construct(Alloc&, T*, Args&& ...) [with T = std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> >; Args = {const std::pair<const std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::atomic<long long int> >&}; Alloc = std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> > >]'
external/com_google_absl/absl/container/node_hash_map.h:540:49:   required from 'static absl::container_internal::NodeHashMapPolicy<Key, Value>::value_type* absl::container_internal::NodeHashMapPolicy<Key, Value>::new_element(Allocator*, Args&& ...) [with Allocator = std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> > >; Args = {const std::pair<const std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::atomic<long long int> >&}; Key = std::__cxx11::basic_string<char>; Value = std::atomic<long long int>; absl::container_internal::NodeHashMapPolicy<Key, Value>::value_type = std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> >]'
external/com_google_absl/absl/container/internal/node_hash_policy.h:54:32:   required from 'static void absl::container_internal::node_hash_policy<Reference, Policy>::construct(Alloc*, typename std::remove_cv<typename std::remove_reference<_From>::type>::type**, Args&& ...) [with Alloc = std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> > >; Args = {const std::pair<const std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::atomic<long long int> >&}; Reference = std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> >&; Policy = absl::container_internal::NodeHashMapPolicy<std::__cxx11::basic_string<char>, std::atomic<long long int> >; absl::container_internal::node_hash_policy<Reference, Policy>::slot_type = std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> >*; typename std::remove_cv<typename std::remove_reference<_From>::type>::type = std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> >]'
external/com_google_absl/absl/container/internal/hash_policy_traits.h:76:22:   required from 'static void absl::container_internal::hash_policy_traits<Policy, <template-parameter-1-2> >::construct(Alloc*, absl::container_internal::hash_policy_traits<Policy, <template-parameter-1-2> >::slot_type*, Args&& ...) [with Alloc = std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> > >; Args = {const std::pair<const std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::atomic<long long int> >&}; Policy = absl::container_internal::NodeHashMapPolicy<std::__cxx11::basic_string<char>, std::atomic<long long int> >; <template-parameter-1-2> = void; absl::container_internal::hash_policy_traits<Policy, <template-parameter-1-2> >::slot_type = std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> >*]'
external/com_google_absl/absl/container/internal/raw_hash_set.h:1698:28:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]
external/com_google_absl/absl/container/internal/raw_hash_set.h:815:49:   required from 'absl::container_internal::raw_hash_set<Policy, Hash, Eq, Alloc>::raw_hash_set(const absl::container_internal::raw_hash_set<Policy, Hash, Eq, Alloc>&) [with Policy = absl::container_internal::NodeHashMapPolicy<std::__cxx11::basic_string<char>, std::atomic<long long int> >; Hash = absl::container_internal::StringHash; Eq = absl::container_internal::StringHashEq::Eq; Alloc = std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::atomic<long long int> > >]'
external/com_google_absl/absl/container/internal/raw_hash_map.h:29:7:   required from 'struct std::is_trivially_copy_constructible<absl::node_hash_map<std::__cxx11::basic_string<char>, std::atomic<long long int> > >'
external/com_google_absl/absl/meta/type_traits.h:366:54:   required from 'constexpr const bool absl::is_trivially_copy_constructible<absl::node_hash_map<std::__cxx11::basic_string<char>, std::atomic<long long int> > >::compliant'
external/com_google_absl/absl/meta/type_traits.h:368:27:   required from 'struct absl::is_trivially_copy_constructible<absl::node_hash_map<std::__cxx11::basic_string<char>, std::atomic<long long int> > >'
external/com_google_absl/absl/types/internal/optional.h:173:72:   required from 'class absl::optional<absl::node_hash_map<std::__cxx11::basic_string<char>, std::atomic<long long int> > >'
tensorflow/compiler/xla/debug_options_flags.cc:84:5:   required from here
/usr/include/c++/6/ext/new_allocator.h:120:4: error: use of deleted function 'constexpr std::pair<_T1, _T2>::pair(const std::pair<_T1, _T2>&) [with _T1 = const std::__cxx11::basic_string<char>; _T2 = std::atomic<long long int>]'
  { ::new((void *)__p) _Up(std::forward<_Args>(__args)...); }
    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from /usr/include/c++/6/bits/stl_algobase.h:64:0,
                 from /usr/include/c++/6/vector:60,
                 from ./tensorflow/compiler/xla/debug_options_flags.h:19,
                 from tensorflow/compiler/xla/debug_options_flags.cc:16:
/usr/include/c++/6/bits/stl_pair.h:288:17: note: 'constexpr std::pair<_T1, _T2>::pair(const std::pair<_T1, _T2>&) [with _T1 = const std::__cxx11::basic_string<char>; _T2 = std::atomic<long long int>]' is implicitly deleted because the default definition would be ill-formed:
       constexpr pair(const pair&) = default;
                 ^~~~
/usr/include/c++/6/bits/stl_pair.h:288:17: error: use of deleted function 'std::atomic<long long int>::atomic(const std::atomic<long long int>&)'
In file included from external/protobuf_archive/src/google/protobuf/io/coded_stream.h:113:0,
                 from bazel-out/host/bin/tensorflow/compiler/xla/xla.pb.h:23,
                 from ./tensorflow/compiler/xla/debug_options_flags.h:22,
                 from tensorflow/compiler/xla/debug_options_flags.cc:16:
/usr/include/c++/6/atomic:692:7: note: declared here
       atomic(const atomic&) = delete;
       ^~~~~~
```

I am sure someone in the team notices this; I just need a marker so I will know when it is fixed."
29779,Compiler dependent error for TFLite micro's FastInt32ToBufferLeft,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 x64
- TensorFlow installed from (source or binary):source
- TensorFlow version (use command below):1.14.0-rc1
- Python version:not used
- Bazel version (if compiling from source):not used
- GCC/Compiler version (if compiling from source):Visual C++ 14 or higher.

**Describe the current behavior**
Can't build all TFLite micro's samples on Windows or some embedded systems (requires Visual C++).

**Describe the expected behavior**

[TFLite micro's FastInt32ToBufferLeft](https://github.com/tensorflow/tensorflow/blob/4053e17dbb7a1be85553e5173c2e08fb9653d33f/tensorflow/lite/experimental/micro/debug_log_numbers.cc#L80) causes Error C4146 `unary minus operator applied to unsigned type, result still unsigned` on Visual C++. Meanwhile, tensoflow's implementaion has no problem.
This issue can be solved by rewriting `u = -u;` to `u = 0 - u;` as follows.

* [TFLite micro's FastInt32ToBufferLeft](https://github.com/tensorflow/tensorflow/blob/4053e17dbb7a1be85553e5173c2e08fb9653d33f/tensorflow/lite/experimental/micro/debug_log_numbers.cc#L80)
```cpp
// Populates the provided buffer with an ASCII representation of the number.
char* FastInt32ToBufferLeft(int32_t i, char* buffer) {
  uint32_t u = i;
  if (i < 0) {
    *buffer++ = '-';
    u = -u;
  }
  return FastUInt32ToBufferLeft(u, buffer, 10);
}
```

* [Tensorflow's FastInt32ToBufferLeft](https://github.com/tensorflow/tensorflow/blob/4213d5c1bd921f8d5b7b2dc4bbf1eea78d0b5258/tensorflow/core/lib/strings/numbers.cc#L131)
```cpp
size_t FastInt32ToBufferLeft(int32 i, char* buffer) {
  uint32 u = i;
  size_t length = 0;
  if (i < 0) {
    *buffer++ = '-';
    ++length;
    // We need to do the negation in modular (i.e., ""unsigned"")
    // arithmetic; MSVC++ apparently warns for plain ""-u"", so
    // we write the equivalent expression ""0 - u"" instead.
    u = 0 - u;
  }
  length += FastUInt32ToBufferLeft(u, buffer);
  return length;
}
```

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```cpp
#include ""tensorflow/lite/experimental/micro/debug_log_numbers.h""
int main()
{
    char s[80];
    FastInt32ToBufferLeft(-1, s);
    return 0;
}
```
This issue is critical for us.
Would you like to modify the code?"
29778,GPU usage increases after dozens of steps,"Could you support gpu trace tools for us.@tensorflow
I cant find cause of this bug. 
```
# @tf.function
def train_step(inputs):
    with tf.GradientTape() as tape:
        losses = model(inputs)
    grads = tape.gradient(losses[""total_loss""], model.variables)   
    optimizer.apply_gradients(zip(grads, model.variables),
                              global_step=tf.train.get_or_create_global_step())
    return losses


for epoch in range(10):
    for (batch, inputs) in enumerate(train_dataset):
        # ckpt.step.assign_add(1)
        # print (ckpt.step.numpy())
        losses = train_step(inputs)
```
OOM error after nearly 100 steps. batch_size=1, gpu usage from 11G to 23G+. GPU usage increase after each twenty-odd steps.
train_dataset reader is tf.data. 

tensorflow 1.13 
GPU titan rtx 24G
cuda 10.0 
"
29777,7e1deb1 breaks 2019-06-13 nightly build,"The following part in CL 7e1deb16c6f10a477003b5f2caadbe3e6fb48af4:

```
diff --git a/tensorflow/python/BUILD b/tensorflow/python/BUILD
index 6145b06a9c..a56a3fd488 100644
--- a/tensorflow/python/BUILD
+++ b/tensorflow/python/BUILD
@@ -36,13 +36,10 @@ load(""//tensorflow:tensorflow.bzl"", ""py_tests"")
 load(""//tensorflow:tensorflow.bzl"", ""tf_py_build_info_genrule"")
 load(""//tensorflow:tensorflow.bzl"", ""tf_py_wrap_cc"")
 load(""//tensorflow:tensorflow.bzl"", ""tf_cc_shared_object"")
-load(""//tensorflow:tensorflow.bzl"", ""tf_native_cc_binary"")
-load(""//tensorflow:tensorflow.bzl"", ""tf_custom_op_library_additional_deps_impl"")
 load(""//tensorflow:tensorflow.bzl"", ""cuda_py_test"")
 load(""//tensorflow:tensorflow.bzl"", ""cuda_py_tests"")
 load(""//tensorflow/core:platform/default/build_config.bzl"", ""pyx_library"")
 load(""//tensorflow/core:platform/default/build_config.bzl"", ""tf_proto_library"")
-load(""//tensorflow/core:platform/default/build_config.bzl"", ""tf_proto_library_py"")
 load(""//tensorflow/core:platform/default/build_config.bzl"", ""tf_additional_lib_deps"")
 load(""//tensorflow/core:platform/default/build_config.bzl"", ""tf_additional_all_protos"")
 load(""//tensorflow/core:platform/default/build_config.bzl"", ""tf_protos_grappler"")
```

Causes nightly build break:

```
ERROR: /tensorflow_src/tensorflow/python/BUILD:4563:1: name 'tf_proto_library_py' is not defined (did you mean 'tf_proto_library'?)
```

I am sure someone in the team notices this; I just need a marker so I will know when it is fixed."
29776,Please add a flag to prevent app.run from terminating with  _sys.exit(main(argv)),"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

**System information**
- TensorFlow version (you are using): 1.12.x, for now
- Are you willing to contribute it (Yes/No): No. Simple fix but easy to depart from tf naming conventions, and also to not propagate it properly through the code and doc.

**Describe the feature and the current behavior/state.**
Current behavior is for tf to call _sys.exit at the end of app.run completion:

tensorflow/tensorflow/python/platform/app.py, line 125: 
```
 # Call the main function, passing through any arguments
  # to the final program.
  _sys.exit(main(argv))
```
In python applications where tf.app.run is to be invoked multiple times, it would be useful to suppress the _sys.exit. The current workaround is to call out to an external script, only for the purpose of continued processing after the app.run call.

WHat's needed is a flag - something like _prevent_sys_exit, or whatever is consistent with tf flag naming conventions.
 
**Will this change the current api? How?**
Probably not, but would add another flag to externally specifiable set of tf flags.
**Who will benefit with this feature?**
Anyone with a need to not have a python sys.exit call immediately after running a tf app.

 A specific benefit is to aid both logging and debugging, which are much more difficult with call-outs to external scripts.

**Any Other info.**
"
29772,Bug for calling end() of SessionRunHook,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- Linux Ubuntu 18.04
- TensorFlow installed from: pip
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.7
- CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6
- GPU model and memory: 2080Ti

**Describe the current behavior**
I define a hook class which is inherited from SessionRunHook, and add an assign operation in the begin() function. Then, I run the assign operation in the end() function. Although the value is changed, the results do not store into the checkpoint. So, If I restore the model, I get the model which is not changed. 

**Describe the expected behavior**
Since we only know the end() is called before closing the session. I think the changed result should be store in the chekpoint. Otherwise, the document should provide the ordering of executing all hooks. 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
class NetworkPruningHook(tf.train.SessionRunHook):
    def __init__(self):

    def begin(self):
      self.mask_var = []
      ### collect the masked variables
      for v in tf.global_variables():
        if v.name.find(""mask:0"") != -1:
          self.mask_var.append(v)

      self.check_mask = tf.assign(self.mask_var[0], np.zeros(shape=self.mask_var[0].shape))

    def end(self, session):
      session.run(self.check_mask) # assign 0 to the variable 
      print(session.run(self.mask_var[0])) # get [0, ..., 0]
      
      ### However, if restoring the checkpoint, the self.mask_var[0] is not [0, ..., 0]

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29771,Multi GPU training - inconstant results between virtual GPUs and non Virtual GPUs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
    - Modified from the stock example
    - https://www.tensorflow.org/beta/tutorials/distribute/keras
    - Working example is attached to this bug report
- OS Platform and Distribution
    - Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
    - No
- TensorFlow installed from (source or binary):
    - Binary
- TensorFlow version (use command below):
    - 2.0.0-beta0
- Python version:
    - Python 3.5.2
- Bazel version (if compiling from source):
    - N/A (0.23.2)
- GCC/Compiler version (if compiling from source):
    - N/A (5.4.0 20160609)
- CUDA/cuDNN version:
    - 10.0.130/7.4.1
- GPU model and memory:
    - 4x Titan Xp (12Gb) (Standalong, no SLI connections)

**Describe the current behavior**
The model accuracy is far off between virtual GPUs and physical GPUs. The default tf.distribute.MirroredStrategy() is used for multi GPU training.


**Describe the expected behavior**
The trained model should achieve similar level of accuracy regardless of virtual devices (0.9938) or physical devices (0.9698).

**Code to reproduce the issue**
1. The script attached is used to train a model using multiple GPUs.
  * The code is modified from the stock example for quick experiment.
    * https://www.tensorflow.org/beta/tutorials/distribute/keras
  * Traing using two VirtualDevices after 10 epoches
    * when only one GPU is detected, two virtual devices will be created. (init_gpu())
    * Use the following command to run the script
```
export CUDA_VISIBLE_DEVICES=""0""
python3 mnist_muti_gpus.py
```
  * results after 10 epoches
```
Epoch 10/10
465/469 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9937
Learning rate for epoch 10 is 0.00001
469/469 [==============================] - 4s 9ms/step - loss: 0.0249 - accuracy: 0.9938

...

Epoch 20/20
463/469 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9939
Learning rate for epoch 20 is 0.00001
469/469 [==============================] - 4s 8ms/step - loss: 0.0239 - accuracy: 0.9940

```

  * Traing using two GPUs (non virtual) after 10 epoches
    * If more than one GPU is visiable, no virtual device will be created. (init_gpu())
    * Use the following command to run the script
```
export CUDA_VISIBLE_DEVICES=""0,1""
python3 mnist_muti_gpus.py
```
  * results after 10 epoches
```
Epoch 10/10
464/469 [============================>.] - ETA: 0s - loss: 0.1421 - accuracy: 0.9697
Learning rate for epoch 10 is 0.00001
469/469 [==============================] - 4s 8ms/step - loss: 0.1421 - accuracy: 0.9698

...

Epoch 20/20
465/469 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9728
Learning rate for epoch 20 is 0.00001
469/469 [==============================] - 4s 9ms/step - loss: 0.1157 - accuracy: 0.9728

```

**Other info / logs**


```python
""""""
This script is extended from the following stock example:
https://www.tensorflow.org/beta/tutorials/distribute/keras
""""""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization
from tensorflow.keras.layers import Conv2D, MaxPool2D
from tensorflow.keras import optimizers
from tensorflow.keras import losses
from tensorflow.keras import initializers
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Activation

import tensorflow as tf
import tensorflow_datasets as tfds
import math
import os

# Initialize GPUs
# This function must be called first
# Setting up GPU memory ussage
# https://www.tensorflow.org/beta/guide/distribute_strategy
# https://www.tensorflow.org/beta/guide/using_gpu
def init_gpus(soft_device_placement=True, log_device_placement=False, create_virtual_devices=False, memory_limit=4096):

    tf.config.set_soft_device_placement(soft_device_placement)    
    tf.debugging.set_log_device_placement(log_device_placement)

    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        # If there is only one GPU, create two logical virtual devices for developing
        # on a machine with only one GPU installed
        try:
            # Create 2 virtual GPUs on each physical GPU with the given memory_limit GPU memory
            if create_virtual_devices and len(gpus) == 1:
                for gpu in gpus:
                    tf.config.experimental.set_virtual_device_configuration(
                        gpu,
                        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096),
                         tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]
                    )

            else:
                # Currently, memory growth needs to be the same across GPUs
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)

        except RuntimeError as e:
            # Memory growth must be set before GPUs have been initialized
            print(e)

        # print out physical and logical GPUs
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")

    else:
        print(""No visible GPU is detected..."")

def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255
    return image, label

# Callback for printing the LR at the end of each epoch.
class PrintLR(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        print('\nLearning rate for epoch %d is %.5f' %(epoch + 1, self.model.optimizer.lr.numpy()))

# Function for decaying the learning rate.
# You can define any decay function you need.
def decay(epoch):
    if epoch < 3:
        return 1e-3
    elif epoch >= 3 and epoch < 7:
        return 1e-4
    else:
        return 1e-5

def run():
    ### get data
    init_gpus(
        log_device_placement=False,
        create_virtual_devices=True
    )

    # 
    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())
    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())
    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce())
    strategy = tf.distribute.MirroredStrategy()
    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))

    # Setting with_info to True includes the metadata for the entire dataset, 
    # which is being saved here to info. Among other things, this metadata object
    # includes the number of train and test examples.
    datasets, info = tfds.load(
        name='mnist',
        with_info=True,
        as_supervised=True
    )
    mnist_train, mnist_test = datasets['train'], datasets['test']

    # You can also do info.splits.total_num_examples to get the total
    # number of examples in the dataset.
    num_train_examples = info.splits['train'].num_examples
    num_test_examples = info.splits['test'].num_examples

    #
    print(""num_train_examples = %d, num_test_examples = %d"" %(num_train_examples, num_test_examples))

    BUFFER_SIZE = num_train_examples
    BATCH_SIZE_PER_REPLICA = 64
    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync
    EPOCHS = 20

    # train_dataset = mnist_train.map(scale).shuffle(num_train_examples).repeat().batch(BATCH_SIZE)
    train_dataset = mnist_train.shuffle(num_train_examples).repeat().map(scale).batch(BATCH_SIZE)
    eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)

    with strategy.scope():
        ### compile
        ## Seperate the activation layer so that BatchNormalization can be added later on.
        model = tf.keras.Sequential([
            tf.keras.layers.Conv2D(32, 3, input_shape=(28, 28, 1)),
            tf.keras.layers.Activation(activation='relu'),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(64),
            tf.keras.layers.Activation(activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ])

        model.compile(
            loss='sparse_categorical_crossentropy',
            optimizer=tf.keras.optimizers.Adam(),
            metrics=['accuracy']
        )
        model.summary()

    # print out physical and logical GPUs
    gpus = tf.config.experimental.list_physical_devices('GPU')
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")

    # Define the checkpoint directory to store the checkpoints
    checkpoint_dir = './training_checkpoints'
    # Name of the checkpoint files
    checkpoint_prefix = os.path.join(checkpoint_dir, ""ckpt_{epoch}"")

    callbacks = [
        tf.keras.callbacks.TensorBoard(log_dir='./logs'),
        tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True),
        tf.keras.callbacks.LearningRateScheduler(decay),
        PrintLR()
    ]

    steps_per_epoch = math.ceil(num_train_examples / BATCH_SIZE)
    model.fit(
        train_dataset,
        steps_per_epoch=steps_per_epoch,
        epochs=EPOCHS,
        callbacks=callbacks
    )

    # validation
    eval_loss, eval_acc = model.evaluate(eval_dataset)

    K.clear_session()
    return

if __name__ == '__main__':
    run()

```"
29770,"tf.keras: predict, fit, predict = old result","Windows 10 / Python 3.7 / TF 1.13

```python
m = model.predict(inputs)
print(model.fit(inputs, outputs, batch_size=inputs.shape[0], verbose=1)) # OK: loss: 16.0302
print(model.predict(inputs) - m) # all = 0
```
Synchronization of the weights for the last call predict() does not work."
29767,Support for distributed custom input pipeline,"Feature Request
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04 and 18.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
No
- **TensorFlow installed from (source or binary)**:
Docker hub image using: FROM tensorflow/tensorflow:2.0.0b0-gpu-py3
- **TensorFlow version (use command below)**:
v1.12.1-3259-gf59745a381 2.0.0-beta0
- **Python version**:
Python 3.6.8
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
See prebuilt docker image
- **GPU model and memory**:
Nividia GeForce GTX TITAN-X (Maxwell)
- **Exact command to reproduce**:
None, since this is a feature request

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
This is a feature request:
---------------------------------
In the guide for TensorFlow 2.0 at https://www.tensorflow.org/beta/guide/distribute_strategy
there is an example for using tf.distribute.Strategy with custom training loops. However this guide assumes that one uses tf.data.Dataset for the input pipeline.

I have the need for a very dynamic input pipeline since I do inference-based batch mining for triplet training very much like what is described in an article from Google found here:
FaceNet: A Unified Embedding for Face Recognition and Clustering
https://arxiv.org/pdf/1503.03832.pdf

I believe such capability is fundamental for having flexible customization capability while being able to distribute training. Fixed input pipeline can be very limiting.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

The above mentioned tutorial assumes you can do something like this with the input pipeline:
```python
with mirrored_strategy.scope():
  dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(1000).batch(
      global_batch_size)
  dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)

with mirrored_strategy.scope():
  for inputs in dist_dataset:
    print(train_step(inputs))
```
Whereas my example of custom inference-based dataset reader looks more like this:
```python
[anchor_inputs, positive_inputs, negative_inputs] = get_dynamic_triplet_batches_pytorch(args, model, dataset_handler)
```
The dataset_handler is entirely custom and is used to provide candidate triplets. Then inference is run on them and if the loss is moderate (as described in the FaceNet paper from Google) the triplet is added to a final training batch. In the end that batch is returned to the training loop for the full backprop pass. However, the need to distribute a custom input pipeline is generic and not limited to this use-case.

The example is taken from code I wrote for PyTorch where the distribution strategy available is very flexible, so this input pipeline works just out-of-the-box (for distributing on GPUs on a single machine). I would like to see this be possible in Tensorflow as well (but here for all distribution strategies of course). This would make Tensorflow more attractive for more advanced use-cases for training. Right now I don't see how it is possible to set up a custom training input pipeline like this with the existing distribution strategies.

BR,
/Niclas


                                                                                                    "
29765,ModuleNotFoundError: No module named 'tensorflow.python.saved_model.model_utils,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):NO
- OS Platform and Distribution :Linux Ubuntu 16.04
- TensorFlow installed from (source or binary):conda install tensorflow-gpu=1.13.1
- Python version:3.6


I have installed tf=2.0.0 before on another conda env ,but after uninstalling tf=2.0.0 the whole tensorflow on every conda env has been ruined. Trying different envs/python-version doesn't work at all. 
`pip uninstall/install tensorflow_estimator` in/out of conda envs doesn't work as well

"
29763,Batched tf.RaggedTensor with tf.data.Dataset returns invalid ragged tensors,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): public colab instance
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.0-rc1
- Python version: 3.6

**Describe the current behavior**
Iterating on a batched dataset made from tensor slices of ragged tensors produces `tf.RaggedTensor` that seem to be improperly formatted. Specifically, calling `RaggedTensor.value_rowids` return the row index for every element in `RaggedTensor.values`. This is inconsistent with the output obtained from calling `RaggedTensor.value_rowids` directly on the original tensor (or slice of the original), and also inconsistent with the format expected by `tf.RaggedTensor. from_value_rowids`.
 
**Describe the expected behavior**
Given a batched ragged tensor `x`, manually building a new one using `tf.RaggedTensor. from_value_rowids(x.values, x.value_rowids())` should work. Currently this raise an exception at runtime (not during graph construction).

**Code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf


data_values = tf.RaggedTensor.from_row_splits(
    np.arange(8).reshape((-1, 2)),
    np.array([0, 2, 3, 4]),
)

dataset = tf.data.Dataset.from_tensor_slices(data_values)
dataset = dataset.repeat()
dataset = dataset.batch(3)

iterator = dataset.make_one_shot_iterator()
batch = iterator.get_next()

a = tf.RaggedTensor.from_value_rowids(batch.values, batch.value_rowids())
with tf.Session() as sess:
  sess.run(a)  # this fails due to invalid shapes
  assert np.allclose(sess.run(batch.value_rowids()),  # this will also fail
                     sess.run(data_values.value_rowids()))
  
```
"
29762,Accuracy Discrepancy Between Eager and Graph Mode Tensorflow Alpha 2.0.0,"**System information**
- Custom and Stock Code
- TensorFlow installed from binary:
- [tf_env.txt](https://github.com/tensorflow/tensorflow/files/3288005/tf_env.txt)
- CUDA/cuDNN version: 
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:04_Central_Daylight_Time_2018
Cuda compilation tools, release 10.0, V10.0.130
- GPU model and memory:
  - Name: NVIDIA GeForce GTX 1060 with Max-Q Design
  - Memory: 8124 MB

**Describe the current behavior**
There is a large accuracy difference between running tensorflow in Eager versus Graph mode 
(i.e. using @tf.function and not using @tf.function) for the same model, number of batches and epochs on the same data.

Three different tests are run to measure performance on both a GPU and CPU if
available. Each test uses tensorflow alpha 2.0, and trains using the MNIST dataset provided/bundled by tensorflow. Each test runs for 1 epoch comprised of 1000 mini-batches. A mini-batch contains 32 samples. All tests use Adam optimizer, and sparse categorical loss.

Test descriptions:
- Test 1: Uses the Keras 'compile' and 'fit' function
- Test 2: Uses tf.GradientTape and does not use the @tf.function decorator
- Test 3: Uses tf.GradientTape and the @tf.function decorator. 
    The @tf.function decorator is applied to the function training 
    on MNIST mini-batches

**Describe the expected behavior**
I would expect roughly the same training accuracy after 1000 steps for each test. When using the @tf.function decorator a much greater accuracy is achieved for the same model type, number of epochs, number of batches, and dataset compared to a training run not using @tf.function. 

**Code to reproduce the issue**
```python
import tensorflow as tf
import tensorflow_datasets as tfds

from tensorflow import keras
from tensorflow.python.client import device_lib
import time

# Uncomment this to observe the device used to 
# run tensorflow operations
#tf.debugging.set_log_device_placement(True)
''' 
Description:
Runs three different tests to measure performance on both a GPU and CPU if
available. Each test uses tensorflow
alpha 2.0, and trains using the MNIST dataset provided/bundled by tensorflow.
Each test runs for 1 epoch comprised of 1000 mini-batches. A mini-batch contains
32 samples. All tests use Adam optimizer, and sparse categorical loss.

Test descriptions:
- Test 1: Uses the Keras 'compile' and 'fit' function
- Test 2: Uses tf.GradientTape and does not use the @tf.function decorator
- Test 3: Uses tf.GradientTape and the @tf.function decorator. 
    The @tf.function decorator is applied to the function training 
    on MNIST mini-batches

Issue Observed:
(example below for GPU for example)
Test 1 provides a benchmark accuracy of ~70% (6.4 sec runtime) on the training data after 1000 
steps. Test 3 achieves roughly the same accuracy in a similar time (even 
a little better ~80% with 3.75 sec runtime). Test 2 achieves ~20-40% accuracy (14-16 sec runtime) 
after training for number of batches. The only difference
between Test 2 and Test 3 is no utilization of the tf.function decorator in Test 2. 

The slow down in Test 2 is expected when not using the tf.function decorator.
However, I would expect roughly the same training accuracy after 1000 steps for each 
test.
'''

# ------------------- Create Several Helper Functions and variables 
# ------------------- used for training
def print_info():
    print(tf.__version__)
    print(tf.executing_eagerly())
    print(device_lib.list_local_devices())
    print()

def get_available_device_names():
    local_devices = device_lib.list_local_devices()
    names = []
    for device in local_devices:
        names.append(device.name)
    return names

def get_and_prepare_data():
    data, info = tfds.load(
        'mnist',with_info=True, as_supervised=True)

    train_data, test_data = data['train'], data['test']

    batch_size = 32
    prep_train_data = train_data.batch(batch_size).prefetch(1).repeat()
    return prep_train_data, info

def create_model():
    img_shape = info.features['image'].shape
    model = keras.Sequential([
        keras.layers.Flatten(input_shape=img_shape),
        keras.layers.Dense(128, activation='relu'),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(10, activation='softmax')
    ])
    return model

def train_batch(model, images, label, loss_fn, optimizer, train_loss, train_accuracy):
    with tf.GradientTape() as tape:
        pred = model(images)
        loss = loss_fn(label, pred)
    gradients = tape.gradient(loss, model.trainable_variables)
    grads_and_vars = zip(gradients, model.trainable_variables)
    optimizer.apply_gradients(grads_and_vars)

    train_loss(loss)
    train_accuracy(label, pred)
    
    return loss, pred

def run_batch(batch_train_func, steps_per_epoch=1000, epochs=1):
    train_loss = keras.metrics.Mean()
    train_accuracy = keras.metrics.SparseCategoricalAccuracy()
    for e in range(epochs):
        batch = 0
        for (data, label) in prep_train_data:
            loss, pred = batch_train_func(data, label, train_loss, train_accuracy)
            
            if batch % 500 == 0:
                print(""Batch {} accuracy {} loss {}\n"".format(
                    batch, train_accuracy.result(), train_loss.result()))
            if batch >= steps_per_epoch:
                break
            batch = batch + 1

# Basic info
print_info()
avail_device_names = get_available_device_names()
print(avail_device_names)

steps_per_epoch = 1000
epochs = 1
devices = ['/device:CPU:0', '/device:GPU:0']

for device in devices:
    if device not in avail_device_names:
        print(""Device {} not available"".format(device))
        continue # Device not available

    print(""\n-------------------------------------------"")
    print(""-------------------------------------------"")
    print(""Starting test for device {}"".format(device))
    print(""-------------------------------------------"")

    # Tests record accuracy, loss, batch number and test type
    # ----------------------------- TEST 1 --------------------------- #
    # ------------ Test Using Keras compile and fit ------------------ #

    print(""Begin Benchmarking Test 1"")
    print(""Test uses keras functions compile and fit"")

    # Data prep
    prep_train_data, info = get_and_prepare_data()

    t1_start = time.time()

    with tf.device(device):
        keras_fit_model = create_model()

        keras_fit_model.compile(optimizer='adam', 
                        loss='sparse_categorical_crossentropy', metrics=['accuracy'])

        keras_fit_model.fit(prep_train_data, epochs=epochs, steps_per_epoch=steps_per_epoch,verbose=2)

    t1_end = time.time()
    print(""Test 1 Time Elapsed {}\n"".format(t1_end-t1_start))

    # ----------------------------- TEST 2 ----------------------------- #
    # --------- Test Using Gradient Tape without tf.function ----------- #
    print(""Begin Benchmarking Test 2"")
    print(""Test uses tf.GradientTape() (does not use tf.function decorator)"")

    # Data prep
    prep_train_data, info = get_and_prepare_data()

    t2_start = time.time()

    with tf.device(device):
        eager_model = create_model()
        eager_optimizer = tf.keras.optimizers.Adam()
        eager_loss_func = keras.losses.SparseCategoricalCrossentropy()

        def eager_train_batch(data, label, train_loss, train_accuracy):
            return train_batch(eager_model, data, label, eager_loss_func, eager_optimizer, train_loss, train_accuracy)

        run_batch(eager_train_batch, steps_per_epoch, epochs)

    t2_end = time.time()
    print(""Test 2 Time Elapsed {}\n"".format(t2_end-t2_start))


    # ----------------------------- TEST 3 ----------------------------------- #
    # --------- Test Using Gradient Tape with tf.function decorator----------- #
    print(""Begin Benchmarking Test 3"")
    print(""Test uses tf.GradientTape() (uses tf.function decorator)"")

    # Data prep
    prep_train_data, info = get_and_prepare_data()

    t3_start = time.time()

    with tf.device(device):
        graph_model = create_model()
        graph_optimizer = tf.keras.optimizers.Adam()
        graph_loss_func = keras.losses.SparseCategoricalCrossentropy()

        @tf.function
        def graph_train_batch(data, label, train_loss, train_accuracy):
            return train_batch(graph_model, data, label, graph_loss_func, graph_optimizer, train_loss, train_accuracy)

        run_batch(graph_train_batch, steps_per_epoch, epochs)

    t3_end = time.time()
    print(""Test 3 Time Elapsed {}\n"".format(t3_end-t3_start))
```

**Other info / logs**
[perf_test_tf_2_0.log](https://github.com/tensorflow/tensorflow/files/3287965/perf_test_tf_2_0.log)

"
29761,tf.train.Saver() problem when running session: Cannot assign a device for operation save/SaveV2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available. Registered kernels,"Having an issue when specificying graph/device placement and saving the model.

graph_model = tf.Graph()
 with graph_model.device(self.device):
        with graph_model.as_default():
         ...
         ...
         saver = tf.train.Saver()
 config = tf.ConfigProto()
 config.gpu_options.allow_growth = True
 with tf.Session(graph=graph_model,config=config) as sess:
       sess.run(tf.global_variables_initializer())


and i get this error..

Caused by op 'save/SaveV2', defined at:
  File ""/usr/local/pycharm-2019.1.1/helpers/pydev/pydevd.py"", line 1758, in <module>
    main()
  File ""/usr/local/pycharm-2019.1.1/helpers/pydev/pydevd.py"", line 1752, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""/usr/local/pycharm-2019.1.1/helpers/pydev/pydevd.py"", line 1147, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""/usr/local/pycharm-2019.1.1/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/home/jsidhom1/DeepTCR/ancillary_analysis/supervised/Supervised_Repertoire_Human.py"", line 119, in <module>
    gcn=True,batch_size=10)
  File ""/home/jsidhom1/DeepTCR/DeepTCR/DeepTCR.py"", line 3643, in Monte_Carlo_CrossVal
    embedding_dim_genes=embedding_dim_genes,embedding_dim_hla=embedding_dim_hla)
  File ""/home/jsidhom1/DeepTCR/DeepTCR/DeepTCR.py"", line 3400, in Train
    GO.saver = tf.train.Saver()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py"", line 832, in __init__
    self.build()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py"", line 844, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py"", line 881, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py"", line 510, in _build_internal
    save_tensor = self._AddSaveOps(filename_tensor, saveables)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py"", line 210, in _AddSaveOps
    save = self.save_op(filename_tensor, saveables)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py"", line 124, in save_op
    tensors)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1807, in save_v2
    name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()
InvalidArgumentError (see above for traceback): Cannot assign a device for operation save/SaveV2: Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.
Registered kernels:
  device='CPU'
	 [[node save/SaveV2 (defined at /home/jsidhom1/DeepTCR/DeepTCR/DeepTCR.py:3400) ]]
"
29758,TFlite object detection example contains unimplemented TFlite op,"**System information**
- OS Platform and Distribution Linux ubuntu : Ubuntu 16.04.4 LTS
- TensorFlow installed from pip:
- TensorFlow version 1.13.1:
- TensorFlow repo commit version: 2b4245af999d33a7bdf31cf8b6de2db9c1d0afe5

I followed the directions here, with the change that I did not quanitze (I hope this is not the problem)

https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193 


The command I ran
```
bazel run -c opt tensorflow/lite/toco:toco -- --input_file=$OUTPUT_DIR/tflite_graph.pb --output_file=$OUTPUT_DIR/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --mean_values=128 --std_values=128 --change_concat_input_ranges=false0
```

produced the following error and a zero byte file
```-rw-rw-r--   1 ubuntu ubuntu        0 Jun 13 18:30 detect.tflite```

**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.
```

**Any other info / logs**

```bazel run -c opt tensorflow/lite/toco:toco -- --input_file=$OUTPUT_DIR/tflite_graph.pb --output_file=$OUTPUT_DIR/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --mean_values=128 --std_values=128 --change_concat_input_ranges=false
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=104
INFO: Reading rc options for 'run' from /home/ubuntu/tensorflow/.bazelrc:
  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
INFO: Analyzed target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
Target //tensorflow/lite/toco:toco up-to-date:
  bazel-bin/tensorflow/lite/toco/toco
INFO: Elapsed time: 0.390s, Critical Path: 0.00s
INFO: 0 processes.
INFO: Build completed successfully, 1 total action
INFO: Running command line: bazel-bin/tensorflow/lite/toco/toco '--input_file=/tmp/detection_export_tflite_62750_eMdgL5/tflite_graph.pb' '--output_file=/tmp/detection_export_tflite_62750_eMdgL5/detect.tflite' '--input_shapes=1,300,300,3' '--input_arrays=normalized_input_image_tensor' '--output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostPrINFO: Build completed successfully, 1 total action
2019-06-13 18:30:23.047578: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TFLite_Detection_PostProcess
2019-06-13 18:30:23.070489: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 500 operators, 754 arrays (0 quantized)
2019-06-13 18:30:23.090507: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 500 operators, 754 arrays (0 quantized)
2019-06-13 18:30:23.120462: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 64 operators, 176 arrays (0 quantized)
2019-06-13 18:30:23.122651: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 64 operators, 176 arrays (0 quantized)
2019-06-13 18:30:23.123979: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 64 operators, 176 arrays (0 quantized)
2019-06-13 18:30:23.126908: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 8640000 bytes, theoretical optimal value: 6480000 bytes.
2019-06-13 18:30:23.127414: I tensorflow/lite/toco/toco_tooling.cc:434] Estimated count of arithmetic ops: 1.31037 billion (note that a multiply-add is counted as 2 ops).
2019-06-13 18:30:23.128028: E tensorflow/lite/toco/toco_tooling.cc:462] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.
We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.
```
"
29755,tf.Print was not rendered correctly in the website,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/Print

## Description of issue (what needs changing):

[tf.Print](https://www.tensorflow.org/api_docs/python/tf/Print) was not rendered correctly in the website. I understand that it was deprecated in TF2.0, but it should be rendered correctly in the TF website.

### Correct links

https://www.tensorflow.org/api_docs/python/tf/Print



### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
29753,Dataset Optimization does not complete with a large number of Datasets,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.7
- CUDA/cuDNN version: 10.1
- GPU model and memory: Geforce RTX 2080 ti

**Describe the current behavior**
I am trying to use tf.data.experimental.choose_from_datasets the create specifically constructed batches from a large number of datasets, ~7300. Each of the datasets I want to sample from is a TFRecord Dataset. It fails with a DeadlineExceededError (stack trace below).

The model is implemented as an estimator. I attempted to adjust the operation timeout but that does not seem to have any effect.

A few observations:

1. I know I may have pushed this a bit far. If I should actually build either a completely custom dataset or a custom operator that could take a stream of examples and build the batches with some sort of internal buffer let me know.
1. It is much slower (~5x) to create the datasets in Graph Mode as opposed to eager mode.
1. Eager mode has no problem yielding examples if I just loop over dataset and print them out.
1. The graph that is created by the estimator is extremely large (graph.pbtxt of 2.5GB)


**Describe the expected behavior**
It would be nice if this dataset could execute in graph mode.

**Code to reproduce the issue**
```python
def build_triplet_dataset(root, num_classes, classes_per_batch, num_examples, num_frames, repeat=None, num_gpus=1) -> tf.data.Dataset:
    cores = multiprocessing.cpu_count()

    def _generator():
        while True:
            result = []
            for _ in range(classes_per_batch):
                x = random.randint(0, num_classes)
                result.append([x] * num_examples)
            yield list(itertools.chain(*result))

    def _per_class_dataset(path) -> tf.data.Dataset:
        dataset = tf.data.TFRecordDataset(path, compression_type='GZIP')
        dataset = dataset.apply(tf.data.experimental.shuffle_and_repeat(num_gpus * num_examples, repeat))
        dataset = dataset.map(lambda x: _parse_example(x, num_frames), num_parallel_calls=cores)
        dataset = dataset.apply(tf.data.experimental.unbatch())
        dataset = dataset.shuffle(num_gpus*num_examples)
        return dataset

    files = glob.glob(os.path.join(root, ""*.tfrecord.gz""))
    print('Loading Datasets')
    datasets = list(tqdm(map(lambda x: _per_class_dataset(x), files)))

    choice_dataset = tf.data.Dataset.from_generator(lambda: _generator(), (tf.int64),
                                                    output_shapes=(tf.TensorShape([num_examples * classes_per_batch])))
    choice_dataset = choice_dataset.apply(tf.data.experimental.unbatch())

    dataset = tf.data.experimental.choose_from_datasets(datasets, choice_dataset)
    dataset = dataset.batch(classes_per_batch * num_examples)
    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)
    return dataset
```

**Other info / logs**
Caused by op 'OptimizeDataset', defined at:
  File ""sonia/models/my_model/train.py"", line 14, in <module>
    ds.train_and_evaluate(model_params, hyperparameters, [], [])
  File ""/home/steve/source/core/python/sonia/models/deep_speaker/model2.py"", line 453, in train_and_evaluate
    steps=None))
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py"", line 471, in train_and_evaluate
    return executor.run()
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py"", line 611, in run
    return self.run_local()
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py"", line 712, in run_local
    saving_listeners=saving_listeners)
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 358, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1122, in _train_model
    return self._train_model_distributed(input_fn, hooks, saving_listeners)
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1185, in _train_model_distributed
    self._config._train_distribute, input_fn, hooks, saving_listeners)
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1206, in _actual_train_model_distributed
    input_fn, model_fn_lib.ModeKeys.TRAIN, strategy)
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 985, in _get_iterator_from_input_fn
    iterator = result.make_initializable_iterator()
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow/python/distribute/values.py"", line 1193, in make_initializable_iterator
    self._dataset, self._devices)
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py"", line 180, in __init__
    self._dataset._as_variant_tensor(),  # pylint: disable=protected-access
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 2993, in _as_variant_tensor
    self._input_dataset._as_variant_tensor(),  # pylint: disable=protected-access
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3013, in _as_variant_tensor
    **flat_structure(self))
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 3036, in optimize_dataset
    output_shapes=output_shapes, name=name)
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

DeadlineExceededError (see above for traceback): meta_optimizer exceeded deadline.
         [[node OptimizeDataset (defined at /home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py:985) ]]
         [[node MultiDeviceIteratorInit (defined at /home/steve/venv/sonia/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py:985) ]]
"
29751,KeyError: 'ParallelInterleaveDataset' in Tf >= 1.13 (mkl/gpu),"OS Platform and Distribution - Linux Ubuntu 16.04)
TensorFlow installed from Anaconda dist 3.6.
TensorFlow version 1.13-mkl / 1.13-gpu
Python version: Python 3.6.6 :: Anaconda, Inc.

*Describe the current behavior**
There is an import error on `tf.train.import_meta_graph()` while importing one of the models from the model zoo / coral_ready model. The import works fine on 1.12 but not >= 1.13 ver
**Describe the expected behavior**
The model should be otherwise loaded with the placeholder and graph
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
The model was taken from here - [Model Link] (http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz)
[Model Website](https://coral.withgoogle.com/models/)

**Other info / logs**
```
Traceback (most recent call last):
  File ""ssd_test.py"", line 6, in <module>
    model = Importers.ImportMeta(dir_path=model_dir, quantizer='LINEAR')
  File ""/home/local/SRI/e32640/Documents/aiquantizer/Importers.py"", line 89, in __init__
    self.import_graph()
  File ""/home/local/SRI/e32640/Documents/aiquantizer/Importers.py"", line 118, in import_graph
    clear_devices=True)
  File ""/home/local/SRI/e32640/anaconda3/envs/tf13-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1435, in import_meta_graph
    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]
  File ""/home/local/SRI/e32640/anaconda3/envs/tf13-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1457, in _import_meta_graph_with_return_elements
    **kwargs))
  File ""/home/local/SRI/e32640/anaconda3/envs/tf13-gpu/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py"", line 806, in import_scoped_meta_graph_with_return_elements
    return_elements=return_elements)
  File ""/home/local/SRI/e32640/anaconda3/envs/tf13-gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/local/SRI/e32640/anaconda3/envs/tf13-gpu/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 399, in import_graph_def
    _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)
  File ""/home/local/SRI/e32640/anaconda3/envs/tf13-gpu/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 159, in _RemoveDefaultAttrs
    op_def = op_dict[node.op]
KeyError: 'ParallelInterleaveDataset'

```

UPDATE [1]:
The following code snippet is used for importing the model downloaded from the model zoo

```
model_dir = 'ssd_mobilenet_v2/'
meta = glob.glob(model_dir + ""*.meta"")[0]
ckpt = meta.replace('.meta', '').strip()

graph = tf.Graph()
with graph.as_default():
    with tf.Session() as sess:
        reader = tf.train.import_meta_graph(meta, clear_devices=True)
        reader.restore(sess, ckpt)
        writer = tf.summary.FileWriter(logdir=model_dir, graph=tf.get_default_graph())  # write to event
        writer.flush()
        vari = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
        for var in vari:
            print(var.name, ""\n"")
```"
29750,No module named 'tensorflow._api',"**System information**
- Microsoft Windows 10 Home
- Version 10.0.17.134 Build 17134
- TensorFlow installed from: Not sure, installed using python environments within visual studio
- TensorFlow version: 1.13.1
- Python version: 3.7 (64-bit)
- Installed using pip
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: Asus - GeForce GTX 1060 6GB Dual Video Card



New user to python and this website. So please bear with me and I'll do my best. 

I am attempting to run a simple code here: https://www.tensorflow.org/tutorials/load_data/images
in order to eventually upload my own set of images for a neural net to process. 

I'm using visual studio as well, and know little about how that could affect things. 

Here is my exact code: 

```
from __future__ import absolute_import, division, print_function

import tensorflow as tf
tf.enable_eager_execution()
tf.VERSION

AUTOTUNE = tf.data.experimental.AUTOTUNE
```
And here is the full error provided:

```
Traceback (most recent call last):
  File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\ptvsd_launcher.py"", line 119, in <module>
    vspd.debug(filename, port_num, debug_id, debug_options, run_as)
  File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\Packages\ptvsd\debugger.py"", line 41, in debug
    run(address, filename, *args, **kwargs)
  File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\Packages\ptvsd\_local.py"", line 80, in run_file
    run(argv, addr, **kwargs)
  File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\Packages\ptvsd\_local.py"", line 140, in _run
    _pydevd.main()
  File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\Packages\ptvsd\_vendored\pydevd\pydevd.py"", line 2329, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\Packages\ptvsd\_vendored\pydevd\pydevd.py"", line 1664, in run
    return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)
  File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\Packages\ptvsd\_vendored\pydevd\pydevd.py"", line 1671, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\Packages\ptvsd\_vendored\pydevd\_pydev_imps\_pydev_execfile.py"", line 25, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:\Users\Andrew\Desktop\Visual Studio\Python\Scoliosis NN Thesis\ScNN_v1.1.py"", line 3, in <module>
    import tensorflow as tf
  File ""D:\Apps\Python\lib\site-packages\tensorflow\__init__.py"", line 26, in <module>
    from tensorflow._api.v1 import app
**ModuleNotFoundError: No module named 'tensorflow._api'**
Press any key to continue . . .
```
If there is any other information I can provide, please let me know. 




"
29748,Improve interface for warmstarting non-TRAINABLE variables in warm_starting_util,"**System information**
- TensorFlow version (you are using): 1.13.1
- Are you willing to contribute it (Yes/No): Yes (if need be)

**Describe the feature and the current behavior/state.**
When warmstarting a pre-trained estimator, a common workflow is to warmstart a small number of non-TRAINABLE variables in addition to the TRAINABLE_VARIABLES. In particular, when warmstarting a Keras estimator with BatchNorm layers, it's necessary to manually warmstart the moving_mean and moving_variance variables, since these are non-trainable (see https://github.com/tensorflow/tensorflow/issues/19903, https://github.com/tensorflow/tensorflow/issues/17950, https://github.com/keras-team/keras/pull/9965). Failure to properly restore these variables can break warmstarting for pre-trained Keras models like InceptionV3 (see https://github.com/keras-team/keras/issues/9214).

The current solution is to create `tf.estimator.WarmStartSettings()` object with `vars_to_warm_start=['.*']`. As per the [TF WarmStartSettings docs ](https://www.tensorflow.org/api_docs/python/tf/estimator/WarmStartSettings), passing in a list will warmstart all variables (including non-TRAINABLE), which allows users to warmstart vars from GLOBAL_VARIABLES. However, as [noted](https://github.com/tensorflow/tensorflow/issues/19903#issuecomment-470009739) by some users, this solution is undesirable because it will warmstart all GLOBAL_VARIABLES (including global_step, accumulators, and other state that we generally don't want to restore). 

Ideally, the warmstart API should allow users to cherry-pick additional non-TRAINABLE variables to warmstart alongside TRAINABLE variables. Unfortunately, it's generally not possible to use the regex mechanism in `vars_to_warm_start` for this purpose, since there's no distinction between trainable and non-trainable variables in the default TF variable naming scheme. Furthermore, in most cases, the `WarmStartSettings` object is defined before graph creation, so it's not possible for the user to access `TRAINABLE_VARIABLES` or `GLOBAL_VARIABLES` at Estimator creation time. 

**Proposed solution**
Extend the `tf.train.warm_start()` / `tf.estimator.WarmStartSettings()` API to allow the user to separately define TRAINABLE and non-TRAINABLE variables to warmstart. I can see a couple ways to accomplish this:

1. Create separate arguments `trainable_vars_to_warmstart` and `nontrainable_vars_to_warmstart`, where non-TRAINABLE variables are defined as `set(GLOBAL_VARIABLES) - set(TRAINABLE_VARIABLES)`.
2. Extend the `vars_to_warmstart` arg to accept a dict of `{""trainable"": "".*"", ""nontrainable"": ""\moving_\""}`, which in this case would warmstart all TRAINABLE_VARIABLES plus the BatchNorm moving mean and variance.

**Will this change the current api? How?**
Depending on the solution, the args for `tf.train.warm_start()` / `tf.estimator.WarmStartSettings()` may change. Something like Option 2 above would probably be able to preserve backwards compatibility reasonably well.

**Who will benefit with this feature?**
Users who want to warmstart a pre-trained Keras model that contains BatchNormalization layers or other stateful model components not found in TRAINABLE_VARIABLES.

**Any Other info.**
This [blog post](http://blog.datumbox.com/the-batch-normalization-layer-of-keras-is-broken/) gives useful background on partially-overlapping issues related to BatchNorm in Keras."
29747," 'TensorSliceDataset' object has no attribute {'make_initializable_iterator', 'output_shapes', 'make initializable_iterator'...}","Short description
TensorSliceDataset is lacking a lot of attributes to make is usable ('make_initializable_iterator', 'output_shapes', 'make initializable_iterator'...).

Environment information

Operating System: 18.04
Python version: 3.6
tensorflow-datasets/tfds-nightly version: tfds-nightly
tensorflow/tensorflow-gpu/tf-nightly/tf-nightly-gpu version: tf-nightly-2.0-preview
Reproduction instructions

randt = tf.random.uniform([2000, 80, 5])
dataset = tf.data.Dataset.from_tensor_slices(randt)
dataset.batch(20)
iter = dataset.make_one_shot_iterator()

Link to logs
AttributeError: 'TensorSliceDataset' object has no attribute 'make_one_shot_iterator'"
29746,Inference Time TensorFlow C++ API vs Python API,"Hi,
In the inference mode, Is C++ API faster than Python API? In the some issues, I see the C++ slower than python, why? Is this right?
[Issue 1](https://github.com/tensorflow/tensorflow/issues/22852 )
[Issue 2](https://github.com/tensorflow/tensorflow/issues/15552)"
29745,To be deleted,"To be deleted, moved to the right section "
29744,ImportError: cannot import name 'label_map_util' in pycharm,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
29743,TFRecordDataset iterator not usuable in tf.keras .fit function (steps_per_epoch),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): pip3 (binary)
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.7

**Describe the current behavior**
When using tf.Dataset (TFRecordDataset) API with new tf.keras API, I am passing the data iterator made from the dataset, however, before the first epoch finished, I got an `When using data tensors as input to a model, you should specify the `steps_per_epoch` argument.` exception, even though I've set this attribute in the fit method.

```
2019-06-13 14:22:25.393398: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1995445000 Hz
2019-06-13 14:22:25.393681: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2f7d120 executing computations on platform Host. Devices:
2019-06-13 14:22:25.393708: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Epoch 1/2
19/20 [===========================>..] - ETA: 0s - loss: 1.1921e-07 - acc: 1.0000Traceback (most recent call last):
  File ""TestServe.py"", line 62, in <module>
    ts.train()
  File ""TestServe.py"", line 56, in train
    epochs=2, verbose=1, callbacks=callbacks, steps_per_epoch=20) #The steps_per_epoch is typically samples_per_epoch / batch_size
  File ""/home/josef/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 880, in fit
    validation_steps=validation_steps)
  File ""/home/josef/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 364, in model_iteration
    validation_in_fit=True)
  File ""/home/josef/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 202, in model_iteration
    steps_per_epoch)
  File ""/home/josef/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 76, in _get_num_samples_or_steps
    'steps_per_epoch')
  File ""/home/josef/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py"", line 230, in check_num_samples
    if check_steps_argument(ins, steps, steps_name):
  File ""/home/josef/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py"", line 960, in check_steps_argument
    input_type=input_type_str, steps_name=steps_name))
ValueError: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument.
```

**Describe the expected behavior**
I would expect the epochs to to through smoothly, I actually suspect the validation part, because it is failing exactly before it.

**Code to reproduce the issue**
Here is my failing part:
```
import tensorflow as tf
import numpy as np
from typing import Union, List
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras import layers
from tftools import TFTools


class TestServe():
    def __init__(self, tfrecords: Union[List[tf.train.Example], tf.train.Example], batch_size: int = 10, input_shape: tuple = (64, 23)) -> None:
        self.tfrecords = tfrecords
        self.batch_size = batch_size
        self.input_shape = input_shape

    def get_model(self):
        ins = layers.Input(shape=(64, 23))

        l = layers.Reshape((*self.input_shape, 1))(ins)
        l = layers.Conv2D(8, (30, 23), padding='same', activation='relu')(l)
        l = layers.MaxPool2D((4, 5), strides=(4, 5))(l)
        l = layers.Conv2D(16, (3, 3), padding='same', activation='relu')(l)
        l = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(l)
        l = layers.MaxPool2D((2, 2), strides=(2, 2))(l)
        l = layers.Flatten()(l)

        out = layers.Dense(1, activation='softmax')(l)
        return tf.keras.models.Model(ins, out)

    def train(self):

        # Create Dataset
        dataset = TFTools.create_dataset(self.tfrecords)
        dataset = dataset.repeat(6).batch(self.batch_size)

        val_iterator = dataset.take(300).make_one_shot_iterator()
        train_iterator = dataset.skip(300).make_one_shot_iterator()

        model = self.get_model()
        model.summary()
        model.compile(optimizer='rmsprop',
                      loss='binary_crossentropy', metrics=['accuracy'])
        model.fit(train_iterator, validation_data=val_iterator,
                  epochs=10, verbose=1, steps_per_epoch=20)

    def predict(self, X: np.array) -> np.array:
        pass

ts = TestServe(['./ok.tfrecord', './nok.tfrecord'])
ts.train()
```

**Other info / logs**
I have ~ 1500 samples in those two tfrecord files, repeating it 6 times is 9.5k samples, so I dont think my generator ran out of samples.

I've even created [StackOverflow](https://stackoverflow.com/questions/56580538/tf-keras-api-with-tf-dataset-problem-steps-per-epoch-argument-problem) question as I am not entirely sure if this is a bug, but looks like it, since the tf.keras si relatively new, I cannot find much help elsewhere."
29739,Undefined symbol: DeleteGpuDelegate(_TfLiteDelegate*),"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.



I had built tensorflowlite.a for ios follow offcial website, build successful!
but not working for gpu, below is error msg with xcode:

Undefined symbol: DeleteGpuDelegate(_TfLiteDelegate*)
![image](https://user-images.githubusercontent.com/17869361/59423729-4e3b4a80-8e05-11e9-9844-dfa2fe2f785b.png)

Offcial website building instruction do not enable gpu feature, how to do this?

Below is website about how to build tensorflowlite for ios
https://www.tensorflow.org/lite/guide/build_ios 



"
29738,custom op: undefined symbol: _ZN10tensorflow8str_util9LowercaseEN4absl11string_viewE,"
**System information**
tensorflow/tensorflow   latest-py3                     4ddde1227df8       
tensorflow/tensorflow   devel-py3                      b558e7fc2018 

**Describe the current behavior**
compile ops.so under latest-py3 , then using the ops.so with tf c++ api under devel-py3.

the error is below:
```
ops.so: undefined symbol: _ZN10tensorflow8str_util9LowercaseEN4absl11string_viewE
```

**Describe the expected behavior**
I think ops.so will work in both docker image.


**Other info / logs**
refs:
https://github.com/tensorflow/io/issues/161
https://github.com/tensorflow/io/issues/173
"
29737,tacotron pb model conversion to tflite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04
- TensorFlow installed from (source or binary):
Source 1.13.1
- TensorFlow version (or github SHA if from source):
1.13.1

**Provide the text output from tflite_convert**

```
# Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXPAND_DIMS, FILL, FLOOR, FULLY_CONNECTED, GATHER, GREATER_EQUAL, LESS, LOGICAL_AND, LOGICAL_NOT, LOGICAL_OR, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, RANGE, REDUCE_ANY, REDUCE_MAX, RESHAPE, SELECT, SHAPE, SOFTMAX, SPLIT, SQUEEZE, STRIDED_SLICE, SUM, TANH, TILE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: All, BatchMatMul, Enter, Exit, LoopCond, Merge, RandomUniform, ReverseSequence, Round, Switch, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.

```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29736,Object Detection API: Unable to train a quantization aware Faster RCNN + Resnet50 object detector,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian Linux 9 (m26 Deep Learning Image) running on Google Cloud
- TensorFlow installed from (source or binary): binary (using the one provided with the Deep Learning image 'tensorflow_gpu-1.13.1+nv-cp35-cp35m-linux_x86_64.whl')
- TensorFlow version (use command below): 1.13.1
- Python version: 3.5.3
- CUDA/cuDNN version: CUDA 10.0 / cuDNN 7.4.1
- GPU model and memory: NVIDIA Tesla V100

**Describe the current behavior**

When I try to fine tune a Faster RCNN + Resnet50 object detector I get a runtime error.

Stack trace:
`Traceback (most recent call last):
  File ""models/research/object_detection/model_main.py"", line 109, in <module>
    tf.app.run()
  File ""/home/klemen/ml/models/venv/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""models/research/object_detection/model_main.py"", line 105, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/home/klemen/ml/models/venv/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py"", line 471, in train_and_evaluate
    return executor.run()
  File ""/home/klemen/ml/models/venv/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py"", line 611, in run
    return self.run_local()
  File ""/home/klemen/ml/models/venv/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py"", line 712, in run_local
    saving_listeners=saving_listeners)
  File ""/home/klemen/ml/models/venv/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 358, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/klemen/ml/models/venv/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1124, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/klemen/ml/models/venv/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1154, in _train_model_default
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/home/klemen/ml/models/venv/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1112, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/home/klemen/ml/models/research/object_detection/model_lib.py"", line 369, in model_fn
    graph_rewriter_fn()
  File ""/home/klemen/ml//models/research/object_detection/builders/graph_rewriter_builder.py"", line 37, in graph_rewrite_fn
    quant_delay=graph_rewriter_config.quantization.delay
  File ""/home/klemen/ml//models/venv/lib/python3.5/site-packages/tensorflow/contrib/quantize/python/quantize_graph.py"", line 205, in experimental_create_training_graph
    scope=scope)
  File ""/home/klemen/ml/models/venv/lib/python3.5/site-packages/tensorflow/contrib/quantize/python/quantize_graph.py"", line 73, in _create_graph
    is_training=is_training)
  File ""/home/klemen/ml/models/venv/lib/python3.5/site-packages/tensorflow/contrib/quantize/python/fold_batch_norms.py"", line 53, in FoldBatchNorms
    graph, is_training, freeze_batch_norm_delay=freeze_batch_norm_delay)
  File ""/home/klemen/ml/models/venv/lib/python3.5/site-packages/tensorflow/contrib/quantize/python/fold_batch_norms.py"", line 98, in _FoldFusedBatchNorms
    freeze_batch_norm_delay=freeze_batch_norm_delay))
  File ""/home/klemen/ml/models/venv/lib/python3.5/site-packages/tensorflow/contrib/quantize/python/fold_batch_norms.py"", line 384, in _ComputeBatchNormCorrections
    match.moving_variance_tensor + match.batch_epsilon)
TypeError: unsupported operand type(s) for +: 'NoneType' and 'float'`

Config used:
`model {
  faster_rcnn {
    num_classes: 1
    image_resizer {
      fixed_shape_resizer {
        height: 600
        width: 600
      }
    }
    feature_extractor {
      type: ""faster_rcnn_resnet50""
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        height_stride: 16
        width_stride: 16
        scales: 0.25
        scales: 0.5
        scales: 1.0
        scales: 2.0                                                                                                                                                                                                                 
        aspect_ratios: 0.5
        aspect_ratios: 1.0
        aspect_ratios: 2.0
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.00999999977648
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.699999988079                                                                                                                                                                                    
    first_stage_max_proposals: 20
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    second_stage_batch_size: 20
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true                                                                                                                                                                                                          
              mode: FAN_AVG
            }
          }
        }
        use_dropout: false
        dropout_keep_probability: 1.0
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.300000011921
        iou_threshold: 0.600000023842
        max_detections_per_class: 20
        max_total_detections: 20
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }                                                                                                                                                                                                                                 
}
train_config {
  batch_size: 16
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  optimizer {
    momentum_optimizer {
      learning_rate {
        manual_step_learning_rate {
          initial_learning_rate: 0.000300000014249
          schedule {
            step: 0
            learning_rate: 0.000300000014249
          }
          schedule {
            step: 900000
            learning_rate: 2.99999992421e-05
          }                                                                                                                                                                                                                          
          schedule {
            step: 1200000
            learning_rate: 3.00000010611e-06
          }
        }
      }
      momentum_optimizer_value: 0.899999976158
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""/home/klemen/ml/resnet50/model.ckpt""
  fine_tune_checkpoint_type: ""detection""
  num_steps: 200000
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""/home/klemen/ml/widerface-to-tfrecord/output/train.tfrecord-?????-of-00010""
  }                                                                                                                                                                                                                                  
  label_map_path: ""/home/klemen/ml/widerface-to-tfrecord/output/face_label_map.pbtxt""
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  num_examples: 1000
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""/home/klemen/ml/widerface-to-tfrecord/output/val.tfrecord-?????-of-00010""
  }
  label_map_path: ""/home/klemen/ml/widerface-to-tfrecord/output/face_label_map.pbtxt""
  shuffle: false
  num_readers: 1
}

graph_rewriter {
  quantization {
    delay: 100
    activation_bits: 8
    weight_bits: 8
  }
}
`

**Describe the expected behavior**
It's supposed to train the model and not throw the error.

**Code to reproduce the issue**
Get the Faster RCNN + ResNet50 pretrained model from `http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_lowproposals_coco_2018_01_28.tar.gz` and run `models/research/object_detection/model_main.py` with the above config.
"
29735, Cannot copy between a TensorFlowLite tensor with shape,"In Android , the sample as it is ,working fine.
But with my model which is having only 2 labels getting crashed.
Below is my crash description.

org.tensorflow.lite.examples.classification E/AndroidRuntime: FATAL EXCEPTION: inference
    Process: org.tensorflow.lite.examples.classification, PID: 31666
    java.lang.IllegalArgumentException: Cannot copy between a TensorFlowLite tensor with shape [1, 1001] and a Java object with shape [1, 2].
        at org.tensorflow.lite.Tensor.throwIfShapeIsIncompatible(Tensor.java:282)
        at org.tensorflow.lite.Tensor.throwIfDataIsIncompatible(Tensor.java:249)
        at org.tensorflow.lite.Tensor.copyTo(Tensor.java:141)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:161)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:275)
        at org.tensorflow.lite.Interpreter.run(Interpreter.java:249)
        at org.tensorflow.lite.examples.classification.tflite.ClassifierQuantizedMobileNet.runInference(ClassifierQuantizedMobileNet.java:94)
        at org.tensorflow.lite.examples.classification.tflite.Classifier.recognizeImage(Classifier.java:257)
        at org.tensorflow.lite.examples.classification.ClassifierActivity$1.run(ClassifierActivity.java:114)
        at android.os.Handler.handleCallback(Handler.java:751)
        at android.os.Handler.dispatchMessage(Handler.java:95)
        at android.os.Looper.loop(Looper.java:154)
        at android.os.HandlerThread.run(HandlerThread.java:61)


"
29734,Autograph failed for function contains Non-ASCII character comment in TF 2.0.0-beta0,"**System information**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-beta0
- Python version: 3.6.8
- CUDA/cuDNN version: 10.0
- GPU model and memory: GeForce GTX 1080 8GB

**Describe the current behavior**

When using non-ASCII character in the function with @tf.function, autograph failed.

> W0613 17:25:35.704982  5776 ag_logging.py:145] Entity <function train at 0x0000000003C96F28> could not be transformed and will be executed as-is. Please report 
this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: (unicode
 error) 'utf-8' codec can't decode byte 0x93 in position 1: invalid start byte (tmp9j9bce4r.py, line 6)

Temporary file is created by Shift JIS (Japanese Windows default) character code.

**Describe the expected behavior**

No warning and building a graph successfully.

**Code to reproduce the issue**

```
import tensorflow as tf
@tf.function
def train():
    ''' Japanese character æ—¥æœ¬èªž '''
    pass
train()
```
"
29733,Does TF_SessionRun have a memory leak?,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, it is a C++ project using the C API
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): C API (no installation necessary, only linked)
- TensorFlow version (use command below): 1.13
- Python version: 3.6
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: - (CPU only)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I have written a code performing inference on frozen graphs. Due to certain circumstances I must use the C API. The code does exactly what I expect. However as I must do the inference thousands of times during a simulation, at some point the simulation crashes as I run out of memory. So I started to uncomment my code and rejoin one part after the other. I found out that the memory leak only occurs if I uncomment TF_SessionRun. I was unable to figure out what it does to increase the required memory. Maybe it is also my fault but I do not see an error in memory management. Another remarkable thing is that before the inference I get the following warning 5 times:

`W tensorflow/core/framework/allocator.cc:124] Allocation of 7420800000 exceeds 10% of system memory.`

**Describe the expected behavior**

Basically just as it is now, without increasing used memory every single time I do the inference.

**Code to reproduce the issue**
I will come up later with the code.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29732,saved_model_cli can't convert a severable model for Tensorflow:serving,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux RHEL 7.6
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):1.13.1
- Python version: Python 2.7.16 :: Anaconda, Inc.
- CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6
- GPU model and memory: Tesla K80, 12G

**Describe the current behavior**

Use the tool saved_model_cli to covert a severable model with TF-TRT:
~~~
saved_model_cli convert \
--dir ""/path/to/mask_rcnn/saved_model"" \
--output_dir ""/path/to/trt-mask-rcnn"" \
--tag_set serve \
tensorrt --precision_mode FP32 --max_batch_size 32 --is_dynamic_op True
~~~

## While I got a frozen_graph model and the variables fold is empty, which is not severable!
~~~
variables/
    NULL
saved_model.pb
~~~

**Describe the expected behavior**

The following structure is expected. https://www.tensorflow.org/guide/saved_model#structure_of_a_savedmodel_directory

~~~
assets/
assets.extra/
variables/
    variables.data-?????-of-?????
    variables.index
saved_model.pb|saved_model.pbtxt
~~~

My final target is to [Optimizing TensorFlow Serving performance with NVIDIA TensorRT](https://medium.com/tensorflow/optimizing-tensorflow-serving-performance-with-nvidia-tensorrt-6d8a2347869a), and the model that I want to launch is a pre-trained mask-rcnn downloaded from [tensorflow_model_zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)


Any help would be grateful!"
29731,Error while building Android AAR target with select TensorFlow ops,"**System information**
- OS Platform and Distribution: macos 10.14.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary):binary
- TensorFlow version: 1.13.1
- Python version: 3.5.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 0.25.2


**Describe the problem**
Encountered an error when building AAR with select TensorFlow ops:
`bazel build --cxxopt='--std=c++11' -c opt             \
  --config=android_arm --config=monolithic          \
  //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops`

Error shows: 
```
ERROR: /Users/darrenzhao/Documents/Git_repository/tensorflow/tensorflow/lite/java/BUILD:33:1: Executing genrule //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops_binary_manifest_generator failed (Exit 127)
: command not found
Target //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2702.849s, Critical Path: 661.01s
INFO: 1941 processes: 1941 local.
FAILED: Build did NOT complete successfully
```
Besides, as new to TensorFlow Lite, I have trouble understanding what is 'TensorFlow Lite build environment' mentioned in the [doc](https://www.tensorflow.org/lite/guide/ops_select#android_aar). To me it means Android studio + bazel + tensorflow, is that correct?


**Any other info / logs**
output of `--verbose_failures` :
```
ERROR: /Users/darrenzhao/Documents/Git_repository/tensorflow/tensorflow/lite/java/BUILD:33:1: Executing genrule //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops_binary_manifest_generator failed (Exit 127): bash failed: error executing command 
  (cd /private/var/tmp/_bazel_darrenzhao/c04f0a0d10b76f360494fa7712b36837/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=28.0.3 \
    ANDROID_NDK_API_LEVEL=18 \
    ANDROID_NDK_HOME=/Users/darrenzhao/library/Android/Sdk/ndk-bundle \
    ANDROID_SDK_API_LEVEL=28 \
    ANDROID_SDK_HOME=/Users/darrenzhao/library/Android/Sdk \
    PATH=/anaconda3/bin:/anaconda3/condabin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/darrenzhao/Library/Android/sdk/tools:/Users/darrenzhao/Library/Android/sdk/platform-tools:/Users/darrenzhao/bin \
    PYTHON_BIN_PATH=/anaconda3/bin/python \
    PYTHON_LIB_PATH=/anaconda3/lib/python3.7/site-packages \
    TF_CONFIGURE_IOS=0 \
    TF_DOWNLOAD_CLANG=0 \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL_SYCL=0 \
    TF_NEED_ROCM=0 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; 
cat > bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/java/tensorflow-lite-with-select-tf-ops_generated_AndroidManifest.xml <<EOF
<manifest
  xmlns:android=""http://schemas.android.com/apk/res/android""
  package=""dummy.package.for.so"">
  <uses-sdk android:minSdkVersion=""999""/>
</manifest>
EOF
')
Execution platform: @bazel_tools//platforms:host_platform
: command not found
Target //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops failed to build
INFO: Elapsed time: 2.356s, Critical Path: 0.70s
INFO: 4 processes: 4 worker.
```

Any help would be appreciated, thanks!"
29730,MirroredStrategy does not work with CudnnLSTM,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.13.1 v1.13.1-2-ga5c387b5ed
- Python version: 3.6.7
- Bazel version (if compiling from source): 0.21.0
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: 10.1
- GPU model and memory: 1080 Ti 11GB

**Describe the current behavior**
Unable to train a model using MirroredStrategy with CudnnLSTM. Fails with the following error:

```
FailedPreconditionError (see above for traceback): Error while reading resource variable cudnn_lstm/opaque_kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/cudnn_lstm/opaque_kernel)
	 [[node Shape_2/Identity_1/ReadVariableOp (defined at /home/sharvil/.virtualenv/tensorflow/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py:1254) ]]
```

**Describe the expected behavior**
Code should run.

**Code to reproduce the issue**
```python
import tensorflow as tf


def gen():
  yield 0


def model_fn(features, labels, mode):
  shape = [1, 100, 10]
  x = tf.random_normal(shape)
  y = tf.zeros(shape)

  cell = tf.contrib.cudnn_rnn.CudnnLSTM(1, shape[-1])
  prediction, _ = cell(x)

  loss = tf.reduce_sum(tf.squared_difference(prediction, y))
  train_op = tf.train.AdamOptimizer().minimize(loss, tf.train.get_or_create_global_step())
  return tf.estimator.EstimatorSpec(mode, prediction, loss, train_op)

config = tf.estimator.RunConfig()
# Training begins successfully with the following line commented out.
config = config.replace(train_distribute=tf.distribute.MirroredStrategy())
estimator = tf.estimator.Estimator(model_fn, '/tmp/tf-bug', config=config)
estimator.train(input_fn=lambda: tf.data.Dataset.from_generator(gen, tf.int32))
```"
29729,tf.keras.Model can't initialize variables given input shape in tf2.0 beta,"When given `input_shape` of the input, the model built on `Sequential` will initialize all the variables at once. 
```python  
model = Sequential()
model.add(layers.Dense(32, input_shape=(500,)))
model.add(layers.Dense(32))
print(len(model.weights)) #output 4
```

--------------------------------------
When given `input_shape` of the input, the model built on `Model` will not initialize all the variables at once and only initializes them after doing some predictions.
I can understand when no `input_shape` is given, the model cannot initialize all the variables, but why it doesn't when given `input_shape`?

```python
class MyModel(tf.keras.Model):
  def __init__(self, state_dim, action_dim):
    super(MyModel, self).__init__()
    self.state_dim = state_dim
    self.action_dim = action_dim

    self.fc1 = tf.keras.layers.Dense(100, input_shape=(2,))
    self.fc2 = tf.keras.layers.Dense(1)

  def call(self, inputs):
    out = self.fc1(inputs)
    out = self.fc2(out)
    return out

Q = MyModel(2, 2)
print(len(Q.weights)) # output 0
states = np.random.random((10, 2))
Q(states)
print(len(Q.weights)) # output 4
```
"
29727,EagerFunc tensor conversion error - dtype mismatch,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.0 / 7.4.2
- GPU model and memory: 1080Ti

**Describe the current behavior**
[GIST Link 1](https://gist.github.com/kami93/27da32514c4c9b085bf4fd20dcf6ef57)
[GIST Link 2](https://gist.github.com/kami93/49355db2491ff7b4a03a22fbfbce09f7)

I am trying to use tfe.pyfunc to combine eager block in the operation graph (See Link 1). There are four input arguments to the eager mode function of dtype tf.float32 and tf.int32. When I try to calculate the gradient of a tensor w.r.t some variables that the calculations involving them are happen in the eager block, the error in the Link 2 is raised (TypeError: Cannot convert provided value to EagerTensor. Provided value: 0.0 Requested dtype: int32).

**Describe the expected behavior**
The gradient is calculated and returned after calling tf.Session.run,

**Code to reproduce the issue**
See Link 1.

**Other info / logs**
See Link 2.
I posted a Pull Request for the fix of this issue. [https://github.com/tensorflow/tensorflow/pull/29728](https://github.com/tensorflow/tensorflow/pull/29728)"
29724,ok,"bazel build --config=opt --config=mkl //tensorflow:libtensorflow_cc.so
successfully!
but, have no absl and eigen3
"
29723,Cannot import tensor_util in TF 1.14.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 1.14.0rc1
- Python version: 3.5
- Bazel version (if compiling from source): 0.25.2
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: 10.1
- GPU model and memory: TITAN V

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Cannot import tensor_util.

```
$ python
Python 3.6.8 (default, Jan 14 2019, 11:02:34) 
[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from tensorflow.python.framework import tensor_util
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: cannot import name 'tensor_util'
```

**Describe the expected behavior**

We can import tensor_util in TF 1.13.

**Code to reproduce the issue**

See above.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29719,TF problem when run with lingvo,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Ubuntu 16.04:
- TensorFlow installed from pip:
- TensorFlow 1.13:
- 3.5:
- conda and pip:
- Bazel 0.26.1:
- 4.8:
- CUDA/cuDNN 10.0/ 7.5:
- RTX 2080 TI:

This may be not the proper area to ask. But I cannot find any other place to ask. I am running lingvo based on tensorflow. I follow their mnist demo and run:

bazel build -c opt //lingvo:trainer

It gives me an error:

Extracting Bazel installation...
Starting local Bazel server and connecting to it...
DEBUG: Rule 'subpar' indicated that a canonical reproducible form can be obtained by modifying arguments commit = ""07ff5feb7c7b113eea593eb6ec50b51099cf0261"", shallow_since = ""1524766240 -0700"" and dropping [""tag""]
INFO: Analyzed target //lingvo:trainer (37 packages loaded, 4470 targets configured).
INFO: Found 1 target...
ERROR: missing input file '@tensorflow_solib//:tensorflow_solib/libtensorflow_framework.so.1'
ERROR: /home/feit/.cache/bazel/_bazel_feit/965fc5b73beb9f5ea41273ac0e3737bf/external/tensorflow_solib/BUILD:2:1: @tensorflow_solib//:framework_lib: missing input file '@tensorflow_solib//:tensorflow_solib/libtensorflow_framework.so.1'
Target //lingvo:trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/feit/.cache/bazel/_bazel_feit/965fc5b73beb9f5ea41273ac0e3737bf/external/tensorflow_solib/BUILD:2:1 1 input file(s) do not exist
INFO: Elapsed time: 9.563s, Critical Path: 0.02s
INFO: 0 processes.
FAILED: Build did NOT complete successfully


What is this about? How can I fix it?"
29718,How to generate graph.pbtxt file from the frozen_graph.pb file?,"Hello,
I am trying to import a custom tensor flow model in opencv using the dnn module. Below is the example command:
cvNet = cv2.dnn.readNetFromTensorflow('frozen_inference_graph.pb','graph.pbtxt')
I have the frozen_inference_graph.pb' file? Please tell me how can I generate the 'graph.pbtxt' file?

Below is the complete code:
#!/usr/bin/env python
import cv2

# Load a model imported from Tensorflowload using OpenCV dnn module
cvNet = cv2.dnn.readNetFromTensorflow('frozen_inference_graph.pb','graph.pbtxt')

# Input image
img = cv2.imread(""image1.jpg"")
rows = img.shape[0]
cols = img.shape[1]

# Use the given image as input, which needs to be blob(s).
cvNet.setInput(cv2.dnn.blobFromImage(img, size=(300, 300), swapRB=True, crop=False))

# Runs a forward pass to compute the net output
cvOut = cvNet.forward()

# Loop on the outputs
for detection in cvOut[0,0,:,:]:
    score = float(detection[2])
    if score > 0.3:
        left = detection[3] * cols
        top = detection[4] * rows
        right = detection[5] * cols
        bottom = detection[6] * rows
        cv2.rectangle(img, (int(left), int(top)), (int(right), int(bottom)), (23, 230, 210), thickness=2)

cv2.imshow('img', img)
#save the image
cv2.imwrite( ""processedImg4.jpg"", img );
cv2.waitKey()
cv2.destroyAllWindows()"
29715,Session crashed when I use TFLiteConverter with tf.lite.OpsSet.TFLITE_BUILTINS_INT8 option.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes. 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colaboratory (Ubuntu 18.04.2 LTS)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): pre-installed
- TensorFlow version (use command below): 2.0.0-beta0
- Python version: Python 3.6.7
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source) NA:
- CUDA/cuDNN version: CUDA v10.0.130, cuDNN 7.6.0 
- GPU model and memory: K80

**Describe the current behavior**
I tried to build fully quantized AutoEncoder model using TF2.0 beta and keras on [Colaboratory](https://colab.research.google.com/gist/ohtaman/09c66e27f240d151f6f17ac4a9f62e54/-post-training-integer-quantization-error.ipynb)
But when I run TFLiteConverter.convert method, the Jupyter kernel crashes and the session is restarted.

**Describe the expected behavior**

Finish conversion without any errors.

**Code to reproduce the issue**

Please check [Colaboratory](https://colab.research.google.com/gist/ohtaman/09c66e27f240d151f6f17ac4a9f62e54/-post-training-integer-quantization-error.ipynb)

**Other info / logs**

```
Jun 13, 2019, 6:47:41 AM | WARNING | WARNING:root:kernel dd551b22-18b1-4c36-917e-0dc4b698c41e restarted
-- | -- | --
Jun 13, 2019, 6:47:41 AM | INFO | KernelRestarter: restarting kernel (1/5), keep random ports
Jun 13, 2019, 6:47:38 AM | WARNING | what(): _Map_base::at
Jun 13, 2019, 6:47:38 AM | WARNING | terminate called after throwing an instance of 'std::out_of_range'
Jun 13, 2019, 6:47:38 AM | WARNING | INFO: Initialized TensorFlow Lite runtime.
```"
29714,Polynomial Decay Document Page question,"
## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/train/polynomial_decay

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/train/polynomial_decay
## Description of issue (what needs changing):
A clarification of the example and why it actually works.

### Clear description
In the example mentioned, if the global step is 0, it is unclear how the learning rate will actually change.

The formula can be rewritten as follows:

d = (l - e) * (1 - g/s)^p + e

In the example, g = 0, which means the formula becomes (l - e) * 1 + e = l - e + e = l

So, I'm very unsure of why/how the learning rate in this example is actually going to decrease.

"
29713,Can't import tensorflow,"

**System information**
- OS Platform and Distribution (Windows 7):
- TensorFlow installed from (source or binary):
- TensorFlow version: 1.13.1
- Python version: 3.6
- Installed using virtualenv? installed using pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 9.0
- GPU model and memory: Geforce GTX 550 Ti 2811mb



**Hello everyone. I just started to learn machine learning with python, and when I try to import tensorflow, I keep getting the same error:**

Python 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)] on win32
runfile('D:/Users/Lucas/PycharmProjects/TensorENV/test.py', wdir='D:/Users/Lucas/PycharmProjects/TensorENV')
Traceback (most recent call last):
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Program Files\JetBrains\PyCharm Community Edition 2019.1.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed with error code -1073741795
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""<input>"", line 1, in <module>
  File ""D:\Program Files\JetBrains\PyCharm Community Edition 2019.1.3\helpers\pydev\_pydev_bundle\pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""D:\Program Files\JetBrains\PyCharm Community Edition 2019.1.3\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""D:/Users/Lucas/PycharmProjects/TensorENV/test.py"", line 1, in <module>
    import tensorflow
  File ""D:\Program Files\JetBrains\PyCharm Community Edition 2019.1.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""D:\Program Files\JetBrains\PyCharm Community Edition 2019.1.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""D:\Program Files\JetBrains\PyCharm Community Edition 2019.1.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Program Files\JetBrains\PyCharm Community Edition 2019.1.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""D:\Users\Lucas\Anaconda3\envs\tensor\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed with error code -1073741795
Failed to load the native TensorFlow runtime.


"
29709,Export FeatureColumn and subclasses,"**System information**

- TensorFlow version (you are using): 2.0.0b0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

TensorFlow should export the `FeatureColumn` class and all classes that are subclasses of it. Currently, only the functions used to construct objects of these types, such as `numeric_column`, are exported.

**Will this change the current api? How?**

Yes, it will change the current api by extending it.

**Who will benefit with this feature?**

- Developers who want to extend the provided `FeatureColumn` functionality, such as by subclassing `FeatureColumn` or by creating new functions to instantiate members of its existing subclasses
- Developers who document and/or verify their code using type annotations

**Any Other info.**
"
29704,Tensorflow 2.0 for raspberry pi installation,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian GNU/Linux 9 (stretch)
- TensorFlow version: Tried tensorflow 2.0 alpha and tensorflow 2.0 beta
- Python version: 3.5.3
- Installed using virtualenv? pip? conda?: virtual environmet and pip

**Describe the problem**

Can not install tensorflow 2.0 with pip install. The pip install command doesn't find the distribution package

**Provide the exact sequence of commands / steps that you executed before running into the problem**

On a raspberry py with raspbian 9:

- Create virtualenv
- Activate virtualenv
- Use command: pip install tensorflow==2.0.0-beta0 or pip install tensorflow==2.0.0-a0

**Any other info / logs**

 ERROR: Could not find a version that satisfies the requirement  tensorflow==2.0.0-beta0 (from versions: 0.11.0, 1.8.0, 1.9.0, 1.10.1, 1.11.0)
ERROR: No matching distribution found for  tensorflow==2.0.0-beta0
"
29701,ERROR: Using multiple TPUs in a single session is not yet implemented,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9
- TensorFlow installed from (source or binary): preinstalled
- TensorFlow version (use command below): 1.13.1
- Python version: 3.5

**Describe the current behavior**

Error when trying to use 2 x TPUs v3 in TPUClusterResolver

**Describe the expected behavior**

No error

Model
```
TPU_ADDRESS1 = 'grpc://10.240.1.2:8470'
TPU_ADDRESS2 = 'grpc://10.240.2.2:8470'
   
opt = tf.train.AdamOptimizer(0.01)

model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])

tpu_model = tf.contrib.tpu.keras_to_tpu_model(model, 
        strategy=tf.contrib.tpu.TPUDistributionStrategy(
            tf.contrib.cluster_resolver.TPUClusterResolver(tpu = [TPU_ADDRESS1,TPU_ADDRESS2])))
```
Error
```
/usr/local/lib/python3.5/dist-packages/tensorflow/python/distribute/cluster_resolver/tpu_cluster_resolver.py in __init__(self, tpu, zone, project, job_name, coordinator_name, coordinator_address, credentials, service, discovery_url)
    215       if len(tpu) != 1:
    216         raise NotImplementedError(
--> 217             'Using multiple TPUs in a single session is not yet implemented')
    218       tpu = tpu[0]
    219 

NotImplementedError: Using multiple TPUs in a single session is not yet implemented
```
"
29700,[TF 2.0] tf.linalg.inv,"**System information**
- TensorFlow version: '2.0.0-dev20190612'
- Python version: 3.6.7

**Describe the current behavior**
I am taking the inverse of a matrix with a large condition number, see the code for the matrix example, when I try tf.linalg.inv(A) I get the error: InvalidArgumentError: Input is not invertible. [Op:MatrixInverse]

**Describe the expected behavior**
I don't think that is the correct error, because the Matrix can be inverted because the determinant is not exactly zero and TF gets it as zero due to the way tf.linalg.det is implemented. But if you try the same in numpy or Matlab, we can get the inv, in numpy you get the inv and in Matlab, you get the inv with a warning. Again, the determinant is very small (2.1934511e-08), for all purposes it can be assumed to be zero, so in the least, the error can be more of a warning rather than a not invertible error.

Also, I am curious to know how precise TF calculations are or after how many significant figure something is rounded to be zero. If you have any resources or links so I can check it out, would really appreciate it.

**Code to reproduce the issue**
```
A = tf.constant([[4.1, 2.8], [9.676, 6.608]], dtype=tf.float32)
Ainvnp = np.linalg.inv(A)
print(A2inv)

Ainvtf = tf.linalg.inv(A)
print(Ainvtf)
```
"
29697,tensorflow 2.0 tf.data cache,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): Binary pip3
- TensorFlow version (use command below):  2.0.0.dev20190523 
- Python version: 3.5
- CUDA/cuDNN version: 10/7
- GPU model and memory: Titan V 12GB

**Describe the current behavior**
Whenever using dataset.cache(""tmp_disk_file""), memory keeps increasing even though I save them into a disk file.  

**Describe the expected behavior**
No memory usage difference with and without cache to disk.

**Code to reproduce the issue**
I don't have a code to regenerate the exact issue, but here is a pipeline sample.
```
list_of_tfrecords = [filename1, filename2, filename3]
# construct_dataset will form a pipeline to process data, 
# at the end of the pipeline, cache that pipeline for file
list_of_datasets_to_cache = [construct_dataset(filename) for filename in list_of_tfrecords]
train_dataset = tf.data.experimental.sample_from_datasets(list_of_datasets_to_cache)
```
Note: the reason I'm doing this is I have a very expensive pipeline, I want to speed up the second epoch. There's better way doing this, but I want to do it this way because I'm doing cross-validation, and if I cache by forming a pipeline with all files, then I can't reuse the cache (I'm going to change to different folds next epoch - i.e. new dataset).
"
29696,MemoryError in the middle of training after x epochs: _XlaCompile error at beginning,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- custom code
- Windows 10 1803
- TensorFlow installed using pip with conda as environment manager. 
    `pip install --ignore-installed --upgrade tensorflow-gpu==2.0.0-beta0`
- TensorFlow version unknown 2.0.0-beta0
- Python version: 3.6.8
- CUDA version: 10.0
- GPU model and memory: Nvidia GeForce 1060 3GB

**Describe the current behavior**
While training the model after a number of epochs, a MemoryError suddenly occurs with top Error as `Operation 'simple_rnn_1/while' has no attr named '_XlaCompile'`. This occured while extending the training epochs by executing `model.fit()` subsequently. However, restarting the computer resolves the problem. 

_The problem occurred only once so far._ 

**Describe the expected behavior**
The training should finish after the set number of epochs.
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
uniform_regularizer=0
model=tf.keras.Sequential([
    tf.keras.layers.SimpleRNN(
    units=5,
    kernel_initializer='he_normal',
    recurrent_initializer='he_normal',
    kernel_regularizer=tf.keras.regularizers.l1(l=uniform_regularizer),
    use_bias=False,
    stateful=True,
    batch_input_shape=(3, 20, 3)),
    tf.keras.layers.Dense(3,
        kernel_initializer='he_normal',
        kernel_regularizer=tf.keras.regularizers.l1(l=uniform_regularizer),
        use_bias=False)
])
def loss(explanvar, targetvar):
  return tf.keras.metrics.mean_absolute_error(
    explanvar,
    targetvar)
model.compile(
    optimizer='adam',
    loss = loss)
checkpoint_path = ""training_1/cp.ckpt""
checkpoint_dir = os.path.dirname(checkpoint_path)

# Create checkpoint callback
cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,
                                                 save_weights_only=True)
history = model.fit(train, 
                    epochs=55, 
                    steps_per_epoch=10,
                    callbacks=[cp_callback],
                    class_weight={0:0.4,
                                  1:0.2,
                                  2:0.4},                   
                    validation_data=test)
```
**Other info / logs**
_See attached file_
[stacktrace.txt](https://github.com/tensorflow/tensorflow/files/3281953/stacktrace.txt)
"
29695,Scripts halts with make_initializable_iterator with non empty shared_name,"**System information**
- Custom code
- Linux Ubuntu 16.04
- TensorFlow installed from: source
- TensorFlow version: 1.12.0
- Python version: 2.7.12
- Bazel version: 0.25.1
- CUDA/cuDNN version: 9.0.176 / 7.0
- GPU model and memory: GeForce GTX 1080Ti

**Describe the current behavior**

The script doesn't finish. I discovered that it halts after TF_CloseSession and even KeyboardInterrupt can't stop the script. I also discovered that it exits normally if I pass `shared_name=""""`. So it looks like that this place https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/iterator_ops.cc#L465
contains the bug. Possible deadlock or session can wait for iterator to free resources.

I also can reproduce the problem with MacOS without Cuda.

**Describe the expected behavior**

I expect this script to finish normally.

**Code to reproduce the issue**

```
import tensorflow as tf
import os
os.environ['CUDA_VISIBLE_DEVICES'] = """"


def generator():
    for i in range(10):
        yield [20.]


def main():
    config = tf.ConfigProto(intra_op_parallelism_threads=1,
                            inter_op_parallelism_threads=1)

    dataset = tf.data.Dataset.from_generator(
        generator,
        output_types=(tf.float32), output_shapes=(tf.TensorShape([1])))
    train_iterator = dataset.make_initializable_iterator(shared_name='g')

    with tf.Session(config=config) as session:
        session.run(train_iterator.initializer)

        data_producer = train_iterator.get_next()
        session.run(data_producer)
if __name__ == '__main__':
    main()
```

**Other info / logs**
Traceback from gdb:
```
#0  syscall () at ../sysdeps/unix/sysv/linux/x86_64/syscall.S:38
#1  0x00007fffeafd62b1 in nsync::nsync_mu_semaphore_p(nsync::nsync_semaphore_s_*) () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#2  0x00007fffeafd4028 in nsync::nsync_mu_lock_slow_(nsync::nsync_mu_s_*, nsync::waiter*, unsigned int, nsync::lock_type_s*) () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#3  0x00007fffeafd411d in nsync::nsync_mu_lock(nsync::nsync_mu_s_*) () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#4  0x00007fffe5618998 in tensorflow::ResourceMgr::Cleanup(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) ()
   from /usr/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so
#5  0x00007fffe8a96fc0 in ?? () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#6  0x00007fffe8a99ec5 in tensorflow::data::CapturedFunction::RunInstantiated(std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) ()
   from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007fffe894b13b in tensorflow::data::GeneratorDatasetOp::Dataset::Iterator::~Iterator() () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#8  0x00007fffe894b211 in tensorflow::data::GeneratorDatasetOp::Dataset::Iterator::~Iterator() () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#9  0x00007fffe8946ac5 in ?? () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#10 0x00007fffe8966571 in tensorflow::data::IteratorResource::~IteratorResource() () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#11 0x00007fffe5615d1c in tensorflow::ResourceMgr::Clear() () from /usr/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so
#12 0x00007fffea97826b in tensorflow::DirectSession::~DirectSession() () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#13 0x00007fffea9787a1 in tensorflow::DirectSession::~DirectSession() () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#14 0x00007fffe7903a07 in tensorflow::SessionRef::Close() () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#15 0x00007fffe7ae2f0b in TF_CloseSession () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#16 0x00007fffe789fae6 in ?? () from /usr/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#17 0x00000000004bc4aa in call_function (oparg=<optimized out>, pp_stack=0x7fffffffd260) at ../Python/ceval.c:4350
#18 PyEval_EvalFrameEx () at ../Python/ceval.c:2987
#19 0x00000000004b9b66 in PyEval_EvalCodeEx () at ../Python/ceval.c:3582
#20 0x00000000004c1f56 in fast_function (nk=<optimized out>, na=<optimized out>, n=1, pp_stack=0x7fffffffd460, func=<function at remote 0x7fffb659b578>) at ../Python/ceval.c:4445
#21 call_function (oparg=<optimized out>, pp_stack=0x7fffffffd460) at ../Python/ceval.c:4370
#22 PyEval_EvalFrameEx () at ../Python/ceval.c:2987
#23 0x00000000004b9b66 in PyEval_EvalCodeEx () at ../Python/ceval.c:3582
#24 0x00000000004d5669 in function_call.lto_priv () at ../Objects/funcobject.c:523
#25 0x00000000004eef5e in PyObject_Call (kw=0x0,
    arg=(<Session(_config=<ConfigProto at remote 0x7fffa22d57d0>, _graph=<Graph(_default_original_op=None, _handle_feeders={}, _stack_state_is_thread_local=False, _collections={'iterators': [<Tensor(_op=<Operation(_graph=<...>, _device_code_locations=[], _id_value=2, _control_flow_context=None, _outputs=[<...>], _original_op=None, _traceback=[('minimal_example.py', 30, '<module>', {'generator': <function at remote 0x7fffa22d56e0>, '__builtins__': <module at remote 0x7ffff7fb7b08>, '__file__': 'minimal_example.py', '__package__': None, 'tf': <module at remote 0x7ffff7ead2f0>, '__name__': '__main__', 'main': <function at remote 0x7fffa22d55f0>, 'os': <module at remote 0x7ffff7f8cd00>, '__doc__': None}, 3, None), ('minimal_example.py', 20, 'main', {...}, 13, None), ('/usr/lib/python2.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py', 140, 'make_initializable_iterator', {'CacheDataset': <ABCMeta(__module__='tensorflow.python.data.ops.dataset_ops', _abc_negative_cache=<WeakSet(_remove=<function at remote 0x7fffb5...(truncated), func=<function at remote 0x7fffb659f140>) at ../Objects/abstract.c:2546
#26 instancemethod_call.lto_priv () at ../Objects/classobject.c:2602
#27 0x00000000004ae043 in PyObject_Call (kw=0x0, arg=(None, None, None), func=<instancemethod at remote 0x7fffa3329820>) at ../Objects/abstract.c:2546
#28 PyObject_CallFunctionObjArgs () at ../Objects/abstract.c:2773
#29 0x00000000004bed46 in PyEval_EvalFrameEx () at ../Python/ceval.c:2948
#30 0x00000000004c141f in fast_function (nk=<optimized out>, na=<optimized out>, n=0, pp_stack=0x7fffffffdb40, func=<function at remote 0x7fffa22d55f0>) at ../Python/ceval.c:4435
#31 call_function (oparg=<optimized out>, pp_stack=0x7fffffffdb40) at ../Python/ceval.c:4370
#32 PyEval_EvalFrameEx () at ../Python/ceval.c:2987
#33 0x00000000004b9b66 in PyEval_EvalCodeEx () at ../Python/ceval.c:3582
#34 0x00000000004eb69f in PyEval_EvalCode (
    locals={'generator': <function at remote 0x7fffa22d56e0>, '__builtins__': <module at remote 0x7ffff7fb7b08>, '__file__': 'minimal_example.py', '__package__': None, 'tf': <module at remote 0x7ffff7ead2f0>, '__name__': '__main__', 'main': <function at remote 0x7fffa22d55f0>, 'os': <module at remote 0x7ffff7f8cd00>, '__doc__': None},
    globals={'generator': <function at remote 0x7fffa22d56e0>, '__builtins__': <module at remote 0x7ffff7fb7b08>, '__file__': 'minimal_example.py', '__package__': None, 'tf': <module at remote 0x7ffff7ead2f0>, '__name__': '__main__', 'main': <function at remote 0x7fffa22d55f0>, 'os': <module at remote 0x7ffff7f8cd00>, '__doc__': None}, co=0x7ffff7eecd30) at ../Python/ceval.c:669
#35 run_mod.lto_priv () at ../Python/pythonrun.c:1376
#36 0x00000000004e58f2 in PyRun_FileExFlags () at ../Python/pythonrun.c:1362
#37 0x00000000004e41a6 in PyRun_SimpleFileExFlags () at ../Python/pythonrun.c:948
#38 0x00000000004938ce in Py_Main () at ../Modules/main.c:640
#39 0x00007ffff760b830 in __libc_start_main (main=0x493370 <main>, argc=2, argv=0x7fffffffdf88, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffffffdf78) at ../csu/libc-start.c:291
#40 0x0000000000493299 in _start ()
```

Looking at the `info threads`, we can see that all the threads are waiting for something:

```
* 1    Thread 0x7ffff7faf840 (LWP 27148) ""python"" syscall () at ../sysdeps/unix/sysv/linux/x86_64/syscall.S:38
  2    Thread 0x7fffa2256700 (LWP 27153) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  3    Thread 0x7fffa1a55700 (LWP 27154) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  6    Thread 0x7fff93fff700 (LWP 27157) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  7    Thread 0x7fffa0a53700 (LWP 27158) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
  8    Thread 0x7fffa1254700 (LWP 27159) ""python"" pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
```"
29694,Get Per-sample Gradient for a Batch,"**System information**
- TensorFlow version (you are using): --
- Are you willing to contribute it (Yes/No): Yes, but not sure if I am able to.



**Describe the feature and the current behavior/state.**
Now when I do SGD on a model, the gradients for a batch is returned but I want an array of gradients such that each element corresponds to a sample in this batch.

**Will this change the current api? How?**
I assume we can achieve this by changing `optimizer.compute_gradients` or `tf.gradients`

**Who will benefit with this feature?**
There are other ways to use the gradients including the one I am trying to implement.

**Any Other info.**"
29693,Tflite results dont match corresponding Tensorflow for Mobilenet.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10 and Ubuntu16.04
- TensorFlow installed from (source or binary): pip install tensorflow-gpu
- TensorFlow version (or github SHA if from source):1.13


[mobilenet_tflite_test.zip](https://github.com/tensorflow/tensorflow/files/3281327/mobilenet_tflite_test.zip)


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

Also, please include a link to a GraphDef or the model if possible.
https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_1.0_224_frozen.tgz

**Any other info / logs**
Description : I am trying to quantize the Mobilenet using tflite. After converting , i used tensorflow to validate my results. I find that quantized results are not matching to float tensorflow based results.
I have an output for about 10 elements and maximum value index , both of them are mismatching as shown.
Please let me know whether i am missing any thing or is this real problem ?

_--------------------Float values are --------------------------
[-1.8004932  -0.23941718  0.61870384 -0.4235621  -1.1386781   0.99633265
  0.16455668  0.743189   -1.9882091  -1.270742  ]
Max Index  (array([420], dtype=int64),)
---------Fixed pt values are -----------------------------------
[-2. -8.  0. -6. -2. -6.  2. -2. -2. -2.]
Max Index  (array([812], dtype=int64),)_

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29692,ModuleNotFoundError: No module named '_pywrap_tensorflow_internal',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 1.8
- Python version: 3.6.5
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CPU only
- GPU model and memory: CPU only



**Describe the problem**
All of my Tensorflow codes work fine for version 1.5 but fail when I upgraded it to 1.8. The error is shown below:

```
Traceback (most recent call last):
  File ""C:\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 14, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: DLL load failed with error code -1073741795

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 16, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""d:\SVNRepo\Python_codes\scratch.py"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Python36\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Python36\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 14, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: DLL load failed with error code -1073741795

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 16, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.
```
See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.`

**Provide the exact sequence of commands / steps that you executed before running into the problem**

The error occurs by only running `import tensorflow as tf`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29689,Sharing output of one model as input for other models  ,"I am trying something like where i have three models named model_1, model_2 and model_3. I want to use output of model_1 as input to model_2 and model_3. These models are running in separate threads parallelly. How can i do this? 

I stored output Tensor of model_1 in a queue and tried to get data for model_2 and model_3 from there using locks.  But it failed please help in solving this issue. 
Here is my code:

```  python
import tensorflow as tf
import threading
import queue

inputQ = queue.Queue()
outputQ = queue.Queue()

from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)

learning_rate = 0.001
num_steps = 300
batch_size = 128
display_step = 100

input = 784 # MNIST data input (img shape: 28*28)
n_classes = 10 # MNIST total classes (0-9 digits)
dropout = 0.75 # Dropout, probability to keep units



g1 = tf.Graph()
sess1 = tf.Session(graph=g1)

with g1.as_default():
    dataset = tf.data.Dataset.from_tensor_slices(
        (mnist.train.images, mnist.train.labels))

    dataset = dataset.repeat()
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(batch_size)
    iterator = dataset.make_initializable_iterator()
    sess1.run(iterator.initializer)
    X, Y = iterator.get_next()


def model_1 (g2,sess,x, n_classes, dropout, reuse):
        with g2.as_default(), sess.as_default():
            with tf.variable_scope('ConvNet', reuse=reuse):
                    x = tf.reshape(x, shape=[-1, 28, 28, 1])
                    conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)
                    conv1 = tf.layers.max_pooling2d(conv1, 2, 2)
                    conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)
                    conv2 = tf.layers.max_pooling2d(conv2, 2, 2)
                    fc1 = tf.contrib.layers.flatten(conv2)
                    init = tf.global_variables_initializer()
                    sess.run(init)
                    sess.run(fc1)
                    inputQ.put(fc1)

def model_2 (g2,sess,n_classes, dropout, reuse, is_training):
    with g2.as_default(), sess.as_default():
        with tf.variable_scope('ConvNet2', reuse=reuse):
            fc1 = inputQ.queue[0]
            fc1 = tf.layers.dense(fc1, 1024)
            fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)
            out = tf.layers.dense(fc1, n_classes)
            out = tf.nn.softmax(out) if not is_training else out
            loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                        logits=out, labels=Y))
            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
            train_op = optimizer.minimize(loss_op)
            correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(Y, 1))
            accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
            init = tf.global_variables_initializer()
            sess.run(init)

            for step in range(1, num_steps + 1):
                sess.run(train_op)
                if step % 100 == 0 or step == 1:           
                    loss, acc = sess.run([loss_op, accuracy])
                    print(""T1 Step "" + str(step) + "", Minibatch Loss= "" + ""{:.4f}"".format(loss) + "",Training Accuracy= ""+""{:.3f}"".format(acc))


def model_3 (g2,sess,n_classes, dropout, reuse, is_training):
    with g2.as_default(), sess.as_default():
        with tf.variable_scope('ConvNet3', reuse=reuse):
            fc1 = inputQ.queue[0]
            fc1 = tf.layers.dense(fc1, 512)
            fc1 = tf.layers.dense(fc1, 1024)
            fc1 = tf.layers.dropout(fc1, rate=0.55, training=is_training)
            out = tf.layers.dense(fc1, n_classes)          
            out = tf.nn.softmax(out) if not is_training else out
            loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                        logits=out, labels=Y))

            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
            train_op = optimizer.minimize(loss_op)
            correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(Y, 1))
            accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
            init = tf.global_variables_initializer()
            sess.run(init)
            
            for step in range(1, num_steps + 1):
                sess.run(train_op)
                if step % 100 == 0 or step == 1:
                    loss, acc = sess.run([loss_op, accuracy])
                    print(""T2 Step "" + str(step) + "", Minibatch Loss= ""+""{:.4f}"".format(loss) + "",Training Accuracy=""+""{:.3f}"".format(acc))


thread_Train0 = threading.Thread(target=model_1,args = (g1,sess1,X,n_classes,dropout, False))
thread_Train1 = threading.Thread(target=model_2,args = (g1,sess1,n_classes,  dropout, False, True))
thread_Train2 = threading.Thread(target=model_3,args = (g1,sess1,n_classes,  dropout, False, True))

thread_Train0.start()
thread_Train1.start()
thread_Train2.start()

thread_Train0.join()
thread_Train1.join()
thread_Train2.join()
```"
29688,[TF API Docs] UX - `tf.io.FixedLenFeature` and `tf.FixedLenFeature `,"#### Issue description:
In the `tf.data` pipelines guide on TensorFlow.org called 'Importing Data', under 'Processing data with `Dataset.map()`' there is an [example](https://www.tensorflow.org/guide/datasets#parsing_tfexample_protocol_buffer_messages) showcasing how to parse `tf.example` protocol buffer messages':

```python
def _parse_function(example_proto):
  features = {""image"": tf.FixedLenFeature((), tf.string, default_value=""""),
              ""label"": tf.FixedLenFeature((), tf.int64, default_value=0)}
  parsed_features = tf.parse_single_example(example_proto, features)
  return parsed_features[""image""], parsed_features[""label""]
...
```
The config class for parsing fixed length input features used in the example - `tf.FixedLenFeature` - may not be easily identifiable in the API docs since its description is under the `tf.io` module under the alias `tf.io.FixedLenFeature`. 

UX: Figuring out what  `tf.FixedLenFeature` does required using the search bar on TensorFlow.org vs the TF Python [API site](https://www.tensorflow.org/api_docs/python/tf).

(For your reference: [1.13 (core) doc](https://www.tensorflow.org/api_docs/python/tf/io/FixedLenFeature),  [r1.14 doc](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/io/FixedLenFeature), [r2.0 beta doc](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/FixedLenFeature))

#### Feature request:
Change the class in the guide to `tf.io.FixedLenFeature` or reference with a link to `tf.io...` for better UX."
29687,"HashTable lookup performance very low in comparison to plain Python dictionaries (~5,000x)","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04.2 LTS (Bionic Beaver)
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No
- **TensorFlow installed from (source or binary)**: Don't know (Colab)
- **TensorFlow version (use command below)**: 1.13.1
- **Python version**: 3.6.7
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: - 
- **CUDA/cuDNN version**: 10.0.130
- **GPU model and memory**: 
- **Exact command to reproduce**:  tf.contrib.lookup.HashTable..lookup()




### Describe the problem
While writing a document ranking algorithm in TensorFlow we found out that TensorFlow `HashTable`s appear to be very slow (~5,000x) in comparison to plain Python `dict`ionaries. 

Looking into the TensorFlow source code in `lookup_table_op.cc` (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/lookup_table_op.cc) shows that the underlying object structure appears to be an `unordered_map`. So we wonder, why the performance is so low? 

### Source code / logs
Here is the source code that is similar to a part of what we use and can be easily executed on any system. There is actually a __Colab__ notebook that can be used: https://colab.research.google.com/drive/1bB_sir7-sVd3bNrSgkcdT9UlU9eoyA2Q 

```python
import urllib.request
import tensorflow as tf
import re, time
from nltk.corpus import stopwords
from nltk import word_tokenize, download
# For loading the 'punkt' module of 'nltk'. This has to be done only once.
download( 'punkt' )
download( 'stopwords' )

url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/cowper.txt'
urllib.request.urlretrieve( url, './cowper.txt' )

def parse_text( input_path = './cowper.txt', output_path = 'cowper_tf.txt' ):
    stop_words      = set( stopwords.words( 'english' ) )    
    with open( output_path, 'w+' ) as output_file:
        document = []
        with open( input_path, 'r' ) as file:
            for line in file:
                for token in map( str.lower, word_tokenize( line ) ):                    
                    if not token in stop_words and bool( re.match( r'[a-zA-Z]', token ) ):
                        document.append(token)             
            output_file.write(' '.join( document ) ) 

parse_text()

with open( 'cowper_tf.txt' ) as file:
    for line in file:
        document = re.split( r'\s', line )[1:-1]

k = 100
dictionary_list = []
hashtable_list  = []
frequencies     = {}
for i in range( k ):
    for word in document:    
        if word not in frequencies:
            frequencies[word] = 0        
            frequencies[word] += 1        
    keys           = tf.constant( list( frequencies.keys() ) )
    values         = tf.constant( list( frequencies.values() ) )
    frequencies_tf = tf.contrib.lookup.HashTable( 
        tf.contrib.lookup.KeyValueTensorInitializer(
            keys   = keys,
            values = values ),
        default_value = 0 )
    hashtable_list.append( frequencies_tf )
    dictionary_list.append( frequencies )

n = 100
test_word = tf.constant( 'sing', dtype = tf.string, shape = () )
global tf_time
def test_lookup( test_word, n = 100 ):
    start = time.clock()
    for i in range( n ):    
        a = [hashtable.lookup( test_word ) for hashtable in hashtable_list]
    tf_time = ( time.clock() - start ) / n
    print( 'time elapsed per lookup: ', tf_time )
    return a
with tf.Session() as sess:
    sess.run( tf.global_variables_initializer() )
    sess.run( tf.tables_initializer() )
    sess.run( test_lookup( test_word, n ) )

test_word = 'add'
start = time.clock()
for i in range( n ):
    a = [dictionary[test_word] for dictionary in dictionary_list]
plain_python_time = ( time.clock() - start ) / n
print( 'elapsed time:', plain_python_time )
```
"
29686,[Find header file after build manually tensor flow lite],"Hello, I built tensorflow lite for ARM 64 on Linux.
And After building successful I have a library called ""libtensorflow-lite.a""
As you know, if we want to use this lib, we have both lib and header file (.h file in my case).
But where can I get all header file for libtensorflow lib.
In result folder (gen folder in my case), I see bin, lib, object but include folder does't exist."
29685, [TF 2.0 API Docs] tf.keras.constraints.MinMaxNorm,"# Existing URLs containing the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/constraints/MinMaxNorm
## Description of the issue (what needs changing):
- ### Correct links:
     Yes

- ###  Clear Description:
  No, The description does not give recommendations of when and when not to use this symbol

- ### Usage Example:
   No usage example 

- ### Parameters Defined:
   Parameters are Well defined

  - ### Returns are not defined

- ### Raises listed and Defined:
  Errors are not defined.

- ### Visuals if applicable:
  No visuals are included."
29684,Error building hlo_verifier_test.cc,"```
tensorflow/compiler/xla/service/hlo_verifier_test.cc:719:31: error: 'StrReplaceAll' is not a member of 'absl'
   return ParseHloString(absl::StrReplaceAll(
                               ^~~~~~~~~~~~~
```

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes - but no changes to this file.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04
- TensorFlow installed from (source or binary): source build
- TensorFlow version (use command below): master
- Python version: master build
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0

When building from source including XLA I receive the error above.
"
29683,[TF 2.0 API Docs]  tf.keras.metrics.BinaryAccuracy,"TensorFlow version: 2.0
## Existing URLs containing the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/metrics/BinaryAccuracy

## Description of the issue (what needs changing):

- #### Correct links: 
       Yes

- #### Clear Description: 
   No, The description does not  give recommendations of when and when not to use this symbol

- #### Usage Example: 
       Yes
- #### Parameters Defined:

  Parameters are poorly defined, and not formatted appropriately.
- ####  Returns Defined: 

    Returns are not defined
. 
- ####  Raises listed and Defined:

   Errors are not defined.

- #### Visuals if applicable: 
   No visuals are included.
"
29682,can not start session,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29681,Cannot run a Process under a Thread when using tf.set_random_seed,"**System information**
- OS Platform and Distribution: Linux Ubuntu 16 and 18
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.8

**No issue on:** tf 1.5.0, Python 3.6.8 and Ubuntu 16

**Issue**

When using `tf.set_random_seed` I cannot run a Process under a Thread

**Code**

```python
import tensorflow as tf
from threading import Thread
from multiprocessing import Process

def misc():
    print(""misc"")

def do():
    p = Process(target=misc)
    p.start()
    p.join()

def test():
    a = Thread(target=do)
    a.start()
    a.join()

if __name__ == '__main__':
    print(""main start"")
    test()
    print(""first test done"")
    tf.set_random_seed(0)
    test()
    print(""second test done"")
```

This script ouput:

```
main start
misc
first test done
```
 
And the process block.

**Expected output**

```
main start
misc
first test done
misc
second test done
```
"
29680,TF2-BETA: Model inputs check bug with new feature: distribute model without cloning.,"**System information**
- Have I written custom code: Yes
- OS Platform: Win10
- TensorFlow installed: pip install
- TensorFlow version: tensorflow-gpu==2.0.0-beta0 and tf-nightly-gpu-2.0-preview==2.0.0.dev20190509
- Python version: 3.6

**Describe the current behavior**
Distribute strategy cannot properly handle dict/tuple type inputs in tensorflow-gpu==2.0.0-beta0 while there is no problem in non-distribute scenario.

What the interesting thing is that in tf2.0-alpha, the bug existed already, but later in tf-nightly-gpu-2.0-preview==2.0.0.dev20190509. The problem seems to be solved. In that version, both distribute/non-distribute scenarios works good with dict type inputs. But I dont know why this bug appears again in beta version.

I thought this problem is caused when distribute strategy trying to slice the inputs equally to all replica. Maybe the input parse method in distribute strategy is not fully tested. But since there is no public change log for tf-nightly. So i myself cannot dig this anymore without the help of tf team members.


```python
import tensorflow as tf
from tensorflow.python.keras import layers as KL
from tensorflow.python.keras import models as KM
import numpy as np

def custom_loss(predict, label, weight):
    bce = tf.losses.binary_crossentropy(label, predict)
    return tf.reduce_mean(bce * weight)

def create_model():
    input_img = KL.Input([64, 64, 3], name=""img"")
    input_lbl = KL.Input([64, 64, 1], name=""lbl"")
    input_weight = KL.Input([64, 64], name=""weight"")
    predict = KL.Conv2D(2, [1, 1], padding=""same"")(input_img)
    my_loss = KL.Lambda(lambda x: custom_loss(*x), name=""my_loss"")([predict, input_lbl, input_weight])
    model = KM.Model(inputs=[input_img, input_lbl, input_weight], outputs=[predict, my_loss])
    model.add_loss(model.get_layer(""my_loss"").output)
    model.compile(optimizer=""adam"")
    return model

def get_dict_dataset():
    def map_fn(img, lbl, weight):
        inputs = {""img"": img, ""lbl"": lbl, ""weight"": weight}
        targets = {}
        return inputs, targets

    fake_imgs = np.ones([50, 64, 64, 3])
    fake_lbls = np.ones([50, 64, 64, 1])
    fake_weights = np.ones([50, 64, 64])

    return tf.data.Dataset.from_tensor_slices((fake_imgs, fake_lbls, fake_weights)).map(map_fn).batch(10)
```
tensorflow-gpu==2.0.0-beta0
in non-distribute scenario:
```python
model = create_model()
data = get_dict_dataset()
model.fit(data)
10/10 [==============================] - 1s 143ms/step - loss: 0.0000e+00
```
in distribute scenario:
```python
strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())
with strategy.scope():
    model = create_model()
    data = get_dict_dataset()
    model.fit(data)
AttributeError: 'dict' object has no attribute 'shape'
```
Still not working Even if i change the dict to tuple:
```python
def get_tuple_dataset():
    def map_fn(img, lbl, weight):
        inputs = (img, lbl, weight)
        targets = tuple()
        return inputs, targets

    fake_imgs = np.ones([50, 64, 64, 3])
    fake_lbls = np.ones([50, 64, 64, 1])
    fake_weights = np.ones([50, 64, 64])

    return tf.data.Dataset.from_tensor_slices((fake_imgs, fake_lbls, fake_weights)).map(map_fn).batch(10)

with strategy.scope():
    model = create_model()
    data = get_tuple_dataset()
    model.fit(data)
ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 2 arrays
```

Again, the scenarios described above working good in  tf-nightly-gpu-2.0-preview==2.0.0.dev20190509. And again there is no public change log for tf-nightly so I cannot dig this any deeper alone.


**Describe the expected behavior**
Since the model behavior should be consistent. Tf team should decide weather to support dict type inputs. If no, both distribute/non-distribute model should not accept dict input and vice versa.

"
29679,the tfdbg CLI does not apepar  in tensorflow alpha2.0,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):   Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):   pip install
- TensorFlow version (use command below):   tensorflow apha 2.0
- Python version:   3.6.3
- CUDA/cuDNN version:   CUDA Version 10.1.105, cudnn 7.5
- GPU model and memory:   GTX 2080TI

*Describe the current behavior**
```
from tensorflow.python import debug as tf_debug
keras.backend.set_session(\
        tf_debug.LocalCLIDebugWrapperSession(tf.compat.v1.Session()))
```
**the tfdbg CLI does not apepar**, I want to know what is the problem, and how to solve it


**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
import sys
import os
import json
import numpy as np
import tensorflow as tf
import tensorflow.keras as keras

os.environ['CUDA_VISIBLE_DEVICES'] = ''

def basic_generator():
    """"""
    """"""
    data_x = [[0, 1, 2, 3], [1, 2, 3, 4], \
        [0, 1, 3, 4], [0, 2, 1, 4]]
    data_y = [[0, 1, 2, 3], [1, 2, 3, 4], \
        [0, 1, 3, 4], [0, 2, 1, 4]]
    for x, y in zip(data_x, data_y):
        yield (x, y)

if __name__ == ""__main__"":
    params = { 
       'seq_len': 8,
        'use_bert': False,
        'batch_size': 2,
        'epochs': 5,
        'vocab_len': 5,
        'num_entities': 3,
        'use_pre_emb': False,
        'emb_dim': 20,
        'use_emb_drop': False,
        'emb_drop_rate': 0.8,
        'num_layer': 1,
        'num_lstm_cell': [15],
        'rec_drops': [0.8],
        'lr': 0.001
    }

    output_types = (tf.int32, tf.int32)
    dataset = tf.data.Dataset.from_generator(\
        basic_generator, output_types)
    dataset = dataset.padded_batch(\
        params['batch_size'], \
            ([params['seq_len'], ], [params['seq_len'], ]))

    from tensorflow.python import debug as tf_debug
    keras.backend.set_session(\
        tf_debug.LocalCLIDebugWrapperSession(tf.compat.v1.Session()))

    dataset = dataset.map(lambda x, y: (x, tf.one_hot(y, params['num_entities'])))
    dataset = dataset.repeat(params['epochs'])
    
    #model = LstmCrf(params)
    model = keras.Sequential()
    inputs = keras.Input(shape=(None, ))
    emb_ini = keras.initializers.TruncatedNormal()
    model.add(keras.layers.Embedding(\
                params['vocab_len'], params['emb_dim'], \
                    embeddings_initializer=emb_ini, mask_zero=True))        
    model.add(keras.layers.TimeDistributed(\
        keras.layers.Dense(params['num_entities'])))
    model.add(keras.layers.Activation('softmax'))
       
    model.compile(optimizer=keras.optimizers.Adam(params['lr']), \
        loss='categorical_crossentropy', \
            metrics=['accuracy'])

    model.fit(dataset, epochs=params['epochs'], \
        steps_per_epoch=2)
    
```
"
29678,LoggingTensorHook used with TPUEstimator cause 'marked as not fetchable' exception.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Debian 4.9.168-1+deb9u2 (2019-05-13) x86_64 GNU/Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
N/A (GCP)
- TensorFlow version (use command below):
b'v1.13.0-rc0-0-g6ce86799c8' 1.13.0-rc0
- Python version:
Python 3.5.3
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
N/A
- GPU model and memory:
N/A

**Describe the current behavior**
With use_tpu set to True, and LoggingTensorHook is used by uncommenting the commented part (see the code below), training on GCP with TPU fails with 'marked as not fetchable' exception.

**Describe the expected behavior**
The behavior goes away and works without problem if I comment out the LoggingTensorHook parts, yet I have no idea what's the relevant issue.

The training fails with a very vague exception, which only says that the last op(tf.reduce_mean() in my case) has been marked as not fetchable, and no other useful information provided.

It makes it almost impossible to find the actual cause of the problem since the exception points to the wrong op, the reduce_mean(), which was actually not the problem.

**Code to reproduce the issue**
Uncommenting the commented parts reproduce the problem.

This is just a sample. With any model with the LoggingTensorHook provided as the hooks parameter, it throws an exception when trained with TPUs.
```
    def model_fn(features, labels, mode, params):
        del params

        char_embedding = CharacterAwareEmbedding(
            word_length=word_length,
            embedding_size=FLAGS.embedding_size,
            conv_size=FLAGS.conv_size,
            output_unit=FLAGS.output_unit,
        )

        target = features[""input_target""]
        target = char_embedding(target)

        if mode == tf.estimator.ModeKeys.PREDICT:
            predictions = {
                'vectorized': target,
                'word': features[""word""]
            }
            return tf.contrib.tpu.TPUEstimatorSpec(
                mode=mode,
                predictions=predictions)

        context = features[""input_context""]
        context = char_embedding(context)

        cossim = cossim_similarity(target, context)

        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(labels, tf.float32), logits=cossim))
        optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)

        # hook = tf.train.LoggingTensorHook({""loss"": loss}, every_n_iter=100)

        if mode == tf.estimator.ModeKeys.TRAIN:
            if FLAGS.use_tpu:
                optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)

            return tf.contrib.tpu.TPUEstimatorSpec(
                mode=mode,
                loss=loss,
                #training_hooks=[hook],
                train_op=optimizer.minimize(loss, tf.train.get_global_step()))

        if mode == tf.estimator.ModeKeys.EVAL:
            return tf.contrib.tpu.TPUEstimatorSpec(
                mode=mode,
                loss=loss,
                #training_hooks=[hook],
                eval_metrics=(metric_fn, [labels, cossim]))
```
**Other info / logs**
"
29677,tf.layers.dense deprecation update hint,"Referencing the deprecation hint of https://www.tensorflow.org/api_docs/python/tf/layers/dense

## Description of issue (what needs changing):

I wasn't able to find the referenced `tf.keras.layers.dense`, but only `tf.keras.layers.Dense`. Could this be a simple typo and the latter was ment to be pointed to?

### Submit a pull request?

If this is a simple issue and not a functionality missing or a fault of me not finding the referenced method, then yes, I would PR it."
29675,Adam/Adagrad gives different derivatives when initializing globaly and localy,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (2.0):
- Python version:(3.6)


**Describe the current behavior**
Adam and Adagrad, both gives different losses, when initialized once (globally) and initialized every time train function is called. 

````
#### Locally
def train2(model, inputs, outputs, learning_rate):
    trainable_variables = [model.W, model.b]
    with tf.GradientTape() as t:
        current_loss = loss(model(inputs), outputs)
    optimizer = tf.keras.optimizers.Adagrad(
    learning_rate=learning_rate,
    initial_accumulator_value=0.1,
    epsilon=1e-07,
)
    gradients = t.gradient(current_loss,  trainable_variables)    
    optimizer.apply_gradients(zip(gradients, trainable_variables))
#----------------------------------------------------------------------------------------------------
#### Globally

optimizer_global = tf.keras.optimizers.Adagrad(
    learning_rate=0.1,
    initial_accumulator_value=0.1,
    epsilon=1e-07,
)

def train(model, inputs, outputs, learning_rate):
    trainable_variables = [model.W, model.b]
    with tf.GradientTape() as t:
        current_loss = loss(model(inputs), outputs)
    
    gradients = t.gradient(current_loss,  trainable_variables)    
    optimizer_global.apply_gradients(zip(gradients, trainable_variables))
````


**Describe the expected behavior**
We expect same loss from both train and train2. ( Is it because, some internal parameters are changing inside the optimizer, because SGD optimizer works fine in both the cases).


**Code to reproduce the issue**
The plot of derivatives are provided in the image . Full code to reproduce is in the .ipynb file.
![tf](https://user-images.githubusercontent.com/10637096/59318400-9151cc80-8ce4-11e9-9b65-1712a86d2218.png)

````
#!/usr/bin/env python
# coding: utf-8



import tensorflow as tf
tf.compat.v1.set_random_seed(1)
import numpy as np
tf.__version__



class Model(object):
  def __init__(self):
    # Initialize variable to (5.0, 0.0)
    # In practice, these should be initialized to random values.
    self.W = tf.Variable(5.0)
    self.b = tf.Variable(0.0)
    
  def __call__(self, x):
    return self.W * x + self.b
  
model = Model()
def loss(predicted_y, desired_y):
    return tf.reduce_mean(tf.square(predicted_y - desired_y))

TRUE_W = 3.0
TRUE_b = 2.0
NUM_EXAMPLES = 1000

inputs  = tf.random.normal(shape=[NUM_EXAMPLES])
noise   = tf.random.normal(shape=[NUM_EXAMPLES])
outputs = inputs * TRUE_W + TRUE_b + noise # 3 x + 2 + noise()

import matplotlib.pyplot as plt
get_ipython().run_line_magic('matplotlib', 'inline')
plt.scatter(inputs, outputs, c='b')
plt.scatter(inputs, model(inputs), c='r')
plt.show()

def train2(model, inputs, outputs, learning_rate):
    trainable_variables = [model.W, model.b]
    with tf.GradientTape() as t:
        current_loss = loss(model(inputs), outputs)
    optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, 
                                         epsilon=1e-9)
    gradients = t.gradient(current_loss,  trainable_variables)    
    optimizer.apply_gradients(zip(gradients, trainable_variables))
    
#-----------------------------------------------------------------------------------------------

optimizer_global = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.98, 
                                         epsilon=1e-9)
def train(model, inputs, outputs, learning_rate):
    trainable_variables = [model.W, model.b]
    with tf.GradientTape() as t:
        current_loss = loss(model(inputs), outputs)
    
    gradients = t.gradient(current_loss,  trainable_variables)    
    optimizer_global.apply_gradients(zip(gradients, trainable_variables))

model = Model()

# Collect the history of W-values and b-values to plot later
Ws, bs = [], []
epochs = range(100)
for epoch in epochs:
  Ws.append(model.W.numpy())
  bs.append(model.b.numpy())
  current_loss = loss(model(inputs), outputs)

  train(model, inputs, outputs, learning_rate=0.1)
  print('Epoch %2d: W=%1.2f b=%1.2f, loss=%2.5f' %
        (epoch, Ws[-1], bs[-1], current_loss))

# Let's plot it all
plt.plot(epochs, Ws, 'r',
         epochs, bs, 'b')
plt.plot([TRUE_W] * len(epochs), 'r--',
         [TRUE_b] * len(epochs), 'b--')
plt.legend(['W', 'b', 'true W', 'true_b'])
plt.show()
  

#---------------------------------------------------------

model = Model()

# Collect the history of W-values and b-values to plot later
Ws, bs = [], []
epochs = range(100)
for epoch in epochs:
  Ws.append(model.W.numpy())
  bs.append(model.b.numpy())
  current_loss = loss(model(inputs), outputs)

  train2(model, inputs, outputs, learning_rate=0.1)
  print('Epoch %2d: W=%1.2f b=%1.2f, loss=%2.5f' %
        (epoch, Ws[-1], bs[-1], current_loss))

# Let's plot it all
plt.plot(epochs, Ws, 'r',
         epochs, bs, 'b')
plt.plot([TRUE_W] * len(epochs), 'r--',
         [TRUE_b] * len(epochs), 'b--')
plt.legend(['W', 'b', 'true W', 'true_b'])
plt.show()
  ````"
29674,Cannot find the placeholder op that is an input to ReadVariableOp in tf lite conversion.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2 beta
- Python version: 3.6.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: Cuda 10
- GPU model and memory: Geforce GTX 1060


**Describe the current behavior**
I have a pretty complicated model with three different inputs  and I can save and load it with custom objects as a keras model with model.save() and model.load() methods. I want to convert it to  tf lite and I get this error:
ValueError: Cannot find the Placeholder op that is an input to the ReadVariableOp

**Code to reproduce the issue**

```
loss_function = get_loss_function()
    model = tf.keras.models.load_model(save_checkpoint_address, custom_objects={
        'customlayer': CustomLayer,
        'loss_function': loss_function
    })

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open(""converted_model.tflite"", ""wb"").write(tflite_model)
```
**Other info / logs**
```
2019-06-11 19:55:42.378746: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2019-06-11 19:55:42.378868: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2019-06-11 19:55:42.434841: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-06-11 19:55:42.434867: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 2213 nodes (393), 3499 edges (663), time = 18.406ms.
2019-06-11 19:55:42.434874: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.785ms.
Traceback (most recent call last):
  File ""/home/siavash/programming/ximpa/carim_tensor/convert_to_tflite.py"", line 32, in <module>
    convert_saved_model()
  File ""/home/siavash/programming/ximpa/carim_tensor/convert_to_tflite.py"", line 27, in convert_saved_model
    tflite_model = converter.convert()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py"", line 348, in convert
    self._funcs[0])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py"", line 166, in convert_variables_to_constants_v2
    raise ValueError(""Cannot find the Placeholder op that is an input ""
ValueError: Cannot find the Placeholder op that is an input to the ReadVariableOp.
```"
29672,tf.image.crop_and_resize ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 14.04):
- TensorFlow installed from (binary):
- TensorFlow version (1.9):

Hi all, 
I am looking at op crop_and_resize which takes image, boxes, box_index and crop_size as input. My question is why dimension of boxes is (num_boxes by, 4) while image has (batch, height, width, depth). Does it mean the same boxes for every image? And output is also (num_boxes, crop_height, crop_width, depth). Should it be (batch, num_boxes, crop_height, crop_width, depth)? 
Thanks in advance for any help.
"
29668,The documentation has a cat instead of a bridge,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue: https://www.tensorflow.org/tutorials/load_data/tf_records#fetch_the_images

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing): There are two cat images but the second cat image should be replace by the bridge image as the image refers to a bridge.

### Clear description

The second cat image should be changed to the bridge as the url points a bridge but the cat image has been published

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
29666,Build tensorflow c library for mips64.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version: 2.7
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): 7.3.0



**Describe the problem**
I want to build a tensorflow C library for MIPS architecture. 
So in order to do that, I specified the following options before building:
```
export CC=/usr/bin/mips64-linux-gnuabi64-gcc
export CXX=/usr/bin/mips64-linux-gnuabi64-g++
```

Those are cross-compilers for MIPS64.
So when I try to build bazel using:
```
bazel build //tensorflow/tools/lib_package:libtensorflow --spawn_strategy=standalone --verbose_failures
```
I get the following error:
```
ERROR: /root/.cache/bazel/_bazel_root/36c1970dc5e3eff66b396f9517eb3547/external/hwloc/BUILD.bazel:214:1: C++ compilation of rule '@hwloc//:hwloc' failed (Exit 1): mips64-linux-gnuabi64-gcc failed: error executing command
  (cd /root/.cache/bazel/_bazel_root/36c1970dc5e3eff66b396f9517eb3547/execroot/org_tensorflow && \
  exec env - \
    PATH='/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/mnt/c/Users/kprosvir/Downloads/cmder/vendor/conemu-maximus5/ConEmu/wsl:/mnt/c/Users/kprosvir/Downloads/cmder/vendor/conemu-maximus5/ConEmu/Scripts:/mnt/c/Users/kprosvir/Downloads/cmder/vendor/conemu-maximus5:/mnt/c/Users/kprosvir/Downloads/cmder/vendor/conemu-maximus5/ConEmu:/mnt/c/Program Files (x86)/NVIDIA Corporation/PhysX/Common:/mnt/c/Windows/System32:/mnt/c/Windows:/mnt/c/Windows/System32/wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0:/mnt/c/Windows/System32/OpenSSH:/mnt/c/Program Files (x86)/Sennheiser/SoftphoneSDK:/mnt/c/ProgramData/Webex/Webex/Applications:/mnt/c/Users/kprosvir/AppData/Local/Microsoft/WindowsApps:/mnt/c/Users/kprosvir/AppData/Local/Programs/Microsoft VS Code/bin:/mnt/c/Users/kprosvir/AppData/Local/hyper/app-3.0.0/resources/bin:/mnt/c/Users/kprosvir/AppData/Local/Box/Box Edit:/snap/bin:/usr/local/go/bin:/root/go//bin' \
    PWD=/proc/self/cwd \
  /usr/bin/mips64-linux-gnuabi64-gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -MD -MF bazel-out/host/bin/external/hwloc/_objs/hwloc/topology-x86.pic.d '-frandom-seed=bazel-out/host/bin/external/hwloc/_objs/hwloc/topology-x86.pic.o' -fPIC -iquote external/hwloc -iquote bazel-out/host/bin/external/hwloc -isystem external/hwloc/hwloc -isystem bazel-out/host/bin/external/hwloc/hwloc -isystem external/hwloc/include -isystem bazel-out/host/bin/external/hwloc/include -g0 -I. -Ihwloc -Iinclude -Wno-vla '-DHWLOC_DUMPED_HWDATA_DIR=' '-DRUNSTATEDIR=' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/hwloc/hwloc/topology-x86.c -o bazel-out/host/bin/external/hwloc/_objs/hwloc/topology-x86.pic.o)
Execution platform: @bazel_tools//platforms:host_platform
In file included from external/hwloc/hwloc/topology-x86.c:23:0:
external/hwloc/hwloc/topology-x86.c: In function 'cpuid_or_from_dump':
external/hwloc/include/private/cpuid-x86.h:67:3: error: invalid 'asm': invalid use of '%k'
   __asm__(
   ^~~~~~~
Target //tensorflow/tools/lib_package:libtensorflow failed to build
```

So the question is: is there any way to fix it and successfully build it for MIPS64?"
29665,more cuDNN problems following audio_recognition tutorial,"The train.py script ran just fine, so I know my tensorflow-gpu installation is fine, and cuDNN is working.  But the label_wav.py script reports the infamous ""Failed to get convolution algorithm. This is probably because cuDNN failed to initialize...""  During this exception the python process has successfully loaded cudnn64_7.dll and _pywrap_tensorflow_internal.pyd with no problem?  So question is, for v1.13.1 of tensorflow-gpu, on CUDA 10.0, what version of cudnn is needed exactly?  Would be nice if the release notes included the cudnn version required.

**System information**
- stock tensorflow example https://www.tensorflow.org/tutorials/sequences/audio_recognition
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, 1809
- TensorFlow installed from (source or binary): pip install tensorflow-gpu
- TensorFlow version (use command below): v1.13.1-0-g6612da8951      
- Python version: 3.6
- CUDA/cuDNN version: 10.0 and cudnn64_7.dll 
- GPU model and memory: NVIDIA 1080 

**Describe the current behavior**
Running the tutorial step fails with the cuDNN error:
```
python tensorflow/examples/speech_commands/label_wav.py --graph=/tmp/my_frozen_graph.pb --labels=/tmp/speech_commands_train/conv_labels.txt --wav=c:\datasets\speech_commands_v01\audio\left\a5d485dc_nohash_0.wav
```

**Describe the expected behavior**
Should work, especially since _pywrap_tensorflow_internal.pyd already successfully loaded into the python process, and so did cudnn64_7.dll

**Code to reproduce the issue**
See your tutorial on audio recognition.

**Other info / logs**
Attached is the full output of the label_wav.py command, including exception details, and a list of all modules loaded into the python process at the time of the failure.
[output.txt](https://github.com/tensorflow/tensorflow/files/3278584/output.txt)
"
29664,Not all threads are terminated.,"Windows 10 / Python 3.7 / TF 1.13 and TF from sources

I used TF in embedded Python.
After completion of the main program at the termination stage, an error occurs:
```
	ntdll.dll!NtWaitForAlertByThreadId()	Unknown
 	ntdll.dll!RtlSleepConditionVariableSRW()	Unknown
 	KERNELBASE.dll!SleepConditionVariableSRW()	Unknown
 	msvcp140.dll!__crtSleepConditionVariableSRW(_RTL_CONDITION_VARIABLE * pCond, _RTL_SRWLOCK * pLock, unsigned long dwMs, unsigned long flags) Line 659	C++
>	[Inline Frame] msvcp140.dll!Concurrency::details::stl_condition_variable_win7::wait_for(Concurrency::details::stl_critical_section_interface *) Line 216	C++
 	msvcp140.dll!Concurrency::details::stl_condition_variable_win7::wait(Concurrency::details::stl_critical_section_interface * lock) Line 210	C++
 	msvcp140.dll!do_wait(_Cnd_internal_imp_t * cond, _Mtx_internal_imp_t * mtx, const xtime * target) Line 77	C++
 	_pywrap_tensorflow_internal.pyd!Eigen::ThreadPoolTempl<struct tensorflow::thread::EigenEnvironment>::WaitForWork(class Eigen::EventCount::Waiter *,struct tensorflow::thread::EigenEnvironment::Task *)	C++
 	_pywrap_tensorflow_internal.pyd!Eigen::ThreadPoolTempl<struct tensorflow::thread::EigenEnvironment>::WorkerLoop(int)	C++
 	_pywrap_tensorflow_internal.pyd!std::_Func_impl_no_alloc<class <lambda_fe7aa395b13fe170862dcdb4d85eb030>,void>::_Do_call(void)	C++
 	_pywrap_tensorflow_internal.pyd!std::_LaunchPad<class std::unique_ptr<class std::tuple<class std::function<void > >,struct std::default_delete<class std::tuple<class std::function<void > > > > >::_Go(void)	C++
 	_pywrap_tensorflow_internal.pyd!std::_Pad::_Call_func(void *)	C++
 	ucrtbase.dll!thread_start<unsigned int (__cdecl*)(void * __ptr64)>()	Unknown
 	kernel32.dll!BaseThreadInitThunk()	Unknown
 	ntdll.dll!RtlUserThreadStart()	Unknown
```
This is a stack of one of the many threads in the dump. It looks like these threads have no background status.

I can test this theory if you tell me what to fix in the source.
"
29663,tf.keras.models.Model's methods get_weights() and set_weights() should retrieve/return Tensors ,"**System information**
- TensorFlow version (you are using): 1.13
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Right now, get_weights() returns a numpy array, and set_weights expects a numpy array as input. Both functions should in my opinion also work for Tensor objects (and therefore be part of the computational graph).

**Will this change the current api? How?**
Two new methods get_weights_tensor(), set_weights_tensor() could be added to tf.keras.models.Models

**Who will benefit with this feature?**
Everybody who wants to modify weights of layers in a loop style.

**Any Other info.**
"
29662,Updating NCCL from 2.3.5 to 2.4.7 broke the build,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): tensorflow/tensorflow:devel-gpu-py3 docker image
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: master / HEAD / 21f595c4c6a92ade7fa650d004cdb32c7e80ecf5
- Python version: 3.6.7
- Installed using virtualenv? pip? conda?: source
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: 10.0 / 7
- GPU model and memory: 2 P100 16 GB GPUs



**Describe the problem**

bazel build fails with

```
ERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/nccl_archive/BUILD.bazel:69:1: undeclared inclusion(s) in rule '@nccl_archive//:nccl':
this rule is missing dependency declarations for the following files included by 'external/nccl_archive/src/collectives/broadcast.cc':
  'external/nccl_archive/src/collectives/collectives.h'
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
docker pull tensorflow/tensorflow:devel-gpu-py3
docker run -idt --name nccl-failure docker.io/tensorflow/tensorflow:devel-gpu-py3 bash
docker attach nccl-failure

cd $HOME
git clone https://github.com/tensorflow/tensorflow
cd tensorflow/
./configure  [pressed enter for all prompts]
bazel build //tensorflow/tools/pip_package:build_pip_package
```


**Any other info / logs**
Error started after Commit 5b5ada737a7f2c69c51748b0f54636b6849580a5 ""Update NCCL from 2.3.5 to 2.4.7"" was merged. 
"
29661,Bug in exception handling of tf.histogram_fixed_width_bins ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): y
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.0.0-beta0
- Python version: python3 from colab
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
when value range for  `tf.histogram_fixed_width_bins ` is `[0.0, 0.0], it outputs an index outside `nbins`. See the code below.

```
nbins = 5
value_range = [.0, .0]
new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]
indices = tf.histogram_fixed_width_bins(new_values, value_range, nbins=5)
print(indices)

```
Output is 
```
tf.Tensor([          0 -2147483648           4           4           4           4], shape=(6,), dtype=int32)
```

**Describe the expected behavior**
It should show indices as [0,0,4,4,4,4] and throw a warning saying that the range needs to be updated

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
See above

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29659,TPU estimator error with tensorflow 1.13 after adding GRU and bidirectionalrnn,"I am getting the following error. This has occured after adding extra GRU and bidirectional rnn layers to my existing model. Can someone please explain what these mean?
```
INFO:tensorflow:Init TPU system
INFO:tensorflow:Initialized TPU in 2 seconds
INFO:tensorflow:Starting infeed thread controller.
INFO:tensorflow:Starting outfeed thread controller.
INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.
INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.
INFO:tensorflow:Error recorded from infeed: Bad hardware status: 0x1
         [[node input_pipeline_task0/while/InfeedQueue/enqueue/4 (defined at /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1112) ]]

Caused by op u'input_pipeline_task0/while/InfeedQueue/enqueue/4', defined at:
  File ""aoa.py"", line 1437, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""aoa.py"", line 1369, in main
    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2452, in train
    saving_listeners=saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 358, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1124, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1154, in _train_model_default
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2251, in _call_model_fn
    config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1112, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2547, in _model_fn
    input_holders.generate_infeed_enqueue_ops_and_dequeue_fn())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 1167, in generate_infeed_enqueue_ops_and_dequeue_fn
    self._invoke_input_fn_and_record_structure())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 1271, in _invoke_input_fn_and_record_structure
    wrap_fn(device=host_device, op_fn=enqueue_ops_fn))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2945, in _wrap_computation_in_while_loop parallel_iterations=1)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 3556, in while_loop
    return_same_structure)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 3087, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 3022, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2934, in computation
    with ops.control_dependencies(op_fn()):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 894, in enqueue_ops_fn
    tpu_ordinal_function=tpu_ordinal_function_impl)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_feed.py"", line 526, in generate_enqueue_ops
    for (shard, index) in zip(sharded_inputs, xrange(self.number_of_shards))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_feed.py"", line 458, in _generate_enqueue_op
    device_ordinal=tpu_ordinal)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/ops/gen_tpu_ops.py"", line 1314, in infeed_enqueue_tuple
    device_ordinal=device_ordinal, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

UnavailableError (see above for traceback): Bad hardware status: 0x1
         [[node input_pipeline_task0/while/InfeedQueue/enqueue/4 (defined at /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1112) ]]

INFO:tensorflow:Error recorded from training_loop: Combined status information from 9 operations:
Status code: Unimplemented [9x]
  Compilation failure: Convolution is only implemented for TPU for F32 and BF16 element types.
        TPU compilation failed
         [[node TPUReplicateMetadata (defined at /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1112) ]] [1x]
  Compilation failure: Convolution is only implemented for TPU for F32 and BF16 element types.
        TPU compilation failed
         [[node TPUReplicateMetadata (defined at /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1112) ]]
         [[node TPUReplicateMetadata (defined at /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1112) ]] [8x]
(0 successful operations.)

Caused by op u'TPUReplicateMetadata', defined at:
  File ""aoa.py"", line 1437, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""aoa.py"", line 1369, in main
    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2452, in train
    saving_listeners=saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 358, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1124, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1154, in _train_model_default
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2251, in _call_model_fn
    config)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1154, in _train_model_default
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2251, in _call_model_fn
    config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1112, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2558, in _model_fn
    _train_on_tpu_system(ctx, model_fn_wrapper, dequeue_fn))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2893, in _train_on_tpu_system
    device_assignment=ctx.device_assignment)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py"", line 890, in split_compile_and_shard
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py"", line 636, in split_compile_and_replicate
    num_replicas=num_replicas, use_tpu=use_tpu, **metadata_kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/ops/gen_tpu_ops.py"", line 7366, in tpu_replicate_metadata
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()
```"
29658,Error: Linking of rule '@protobuf_archive//:protoc' failed (Exit 1): clang failed: error executing command,"**System information**
- OS Platform and Distribution: Windows 10
- TensorFlow installed from (source or binary): 
- TensorFlow version: 1.12
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 0.23.0
- GCC/Compiler version (if compiling from source): 7.4.0


I was trying to do real-time object detection in android using tensorflow. I already trained the model and have the frozen inference graph and other required data. Then I started following this website (https://www.skcript.com/svr/realtime-object-and-face-detection-in-android-using-tensorflow-object-detection-api/) to deploy it to android. Now I am not able to build a .so(c++ compiled) file from my existing tensorflow model. When I run the command, 

```
bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so 
  --crosstool_top=//external:android/crosstool
  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain
  --cpu=armeabi-v7a
  --cxxopt=-std=c++17
```

I got this error:

```
(tensorflow1) C:\tensorflow1\models\research\object_detection\tensorflow>bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=armeabi-v7a --cxxopt=-std=c++17
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Options provided by the client:
  'build' options: --python_path=C:/ProgramData/Anaconda3/envs/tensorflow1/python.exe
INFO: Reading rc options for 'build' from c:\tensorflow1\models\research\object_detection\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
INFO: Reading rc options for 'build' from c:\tensorflow1\models\research\object_detection\tensorflow\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=C:/ProgramData/Anaconda3/envs/tensorflow1/python.exe --action_env PYTHON_LIB_PATH=C:/ProgramData/Anaconda3/envs/tensorflow1/lib/site-packages --python_path=C:/ProgramData/Anaconda3/envs/tensorflow1/python.exe --config monolithic --copt=-w --host_copt=-w --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --verbose_failures --distinct_host_configuration=false --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:monolithic in file c:\tensorflow1\models\research\object_detection\tensorflow\.bazelrc: --define framework_shared_object=false
DEBUG: Rule 'io_bazel_rules_docker' modified arguments {""shallow_since"": ""1556410077 -0400""}
INFO: Build option --cxxopt has changed, discarding analysis cache.
WARNING: The major revision of the Android NDK referenced by android_ndk_repository rule 'androidndk' is 20. The major revisions supported by Bazel are [10, 11, 12, 13, 14, 15, 16, 17, 18]. Bazel will attempt to treat the NDK as if it was r18. This may cause compilation and linkage problems. Please download a supported NDK version.
WARNING: API level 14 specified by android_ndk_repository 'androidndk' is not available. Using latest known API level 28
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/profiler/internal:profiler_interface.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/profiler/internal:profiler_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/profiler/internal:traceme_recorder.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/profiler/internal:traceme_recorder.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/profiler/lib:BUILD' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/profiler/lib:profiler_session.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/profiler/lib:profiler_session.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/profiler/lib:traceme.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/profiler/lib:traceme.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:attr_builder.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:attr_builder.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:context.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:context.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:copy_to_device_node.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:eager_executor.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:eager_executor.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:eager_operation.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:eager_operation.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:execute.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:execute.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:execute_node.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:kernel_and_device.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:kernel_and_device.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:tensor_handle.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/common_runtime/eager:tensor_handle.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:batch_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_gradients.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions-inl.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_volume_patch.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:padding_fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_base.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_op.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:typed_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:c_api.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:c_api.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:c_api_function.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:c_api_internal.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:checkpoint_reader.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:checkpoint_reader.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:env.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:env.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:kernels.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:kernels.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:ops.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:ops.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:tf_attrtype.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:tf_datatype.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:tf_datatype.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:tf_status.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:tf_status.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:tf_status_helper.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:tf_status_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:tf_status_internal.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:tf_tensor.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c:tf_tensor.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/cc:framework/gradients.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/cc:framework/ops.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/cc:framework/scope.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/cc:framework/scope_internal.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/cc:ops/while_loop.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/cc/saved_model:loader.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/distributed_runtime:server_lib.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c/eager:c_api.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c/eager:c_api.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c/eager:c_api_debug.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c/eager:c_api_internal.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/BUILD:1890:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/c/eager:tape.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: C:/tensorflow1/models/research/object_detection/tensorflow/tensorflow/core/kernels/BUILD:6410:12: in srcs attribute of cc_library rule //tensorflow/core/kernels:android_tensorflow_kernels: please do not import '//tensorflow/c/kernels:bitcast_op.cc' directly. You should either move the file to this package or depend on an appropriate rule there
INFO: Analysed target //tensorflow/contrib/android:libtensorflow_inference.so (0 packages loaded, 10655 targets configured).
INFO: Found 1 target...
ERROR: C:/users/devim/_bazel_devim/ktcla6nj/external/protobuf_archive/BUILD:388:1: Linking of rule '@protobuf_archive//:protoc' failed (Exit 1): clang failed: error executing command
  cd C:/users/devim/_bazel_devim/ktcla6nj/execroot/org_tensorflow
  SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\ProgramData\Anaconda3\envs\tensorflow1;C:\ProgramData\Anaconda3\envs\tensorflow1\Library\mingw-w64\bin;C:\ProgramData\Anaconda3\envs\tensorflow1\Library\usr\bin;C:\ProgramData\Anaconda3\envs\tensorflow1\Library\bin;C:\ProgramData\Anaconda3\envs\tensorflow1\Scripts;C:\ProgramData\Anaconda3\envs\tensorflow1\bin;C:\ProgramData\Anaconda3\condabin;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\MATLAB\R2018a\bin;C:\WINDOWS\System32\OpenSSH\;C:\Tensorflow\models\research\object_detection;C:\Tensorflow\object_detection;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Users\devim\.dnx\bin;C:\Program Files\Microsoft DNX\Dnvm\;C:\Program Files (x86)\Windows Kits\8.1\Windows Performance Toolkit\;C:\Users\devim\AppData\Local\Microsoft\WindowsApps;C:\Users\devim\AppData\Local\GitHubDesktop\bin;c:\msys64\usr\bin;C:\tensorflow1\models;C:\tensorflow1\models\research;C:\tensorflow1\models\research\slim
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/ProgramData/Anaconda3/envs/tensorflow1/python.exe
    SET PYTHON_LIB_PATH=C:/ProgramData/Anaconda3/envs/tensorflow1/lib/site-packages
    SET TF_CONFIGURE_IOS=0
  external/androidndk/ndk/toolchains/llvm/prebuilt/windows-x86_64/bin/clang -o bazel-out/armeabi-v7a-opt/bin/external/protobuf_archive/protoc bazel-out/armeabi-v7a-opt/bin/external/protobuf_archive/_objs/protoc/main.o bazel-out/armeabi-v7a-opt/bin/external/protobuf_archive/libprotoc_lib.a bazel-out/armeabi-v7a-opt/bin/external/protobuf_archive/libprotobuf.a bazel-out/armeabi-v7a-opt/bin/external/protobuf_archive/libprotobuf_lite.a bazel-out/armeabi-v7a-opt/bin/external/zlib_archive/libzlib.a external/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/armeabi-v7a/libandroid_support.a external/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/armeabi-v7a/libc++_static.a external/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/armeabi-v7a/libc++abi.a external/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/armeabi-v7a/libunwind.a -target armv7-none-linux-androideabi -Wl,--fix-cortex-a8 -gcc-toolchain external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/windows-x86_64 -no-canonical-prefixes -Lexternal/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/armeabi-v7a -static-libgcc --sysroot=external/androidndk/ndk/platforms/android-28/arch-arm
Execution platform: @bazel_tools//platforms:host_platform
external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/math.h:834: error: undefined reference to 'ceilf'
external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/math.h:834: error: undefined reference to 'ceilf'
external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/math.h:834: error: undefined reference to 'ceilf'
external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/math.h:834: error: undefined reference to 'ceilf'
external/protobuf_archive/src/google/protobuf/stubs/common.cc:149: error: undefined reference to '__android_log_write'
external/protobuf_archive/src/google/protobuf/stubs/common.cc:157: error: undefined reference to '__android_log_write'
/usr/local/google/buildbot/src/android/ndk-release-r20/external/libcxx/../../external/libunwind_llvm/src/AddressSpace.hpp:481: error: undefined reference to 'dladdr'
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Target //tensorflow/contrib/android:libtensorflow_inference.so failed to build
INFO: Elapsed time: 143.166s, Critical Path: 28.59s
INFO: 297 processes: 297 local.
FAILED: Build did NOT complete successfully

Protobuf version is 3.6.1
```

Please help me. I don't know what is causing this error. Is it because I am doing everything on Windows ??
"
29656,Bug on `gather_nd` with gradient.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): tf2-gpu-beta
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
A simple test code
```python
v = tf.Variable(np.random.uniform(size=[2,2]), dtype=tf.float32)

with tf.GradientTape() as tape:
    l = tf.gather_nd(v, [[1, 1]])
    l = tf.reduce_sum(l)
    
grads = tape.gradient(l, v)
print(grads)
````
gives following error message
```
---------------------------------------------------------------------------
LookupError                               Traceback (most recent call last)
<ipython-input-12-28efd3aa3042> in <module>
      5     l = tf.reduce_sum(l)
      6 
----> 7 grads = tape.gradient(l, v)
      8 print(grads)

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)
   1000         output_gradients=output_gradients,
   1001         sources_raw=flat_sources_raw,
-> 1002         unconnected_gradients=unconnected_gradients)
   1003 
   1004     if not self._persistent:

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)
     74       output_gradients,
     75       sources_raw,
---> 76       compat.as_str(unconnected_gradients.value))

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)
    131   """"""
    132   mock_op = _MockOp(attr_tuple, inputs, outputs, op_name, skip_input_indices)
--> 133   grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access
    134   if grad_fn is None:
    135     return [None] * num_inputs

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/registry.py in lookup(self, name)
     95     else:
     96       raise LookupError(
---> 97           ""%s registry has no entry for: %s"" % (self._name, name))

LookupError: gradient registry has no entry for: ResourceGatherNd
```
**Describe the expected behavior**
the grads should be `[[0, 0], [0, 1]]` but error occurs. 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29654,[TF 2.0 API Docs] tf.lite.OpHint.OpHintArgumentTracker,"URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/lite/OpHint/OpHintArgumentTracker

Description of issue (what needs changing):
The link to the TF 2.0 API Documentation is broken, it does not link to the documentation of the API. So, there is no documentation of TF 2.0 for this function."
29653,[TF 2.0 API Docs] tf.lite.OpHint,"## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/lite/OpHint

## Description of issue (what needs changing):
The link to the TF 2.0 API Documentation  is broken, it does not link to the documentation of the API. So, there is no documentation of TF 2.0 for this function.
"
29652,[TF 2.0 API Docs] tf.data.experimental.Counter,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/Counter

## Description of issue (what needs changing):

### Clear description
The description is not clear, not provided as in the DOCS

### Raises listed and defined
Errors are not defined at all

### Request visuals, if applicable
No visuals are included

### Submit a pull request?
Yes
"
29651,[TF 2.0 API Docs] tf.io.write_file,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/write_file

## Description of issue (what needs changing):

### Clear description
The description does not recommend at all in any way when and when not to use this symbol.

### Correct links

Yes

### Parameters defined

Yes

### Returns defined

Yes

### Raises listed and defined
The returned objects are not well defined and therefore not correct, complete and appropriately formatted

### Usage example

Yes

### Request visuals, if applicable

No single visual included in the symbolâ€™s description. In some instances it will definitely clarify the content being presented.

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
29650,[TF 2.0 API Docs] tf.data.experimental,"## Existing URLs containing the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental

## Description of the issue:
Correct Links: All links are correct and well defined

## Clear Description

The description is not clear about when to use this symbol 

## Usage Example
No usage example is provided.

## Parameters Defined
Parameters are poorly defined, and not formatted appropriately.

## Returns Defined
Returns are not defined.

## Raises Listed and Defined
Errors are not defined.

## Visuals, if Applicable
No visuals are included."
29649,[TF 2.0 API Docs] tf.io.FixedLenSequenceFeature,"## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/FixedLenSequenceFeature

## Description of issue (what needs changing):

### Clear description
The description doesnâ€™t give recommendation on when to use and not use the symbol

### Parameters defined
No parameters defined.

### Returns defined
No returns defined

### Raises listed and defined

Are the errors defined? For example,
No errors defined 

### Usage example
No usage example 

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?
Yes"
29648,[TF 2.0 API Docs]  tf.io.read_file,"## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/read_file

## Description of issue (what needs changing):

### Clear description
The description does not give recommendations of when and when not to use this symbol.

### Correct links
The link to the source code file (python/ops/gen_io_ops.py) is dormant.

### Raises listed and defined
Errors are not defined.

### Usage example
No usage example provided.

### Submit a pull request?
Yes"
29647,[TF 2.0 API Docs] tf.io.write_file,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
29646,[TF 2.0 API Docs] tf.io.FixedLenFeature,"## Existing Url with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/FixedLenFeature

## Description of issue (what needs changing):
Clear description with parameters, returns and usage example
### Clear description

### Correct links
The link to the python script where the function is define is activeâ€¨https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/FixedLenFeature

### Parameters defined
No parameters defined

### Returns defined
No returns defined

### Raises listed and defined
The raises is defined further in this link
https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/ops/parsing_ops.py

###Are the errors defined? For example,
Errors are not defined

### Usage example
Usage example provided in this link https://www.tensorflow.org/beta/tutorials/load_data/tf_records"
29644,Default build options creating larger(~3x) binary in linux ,"**System information**
- OS Platform and Distribution : ubuntu 16.04.10
- TensorFlow installed from (source or binary): Not Installing. Building Binary
- TensorFlow version: 1.13.1 and 1.14-rc0
- Python version: 3.5
- Bazel version (if compiling from source): 0.25.2
- GCC/Compiler version (if compiling from source): 4.9
- CUDA/cuDNN version: NA. Not building with CUDA
- GPU model and memory: NA

**Describe the problem**

The size of TF binary we are building has increased from 54.3 MB(in TF 1.8) to 148.1 MB (int TF 1.14-rc0 and 1.13.1). 

We have used all default settings in configure.py in 1.8. Building 1.14-rc0 with defaults is anyways giving a larger binary. Additionally we tried to disable many optional dependencies (like aws,kafka etc), but still the size was around 148 MB. 

Is there any new optional dependency added by default after 1.8 ? 

**Steps Followed**

We are building with default settings (except we say NO to XLA JIT support in 1.14.1-rc0 and 1.13.1). We are using following command to build : 

1) bazel build --config=opt //tensorflow:tensorflow
2) bazel build --config=opt --config=noaws --config=nogcp --config=nohdfs --config=noignite --config=nokafka --config=nonccl  //tensorflow:tensorflow


"
29643,SetShapeFn gets nullptr for custom operator leading to crash,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.0rc1
- Python version: 2.7
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): gcc 7.4.0
- CUDA/cuDNN version: NR
- GPU model and memory: NR

**Describe the current behavior**
`SetShapeFn` doesn't work when called for `REGISTER_OP` for the custom operators. Whenever it is called by TF is gets `nullptr` instead valid value of the `InferenceContext` argument.

**Describe the expected behavior**
`SetShapeFn` should get meaningful ptr.

**Code to reproduce the issue**
It doesn't work with https://www.tensorflow.org/guide/extend/op. [ Repro attached](https://github.com/tensorflow/tensorflow/files/3276625/tf_crash_repro.zip), just call `run.sh`.

**Other info / logs**
NA"
29642,Customized loss can't get the shape of input data (BUG?),"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-beta
- Python version:
- Bazel version (if compiling from source): 3.7.3
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda 10.0 with cudnn 7.6
- GPU model and memory: 12GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I write a custom loss function (dice coefficient) with following code:
``` python
def dice_coef(y_true, y_pred, smooth=1e-7):
    _, W, H, D, C = y_pred.get_shape()

    y_pred = tf.reshape(y_pred, shape=[-1, W * H * D * C])
    y_true = tf.reshape(y_true, shape=[-1, W * H * D * C])

    y_pred = tf.cast(y_pred, dtype=tf.float32)
    y_true = tf.cast(y_true, dtype=tf.float32)

    dice_numerator = 2.0 * tf.reduce_sum(y_true * y_pred, axis=1) + smooth
    dice_denominator = tf.reduce_sum(y_pred + y_true, axis=1) + smooth

    dice_coefficient = dice_numerator / dice_denominator
    dice_coefficient = tf.reduce_mean(dice_coefficient)
    return dice_coefficient
```
when i run code like this:
``` python
mirrored_strategy = tf.distribute.MirroredStrategy()
    with mirrored_strategy.scope():
        model = unet3d(input_shape=input_shape, num_class=num_class, activation='sigmoid')
        model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),
                      loss=bce_dice,
                      metrics=[
                          tf.keras.metrics.BinaryAccuracy(),
                          tf.keras.metrics.BinaryCrossentropy(),
                      ])
```
i got the following error 
``` python
Traceback (most recent call last):
  File ""/tmp/pycharm_project_317/opt/train.py"", line 84, in <module>
    epochs=50)
  File ""/tmp/pycharm_project_317/opt/train.py"", line 21, in train
    callbacks=callbacks)
  File ""/home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 643, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_distributed.py"", line 681, in fit
    steps_name='steps_per_epoch')
  File ""/home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 294, in model_iteration
    batch_outs = f(actual_inputs)
  File ""/home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py"", line 813, in execution_function
    return [out.numpy() for out in distributed_function(input_fn)]
  File ""/home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 416, in __call__
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""/home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 359, in _initialize
    *args, **kwds))
  File ""/home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1360, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1648, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1541, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 716, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 309, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 706, in wrapper
    raise e.ag_error_metadata.to_exception(type(e))
TypeError: in converted code:

    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py:804 distributed_function  *
        outputs = strategy.experimental_run_v2(
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:708 experimental_run_v2
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1710 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py:708 _call_for_each_replica
        fn, args, kwargs)
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py:195 _call_for_each_replica
        coord.join(threads)
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/training/coordinator.py:389 join
        six.reraise(*self._exc_info_to_raise)
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/six.py:693 reraise
        raise value
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception
        yield
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py:926 run
        self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:908 train_on_batch
        output_loss_metrics=self._output_loss_metrics)
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_eager.py:307 train_on_batch
        output_loss_metrics=output_loss_metrics))
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_eager.py:237 _process_single_batch
        training=training))
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_eager.py:152 _model_loss
        per_sample_losses = loss_fn.call(targets[i], outs[i])
    /home/tanjl/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:215 call
        return self.fn(y_true, y_pred, **self._fn_kwargs)
    /tmp/pycharm_project_317/app/losses/binary.py:26 bce_dice
        return -dice_coef(y_true, y_pred, smooth) + \
    /tmp/pycharm_project_317/app/losses/binary.py:7 dice_coef
        y_pred = tf.reshape(y_pred, shape=[-1, W * H * D * C])

    TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'

bash: è¡Œ 1:  7597 æ®µé”™è¯¯               (æ ¸å¿ƒå·²è½¬å‚¨) env ""PYCHARM_HOSTED""=""1"" ""PYTHONUNBUFFERED""=""1"" ""PYTHONIOENCODING""=""UTF-8"" ""PYCHARM_MATPLOTLIB_PORT""=""52949"" ""JETBRAINS_REMOTE_RUN""=""1"" ""PYTHONPATH""=""/home/tanjl/.pycharm_helpers/pycharm_matplotlib_backend:/tmp/pycharm_project_317"" /home/tanjl/anaconda3/envs/tensorflow2/bin/python3.7 -u /tmp/pycharm_project_317/opt/train.py
```
**Describe the expected behavior**
it have no error when i run code with tf-2.0.0-alpha but the error happend with beta version tensorflow 
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
it can't get the input shape in loss function, is that right? and i wish u could help me, thanks
"
29640,[XLA]make xlaop optimization algorithm configurable,"As far as my understanding to XLA,  a XlaCompile op which is responsible for compiling tfops into one executable op will be inserted into the graph.  but nowadays there is no horovod xlaop support in the current version, which means horovodallreduce is excluded from the _XlaRun op just like the following pic shows.
<img width=""1389"" alt=""Screen Shot 5779-09-05 at 14 41 00"" src=""https://user-images.githubusercontent.com/50541066/59266222-bbba7000-8c79-11e9-98c7-3759364cb5e4.png"">

as i see it, in distributed environment,  the transmission of parameters over network  cost the most of time  during the calculation of allreduce op.  if we can parallelize the horovod ops and XLaRun, which means  transforming the timeline into the following,  a better perf can be obtained. 

![image](https://user-images.githubusercontent.com/50541066/59268095-911ee600-8c7e-11e9-9c6b-64b0635367f7.png)

So i'd like to know if there is a way to produce a separated _XlaRun, a horovod related part and a horovod non-related part,  in order to parallelize the HorovodAllreduce op and the _XlaRun. Besides, will it be possible to provide a synchronization interface  in XLA ? 

Thanks.

**System information**
- TensorFlow version (you are using):
1.14
- Are you willing to contribute it (Yes/No):
Yes


**Describe the feature and the current behavior/state.**
all xlaop are compiled together 
**Will this change the current api? How?**
No
**Who will benefit with this feature?**
Any existing code using Horovod ans xla at the same time
**Any Other info.**
"
29639,quantized  tflite model result is different with CPU and NNAPI on my Android P devices,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:Reno710
- TensorFlow installed from (source or binary):conda  install
- TensorFlow version (use command below):tf1.13.1
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
custom quantized model run on android P with CPU get the right result.when I set use NNAPI  it get wrong result. So I had done some research :when I use tensorflow-lite-1.13.1.aar ,the two model get the same result.because my model have to use Op resizebiliear,but NNAPI before dose not include the Op ,I change it to tensorflow-nightly-0.0.0.aar,so I got the wrong result.Besides,I have build a aar with tensorflow master code,the result is still wrong.I have check the first Conv,and print the result.I found the result is still different.I don't know why.
**Describe the expected behavior**
got the same result with quantized model between CPU model  and NNAPI
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
![CLz9KG2i](https://user-images.githubusercontent.com/30410113/59268453-46519e00-8c7f-11e9-9b36-adc9b0173baa.png)
here is my test model,just to verify the  output data


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29636,Can't call tf.contrib.layers.group_norm() due to supplying a DeferredTensor instead of (Eager)Tensor during eager execution.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.12
- Python version: 3.5
- CUDA/cuDNN version: V8.0.61
- GPU model and memory: Tesla P100-PCIE, 12193MiB

**Describe the current behavior**
I run the following snippet of code in eager execution:

```
tensor = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(tensor)
tensor = tf.contrib.layers.group_norm(tensor)
```

However, the call to `tf.contrib.layers.group_norm(tensor)` gives me the following error:

```
ValueError: Attempt to convert a value (<DeferredTensor 'None' shape=(?, 16, 16, 128) dtype=float32>) with an unsupported type (<class 'tensorflow.python.keras.engine.base_layer.DeferredTensor'>) to a Tensor.
```


Also, I am not able to find any documentation on `DeferredTensor`s whatsoever. Can anyone link me to some?

**Describe the expected behavior**
A possible conversion from the `DeferredTensor` to a `Tensor` or `EagerTensor`, or alternatively to perform group normalization in another way.

**Code to reproduce the issue**
```
from __future__ import absolute_import, division, print_function
import tensorflow as tf
import numpy as np
import sys
import os
import cv2
import json
from sklearn.metrics import confusion_matrix

ORIGINAL_WIDTH = 4608
ORIGINAL_HEIGHT = 4608
SCALED_WIDTH = 512
SCALED_HEIGHT = 512

tf.enable_eager_execution()

def identity_block(input_tensor, kernel_size, filters, stage, block):
    filters1, filters2, filters3 = filters
    conv_name_base = 'res' + str(stage) + block + '_branch'
    bn_name_base = 'bn' + str(stage) + block + '_branch'

    x = tf.keras.layers.Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)
    x = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(x)
    x = tf.keras.layers.Activation('relu')(x)

    x = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)
    x = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(x)
    x = tf.keras.layers.Activation('relu')(x)

    x = tf.keras.layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)
    x = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2c')(x)

    x = tf.keras.layers.add([x, input_tensor])
    x = tf.keras.layers.Activation('relu')(x)
    return x

def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2,2)):

    filters1, filters2, filters3 = filters
    conv_name_base = 'res' + str(stage) + block + '_branch'
    bn_name_base = 'bn' + str(stage) + block + '_branch'
    x = tf.keras.layers.Conv2D(filters1, (1, 1), strides=strides, name=conv_name_base + '2a')(input_tensor)
    x = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(x)
    x = tf.keras.layers.Activation('relu')(x)

    x = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)
    x = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(x)
    x = tf.keras.layers.Activation('relu')(x)

    x = tf.keras.layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)
    x = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2c')(x)

    shortcut = tf.keras.layers.Conv2D(filters3, (1, 1), strides=strides, name=conv_name_base + '1')(input_tensor)
    shortcut = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base + '1')(shortcut)

    x = tf.keras.layers.add([x, shortcut])
    x = tf.keras.layers.Activation('relu')(x)
    return x

def get_fpn(num_channels=3):

    input = tf.keras.Input(shape=(SCALED_HEIGHT, SCALED_WIDTH, num_channels))
    x = tf.keras.layers.Conv2D(64, (7, 7), strides=(2, 2), padding='same', name='conv1')(input)
    x = tf.keras.layers.BatchNormalization(axis=3, name='bn_conv1')(x)
    x = tf.keras.layers.Activation('relu')(x)
    x = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)
    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))
    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')
    bottomup_xl = identity_block(x, 3, [64, 64, 256], stage=2, block='c') # (?, 127, 127, 256)

    x = conv_block(bottomup_xl, 3, [128, 128, 512], stage=3, block='a')
    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')
    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')
    bottomup_l = identity_block(x, 3, [128, 128, 512], stage=3, block='d') # (?, 64, 64, 512)

    x = conv_block(bottomup_l, 3, [256, 256, 1024], stage=4, block='a')
    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')
    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')
    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')
    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')
    bottomup_m = identity_block(x, 3, [256, 256, 1024], stage=4, block='f') # (?, 32, 32, 1024)

    x = conv_block(bottomup_m, 3, [512, 512, 2048], stage=5, block='a')
    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')
    bottomup_s = identity_block(x, 3, [512, 512, 2048], stage=5, block='c') # (?, 16, 16, 2048)

    topdown_s = tf.keras.layers.Conv2D(1024, (1, 1), padding='same')(bottomup_s)
    x = tf.keras.layers.UpSampling2D(size=(2,2))(topdown_s)
    #x = tf.image.resize_images(topdown_s, (topdown_s.shape[1] * 2, topdown_s.shape[2] * 2), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    #x = tf.convert_to_tensor(cv2.resize(np.array(topdown_s), dsize=None, fx=2, fy=2, interpolation=cv2.INTER_NEAREST))
    topdown_m = tf.keras.layers.add([x, tf.keras.layers.Conv2D(1024, (1, 1), padding='same')(bottomup_m)])

    x = tf.keras.layers.UpSampling2D(size=(2, 2))(topdown_m)
    topdown_l = tf.keras.layers.add([x, tf.keras.layers.Conv2D(1024, (1, 1), padding='same')(bottomup_l)])
    x = tf.keras.layers.UpSampling2D(size=(2, 2))(topdown_l)
    topdown_xl = tf.keras.layers.add([x, tf.keras.layers.Conv2D(1024, (1, 1), padding='same')(bottomup_xl)])

    pyramid_s = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(topdown_s)
    pyramid_m = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(topdown_m)
    pyramid_l = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(topdown_l)
    pyramid_xl = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(topdown_xl)

    # extra_channels = num_channels - 3
    # paddings = tf.constant([[0, 0, ], [0, 0], [0, extra_channels], [0, 0]])
    # weights[0] = tf.pad(weights[0], paddings, mode='REFLECT')
    # model.set_weights(weights[:36])
    return tf.keras.Model(input, [pyramid_s, pyramid_m, pyramid_l, pyramid_xl])

def get_semantic_fpn(num_channels=3):
    def upsample(tensor, repetitions):
        print(tf.executing_eagerly())
        if repetitions == 0:
            tensor = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(tensor)
            tensor = tf.contrib.layers.group_norm(tensor) # Problematic line
            return tf.keras.layers.ReLU()(tensor)
        for _ in range(repetitions):
            tensor = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(tensor)
            tensor = tf.contrib.layers.group_norm(tensor) # Problematic line
            tensor = tf.keras.layers.ReLU()(tensor)
            tensor = tf.image.resize_images(tensor, (tensor.shape[1] * 2, tensor.shape[2] * 2))
        return tensor

    input = tf.keras.Input(shape=(SCALED_HEIGHT, SCALED_WIDTH, num_channels))
    fpn = get_fpn(num_channels)
    pyramid_s, pyramid_m, pyramid_l, pyramid_xl = fpn(input)
    from_s = upsample(pyramid_s, 3)
    from_m = upsample(pyramid_m, 2)
    from_l = upsample(pyramid_l, 1)
    from_xl = upsample(pyramid_xl, 0)

    x = tf.keras.layers.add([from_s, from_m, from_l, from_xl])
    x = tf.keras.layers.Conv2D(NUM_LABELS, (1, 1), padding='same')(x)
    output = tf.image.resize_images(x, (x.shape[1] * 4, x.shape[2] * 4))
    return tf.keras.Model(input, output)

model = get_semantic_fpn()
```"
29635,Allow growth seems to take more VRAM than needed,"
**System information**
- Have I written custom code: yes using C++ API
- OS Platform and Distribution: Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: I don't know
- TensorFlow installed from: source
- TensorFlow version: 1.12
- Python version: not used
- Bazel version (if compiling from source): I don't know
- GCC/Compiler version (if compiling from source): g++ 5.4.0
- CUDA/cuDNN version: 10.1/libcudnn.so.7.5
- GPU model and memory: GeForce GTX 1080 Ti 11175MiB

**Describe the current behavior**

It seems setting `allow_growth` to true takes much more VRAM than needed. A simple classification inception_v3 network reports on nvidia-smi using 3705MiB whereas if I set a `per_process_gpu_memory_fraction` to for example 0.02, there is not performance impact when serving and it takes only 600MiB of VRAM. Going below 0.015 make it crash (as it obviously don't have enough VRAM to run).

**Describe the expected behavior**

Since I have many networks served on the same GPU, I would like them to take as low VRAM as possible. Each of them being in a separated process (easier to schedule). 
Finding the good `per_process_gpu_memory_fraction` for each neural network is a bit complicated since I have to grope.

**Code to reproduce the issue**

I think it is reproducable with any python code that load and serve a neural network. I unfortunately only have custom code for now. If you don't manage to reproduce, I will give a sample code.

"
29634,Realime webcam error,"(tfpose) C:\Users\Prabhavi\Desktop\ml\tf-pose-estimation>python run_webcam.py --model=mobilenet_thin --resize=432x368 --camera=0
Traceback (most recent call last):
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""run_webcam.py"", line 8, in <module>
    from tf_pose.estimator import TfPoseEstimator
  File ""C:\Users\Prabhavi\Desktop\ml\tf-pose-estimation\tf_pose\__init__.py"", line 5, in <module>
    from tf_pose.runner import infer, Estimator, get_estimator
  File ""C:\Users\Prabhavi\Desktop\ml\tf-pose-estimation\tf_pose\runner.py"", line 7, in <module>
    from tf_pose import common
  File ""C:\Users\Prabhavi\Desktop\ml\tf-pose-estimation\tf_pose\common.py"", line 3, in <module>
    import tensorflow as tf
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Prabhavi\Anaconda3\envs\tfpose\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found."
29632,TF2.0 beta on RTX 2080 throws Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0.0-beta0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: built whl and installed with virtualenv
- Bazel version (if compiling from source): 0.25.0
- GCC/Compiler version (if compiling from source): 7.3.0
- CUDA/cuDNN version: 10.0 / 7.5.0
- GPU model and memory: RTX 2080, driver 418.40.04 



**Describe the problem**
I am trying to build the tf2.0 beta on my rtx system, and i can build successfully but i cannot run anything on i install the whl. i keep hitting 
```
Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
```
I also tried using the prebuilt binary it still throws the same error. Strangely 1.13.1 works prefectly only if i build it from source.

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
```
Python 3.6.7 (default, Oct 22 2018, 11:32:17) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.5.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import tensorflow as tf                                                                                                                                                                             

In [2]: model = tf.keras.applications.ResNet50()                                                                                                                                                            
2019-06-11 14:12:10.599679: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-06-11 14:12:10.654528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-11 14:12:10.655435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.83
pciBusID: 0000:02:00.0
2019-06-11 14:12:10.655756: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-11 14:12:10.656708: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-11 14:12:10.672933: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-11 14:12:10.673320: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-11 14:12:10.674796: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-11 14:12:10.675938: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-11 14:12:10.679002: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-11 14:12:10.679234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-11 14:12:10.680150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-11 14:12:10.680897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-06-11 14:12:10.681515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-11 14:12:10.682282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.83
pciBusID: 0000:02:00.0
2019-06-11 14:12:10.682345: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-11 14:12:10.682365: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-11 14:12:10.682391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-11 14:12:10.682412: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-11 14:12:10.682432: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-11 14:12:10.682451: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-11 14:12:10.682470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-11 14:12:10.682548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-11 14:12:10.683363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-11 14:12:10.684127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-06-11 14:12:10.722429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-11 14:12:10.842536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-11 14:12:10.842661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-06-11 14:12:10.842716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-06-11 14:12:10.867592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-11 14:12:10.868473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-11 14:12:10.869242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-11 14:12:10.869958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7248 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:02:00.0, compute capability: 7.5)

In [3]: model(tf.random.normal([5, 224, 224, 3]))                                                                                                                                                           
2019-06-11 14:13:21.027798: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-11 14:13:22.315487: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-06-11 14:13:22.318659: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR

````"
29631,fitting the model gives training data empty,"in model.fit there is an error
model.fit( train_dataset, 
    steps_per_epoch=len(image_list),
    epochs=1, 
    validation_data=val_dataset, 
    validation_steps=len(val_image_list), 
    callbacks=callbacks)


  File ""C:\Users\Student\Anaconda2\lib\site-packages\tensorflow\python\keras\engine\training_utils.py"", line 113, in finalize
    raise ValueError('Empty training data.')

ValueError: Empty training data.

using tensorflow 2.0 for this and running on i7 CPU

![1](https://user-images.githubusercontent.com/50418503/59259851-21960000-8c58-11e9-8576-95e26b7b0ead.JPG)

"
29630,TF 2.0 Beta CPU version not working,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (use command below): beta
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: I'm using CPU version
- GPU model and memory: not relevant

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
It throws this error
2019-06-11 17:55:04.982068: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
WARNING: Logging before flag parsing goes to stderr.
W0611 17:55:05.086806 23064 ag_logging.py:145] Entity <bound method FE.call of <__main__.FE object at 0x0000027010557DA0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FE.call of <__main__.FE object at 0x0000027010557DA0>>: ValueError: Unable to locate the source code of <bound method FE.call of <__main__.FE object at 0x0000027010557DA0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
W0611 17:55:05.133668 23064 ag_logging.py:145] Entity <bound method LP.call of <__main__.LP object at 0x00000270184E6CF8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LP.call of <__main__.LP object at 0x00000270184E6CF8>>: ValueError: Unable to locate the source code of <bound method LP.call of <__main__.LP object at 0x00000270184E6CF8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
W0611 17:55:05.149287 23064 ag_logging.py:145] Entity <bound method DC.call of <__main__.DC object at 0x00000270184E64E0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DC.call of <__main__.DC object at 0x00000270184E64E0>>: ValueError: Unable to locate the source code of <bound method DC.call of <__main__.DC object at 0x00000270184E64E0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
W0611 17:55:05.149287 23064 ag_logging.py:145] Entity <bound method GRL.call of <__main__.GRL object at 0x00000270184E6128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRL.call of <__main__.GRL object at 0x00000270184E6128>>: ValueError: Unable to locate the source code of <bound method GRL.call of <__main__.GRL object at 0x00000270184E6128>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code

**Describe the expected behavior**
It should work! it works in GPU version seemlessly

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
The code is massive and I cannot tell where the error is. Any way, it works well in GPU version of TF.
PS: when in CPU version, I'm not even using tf.function decorator. But it seems from the error that it is related to graphs.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29629,`Check failed` error in Keras distributed (MultiWorkerMirroredStrategy) training.,"Hello, in attempt to train simple keras model in distributed environment with TF 2.0 MultiWorkerMirroredStrategy I have encoutered an error `Check failed: size >= 0 ... Aborted` that appears only when the number of workers in TF_CONFIG is greater than 1. 

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
True

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
CentOS Linux release 7.4.1708 (Core)

- TensorFlow installed from (source or binary):
pip install

- TensorFlow version (use command below):
v1.12.1-3259-gf59745a381 2.0.0-beta0

- Python version:
3.6.7

**Describe the current behavior**

When run with more then one worker it fails:

```
Train on 2781 steps
Epoch 1/100
2019-06-11 10:54:04.220333: F tensorflow/core/framework/tensor_shape.cc:324] Check failed: size >= 0 (-19 vs. 0)
Aborted
```

The negative value in check seems to depend only on `drop_remainder` argument to `padded_batch` method and not on: `num_inputs`, `batch_size`, length of dataset, `epochs`. It equals to `-19` when `drop_remainder=False` and to `-16` when `drop_remainder=True`.

```
Check failed: size >= 0 (-19 vs. 0) <-> drop_remainder=False
Check failed: size >= 0 (-16 vs. 0) <-> drop_remainder=True
```

**Describe the expected behavior**

Should work

**Code to reproduce the issue**
Save this script as `tensorflow_issues_29629.py` and run on each node with fully qualified domain names `master` and `slave1`:
```
python tensorflow_issues_29629.py `hostname -f` 
```
or set different index of worker in TF_CONFIG in `tensorflow_issues_29629.py` on different nodes.

```python
import tensorflow as tf
import tensorflow.keras as keras
import types
import numpy as np
import json
import os
import sys

hostname_idx = {
    ""master"": 0,
    ""slave1"": 1
}
worker_index = hostname_idx[sys.argv[1]]


os.environ['TF_XLA_FLAGS'] = '--tf_xla_cpu_global_jit'
os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': [""master:1531"",
                   ""slave1:1531""
                  ]
    },
    'task': {'type': 'worker', 'index': worker_index}
})

mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
options_distribute = tf.data.Options()
options_distribute.experimental_distribute.auto_shard = True

def sliding_window(values, window_size=2, stride=1, start=0):
    i = start
    r = None
    if i+window_size <= len(values):
        yield values[i:i+window_size]
    while True:
        i = i+stride
        if (i+window_size-1) < len(values):
            yield values[i:i+window_size]
        else:
            break
            
num_timesteps = 100
num_timesteps_to_predict = 1000
num_signals = 2
num_inputs = num_signals*num_timesteps_to_predict
batch_size = 2**5
epochs = 100

dataset = types.SimpleNamespace()
dataset.xmin = 0
dataset.xmax = 50
dataset.size = 100000
dataset.split_train_ratio = 0.9

dataset.x = np.linspace(dataset.xmin, dataset.xmax, dataset.size)
dataset.y = np.array([np.sin(dataset.x*(i+1)) for i in range(num_signals)])
dataset.input = np.array([list(sliding_window(y,
                                    window_size=num_timesteps,
                                    stride=1,
                                    start=0))[:-num_timesteps_to_predict] for y in dataset.y])
dataset.target = np.array([list(sliding_window(y,
                                     window_size=num_timesteps_to_predict,
                                     stride=1,
                                     start=num_timesteps)) for y in dataset.y])

dataset.input = np.transpose(dataset.input, axes=[1,2,0])
dataset.target = np.transpose(dataset.target, axes=[1,2,0])

dataset.target = dataset.target.reshape((dataset.target.shape[0], dataset.target.shape[1]*dataset.target.shape[2]))

split_point = int(len(dataset.input)*dataset.split_train_ratio)
split_point = (split_point//batch_size)*batch_size
dataset.train_input = dataset.input[:split_point]
dataset.train_target = dataset.target[:split_point]


input_dataset = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(dataset.train_input), 
                                     tf.data.Dataset.from_tensor_slices(dataset.train_target)))
input_dataset = input_dataset.padded_batch(batch_size, 
                                           ((num_timesteps, num_signals), 
                                            (num_timesteps_to_predict*num_signals)),
                                           drop_remainder=False)
# Check failed: size >= 0 (-19 vs. 0) <-> drop_remainder=False
# Check failed: size >= 0 (-16 vs. 0) <-> drop_remainder=True
# num_inputs, batch_size, length of dataset, epochs do not change this value

input_dataset = input_dataset.shuffle(dataset.size)
input_dataset = input_dataset.with_options(options_distribute)

print('Train dataset shape', dataset.train_input.shape)
print('MultiWorkerMirroredStrategy: ', mirrored_strategy)


with mirrored_strategy.scope():
    inputs = keras.Input(shape=(num_timesteps, num_signals), name='input')
    lstm = keras.layers.LSTM(num_inputs)(inputs)
    model = keras.Model(inputs=inputs, outputs=lstm)
    optimizer = keras.optimizers.RMSprop(lr=1e-3)
    model.compile(loss=keras.losses.mean_squared_error,
                  optimizer=optimizer,
                  metrics=['accuracy'])
    
model.fit(input_dataset, epochs=epochs)
model.save('past_100_pred_1000_model.h5') 
```

**Other info / logs**

One guess is that protobuf or python->cpp marshalling is broken.. Python, tensorflow, protobuf version are the same across machines.

```
libprotobuf               3.8.0                h8b12597_0    conda-forge
protobuf                  3.8.0            py36he1b5a44_0    conda-forge
```

"
29628,TF 2.0 tf.image.non_max_suppression always output the length of max_output_size,"tensorflow version: tensorflow-2.0.0-beta0

```
import tensorflow as tf

print(tf.__version__)

bbox = [[0,0,0,0],[0,0,0,0],[0.71619,0.3128575,0.7752377,0.37428612],[0.71619,0.3128575,0.7752377,0.37428612]]
scores = [2.4719129,1.701416,0.89775455,4.354542]

selected_index = tf.image.non_max_suppression(bbox,scores,3000,0.99)

print(selected_index)
```

and the output is
```
2.0.0-beta0
tf.Tensor([3 0 0 ... 0 0 0], shape=(3000,), dtype=int32)
```

I also tried `tf.image.non_max_suppression_padded` function with parameter `pad_to_max_output_size=False` and `pad_to_max_output_size=True`, the output shape is the same"
29627,iPhone 6 crash: EXC_BAD_INSTRUCTION in v1.14.0-rc1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Compiled on MacOS 10.14.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
[iPhone6](https://en.wikipedia.org/wiki/IPhone_6), iOS 11.4
- TensorFlow installed from (source or binary):
Source
iOS tensorflow lib built with the script: `tensorflow/contrib/makefile/build_all_ios.sh`
- TensorFlow version (use command below):
v1.14.0-rc1
- GCC/Compiler version (if compiling from source):
XCode 10.2.1
```
gcc --version
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/c++/4.2.1
Apple LLVM version 10.0.1 (clang-1001.0.46.4)
Target: x86_64-apple-darwin18.6.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
```

**Describe the current behavior**
I have written an iOS app that uses TensorFlow from C++.
The app crashes on Session::Run() with `Thread 6: EXC_BAD_INSTRUCTION (code=1, subcode=0xd53be053)`
XCode breaks and highlights an assembler line 329: ->  ```0x1014e7f30 <+1308>: mrs    x19, CNTVCT_EL0```

**Describe the expected behavior**
No crash. The same app built with TensorFlow v1.13.1 runs successfully.

**Other info / logs**
This appears to have been introduced with commit [9a486811ca07b5ca3f60f6fd96e69fc1df889818](https://github.com/tensorflow/tensorflow/commit/9a486811ca07b5ca3f60f6fd96e69fc1df889818) which was not in 1.13.1 but is in 1.14.0-rc0.
It introduces the struct `KernelTimer`, which calls `profile_utils::CpuUtils::GetCurrentClockCycle()` in [cpu_utils.h](https://github.com/tensorflow/tensorflow/blob/v1.14.0-rc1/tensorflow/core/platform/profile_utils/cpu_utils.h#L58) on initialization. On aarch64, this calls `asm volatile(""mrs %0, cntvct_el0"" : ""=r""(virtual_timer_value));` which is the line XCode breaks on.
If I [exit that function with an early return](https://github.com/travbid/tensorflow/commit/8b6b0d2ddb7fb3262c41f471e5f299b9ee377560#diff-5f82d595cba7425ac17d71e7615343d9) then the session runs without crashing.
After consulting the [armv8 reference guide](https://developer.arm.com/docs/ddi0487/latest/arm-architecture-reference-manual-armv8-for-armv8-a-architecture-profile) the instruction in question looks right to me and can be found in other code samples with a google search.

Unfortunately, I don't have any other iOS devices to test on currently.

I know little about assembler or ARM architectures and have reached the limits of my debugging ability here. Could this be a hardware bug in iPhone 6? Any insight appreciated.

"
29626,Tensor flow lite stable release for Linux on ARM 64 bit,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

**Describe the problem**
Have we have any version(or tag) for tensor flow lite which can build successfully (or stable release) for ARM64 ?
 I have try many tag version, but sometimes script build was deleted, what's happend?
If it is not stable now, please tell me and I think I will try it later.

Some bug Im facing now:
https://www.gitmemory.com/issue/tensorflow/tensorflow/28863/496775232
https://github.com/tensorflow/tensorflow/issues/25120"
29625,Switching default model with tf.keras,"## URL(s) with the issue:

I don't think it's documented so no link available.

## Description of issue (what needs changing):

There doesn't seem to be any documentation on how to change the default model for the `tf.keras.backend.get_session`. I need to do this to properly save my model (I think).

### Clear description

I have an RNN that I'm training in batches with TBTT using tf.keras. Since my model is stateful I have to be explicit about the batch size when I create the model. However, at predict time I want to be able to do predictions on arbitrary length sequences and to have a batch size of 1. So I create a new, nearly identical model,  and then copy the weights via `predict_model.set_weights(train_model.get_weights())`. This all works as expected.

Now I want to save my prediction model so I can do inference from C++. If I follow the directions one finds on the internet (e.g. on [this page](https://medium.com/@pipidog/how-to-convert-your-keras-models-to-tensorflow-e471400b886a)) I need to do something like:

```
session = tf.keras.backend.get_session()
graph = session.graph
with graph.as_default_graph():
    # Do things to serialize the GraphDef to protobuf
```

But if I do this the `session.graph` is the graph I used for training, not my prediction model. It seems `tf.keras` does some ""magic"" to switch sessions or default graph (not sure which) and I can't find any documentation about what it does or when. I believe I could make one ""dummy prediction"" with my `predict_model` to make it current but that seems super hacky.

Is there any way to get the `Graph` that corresponds to a `tf.keras.Model`? If not, is there any way to make a `Model` be the current graph without doing something super hacky like making a prediction for data I don't care about?

I tried tracing through the `model.predict` code to see where the session is used but didn't find it quickly and figured this should be documented so I decided to ask here.

"
29624,on_epoch_end not triggered when workers=0 in fit_generator,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X 10.14
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-beta0 (issue also happens on TF 1.12 and 1.13)
- Python version: Python 3.6.7
- Bazel version (if compiling from source):  N/A
- GCC/Compiler version (if compiling from source):  N/A
- CUDA/cuDNN version:  N/A
- GPU model and memory:  N/A

**Describe the current behavior**
When running `fit_generator` on the main thread (i.e. with `use_multiprocessing=False` and `workers=0`), `on_epoch_end` doesn't get triggered

**Describe the expected behavior**
Having looked at the source code, I would expect `on_epoch_end` to be triggered at the end of each epoch

**Code to reproduce the issue**
I create a simple generator by subclassing from tf.keras.utils.Sequence:
```
class DataGenerator(Sequence):
    def __init__(self, split):
        self.split = split
        
    def __len__(self):
        return 2

    def __getitem__(self, index):

        print (f'\n split: {self.split} generator, index: {index}', flush=True)
        y = np.random.uniform(low=0, high=1, size=(2_000, 1))
        y = (y > 0.5).astype(np.int32)
        X = np.random.normal(loc=0, scale=1, size=(2_000, 10))
        X = X.astype(np.float32)
        return X, y

    def on_epoch_end(self):
        print (f'on epoch end: {self.split}', flush=True)
```

I then create a simple model
```
model = Sequential()
model.add(Dense(20, activation='relu', input_shape=(10,)))
model.add(Dense(1, activation='sigmoid'))
optimizer = Adam(lr=0.001)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
```

I set up my training and validation generators and run fit_generator
```
training_generator = DataGenerator(
    split='training')

validation_generator = DataGenerator(
    split='validation')

model.fit_generator(
    generator=training_generator,
    validation_data=validation_generator,
    use_multiprocessing=False,
    max_queue_size=10,
    epochs=4,
    shuffle=False,
    workers=0,
    verbose=0)
```

I get the following output:
```
 split: training generator, index: 0

 split: training generator, index: 1

 split: validation generator, index: 0

 split: validation generator, index: 1

 split: training generator, index: 0

 split: training generator, index: 1

 split: validation generator, index: 0

 split: validation generator, index: 1

 split: training generator, index: 0

 split: training generator, index: 1

 split: validation generator, index: 0

 split: validation generator, index: 1

 split: training generator, index: 0

 split: training generator, index: 1

 split: validation generator, index: 0

 split: validation generator, index: 1
```

If I change workers from 0 to 1, then `on_epoch_end` is triggered (i.e. `'on epoch end: {}'` print statements) appear."
29623,"tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 76800 values, but the requested shape has 768","The shape of the intermediate tensor is as followsï¼š
lad_tensor: (1, 17, 17, 768)
AvgPool_1a_5x5: (1, 5, 5, 768)
Conv2d_1b_1x1: (1, 5, 5, 128)
Conv2d_2a_5x5 (1, 1, 1, 768)
for example: aux_logits --> Tensor(""Ã—Ã—Ã—Ã—"", shape=(1, 1, 1, 768), dtype=float32)
and I want to convert a four-dimensional tensor into a two-dimensional tensor, I use the following methodï¼š
bottleneck_tensor=tf.squeeze(aux_logits,[1,2],name='SpatialSqueeze')
orï¼š
bottleneck_tensor=tf.reshape(aux_logits,(-1,768),name='SpatialSqueeze')
So the result isï¼š
bottleneck_tensor: Tensor(""Ã—Ã—Ã—Ã—Ã—"", shape=(1, 768), dtype=float32)

But I use the following statement ï¼š
bottleneck_input = tf.placeholder_with_default(
bottleneck_tensor, shape=[None, 768],
name='BottleneckInputPlaceholder')

The program reported the following errorï¼š
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 76800 values, but the requested shape has 768
[[Node: train/gradients/AuxLogits/SpatialSqueeze_grad/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](train/gradients/final_training_ops/Wx_plus_b/MatMul_grad/tuple/control_dependency, train/gradients/AuxLogits/SpatialSqueeze_grad/Shape)]]
and 76800=768Ã—100ï¼Œtrain_batch_size=100

But if I use the following statement, the program does not report errorsï¼š
bottleneck_input = tf.placeholder_with_default(
s, shape=[None, 768],
name='BottleneckInputPlaceholder')
and s is the type of array

but I find in TensorBoard, the nodes in the graph are disconnected

I'm very confused about it !"
29622,How to change the LSTMCell weight format from tensorflow to tf.keras,"

I I have some old code from tensorflow that I want to make work for tensorflow2/tf.keras. I would like to keep the same LSTM weights, but cannot figure out how to convert the format.

I have the old weights saved in a checkpoint file, and also have them saved in csv files.

My old code looks something like this:
```
input_placeholder = tf.placeholder(tf.float32, [None, None, input_units])
lstm_layers = [tf.nn.rnn_cell.LSTMCell(layer_size), tf.nn.rnn_cell.LSTMCell(layer_size)]
stacked = tf.contrib.rnn.MultiRNNCell(lstm_layers)
features, state = tf.nn.dynamic_rnn(stacked, input_placeholder, dtype=tf.float32)
```

And my new code looks something like this:
```
input_placeholder = tf.placeholder(tf.float32, [None, None, input_units])
lstm_layers = [tf.keras.layers.LSTMCell(layer_size),tf.keras.layers.LSTMCell(layer_size)]
stacked = tf.keras.layers.StackedRNNCells(lstm_layers)
features = stacked(input_placeholder)
... #later in the code
features.set_weights(previous_weights)
```

The old bias seems to match the new bias. The old kernel seems to be the concatenation of the kernel and recurrent kernel. I am able to load the previous_weights into the model (have explicitly checked the weights loaded correctly), however tests I have fail to produce the same result. Digging into the source code, the kernels seem to have a different format under the hood.

Is it possible to calculate the kernel and recurrent_kernel (tf.keras) using these old saved kernel weights?

Links if they're helpful:

https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/ops/rnn_cell_impl.py

https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/keras/layers/recurrent.py
"
29621,How to change the protobuf version compiled in the tensorflowï¼Ÿ,"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04.2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Master source
- TensorFlow version (use command below): 1.13.2
- Python version: 3.6
- Bazel version (if compiling from source): 0.26
- GCC/Compiler version (if compiling from source): 7.4
- CUDA/cuDNN version: 10 7.5
- GPU model and memory: 11G

I met this problem for tensorflow c++ application.
/home/wjl/github/tensorflow/bazel-genfiles/tensorflow/core/protobuf/verifier_config.pb.h:18:2: error: #error incompatible with your Protocol Buffer headers. 
My system is protobuf 3.8. Tensorflow uses 3.7.
How can I change it?

"
29620,TensorBoard in SageMaker notebook doesn't work with an S3 location on AL,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1
- Python version: 27 and 36
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the current behavior**
`tensorboard --logdir ""s3://[bucket]"" --inspect`

Error log: 
`No event files found within logdir s3://[bucket]`
`2019-05-29 00:03:04.879182: I tensorflow/core/platform/retrying_utils.cc:70] The operation failed and will be automatically retried in 0.459992 seconds (attempt 1 out of 10), caused by: Failed precondition: Not a directory`


**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
`sudo cp /etc/ssl/certs/ca-bundle.crt /etc/ssl/certs/ca-certificates.crt` fixes the issue


----

Amazon Linux:
[ec2-user@ip-172-31-28-240 certs]$ pwd
/etc/ssl/certs
[ec2-user@ip-172-31-28-240 certs]$ ls -alL *.crt
-r--r--r-- 1 root root 211658 Mar  8 19:58 ca-bundle.crt

[ec2-user@ip-172-31-28-240 certs]$ ls -al *.crt
lrwxrwxrwx 1 root root 49 Mar  8 19:58 ca-bundle.crt -> /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem
lrwxrwxrwx 1 root root 55 Mar  8 19:58 ca-bundle.trust.crt -> /etc/pki/ca-trust/extracted/openssl/ca-bundle.trust.crt

----

Ubuntu:
ubuntu@ip-172-31-76-35:/etc/ssl/certs$  ls -alL *.crt
-rw-r--r-- 1 root root 233394 Mar 19 07:23 ca-certificates.crt

---


Can Tensorflow move the required /etc/ssl/certs/ca-certificates in the right location for tensorboard to work with Amazon Linux?"
29618,Tflite opengles delegate gives inaccurate result,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Internal Android 8.1 board
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.13.1
- Python version: 2.7
- Bazel version (if compiling from source): 0.22.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: Mali-T864 GPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I wrote a simple demo using tflite opengles delegate to run deeplab models from [model zoo](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md).

I have tried your hosted model [deeplabv3_mv2_257_gpu.tflite](https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/deeplabv3_257_mv_gpu.tflite), It works perfect on my device on CPU and Opengles delegate.

However, when I tried the [deeplab mode with xception65 ](http://download.tensorflow.org/models/deeplabv3_xception_ade20k_train_2018_05_29.tar.gz), The tflite perform differently on CPU and Opengles delegate. My input layer is sub_7, output layer is ResizeBilinear_3.


Here is my result:
test image:
![two_human](https://user-images.githubusercontent.com/43549654/59234008-b852b600-8b9f-11e9-8ce2-703664cadcf4.png)

result from CPU (correct):
![hp_nonflatten_cpu](https://user-images.githubusercontent.com/43549654/59234023-d02a3a00-8b9f-11e9-98f0-f17874fca671.png)

result from opengles delegate:
![hp_flatten2_gpu](https://user-images.githubusercontent.com/43549654/59234034-dc15fc00-8b9f-11e9-9982-008d9f5064fa.png)

I believed that this issue is related to the operations(BATCH_TO_SPACE_ND, SPACE_TO_BATCH_ND)  that opengles not supporting thus fallback to CPU. Another [issue](https://github.com/tensorflow/tensorflow/issues/29509) of mine described more detail.

Flatten the unsupported ops using graph_transforms also failed. It gives me the same inaccurate result or shows message like:
`INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for GPU.
ERROR: TfLiteGpuDelegate Prepare: Program is not properly linked: L0005 The number of compute uniform components (1261) is greater than the maximum number allowed (1024).
ERROR: Node number 199 (TfLiteGpuDelegate) failed to prepare.
ERROR: Node number 199 (TfLiteGpuDelegate) failed to prepare.
`

**Describe the expected behavior**
all models work as good as your hosted model


**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29617,tensorflow/contrib module still tries to import cloud even when TF is compiled without GCP support,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.13.1
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 0.21.0
- GCC/Compiler version (if compiling from source): 6.3.1
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a



**Describe the problem**

It seems `tensorflow.contrib` will try to `import cloud` on an x86 machine even when TF is compiled without GCP support:

```
if os.name != ""nt"" and platform.machine() != ""s390x"":
  from tensorflow.contrib import cloud
```

I build TF with `--config=nogcp` which causes the `cloud` module NOT to be included in the pip package. But then when `tensorflow.contrib` is importing, you get `ImportError: cannot import name 'cloud' from 'tensorflow.contrib'`.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Build TF with `--config=nogcp`:

```
bazel build --config=nogcp //tensorflow/tools/pip_package:build_pip_package
```

Install the pip package, start Python, and run `import tensorflow.contrib`.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29614,Get global batch size for MirroredStrategy when using bucket_by_sequence_length,"**System information**
- TensorFlow version (you are using): 1.14-rc1
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**

I'm using [bucket_by_sequence_length](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/data/experimental/bucket_by_sequence_length) to batch sequences based on the maximum tokens allowed in a batch. This makes the batch size dynamic and not pre-determined. 

When I want to use distributed training using MirroredStrategy, I have to average the loss based on the global batch size or in other words the total examples I'm training in parallel in a single step across my GPUs. But since each GPU will have each own dynamic batch based on max tokens it's impossible for me to compute the total number of examples running in parallel since I only have access to a single GPU processing using the defined step_fn to run on [experimental_run](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/distribute/MirroredStrategy#experimental_run) function. 

It would be very helpful to be able to have access to global information as input to step_fn with details about all the batches running in parallel.

"
