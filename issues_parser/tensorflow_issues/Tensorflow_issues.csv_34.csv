Issue Number,Issue Title,Issue Body
34029,error on saving RNN layer with recurrent_dropout parameter as saved_model ,"```
layer_input   = Input(shape=(10, 100)) 
    layer_bi_rnn  = Bidirectional(GRU(units=10,recurrent_dropout=0.2, return_sequences=True))(layer_input)
    layer_dense   = TimeDistributed(Dense(5))(layer_bi_rnn)
    layer_act     = Activation('softmax')(layer_dense)
    model         = Model([layer_input], layer_act)

    model.compile(loss='categorical_crossentropy')
```

save this model as saved_model on `tf-nightly 2.1.0-dev20191104` raise bug as : 

```
Attempted to save a function b'__inference_forward_lstm_1_layer_call_fn_19037' which references a symbolic Tensor Tensor(""dropout/mul_1:0"", shape=(None, 256), dtype=float32) that is not a simple constant. This is not supported.
```

after trying to change some parameter, i got the conclusion that this issue happens because of `recurrent_dropout` parameter. Any suggestion? "
34028,tensorflow keras SavedModel for LSTM fails,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):  2.0
- Python version: 3.6.1
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Attempting to save LSTM based tf.keras model to a SavedModel it fails with error:

`ValueError: Attempted to save a function b'__inference_lstm_layer_call_fn_5041' which references a symbolic Tensor Tensor(""dropout/mul_1:0"", shape=(None, 2048), dtype=float32) that is not a simple constant. This is not supported.`
**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

`BASE_DATA_PATH = 'C:\Grewe\Classes\CS663\Mat\LSTM\data' `
`model_file = os.path.join(BASE_DATA_PATH, 'my_model.h5')`
`model = tf.keras.models.load_model(model_file)`
`model.summary()`


`print('\n# Generate predictions ')`
`predictions = model.predict(valid_dataset, verbose=1 )`
`print('predictions shape:', predictions.shape)`
`print(predictions)`
`print(len(predictions))`


`saved_model_dir = os.path.join(BASE_DATA_PATH, 'saved_model\catsdogsCNN')`
`!mkdir -#p saved_model_dir`
`model.save(saved_model_dir) `


[pythonLSTMCode.txt](https://github.com/tensorflow/tensorflow/files/3812314/pythonLSTMCode.txt)


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

See attached python file that contains the original training code for the sequential LSTM model defined as:
`model = tf.keras.Sequential([
    tf.keras.layers.Masking(mask_value=0.),
    tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(len(LABELS), activation='softmax')
])`
"
34026,UnboundLocalError: local variable 'weights_normed' referenced before assignment,"This is my code, it can be trained normally, but when he tests, he gives an error.
![image](https://user-images.githubusercontent.com/50411057/68261608-9f313100-007b-11ea-93e8-54c497055e91.png)
"
34025,"Understanding warning ""5 out of the last 5 calls to <function XXX> triggered tf.function retracing""","**System information**
- Have I written custom code: Yes, below.
- Linux Ubuntu 16.04 
- TensorFlow 2.1.0-dev20191103, binary install.
- Python 3.6
- CUDA 10.0 / cnDNN 7.6.4
- 4 * NVIDIA TITAN X (12GB)

I defined a very simple training script with a custom loss function and `.fit()` as below. The `loss_fn`  is very simple and I think every time it takes tensors **of the same shape and type**. But I'm getting the **following warning message**. Interesting is that I'm getting the message only when training **with multiple GPUs**. Is it a bug? Is it harmful? Is it really affecting the computational cost?

Warning message:
```
WARNING:tensorflow:5 out of the last 5 calls to <function loss_fn at 0x7f0070ef0e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_re
lax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
```
Code:
````python
from __future__ import absolute_import, division, print_function, unicode_literals
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import (Conv2D, Conv3D, Dense)


@tf.function
def loss_fn(y_pred, y_true):
    return tf.reduce_mean(tf.math.square(y_pred - y_true))

if __name__ == ""__main__"":

    BATCH_SIZE_PER_SYNC = 4
    strategy = tf.distribute.MirroredStrategy()
    num_gpus = strategy.num_replicas_in_sync
    global_batch_size = BATCH_SIZE_PER_SYNC * num_gpus
    print('num GPUs: {}, global batch size: {}'.format(num_gpus, global_batch_size))


    # fake data ------------------------------------------------------
    fakea = np.random.rand(global_batch_size, 10, 200, 200, 128).astype(np.float32)
    targets = np.random.rand(global_batch_size, 200, 200, 14).astype(np.float32)

    fakea = tf.constant(fakea)
    targets = tf.constant(targets)

    # tf.Dataset ------------------------------------------------------
    def gen():
        while True:
            yield (fakea, targets)

    dataset = tf.data.Dataset.from_generator(gen,
        (tf.float32, tf.float32),
        (tf.TensorShape(fakea.shape), tf.TensorShape(targets.shape)))

    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

    # training ------------------------------------------------------
    callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./logs')]
    training = True
    with strategy.scope():
        va = keras.Input(shape=(10, 200, 200, 128), dtype=tf.float32, name='va')
        x = Conv3D(64, kernel_size=3, strides=1, padding='same')(va)
        x = Conv3D(64, kernel_size=3, strides=1, padding='same')(x)
        x = Conv3D(64, kernel_size=3, strides=1, padding='same')(x)
        x = tf.reduce_max(x, axis=1, name='maxpool')                         
        b = Conv2D(14, kernel_size=3, padding='same')(x)
        model = keras.Model(inputs=va, outputs=b, name='net')
        optimizer = keras.optimizers.RMSprop()

        model.compile(optimizer=optimizer, loss=loss_fn)
        model.fit(x=dataset, epochs=10, steps_per_epoch=100, callbacks=callbacks)
````
"
34024,Group Convolution not working in TF 2.0.0,"The merged PR #25818 enables group convolution by allowing the input's depth to be multiples of the filter's in_depth parameter rather than exactly equal.

However, as you can see below, whenever I attempt to perform a group convolution, it results in an ambiguous error ""No Algorithm Found"". Same issue if I make the filter's in_depth = 1.
Making the convolution filter in_depth parameter equal to the channels of the input (=16) it works (regular convolution).

Am I missing something or is this not supported for eager execution?

Tensorflow installed via: pip3 install --upgrade tensorflow-gpu
OS: Ubuntu 18.04.1, kernel: 5.0.0-15 lowlatency.
GTX 1080Ti , cuda: 10.1 , cudnn-7.6.0

(I left tensorflow initialization log in case it provides relevant information)
```
Python 3.7.4 (default, Aug 13 2019, 20:35:49)
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> print(tf.version.GIT_VERSION, tf.version.VERSION)
v2.0.0-rc2-26-g64c3d38 2.0.0
>>> tf.nn.conv2d(tf.random.normal((11,13,17,16)), tf.random.normal((3,5,16//2,7)), padding='SAME',strides=[1,1,1,1]).shape
2019-11-05 18:00:39.800225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-11-05 18:00:39.841613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:39.842211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6705
pciBusID: 0000:1d:00.0
2019-11-05 18:00:39.842279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:39.843083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:1e:00.0
2019-11-05 18:00:39.843414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-05 18:00:39.844684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-05 18:00:39.846034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-05 18:00:39.847021: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-05 18:00:39.849473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-05 18:00:39.850970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-05 18:00:39.855126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-05 18:00:39.855289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:39.856005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:39.856903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:39.857518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:39.858304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2019-11-05 18:00:39.858525: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-05 18:00:39.877459: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3699425000 Hz
2019-11-05 18:00:39.878231: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563f2440c8b0 executing computations on platform Host. Devices:
2019-11-05 18:00:39.878267: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-05 18:00:40.042173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:40.068620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:40.069774: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563f244af3e0 executing computations on platform CUDA. Devices:
2019-11-05 18:00:40.069799: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-11-05 18:00:40.069819: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-11-05 18:00:40.071588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:40.072539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6705
pciBusID: 0000:1d:00.0
2019-11-05 18:00:40.072670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:40.073607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:1e:00.0
2019-11-05 18:00:40.073652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-05 18:00:40.073666: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-05 18:00:40.073678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-05 18:00:40.073688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-05 18:00:40.073699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-05 18:00:40.073710: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-05 18:00:40.073720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-05 18:00:40.073771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:40.074334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:40.074891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:40.075465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:40.075960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2019-11-05 18:00:40.075991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-05 18:00:40.077335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-05 18:00:40.077350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1
2019-11-05 18:00:40.077358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y
2019-11-05 18:00:40.077364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N
2019-11-05 18:00:40.077488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:40.078794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:40.080681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:40.081210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10478 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:1d:00.0, compute capability: 6.1)
2019-11-05 18:00:40.081733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 18:00:40.082722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10479 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:1e:00.0, compute capability: 6.1)
2019-11-05 18:00:40.562956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-05 18:00:41.155546: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at conv_ops.cc:1069 : Not found: No algorithm worked!
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/bahaa/miniconda3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 1913, in conv2d_v2
    name=name)
  File ""/home/bahaa/miniconda3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d
    name=name)
  File ""/home/bahaa/miniconda3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1039, in conv2d
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.NotFoundError: No algorithm worked! [Op:Conv2D]
>>> tf.nn.conv2d(tf.random.normal((11,13,17,16)), tf.random.normal((3,5,16,7)), padding='SAME',strides=[1,1,1,1]).shape
TensorShape([11, 13, 17, 7])
```


"
34022,List index out of range for FashionMNIST tutorial.,"I've just started learning a bit about Tensorflow, and I tried out the Fashion MNIST tutorial. However, I keep getting a list index out of range error. I've copied the code from the official tutorial and also tried using tf.reset_default_graph() as suggested in some other posts, but neither have worked.

Here is the notebook with the error:
https://github.com/fsiraj/Tensorflow-Tutorials/blob/master/Fashion%20MNIST.ipynb"
34021,Unable to save TensorFlow Keras LSTM model to SavedModel format,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip installed
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0
- Python version: 3.7.1
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Unable to save TensorFlow Keras LSTM model to SavedModel format for exporting to Google Cloud and Google AI platform.

Error message: ValueError: Attempted to save a function b'__inference_lstm_2_layer_call_fn_36083' which references a symbolic Tensor Tensor(""dropout/mul_1:0"", shape=(None, 1280), dtype=float32) that is not a simple constant. This is not supported.

**Describe the expected behavior**
LSTM model would be saved in the SavedModel format to be exported into a Google Cloud bucket to work with Google's AI platform.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

`import tensorflow as tf
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tqdm
import datetime
from sklearn.preprocessing import LabelBinarizer 

model = tf.keras.Sequential([
    tf.keras.layers.Masking(mask_value=0.),
    tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(len(LABELS), activation='softmax')
])

model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy', 'top_k_categorical_accuracy'])

test_file = 'C:/.../testlist01.txt'
train_file = 'C:/.../trainlist01.txt'

with open(test_file) as f:
    test_list = [row.strip() for row in list(f)]

with open(train_file) as f:
    train_list = [row.strip() for row in list(f)]
    train_list = [row.split(' ')[0] for row in train_list]

def make_generator(file_list):
    def generator():
        np.random.shuffle(file_list)
        for path in file_list:
            full_path = os.path.join(BASE_PATH, path).replace('.avi', '.npy')

            label = os.path.basename(os.path.dirname(path))
            features = np.load(full_path)

            padded_sequence = np.zeros((SEQUENCE_LENGTH, 1280))
            padded_sequence[0:len(features)] = np.array(features)

            transformed_label = encoder.transform([label])
            yield padded_sequence, transformed_label[0]
    return generator

train_dataset = tf.data.Dataset.from_generator(make_generator(train_list),
                 output_types=(tf.float32, tf.int16),
                 output_shapes=((SEQUENCE_LENGTH, 1280), (len(LABELS))))
train_dataset = train_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)

valid_dataset = tf.data.Dataset.from_generator(make_generator(test_list),
                 output_types=(tf.float32, tf.int16),
                 output_shapes=((SEQUENCE_LENGTH, 1280), (len(LABELS))))
valid_dataset = valid_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)

model.fit(train_dataset, epochs=17, validation_data=valid_dataset)

BASE_DIRECTORY = 'C:\\...\\saved_model\\LSTM\\1\\';
tf.saved_model.save(model, BASE_DIRECTORY)
`

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34020,Checkpoint.restore doesn't restore Dataset iterator state when Dataset contains shuffle(),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.5.2
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: not installed
- GPU model and memory: no GPU

**Describe the current behavior**
The code at the end results in the following output.
```
2019-11-05 13:54:16.140994: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-05 13:54:16.149389: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2397225000 Hz
2019-11-05 13:54:16.151608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50ebc70 executing computations on platform Host. Devices:
2019-11-05 13:54:16.151636: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
tf.Tensor(72, shape=(), dtype=int64)
tf.Tensor(83, shape=(), dtype=int64)
tf.Tensor(19, shape=(), dtype=int64)
Saved to /tmp/x/ckpt-1
tf.Tensor(74, shape=(), dtype=int64)
tf.Tensor(33, shape=(), dtype=int64)
tf.Tensor(93, shape=(), dtype=int64)
Restored from /tmp/x/ckpt-1
tf.Tensor(21, shape=(), dtype=int64)
tf.Tensor(0, shape=(), dtype=int64)
tf.Tensor(8, shape=(), dtype=int64)
```

**Describe the expected behavior**
After restoring from the checkpoint, I expect the iterator to return the same elements as it did after saving the checkpoint.  I.e.
```
2019-11-05 13:54:16.140994: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-05 13:54:16.149389: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2397225000 Hz
2019-11-05 13:54:16.151608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50ebc70 executing computations on platform Host. Devices:
2019-11-05 13:54:16.151636: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
tf.Tensor(72, shape=(), dtype=int64)
tf.Tensor(83, shape=(), dtype=int64)
tf.Tensor(19, shape=(), dtype=int64)
Saved to /tmp/x/ckpt-1
tf.Tensor(74, shape=(), dtype=int64)
tf.Tensor(33, shape=(), dtype=int64)
tf.Tensor(93, shape=(), dtype=int64)
Restored from /tmp/x/ckpt-1
tf.Tensor(74, shape=(), dtype=int64)
tf.Tensor(33, shape=(), dtype=int64)
tf.Tensor(93, shape=(), dtype=int64)
```

**Code to reproduce the issue**
```py
import tensorflow as tf
ds = tf.data.Dataset.range(100).shuffle(100, seed=42, reshuffle_each_iteration=False)
it = iter(ds)
ckpt = tf.train.Checkpoint(foo=it)
mgr = tf.train.CheckpointManager(ckpt, '/tmp/x', max_to_keep=3)
for _ in range(3): print(next(it))
mgr.save()
print(""Saved to {}"".format(mgr.latest_checkpoint))
for _ in range(3): print(next(it))
ckpt.restore(mgr.latest_checkpoint)
print(""Restored from {}"".format(mgr.latest_checkpoint))
for _ in range(3): print(next(it))
```
FWIW, I get the expected result if I remove `.shuffle(...)`.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34019,LSTM model can not save via SavedModel,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Microsoft Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  
- TensorFlow version (use command below):2.0
- Python version:  3.6.1
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When attempt from python using tf.keras LSTM model to create a SavedModel get error  (first load model from h5 file first)
ValueError: Model <tensorflow.python.keras.engine.sequential.Sequential object at 0x000001F7676BDEF0> cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling .fit() or .predict(). To manually set the shapes, call model._set_inputs(inputs).



**Describe the expected behavior**
To be able to create SavedModel directory
**Code to reproduce the issue**

`# Save the entire model as a SavedModel.
BASE_DATA_PATH = 'C:\Grewe\Classes\CS663\Mat\LSTM\data'  

#load the previously saved h5 model
# try to reload the saved h5 file
# Recreate the exact same model, including its weights and the optimizer

model_file = os.path.join(BASE_DATA_PATH, 'my_model.h5')
model = tf.keras.models.load_model(model_file)
# Show the model architecture
model.summary()

#create directory to save the SavedModel

saved_model_dir = os.path.join(BASE_DATA_PATH, 'saved_model\catsdogsCNN')
!mkdir -#p saved_model_dir
model.save(saved_model_dir) 


`
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
34017,Rename this repo to Big Migraine !!,"I don;t know which version to use for which purpose ... huge compatibility disaster !
Training on multiple gpu even bill gates cannot do...
AVX instructions are missing for pip install...
Tensorflow lite, Tensorflow TFX, Tensorflow serving.... crap after crap.
whether to use keras or tensorflow
There are no performance matrix comparing and converting your models...
Even the book publishers and article writers are confused which version should they be using....
"
34016,Keras' load_weights() bug: ValueError: You are trying to load a weight file containing 1 layers into a model with 0 layers.,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Colab
- TensorFlow version: 2.0.0

**Describe the current behavior**

Using `model.save_weights()` and then `model.load_weights()` caused this error:
`ValueError: You are trying to load a weight file containing 1 layers into a model with 0 layers.`

**Code to reproduce the issue**
See [this Colab notebook](https://colab.research.google.com/drive/1-8kVsk-2PMTX_V_6VRHMWczz4T_4MPev)."
34015,Identity initializer not working as expected in Layer class add_weight method,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):
v1.15.0-rc3-22-g590d6ee 1.15.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10.0 / cuDNN 7.6.4
- GPU model and memory: Tesla K80

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
If trying to use the `identity` initializer in the `build` method of a custom `Layer`, passing the shape as a tuple of `Dimension`s fails, e.g.
```
    def build(self, input_shape):
        """"""Build layer.""""""
        self.w = self.add_weight(
            shape=(input_shape[-1], input_shape[-1]),
            initializer=tf.initializers.identity(),
            trainable=True,
        )
```
fails with `TypeError: num_rows and num_columns must be positive integer values.`. However, exactly the same code, where we replace `identity` by `ones` works perfectly.

Failure happens because `tf.eye` doesn't accept `Dimension` objects as inputs, only integers, e.g.:
```
    def build(self, input_shape):
        """"""Build layer.""""""
        self.w = self.add_weight(
            shape=(input_shape[-1].value, input_shape[-1].value),
            initializer=tf.initializers.identity(),
            trainable=True,
        )
```
works

**Describe the expected behavior**
Behavior for different initializers should be consistent. `tf.initializers.identity` should accept a tuple of `Dimension` objects for shape, as other initializers do.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import tensorflow as tf
import numpy as np


class MyLayer(tf.keras.layers.Layer):
    def __init__(self, *args, kernel_initializer=tf.initializers.identity(), **kwargs):
        super().__init__(*args, **kwargs)
        self.kernel_initializer = kernel_initializer

    def build(self, input_shape):
        """"""Build layer.""""""
        self.w = self.add_weight(
            shape=(input_shape[-1], input_shape[-1]),
            initializer=self.kernel_initializer,
            trainable=True,
        )

    def call(self, inputs):
        """"""Apply layer.""""""
        return tf.matmul(inputs, tf.expand_dims(self.w, 0))


if __name__ == ""__main__"":
    tf.enable_eager_execution()
    inputs = np.random.normal(size=(1, 10, 3))
    layer = MyLayer()
    outputs = layer(inputs)
    print(outputs.numpy())
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
Traceback (most recent call last):
  File ""reproduce.py"", line 27, in <module>
    outputs = layer(inputs)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 894, in __call__
    self._maybe_build(inputs)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 2146, in _maybe_build
    self.build(input_shapes)
  File ""reproduce.py"", line 15, in build
    trainable=True,
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 529, in add_weight
    aggregation=aggregation)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py"", line 712, in _add_variable_with_custom_getter
    **kwargs_for_getter)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py"", line 139, in make_variable
    shape=variable_shape if variable_shape else None)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 258, in __call__
    return cls._variable_v1_call(*args, **kwargs)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 219, in _variable_v1_call
    shape=shape)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 197, in <lambda>
    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py"", line 2503, in default_variable_creator
    shape=shape)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 262, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 1406, in __init__
    distribute_strategy=distribute_strategy)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 1537, in _init_from_args
    initial_value() if init_from_fn else initial_value,
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py"", line 119, in <lambda>
    init_val = lambda: initializer(shape, dtype=dtype)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py"", line 1211, in __call__
    initializer = linalg_ops_impl.eye(*full_shape, dtype=dtype)
  File ""/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/linalg_ops_impl.py"", line 57, in eye
    'num_rows and num_columns must be positive integer values.')
TypeError: num_rows and num_columns must be positive integer values.
```
"
34013,Error message in Hello_world example - ML for micro ,"I am having the following error message when I am trying to run the hello_world example for microcontrollers:

`C:\Users\arge10\tensorflow>make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=mbed TAGS=""CMSIS disco_f746ng"" generate_hello_world_mbed_project
process_begin: CreateProcess(NULL, uname -m, ...) failed.
-m was unexpected at this time.
tensorflow/lite/experimental/micro/tools/make/download_and_extract.sh ""https://github.com/google/gemmlowp/archive/719139ce755a0f31cbf1c37f7f98adcc7fc9f425.zip"" ""7e8191b24853d75de2af87622ad293ba"" tensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp
'tensorflow' is not recognized as an internal or external command,
operable program or batch file.
tensorflow/lite/experimental/micro/tools/make/Makefile:240: recipe for target 'tensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp' failed
make: *** [tensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp] Error 1`

I searched for some solution on the internet about this issue, but I was unable to find any solution
Did someone else face this problem before?"
34012,tf.function accept namedtuples,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
34011,"crop_and_resize_v2() got an unexpected keyword argument 'box_ind'，how to understand the 'box_ind' when the num_boxes equal to 1, batch_size equal to 32?","I am using the ROI_pooling layer for feature extraction. The dimension of the feature map is 32 * 12 * 12 * 64, and the output clipping dimension is 7 * 7. Only one clipping is needed. How do I use the function tf.image.crop_and_ resize?"
34010,TFLite 5D Tensors with the OpenCL Back-End,"I am planning to gradually add support for 5D tensors in TFLite in the OpenCL GPU back-end, which was not available in r2.0.
My main concern with the OpenGL API was the limit on the number of dimensions that work groups have, but that's no longer the issue with OpenCL as it seems to allow N-dimensional work groups.

What is the status of the OpenCL back-end? What about 5D tensors? (this is a massive re-write so it would be cool to know there's no duplicate work)
Why was the initial GPU back-end implemented with OpenGL and not OpenCL?

My ultimate goal is to support Conv3D. #19658

EDIT:
While its true that OpenCL's API allows N-dimensional work groups, I came across the CL_DEVICE_MAX_WORK_ITEM_DIMENSIONS. This setting is bound to 3 on all of the GPUs I queried, any tips to how go around it? or should I do multiple enqueue's?"
34009,BatchNormalization,"If I want to freeze gamma, beta, moving_average_mean, moving_average_var in BatchNormalization
could tf.keras.layers.BatchNormalization(trainable=False)  be OK?
or only could freeze gamma, beta ?
"
34008,Why computation time increases proportionally when using more GPUs (mirror strategy)?,"**System**
- Ubuntu 16.04, python 3.6, Tensorflow 2.1.0-dev20191103 (binary), 
- CUDA 10.0, cuDNN 7.6.4
- 4 x GPU NVIDIA Titan X 12GB

I expected a similar computation time of each training step as I increase the # of GPUs thanks to parallelism (or slight increase due to possible overhead). However, I'm getting a proportional increase as if they run serially. **Why am I not getting the advantage of parallelism here? Any advice, please?**

Note that
- I checked ""per-replica"" input and outputs are the same across those situations.
- I'm repeating the same dummy data here, so I don't think it's a data pipeline-related issue.
- Although I posted this question in stackoverflow, too, I post here since I'm not sure if this is a misuse or a bug.

The result looks like:
````bash
$ CUDA_VISIBLE_DEVICES=0 python train_v2_multi_example.py
...
Ep 01/100 | step 02 | 0.473 sec/step | loss: 46485.430
Ep 01/100 | step 03 | 0.482 sec/step | loss: 9216.726

$ CUDA_VISIBLE_DEVICES=0,1 python train_v2_multi_example.py
...
Ep 01/100 | step 02 | 1.141 sec/step | loss: 22627.699
Ep 01/100 | step 03 | 1.091 sec/step | loss: 11679.490

$ CUDA_VISIBLE_DEVICES=0,1,2 python train_v2_multi_example.py
...
Ep 01/100 | step 02 | 1.408 sec/step | loss: 32166.996
Ep 01/100 | step 03 | 1.380 sec/step | loss: 14036.578
````

Code is as follows:
````python
from __future__ import absolute_import, division, print_function, unicode_literals
import os, time, sys, numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import (Conv2D, Conv3D, Dense)


@tf.function
def loss_fn(y_pred, y_true):
    return tf.reduce_mean(tf.math.square(y_pred - y_true))

@tf.function
def train_step(dist_inputs):
    def step_fn(inputs):
        inputs, labels = inputs

        # tf.print(""in"", tf.shape(inputs), ""out"", tf.shape(labels), output_stream=sys.stdout)
        with tf.GradientTape() as tape:
            out = model(inputs)
            loss_value = loss_fn(out, labels)
        grads = tape.gradient(loss_value, model.trainable_weights)
        optimizer.apply_gradients(zip(grads, model.trainable_weights))
        return loss_value

    per_example_losses = strategy.experimental_run_v2(step_fn, args=(dist_inputs,))
    mean_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, per_example_losses, axis=None)
    return mean_loss


if __name__ == ""__main__"":

    BATCH_SIZE_PER_SYNC = 4
    logdir = os.path.join('logs/test')
    strategy = tf.distribute.MirroredStrategy()
    num_gpus = strategy.num_replicas_in_sync
    global_batch_size = BATCH_SIZE_PER_SYNC * num_gpus
    print('num GPUs: {}, global batch size: {}'.format(num_gpus, global_batch_size))

    # fake data ------------------------------------------------------
    fakea = np.random.rand(global_batch_size, 10, 200, 200, 128).astype(np.float32)
    targets = np.random.rand(global_batch_size, 200, 200, 14)

    # tf.Dataset ------------------------------------------------------
    def gen():
        while True:
            yield (fakea, targets)

    dataset = tf.data.Dataset.from_generator(gen,
        (tf.float32, tf.float32),
        (tf.TensorShape(fakea.shape), tf.TensorShape(targets.shape)))

    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    dist_dataset = strategy.experimental_distribute_dataset(dataset)

    # Model ------------------------------------------------------
    training = True
    with strategy.scope():
        # Model
        va = keras.Input(shape=(10, 200, 200, 128), dtype=tf.float32, name='va')
        x = Conv3D(64, kernel_size=3, strides=1, padding='same')(va)
        x = Conv3D(64, kernel_size=3, strides=1, padding='same')(x)
        x = Conv3D(64, kernel_size=3, strides=1, padding='same')(x)
        x = tf.reduce_max(x, axis=1, name='maxpool')  # [ΣK, 128]
        b = Conv2D(14, kernel_size=3, padding='same')(x)
        model = keras.Model(inputs=va, outputs=b, name='net')
        optimizer = keras.optimizers.RMSprop()
    model.summary()

    # TRAIN ---------------------------------------------------------
    writer = tf.summary.create_file_writer(logdir)

    num_steps = 100
    num_epoches = 100
    global_step = 0

    with strategy.scope():
        iterator = iter(dist_dataset)
        with writer.as_default():
            for epoch in range(num_epoches):
                for step in range(num_steps):

                    if global_step == 0 or 5 < global_step < 8:
                        tf.summary.trace_on(graph=True, profiler=True)

                    start = time.time()
                    loss_value = train_step(next(iterator))
                    duration = time.time() - start

                    prefix = 'Ep {:02d}/{:02d} | step {:02d} '.format(epoch + 1, num_epoches, step)
                    suffix = '| {:.3f} sec/step | loss: {:.3f} '.format(duration, float(loss_value))
                    print(prefix + suffix)

                    tf.summary.scalar(""loss"", loss_value, step=global_step)

                    if global_step == 0 or 5 < global_step < 8:
                        tf.summary.trace_export(name=""model_trace"", step=global_step, profiler_outdir=logdir)
                    writer.flush()
                    global_step += 1
````



"
34007,"Comments on the ""Custom model_fn with TF 2.0 symbols"" section of the ""Migrate your TensorFlow 1 code to TensorFlow 2"" guide","## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/guide/migrate#custom_model_fn_with_tf_20_symbols

## Description of issue (what needs changing):

My comments are about this piece of code:
```
def my_model_fn(features, labels, mode):
  model = make_model()

  training = (mode == tf.estimator.ModeKeys.TRAIN)
  loss_obj = tf.keras.losses.SparseCategoricalCrossentropy()
  predictions = model(features, training=training)

  # Get both the unconditional losses (the None part)
  # and the input-conditional losses (the features part).
  reg_losses = model.get_losses_for(None) + model.get_losses_for(features)
  total_loss = loss_obj(labels, predictions) + tf.math.add_n(reg_losses)

  # Upgrade to tf.keras.metrics.
  accuracy_obj = tf.keras.metrics.Accuracy(name='acc_obj')
  accuracy = accuracy_obj.update_state(
      y_true=labels, y_pred=tf.math.argmax(predictions, axis=1))

  train_op = None
  if training:
    # Upgrade to tf.keras.optimizers.
    optimizer = tf.keras.optimizers.Adam()
    # Manually assign tf.compat.v1.global_step variable to optimizer.iterations
    # to make tf.compat.v1.train.global_step increased correctly.
    # This assignment is a must for any `tf.train.SessionRunHook` specified in
    # estimator, as SessionRunHooks rely on global step.
    optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()
    # Get both the unconditional updates (the None part)
    # and the input-conditional updates (the features part).
    update_ops = model.get_updates_for(None) + model.get_updates_for(features)
    # Compute the minimize_op.
    minimize_op = optimizer.get_updates(
        total_loss,
        model.trainable_variables)[0]
    train_op = tf.group(minimize_op, *update_ops)

  return tf.estimator.EstimatorSpec(
    mode=mode,
    predictions=predictions,
    loss=total_loss,
    train_op=train_op,
    eval_metric_ops={'Accuracy': accuracy_obj})

# Create the Estimator & Train.
estimator = tf.estimator.Estimator(model_fn=my_model_fn)
tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
```
My first comment is: why write
```
accuracy = accuracy_obj.update_state(
      y_true=labels, y_pred=tf.math.argmax(predictions, axis=1))
```
instead of just `accuracy_obj.update_state(y_true=labels, y_pred=tf.math.argmax(predictions, axis=1))` ? First, `accuracy`is never used. Second, this may lead the reader to believe that the `tf.keras.metrics.Metric.update_state` outputs the accuracy value, just like the `tf.keras.metrics.Metric.result` method, whereas the output of `update_state` is `accuracy_obj.count`. See on the code below:
```
import tensorflow as tf

accuracy_obj = tf.keras.metrics.Accuracy(name='acc_obj')
accuracy = accuracy_obj.update_state(
      y_true=[0, 1], y_pred=tf.math.argmax([[0.3, 0.7], [0.3, 0.7]], axis=1))

tf.print(accuracy)
# 2
tf.print(accuracy_obj.result())
# 0.5
tf.print(accuracy_obj.count)
# 2
```

My other comment is that we have the line `train_op = tf.group(minimize_op, *update_ops)` whereas in the [""Custom model_fn with minimal changes"" section](https://www.tensorflow.org/guide/migrate#custom_model_fn_with_minimal_changes) the corresponding line is `train_op = tf.group(minimize_op, update_ops)` without the `*`. Why is that? Is this a mistake?"
34006,Tensorflow mix precision training error,"ystem info:

GPU Type: Tesla T4
Nvidia Driver Version: 418.87.01
CUDA Version: 10.1.243
CUDNN Version: 7.6.3
Python Version (if applicable): 3.7.4
TensorFlow Version (if applicable):1.14.0
Operating System + Version: Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-142-generic x86_64)

Hi, I am training tensorflow version Tacotron2 model with mix precision training.
after some training iterations , when doing validation, an error occurs, the detailed error info is like below:

`Exiting due to exception: 2 root error(s) found. (0) Invalid argument: TensorArray dtype is float but Op is trying to write dtype half. [[node Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 (defined at /home/yichao.li/lite-tacotron2/tacotron/models/modules.py:225) ]] [[strided_slice_51/_7343]] (1) Invalid argument: TensorArray dtype is float but Op is trying to write dtype half. [[node Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 (defined at /home/yichao.li/lite-tacotron2/tacotron/models/modules.py:225) ]] 0 successful operations. 0 derived errors ignored.`

Do I need to turn off auto mixed precision on evaluation time?
could you help to clarify this? how to fix?"
34005,Documentation unclear tf.batch_to_space,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/batch_to_space

## Description of issue (what needs changing):
1. Example needs to be added.
2. `crops` part in `Args:` section is very difficult to understand. Needs to be better formatted (put into code). 

### Clear description:
Documentation is unclear, no example is shown. Also, there is one extremely long paragraph with code in between in the `crops` section under args.

### Parameters defined

Are all parameters defined and formatted correctly? 
=> Not well formatted.

### Returns defined

Are return values defined?
=> Yes

### Raises listed and defined

Are the errors defined? 
=> No

### Usage example

Is there a usage example?
=> No

### Submit a pull request?
=> No
"
34004,tf.keras.layers.SimpleRNN doesn't use GPU?,"First, This is a example in TensorFlow 2.0 with Keras.

```
from tensorflow.keras.datasets import imdb

num_words = 10000
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)

from tensorflow.keras.preprocessing.sequence import pad_sequences

max_len = 500

pad_X_train = pad_sequences(X_train, maxlen=max_len)
pad_X_test = pad_sequences(X_test, maxlen=max_len)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense, Embedding  

model = Sequential()
model.add(Embedding(input_dim = num_words, output_dim = 32))
model.add(SimpleRNN(32, return_sequences = True, dropout = 0.15, recurrent_dropout = 0.15))
model.add(SimpleRNN(32))
model.add(Dense(1, activation = 'sigmoid'))

model.compile(optimizer='adam',
             loss = 'binary_crossentropy',
             metrics = ['acc'])

# model.summary()

history = model.fit(pad_X_train, y_train, 
                    batch_size = 32, epochs = 15, 
                    validation_split = 0.2)
```

+ Use Window 10 and TF 2.0
+ NVidia Driver : 418.81
+ CUDA : 10.1
+ GPU : GeForce GTX 1050

And, When I use the layer SimpleRNN in keras, GPU-Utils is very low. what happen??
![image](https://user-images.githubusercontent.com/33315343/68199250-04940c00-0001-11ea-9b53-b315e6ff8505.png)

For checking if my GPU worked correctly, I use it using Conv2D.
![image](https://user-images.githubusercontent.com/33315343/68199475-753b2880-0001-11ea-90be-bae41dc5d637.png)

The above picture was run on the MNIST dataset, which does not seem to require much GPU-Utils.

I haven't seen 100% use, but my GPU seems to work fine.

Stacking multiple SimpleRNN layers or using just one will not increase GPU-Utils at 10%. 
What's wrong?

Is it because of the feature of the layer?"
34003,"Something wrong with ""model.fit(x_train, y_train, epochs=5)""","Even I copy the code like below from the official website and run it in jupyter notebook, I get an error:
**ValueError: Attempt to convert a value (5) with an unsupported type (<class 'numpy.uint8'>) to a Tensor.**
My tensorflow version is 2.0, plz help
```
import tensorflow as tf
mnist = tf.keras.datasets.mnist

(x_train, y_train),(x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)
model.evaluate(x_test, y_test)

```"
34002,Can I say the version compatibility of tensorflow is just not great. ,"Can I say the version compatibility of tensorflow is just like shit. The code under older versions can not work at all under the new versions and you never know which version you should use. The defintions of  functions in different versions changes greatly and you never know which function is really what you need. When you want to run a new code, you have to try all the versions to make it work if you don't know its original tf version. Or you must change the code to statisfy the demand of the old versions. And sometimes you waste so much time and then you find you still can't make it work.
Anybody has the same problem? I think it's one of the most important reasons why more and more people are turning to pytorch. "
34001, About failed to load model from pb ," I train the model in Ubuntu(VM) ,with tensorflow 1.14.0 , export pb file

but in android app whit tensorflow-android:1.13.1 ，can not load pb file

“ failed to load model from pb  ”

"
34000,Custom layer not working ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10
- GPU model and memory: P100

**Describe the current behavior**
Functional API in tf.keras complaining about Eager mode

**Code to reproduce the issue**
```python
!pip install --quiet tensorflow-gpu==2.0

import cv2
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from skimage.io import imread, imshow, imsave
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras import layers as L
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping
from tensorflow.keras import backend as K


class Sampling(tf.keras.layers.Layer):
    def __init__(self, mu_shape, **kwargs):
        super(Sampling, self).__init__(**kwargs)

    def call(self, args):
        mu, log_var = args
        epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)
        return mu + K.exp(log_var / 2) * self.epsilon

def build_autoencoder(latent_dim_size):
    # Enocder 
    input_img = L.Input(shape=(224,224,1), name='image_input')
    x = L.Conv2D(32, (3,3), strides=(2,2), padding='same', name='Conv1')(input_img)
    x = L.BatchNormalization(name=""bn1"", axis=-1)(x)
    x = L.Activation(""relu"")(x)
    x = L.Dropout(0.25)(x)
    
    x = L.Conv2D(64, (3,3), strides=(2,2), padding='same', name='Conv2')(x)
    x = L.BatchNormalization(name=""bn2"", axis=-1)(x)
    x = L.Activation(""relu"")(x)

    shape_before_flattening = x.shape[1:]
    
    x = L.Flatten()(x)
    mu = L.Dense(latent_dim_size, name='mu')(x)
    log_var = L.Dense(latent_dim_size, name='log_var')(x)
     
    # This doesn't work!
    encoder_output = Sampling(mu.shape[1:], name=""encoder_output"")([mu, log_var])
    
    #############################################################

    # Decoder
    x = L.Dense(np.prod(shape_before_flattening))(encoder_output)
    x = L.Reshape(shape_before_flattening)(x)

    x = L.Conv2D(64, (3,3), padding='same', name='Conv3')(x)
    x = L.BatchNormalization(name=""bn3"", axis=-1)(x)
    x = L.Activation(""relu"")(x)
    x = L.UpSampling2D((2,2), name='upsample1')(x)

    x = L.Conv2D(32, (3,3), padding='same', name='Conv4')(x)
    x = L.BatchNormalization(name=""bn4"", axis=-1)(x)
    x = L.Activation(""relu"")(x)
    x = L.UpSampling2D((2,2), name='upsample2')(x)
    
    x = L.Conv2D(1, (3,3), padding='same', name='Conv5')(x)
    x = L.Activation(""sigmoid"")(x)

    #############################################################

    ae = Model(input_img, x, name=""autoencoder"")
    return ae, mu, log_var

ae, mu, log_var = build_autoencoder(latent_dim_size=200)
ae.summary()

def loss_fn(y_true, y_pred):
    r_loss = K.mean(K.square(y_true - y_pred), axis = [1,2,3])
    return r_loss

optimizer = tf.keras.optimizers.Adam(lr=0.0001)
ae.compile(optimizer=optimizer, loss=loss_fn,  metrics = [loss_fn])
ae.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=batch_size)
```
**Other info / logs**
```
TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: log_var_12/Identity:0

During handling of the above exception, another exception occurred:
```
"
33998,tf.tensor_scatter_nd_update() doesn't work in custom layer/graph to update a  2D Tensor with indices,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.04**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **NA**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **2.0**
- Python version: **3.7**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:*10.0/7.3.0*                                                                                                                    
                                                                                                                                                              
                                                                    **
- GPU model and memory: GeForce 940m

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**  ValueError: Shape must be at least rank 1 but is rank 0 for 'TensorScatterUpdate' (op: 'TensorScatterUpdate') with input shapes: [64,64], [2], [].

**Describe the expected behavior** : it should update the tensor given the row, column position

**Code to reproduce the issue**
**The following code is part of the custom layer and written in call function, the layer is not trainable hence I used Tensor instead of tf.Variable, size of sub_sub_mapl Tensor is 64,64, temp_val will be scalar, and m, n are a row & column position to be updated**

                 ```
 temp_val = tf.convert_to_tensor(
                    tf.add(tf.math.reduce_max(mat[i, j:j + 2]), tf.math.reduce_max(mat[i, l:l + 2])) / 2)
                  indices = tf.constant([m, n], dtype=tf.int32)
                  tf.tensor_scatter_nd_update(self.sub_sub_mapl, indices, temp_val)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Traceback (most recent call last):
  File ""F:/pom/pom_cust_layer_parallel_v5.py"", line 93, in <module>
    tf.keras.layers.Dense(num_classes, activation='softmax')])
  File ""F:\tf2venv\lib\site-packages\tensorflow_core\python\training\tracking\base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""F:\tf2venv\lib\site-packages\tensorflow_core\python\keras\engine\sequential.py"", line 114, in __init__
    self.add(layer)
  File ""F:\tf2venv\lib\site-packages\tensorflow_core\python\training\tracking\base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""F:\tf2venv\lib\site-packages\tensorflow_core\python\keras\engine\sequential.py"", line 196, in add
    output_tensor = layer(self.outputs[0])
  File ""F:\tf2venv\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 842, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""F:\tf2venv\lib\site-packages\tensorflow_core\python\autograph\impl\api.py"", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:
    relative to F::

    pom/pom_cust_layer_parallel_v5.py:71 call  *
        self.MAPL = tf.map_fn(fn=self.get_avg_pool, elems=input)
    tf2venv\lib\site-packages\tensorflow_core\python\ops\map_fn.py:268 map_fn
        maximum_iterations=n)
    tf2venv\lib\site-packages\tensorflow_core\python\ops\control_flow_ops.py:2675 while_loop
        back_prop=back_prop)
    tf2venv\lib\site-packages\tensorflow_core\python\ops\while_v2.py:198 while_loop
        add_control_dependencies=add_control_dependencies)
    tf2venv\lib\site-packages\tensorflow_core\python\framework\func_graph.py:915 func_graph_from_py_func
        func_outputs = python_func(*func_args, **func_kwargs)
    tf2venv\lib\site-packages\tensorflow_core\python\ops\while_v2.py:176 wrapped_body
        outputs = body(*_pack_sequence_as(orig_loop_vars, args))
    tf2venv\lib\site-packages\tensorflow_core\python\ops\map_fn.py:257 compute
        packed_fn_values = fn(packed_values)
    pom/pom_cust_layer_parallel_v5.py:62 get_avg_pool
        self.sub_mapl = tf.map_fn(fn=self.get_avg_pool_channel, elems=mat_unstacked)
    tf2venv\lib\site-packages\tensorflow_core\python\ops\map_fn.py:268 map_fn
        maximum_iterations=n)
    tf2venv\lib\site-packages\tensorflow_core\python\ops\control_flow_ops.py:2675 while_loop
        back_prop=back_prop)
    tf2venv\lib\site-packages\tensorflow_core\python\ops\while_v2.py:198 while_loop
        add_control_dependencies=add_control_dependencies)
    tf2venv\lib\site-packages\tensorflow_core\python\framework\func_graph.py:915 func_graph_from_py_func
        func_outputs = python_func(*func_args, **func_kwargs)
    tf2venv\lib\site-packages\tensorflow_core\python\ops\while_v2.py:176 wrapped_body
        outputs = body(*_pack_sequence_as(orig_loop_vars, args))
    tf2venv\lib\site-packages\tensorflow_core\python\ops\map_fn.py:257 compute
        packed_fn_values = fn(packed_values)
    pom/pom_cust_layer_parallel_v5.py:50 get_avg_pool_channel
        tf.tensor_scatter_nd_update(self.sub_sub_mapl, indices, temp_val)
    tf2venv\lib\site-packages\tensorflow_core\python\ops\gen_array_ops.py:11087 tensor_scatter_update
        updates=updates, name=name)
    tf2venv\lib\site-packages\tensorflow_core\python\framework\op_def_library.py:793 _apply_op_helper
        op_def=op_def)
    tf2venv\lib\site-packages\tensorflow_core\python\framework\func_graph.py:548 create_op
        compute_device)
    tf2venv\lib\site-packages\tensorflow_core\python\framework\ops.py:3429 _create_op_internal
        op_def=op_def)
    tf2venv\lib\site-packages\tensorflow_core\python\framework\ops.py:1773 __init__
        control_input_ops)
    tf2venv\lib\site-packages\tensorflow_core\python\framework\ops.py:1613 _create_c_op
        raise ValueError(str(e))
"
33997,[TF 2.0] 'Unknown graph' error when using tf.function decorator with pre-trained models,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-rc0
- Python version: 3.6.9
- CUDA/cuDNN version: 10.0
- GPU model and memory: GTX 1050 Ti

**Describe the current behavior**
If I remove the `@tf.function` decorator, the error disappears. Facing this error when I created the loss function where feature extraction with the pre-trained VGG16 is a step in the pipeline.

> ValueError: Unknown graph. Aborting.

**Code to reproduce the issue**
```
""""""
Reproduce the error of keras pretrain model with tf.function wrapper in TF 2.0
""""""

import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
import numpy as np


@tf.function
def extract_feat(feat_extractor, _input):
    feat = feat_extractor.predict(_input, steps=1)
    return feat


def main():
    pretrain_vgg16 = VGG16(weights='imagenet', include_top=False)
    feature_extractor = Model(inputs=pretrain_vgg16.input, outputs=pretrain_vgg16.get_layer('block3_conv3').output)

    # create an dummy input
    _input = np.random.rand(1, 224, 224, 3) - 0.5 / 0.5

    feat = extract_feat(feature_extractor, _input)
    print(feat.shape)


if __name__ == '__main__':
    main()
```

**Other info / logs**
```
2019-11-05 12:03:34.045339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-11-05 12:03:34.066201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 12:03:34.066747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
2019-11-05 12:03:34.066896: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-05 12:03:34.067713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-05 12:03:34.068423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-05 12:03:34.068599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-05 12:03:34.069586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-05 12:03:34.070296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-05 12:03:34.072541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-05 12:03:34.072620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 12:03:34.073192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 12:03:34.073714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-05 12:03:34.073892: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-05 12:03:34.101732: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2208000000 Hz
2019-11-05 12:03:34.102528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557c6a90fd40 executing computations on platform Host. Devices:
2019-11-05 12:03:34.102541: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-05 12:03:34.167039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 12:03:34.167648: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557c6a942ac0 executing computations on platform CUDA. Devices:
2019-11-05 12:03:34.167662: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2019-11-05 12:03:34.167802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 12:03:34.168336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
2019-11-05 12:03:34.168363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-05 12:03:34.168374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-05 12:03:34.168384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-05 12:03:34.168393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-05 12:03:34.168403: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-05 12:03:34.168412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-05 12:03:34.168421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-05 12:03:34.168455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 12:03:34.168990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 12:03:34.169514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-05 12:03:34.169538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-05 12:03:34.170424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-05 12:03:34.170433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-11-05 12:03:34.170437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-11-05 12:03:34.170550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 12:03:34.171093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-05 12:03:34.171631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2787 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""/home/biendltb/Projects/derain_gan/tools/error_reproduce.py"", line 29, in <module>
    main()
  File ""/home/biendltb/Projects/derain_gan/tools/error_reproduce.py"", line 24, in main
    feat = extract_feat(feature_extractor, _input)
  File ""/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 427, in __call__
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 370, in _initialize
    *args, **kwds))
  File ""/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1847, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2147, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2038, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 320, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 905, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:
    relative to /home/biendltb:

    Projects/derain_gan/tools/error_reproduce.py:13 extract_feat  *
        feat = feat_extractor.predict(_input, steps=1)
    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py:915 predict
        use_multiprocessing=use_multiprocessing)
    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py:722 predict
        callbacks=callbacks)
    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py:189 model_iteration
        f = _make_execution_function(model, mode)
    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py:565 _make_execution_function
        return model._make_execution_function(mode)
    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py:2155 _make_execution_function
        self._make_predict_function()
    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py:2145 _make_predict_function
        **kwargs)
    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:3658 function
        return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)
    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:3542 __init__
        raise ValueError('Unknown graph. Aborting.')

    ValueError: Unknown graph. Aborting.
```
"
33996,different gpu to each session in a thread,"tensorflow c API：I want to create multiple sessions for different models in a thread, how to assign a different gpu to each session.
"
33995,ResourceExhausted while doing K-fold cross-validation regardless of the chosen K,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
windows 10
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
Tensorflow 2.0.0
- Python version: 
3.7
- CUDA/cuDNN version: CUDA 10, cuDNN 7.6
- GPU model and memory: Titan V 12GB

**Describe the current behavior**
ResourceExhausted at last K fold of a K-fold cross-validation. Regardless of the K chosen. I've tried
3 fold, 5 fold and 10 fold and it always happens at the last fold.

**Code to reproduce the issue**
`
for j, (train_indices, val_indices) in enumerate(kf.split(datos_random)):

    train = datos.iloc[train_indices]
    val = datos.iloc[val_indices]    

    metrics = ['accuracy']
    model = build_model(DROPOUT, FC_LAYERS, num_classes=NUM_CLASSES, opt=OPT, metrics=metrics)

    train_datagen =  keras.preprocessing.image.ImageDataGenerator(
        preprocessing_function=preprocess_input,
        horizontal_flip=True,
        vertical_flip=True,
        # rotation_range=25,
        fill_mode='constant'
        
    )
    
    test_datagen = keras.preprocessing.image.ImageDataGenerator(
        preprocessing_function=preprocess_input,
    )
    
    train_generator = train_datagen.flow_from_dataframe(
                                          train,
                                          None,
                                          x_col='file',
                                          target_size=(WIDTH, HEIGHT),
                                          y_col=f'Class_cat_{NUM_CLASSES}', 
                                          batch_size=BATCH_SIZE, 
                                          seed=SEED,
                                          has_ext=True,class_mode='categorical')

    
    test_generator = test_datagen.flow_from_dataframe(val, 
                                          None, 
                                          x_col='file', 
                                          target_size=(WIDTH, HEIGHT),
                                          y_col=f'Class_cat_{NUM_CLASSES}', 
                                          batch_size=BATCH_SIZE,
                                          seed=SEED,
                                          has_ext=True,
                                          class_mode='categorical', 
                                          shuffle=True)
    class_list = list(test_generator.class_indices.keys())
   
    checkpoint = keras.callbacks.ModelCheckpoint(name_weights, 
                                                 monitor=""val_accuracy"", 
                                                 verbose=1, 
                                                 mode='max', 
                                                 save_best_only=True)
    callbacks_list = [
                      checkpoint, 
                      keras.callbacks.CSVLogger(os.path.join(fold_dir, 'log.csv'))
    ]
    print('Iniciando entrenamiento')
    history = model.fit(train_generator, 
                        epochs=EPOCHS, 
                        workers=16, 
                        shuffle=True, 
                        callbacks=callbacks_list, 
                        verbose=1, 
                        steps_per_epoch=math.ceil(len(train_indices) / BATCH_SIZE),
                        validation_data=test_generator, 
                        validation_steps=math.ceil(len(val_indices) / BATCH_SIZE)
                                 )
    
    acc = history.history['accuracy']
    val_accuracy = history.history['val_accuracy']

    loss = history.history['loss']
    val_loss = history.history['val_loss']
    
    avg_loss.append(val_loss[-1])
    avg_acc.append(val_accuracy[-1]*100)
                                      
    model.save(os.path.join(fold_dir, 'model.h5')) `
`

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
`
ResourceExhaustedError: 2 root error(s) found.
  (0) Resource exhausted: OOM when allocating tensor with shape[128,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node block1_conv2_8/Conv2D}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

  (1) Resource exhausted: OOM when allocating tensor with shape[128,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node block1_conv2_8/Conv2D}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[metrics_16/accuracy/Identity/_3869]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored.
`"
33994,TOCO failed,"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, AVERAGE_POOL_2D, CONCATENATION, CONV_2D, FLOOR, FULLY_CONNECTED, L2_NORMALIZATION, MAX_POOL_2D, MUL, PACK, RELU, RESHAPE, RSQRT, SHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: BatchNormalization, Merge, RandomUniform, Switch."
33993,tensorflow lite performance,"**System information**
- OS Platform and Distribution : Windows10
- TensorFlow installed from : binary
- TensorFlow version : 2.0


**How**
- How to improve the performance for running tensorflow lite model in my ARM cortex-M devices?
Someone change standard C/C++ lib (for example using inline function to reduce the time) to improve performance. Could you please give me some advice to figure out that?

"
33991,Autograph error in LSTMCell when using dropout,"**System information**
- Have I written custom code: no
- OS Platform and Distribution: Manjaro linux testing
- TensorFlow installed from: pip binary
- TensorFlow version: v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.7.4
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
TensorFlow returns an error when decorating functions calling `LSTMCell.call` with `@tf.function` if dropout is non-zero (most common scenario).
```
TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: lstm_cell_1/ones_like:0
```

**Describe the expected behavior**
Compile the LSTMCell code correctly

**Code to reproduce the issue**
```
import tensorflow as tf


good_cell = tf.keras.layers.LSTMCell(units=2, dropout=0.0, implementation=1)
bad_cell = tf.keras.layers.LSTMCell(units=2, dropout=0.1, implementation=1)
inputs = tf.ones((1, 2))

state = good_cell.get_initial_state(inputs)

@tf.function
def no_dropout():
    output = good_cell(inputs, state)
    return output

@tf.function
def dropout():
    output = bad_cell(inputs, state)
    return output

print('='*50)
print(no_dropout())
print('='*50)
print(dropout())
```

**Other info / logs**
I did a quick investigation and found out that setting `self._dropout_mask = None` [at the top of the call method](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/recurrent.py#L2210) makes the code work again. This forces the reset of the cached dropout mask used at the previous/first call of LSTMCell.
"
33989,module 'tensorflow' has no attribute 'AdamOptimizer',"## Docs URL
https://www.tensorflow.org/api_docs/python/tf/estimator/DNNRegressor

## Tensorflow Version (that I'm using);
2.0.0

## Issue
I'm trying to create an ""estimator using an optimizer with a learning rate decay"". The documentation says to use `tf.AdamOptimizer`, `tf.exponential_decay`, and `tf.get_global_step`. Tensorflow has none of those attributes. I've tried playing around with suggestions from stack overflow (ie -- tf.train.AdamOptimizer), but I can't figure out where any of those attributes are actually located.

example code
```
model= tf.estimator.DNNRegressor(
    feature_columns=feature_columns,
    hidden_units = [100, 100, 100],
    optimizer=lambda: tf.AdamOptimizer(
        learning_rate=tf.exponential_decay(
            learning_rate=0.1,
            global_step=tf.get_global_step(),
            decay_steps=10000,
            decay_rate=0.96
        )
    )
)
```
"
33988,Keras .fit() yields incorrect results when using a custom loss function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow version (use command below): 2.0.0

**Describe the current behavior**
When using a custom loss function, Keras' `.fit()` produces incorrect results.

**Code to reproduce the issue**
See this [Colab Notebook](https://colab.research.google.com/drive/1Q5hVfxVKdeqtIPWrYuvsPQ-IE0dUOeWO)."
33987,Update `nogpu` tag references to be `no_gpu` instead?,"Currently the scripts used to run TF unit tests on the ROCm platform filter out tests that are tagged with the `no_gpu` tag

* https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/linux/rocm/run_cc_core.sh
* https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/linux/rocm/run_csb_tests.sh
* https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/linux/rocm/run_py3_core.sh
* https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/xla/linux/rocm/run_py3.sh

The same applies for scripts for the CUDA platform as well.

There seem to be some tests that are tagged with the `nogpu` tag instead of the `no_gpu` tag.
One example is 

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tpu/tpu.bzl#L44

Such tests do not get filtered out by the test scripts above, and as a consequence they get reported as regression failures when those test scripts are run.

So the question here is 
* should we update all references to the `nogpu` tag to instead be `no_gpu`
OR
* should we update all the scripts instead to also filter out the `nogpu` tagged tests?

-----------------------

@chsigg 
"
33986,Errors when instantiating multiple tf.keras models on different threads concurrently,"**System information**
I am running custom code on a MacBook Pro running Mac OS Mojave 10.14.6:
```
 Model Name:	MacBook Pro
  Model Identifier:	MacBookPro15,1
  Processor Name:	Intel Core i9
  Processor Speed:	2.3 GHz
  Number of Processors:	1
  Total Number of Cores:	8
  L2 Cache (per Core):	256 KB
  L3 Cache:	16 MB
  Hyper-Threading Technology:	Enabled
  Memory:	16 GB
```

I am running Python 3.7.3 installed via homebrew and Tensorflow 2.0.0 (v2.0.0-rc2-26-g64c3d382ca 2.0.0) installed via pip.

**Describe the current behavior**

When instantiating multiple `tf.keras.Sequential` models concurrently on different threads, I sometimes get errors in certain calls within `site-packages/tensorflow_core/python/framework/ops.py`. Tracebacks are included below.

**Describe the expected behavior**

Expected behavior is that multiple tf.keras models can be instantiated on multiple threads without conflict.

**Code to reproduce the issue + Other info / logs**

The error that I am getting in my development code is this:

```
Traceback (most recent call last):
...
  File ""/Users/josephcappadona/Documents/demo/demo/models/models.py"", line 24, in __init__
    super().__init__([logit_layer, activation_layer], name)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py"", line 114, in __init__
    self.add(layer)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py"", line 174, in add
    batch_shape=batch_shape, dtype=dtype, name=layer.name + '_input')
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_layer.py"", line 263, in Input
    input_tensor=tensor)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_layer.py"", line 125, in __init__
    ragged=ragged)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py"", line 1057, in placeholder
    x = array_ops.placeholder(dtype, shape=shape, name=name)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 2630, in placeholder
    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py"", line 6671, in placeholder
    ""Placeholder"", dtype=dtype, shape=shape, name=name)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper
    op_def=op_def)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 548, in create_op
    compute_device)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3430, in _create_op_internal
    self._create_op_helper(ret, compute_device=compute_device)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3469, in _create_op_helper
    for key, value in self._attr_scope_map.items():
RuntimeError: dictionary changed size during iteration
```
however I cannot reproduce this error reliably. It seems to happen a very small percentage of the time, making debugging it very difficult. Essentially, this happens when running a Flask app in which multiple models are instantiated concurrently across different threads at the same time.

In trying to write some code that reproduces something similar so that I could include something in this issue, I was able to use this code
```python
import tensorflow as tf
from threading import Thread

def build_model():
    layer_1 = tf.keras.layers.Dense(1, input_shape=(20,))
    layer_2 = tf.keras.layers.Activation(tf.sigmoid)
    tf.keras.Sequential([layer_1, layer_2])

for i in range(100):
    t = Thread(target=build_model)
    t.start()
```

in a jupyter notebook to generate this error

```
Exception in thread Thread-369:
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py"", line 917, in _bootstrap_inner
    self.run()
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py"", line 865, in run
    self._target(*self._args, **self._kwargs)
  File ""<ipython-input-8-c7ffb35bc6af>"", line 4, in build_model
    tf.keras.Sequential([layer_1, layer_2])
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py"", line 114, in __init__
    self.add(layer)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py"", line 196, in add
    output_tensor = layer(self.outputs[0])
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 845, in __call__
    outputs = base_layer_utils.mark_as_return(outputs, acd)
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/framework/auto_control_deps.py"", line 300, in __exit__
    if op.type == ""Switch"" and op.inputs[0].dtype == dtypes_module.resource:
  File ""/Users/josephcappadona/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 2259, in type
    return c_api.TF_OperationOpType(self._c_op)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xf2 in position 0: invalid continuation byte
```
which, while obviously is a different error, also happens in `tensorflow_core/python/framework/ops.py` and also involves the use of an instance variable (in this case `self._c_op`).

Please let me know if there's any other information I need to provide to help debug. I assume this has something to do with shared global state across a tensorflow session, but I'm not sure if there is something that I am supposed to do to prevent these types of errors."
33985,Unable to get_layer by name on custom layer and lambda layer,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macos mohave
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tensorflow==2.0.0
- TensorFlow version (use command below): pip install tensorflow==2.0.0
- Python version: python3.7
- Bazel version (if compiling from source):  -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**

get_layer raises exception

**Describe the expected behavior**

Should pass and not raise exception.

    ValueError: No such layer: embeddings

**Code to reproduce the issue**

import tensorflow as tf


```python
import tensorflow as tf

class L2NormalizeLayer(tf.keras.layers.Layer):
    def __init__(self, name=""normalize"", **kwargs):
        super(L2NormalizeLayer, self).__init__(name=name, **kwargs)

    def call(self, input):
        return tf.keras.backend.l2_normalize(input, axis=1)

    def get_config(self):
        config = super(L2NormalizeLayer, self).get_config()
        return config

shape = (224, 224, 3)

# functional model
base_model2 = tf.keras.applications.MobileNetV2(include_top=False, weights=""imagenet"", input_shape=shape)
inputs = tf.keras.Input(shape=shape, name=""input"")
x = base_model2(inputs)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(256, activation=""relu"")(x)
y = L2NormalizeLayer(name=""embeddings"")(x)
#y = tf.keras.layers.Lambda(lambda k: tf.keras.backend.l2_normalize(k, axis=1), name=""embeddings"")(x)
outputs = tf.keras.layers.Dense(2, activation=""softmax"", name=""probs"")(x)
model2 = tf.keras.Model(inputs=inputs, outputs=outputs)

# after training model i would like to load it and extract probs with embeddings
tf.keras.models.save_model(model2, ""model.h5"")
model_l2 = tf.keras.models.load_model(""model.h5"")

model_loaded = tf.keras.Model(
    inputs=model_l2.input, outputs=[model_l2.get_layer(layer_name).output for layer_name in [""probs"", ""embeddings""]]
)
```

**Other info / logs**

```
19:29:07.817639: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-04 19:29:07.832947: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa8ada42530 executing computations on platform Host. Devices:
2019-11-04 19:29:07.832973: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
Traceback (most recent call last):
  File ""save2.py"", line 36, in <module>
    inputs=model_l2.input, outputs=[model_l2.get_layer(layer_name).output for layer_name in [""probs"", ""embeddings""]]
  File ""save2.py"", line 36, in <listcomp>
    inputs=model_l2.input, outputs=[model_l2.get_layer(layer_name).output for layer_name in [""probs"", ""embeddings""]]
  File ""/Users/michallukac/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 539, in get_layer
    raise ValueError('No such layer: ' + name)
ValueError: No such layer: embeddings
```"
33984,Failed to convert object of type <class 'tensorflow.python.ops.init_ops_v2.RandomNormal'> to Tensor,"This problem relates to adapting existing code from previous TensorFlow versions to use Bayesian probability estimation in Dense layers. 

[Original code is here](http://krasserm.github.io/2019/03/14/bayesian-neural-networks/)

The function for tensorflow 1.12 + keras 2.2.2 is as follows:

```
from keras import backend as K
from keras import activations, initializers
from keras.layers import Layer
import tensorflow as tf

def mixture_prior_params(sigma_1, sigma_2, pi, return_sigma=False):
    params = K.variable([sigma_1, sigma_2, pi], name='mixture_prior_params')
    sigma = np.sqrt(pi * sigma_1 ** 2 + (1 - pi) * sigma_2 ** 2)
    return params, sigma

def log_mixture_prior_prob(w):
    comp_1_dist = tf.distributions.Normal(0.0, prior_params[0])
    comp_2_dist = tf.distributions.Normal(0.0, prior_params[1])
    comp_1_weight = prior_params[2]    
    return K.log(comp_1_weight * comp_1_dist.prob(w) + (1 - comp_1_weight) * comp_2_dist.prob(w))    

# Mixture prior parameters shared across DenseVariational layer instances
prior_params, prior_sigma = mixture_prior_params(sigma_1=1.0, sigma_2=0.1, pi=0.2)

class DenseVariational(Layer):
    def __init__(self, output_dim, kl_loss_weight, activation=None, **kwargs):
        self.output_dim = output_dim
        self.kl_loss_weight = kl_loss_weight
        self.activation = activations.get(activation)
        super().__init__(**kwargs)

    def build(self, input_shape):  
        self._trainable_weights.append(prior_params) 

        self.kernel_mu = self.add_weight(name='kernel_mu', 
                                         shape=(input_shape[1], self.output_dim),
                                         initializer=initializers.normal(stddev=prior_sigma),
                                         trainable=True)
        self.bias_mu = self.add_weight(name='bias_mu', 
                                       shape=(self.output_dim,),
                                       initializer=initializers.normal(stddev=prior_sigma),
                                       trainable=True)
        self.kernel_rho = self.add_weight(name='kernel_rho', 
                                          shape=(input_shape[1], self.output_dim),
                                          initializer=initializers.constant(0.0),
                                          trainable=True)
        self.bias_rho = self.add_weight(name='bias_rho', 
                                        shape=(self.output_dim,),
                                        initializer=initializers.constant(0.0),
                                        trainable=True)
        super().build(input_shape)

    def call(self, x):
        kernel_sigma = tf.math.softplus(self.kernel_rho)
        kernel = self.kernel_mu + kernel_sigma * tf.random.normal(self.kernel_mu.shape)

        bias_sigma = tf.math.softplus(self.bias_rho)
        bias = self.bias_mu + bias_sigma * tf.random.normal(self.bias_mu.shape)
                
        self.add_loss(self.kl_loss(kernel, self.kernel_mu, kernel_sigma) + 
                      self.kl_loss(bias, self.bias_mu, bias_sigma))
        
        return self.activation(K.dot(x, kernel) + bias)

    def compute_output_shape(self, input_shape):
        return (input_shape[0], self.output_dim)
    
    def kl_loss(self, w, mu, sigma):
        variational_dist = tf.distributions.Normal(mu, sigma)
        return self.kl_loss_weight * K.sum(variational_dist.log_prob(w) - log_mixture_prior_prob(w))
```

To get this working for Tensorflow 2.0, I've got the following:

```
import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras import activations, initializers
from tensorflow.keras.layers import Layer
import tensorflow_probability as tfp

def mixture_prior_params(sigma_1, sigma_2, pi, return_sigma=False):
    params = K.variable([sigma_1, sigma_2, pi], name='mixture_prior_params')
    sigma = np.sqrt(pi * sigma_1 ** 2 + (1 - pi) * sigma_2 ** 2)
    return params, sigma

def log_mixture_prior_prob(w):
    comp_1_dist = tfp.distributions.Normal(0.0, prior_params[0])
    comp_2_dist = tfp.distributions.Normal(0.0, prior_params[1])
    comp_1_weight = prior_params[2]
    return K.log(comp_1_weight * comp_1_dist.prob(w) + (1 - comp_1_weight) * comp_2_dist.prob(w))

# Mixture prior parameters shared across DenseVariational layer instances
prior_params, prior_sigma = mixture_prior_params(sigma_1=1.0, sigma_2=0.1, pi=0.2)

class DenseVariational(Layer):
    def __init__(self, output_dim, kl_loss_weight, activation=None, **kwargs):
        self.output_dim = output_dim
        self.kl_loss_weight = kl_loss_weight
        self.activation = activations.get(activation)
        super().__init__(**kwargs)
        
    def build(self, input_shape):
        self._trainable_weights.append(prior_params)
        self.kernel_mu = self.add_weight(name='kernel_mu', shape=(input_shape[1], self.output_dim), initializer=tf.random_normal_initializer(stddev=prior_sigma), trainable=True)
        self.bias_mu = self.add_weight(name='bias_mu', shape=(self.output_dim,), initializer=tf.random_normal_initializer(stddev=prior_sigma), trainable=True)
        self.kernel_rho = self.add_weight(name='kernel_rho', shape=(input_shape[1], self.output_dim), initializer=tf.constant_initializer(0.0), trainable=True)
        self.bias_rho = self.add_weight(name='bias_rho', shape=(self.output_dim,), initializer=tf.constant_initializer(0.0), trainable=True)
        super().build(input_shape)
        
    def call(self, x):
        kernel_sigma = tf.math.softplus(self.kernel_rho)
        kernel = self.kernel_mu + kernel_sigma * tf.random_normal_initializer(self.kernel_mu.shape)
        bias_sigma = tf.math.softplus(self.bias_rho)
        bias = self.bias_mu + bias_sigma * tf.random_normal_initializer(self.bias_mu.shape)
        self.add_loss(self.kl_loss(kernel, self.kernel_mu, kernel_sigma) + self.kl_loss(bias, self.bias_mu, bias_sigma))
        return self.activation(K.dot(x, kernel) + bias)
        
    def compute_output_shape(self, input_shape):
        return (input_shape[0], self.output_dim)
        
    def kl_loss(self, w, mu, sigma):
        variational_dist = tfp.distributions.Normal(mu, sigma)
        return self.kl_loss_weight * K.sum(variational_dist.log_prob(w) - log_mixture_prior_prob(w))
       
```

However, when I try to add this layer with the following code in a sequential model:

`model.add(DenseVariational(128, kl_loss_weight=kl_loss_weight, activation='relu'))
`
I get the following error:

> WARNING:tensorflow:Entity <bound method DenseVariational.call of <__main__.DenseVariational object at 0x7f0cf1837b10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DenseVariational.call of <__main__.DenseVariational object at 0x7f0cf1837b10>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
> WARNING: Entity <bound method DenseVariational.call of <__main__.DenseVariational object at 0x7f0cf1837b10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DenseVariational.call of <__main__.DenseVariational object at 0x7f0cf1837b10>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""/home/bly/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
>     result = method(self, *args, **kwargs)
>   File ""/home/bly/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py"", line 196, in add
>     output_tensor = layer(self.outputs[0])
>   File ""/home/bly/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 842, in __call__
>     outputs = call_fn(cast_inputs, *args, **kwargs)
>   File ""/home/bly/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 237, in wrapper
>     raise e.ag_error_metadata.to_exception(e)
> TypeError: in converted code:
> 
>     <stdin>:18 call
>         
>     /home/bly/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py:903 binary_op_wrapper
>         y, dtype_hint=x.dtype.base_dtype, name=""y"")
>     /home/bly/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1242 convert_to_tensor_v2
>         as_ref=False)
>     /home/bly/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1296 internal_convert_to_tensor
>         ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
>     /home/bly/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py:286 _constant_tensor_conversion_function
>         return constant(v, dtype=dtype, name=name)
>     /home/bly/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py:227 constant
>         allow_broadcast=True)
>     /home/bly/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py:265 _constant_impl
>         allow_broadcast=allow_broadcast))
>     /home/bly/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py:545 make_tensor_proto
>         ""supported type."" % (type(values), values))
> 
>     TypeError: Failed to convert object of type <class 'tensorflow.python.ops.init_ops_v2.RandomNormal'> to Tensor. Contents: <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7f0f8c54cd90>. Consider casting elements to a supported type.

The problem lies in the use of tf.random_normal_initializer in place of the earlier initializers.normal. I am not sure how to resolve this - I can't see a direct replacement for this in the Tensorflow 2.0 documentation. "
33983,Build error in Macbook (tensorflow lite),"- OS Platform and Distribution Macbook
- TensorFlow installed from (source or binary): github latest bf282dece59bdf88f7a58bcf1064723cb3eea51e 
- TensorFlow version:trunk
- Bazel version (if compiling from source):  1.0.0-homebrew
- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.8)

Run ./tensorflow/lite/tools/make/build_lib.sh or ./tensorflow/lite/tools/make/build_ios_universal_lib.sh
Same build problem:

g++ -O3 -DNDEBUG -fPIC  --std=c++11 -I. -I/Users/kmok/workspaces/tensorflow/tensorflow/lite/tools/make/../../../../../ -I/Users/kmok/workspaces/tensorflow/tensorflow/lite/tools/make/../../../../../../ -I/Users/kmok/workspaces/tensorflow/tensorflow/lite/tools/make/downloads/ -I/Users/kmok/workspaces/tensorflow/tensorflow/lite/tools/make/downloads/eigen -I/Users/kmok/workspaces/tensorflow/tensorflow/lite/tools/make/downloads/absl -I/Users/kmok/workspaces/tensorflow/tensorflow/lite/tools/make/downloads/gemmlowp -I/Users/kmok/workspaces/tensorflow/tensorflow/lite/tools/make/downloads/neon_2_sse -I/Users/kmok/workspaces/tensorflow/tensorflow/lite/tools/make/downloads/farmhash/src -I/Users/kmok/workspaces/tensorflow/tensorflow/lite/tools/make/downloads/flatbuffers/include -I -I/usr/local/include -c tensorflow/lite/experimental/ruy/block_map.cc -o /Users/kmok/workspaces/tensorflow/tensorflow/lite/tools/make/gen/osx_x86_64/obj/tensorflow/lite/experimental/ruy/block_map.o
In file included from tensorflow/lite/core/api/op_resolver.cc:16:
In file included from ./tensorflow/lite/core/api/op_resolver.h:20:
**./tensorflow/lite/schema/schema_generated.h:2660:8: error: ISO C++ forbids forward references to 'enum' types**
In file included from tensorflow/lite/core/api/flatbuffer_conversions.cc:  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
16:
       ^In file included from 
./tensorflow/lite/core/api/flatbuffer_conversions.h:24:
In file included from ./tensorflow/lite/core/api/op_resolver.h:20:
**./tensorflow/lite/schema/schema_generated.h:2660:8: error: ISO C++ forbids forward references to 'enum' types**
**./tensorflow/lite/schema/schema_generated.h:2660:32: error: field has incomplete type 'enum FlatBuffersVTableOffset'**
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
       ^
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
"
33980,Shared library libtensorflowlite.so cannot be found after building from source,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 x86 64 bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): docker image devel-gpu-py3
- TensorFlow version (use command below):
- Python version: 3.6
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version:
- GPU model and memory: 

**Describe the current behavior**

Goal is to build TF Lite with the extended runtime to support non-tf-ops. For this I followed the steps from the official guide (https://www.tensorflow.org/lite/guide/ops_select#c). I added the missing flex delegate dependencies to `/tensorflow_src/tensorflow/lite/BUILD`:

```
tflite_cc_shared_object(
    name = ""libtensorflowlite.so"",
    linkopts = select({
        ""//tensorflow:macos"": [
            ""-Wl,-exported_symbols_list,$(location //tensorflow/lite:tflite_exported_symbols.lds)"",
            ""-Wl,-install_name,@rpath/libtensorflowlite.so"",
        ],
        ""//tensorflow:windows"": [],
        ""//conditions:default"": [
            ""-z defs"",
            ""-Wl,--version-script,$(location //tensorflow/lite:tflite_version_script.lds)"",
        ],
    }),
    deps = [
        "":framework"",
        "":tflite_exported_symbols.lds"",
        "":tflite_version_script.lds"",
        ""//tensorflow/lite/kernels:builtin_ops"",
        ""//tensorflow/lite/delegates/flex:delegate"",
    ],
)
```
I ran the configure script with defaults only and the bazel build command with the mentioned options:

```
bazel build --config=monolithic --define=with_select_tf_ops=true -c opt //tensorflow/lite:libtensorflowlite.so
```
This builds without errors. When building my C++ app, it also compiles without errors. But when executing the binary, I get an error:

```
./myapp: error while loading shared libraries: libtensorflowlite.so: cannot open shared object file: No such file or directory
```
This is not a path problem because it lies in the same directory as my other .so files. The app works when using the static library generated by the shell scripts in the same directory.

**Describe the expected behavior**

The app should run just fine with the paths specified.

**Other info / logs**

**.tf_configure.bazel_rc**
```
build --action_env PYTHON_BIN_PATH=""/usr/local/bin/python""
build --action_env PYTHON_LIB_PATH=""/usr/local/lib/python3.6/dist-packages""
build --python_path=""/usr/local/bin/python""
build:xla --define with_xla_support=true
build --config=xla
build --config=tensorrt
build --action_env TF_CUDA_VERSION=""10.0""
build --action_env TF_CUDNN_VERSION=""7""
build --action_env CUDA_TOOLKIT_PATH=""/usr/local/cuda-10.0""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""3.5,5.2,6.0,6.1,7.0""
build --action_env LD_LIBRARY_PATH=""/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64""
build --action_env GCC_HOST_COMPILER_PATH=""/usr/bin/gcc""
build --config=cuda
build:opt --copt=-march=native
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_tag_filters=-benchmark-test,-no_oss,-oss_serial
test --build_tag_filters=-benchmark-test,-no_oss
test --test_tag_filters=-no_gpu
test --build_tag_filters=-no_gpu
test --test_env=LD_LIBRARY_PATH
build --action_env TF_CONFIGURE_IOS=""0""
```
"
33979,Crash with MultiWorkerMirroredStrategy Keras Example from docs,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from (source or binary): pip install tensorflow-gpu
- TensorFlow version (use command below): 2.0
- Python version: 3.7.3
- CUDA/cuDNN version: 10/7.6.4.38
- GPU model and memory: Tesla P100 16GB

**Describe the current behavior**
I can't make run the tutorial described here:
https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras
The example is crashing with the following TF_CONFIG
```python
os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': [""server1:23531"", ""server2:41660""]
    },
    'task': {'type': 'worker', 'index': 0}
})
```
In the other machine
```python
os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': [""server1:23531"", ""server2:41660""]
    },
    'task': {'type': 'worker', 'index': 1}
})
```
When the script start processing the first epoch it crashes, I tested on a single machine and it worked,

**Describe the expected behavior**
Don't crash...

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python
#!/usr/bin/env python
# coding: utf-8

# # Multiple Worker Training
import tensorflow as tf
# Use tensorflow datasets
import tensorflow_datasets as tfds
tfds.disable_progress_bar()
import os
import json

BUFFER_SIZE = 10000
BATCH_SIZE = 64

NUM_WORKERS = 2
# Here the batch size scales up by number of workers since 
# `tf.data.Dataset.batch` expects the global batch size. Previously we used 64, 
# and now this becomes 128.
GLOBAL_BATCH_SIZE = BATCH_SIZE * NUM_WORKERS

# Define TF_CONVIG environemnt variable
# This step create a environment variable that gives the location and ports available on the server to perform training.
os.environ['TF_CONFIG'] = json.dumps({
    'cluster': {
        'worker': [""server1:23531"", ""server2:41660""]
    },
    'task': {'type': 'worker', 'index': 1}
})

# This need to be called at the program startup
strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()


def make_datasets_unbatched():
    # Scaling MNIST data from (0, 255] to (0., 1.]
    def scale(image, label):
        image = tf.cast(image, tf.float32)
        image /= 255
        return image, label

    datasets, info = tfds.load(name='mnist',with_info=True,as_supervised=True)

    #return datasets['train'].map(scale).cache().shuffle(BUFFER_SIZE)
    return datasets['train'].map(scale).shuffle(BUFFER_SIZE)


def build_and_compile_cnn_model():
    model = tf.keras.Sequential([
          tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
          tf.keras.layers.MaxPooling2D(),
          tf.keras.layers.Flatten(),
          tf.keras.layers.Dense(64, activation='relu'),
          tf.keras.layers.Dense(10, activation='softmax')
    ])
    model.compile(
          loss=tf.keras.losses.sparse_categorical_crossentropy,
          optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
          metrics=['accuracy'])
    return model

# #### Define a Strategy and distribute training
with strategy.scope():
    # Creation of dataset, and model building/compiling need to be within 
    # `strategy.scope()`.
    train_datasets = make_datasets_unbatched().batch(GLOBAL_BATCH_SIZE)
    multi_worker_model = build_and_compile_cnn_model()
    

multi_worker_model.fit(x=train_datasets, epochs=3)

```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```bash
2019-11-04 16:59:37.654216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-04 16:59:38.488142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-04 16:59:38.488853: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Collective Op  has group_size 8 and group_key2 but that group has size 4
Additional GRPC error information:
{""created"":""@1572886778.488763529"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Collective Op  has group_size 8 and group_key2 but that group has size 4"",""grpc_status"":13}
         [[{{node allreduce_1/CollectiveReduce_1}}]]
         [[replica_2/strided_slice/_7]]
2019-11-04 16:59:38.488860: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Collective Op  has group_size 8 and group_key2 but that group has size 4
Additional GRPC error information:
{""created"":""@1572886778.488763529"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Collective Op  has group_size 8 and group_key2 but that group has size 4"",""grpc_status"":13}
         [[{{node allreduce_1/CollectiveReduce_1}}]]
         [[GroupCrossDeviceControlEdges_0/metrics/accuracy/div_no_nan/_85]]
2019-11-04 16:59:38.489032: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Collective Op  has group_size 8 and group_key2 but that group has size 4
Additional GRPC error information:
{""created"":""@1572886778.488763529"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Collective Op  has group_size 8 and group_key2 but that group has size 4"",""grpc_status"":13}
         [[{{node allreduce_1/CollectiveReduce_1}}]]
         [[SGD/SGD/group_deps/_165]]
2019-11-04 16:59:38.489335: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Collective Op  has group_size 8 and group_key2 but that group has size 4
Additional GRPC error information:
{""created"":""@1572886778.488763529"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Collective Op  has group_size 8 and group_key2 but that group has size 4"",""grpc_status"":13}
         [[{{node allreduce_1/CollectiveReduce_1}}]]
2019-11-04 16:59:39.358800: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Collective Op  has group_size 8 and group_key2 but that group has size 4
Additional GRPC error information:
{""created"":""@1572886778.488763529"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Collective Op  has group_size 8 and group_key2 but that group has size 4"",""grpc_status"":13}
         [[{{node allreduce_1/CollectiveReduce_1}}]]
         [[GroupCrossDeviceControlEdges_2/SGD/SGD/update_0/Const/_117]]
2019-11-04 16:59:40.201240: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-11-04 16:59:40.210692: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-11-04 16:59:40.276529: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-11-04 16:59:40.294888: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-11-04 16:59:40.356048: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-11-04 16:59:40.360051: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
      1/Unknown - 7s 7s/stepTraceback (most recent call last):
  File ""multi_worker_train.py"", line 83, in <module>
    multi_worker_model.fit(x=train_datasets, epochs=3)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 789, in fit
    *args, **kwargs)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 776, in wrapper
    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 853, in run_distribute_coordinator
    task_id, session_config, rpc_layer)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 360, in _run_single_worker
    return worker_fn(strategy)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 771, in _worker_fn
    return method(model, **kwargs)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1823, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 511, in call
    ctx=ctx)
  File ""/mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: 3 root error(s) found.
  (0) Internal:  Collective Op  has group_size 8 and group_key2 but that group has size 4
Additional GRPC error information:
{""created"":""@1572886778.488763529"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Collective Op  has group_size 8 and group_key2 but that group has size 4"",""grpc_status"":13}
         [[node allreduce_1/CollectiveReduce_1 (defined at /mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]
         [[GroupCrossDeviceControlEdges_0/metrics/accuracy/div_no_nan/_85]]
  (1) Internal:  Collective Op  has group_size 8 and group_key2 but that group has size 4
Additional GRPC error information:
{""created"":""@1572886778.488763529"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Collective Op  has group_size 8 and group_key2 but that group has size 4"",""grpc_status"":13}
         [[node allreduce_1/CollectiveReduce_1 (defined at /mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]
  (2) Internal:  Collective Op  has group_size 8 and group_key2 but that group has size 4
Additional GRPC error information:
{""created"":""@1572886778.488763529"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Collective Op  has group_size 8 and group_key2 but that group has size 4"",""grpc_status"":13}
         [[node allreduce_1/CollectiveReduce_1 (defined at /mnt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]
         [[replica_2/strided_slice/_7]]
0 successful operations.
2 derived errors ignored. [Op:__inference_distributed_function_2500]

Function call stack:
distributed_function -> distributed_function -> distributed_function

2019-11-04 16:59:40.527776: W tensorflow/core/kernels/data/generator_dataset_op.cc:102] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
2019-11-04 16:59:40.884570: W tensorflow/core/common_runtime/eager/context.cc:290] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
```
"
33978,Keras load weights fails to load model from directory containing [[,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.6.1810 (Core)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary, using conda
- TensorFlow version (use command below): unknown 1.14.0, with intel MKL
- Python version: 3.7.4
- CUDA/cuDNN version: no gpu
- GPU model and memory: no gpu

**Describe the current behavior**
When model checkpoint is stored in a directory containing `[[` in its name, the model fails to load, looks like the model files are missing, throwing NotFoundError

`model.load_weights(osp.join(model_dir, 'model'))` throws exception when for example, the model_dir='/home/projects/my_ml/data/sims/bs=2048_dataset=[[2019_9_13],[2019_9_12,2019_9_11,2019_9_10,2019_9_9]]'

**Describe the expected behavior**

`model.load_weights(osp.join(model_dir, 'model'))` should load the data without problems

**Code to reproduce the issue**
Here is [google colab code](https://colab.research.google.com/drive/1N1oPDXcmijzXs49C3DDLjm2pVHsUQvYP) with mnist example.

**Other info / logs**
The error is NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bs=2048_dataset=[[2019_9_13],[2019_9_12,2019_9_11,2019_9_10,2019_9_9]]/model"
33977,AttributeError: 'Tensor' object has no attribute '_keras_shape',"
this si my code 
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')


this is my error
Traceback (most recent call last):
  File ""/Users/***/Sites/python/nlp/images/Transfer learning with a pretrained ConvNet.py"", line 154, in <module>
    weights='imagenet')
  File ""/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/applications/__init__.py"", line 70, in wrapper
    return base_fun(*args, **kwargs)
  File ""/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/applications/mobilenet_v2.py"", line 32, in MobileNetV2
    return mobilenet_v2.MobileNetV2(*args, **kwargs)
  File ""/anaconda3/lib/python3.6/site-packages/keras_applications/mobilenet_v2.py"", line 355, in MobileNetV2
    expansion=1, block_id=0)
  File ""/anaconda3/lib/python3.6/site-packages/keras_applications/mobilenet_v2.py"", line 461, in _inverted_res_block
    in_channels = inputs._keras_shape[-1]
AttributeError: 'Tensor' object has no attribute '_keras_shape'

I learn tensorflow2.0  Tutorials Transfer learning with a pretrained ConvNet
please help me .

"
33976,  java.lang.IllegalArgumentException: Invalid output Tensor index: 1,"I've trained my own model for object detection with TensorFlow and I got it working with Tensorflow mobile for android. Now since Tensorflow Lite is released and is going to replace mobile in the future I wanted to start working with it. The Tensorflow team provided a demo for TFLite for object detection. So I tried to get it working with my model but I got the error in the title. Here's the logcat :

    java.lang.IllegalArgumentException: Invalid output Tensor index: 1
        at org.tensorflow.lite.NativeInterpreterWrapper.getOutputTensor(NativeInterpreterWrapper.java:308)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:164)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:296)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:194)
        at org.tensorflow.lite.examples.detection.DetectorActivity$2.run(DetectorActivity.java:181)"
33975,Bazel build does not pick up correct compiler include paths,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.5
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0.0
- Python version: 3.7.5
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): GCC 8.2.0
- CUDA/cuDNN version: 10.1


**Describe the problem**

Bazel does not pick up the correct include paths of GCC and returns errors such as:

```
ERROR: /tmp/easybuild-tmp/eb-5QGVSJ/tmpMZolLj-bazel-build/external/fft2d/BUILD.bazel:27:1: undeclared inclusion(s) in rule '@fft2d//:fft2d':
this rule is missing dependency declarations for the following files included by 'external/fft2d/fft2d/fftsg2d.c':
  '/sw/installed/GCCcore/8.2.0/lib/gcc/x86_64-pc-linux-gnu/8.2.0/include/stddef.h'
  '/sw/installed/GCCcore/8.2.0/lib/gcc/x86_64-pc-linux-gnu/8.2.0/include/stdarg.h'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

- `TF_NEED_CUDA=1 ./configure`
- `export TF_MKL_DOWNLOAD=1 &&   bazel --output_base=/tmp/easybuild-tmp/eb-5QGVSJ/tmpMZolLj-bazel-build --install_base=/tmp/easybuild-tmp/eb-5QGVSJ/tmpMZolLj-bazel-build/inst_base --output_user_root=/tmp/easybuild-tmp/eb-5QGVSJ/tmp514aJM-user_root build --compilation_mode=opt --config=opt --subcommands --verbose_failures --jobs=24 --action_env=PYTHONPATH --action_env=EBPYTHONPREFIXES --distinct_host_configuration=false  --config=mkl //tensorflow/tools/pip_package:build_pip_package`

Note that the installation is triggered via EasyBuild

**Any other info / logs**
[command.log](https://github.com/tensorflow/tensorflow/files/3804323/command.log)

"
33974,assert_shapes broken code in documentation,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/debugging/assert_shapes

## Description of issue (what needs changing):
The source code in the example is incorrect.

Is:
tf.assert_shapes([
  (x: ('N', 'Q')),
  (y: ('N', 'D')),
  (param: ('Q',)),
  (scalar: ()),
])

Should be:
tf.assert_shapes([
  (x, ('N', 'Q')),
  (y, ('N', 'D')),
  (param, ('Q',)),
  (scalar, ()),
]).

Note that "":"" is not allowed in Python to form 2-tuples. "
33973,Calling set_session before fit_generator causes training to freeze when using multiprocessing,"**System information**
- Have I written custom code: No
- OS Platform and Distribution: Linux Ubuntu 16.04
- Mobile device if the issue happens on mobile device: N/A
- TensorFlow installed from: binary
- TensorFlow version: v1.14.0-rc1-22-gaf24dc91b5 1.14.0
- Python version: 3.5
- Bazel version: N/A
- GCC/Compiler version: N/A
- CUDA/cuDNN version: 10.0 / 7
- GPU model and memory: GTX 1080Ti

**Describe the current behavior**
I am trying to modify TF session parameters in combination with Keras (e.g. the allowed GPU memory) and use `set_session()` to store these parameters. However, if `set_session()` is called  before `fit_generator()`, it causes the training to freeze when using multiprocessing. To reproduce the error, set `if True` in the main function.

**Describe the expected behavior**
No freeze should occur.

**Code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf
import tensorflow.keras.backend as K
from tensorflow.keras.layers import Input, Conv2D
from tensorflow.keras.models import Model
from tensorflow.keras.utils import Sequence


def get_model(input_shape, output_shape, compile_batch_size):
    assert K.image_data_format() == 'channels_last'
    m_input = Input(shape=input_shape, batch_size=compile_batch_size)
    m_output = Conv2D(output_shape[-1], 1, activation=None)(m_input)
    model = Model(inputs=m_input, outputs=m_output)
    return model


class DataGenerator(Sequence):
    def __init__(self, batch_size, image_size, num_batches):
        assert K.image_data_format() == 'channels_last'

        self.batch_size = batch_size
        self.image_size = image_size
        self.num_batches = num_batches
        self.on_epoch_end()

    def __len__(self):
        assert self.num_batches > 0
        return self.num_batches

    def __getitem__(self, index):
        return np.zeros((self.batch_size,) + self.image_size).astype('float32'), np.zeros(
            (self.batch_size,) + self.image_size).astype('float32')

    def on_epoch_end(self):
        pass


if __name__ == '__main__':
    print(tf.version.GIT_VERSION, tf.version.VERSION)

    # set to True to trigger infinite wait
    if True:
        # limit GPU memory
        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True
        config.gpu_options.per_process_gpu_memory_fraction = 0.5
        tf.keras.backend.set_session(tf.Session(config=config))

    inp_shape = (128, 64, 2)
    outp_shape = (128, 64, 2)
    batch_size = 16

    gen = DataGenerator(batch_size, inp_shape, 10)
    model = get_model(inp_shape, outp_shape, batch_size)
    model.summary()
    model.compile(loss=[""mse""], optimizer=""adam"", metrics=[""accuracy""])
    model.fit_generator(gen, steps_per_epoch=10, epochs=5, workers=2, use_multiprocessing=True)

```

**Other info / logs**
```
Traceback (most recent call last):
  File ""keras_mwe.py"", line 57, in <module>
    model.fit_generator(gen, steps_per_epoch=10, epochs=5, workers=2, use_multiprocessing=True)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py"", line 1433, in fit_generator
    steps_name='steps_per_epoch')
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py"", line 220, in model_iteration
    batch_data = _get_next_batch(generator, mode)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py"", line 362, in _get_next_batch
    generator_output = next(generator)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/data_utils.py"", line 779, in get
    inputs = self.queue.get(block=True).get()
  File ""/usr/lib/python3.5/multiprocessing/pool.py"", line 602, in get
    self.wait(timeout)
  File ""/usr/lib/python3.5/multiprocessing/pool.py"", line 599, in wait
    self._event.wait(timeout)
  File ""/usr/lib/python3.5/threading.py"", line 549, in wait
    signaled = self._cond.wait(timeout)
  File ""/usr/lib/python3.5/threading.py"", line 293, in wait
    waiter.acquire()
KeyboardInterrupt
```
"
33969,"2 issues: tf.train.Checkpoint does not seem to save optimizer state, impossible to load_weights using skip_mismatch=True","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, with minor modifications from the official documentation
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installed from (source or binary): `!pip install tf-nightly-gpu`
- TensorFlow version (use command below): 
- Python version: `v1.12.1-17291-ga2a3b22 2.1.0-dev20191103`

**Describe the current behavior**

1. When restoring from a tf.train.Checkpoint, training does not seem to resume from exactly where it was left off.

2. It is not possible to load pretrained weights to the same model with different output dimension, even with `skip_mismatch=True`.

**Code to reproduce the issue**
The two issues can be reproduced using [this Colab Notebook](https://colab.research.google.com/drive/1M0PDxTsXfL0lvFcsEhNTvNG-titdARYo).
"
33968,Can not compile the tensorflow lite example,"When I use the command ""make -f tensorflow/lite/experimental/micro/tools/make/Makefile micro_speech"", it shows the error message below:
**./tensorflow/lite/experimental/micro/kernels/activation_utils.h:43:23: error: ‘signbit’ was not declared in this scope 
    return signbit(a);**
I am sure I had build this example successfully few days ago(I built it on Ubuntu 16.04 x64). Is there anything changed for this example this week? Thanks.
"
33967,Cannot use dictionary embeddings metadata for keras callbacks,"Using dictionary as embeddings_metadata does not seem to be handled correctly in the Keras callbacks v2.
Indeed, while trying to do so I get the following error message:
```ValueError: Unrecognized `Embedding` layer names passed to `keras.callbacks.TensorBoard` `embeddings_metadata` argument: dict_keys(['embedding_1', 'embedding_2'])```
After looking at the source code (see [here](https://github.com/tensorflow/tensorflow/blob/32d76ec3e633e0ef5c980b5a91a510bb71d668ed/tensorflow/python/keras/callbacks.py#L1575)), I figured that, when the metadata is not a string, it checked if the layer names was in `embedding.metadata_path`. However, this variable is never set in this case and it is an empty string by default.

Looking at how it is handled in the [v1](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/callbacks_v1.py), I think the check should be done on `self.embeddings_metadata` (assuming if it is not a string it is a dictionary). So
```if layer.name in embedding.metadata_path:```
should be something like
```if layer.name in self.embeddings_metadata:```
Maybe it should be a copy of this dictionary or there should be a test to check that this is indeed a dictionary."
33966,Any way to generate offline documents for TF2.0 in HTML/pdf/markdown?,"Since we have network issues visiting official tensorflow document website within our area, are there any clues for generating offline api-docs with the document repository?"
33963,init_from_checkpoint support loading different variables from multiple checkpoints,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

**For example**
say I created a model with encoder + decoder, could `init_from_checkpoint` support loading encoder from A-checkpoint, and loading decoder from B-checkpoint?
```python
init_from_checkpoint(init_checkpoint_0, assignment_map_0)
init_from_checkpoint(init_checkpoint_1, assignment_map_0)
```

**System information**
- TensorFlow version (you are using): version 1.12


**Describe the feature and the current behavior/state.**

**Will this change the current api? How?** probably not

**Who will benefit with this feature?** developers who need more flexible graph loading， who need more flexible transfer leaning tricks

**Any Other info.**
pip install 
on both windows and linux
"
33962,AutoGraph unexpected indent in tf-nightly-gpu-2.1.0.dev20191103,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): `tf-nightly-gpu-2.1.0.dev20191103`
- Python version: 3.5.2
- CUDA/cuDNN version: 10.0/7.1
- GPU model and memory: GTX 1080 Ti

**Describe the current behavior**

After upgrading to `tf-nightly-gpu-2.1.0.dev20191103` from `tensorflow-gpu-2.0.0`, I obtained this error when running my code:

```
WARNING:tensorflow:AutoGraph could not transform <bound method CRFLayer.mean_field of <models.crf_layer.CRFLayer object at 0x7f6124237b00>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: unexpected indent (<unknown>, line 36)
```
I did `export AUTOGRAPH_VERBOSITY=10` but did not observe any other types of output other than the above. It says **unexpected indent** so I guess something changed in the parsing of Python code when building the graph? The problem does not occur on `tensorflow-gpu-2.0.0` (I installed `tf-nightly-gpu-2.1.0.dev20191103` because I need to be able to `load_weights(pretrained_weights, by_name=True, skip_mismatch=True)`, which is not available in 2.0.0. There is another bug with this function that I will report in a separate issue.)

**Describe the expected behavior**
Like in TF 2.0.0: no AutoGraph warning.

**Code to reproduce the issue**
Unfortunately my code has a lot of dependencies and I was unable to create a minimal reproducible example. But from the warning message I guess it's easy enough to check in the source code."
33961,dynamic shape for deconv ops,"i just check https://github.com/tensorflow/tensorflow/issues/833
it provide code for tf.nn.conv2d_transpose to support dyncmic shape. i want to ask how to apply it for slim.conv2d_transpose. Plz help to check. thank you!"
33960,Docker/Kubernetes memory limits not respected? OOMKilled when deployed to GCP ,"````
== check python ===================================================
python version: 3.5.6
python branch: 
python build version: ('default', 'Aug 26 2018 21:41:56')
python compiler version: GCC 7.3.0
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: #1 SMP Tue Jul 2 22:58:16 UTC 2019
os release version: 4.9.184-linuxkit
os platform: Linux-4.9.184-linuxkit-x86_64-with-debian-buster-sid
linux distribution: ('debian', 'buster/sid', '')
linux os distribution: ('debian', 'buster/sid', '')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='413655a3a81f', release='4.9.184-linuxkit', version='#1 SMP Tue Jul 2 22:58:16 UTC 2019', machine='x86_64', processor='x86_64')
architecture: ('64bit', '')
machine: x86_64


== are we in docker =============================================
Yes

== compiler =====================================================
c++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy                              1.15.2           
numpydoc                           0.9.1            
protobuf                           3.9.1            
tensorflow                         1.14.0           
tensorflow-estimator               1.14.0           
tensorflow-hub                     0.6.0            
tensorflow-serving-api             1.14.0           

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 1.14.0
tf.version.GIT_VERSION = v1.14.0-0-g87989f6
tf.version.COMPILER_VERSION = 4.8.4
Sanity check: array([1], dtype=int32)
        65:	find library=libpthread.so.0 [0]; searching
   (hundreds of lines follow here)
== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_env_collect.sh.1: line 147: nvidia-smi: command not found

== cuda libs  ===================================================

== tensorflow installed from info ==================
Name: tensorflow
Version: 1.14.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /root/miniconda3/lib/python3.5/site-packages
Required-by: witwidget, tensorflow-serving-api, seldon-core

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 5, 6, 'final', 0)

== bazel version  ===============================================
Build label: 0.19.0
Build time: Mon Oct 29 14:35:30 2018 (1540823730)
Build timestamp: 1540823730
Build timestamp as int: 1540823730
````

**Describe the current behavior**
I'm using Kubeflow to deploy a simple Keras/TF model training job (two LSTM layers, 28000x150x27 input from CSV). The Dockerfile it produces is:

````
FROM gcr.io/deeplearning-platform-release/tf-cpu.1-14
WORKDIR /python_env
COPY requirements.txt .
RUN python3 -m pip install -r requirements.txt
COPY . .
````

...and the output at the top of this issue is from within the resulting container.

The container has a CPU limit of 7 cores and a memory limit of 26Gi (the host node has 8 cores and 30Gi).

By the 3rd of 20 epochs, after about 50 minutes, the container is killed by Kubernetes with OOMKilled. Looking at a graph of memory use, it increases linearly over the 50 minutes, and evidently ignores the limits.

I have previously trained this model on my laptop (8 cores / 16GB RAM), 20 epochs, without issue, so this looks to be related to the Docker or Kubernetes environment.

**Describe the expected behavior**
Memory limits are respected.

**Code to reproduce the issue**
The above Dockerfile, plus:

````python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM
from urllib.request import urlopen
import numpy as np
import importlib
import os

# here's how data is loaded
dataset = np.loadtxt(raw_data, delimiter="","")

# build model
model = Sequential()
model.add(LSTM(32, return_sequences=True))
model.add(LSTM(32))
model.add(Dense(32, activation='softmax'))
opt = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)
model.compile(loss='sparse_categorical_crossentropy',
              optimizer=opt, metrics=['accuracy'])

# training (data has been loaded via np.loadtxt)
model.fit(
    training_dataset,
    training_labels,
    epochs=20,
    shuffle=True,
    validation_data=(validation_dataset, validation_labels)
)
````
"
33959,libtensorflowlite.so build not correct,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): build use Linux Ubuntu 16.04,deploy on android 9.0(arm64)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:None
- TensorFlow installed from (source or binary): git clone source code from master branch
- TensorFlow version:master
- Python version:anaconda python 3.6
- Installed using virtualenv? pip? conda?:source code ,none
- Bazel version (if compiling from source):0.24.1
- GCC/Compiler version (if compiling from source):ndk r19c
- CUDA/cuDNN version:none
- GPU model and memory:none



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I want to build c++ interface of tflite on android device ,using command:
bazel build -s //tensorflow/lite:libtensorflowlite.so --config=android_arm64 --cxxopt='--std=c++11' -c opt
the build could be succeed ,but the libtensorflowlite.so built is only 5784 Byte, and doesn't work correctly.

I use the same command on tensorlfow 1.15 ,and can get the right lib ,which is 2MB.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33958,Is it possible to reduce the number of kernels/filters in a trained model in Tensorflow?,"If I have a trained model, where I want to retrain the same model, with few filters/kernel removed from the existing model. e.g. 
(The sam ecan be found [here](https://stackoverflow.com/questions/58313035/how-to-reduce-the-number-of-kernels-filters-in-a-trained-model-in-tensorflow?noredirect=1&lq=1), i searched, but came to know that TF dose not support variable resizing, only reshape is supported)
`conv1 = tf.get_variable('conv1_1', shape=(11, 11, 3, 64), initializer=tf.contrib.layers.xavier_initializer()),`
and I want to resize this tensor such that it has the shape of (11, 11, 3, 20) but the same name and position, mean exactly the same variable. Advance thanks for the help.

I have tried tf.reshape but it gives me error of not matching the number of elements in a and b I have also tried tf.assign(a,b, validate_shape=false)

```
self.weights = {
    'conv1_': tf.get_variable('conv1_l1', shape=(11, 11, 3, 64), initializer=tf.contrib.layers.xavier_initializer()),
    'conv2_': tf.get_variable('conv2_l1', shape=(7, 7, 64, 128), initializer=tf.contrib.layers.xavier_initializer())
}
```

"
33957,model restore error/confict in tensorflow,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): sudo pip3 install tensorflow-gpu==2.0.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0.130/7.6.2
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I have saved one model (with more than two layers) using `model.save_weights` and want to restore its weights and only use the front conv layers. But when I using `model.load_weights`, I got two different results:

1. First, when I load weights only for the front conv layers, one bigger model can load successfully but another smaller model can not load.
2. Two, the bigger model load success but the weights of the last layer is wrong but any other layers weiight is right.

**Describe the expected behavior**

I want to load a .ckpt into a smaller model successfully.

**Code to reproduce the issue**
Here is my bigger model definition:

```
import tensorflow as tf
import math

NUM_CLASSES = 10

def swish(x):
    return x * tf.keras.activations.sigmoid(x)

def round_filters(filters, multiplier):
    depth_divisor = 8
    min_depth = None
    min_depth = min_depth or depth_divisor
    filters = filters * multiplier
    new_filters = max(min_depth, int(filters + depth_divisor / 2) // depth_divisor * depth_divisor)
    if new_filters < 0.9 * filters:
        new_filters += depth_divisor
    return int(new_filters)

def round_repeats(repeats, multiplier):
    if not multiplier:
        return repeats
    return int(math.ceil(multiplier * repeats))

def SEBlock(inputs, input_channels, ratio=0.25):

    num_reduced_filters = max(1, int(input_channels * ratio))
    branch = tf.keras.layers.GlobalAveragePooling2D()(inputs)
    # branch = tf.keras.layers.Lambda(lambda branch: tf.expand_dims(input=branch, axis=1))(branch)
    branch = tf.keras.backend.expand_dims(branch, 1)
    branch = tf.keras.backend.expand_dims(branch, 1)
    # branch = tf.keras.layers.Lambda(lambda branch: tf.expand_dims(input=branch, axis=1))(branch)
    branch = tf.keras.layers.Conv2D(filters=num_reduced_filters, kernel_size=(1, 1), strides=1, padding=""same"")(branch)
    branch = swish(branch)
    branch = tf.keras.layers.Conv2D(filters=input_channels, kernel_size=(1, 1), strides=1, padding='same')(branch)
    branch = tf.keras.activations.sigmoid(branch)
    output = inputs * branch

    return output

def MBConv(in_channels, out_channels, expansion_factor, stride, k, drop_connect_rate, inputs, training=False):
    x = tf.keras.layers.Conv2D(filters=in_channels * expansion_factor,kernel_size=(1, 1),strides=1,padding=""same"")(inputs)
    x = tf.keras.layers.BatchNormalization()(x, training=training)
    x = swish(x)
    x = tf.keras.layers.DepthwiseConv2D(kernel_size=(k, k), strides=stride, padding=""same"")(x)
    x = tf.keras.layers.BatchNormalization()(x, training=training)
    x = SEBlock(x, in_channels*expansion_factor)
    x = swish(x)
    x = tf.keras.layers.Conv2D(filters=out_channels,kernel_size=(1, 1),strides=1,padding=""same"")(x)
    x = tf.keras.layers.BatchNormalization()(x, training=training)
    if stride == 1 and in_channels == out_channels:
        if drop_connect_rate:
            x = tf.keras.layers.Dropout(rate=drop_connect_rate)(x, training=training)
        x = tf.keras.layers.Add()([x, inputs])

    return x

def build_mbconv_block(inputs, in_channels, out_channels, layers, stride, expansion_factor, k, drop_connect_rate, training):

    x = inputs
    for i in range(layers):
        if i == 0:
            x = MBConv(in_channels=in_channels, out_channels=out_channels, expansion_factor=expansion_factor,
                       stride=stride, k=k, drop_connect_rate=drop_connect_rate, inputs=x, training=training)
        else:
            x = MBConv(in_channels=out_channels, out_channels=out_channels, expansion_factor=expansion_factor,
                       stride=1, k=k, drop_connect_rate=drop_connect_rate, inputs=x, training=training)

    return x


def EfficientNet(inputs, width_coefficient, depth_coefficient, dropout_rate, drop_connect_rate=0.2, training=False):

    features = []

    x = tf.keras.layers.Conv2D(filters=round_filters(32, width_coefficient),kernel_size=(3, 3),strides=2, padding=""same"") (inputs)
    x = tf.keras.layers.BatchNormalization()(x, training=training)
    x = swish(x)

    x = build_mbconv_block(x, in_channels=round_filters(32, width_coefficient),
                           out_channels=round_filters(16, width_coefficient),
                           layers=round_repeats(1, depth_coefficient),
                           stride=1,
                           expansion_factor=1, k=3,
                           drop_connect_rate=drop_connect_rate,
                           training=training)
    features.append(x)

    x = build_mbconv_block(x, in_channels=round_filters(16, width_coefficient),
                           out_channels=round_filters(24, width_coefficient),
                           layers=round_repeats(2, depth_coefficient),
                           stride=1,
                           expansion_factor=6, k=3,
                           drop_connect_rate=drop_connect_rate,
                           training=training)
    features.append(x)

    x = build_mbconv_block(x, in_channels=round_filters(24, width_coefficient),
                           out_channels=round_filters(40, width_coefficient),
                           layers=round_repeats(2, depth_coefficient),
                           stride=2,
                           expansion_factor=6, k=5,
                           drop_connect_rate=drop_connect_rate,
                           training=training)
    features.append(x)

    x = build_mbconv_block(x, in_channels=round_filters(40, width_coefficient),
                           out_channels=round_filters(80, width_coefficient),
                           layers=round_repeats(3, depth_coefficient),
                           stride=2,
                           expansion_factor=6, k=3,
                           drop_connect_rate=drop_connect_rate,
                           training=training)
    features.append(x)

    x = build_mbconv_block(x, in_channels=round_filters(80, width_coefficient),
                           out_channels=round_filters(112, width_coefficient),
                           layers=round_repeats(3, depth_coefficient),
                           stride=1,
                           expansion_factor=6, k=5,
                           drop_connect_rate=drop_connect_rate,
                           training=training)
    features.append(x)

    x = build_mbconv_block(x, in_channels=round_filters(112, width_coefficient),
                           out_channels=round_filters(192, width_coefficient),
                           layers=round_repeats(4, depth_coefficient),
                           stride=2,
                           expansion_factor=6, k=5,
                           drop_connect_rate=drop_connect_rate,
                           training=training)
    features.append(x)

    x = build_mbconv_block(x, in_channels=round_filters(192, width_coefficient),
                           out_channels=round_filters(320, width_coefficient),
                           layers=round_repeats(1, depth_coefficient),
                           stride=1,
                           expansion_factor=6, k=3,
                           drop_connect_rate=drop_connect_rate,
                           training=training)
    features.append(x)

    x = tf.keras.layers.Conv2D(filters=round_filters(1280, width_coefficient), kernel_size=(1, 1), strides=1, padding='same')(x)
    x = tf.keras.layers.BatchNormalization()(x, training=training)
    x = swish(x)
    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    x = tf.keras.layers.Dropout(rate=dropout_rate)(x, training=training)
    x = tf.keras.layers.Dense(units=1, activation=tf.keras.activations.softmax)(x)

    return x, features


def efficient_net_b0(inputs, training):
    return EfficientNet(inputs,
                        width_coefficient=1.0,
                        depth_coefficient=1.0,
                        dropout_rate=0.2,
                        drop_connect_rate=0.2,
                        training=training)

def up_sample(inputs, training=True):
    x = tf.keras.layers.UpSampling2D()(inputs)
    x = tf.keras.layers.BatchNormalization()(x, training=training)
    x = tf.keras.layers.ReLU()(x)
    return x

def biggerModel(inputs, outc, training=True):

    _, features =  efficient_net_b0(inputs=inputs, training=training)

    # [ 1/2, 1/4, 1/8, 1/8, 1/16]
    outputs = []
    for i, name in enumerate(features):
        x = features[i]
        if x.shape[1] > inputs.shape[1] // 4:
            continue
        while x.shape[1] < (inputs.shape[1]//4):
            x = up_sample(x, training)
        outputs.append(x)

    quater_res = tf.keras.layers.Concatenate()(outputs)
    quater_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(quater_res)
    quater_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(quater_res)
    quater_res_out = tf.keras.layers.Conv2D(outc, 1, 1, 'same', name='quater', activation=None)(quater_res)

    half_res = up_sample(quater_res, training)
    half_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(half_res)
    half_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(half_res)
    half_res_out = tf.keras.layers.Conv2D(outc, 1, 1, 'same', name='half', activation=None)(half_res)
    
    if training:
        return quater_res_out, half_res_out
    else:
        return quater_res_out
```
And here is my smaller model definition:
```
def smallModel(inputs, outc, training=True):


    quater_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(inputs)
    quater_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(quater_res)
    quater_res_out = tf.keras.layers.Conv2D(outc, 1, 1, 'same',  activation=None)(quater_res)


    half_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(quater_res)
    half_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(half_res)
    half_res_out = tf.keras.layers.Conv2D(outc, 1, 1, 'same', activation=None)(half_res)

    if training:
        return quater_res_out, half_res_out
    else:
        return quater_res_out
```
About bigger model, first, I save weights and print layer named 'quater' weights :

```
if __name__ == '__main__':
    import os
    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    inputs = tf.keras.Input(shape=(224, 224, 3), name='modelInput')
    outputs = biggerModel(inputs, outc=18 + 1, training=True)
    model = tf.keras.Model(inputs, outputs)
    # model.summary()

    model.save_weights('models/test/test')
    # model.load_weights('models/test/test')

    print(model.get_layer('quater').get_weights()[0][0][0][0:4])
```
and I get this:
![image](https://user-images.githubusercontent.com/18358653/68102867-8441ae00-ff0f-11e9-9d00-3fb77fb126c7.png)
and then I restore weight by setting parameter `training = False` and print **quater layer weights**:
```
if __name__ == '__main__':

    import os
    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    inputs = tf.keras.Input(shape=(224, 224, 3), name='modelInput')
    outputs = biggerModel(inputs, outc=18 + 1, training=False)
    model = tf.keras.Model(inputs, outputs)
    # model.summary()

    # model.save_weights('models/test/test')
    model.load_weights('models/test/test')

    print(model.get_layer('quater').get_weights()[0][0][0][0:4])
```
and got result like this:
![image](https://user-images.githubusercontent.com/18358653/68103002-12b62f80-ff10-11e9-8912-b0364f2d39fc.png)
We can see that this two outputs are different, but I have checkout all other layers weights are same resutlts, so, it's really weird.

For smaller model, as like in bigger model I have done, first save weights and print **quater layer weights**:
```

if __name__ == '__main__':

    import os
    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    inputs = tf.keras.Input(shape=(224, 224, 3), name='modelInput')
    outputs = smallModel(inputs, outc=18 + 1, training=True)
    model = tf.keras.Model(inputs, outputs)
    # model.summary()

    # model.save_weights('models/test/test')
    model.load_weights('models/test/test')

    print(model.get_layer('quater').get_weights()[0][0][0][0:4])
```
and result is:
![image](https://user-images.githubusercontent.com/18358653/68103215-d931f400-ff10-11e9-9e32-32bcf90239d1.png)
Then I tried to restore this and setting parameter `training = False`:
```
if __name__ == '__main__':

    import os
    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    inputs = tf.keras.Input(shape=(224, 224, 3), name='modelInput')
    outputs = smallModel(inputs, outc=18 + 1, training=False)
    model = tf.keras.Model(inputs, outputs)
    # model.summary()

    # model.save_weights('models/test/test')
    model.load_weights('models/test/test')

    print(model.get_layer('quater').get_weights()[0][0][0][0:4])
```
I got this error:
![image](https://user-images.githubusercontent.com/18358653/68103275-0bdbec80-ff11-11e9-92d9-ba878cc2c4be.png)

How can I fix this?

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33956,"The same code, trained in the Ubuntu environment, Loss can converge, but under Windows training, Loss can not converge.","I ran a project on github, the project address is https://github.com/qxde01/keras-alchemy, I tried to train a mobilenetv2 image classifier directly by running the `train_cifar100_classify.py` file, but I encountered some problems at runtime. .

My Windows environment:
```
Windows 10
Tensorflow-gpu 2.0
Keras 2.3.1
CUDA 10.0
```
My Ubuntu environment:
```
Ubuntu 16.04
Tensorflow-gpu 1.12
Keras 2.2.4
CUDA 9.0
```

I changed all `if tf.__version__<'2.0':` results to true at runtime to use keras as a front end to reduce version incompatibility issues.

The final result, as the title says, is trained on Windows and Loss is completely unable to converge. What is the reason for this? Can someone help me analyze it? thank you very much!
"
33952,custom object detection data set tflite_convert,"I have followed ""https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193"" with ""ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz"" model... Only thing I have changed bazel to tflite_convert . I have prepared 300x300x3 labeled images and trained. after trained i have generated frozen_graph. pb file to check on jupyter notebook and wola it runs ... After that I have used below code  to produce tflite_graph.pbtxt and tflite_graph.pb files . 

""python export_tflite_ssd_graph.py --pipeline_config_path training/pipeline.config --trained_checkpoint_prefix training/model.ckpt-2927 --output_directory export_tflite_ssd_graph/tflite --add_postprocessing_op true""

Finally I have used below code to get detect.tflite file and bomm. Nothing happen when I have started https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android that project on android studio.  The project perfectly runs own original detect.tflite file....

""D:\First\Projects\visionApi\START\models\research\object_detection>tflite_convert  --output_file export_tflite_ssd_graph/tflite/detect.tflite --input_shapes 1,300,300,3 --input_arrays normalized_input_image_tensor --output_arrays ""TFLite_Detection_PostProcess"" ""TFLite_Detection_PostProcess:1"" ""TFLite_Detection_PostProcess:2"" ""FLite_Detection_PostProcess:3"" --mean_values 128 --std_dev_values 127 --allow_custom_ops --graph_def_file export_tflite_ssd_graph/tflite/tflite_graph.pb change_concat_input_ranges false --inference_type FLOAT ""

Above code generate a detect.tflite file but it did not run on above android project. 

How could I do correctly ? please help.

After that I tried to change code as below.... and get that error...

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 
- TensorFlow installed from (source or binary):  binary
- TensorFlow version (or github SHA if from source): 1.13.1

**Provide the text output from tflite_convert**

```
D:\First\Projects\visionApi\START\models\research\object_detection>tflite_convert  --output_file export_tflite_ssd_graph/tflite/detect.tflite --input_shapes 1,300,300,3 --input_arrays normalized_input_image_tensor --output_arrays ""TFLite_Detection_PostProcess"" ""TFLite_Detection_PostProcess:1"" ""TFLite_Detection_PostProcess:2"" ""FLite_Detection_PostProcess:3"" --mean_values 128 --std_dev_values 127 --allow_custom_ops --graph_def_file export_tflite_ssd_graph/tflite/tflite_graph.pb change_concat_input_ranges false --inference_type QUANTIZED_UINT8

2019-11-03 19:04:05.430457: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-11-03 19:04:06.351615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705
pciBusID: 0000:01:00.0
totalMemory: 6.00GiB freeMemory: 4.97GiB
2019-11-03 19:04:06.358836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-11-03 19:04:06.856355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-03 19:04:06.860494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-11-03 19:04:06.863385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-11-03 19:04:06.867189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4716 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""c:\python\python37\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""c:\python\python37\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Python\Python37\Scripts\tflite_convert.exe\__main__.py"", line 9, in <module>
  File ""c:\python\python37\lib\site-packages\tensorflow\lite\python\tflite_convert.py"", line 442, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""c:\python\python37\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""c:\python\python37\lib\site-packages\tensorflow\lite\python\tflite_convert.py"", line 438, in run_main
    _convert_model(tflite_flags)
  File ""c:\python\python37\lib\site-packages\tensorflow\lite\python\tflite_convert.py"", line 191, in _convert_model
    output_data = converter.convert()
  File ""c:\python\python37\lib\site-packages\tensorflow\lite\python\lite.py"", line 461, in convert
    **converter_kwargs)
  File ""c:\python\python37\lib\site-packages\tensorflow\lite\python\convert.py"", line 411, in toco_convert_graph_def
    input_data.SerializeToString())
  File ""c:\python\python37\lib\site-packages\tensorflow\lite\python\convert.py"", line 205, in toco_convert_protos
    ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.
2019-11-03 19:04:08.261635: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TFLite_Detection_PostProcess
2019-11-03 19:04:08.262132: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-11-03 19:04:08.262371: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-11-03 19:04:08.262670: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-11-03 19:04:08.262925: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-11-03 19:04:08.289925: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 878 operators, 1279 arrays (0 quantized)
2019-11-03 19:04:08.342088: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 878 operators, 1279 arrays (0 quantized)
2019-11-03 19:04:08.405873: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 100 operators, 259 arrays (1 quantized)
2019-11-03 19:04:08.408766: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 100 operators, 259 arrays (1 quantized)
2019-11-03 19:04:08.410769: F tensorflow/lite/toco/tooling_util.cc:1702] Array FeatureExtractor/MobilenetV2/Conv/Relu6, which is an input to the DepthwiseConv operator producing the output array FeatureExtractor/MobilenetV2/expanded_conv/depthwise/Relu6, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.
```




"
33951,tf.volume.resize ,"
**System information**
- TensorFlow version (you are using): 1.14
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

tf.image.resize works for 2D images, would be nice with tf.volume.resize for 3D volumes, instead of using tf.keras.layers.UpSampling3D that only performs nearest neighbor interpolation.

**Will this change the current api? How?**

I don't think so

**Who will benefit with this feature?**

Many working with 3D data

**Any Other info.**
"
33950,OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key aux_logits/Conv/biases/ExponentialMovingAverage not found in checkpoint,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04

- TensorFlow installed from (source or binary): conda install
- TensorFlow version (use command below): v1.14
- Python version: anaconda 3.7
- Bazel version (if compiling from source): 1.01

Full enviorment details : `
[tf_env.txt](https://github.com/tensorflow/tensorflow/files/3801902/tf_env.txt)


**Describe the current behavior**
I am attempting to evaluate my custom trained inception V3 model, but the variables to restore being generated by this call 
` variable_averages = tf.train.ExponentialMovingAverage(
        inception.MOVING_AVERAGE_DECAY)
    variables_to_restore = variable_averages.variables_to_restore()` 

are not found in my checkpoint file. 

I get this error:

````
Exception has occurred: NotFoundError
Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Key aux_logits/Conv/biases/ExponentialMovingAverage not found in checkpoint
	 [[node save/RestoreV2 (defined at /02_testing/xClasses/inception/nc_inception_eval.py:418) ]]

Original stack trace for 'save/RestoreV2':
  File ""/.vscode-server/extensions/ms-python.python-2019.10.44104/pythonFiles/ptvsd_launcher.py"", line 43, in <module>
    main(ptvsdArgs)
  File ""/.vscode-server/extensions/ms-python.python-2019.10.44104/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py"", line 432, in main
    run()
  File ""/.vscode-server/extensions/ms-python.python-2019.10.44104/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py"", line 316, in run_file
    runpy.run_path(target, run_name='__main__')
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/02_testing/xClasses/nc_imagenet_eval.py"", line 271, in <module>
    tf.app.run()
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/02_testing/xClasses/nc_imagenet_eval.py"", line 65, in main
    precision_at_1, current_score = nc_inception_eval.evaluate(dataset)
  File ""/02_testing/xClasses/inception/nc_inception_eval.py"", line 418, in evaluate
    saver = tf.train.Saver(variables_to_restore)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 831, in __init__
    self.build()
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 843, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 881, in _build
    build_restore=build_restore)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 514, in _build_internal
    restore_sequentially, reshape)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 334, in _AddRestoreOps
    restore_sequentially)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 581, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 1696, in restore_v2
    name=name)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()
  File ""/home/ubuntu/02_testing/xClasses/inception/nc_inception_eval.py"", line 83, in _eval_once
    saver.restore(sess, ckpt.model_checkpoint_path)
  File ""/home/ubuntu/02_testing/xClasses/inception/nc_inception_eval.py"", line 427, in evaluate
    precision_at_1, current_score = _eval_once(saver, summary_writer, top_1_op, top_5_op, summary_op, max_percent, all_filenames, filename_queue, net2048, sel_end_points, logits, labels)
  File ""/home/ubuntu/02_testing/xClasses/nc_imagenet_eval.py"", line 65, in main
    precision_at_1, current_score = nc_inception_eval.evaluate(dataset)
  File ""/home/ubuntu/02_testing/xClasses/nc_imagenet_eval.py"", line 271, in <module>
    tf.app.run()
````

**Describe the expected behavior**
I have done this several times before so I am not sure why I am all the sudden getting this error. I even tried evaluating my old model with these scripts and it still gives me the same error. 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
`inception_eval.evaluate(dataset)`


`def evaluate(dataset):
  """"""Evaluate model on Dataset for a number of steps.""""""
  with tf.Graph().as_default():
    # Get images and labels from the dataset.
    images, labels, all_filenames, filename_queue = image_processing.inputs(dataset)

    # Number of classes in the Dataset label set plus 1.
    # Label 0 is reserved for an (unused) background class
    num_classes = dataset.num_classes() + 1
    print(""there are %d classes!"" % dataset.num_classes())

    # Build a Graph that computes the logits predictions from the
    # inference model.
    logits, _, end_points, net2048, sel_end_points = inception.inference(images, num_classes)

    # Calculate predictions.
    #max_percent =  tf.argmax(logits,1)
    #max_percent = tf.reduce_max(logits, reduction_indices=[1]) / tf.add_n(logits)
    max_percent = end_points['predictions']
    # max_percent = len(end_points)
    #for kk in range(len(labels)):
    #   #max_percent.append(end_points['predictions'][kk][labels[kk]])
    #   max_percent.append(labels[kk])
    if FLAGS.mode == '0_softmax':
      top_1_op = tf.nn.in_top_k(logits, labels, 1)
      top_5_op = tf.nn.in_top_k(logits, labels, 5)
    elif FLAGS.mode == '1_sigmoid':
      top_1_op = None
      top_5_op = None
    # Restore the moving average version of the learned variables for eval.

    variable_averages = tf.train.ExponentialMovingAverage(
        inception.MOVING_AVERAGE_DECAY)
    variables_to_restore = variable_averages.variables_to_restore()
    with open('./vars2res.txt', 'w') as vas:
      for k, v in variables_to_restore.items():
        vas.write(k)
        vas.write('\n')
    saver = tf.train.Saver(variables_to_restore)

    # Build the summary operation based on the TF collection of Summaries.
    summary_op = tf.summary.merge_all()

    graph_def = tf.get_default_graph().as_graph_def()
    summary_writer = tf.summary.FileWriter(FLAGS.eval_dir, graph_def=graph_def)

    while True:
      precision_at_1, current_score = _eval_once(saver, summary_writer, top_1_op, top_5_op, summary_op, max_percent, all_filenames, filename_queue, net2048, sel_end_points, logits, labels)`

`def _eval_once(saver, summary_writer, top_1_op, top_5_op, summary_op, max_percent_op, all_filenames, filename_queue, net2048_op, endpoints_op, logits_op, labels_op):
  """"""Runs Eval once.

  Args:
    saver: Saver.
    summary_writer: Summary writer.
    top_1_op: Top 1 op.
    top_5_op: Top 5 op.
    summary_op: Summary op.
  """"""
  #tf.initialize_all_variables()
  # modify for new tensorflow releases
  tf.global_variables_initializer()
  with tf.Session() as sess:
    ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)
    if ckpt and ckpt.model_checkpoint_path:
      if os.path.isabs(ckpt.model_checkpoint_path):
        # Restores from checkpoint with absolute path.
        saver.restore(sess, ckpt.model_checkpoint_path)`
```


**Other info / logs**
Tensors in my model
[tensors2.txt](https://github.com/tensorflow/tensorflow/files/3801898/tensors2.txt)

Variables attempting to restore
[var2res.txt](https://github.com/tensorflow/tensorflow/files/3801904/var2res.txt)
"
33949,Tensorflow Android Library doesn't define targetSdkVersion,"Hey,
I'm using your android tensorflow library for an android library I'm working on.

When adding your sdk I automatically see 2 additional permissions - Phone and Storage.
I checked and turns our the permissions are added because your SDK doesn't define a targetSdkVersion, so by default the targetSdkVersion of your sdk is considered 1, and according to [android docs](https://developer.android.com/studio/build/manifest-merge.html#implicit_system_permissions) the permissions are added automatically in such case.

Please let me know if you can solve my issue (maybe by adding targetSdkVersion to your project?)

**System information**
The android dependency I'm using is: implementation 'org.tensorflow:tensorflow-android:1.13.1'

Thanks!"
33948,"ValueError: Shapes (8334, 256) and (8335, 256) are incompatible","# **System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
Two OS used:
  - Windows 10
  - Google Compute Engine (GPU) OS (whatever that might be?)
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0 (on both OS)
- Python version: 
  - Windows 10 (running Python 3.6.6)
  - Google Compute Engine OS (running Python 3.6)

# **Describe the current behavior**
A model is compiled and trained using `script A` on the Google Compute Engine. The weights are saved separately rather than altogether due to #33947 , using the `model.save_weights()`.

The weights are then saved as a zip, and transferred to a Windows-based machine.

On the Windows-based machine, the same code is run to compile the model but instead of training the model again - the weights are loaded using `model.load_weights()`.

This results in a 
```
ValueError: Shapes (8334, 256) and (8335, 256) are incompatible
```

# **Describe the expected behavior**
A model is compiled and trained using `script A` on the Google Compute Engine. The weights are saved separately rather than altogether due to #33947 , using the `model.save_weights()`.

The weights are then saved as a zip, and transferred to a Windows-based machine.

On the Windows-based machine, the same code is run to compile the model but instead of training the model again - the weights are loaded using `model.load_weights()`.

The weights are loaded successfully.

# **Possible Cause**
**Model Summary on the two machines are different... which is likely causing the issue.**
- Google Compute Engine (GPU):
```
Model: ""transformer""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
inputs (InputLayer)             [(None, None)]       0                                            
__________________________________________________________________________________________________
dec_inputs (InputLayer)         [(None, None)]       0                                            
__________________________________________________________________________________________________
enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     
__________________________________________________________________________________________________
encoder (Model)                 (None, None, 256)    3187968     inputs[0][0]                     
                                                                 enc_padding_mask[0][0]           
__________________________________________________________________________________________________
look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 
__________________________________________________________________________________________________
dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     
__________________________________________________________________________________________________
decoder (Model)                 (None, None, 256)    3715328     dec_inputs[0][0]                 
                                                                 encoder[1][0]                    
                                                                 look_ahead_mask[0][0]            
                                                                 dec_padding_mask[0][0]           
__________________________________________________________________________________________________
outputs (Dense)                 (None, None, 8335)   2142095     decoder[1][0]                    
==================================================================================================
Total params: 9,045,391
Trainable params: 9,045,391
Non-trainable params: 0
__________________________________________________________________________________________________
```
- Windows-based Machine:
```
Model: ""transformer""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
inputs (InputLayer)             [(None, None)]       0
__________________________________________________________________________________________________
dec_inputs (InputLayer)         [(None, None)]       0
__________________________________________________________________________________________________
enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]
__________________________________________________________________________________________________
encoder (Model)                 (None, None, 256)    3187712     inputs[0][0]
                                                                 enc_padding_mask[0][0]
__________________________________________________________________________________________________
look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]
__________________________________________________________________________________________________
dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]
__________________________________________________________________________________________________
decoder (Model)                 (None, None, 256)    3715072     dec_inputs[0][0]
                                                                 encoder[1][0]
                                                                 look_ahead_mask[0][0]
                                                                 dec_padding_mask[0][0]
__________________________________________________________________________________________________
outputs (Dense)                 (None, None, 8334)   2141838     decoder[1][0]
==================================================================================================
Total params: 9,044,622
Trainable params: 9,044,622
Non-trainable params: 0
__________________________________________________________________________________________________
```

# **Other info / logs**
[log.txt](https://github.com/tensorflow/tensorflow/files/3801603/log.txt)


"
33947,NotImplementedError: Layers with arguments in `__init__` must override `get_config`,"Related to #32662

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
`Google Compute Engine (GPU)` running `Intel(R) Xeon(R) CPU @ 2.30GHz` 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
Model is unable to be saved using `model.save()`

**Describe the expected behavior**
Model is saved successfully.

**Code to reproduce the issue**
Code to reproduce this issue can be found on the related Stackoverflow page: https://stackoverflow.com/q/58678836/12315223

Another good reproduction of this since I'm using `Attention()` layers is found here:
https://github.com/tensorflow/tensorflow/issues/33380#issuecomment-542931948

**Other info / logs**
[log.txt](https://github.com/tensorflow/tensorflow/files/3801439/log.txt)
"
33946,"model summary, input_layer, output_layer not working properly in sub-classing method of tf.keras","**EDIT:** _After further research I found that in subclassing many of the models methods and attributes are not working examples are input_names, output_names etc.._

I am using TF2 I am trying to build a model via sub-classing method. In sequantial model; methods and attributes such as summary, input_layer, output_layer works

```
import tensorflow as tf
import tensorflow.keras as keras

model = keras.Sequential([
    keras.layers.Dense(4,input_shape=(None,3)),
    keras.layers.Dense(3, activation='relu'),
    keras.layers.Dense(2, activation='softmax')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

print(model.summary())
print(model.input_shape)
print(model.output_shape)
```

But in sub classing those methods and attributes are not working properly.

```
class MLP(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.fc1 = tf.keras.layers.Dense(4,input_shape=(None,3))
        self.fc2 = tf.keras.layers.Dense(3,activation = 'relu')
        self.fc3 = tf.keras.layers.Dense(2,activation ='softmax')
    def call(self,x):
        x = self.fc1(x)
        x = self.fc2(x)
        x = self.fc3(x)
        return x


model = MLP()
model.build((1,3))
print(model.summary())

print(model.input_shape)
print(model.output_shape)
```

The summary output in sub class model doesn't show the output shapes
```
Layer (type)                 Output Shape              Param #   
=================================================================
dense_11 (Dense)             multiple                  16        
_________________________________________________________________
dense_12 (Dense)             multiple                  15        
_________________________________________________________________
dense_13 (Dense)             multiple                  8         
=================================================================
Total params: 39
Trainable params: 39
Non-trainable params: 0
```
and model.input_shape and model.output_shape returns this error,
>raise AttributeError('The layer has never been called '
AttributeError: The layer has never been called and thus has no defined output shape."
33944,TPU support has regressed in tf-nightly (worked well in tf=2.0.0) - operation or function not registered in the binary running in this process,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (see below).  The code has been adopted from the Colab notebook (https://colab.research.google.com/drive/1yWaLpCWImXZE2fPV0ZYDdWWI8f52__9A#scrollTo=mnhwpzb73KIL) with instructions below on how to run a TPU using ctpu.  I have 90 days free access with TFRC.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Cloud TPU pair (Master VM is Linux 4.9.0-11-amd64 #1 SMP Debian 4.9.189-3+deb9u1 (2019-09-20) x86_64 GNU/Linux and TPU is v3.8 8 corel)
- TensorFlow installed from (source or binary):  binary (pip)
- TensorFlow version (use command below): Tested on tf-nightly binary (2.1.0-dev20191102) from pip.
- Python version: conda-forge 3.7.3

**Describe the current behavior**
When tf-nightly is installed, following the setup instructions below and running the attached code (yourcode.py) gives an error.  It occurs at lines 54-56 (traceback line 56) of yourcode.py:
tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
tf.config.experimental_connect_to_cluster(tpu)
tf.tpu.experimental.initialize_tpu_system(tpu)

I have marked the place at line 58 with ""# This is where the error occurs"".

The full output including the error is (follow the steps under ""Code to reproduce this issue""):

2019-11-03 06:59:16.549391: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory
2019-11-03 06:59:16.549450: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2.1.0-dev20191102
2019-11-03 06:59:18.662355: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2019-11-03 06:59:18.662422: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2019-11-03 06:59:18.662459: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mimetic): /proc/driver/nvidia/version does not exist
2019-11-03 06:59:18.663151: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-03 06:59:18.672455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-11-03 06:59:18.673297: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ca94e697b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-03 06:59:18.673382: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
INFO:absl:Overwrite dataset info from restored data version.
INFO:absl:Reusing dataset glue (gs://mimetic_store/glue/mrpc/0.0.2)
INFO:absl:Constructing tf.data.Dataset for split None, from gs://mimetic_store/glue/mrpc/0.0.2
Saved glue_mnli_train.
Saved glue_mnli_valid.
2019-11-03 07:00:41.886095: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}
2019-11-03 07:00:41.886162: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:54535}
2019-11-03 07:01:53.957214: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}
2019-11-03 07:01:53.957297: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:54535}
2019-11-03 07:01:53.958220: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:54535
INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0
Traceback (most recent call last):
  File ""yourcode.py"", line 56, in <module>
    tf.tpu.experimental.initialize_tpu_system(tpu)
  File ""/home/daniel_bonner_anu_edu_au/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/tpu/tpu_strategy_util.py"", line 103, in initialize_tpu_system
    serialized_topology = output.numpy()
  File ""/home/daniel_bonner_anu_edu_au/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 942, in numpy
    maybe_arr = self._numpy()  # pylint: disable=protected-access
  File ""/home/daniel_bonner_anu_edu_au/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 910, in _numpy
    six.raise_from(core._status_to_exception(e.code, e.message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.NotFoundError: '__inference__tpu_init_fn_4206710' is neither a type of a primitive operation nor a name of a function registered in binary running on n-48a744b7-w-0. Make sure the operation or function is registered in the binary running in this process.
2019-11-03 07:01:54.492446: W tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:75] Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error: '__inference__tpu_init_fn_4206710' is neither a type of a primitive operation nor a name of a function registered in binary running on n-48a744b7-w-0. Make sure the operation or function is registered in the binary running in this process.

**Describe the expected behavior**
When tested on tensorflow==2.0.0 from pip, the code completes. 
The whole process (with tf2.0.0) outputs at the end:
Epoch: [2] Validation accuracy = 0.843137264251709

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

Create a Google Cloud master VM and TPU pair:

ctpu up --name=yourtpupair --zone=us-central1-a --tpu-size=v3-8 --machine-type=n1-standard-8 --disk-size-gb=40

Set up a conda python 3.7 development environment with tf-nightly on the master VM

sudo apt update && sudo apt install bzip2 libxml2-dev libxslt-dev -y && wget https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh && bash Anaconda3-2019.10-Linux-x86_64.sh

Accept the defaults and initialize Anaconda

rm Anaconda3-2019.10-Linux-x86_64.sh && . ~/.bashrc && conda config --add channels anaconda && conda config --add channels conda-forge && conda config --set channel_priority strict && conda create -n yourconda python=3.7 -y && conda activate yourconda

conda install tqdm

pip install tensorflow-datasets transformers && pip install --upgrade google-api-python-client && pip install --upgrade oauth2client && pip install --ignore-installed --upgrade tf-nightly

Download the ""glue/mrpc"" dataset to ~/tensorflow_datasets in a python shell:

python
import tensorflow as tf
import tensorflow_datasets
data = tensorflow_datasets.load(""glue/mrpc"")

Create a Google storage bucket named ""your_bucket"".

Copy the entire folder (~/tensorflow_datasets/glue) to gs://your_bucket

Run the code in yourcode.py on a Google Cloud VM master's conda environment (yourconda) connected to TPU:

python yourcode.py

The output above (including the error) is produced.

Now install tensorflow==2.0.0 and rerun it and training will complete:

pip install --ignore-installed --upgrade tensorflow==2.0.0
python yourcode.py

[yourcode.py.txt](https://github.com/tensorflow/tensorflow/files/3801308/yourcode.py.txt)
(rename it yourcode.py)"
33943,The current session will be closed and a new session will be created. Error: Stream IDs exhausted,"System information
TensorFlow:

OS Platform and Distribution (e.g., centos7):
TensorFlow installed from ( binary):
TensorFlow version (1.8):
in Distrubuted TensorFlow, train 38 days, we get the error "" INFO:tensorflow:An error was raised. This may be due to a preemption in a connected worker or parameter server. The current session will be closed and a new session will be created. Error: Stream IDs exhausted "" ,
any better to solve this quesution?

more info
INFO:tensorflow:An error was raised. This may be due to a preemption in a connected worker or parameter server. The current session will be closed and a new session will be created. Error: Stream IDs exhausted
	 [[Node: Embedding/emb_D_DOCID_lookup_sparse/embedding_lookup/DynamicPartition_S9663 = _Recv[client_terminated=false, recv_device=""/job:ps/replica:0/task:0/device:CPU:0"", send_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device_incarnation=-1272333736861591317, tensor_name=""edge_636_Embedding/emb_D_DOCID_lookup_sparse/embedding_lookup/DynamicPartition"", tensor_type=DT_INT64, _device=""/job:ps/replica:0/task:0/device:CPU:0""]()]]
	 [[Node: Embedding/emb_U_USERID_lookup_sparse/embedding_lookup/GatherV2_85_S10351 = _HostRecv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device=""/job:ps/replica:0/task:0/device:CPU:0"", send_device_incarnation=-4470066425874193753, tensor_name=""edge_1755_Embedding/emb_U_USERID_lookup_sparse/embedding_lookup/GatherV2_85"", tensor_type=DT_FLOAT, _device=""/job:worker/replica:0/task:0/device:GPU:0""]()]]
	 [[Node: Embedding/emb_U_USERID_lookup_sparse/embedding_lookup/DynamicPartition_S9895 = _Recv[client_terminated=false, recv_device=""/job:ps/replica:0/task:1/device:CPU:0"", send_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device_incarnation=-1272333736861591317, tensor_name=""edge_1132_...cPartition"", tensor_type=DT_INT64, _device=""/job:ps/replica:0/task:1/device:CPU:0""]()]]
"
33942,Stacking CNN wrecks reproducibility (even with seed & CPU),"**REPRODUCIBLE**:
```python
ipt = Input(batch_shape=batch_shape)
x   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(ipt)
x   = Flatten()(x)
out = Dense(6, activation='softmax')(x)
```
**NOT REPRODUCIBLE**:
```python
ipt = Input(batch_shape=batch_shape)
x   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(ipt)
x   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(x)
x   = Flatten()(x)
out = Dense(6, activation='softmax')(x)
```
<hr>

The difference amplifies substantially when using a larger model, and actual data instead of random noise - up to **30% difference in accuracy** (relative) within a single small epoch. Environment setup, considered sources, and full minimal reproducible example below. [Relevant SO](https://stackoverflow.com/questions/58675856/why-does-stacking-cnn-wreck-reproducibility-even-with-seed-cpu?noredirect=1#comment103653213_58675856)

What is the problem, and how to fix it?

<hr>

**POSSIBLE SOURCES**: (**[x]** = ruled out)

 - **[x]** TF2 vs. TF1; Keras 2.3.0+ vs. Keras 2.2.5 (tested both)
 - **[x]** Random seeds (`numpy`, `tf`, `random`, `PYTHONHASHSEED`)
 - **[x]** Data values / shuffling (same values, no shuffling)
 - **[x]** Weight initializations (same values)
 - **[x]** GPU usage (used CPU)
 - **[x]** CPU multithreading (used single thread; also see below's 'further')
 - **[x]** Numeric imprecision (used float64; further, extent of discrepancy too large for num. impr.)
 - **[x]** Bad CUDA install (all [official guide](https://docs.nvidia.com/cuda/archive/10.0/cuda-installation-guide-microsoft-windows/index.html) tests passed, TF detects GPU & CUDA)

<hr>

**ENVIRONMENT**:

 - CUDA 10.0.130, cuDNN 7.6.0, Windows 10, GTX 1070
 - Python 3.7.4, Spyder 3.3.6, Anaconda 3.0 10/19
 - Anaconda Powershell Prompt terminal to set `PYTHONHASHSEED` and start Spyder

<hr>

**OBSERVATIONS**:

 - `float64` vs. `float32` - no noticeable difference
 - CPU vs. GPU - no noticeable difference
 - Non-reproducible also for `Conv1D`
 - Reproducible for `Dense` replacing `Conv`; other layers not tested
 - For a [larger model](https://pastebin.com/VSV7jv7x), which is still 'small', loss variance is substantial within a single epoch:

```python
one_epoch_loss = [1.6814, 1.6018, 1.6577, 1.6789, 1.6878, 1.7022, 1.6689]
one_epoch_acc  = [0.2630, 0.3213, 0.2991, 0.3185, 0.2583, 0.2463, 0.2815]
```

<hr>

**CODE**:

```python
batch_shape = (32, 64, 64, 3)
num_samples = 1152

ipt = Input(batch_shape=batch_shape)
x   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(ipt)
x   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(x)
x   = Flatten()(x)
out = Dense(6, activation='softmax')(x)
model = Model(ipt, out)
model.compile('adam', 'sparse_categorical_crossentropy')

X = np.random.randn(num_samples, *batch_shape[1:])
y = np.random.randint(0, 6, (num_samples, 1))

reset_seeds()
model.fit(x_train, y_train, epochs=5, shuffle=False)
```
<hr>

**Imports / setup**:


```python
import os
os.environ['PYTHONHASHSEED'] = '0'
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
import numpy as np
np.random.seed(1)
import random
random.seed(2)

import tensorflow as tf
session_conf = tf.ConfigProto(
      intra_op_parallelism_threads=1,
      inter_op_parallelism_threads=1)
sess = tf.Session(config=session_conf) # single-threading; TF1-only

def reset_seeds():
    np.random.seed(1)
    random.seed(2)
    if tf.__version__[0] == '2':
        tf.random.set_seed(3)
    else:
        tf.set_random_seed(3)
    print(""RANDOM SEEDS RESET"")
reset_seeds()

from keras.layers import Input, Dense, Conv2D, Flatten
from keras.models import Model
import keras.backend as K

K.set_floatx('float64')
```"
33941,Visualize accuracy on tensorboard,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.13.1
- Python version:3.6.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:9/7.4
- GPU model and memory: Nvidia Geforce 840m 4 Go

**Describe the current behavior**
Hello,
I'm trained a model and I have all .ckpts files with `graph.pbtxt` and `checkpoint` file.
I would like to visualize all parameters, for e.g ( accuracy , precision , valid loss and train loss ) using Tensorboard.
The problem is that I can only visualize the loss and the learning_rate graph

How can I see all the metrics and graphs on Tensorboard? 

"
33940,Add dropout layer to a Resnet Model,"Hello, 
This is not a bug, I'm searching for help or a suggestion, I have posted many questions on StackOverflow but I didn't get any answer.
I search for a way to add a dropout layer to improve the precision and accuracy of the model.
```python
    flatten = tf.layers.flatten(inputs=conv8)

   # dropout=tf.layers.dropout(inputs=flatten,training=false) # Add dropout here

    # Dense layer 1, a fully connected layer.
    dense1 = tf.layers.dense(
        inputs=flatten,
        units=1024,
        activation=tf.nn.relu,
        use_bias=True)

    # Dense layer 2, also known as the output layer.
    logits = tf.layers.dense(
        inputs=dense1,
        units=80,
        activation=None,
        use_bias=True,
        name=""logits"")

    # Make prediction for PREDICATION mode.
    predictions_dict = {
        ""name"": features['name'],
        ""logits"": logits
    }

```

Is it possible to add dropout layer between the flatten and the dense layer?
"
33939,Laconic error when validation_steps ommitted for model.fit in TF 2.0.0,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): **Colab**
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: **TPU selected Colab**

**Describe the current behavior**
When running the script below on TF 1.15, it runs well throughout.
Running in TF 2.0, it crashes on the validation stage of the first epoch.
if `validation_steps` in `model.fit` is included it does run throughout.
however, if it's omitted (which is natural to assume, as the dataset itself is not repeated)
a strange error message `TypeError: 'function' object is not subscriptable` is given.

**Describe the expected behavior**
Either, TF 2 should behave similarly to TF 1, ie use up the entire validation set.
Or report a more informative error regarding 'validation_steps' requirement (similar to the error if steps_per_epoch are omitted for the training data).

**Code to reproduce the issue**
```
%tensorflow_version 2.x  #(commented out for TF 1.x case)
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
import os

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

IMG_HEIGHT=IMG_WIDTH=200
BATCH_SIZE=128

def create_model():
  model = tf.keras.models.Sequential()
  model.add(tf.keras.layers.BatchNormalization(input_shape=(IMG_HEIGHT,IMG_WIDTH,1)))
  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='elu'))
  model.add(tf.keras.layers.MaxPooling2D(2))
  model.add(tf.keras.layers.Dropout(0.25))

  model.add(tf.keras.layers.BatchNormalization(input_shape=(IMG_HEIGHT,IMG_WIDTH,3)))
  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='elu'))
  model.add(tf.keras.layers.MaxPooling2D(2))
  model.add(tf.keras.layers.Dropout(0.25))

  model.add(tf.keras.layers.BatchNormalization(input_shape=(IMG_HEIGHT,IMG_WIDTH,3)))
  model.add(tf.keras.layers.Conv2D(64, (5, 5), activation='elu'))
  model.add(tf.keras.layers.MaxPooling2D(2))
  model.add(tf.keras.layers.Dropout(0.25))

  model.add(tf.keras.layers.BatchNormalization())
  model.add(tf.keras.layers.Conv2D(128, (3, 3),  activation='elu'))
  model.add(tf.keras.layers.MaxPooling2D(2))
  model.add(tf.keras.layers.Dropout(0.25))

  model.add(tf.keras.layers.BatchNormalization())
  model.add(tf.keras.layers.Conv2D(256, (3, 3),  activation='elu'))
  #model.add(tf.keras.layers.MaxPooling2D(2))
  model.add(tf.keras.layers.Dropout(0.25))

  model.add(tf.keras.layers.BatchNormalization())
  model.add(tf.keras.layers.Conv2D(512, (3, 3),  activation='elu'))
  model.add(tf.keras.layers.MaxPooling2D(2))
  model.add(tf.keras.layers.Dropout(0.25))

  model.add(tf.keras.layers.Flatten())
  model.add(tf.keras.layers.Dense(256))
  model.add(tf.keras.layers.Activation('elu'))
  model.add(tf.keras.layers.Dropout(0.5))
  model.add(tf.keras.layers.Dense(10))
  model.add(tf.keras.layers.Activation('softmax'))
  return model


with strategy.scope():
  train_ds = (tfds.load(""mnist:3.*.*"", split=""train"", as_supervised=True, try_gcs=True)
    .map(lambda image,label:(tf.image.convert_image_dtype(image, tf.float32),label))
    .map(lambda image,label:(tf.image.resize(image,(IMG_HEIGHT,IMG_WIDTH)),label))
    #.map(lambda image,label:(tf.cast(image, tf.float32)/255.0,tf.cast(label, tf.float32)))
    .batch(BATCH_SIZE))

  #distributed_train_ds=strategy.experimental_distribute_dataset(train_ds)

  validation_ds = (tfds.load(""mnist:3.*.*"", split=""test"", as_supervised=True, try_gcs=True)
    .map(lambda image,label:(tf.image.convert_image_dtype(image, tf.float32),label))
    .map(lambda image,label:(tf.image.resize(image,(IMG_HEIGHT,IMG_WIDTH)),label))
    #.map(lambda image,label:(tf.cast(image, tf.float32)/255.0,tf.cast(label, tf.float32)))
    .batch(BATCH_SIZE))

  #distributed_validation_ds=strategy.experimental_distribute_dataset(validation_ds)

  model=create_model()
  model.compile(
        optimizer=tf.keras.optimizers.Adam(),
        loss=""sparse_categorical_crossentropy"",
        metrics=['sparse_categorical_accuracy'])

model.fit(train_ds,epochs=3,steps_per_epoch=100,validation_data=validation_ds)
```
this produces this output, after going through the training fine, it crashes on the validation set
```
Train on 100 steps
Epoch 1/3
 99/100 [============================>.] - ETA: 0s - loss: 1.4453 - sparse_categorical_accuracy: 0.7015
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-10-fd27085b00aa> in <module>()
----> 1 model.fit(train_ds,epochs=3,steps_per_epoch=100,validation_data=validation_ds)

5 frames
/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_utils.py in check_num_samples(ins, batch_size, steps, steps_name)
    425     return None
    426 
--> 427   if hasattr(ins[0], 'shape'):
    428     return int(ins[0].shape[0])
    429   return None  # Edge case where ins == [static_learning_phase]

TypeError: 'function' object is not subscriptable

```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33938,CUDNN_STATUS_EXECUTION_FAILED,"**System information**
- I have written custom code (as opposed to using a stock example script provided in TensorFlow): Slightly modified version of seq2seq model from keras documentation 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.0.0 Stable
- Python version: 3.7.5
- CUDA/cuDNN version: CUDA-10.0, CuDNN-7.6.4.38
- GPU model and memory: Nvidia 1050Ti(4GB) + 16GB RAM

**Describe the current behavior**
I'm getting an error while training on a small dataset using a seq2seq model. It trains upto 4 or 5 epochs after which it throws an error saying ""CUDNN_STATUS_EXECUTION_FAILED"" along with ""Failed to call ThenRnnBackward""

**Describe the expected behavior**
I have tried reducing batch size and LSTM latent dimension but it crashes irrespectively. I recently updated to tf 2.0.0 and I never faced any such issues on 1.x

**Code to reproduce the issue**


batch_size = 16
epochs = 50
latent_dim = 50
training_samples = 5000

encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens),dtype='float32')
decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype='float32')
decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype='float32')

for i, (input_text, target_text) in enumerate(zip(input_texts, output_texts)):
    for t, char in enumerate(input_text):
        encoder_input_data[i, t, input_token_index.get(char)] = 1.
    encoder_input_data[i, t + 1:, input_token_index.get(' ')] = 1.

    for t, char in enumerate(target_text):
        decoder_input_data[i, t, target_token_index.get(char)] = 1.
        if t > 0:
            decoder_target_data[i, t - 1, target_token_index.get(char)] = 1.
    decoder_input_data[i, t + 1:, target_token_index.get(' ')] = 1.
    decoder_target_data[i, t:, target_token_index.get(' ')] = 1.


encoder_inputs = tf.keras.layers.Input(shape=(None, num_encoder_tokens))
encoder = tf.keras.layers.LSTM(latent_dim, return_state=True)
encoder_outputs, state_h, state_c = encoder(encoder_inputs)
encoder_states = [state_h, state_c]

encoder_input_datas = tf.keras.layers.Input(shape=(None,num_encoder_tokens))
encoder = tf.keras.layers.LSTM(latent_dim,return_state=True)
encoder_outputs, state_h, state_c = encoder(encoder_input_datas)
encoder_states = [state_h,state_c]

decoder_inputs = tf.keras.layers.Input(shape=(None,num_decoder_tokens))
decoder = tf.keras.layers.LSTM(latent_dim,return_sequences=True,return_state=True)
decoder_outputs,_,_ = decoder(decoder_inputs,initial_state=encoder_states)
decoder_dense = tf.keras.layers.Dense(num_decoder_tokens,activation='softmax')
decoder_outputs = decoder_dense(decoder_outputs)

model = tf.keras.models.Model([encoder_input_datas,decoder_inputs],decoder_outputs)

model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])
model.fit([encoder_input_data,decoder_input_data],decoder_target_data,epochs=epochs)

**Other info / logs**
Full log:
https://pastebin.com/Yht9t6fZ
"
33937,"CuDNN faild to initialize after correct installation, ","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): PiP
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0/7.6.3
- GPU model and memory: RTX 2080TI

**Describe the current behavior**
CuDNN faild to initialize after correct installation, cant make TF2 work

**Describe the expected behavior**
training a conv network without an error

**Other info / logs**

> UnknownError                              Traceback (most recent call last)
<ipython-input-12-4f1e47465b18> in <module>
      1 # Train model
----> 2 model.fit(x, y, epochs=5)

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--> 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    322                 mode=ModeKeys.TRAIN,
    323                 training_context=training_context,
--> 324                 total_epochs=epochs)
    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    326 

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    121         step=step, mode=mode, size=current_batch_size) as batch_logs:
    122       try:
--> 123         batch_outs = execution_function(iterator)
    124       except (StopIteration, errors.OutOfRangeError):
    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in execution_function(input_fn)
     84     # `numpy` translates Tensors to values in Eager mode.
     85     return nest.map_structure(_non_none_constant_value,
---> 86                               distributed_function(input_fn))
     87 
     88   return execution_function

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--> 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    518         # Lifting succeeded, so variables are initialized and we can run the
    519         # stateless function.
--> 520         return self._stateless_fn(*args, **kwds)
    521     else:
    522       canon_args, canon_kwds = \

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   1821     """"""Calls a graph function specialized to the inputs.""""""
   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   1824 
   1825   @property

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
   1139          if isinstance(t, (ops.Tensor,
   1140                            resource_variable_ops.BaseResourceVariable))),
-> 1141         self.captured_inputs)
   1142 
   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1222     if executing_eagerly:
   1223       flat_outputs = forward_function.call(
-> 1224           ctx, args, cancellation_manager=cancellation_manager)
   1225     else:
   1226       gradient_name = self._delayed_rewrite_functions.register()

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    509               inputs=args,
    510               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 511               ctx=ctx)
    512         else:
    513           outputs = execute.execute_with_cancellation(

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

C:\ProgramData\Anaconda3\lib\site-packages\six.py in raise_from(value, from_value)

UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node sequential_1/conv2d_8/Conv2D (defined at C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:1751) ]] [Op:__inference_distributed_function_2411]

Function call stack:
"
33936,sigmoid is ignored when calculating loss by calling method model.fit,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Windoiws

Version: ('v2.0.0-rc2-26-g64c3d382ca', '2.0.0')

**Describe the current behavior**
    I got a incorrect loss from history returned by calling model.fit.  You can see the correct and  incorrect result by change parameter ""error "" from my code.

**Code to reproduce the issue**
```python
import math
import numpy as np
import tensorflow as tf

error = True
n_features = 100
batch = 2

""""""
model
""""""
x = tf.keras.Input(shape=(n_features,), dtype=tf.float32)
w = tf.Variable([1.0] * n_features)
b = tf.Variable(1.0)
z = tf.reduce_sum(w * x, axis=1, keepdims=True) + b

""""""
loss is incorrect if error is true
""""""
if error:
    y_ = tf.sigmoid(z)
else:
    y_ = 1.0 / (1.0 + math.e ** (-z))

m = tf.keras.Model(inputs=x, outputs=y_)

""""""
loss
""""""
optimizer=tf.keras.optimizers.SGD(learning_rate=0.001)
loss = tf.keras.losses.BinaryCrossentropy()
m.compile(optimizer = optimizer, loss = loss)

""""""
train dataset
""""""
x = np.array([[1.0 for i in range(n_features)]] * batch, dtype=np.float32)
y = np.array([0.0] * batch, dtype=np.float32)

""""""
get correct loss
""""""
logits = m(x)
l = loss(y, logits)

""""""
get incorrect loss
""""""
history = m.fit(x, y)

""""""
history.history['loss'] != l.numpy()
""""""
print(history.history)
print(l.numpy())
```"
33935,Remove h5py hard dependency to support python 3.8 on Ubuntu 18.04,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): master
- Are you willing to contribute it (Yes/No): yes



**Describe the feature and the current behavior/state.**

At the moment, I have been able to build tensorflow master on Ubuntu 18.04 with Python 3.8. However, the generated wheel package still could not be installed because `h5py` could not be installed on Ubuntu 18.04 with python 3.8 support.

Note I am using python 3.8 deadsnake/ppa.

I checked the dependency maps of pip. It looks like h5py is not a hard dependency as in tensorflow h5py is dynamically loaded.

If h5py could be removed from the pip requirement, then I think tensorflow could fully support python 3.8.

**Will this change the current api? How?**

n/a

**Who will benefit with this feature?**

python 3.8 support for tensorflow

**Any Other info.**
"
33934,Unable to install tflite-runtime,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
uname -a
Linux matje 4.19.0-5-amd64 #1 SMP Debian 4.19.37-5+deb10u2 (2019-08-08) x86_64 GNU/Linux
- Python version:
python3 --version
Python 3.7.3
- Installed using virtualenv? pip? conda?:
pipsi list
Packages and scripts installed through pipsi:
  Package ""pipsi"":
    pipsi
  Package ""virtualenv"":
    virtualenv

**Describe the problem**
Unable to install tflite-runtime

**Provide the exact sequence of commands / steps that you executed before running into the problem**
pipsi install tflite_runtime-1.14.0-cp37-cp37m-linux_x86_64.whl 
Running virtualenv with interpreter /root/.local/venvs/pipsi/bin/python3
Already using interpreter /root/.local/venvs/pipsi/bin/python3
Using base prefix '/usr'
New python executable in /root/.local/venvs/tflite-runtime-1.14.0-cp37-cp37m-linux-x86-64.whl/bin/python3
Also creating executable in /root/.local/venvs/tflite-runtime-1.14.0-cp37-cp37m-linux-x86-64.whl/bin/python
Installing setuptools, pip, wheel...
done.
Processing ./tflite_runtime-1.14.0-cp37-cp37m-linux_x86_64.whl
Installing collected packages: tflite-runtime
Successfully installed tflite-runtime-1.14.0
Did not find any scripts.  Uninstalling.

"
33933,AttributeError: module 'tensorflow_core.compat.v1.compat' has no attribute 'v1',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33932,Exif Orientation support tf.image.decode_jpeg(),"Hi.
I have large amounts of JPEG files uploaded by users on our service .
They use mainly smartphone camera, so most files contain **EXIF orientation metadata.**

It would seem that the **tf.image.decode_jpeg() ignores this information.** How about adding support for these meta informations, especially orientation ?

This issue is from 
> https://github.com/tensorflow/tensorflow/issues/8430#issue-214362114

**But I found this problem is still existing. Anybody knows how to solve this probelm? I found opencv take the EXIF information into count, but it's hard to use opencv to replace tensorflow image processor.**
```python
        image_bgr = cv2.imread(file_name)
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
        image = np.asarray(image_rgb)
        # image_buffer = tf.read_file(file_name)
        # image_rgb = tf.image.decode_jpeg(image_buffer)
        # image = tf.cond(tf.equal(tf.shape(image_rgb)[2], 1), lambda: tf.image.grayscale_to_rgb(image_rgb), lambda: tf.identity(image_rgb))
```"
33931," in tutorials/load_data/csv ,when trying twice, the test_data is different?","



## URL(s) with the issue:

https://tensorflow.google.cn/tutorials/load_data/csv

## Description of issue (what needs changing):

### Clear description

when run the last code :loop, retry it ,the result is different 

then run the last code 
>>>list(test_data)[0][1][:10]
>>>list(test_data)[0][1][:10]
why the test_data is not shuffled,but result is different

if this ,the actual label is not trustworthy
![5I7`)`M@7HBT@04EG5~(5~6](https://user-images.githubusercontent.com/41684325/68068668-16bc4300-fd92-11e9-992b-9bf9fa743a8c.png)











"
33929,Optimizer clipvalue and clipnorm not working in Tensorflow 2.0,"
**System information**
- Python 3 Google Compute Engine backend (GPU)

**Describe the current behavior**
clipvalue and clipnorm in Optimizers does nothing!

**Describe the expected behavior**
By setting clipvalue=0 or clipnorm=0 no training should occur (gradients should be 0!), but the network still trains, and if using a large learning rate, loss goes to nan.

**Code to reproduce the issue**
![image](https://user-images.githubusercontent.com/567732/68066124-4d01b000-fd09-11e9-8e41-51ece3684869.png)
**Gradient is clearly not zero since the network is getting modified at each iteration.**

![image](https://user-images.githubusercontent.com/567732/68066145-7589aa00-fd09-11e9-8c94-1ae4bcf33e45.png)
**Sanity check by setting lr=0**
**No training occurs when lr=0, as expected.**
"
33928,How to add optimizer in tensorflow CNN,"I wanna know how to add an optimizer such as Adam, or Nadam optimizer to the simple speech recognition example in this repository? Because I don't know where to or how to add it in the code such as to ""model.py"" file or where and how?"
33927,tf_upgrade_v2 can't work on windows,"This is my command
```
tf_upgrade_v2 --infile model_train_testByreallydata.py --outfile model_train_testByreallydata_tf2.py
```

It will get 

```
(tensorflow2) C:\Users\63110\OneDrive\github-backup\mhxy-captcha>tf_upgrade_v2 --infile model_train_testByreallydata.py --outfile model_train_testByreallydata_tf2.py
Traceback (most recent call last):
  File ""E:\ProgramData\Anaconda3\envs\tensorflow2\Scripts\tf_upgrade_v2-script.py"", line 10, in <module>
    sys.exit(main())
  File ""E:\ProgramData\Anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\tools\compatibility\tf_upgrade_v2_main.py"", line 139, in main
    args.input_file, output_file, upgrade)
  File ""E:\ProgramData\Anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\tools\compatibility\tf_upgrade_v2_main.py"", line 40, in process_file
    upgrader.process_file(in_filename, out_filename)
  File ""E:\ProgramData\Anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\tools\compatibility\ast_edits.py"", line 900, in process_file
    temp_file)
  File ""E:\ProgramData\Anaconda3\envs\tensorflow2\lib\site-packages\tensorflow_core\tools\compatibility\ast_edits.py"", line 958, in process_opened_file
    lines = in_file.readlines()
UnicodeDecodeError: 'gbk' codec can't decode byte 0xa7 in position 300: illegal multibyte sequence

```

Os:
windows 10 

Python Version:
3.7 from Anaconda

"
33925,RuntimeError: Quantization not yet supported for op: CUSTOM in Post Training Quantization,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (or github SHA if from source): r1.15

Following error occurs when implementing post training [full integer quantizati](https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization_of_weights_and_activations)on of weights and activations. 
I am using [SSD Mobilenet 2](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz) model from TensorFlow model zoo.

I am following exact steps given on TensorFlow website.
I think it is due to [add_postprocessing_op](https://github.com/tensorflow/models/blob/9df6a3d6d09b360c8775426a8746783ad2d0d4a6/research/object_detection/export_tflite_ssd_graph.py#L39) parameter in export_tflite_ssd_graph.py. 
INT8 implementation is not available for that. 

How this issue can be solved for post training quantization? Is there any temporary work around?
 
**Any other info / logs**
Code to Reproduce

```
import tensorflow as tf
def representative_dataset_gen():
  for _ in range(num_calibration_steps):
    # Get sample input data as a numpy array in a method of your choosing.
    yield [input]

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
converter.representative_dataset = representative_dataset_gen
tflite_quant_model = converter.convert()
```

Traceback (most recent call last):
  File ""weight_quantize.py"", line 46, in <module>
    tflite_quant_model = converter.convert()
  File ""/home/morrisc/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py"", line 993, in convert
    inference_output_type)
  File ""/home/morrisc/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py"", line 239, in _calibrate_quantize_model
    inference_output_type, allow_float)
  File ""/home/morrisc/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/optimize/calibrator.py"", line 78, in calibrate_and_quantize
    np.dtype(output_type.as_numpy_dtype()).num, allow_float)
  File ""/home/morrisc/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py"", line 115, in QuantizeModel
    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, input_py_type, output_py_type, allow_float)
RuntimeError: Quantization not yet supported for op: CUSTOM

However, if I don't enforce full integer quantization for all ops and use integer input and output. It works. But such model won't run Edge TPU
"
33924,Bidirectional LSTM fail on TF2.0,"I tried to reproduce the ""Text classification with an RNN"" article from tensorflow main page (https://www.tensorflow.org/tutorials/text/text_classification_rnn), but it seems that the code is not running properly when it's executed on my local machine. Unfortunatly, I'm not able to reproduce the error on Colab.

It run for few iteration, but no more than 1 epochs..

**System information**
- Code is provided by TensorFlow
- Running on Windows 10
- TensorFlow installed from pip
- TensorFlow version 2.0
- Python version 3.6
- CUDA 10.0 /cuDNN 7.6.4.38
- GeForce GTX 1060


****

**I get the following error**

2019-11-01 21:49:02.287950: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_INTERNAL_ERROR
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1915): 'cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'
2019-11-01 21:49:02.289212: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at cudnn_rnn_ops.cc:1899 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1974, 64, 64] 
2019-11-01 21:49:02.289778: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1974, 64, 64] 
	 [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]
2019-11-01 21:49:02.290428: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.
	 [[{{node Reshape_11/_38}}]]
	 [[Adam/Adam/update/AssignSubVariableOp/_41]]
2019-11-01 21:49:02.291354: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.
	 [[{{node Reshape_11/_38}}]]
    313/Unknown - 40s 128ms/step - loss: 0.6864 - accuracy: 0.5492
    313/Unknown - 40s 128ms/step - loss: 0.6864 - accuracy: 0.5492Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydevd_bundle\pydevd_exec2.py"", line 3, in Exec
    exec(exp, global_vars, local_vars)
  File ""<string>"", line 4, in <module>
  File ""C:\Users\Woody\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""C:\Users\Woody\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""C:\Users\Woody\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""C:\Users\Woody\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""C:\Users\Woody\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\Woody\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 487, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""C:\Users\Woody\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1823, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""C:\Users\Woody\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File ""C:\Users\Woody\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""C:\Users\Woody\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\eager\function.py"", line 511, in call
    ctx=ctx)
  File ""C:\Users\Woody\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\eager\execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.
	 [[{{node Reshape_11/_38}}]] [Op:__inference_distributed_function_7835]

Function call stack:
distributed_function

Exception ignored in: <bound method _RandomSeedGeneratorDeleter.__del__ of <tensorflow.python.data.ops.dataset_ops._RandomSeedGeneratorDeleter object at 0x000001D23EA44278>>
Traceback (most recent call last):
  File ""C:\Users\Woody\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\data\ops\dataset_ops.py"", line 3009, in __del__
AttributeError: 'NoneType' object has no attribute 'device'

****
I tried to change the optimizer, use GRU or other RNN, but as soon as I get the Bidirectional wrapper, I get this error.
TensorFlow-gpu is up to date, drivers are as well.

****
**The Code to reproduce the error is litterally the one from the webpage**
https://www.tensorflow.org/tutorials/text/text_classification_rnn
"
33923,Insert Windows command line in the tutorials,"## URL(s) with the issue:

Example: https://www.tensorflow.org/tutorials/keras/save_and_load

## Description of issue (what needs changing):
 
The tutorial uses POSIX commands like:

`!ls {checkpoint_dir}`

Unfortunately I am on Windows so those commands does not work. Is there no way to condition the command on the OS?

`!dir {checkpoint_dir}`

The alternative way would be to use Python straightaway:

```
onlyfiles = [f for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]
print(onlyfiles)
```"
33922,tf.compat purpose may be misstated,"## URL(s) with the issue
https://www.tensorflow.org/api_docs/python/tf/compat

## Description of issue (what needs changing):
Docs say

> Functions for Python 2 vs. 3 compatibility.

But on [StackOverflow they told me that](https://stackoverflow.com/questions/58631390/what-is-the-purpose-of-tf-compat)

> The documentation for the module about Python should actually be changed. Originally, tf.compat only held functions for that purpose (and it was like that until 1.13, see all module documentation). However, it was later repurposed for TensorFlow version compatibility."
33920,Collective AllReduce ops cannot run with variables shared across tasks in between-graph replication,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): installed by `pip install tensorflow-gpu`
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10.0 and cudnn 7.6
- GPU model and memory:   Tesla V100, ~16Gb

**Describe the current behavior**
The collective ops executor will fail with the following program.

**Describe the expected behavior**
The expected behavior is that the program should run correctly in a between-graph replication as if the graph does not contain collective ops everything will run correctly.

**Code to reproduce the issue**
```python
import threading
from multiprocessing import Process

import tensorflow as tf
from tensorflow.core.protobuf import config_pb2
from tensorflow.python import ops
from tensorflow.python.client.session import Session
from tensorflow.python.ops import collective_ops

cluster_spec = {
    ""worker"": [
        ""localhost:14286"",
        ""localhost:14287""
    ]
}
inputs = [0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1]
group_size = 4
group_key = 1
instance_key = 1
use_nccl = False
num_gpus_per_node = 2


def _configure(group_size):
    gpu_options = config_pb2.GPUOptions(
        visible_device_list='0,1',
        per_process_gpu_memory_fraction=0.7 / (group_size))
    experimental = config_pb2.ConfigProto.Experimental(collective_nccl=use_nccl)
    experimental.collective_group_leader = '/job:worker/replica:0/task:0'
    return config_pb2.ConfigProto(gpu_options=gpu_options, experimental=experimental)


class TFCluster(object):
    def __init__(self, cluster_spec):
        self._cluster_spec = cluster_spec
        self._num_worker = 0
        self._tf_servers = []

    def start(self):
        def server(job_name: str, task_index: int):
            server = tf.distribute.Server(self._cluster_spec,
                                          job_name=job_name,
                                          task_index=task_index,
                                          config=_configure(group_size))
            server.join()

        self._num_worker = len(cluster_spec.get(""worker"", []))
        assert self._num_worker >= 1
        for i in range(self._num_worker):
            self._tf_servers.append(Process(target=server,
                                            args=(""worker"", i), daemon=True))
        for proc in self._tf_servers:
            proc.start()

    def stop(self):
        for proc in self._tf_servers:
            proc.terminate()


def between_graph_test():
    def run_between_graph_clients(client_fn, cluster_spec, num_gpus, *args,
                                  **kwargs):
        threads = []
        for task_type in ['chief', 'worker']:
            for task_id in range(len(cluster_spec.get(task_type, []))):
                t = threading.Thread(
                    target=test_reduction,
                    args=(task_type, task_id, num_gpus) + args,
                    kwargs=kwargs)
                t.start()
                threads.append(t)
        for t in threads:
            t.join()

    def test_reduction(task_type,
                       task_id,
                       num_gpus):
        worker_device = ""/job:%s/task:%d"" % (task_type, task_id)
        master_target = ""grpc://"" + cluster_spec[task_type][0]
        with ops.Graph().as_default(), Session(target=master_target) as sess:
            collectives = []
            for i in range(num_gpus):
                with ops.device('/job:worker/task:0/device:CPU:0'):  # make sure all use the same variable
                    t = tf.Variable(inputs)
                with ops.device(worker_device + '/device:GPU:' + str(i)):
                    collectives.append(collective_ops.all_reduce(
                        t, group_size, group_key, instance_key, 'Add', 'Div'))
            run_options = config_pb2.RunOptions()
            run_options.experimental.collective_graph_key = 6
            sess.run(tf.compat.v1.global_variables_initializer())
            res_m = sess.run(collectives, options=run_options)
            print(res_m)

    run_between_graph_clients(
        test_reduction,
        cluster_spec,
        num_gpus_per_node)

# launch in-process clusters
cluster = TFCluster(cluster_spec)
cluster.start()

# run between graph execution
between_graph_test()
cluster.stop()

```


**Other info / logs**
```
2019-11-01 18:37:48.066477: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:14286
2019-11-01 18:37:48.066556: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:14287
2019-11-01 18:37:48.733123: I tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc:161] Skipping rendezvous re-initialization.
2019-11-01 18:37:50.385293: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Aborted: [_Derived_]Cleanup 95609632845199527
	 [[{{node CollectiveReduce}}]]
2019-11-01 18:37:50.385319: W tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc:510] RecvTensor cancelled for 95609632845199527
[array([0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1], dtype=float32), array([0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1], dtype=float32)]
Exception in thread Thread-2:
Traceback (most recent call last):
  File ""/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call
    return fn(*args)
  File ""/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn
    target_list, run_metadata)
  File ""/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.AbortedError: From /job:worker/replica:0/task:0:
[_Derived_]Cleanup 95609632845199527
	 [[{{node CollectiveReduce}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/ubuntu/anaconda3/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/home/ubuntu/anaconda3/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/ubuntu/pycharm/examples/allreduce/test_collective.py"", line 91, in test_reduction
    res_m = sess.run(collectives, options=run_options)
  File ""/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 956, in run
    run_metadata_ptr)
  File ""/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.AbortedError: From /job:worker/replica:0/task:0:
[_Derived_]Cleanup 95609632845199527
	 [[node CollectiveReduce (defined at /arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]

Original stack trace for 'CollectiveReduce':
  File ""/anaconda3/lib/python3.6/threading.py"", line 884, in _bootstrap
    self._bootstrap_inner()
  File ""/anaconda3/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/anaconda3/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""/pycharm/examples/allreduce/test_collective.py"", line 87, in test_reduction
    t, group_size, group_key, instance_key, 'Add', 'Div'))
  File ""/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/ops/collective_ops.py"", line 58, in all_reduce
    subdiv_offsets=subdiv_offsets)
  File ""/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_collective_ops.py"", line 349, in collective_reduce
    name=name)
  File ""/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper
    op_def=op_def)
  File ""/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op
    attrs, op_def, compute_device)
  File ""/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal
    op_def=op_def)
  File ""/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__
    self._traceback = tf_stack.extract_stack()

```
"
33919,parallel_for: No converter defined for SpaceToBatchND,"Computation of jacobian with ```pfor``` does not work for ``` tf.keras.layers.Convolution2D``` with ```dilation_rate>1``` because there is no converter implemented for ```SpaceToBatchND```

tf-version: 2.1.0-dev20191030

```python
import tensorflow as tf

Nlat=10
Nlon=20
n_channels_in = 1
x = tf.ones((1,Nlat,Nlon,n_channels_in))
layer1 = tf.keras.layers.Convolution2D(32, kernel_size=3, dilation_rate=1)
layer2 = tf.keras.layers.Convolution2D(32, kernel_size=3, dilation_rate=2)


with tf.GradientTape(persistent=True) as gt:
    gt.watch(x)
    y1 = layer1(x)
    y2 = layer2(x)

J = gt.jacobian(y1, x)  # works
J2 = gt.jacobian(y2, x) # fails with following error:
```

```python
ValueError                                Traceback (most recent call last)
/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py in jacobian(self, target, sources, unconnected_gradients, parallel_iterations, experimental_use_pfor)
   1112         output = pfor_ops.pfor(loop_fn, target_size,
-> 1113                                parallel_iterations=parallel_iterations)
   1114       except ValueError as err:

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py in pfor(loop_fn, iters, parallel_iterations)
    188     f = function.defun(f)
--> 189   return f()
    190 

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   2340     with self._lock:
-> 2341       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
   2342     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2675       self._function_cache.missed.add(call_context_key)
-> 2676       graph_function = self._create_graph_function(args, kwargs)
   2677       self._function_cache.primary[cache_key] = graph_function

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2565             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2566             capture_by_value=self._capture_by_value),
   2567         self._function_attributes,

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    957 
--> 958       func_outputs = python_func(*func_args, **func_kwargs)
    959 

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
    947             if hasattr(e, ""ag_error_metadata""):
--> 948               raise e.ag_error_metadata.to_exception(e)
    949             else:

ValueError: in converted code:
    relative to /pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for:

    control_flow_ops.py:183 f  *
        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    control_flow_ops.py:256 _pfor_impl
        outputs.append(converter.convert(loop_fn_output))
    pfor.py:1280 convert
        output = self._convert_helper(y)
    pfor.py:1460 _convert_helper
        (y_op.type, y_op, converted_inputs))

    ValueError: No converter defined for SpaceToBatchND
    name: ""loop_body/SpaceToBatchND""
    op: ""SpaceToBatchND""
    input: ""loop_body/Reshape_2""
    input: ""loop_body/SpaceToBatchND/block_shape""
    input: ""loop_body/SpaceToBatchND/paddings""
    attr {
      key: ""T""
      value {
        type: DT_FLOAT
      }
    }
    attr {
      key: ""Tblock_shape""
      value {
        type: DT_INT32
      }
    }
    attr {
      key: ""Tpaddings""
      value {
        type: DT_INT32
      }
    }
    
    inputs: [WrappedTensor(t=<tf.Tensor 'loop_body/Reshape_2/pfor/Reshape:0' shape=(3072, 1, 6, 16, 32) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/SpaceToBatchND/block_shape:0' shape=(2,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/SpaceToBatchND/paddings:0' shape=(2, 2) dtype=int32>, is_stacked=False, is_sparse_stacked=False)]. 
    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower


During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<ipython-input-29-dd023aa8e2b5> in <module>
----> 1 J2 = gt.jacobian(y2, x) # fails

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py in jacobian(self, target, sources, unconnected_gradients, parallel_iterations, experimental_use_pfor)
   1119                 ""jacobian computation. Vectorization can be disabled by setting""
   1120                 "" experimental_use_pfor to False.""),
-> 1121             sys.exc_info()[2])
   1122     else:
   1123       if context.executing_eagerly() and not self._persistent:

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/six.py in reraise(tp, value, tb)
    690                 value = tp()
    691             if value.__traceback__ is not tb:
--> 692                 raise value.with_traceback(tb)
    693             raise value
    694         finally:

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py in jacobian(self, target, sources, unconnected_gradients, parallel_iterations, experimental_use_pfor)
   1111       try:
   1112         output = pfor_ops.pfor(loop_fn, target_size,
-> 1113                                parallel_iterations=parallel_iterations)
   1114       except ValueError as err:
   1115         six.reraise(

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py in pfor(loop_fn, iters, parallel_iterations)
    187   if context.executing_eagerly() or _is_under_xla_context():
    188     f = function.defun(f)
--> 189   return f()
    190 
    191 

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   2339     """"""Calls a graph function specialized to the inputs.""""""
   2340     with self._lock:
-> 2341       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
   2342     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2343 

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2674 
   2675       self._function_cache.missed.add(call_context_key)
-> 2676       graph_function = self._create_graph_function(args, kwargs)
   2677       self._function_cache.primary[cache_key] = graph_function
   2678       return graph_function, args, kwargs

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2564             arg_names=arg_names,
   2565             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2566             capture_by_value=self._capture_by_value),
   2567         self._function_attributes,
   2568         # Tell the ConcreteFunction to clean up its graph once it goes out of

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    956                                           converted_func)
    957 
--> 958       func_outputs = python_func(*func_args, **func_kwargs)
    959 
    960       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
    946           except Exception as e:  # pylint:disable=broad-except
    947             if hasattr(e, ""ag_error_metadata""):
--> 948               raise e.ag_error_metadata.to_exception(e)
    949             else:
    950               raise

ValueError: in converted code:
    relative to /pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for:

    control_flow_ops.py:183 f  *
        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    control_flow_ops.py:256 _pfor_impl
        outputs.append(converter.convert(loop_fn_output))
    pfor.py:1280 convert
        output = self._convert_helper(y)
    pfor.py:1460 _convert_helper
        (y_op.type, y_op, converted_inputs))

    ValueError: No converter defined for SpaceToBatchND
    name: ""loop_body/SpaceToBatchND""
    op: ""SpaceToBatchND""
    input: ""loop_body/Reshape_2""
    input: ""loop_body/SpaceToBatchND/block_shape""
    input: ""loop_body/SpaceToBatchND/paddings""
    attr {
      key: ""T""
      value {
        type: DT_FLOAT
      }
    }
    attr {
      key: ""Tblock_shape""
      value {
        type: DT_INT32
      }
    }
    attr {
      key: ""Tpaddings""
      value {
        type: DT_INT32
      }
    }
    
    inputs: [WrappedTensor(t=<tf.Tensor 'loop_body/Reshape_2/pfor/Reshape:0' shape=(3072, 1, 6, 16, 32) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/SpaceToBatchND/block_shape:0' shape=(2,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/SpaceToBatchND/paddings:0' shape=(2, 2) dtype=int32>, is_stacked=False, is_sparse_stacked=False)]. 
    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower

Encountered an exception while vectorizing the jacobian computation. Vectorization can be disabled by setting experimental_use_pfor to False.
```
"
33918,Could not find any cupti.h in any subdirectory when running Configure in Tensorflow,"I'm using Ubuntu and have CUDA 7.5 installed according to `nvcc --version`

I git cloned Tensorflow and attempted `./configure` and got the below:

    Please specify the location of python. [Default is /home/me/anaconda3/bin/python]: 
    
    
    Found possible Python library paths:
      /home/me/anaconda3/lib/python3.6/site-packages
    Please input the desired Python library path to use.  Default is [/home/me/anaconda3/lib/python3.6/site-packages]
    
    Do you wish to build TensorFlow with XLA JIT support? [Y/n]: 
    XLA JIT support will be enabled for TensorFlow.
    
    Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n
    No OpenCL SYCL support will be enabled for TensorFlow.
    
    Do you wish to build TensorFlow with ROCm support? [y/N]: 
    No ROCm support will be enabled for TensorFlow.
    
    Do you wish to build TensorFlow with CUDA support? [y/N]: y
    CUDA support will be enabled for TensorFlow.
    
    Do you wish to build TensorFlow with TensorRT support? [y/N]: 
    No TensorRT support will be enabled for TensorFlow.

It then shows the error:

    Could not find any cupti.h in any subdirectory:

It then asks for the CUDA Version:

    Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: 7.5
    
    
    Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 
    
    
    Please specify the locally installed NCCL version you want to use. [Leave empty to use http://github.com/nvidia/nccl]: 
    
    
    Please specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]:

 
But it shows the same error: `Could not find any cupti.h in any subdirectory:`"
33917,Math ops don't work on SparseTensors,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS (Bionic Beaver)
- TensorFlow installed from (source or binary): pip install tensorflow==2.0.0
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: Python 3.6.8

**Describe the current behavior**
Some basic math ops like `tf.math.exp` and `tf.math.pow` don't work on SparseTensors.

**Describe the expected behavior**
Math ops perform similarly to when they have dense Tensor inputs but returning a Sparse format, e.g. `tf.math.exp(tf.sparse.to_dense(d))`

**Code to reproduce the issue**
```
import tensorflow as tf

d = tf.SparseTensor(
indices=[(x,y) for x, y in zip(range(10), range(10))],
values=tf.random.poisson((10,), lam=3),
dense_shape=[10,10]
)

tf.math.exp(d)

# Can also be reproduced like:
tf.math.pow(2.71, d)
```

**Other info / logs**
>>> tf.math.exp(d)
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py"", line 3951, in exp
    name, _ctx._post_execution_callbacks, x)
tensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py"", line 3956, in exp
    x, name=name, ctx=_ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py"", line 4001, in exp_eager_fallback
    _attr_T, (x,) = _execute.args_to_matching_eager([x], _ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py"", line 257, in args_to_matching_eager
    t, dtype, preferred_dtype=default_dtype, ctx=ctx))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1296, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py"", line 286, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py"", line 227, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py"", line 235, in _constant_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py"", line 96, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
ValueError: Attempt to convert a value (<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fd24746d5c0>) with an unsupported type (<class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>) to a Tensor.
"
33916,"InternalError: Blas SGEMM launch failed : m=10, n=1, k=4 [Op:Conv2D] thrown when training Keras model with train_on_batch()","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 

    - `Yes`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
    - `Linux Ubuntu 18.04`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 

    - Docker image, `tensorflow/tensorflow:2.0.0-gpu-py3`
- TensorFlow version (use command below):

     - `v2.0.0-rc2-26-g64c3d38 2.0.0`

- Python version:

    - `3.6.8`

- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
```

- GPU model and memory:

    - `GeForce GTX 960M, 2004MiB`

**Describe the current behavior**

When training a keras model with `train_on_batch()`, an InternalError is thrown (see stacktrace). Training the same model with `fit()` works.

**Describe the expected behavior**

No InternalError thrown and the attached code successfully executing.

**Code to reproduce the issue**

```
mkdir tf_issue
cp run.py tf_issue
docker run --gpus all -it  -v $(pwd)/tf_issue:/tf_issue tensorflow/tensorflow:2.0.0-gpu-py
python3 /tf_issue/run.py
```

(On my machine the above takes a few minutes when ""setting up"" Tensorflow, which is a bit ridiculous. But that's another issue)

```
## run.py ##
import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import Input, Conv2D
from tensorflow.keras.optimizers import Adam

#tf.keras.backend.set_image_data_format(""channels_first"")

model = tf.keras.Sequential()
model.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2, input_shape=(224, 224, 3)))
model.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2))
model.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2))
model.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2))
model.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2))
model.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2))
model.add(tf.keras.layers.Conv2D(filters=1, kernel_size=2, strides=1, activation='sigmoid'))

model.compile( optimizer=Adam(), loss='binary_crossentropy')

model.summary()

gpu = tf.test.is_gpu_available()
print(""GPU is available:"", gpu)
assert(gpu)

batch_size = 10
x = np.random.random((batch_size, 224, 224, 3))
y = np.random.random((batch_size, 1, 1, 1))

print(""x"", x.shape)
print(""y"", y.shape)

y_pred = model.predict(x)
print(""Predict successful: "", y_pred.shape)

print(""Begin training with fit"")
model.fit(x, y, epochs=10)
print(""Fit successful"")

print(""Begin training with train_on_batch"")
for i in range(10):
    model.train_on_batch(x, y)
print(""On batch successful"")
```

**Other info / logs**

Output and stack trace:

```
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 111, 111, 1)       28        
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 55, 55, 1)         10        
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 27, 27, 1)         10        
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 13, 13, 1)         10        
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 6, 6, 1)           10        
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 2, 2, 1)           10        
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 1, 1, 1)           5         
=================================================================
Total params: 83
Trainable params: 83
Non-trainable params: 0
_________________________________________________________________
GPU is available: True
x (10, 224, 224, 3)
y (10, 1, 1, 1)
Predict successful:  (10, 1, 1, 1)
Begin training with fit
Train on 10 samples
Epoch 1/10

10/10 [==============================] - 1s 82ms/sample - loss: 0.6654
Epoch 2/10

10/10 [==============================] - 0s 870us/sample - loss: 0.6633
Epoch 3/10

10/10 [==============================] - 0s 882us/sample - loss: 0.6613
Epoch 4/10

10/10 [==============================] - 0s 1ms/sample - loss: 0.6594
Epoch 5/10

10/10 [==============================] - 0s 979us/sample - loss: 0.6574
Epoch 6/10

10/10 [==============================] - 0s 902us/sample - loss: 0.6555
Epoch 7/10

10/10 [==============================] - 0s 872us/sample - loss: 0.6536
Epoch 8/10

10/10 [==============================] - 0s 960us/sample - loss: 0.6517
Epoch 9/10

10/10 [==============================] - 0s 905us/sample - loss: 0.6498
Epoch 10/10

10/10 [==============================] - 0s 1ms/sample - loss: 0.6479
Fit successful
Begin training with train_on_batch
 not compiled to use: AVX2 FMA
2019-11-01 13:45:13.958471: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592000000 Hz
2019-11-01 13:45:13.959294: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4595560 executing computations on platform Host. Devices:
2019-11-01 13:45:13.959336: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-01 13:45:14.000846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 13:45:14.001574: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x45973c0 executing computations on platform CUDA. Devices:
2019-11-01 13:45:14.001596: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 960M, Compute Capability 5.0
2019-11-01 13:45:14.001719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 13:45:14.002377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 960M major: 5 minor: 0 memoryClockRate(GHz): 1.0975
pciBusID: 0000:01:00.0
2019-11-01 13:45:14.002406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-01 13:45:14.002417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-01 13:45:14.002427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-01 13:45:14.002444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-01 13:45:14.002454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-01 13:45:14.002463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-01 13:45:14.002473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-01 13:45:14.002522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 13:45:14.003154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 13:45:14.003750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-01 13:45:14.003777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-01 13:45:14.004647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-01 13:45:14.004660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-11-01 13:45:14.004667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-11-01 13:45:14.004779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 13:45:14.005421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 13:45:14.006043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1742 MB memory) -> physical GPU (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2019-11-01 13:45:15.207106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 13:45:15.207755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 960M major: 5 minor: 0 memoryClockRate(GHz): 1.0975
pciBusID: 0000:01:00.0
2019-11-01 13:45:15.207787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-11-01 13:45:15.207801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-01 13:45:15.207813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-11-01 13:45:15.207824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-11-01 13:45:15.207836: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-11-01 13:45:15.207847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-11-01 13:45:15.207859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-01 13:45:15.207910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 13:45:15.208535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 13:45:15.209130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-11-01 13:45:15.209154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-01 13:45:15.209161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-11-01 13:45:15.209168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-11-01 13:45:15.209276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 13:45:15.209931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 13:45:15.210556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 1742 MB memory) -> physical GPU (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2019-11-01 13:45:15.339203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-01 13:45:17.264840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-01 13:45:17.421437: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-11-01 13:45:17.421474: W tensorflow/stream_executor/stream.cc:1919] attempting to perform BLAS operation using StreamExecutor without BLAS support
Traceback (most recent call last):
  File ""test_sample_weights.py"", line 41, in <module>
    model.train_on_batch(x, y)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 973, in train_on_batch
    class_weight=class_weight, reset_metrics=reset_metrics)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 264, in train_on_batch
    output_loss_metrics=model._output_loss_metrics)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 311, in train_on_batch
    output_loss_metrics=output_loss_metrics))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 252, in _process_single_batch
    training=training))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 127, in _model_loss
    outs = model(inputs, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 891, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/sequential.py"", line 256, in call
    return super(Sequential, self).call(inputs, training=training, mask=mask)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py"", line 708, in call
    convert_kwargs_to_constants=base_layer_utils.call_context().saving)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py"", line 860, in _run_internal_graph
    output_tensors = layer(computed_tensors, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 891, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call
    outputs = self._convolution_op(inputs, self.kernel)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__
    return self.conv_op(inp, filter)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__
    return self.call(inp, filter)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__
    name=self.name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d
    name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1031, in conv2d
    data_format=data_format, dilations=dilations, name=name, ctx=_ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1130, in conv2d_eager_fallback
    ctx=_ctx, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=10, n=1, k=4 [Op:Conv2D]
```

Docker version:

```
Client: Docker Engine - Community
 Version:           19.03.4
 API version:       1.40
 Go version:        go1.12.10
 Git commit:        9013bf583a
 Built:             Fri Oct 18 15:54:09 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.4
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.10
  Git commit:       9013bf583a
  Built:            Fri Oct 18 15:52:40 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc8+dev
  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```
"
33915,Have a default value for monitor on Early Stopping callback?,https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping
33914,"Writing tflite file from Keras model throws ""Cycle found! We already encountered that input array""","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): v1.12.1-7396-g12481e7e74 1.15.0-dev20190730
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 9.1, 10.0, 10.1
- GPU model and memory: GTX 1050ti 4GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I'm trying to write convert a (pure) Keras model to .pb file in order to write it to tflite. It's a few conv layers and some end logic. In order to do so, I freeze it with `convert_variables_to_constants` and reload it using the `TFLiteConverter.from_frozen_graph()`. However, I get the following error: 
```
F tensorflow/lite/toco/tooling_util.cc:1182] Cycle found! We already encountered that input array, decoded_predictions/loop_over_batch/while/NextIteration, earlier in the above trace! We expect graphs to be acyclic, even RNNs. Let us know if some graph actually needs to have cycles, but first, please check if it really is an *inference* graph. *Training* graphs are out-of-scope for toco.
Fatal Python error: Aborted
```

**Describe the expected behavior**

I would expect `convert_variables_to_constants` to write a frozen graph readable by the `from_frozen_graph` method and simply convert my model. I've tried many things, like writing it with different methods, setting learning phase, changing the final layer (which is causing the problem), etc.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
def freeze_session(session, model, keep_var_names=None, clear_devices=None):
    graph = session.graph
    with graph.as_default():
        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))
        output_names = [out.op.name for out in model.outputs]
        output_names += [v.op.name for v in tf.global_variables()]
        input_graph_def = graph.as_graph_def()
        if clear_devices:
            for node in input_graph_def.node:
                node.device = """"
        frozen_graph = convert_variables_to_constants(session, input_graph_def, output_names)#, freeze_var_names)
        return frozen_graph

def save_model(model, iteration):
    # K.clear_session()
    K.set_learning_phase(0)
    new_model = get_out_model(model)
    
    frozen_graph = freeze_session(K.get_session(), new_model)
    with tf.gfile.GFile('./model/model.pb', ""wb"") as f:
        f.write(frozen_graph.SerializeToString())
    # path = tf.train.write_graph(frozen_graph, './model', 'model' + str(iteration) + '.pb')

    
    converter = tf.lite.TFLiteConverter.from_frozen_graph('./model/model.pb',
                                                          input_arrays=new_model.input_names,
                                                          # output_arrays=['predictions/concat'])
                                                          output_arrays=['decoded_predictions/loop_over_batch/TensorArrayStack/TensorArrayGatherV3'])
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_ops = set([tf.lite.OpsSet.SELECT_TF_OPS])
    converter.allow_custom_ops = True
    converter.drop_control_dependency = False
    tflite_model = converter.convert()
    with open(""./model.tflite"", 'wb') as tfile:
        tfile.write(tflite_model)
        
    K.set_learning_phase(1)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
Current thread 0x00007f8956f0f740 (most recent call first):
  File ""/home/oliver/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52 in execute
  File ""/home/oliver/.local/lib/python3.6/site-packages/absl/app.py"", line 250 in _run_main
  File ""/home/oliver/.local/lib/python3.6/site-packages/absl/app.py"", line 299 in run
  File ""/home/oliver/.local/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40 in run
  File ""/home/oliver/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89 in main
  File ""/home/oliver/.local/bin/toco_from_protos"", line 11 in <module>
Aborted (core dumped)



None
  File ""/home/oliver/Projects/DataGen/Retrainer/Retrainer.py"", line 189, in <module>
    loss = train_saved_model(model, socket)
  File ""/home/oliver/Projects/DataGen/Retrainer/Retrainer.py"", line 168, in train_saved_model
    save_model(model, i)
  File ""/home/oliver/Projects/DataGen/Retrainer/Retrainer.py"", line 121, in save_model
    tflite_model = converter.convert()
  File ""/home/oliver/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 983, in convert
    **converter_kwargs)
  File ""/home/oliver/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 449, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/home/oliver/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 200, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
```"
33913,Setting inputs tf.keras.Model,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (see link below)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -  
- TensorFlow installed from (source or binary): binary  
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source): - 
- GCC/Compiler version (if compiling from source): - 
- CUDA/cuDNN version: -
- GPU model and memory: -

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Input shapes are not determined automatically which leads to impossibility to save a custom keras model.

**Describe the expected behavior**
Input shapes should be derived automatically. And it should be possible to save custom keras model. 

**Code to reproduce the issue**
[Gist](https://gist.github.com/RomanSteinberg/c4a47470ab1c06b0c45fa92d07afe2e3) which is the part of  [Colab example](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras/custom_layers_and_models.ipynb).

**Other info / logs**
There is an [Colab example](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras/custom_layers_and_models.ipynb) which demonstrates the problem. The part ""Putting it all together"" demonstrates the training of VAE. If you try to save model `vae.save('vae')` you obtain an error
```
ValueError: Model <__main__.VariationalAutoEncoder object at 0x7fde216170f0> cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling .fit() or .predict(). To manually set the shapes, call model._set_inputs(inputs).
```
But it is impossible to add such line to `__init__` or `call` method. The only workaround I found is to add
```
if step == 0 and epoch == 0:
     vae._set_inputs(x_batch_train)
```
in the training loop. It is not straight forward. Anyway, input shapes should be determined while training without this code."
33911,tf.keras (tf 2) much slower than tf 1.14,"I try to train a simple dense feedforward network consisting of:

- input layer of size 8
- 3 hidden layers, each with 40 neurons and ReLU activations
- output layer of size 9

for a regression.

The performance of keras using tensorflow 1.14 is about 3 times faster than using a freshly installed tensorflow 2.0.0... Is this to be expected, or might this be a bug?
I am training on a CPU.
"
33910,build tensorflow from source failed on Linux,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): source
- TensorFlow version: r1.14
- Python version: Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0] :: Anaconda, Inc. on linux
- Installed using virtualenv? pip? conda?: NA
- Bazel version (if compiling from source): 0.25.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; nvcc release 9.1, V9.1.85
- CUDA/cuDNN version: 9.1/7.3.0
- GPU model and memory: Nvidia Titan XP with 12 GB memory

**Describe the problem**
build tensorflow from source on branch r1.14 on ubuntu 16.04 with GPU and XLA support failed. Errors related to undefiend symbols in cublas occured. I can ensure the cublas library has been installed in the $CUDA_HOME/lib64 (/usr/local/cuda/lib64) which has been added to $LD_LIBRARY_PATH. I also print the symbols in the installed cublas.so and the two undefined symbols can be found:

> dongxiao@178-ubuntu ~/working/tensorflow                                                                                                                                  
> (base) > $ nm -D /usr/local/cuda/lib64/libcublas.so | grep ""cublasGemmStridedBatchedEx""                                                                                   
> 0000000000398e70 T cublasGemmStridedBatchedEx
> dongxiao@178-ubuntu ~/working/tensorflow                                                                                                                                  
> (base) > $ nm -D /usr/local/cuda/lib64/libcublas.so | grep ""cublasGemmBatchedEx""                                                                                          
> 0000000000399e20 T cublasGemmBatchedEx

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
git clone https://github.com/tensorflow/tensorflow.git
git checkout r1.14
./configure  #only enable GPU and XLA support
bazel build --verbose_failures --config=noaws --config=nogcp --config=nohdfs --config=noignite --config=nokafka --config=nonccl --action_env=LD_LIBRARY_PATH=/usr/local/cuda/lib64/ --config=cuda --config=opt //tensorflow/tools/pip_package:build_pip_package
```

**Any other info / logs**

> ERROR: /home/dongxiao/working/tensorflow/tensorflow/contrib/ffmpeg/BUILD:100:1: Linking of rule '//tensorflow/contrib/ffmpeg:gen_decode_video_op_py_py_wrappers_cc' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command
>   (cd /home/dongxiao/.cache/bazel/_bazel_dongxiao/09108a4ee4f3be79160332645b3550ec/execroot/org_tensorflow && \
>   exec env - \
>     LD_LIBRARY_PATH=/usr/local/cuda/lib64: \
>     PATH=/home/dongxiao/anaconda3/bin:/home/dongxiao/anaconda3/condabin:/usr/local/cuda/bin:/home/dongxiao/tools/login/node-v8.2.1-linux-x64/bin:/home/dongxiao/tools/llvm-4.0.0.src/build/bin:/home/dongxiao/tools/cfe-4.0.1.src/build/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \
>     PWD=/proc/self/cwd \
>   external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/contrib/ffmpeg/gen_decode_video_op_py_py_wrappers_cc '-Wl,-rpath,$ORIGIN/../../../_solib_local/_U_S_Stensorflow_Scontrib_Sffmpeg_Cgen_Udecode_Uvideo_Uop_Upy_Upy_Uwrappers_Ucc___Utensorflow' -Lbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sffmpeg_Cgen_Udecode_Uvideo_Uop_Upy_Upy_Uwrappers_Ucc___Utensorflow -Wl,-ldl '-Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..,-rpath,$ORIGIN/../..' -pthread -pthread -pthread -pthread -Wl,-S -Wl,-no-as-needed -pie -Wl,-z,relro,-z,now '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -no-canonical-prefixes -fno-canonical-system-headers -B/usr/bin -Wl,--gc-sections -Wl,@bazel-out/host/bin/tensorflow/contrib/ffmpeg/gen_decode_video_op_py_py_wrappers_cc-2.params)
> Execution platform: @bazel_tools//platforms:host_platform
> bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sffmpeg_Cgen_Udecode_Uvideo_Uop_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.1: undefined reference to `cublasGemmBatchedEx'
> bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sffmpeg_Cgen_Udecode_Uvideo_Uop_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.1: undefined reference to `cublasGemmStridedBatchedEx'
> collect2: error: ld returned 1 exit status
> Target //tensorflow/tools/pip_package:build_pip_package failed to build
> INFO: Elapsed time: 348.727s, Critical Path: 79.30s
> INFO: 1621 processes: 1621 local.
> FAILED: Build did NOT complete successfully

It seems the cublas linking options are not added in the command properly, which should be '-lcublas -L/usr/local/cuda/lib64'. But I'm not sure about that. I have not found propoer place to add these options to try."
33908,tf.keras.layers.SimpleRNN train with batch data  like original keras API,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):conda
- TensorFlow version (use command below):1.14.0
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1
- GPU model and memory:16G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I can not train my image with shape (None,256,256)

**Describe the expected behavior**
I need a interface from the new api like this:
# RNN cell
model.add(SimpleRNN(
    # for batch_input_shape, if using tensorflow as the backend, we have to put None for the batch_size.
    # Otherwise, model.evaluate() will get error.
    batch_input_shape=(None, TIME_STEPS, INPUT_SIZE),  # Or: input_dim=INPUT_SIZE, input_length=TIME_STEPS,
    output_dim=CELL_SIZE,
    unroll=True,
))

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
class Simple_IRNN(tf.keras.layers.Layer):
    def __init__(self,in_channels,scope='simpleirnn',alpha=1.0):
        super(Simple_IRNN,self).__init__()
        self.num_outputs=in_channels
        self.batch_size=8
        self.num_outputs=256
        self.alpha=alpha
    

        self.left=tf.keras.layers.SimpleRNN(self.num_outputs,activation='relu',
        recurrent_initializer=tf.keras.initializers.Identity(gain=self.alpha),return_sequences=True) # (batch_size, timesteps,input_features)
        self.right=tf.keras.layers.SimpleRNN(self.num_outputs,activation='relu',
        recurrent_initializer=tf.keras.initializers.Identity(gain=self.alpha),return_sequences=True)
        self.up=tf.keras.layers.SimpleRNN(self.num_outputs,activation='relu',
        recurrent_initializer=tf.keras.initializers.Identity(gain=self.alpha),return_sequences=True)
        self.down=tf.keras.layers.SimpleRNN(self.num_outputs,activation='relu',
        recurrent_initializer=tf.keras.initializers.Identity(gain=self.alpha),return_sequences=True)



    def call(self,inputs):
   

        inputs=tf.nn.relu(inputs)
        inputs=tf.reduce_sum(inputs,axis=-1)
  
        mask=tf.cast(tf.ones(shape=(256,256),dtype=tf.int32),dtype=tf.bool)

        temp=tf.image.flip_up_down(inputs)
        temp=tf.image.rot90(temp,k=1)

        print(""inputs shape:"",inputs.shape)
        self.up.get_initial_state(inputs=temp)   
        self.right.get_initial_state(inputs=inputs)

        output_up=self.up(temp)
        output_right=self.right(inputs)

        temp=tf.image.rot90(inputs,k=1)

        self.down.get_initial_state(inputs=temp)
        output_down=self.down(temp)
       

        temp=tf.image.flip_left_right(inputs)
        self.left.get_initial_state(inputs=temp)
  
        output_left=self.left(temp)


        output_right=tf.reshape(output_right,(self.batch_size,256,256,1))
        output_up=tf.reshape(output_up,(self.batch_size,256,256,1))
        output_down=tf.reshape(output_down,(self.batch_size,256,256,1))
        output_left=tf.reshape(output_left,(self.batch_size,256,256,1))

        
        return output_up,output_right,output_down,output_left


here is my selfdefine layer ,it can run,but I found change to my selflayer my eval loss and acc don't change anymore 


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33907,Init node Adam/iter/Assign doesn't exist in graph," model = keras.Sequential([

        layers.Flatten(input_shape=(image_h, image_h, 1)),
    ])
model.compile(optimizer='adam',
                      loss='sparse_categorical_crossentropy',
                      metrics=['accuracy'])
model.save(""model_right_error.h5"")

--------------

converter = tf.lite.TFLiteConverter.from_keras_model_file(""model_right_error.h5"")
tflite_model = converter.convert()
open(""model2.tflite"", ""wb"").write(tflite_model)

tensorflow/core/grappler/grappler_item_builder.cc:637] Init node Adam/iter/Assign doesn't exist in graph


how to fix?

"
33906,Update sample session for build from source instruction docs,"## URL(s) with the issue:
https://www.tensorflow.org/install/source_windows
https://www.tensorflow.org/install/source

## Description of issue (what needs changing):
The sample sessions given in the docs are old (Bazel 0.15.1, TensorFlow 1.11, python 2.7)
A new session-copy with the more recent TensorFlow 2.x with Bazel 0.26.1 would be more helpful.
Also, python 2.7 is reaching end-of-life in Jan 2020.

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? Yes. 
"
33905,'Copy link to this section' feature not working for certain sections.,"## URL(s) with the issue:
- https://www.tensorflow.org/install/source_windows
- https://www.tensorflow.org/install/source

## Browser used:
Tried on Microsoft Edge and Mozilla Firefox up-to-date versions.

## Description of issue (what needs changing):
The 'Copy link to this section' feature is not working for the `View sample configuration session` sections for the Linux and Windows build-from-source instruction docs.
### Clear description:
The issue-causing sections are located under these sections: 
- https://www.tensorflow.org/install/source#sample_session (Linux)
- https://www.tensorflow.org/install/source_windows#configure_the_build (Windows)

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue?:  Yes, I can fix the markdown to correct the issue.
"
33903,"tensorflow 2.0, tf.keras can't place model with tf.device('/device:GPU:0')?","
I have 2 different models and I want to train multitasks by loading those models to different GPUs respectively. I think this is so-called model parallelism. For example, one model is about 8GB, another is 12GB, I use the following code to load model to the respective device, however, it just doesn't work, the TensorFlow trying to load the whole model into same GPU(PC with 2 RTX Titan 24GB). Is this the problem with namescope?

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
TensorFlow version (use command below): 2.0.0-stable version
Python version: 3.7.4
CUDA/cuDNN version: 10.0
GPU model and memory: RTX Titan x2 

```
with tf.device('/device:GPU:0'):
     model_1 = K.models.load_model(model_path1)
with tf.device('/device:GPU:1'):
     model_2 = K.models.load_model(model_path2)
```

Can I have some support with this?

I have been asked this problem in [stackoverflow](https://stackoverflow.com/questions/58448034/tensorflow-2-0-how-to-train-mutliple-model-with-mutliple-gpu) but no body answer my question.
"
33901,Is there any method to calculate batch linear regression in GPU efficiently???,"I have written a cpu version of such calculate problem, but cpu version is still slow.

```
from numba import jit 
import numpy as np 

@jit(nopython=True)
def resid_lstsq(x,y):
	ret = np.linalg.lstsq(x,y)
	coef = ret[0]
	yHat = np.dot(x,coef)
	residuls = y - yHat

	return residuls


@jit(nopython=True)
def resid_matrixReverse(x,y):
	
	coef = np.dot(np.dot(np.linalg.inv(np.dot(x.T,x)),x.T),y)
	yHat = np.dot(x,coef)
	residuls = y - yHat

	return residuls


@jit(nopython=True)
def resid_matrixSolve(x,y):
	
	coef = np.linalg.solve(np.dot(x.T, x), np.dot(x.T, y))
	yHat = np.dot(x,coef)
	residuls = y - yHat

	return residuls


def residCalculatorVector(x,y,method='matrixReverse'):
	'''
	get the residuls of regression for one period
	x: the independent variables
	y: the dependent variables
	'''
	if method == 'lstsq':
		return resid_lstsq(x,y)

	elif method == 'matrixReverse':
		return resid_matrixReverse(x,y)

	elif method == 'matrixSolve':
		return resid_matrixSolve(x,y)

	elif method == 'sklearn':
		pass 

def residCalculatorMatrix(newFactorMatrix,targetMatrix,oldFactorTensor,method='matrixReverse'):
	'''
	calculate the residuals between one new factor with several old factors
	newFactorMatrix: (i,j)(i:trade date, j: stock ID)
	oldFactorTensor (i,j,k)(i:stock ID, j: trade date, k:factors )
	'''
	shape0 = oldFactorTensor.shape[0]
	shape2 = oldFactorTensor.shape[2]	
	
	if shape0 < shape2:
		oldFactorTensor_ = oldFactorTensor.T
	else:
		oldFactorTensor_ = oldFactorTensor  #(j,i,k)

	rowNum = newFactorMatrix.shape[0]
	colNum = newFactorMatrix.shape[1]
	factorResidMatrix = np.full(fill_value=np.nan,shape=(rowNum,colNum))
	targetResidMatrix = np.full(fill_value=np.nan,shape=(rowNum,colNum))

	for i in range(rowNum):
		y_i = newFactorMatrix[i,:]
		retY_i = targetMatrix[i,:]
		x_i = oldFactorTensor_[:,i,:]

		idx = np.where(~np.isnan(y_i))[0]	#the index which is NAs
		#idx_ = np.where(np.isnan(y_i))[0]	#the index which is NAs

		y_i_ = y_i[idx]
		x_i_ = x_i[idx]
		retY_i_ = retY_i[idx]

		factorResid_i = residCalculatorVector(x_i_,y_i_,method=method)
		retResid_i = residCalculatorVector(x_i_,retY_i_,method=method)
		factorResidMatrix[i,idx] = factorResid_i
		targetResidMatrix[i,idx] = retResid_i

	return factorResidMatrix,targetResidMatrix


newF_01 = np.random.randn(500,3000)
target_01 = np.random.randn(500,3000)
oldFTen_01 = np.random.randn(3000,500,100)

%timeit residCalculatorMatrix(newF_01,target_01,oldFTen_01,method='matrixReverse')
1.46 s ± 104 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

%timeit residCalculatorMatrix(newF_01,target_01,oldFTen_01,method='matrixSolve')
973 ms ± 98.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

%timeit residCalculatorMatrix(newF_01,target_01,oldFTen_02,method='lstsq')
4.45 s ± 116 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
```

The np.linalg.solve is most efficient method in cpu version.
But If I have a Nvidia 2080Ti
And how can I broadcast the loop of massive regressions into GPU.
Or is there any method to calculate massive regressions in GPU ???
Thank you so much."
33899,Porting gradients to C++ from python,"**System information**
- TensorFlow version (you are using): v2
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
I'm writing a Java gradient optimizer to allow training models on the JVM. I've got pretty much everything working, but some of the gradients can't be calculated as they aren't available in C++, and so I get errors of the form `Exception in thread ""main"" org.tensorflow.TensorFlowException: No gradient defined for op: SparseSoftmaxCrossEntropyWithLogits.`. What's the roadmap for porting gradients from Python to C++? If there isn't a roadmap, would a pull request to add this gradient be accepted (and is there any relevant guidance for working in the TF C++ codebase)? The relevant issues according to GitHub are all from 2016/7 and the internals might be quite different after the v2 release.

**Will this change the current api? How?**
It will expand the set of models that can be trained using languages other than python. It should only add API endpoints and won't change any of the existing ones.

**Who will benefit with this feature?**
Users of the the TF Java API, users of the C API, and other languages which bind the C API. Without the ability to train models using a specific language binding it's very hard to say Tensorflow actually supports that language.
"
33898,tf.GradientTape training much slower than keras.fit,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 1*.04
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.4
- CUDA/cuDNN version: 10.0
- GPU model and memory: GTX 1080

I am currently trying to get a hold of the **TF2.0** api, but as I compared the [**GradientTape**][1] to a regular **keras.Model.fit** I noticed: 

1. It ran slower(probably due to the Eager Execution)

2. It converged much slower (and I am not sure why).

```
+--------+--------------+--------------+------------------+
|  Epoch | GradientTape | GradientTape | keras.Model.fit  |
|        |              |  shuffling   |                  |
+--------+--------------+--------------+------------------+
|    1   |     0.905    |     0.918    |      0.8793      |
+--------+--------------+--------------+------------------+
|    2   |     0.352    |     0.634    |      0.2226      |
+--------+--------------+--------------+------------------+
|    3   |     0.285    |     0.518    |      0.1192      |
+--------+--------------+--------------+------------------+
|    4   |     0.282    |     0.458    |      0.1029      |
+--------+--------------+--------------+------------------+
|    5   |     0.275    |     0.421    |      0.0940      |
+--------+--------------+--------------+------------------+
```

Here is the training loop I used with the **GradientTape**:
```python

optimizer = keras.optimizers.Adam()
glove_model = GloveModel(vocab_size=len(labels))
train_loss = keras.metrics.Mean(name='train_loss')

@tf.function
def train_step(examples, labels):
	with tf.GradientTape() as tape:
		predictions = glove_model(examples)
		loss = glove_model.glove_loss(labels, predictions)

	gradients = tape.gradient(loss, glove_model.trainable_variables)
	optimizer.apply_gradients(zip(gradients, glove_model.trainable_variables))

	train_loss(loss)



total_step = 0
for epoch in range(epochs_number):

	pbar = tqdm(train_ds.enumerate(), total=int(len(index_data) / batch_size) + 1)

	for ix, (examples, labels) in pbar:

		train_step(examples, labels)


	print(f""Epoch {epoch + 1}, Loss {train_loss.result()}"")

	# Reset the metrics for the next epoch
	train_loss.reset_states()
```

And here is the **Keras.Model.fit** training:
```python
glove_model.compile(optimizer, glove_model.glove_loss)
glove_model.fit(train_ds, epochs=epochs_number)
```
Here is the **tf.data.Dataset** source 

```python
train_ds = data.Dataset.from_tensor_slices(
	(np.hstack([index_rows.reshape(-1, 1), index_cols.reshape(-1, 1)]), index_data)
).shuffle(100000).batch(batch_size, drop_remainder=True)
```

And Here is the model.

```python
class GloveModel(keras.Model):

    def __init__(self, vocab_size, dim=100, a=3/4, x_max=100):
        super(GloveModel, self).__init__()

        self.vocab_size = vocab_size
        self.dim = dim
        self.a = a
        self.x_max = x_max

        self.target_embedding = layers.Embedding(
            input_dim=self.vocab_size, output_dim=self.dim, input_length=1, name=""target_embedding""
        )
        self.target_bias = layers.Embedding(
            input_dim=self.vocab_size, output_dim=1, input_length=1, name=""target_bias""
        )

        self.context_embedding = layers.Embedding(
            input_dim=self.vocab_size, output_dim=self.dim, input_length=1, name=""context_embedding""
        )
        self.context_bias = layers.Embedding(
            input_dim=self.vocab_size, output_dim=1, input_length=1, name=""context_bias""
        )

        self.dot_product = layers.Dot(axes=-1, name=""dot"")

        self.prediction = layers.Add(name=""add"")
        self.step = 0

    def call(self, inputs):

        target_ix = inputs[:, 0]
        context_ix = inputs[:, 1]

        target_embedding = self.target_embedding(target_ix)
        target_bias = self.target_bias(target_ix)

        context_embedding = self.context_embedding(context_ix)
        context_bias = self.context_bias(context_ix)

        dot_product = self.dot_product([target_embedding, context_embedding])
        prediction = self.prediction([dot_product, target_bias, context_bias])

        return prediction

    def glove_loss(self, y_true, y_pred):

        weight = tf.math.minimum(
            tf.math.pow(y_true/self.x_max, self.a), 1.0
        )
        loss_value = tf.math.reduce_mean(weight * tf.math.pow(y_pred - tf.math.log(y_true), 2.0))

        return loss_value



```
I tried multiple configurations and optimizers but nothing seems to change the convergence rate.
I tried to **reshuffle** the dataset but with no luck. I also consulted the different issues on GitHub regarding this problem but they all seem to relate to a `tf.function` miss-use.
I also posted this issue on [**StackOverflow**][2] but I had no luck either.

  [1]: https://www.tensorflow.org/tutorials/quickstart/advanced
  [2]: https://stackoverflow.com/questions/58584359/gradientape-convergence-much-slower-than-keras-model-fit"
33897,TF Real Op Not Supported for TFLite when generating MFCCs,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (or github SHA if from source): 2.1.0-dev20191023

Code throwing error is from TF2.0 docs about generating MFCCs from audio. Using the SELECT_TF_OPS flag helps with RFFT and ComplexAbs, but now Real (assuming tf.math.real) is not able to convert. Is there any way to add a custom op for this or is there something I am missing?

```python
def generate_mfcc_features(audio_tensor):
    sample_rate = 16000.0

    # A 1024-point STFT with frames of 64 ms and 75% overlap.
    stfts = tf.signal.stft(audio_tensor, frame_length=1024, frame_step=256,fft_length=1024)
    spectrograms = tf.cast(tf.abs(stfts), tf.float32)

    # Warp the linear scale spectrograms into the mel-scale.
    num_spectrogram_bins = stfts.shape[-1]
    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 80
    linear_to_mel_weight_matrix = tf.cast(tf.signal.linear_to_mel_weight_matrix(num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz, upper_edge_hertz), tf.float32)
    mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)
    mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))

    # Compute a stabilized log to get log-magnitude mel-scale spectrograms.
    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)

    # Compute MFCCs from log_mel_spectrograms and take the first 13.
    return tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :13]
```
when converting like this:
```python
converter = tf.lite.TFLiteConverter.from_concrete_functions([enc_to_save])
# converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
converter.target_spec.supported_ops = set([tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS])
tflite_model_enc = converter.convert()
```

```
---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-275-096221475907> in <module>()
      6 # converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
      7 converter.target_spec.supported_ops = set([tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS])
----> 8 tflite_model_enc = converter.convert()
      9 
     10 converter = tf.lite.TFLiteConverter.from_concrete_functions([dec_to_save])

~/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py in convert(self)
    460         input_tensors=input_tensors,
    461         output_tensors=output_tensors,
--> 462         **converter_kwargs)
    463 
    464     if self._is_calibration_quantize():

~/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    450       input_data.SerializeToString(),
    451       debug_info_str=debug_info_str,
--> 452       enable_mlir_converter=enable_mlir_converter)
    453   return data
    454 

~/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    201       stdout = _try_convert_to_unicode(stdout)
    202       stderr = _try_convert_to_unicode(stderr)
--> 203       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    204   finally:
    205     # Must manually cleanup files.

ConverterError: See console for info.
2019-10-31 16:49:07.859294: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: RFFT
2019-10-31 16:49:07.859376: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ComplexAbs
2019-10-31 16:49:07.859438: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: RFFT
2019-10-31 16:49:07.859470: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Real
2019-10-31 16:49:07.879329: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 403 operators, 705 arrays (0 quantized)
2019-10-31 16:49:07.897088: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 403 operators, 705 arrays (0 quantized)
2019-10-31 16:49:08.185116: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 351 operators, 648 arrays (0 quantized)
2019-10-31 16:49:08.199468: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 350 operators, 647 arrays (0 quantized)
2019-10-31 16:49:08.213695: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 350 operators, 647 arrays (0 quantized)
2019-10-31 16:49:08.224572: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 350 operators, 647 arrays (0 quantized)
2019-10-31 16:49:08.307894: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 384 bytes, theoretical optimal value: 192 bytes.
2019-10-31 16:49:08.309673: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 3677275
2019-10-31 16:49:08.310492: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Real is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-10-31 16:49:08.311448: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Real is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2019-10-31 16:49:08.312363: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, EXPAND_DIMS, FLOOR_DIV, FULLY_CONNECTED, GATHER, LEAKY_RELU, LOG, LOGISTIC, MAXIMUM, MAX_POOL_2D, MUL, PACK, PAD, RANGE, RESHAPE, SHAPE, SPLIT, SPLIT_V, SQUEEZE, STRIDED_SLICE, SUB, TANH, TRANSPOSE, UNPACK. Here is a list of operators for which you will need custom implementations: Real.
Traceback (most recent call last):
  File ""/home/mattc/anaconda3/envs/main/bin/toco_from_protos"", line 10, in <module>
    sys.exit(main())
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, EXPAND_DIMS, FLOOR_DIV, FULLY_CONNECTED, GATHER, LEAKY_RELU, LOG, LOGISTIC, MAXIMUM, MAX_POOL_2D, MUL, PACK, PAD, RANGE, RESHAPE, SHAPE, SPLIT, SPLIT_V, SQUEEZE, STRIDED_SLICE, SUB, TANH, TRANSPOSE, UNPACK. Here is a list of operators for which you will need custom implementations: Real.
```
"
33894,Eager context device issue (Segmentation Fault) after context (re-)setting ServerDef ,"
**System information**
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from (source or binary): binary whl
- TensorFlow version (use command below): `tensorflow-gpu==2.0.0`
- Python version: 3.6.8
- CUDA/cuDNN version: 10.0 / 7.6.4
- GPU model and memory: GeForce GTX 1080 Ti


**Describe the current behavior**
```python
import tensorflow as tf
from tensorflow.core.protobuf.tensorflow_server_pb2 import ServerDef
from tensorflow.python.eager import context
from tensorflow.python.training.server_lib import ClusterSpec


cluster_def = ClusterSpec({'worker': ['127.0.0.1:15293']}).as_cluster_def()
# 15293 is just some random available port

server_def = ServerDef(
    cluster=cluster_def,
    job_name='worker',
    task_index=0,
    protocol='grpc'
)

v = tf.Variable(3)

print(v.device)
# > /job:localhost/replica:0/task:0/device:CPU:0

context.set_server_def(server_def)

####################################
print(v.device)
# > Segmentation fault (core dumped)
####################################
```

**Describe the expected behavior**

* Should API users expect the Variable re-placed and re-initialized on the new Server?

**Code to reproduce the issue**
See above
"
33893,Support INT8 quantisation for RESIZE_NEAREST_NEIGHBOR with TFLITE_BUILTINS_INT8 OpsSet,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.0.0

TFLiteConverter post-training quantisation flow does not support RESIZE_NEAREST_NEIGHBOR op

**Provide the text output from tflite_convert**

```
RuntimeError: Quantization not yet supported for op: RESIZE_NEAREST_NEIGHBOR
```

**Any other info / logs**

Source code (as in [guide](https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization_of_weights_and_activations)):

```
model = tf.keras.models.load_model('mobilenetv2.h5')
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = calibrate
tflite_model = converter.convert()
```

Full traceback:

```
RuntimeError                              Traceback (most recent call last)
<ipython-input-29-0a875b86673a> in <module>()
      5 converter.optimizations = [tf.lite.Optimize.DEFAULT]
      6 converter.representative_dataset = calibrate
----> 7 tflite_model = converter.convert()

3 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py in convert(self)
    467       result = self._calibrate_quantize_model(
    468           result, constants.FLOAT, constants.FLOAT,
--> 469           self.experimental_new_quantizer)
    470 
    471     return result

/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py in _calibrate_quantize_model(self, result, inference_input_type, inference_output_type, enable_mlir_quantizer)
    241     return calibrate_quantize.calibrate_and_quantize(
    242         self.representative_dataset.input_gen, inference_input_type,
--> 243         inference_output_type, allow_float, enable_mlir_quantizer)
    244 
    245   def _get_base_converter_args(self):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/optimize/calibrator.py in calibrate_and_quantize(self, dataset_gen, input_type, output_type, allow_float, enable_mlir_quantizer)
     79         np.dtype(input_type.as_numpy_dtype()).num,
     80         np.dtype(output_type.as_numpy_dtype()).num, allow_float,
---> 81         enable_mlir_quantizer)
     82 
     83   def calibrate_and_quantize_single(self, dataset_gen, input_type, output_type,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py in QuantizeModel(self, *args)
    113 
    114     def QuantizeModel(self, *args):
--> 115         return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, *args)
    116 CalibrationWrapper_swigregister = _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_swigregister
    117 CalibrationWrapper_swigregister(CalibrationWrapper)

RuntimeError: Quantization not yet supported for op: RESIZE_NEAREST_NEIGHBOR
```"
33892,tf.image.per_image_standardization return wrong values,"Tensorflow version = 1.15
tf.image.per_image_standardization does not standardize value to [-1,1] 
i test in tensorflow 1.12 it work correctly
 
```python
import tensorflow as tf 
import numpy as np 
print(tf.__version__)
a = tf.constant([[[1,2,3],[4,5,6]]])
b = tf.image.per_image_standardization(a)
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(sess.run(b))
x = np.asarray([[[1,2,3],[4,5,6]]], dtype=np.float64)

def normalize_meanstd(a, axis=None): 
    # axis param denotes axes along which mean & std reductions are to be performed
    mean = np.mean(a, axis=axis, keepdims=True)
    std = np.sqrt(((a - mean)**2).mean(axis=axis, keepdims=True))
    return (a - mean) / std

print(normalize_meanstd(x))
```
```
1.15.0
[[[-6 -3 -1]
  [ 1  3  6]]]
[[[-1.46385011 -0.87831007 -0.29277002]
  [ 0.29277002  0.87831007  1.46385011]]]
```"
33891,'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory,"Ubuntu 16.04, Python 2.7.12

~$ python
Python 2.7.12 (default, Oct  8 2019, 14:14:10) 
[GCC 5.4.0 20160609] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
2019-11-01 02:23:07.614115: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-11-01 02:23:07.640540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 02:23:07.641857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:0a:00.0
2019-11-01 02:23:07.641907: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory
2019-11-01 02:23:07.641942: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory
2019-11-01 02:23:07.641975: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory
2019-11-01 02:23:07.642007: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory
2019-11-01 02:23:07.642040: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory
2019-11-01 02:23:07.642072: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory
2019-11-01 02:23:07.644213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-01 02:23:07.644227: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2019-11-01 02:23:07.644455: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-01 02:23:07.666762: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 4000070000 Hz
2019-11-01 02:23:07.667387: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4fa0e80 executing computations on platform Host. Devices:
2019-11-01 02:23:07.667399: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-01 02:23:07.739881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-01 02:23:07.740582: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5003bc0 executing computations on platform CUDA. Devices:
2019-11-01 02:23:07.740595: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2019-11-01 02:23:07.740645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-01 02:23:07.740651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      
>>> 

"
33890,"[TF 2.0] Using Keras custom layers, cannot learn on Colaboratory on TPU.","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Colaboratory on TPU
- TensorFlow version (use command below):2.0.0
- Python version:Python 3.6.8

**Describe the current behavior**
Tansfomer, which uses Keras custom layers, cannot learn on Colaboratory's TPU.
It shows the error below.
```
UnimplementedError:  Compilation failure: Asked to propagate a dynamic dimension from hlo %scatter.14694 = f32[8333,256]{1,0} scatter(f32[8333,256]{1,0} %broadcast.14689, s32[320]{0} %reshape.2569, f32[320,256]{1,0} %reshape.14686), update_window_dims={1}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%scatter-combiner.14690, metadata={op_type=""UnsortedSegmentSum"" op_name=""Adam/CrossReplicaSum/input""}@{}@0 to hlo %all-reduce.14699 = f32[8333,256]{1,0} all-reduce(f32[8333,256]{1,0} %scatter.14694), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%sum.14695, metadata={op_type=""CrossReplicaSum"" op_name=""Adam/CrossReplicaSum""}, which is not implemented.
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_16451521731088977986/_6}}]]
Additional GRPC error information:
{""created"":""@1572537805.656904528"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":"" Compilation failure: Asked to propagate a dynamic dimension from hlo %scatter.14694 = f32[8333,256]{1,0} scatter(f32[8333,256]{1,0} %broadcast.14689, s32[320]{0} %reshape.2569, f32[320,256]{1,0} %reshape.14686), update_window_dims={1}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%scatter-combiner.14690, metadata={op_type=""UnsortedSegmentSum"" op_name=""Adam/CrossReplicaSum/input""}@{}@0 to hlo %all-reduce.14699 = f32[8333,256]{1,0} all-reduce(f32[8333,256]{1,0} %scatter.14694), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%sum.14695, metadata={op_type=""CrossReplicaSum"" op_name=""Adam/CrossReplicaSum""}, which is not implemented.\n\tTPU compilation failed\n\t [[{{node tpu_compile_succeeded_assert/_16451521731088977986/_6}}]]"",""grpc_status"":12} [Op:__inference_distributed_function_41790]

Function call stack:
distributed_function -> distributed_function
```
The code I used is from the following site and I wanted it to work with TPU.
(https://medium.com/tensorflow/a-transformer-chatbot-tutorial-with-tensorflow-2-0-88bf59e66fe2)

**Describe the expected behavior**
The Model can be learned on Colaboratory's TPU using custom layers.

**Code to reproduce the issue**
Here is a notebook to reproduce the problem. Look at this.
https://colab.research.google.com/github/july1997/transformer_chatbot_tpu/blob/master/transformer_chatbot_tf2_fix_tpu.ipynb

**Other info / logs**
Here all Logs.
```
INFO:tensorflow:Initializing the TPU system: 10.8.123.210:8470
INFO:tensorflow:Initializing the TPU system: 10.8.123.210:8470
INFO:tensorflow:Clearing out eager caches
INFO:tensorflow:Clearing out eager caches
INFO:tensorflow:Finished initializing TPU system.
INFO:tensorflow:Finished initializing TPU system.
INFO:tensorflow:Found TPU system:
INFO:tensorflow:Found TPU system:
INFO:tensorflow:*** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
Train on 689 steps
Epoch 1/20
---------------------------------------------------------------------------
UnimplementedError                        Traceback (most recent call last)
<ipython-input-23-234b607b615c> in <module>()
     34   model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])
     35 
---> 36   model.fit(create_dataset(questions, answers), epochs=EPOCHS)

11 frames
/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--> 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_distributed.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    683         validation_steps=validation_steps,
    684         validation_freq=validation_freq,
--> 685         steps_name='steps_per_epoch')
    686 
    687   def evaluate(self,

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)
    297           else:
    298             actual_inputs = ins()
--> 299           batch_outs = f(actual_inputs)
    300         except errors.OutOfRangeError:
    301           if is_dataset:

/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/distribute/distributed_training_utils.py in execution_function(input_fn)
    876       def execution_function(input_fn):
    877         # `numpy` translates Tensors to values in Eager mode.
--> 878         return [out.numpy() for out in distributed_function(input_fn)]
    879     else:
    880       execution_function = distributed_function

/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--> 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    518         # Lifting succeeded, so variables are initialized and we can run the
    519         # stateless function.
--> 520         return self._stateless_fn(*args, **kwds)
    521     else:
    522       canon_args, canon_kwds = \

/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   1821     """"""Calls a graph function specialized to the inputs.""""""
   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   1824 
   1825   @property

/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)
   1139          if isinstance(t, (ops.Tensor,
   1140                            resource_variable_ops.BaseResourceVariable))),
-> 1141         self.captured_inputs)
   1142 
   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1222     if executing_eagerly:
   1223       flat_outputs = forward_function.call(
-> 1224           ctx, args, cancellation_manager=cancellation_manager)
   1225     else:
   1226       gradient_name = self._delayed_rewrite_functions.register()

/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    509               inputs=args,
    510               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 511               ctx=ctx)
    512         else:
    513           outputs = execute.execute_with_cancellation(

/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

UnimplementedError:  Compilation failure: Asked to propagate a dynamic dimension from hlo %scatter.14694 = f32[8333,256]{1,0} scatter(f32[8333,256]{1,0} %broadcast.14689, s32[320]{0} %reshape.2569, f32[320,256]{1,0} %reshape.14686), update_window_dims={1}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%scatter-combiner.14690, metadata={op_type=""UnsortedSegmentSum"" op_name=""Adam/CrossReplicaSum/input""}@{}@0 to hlo %all-reduce.14699 = f32[8333,256]{1,0} all-reduce(f32[8333,256]{1,0} %scatter.14694), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%sum.14695, metadata={op_type=""CrossReplicaSum"" op_name=""Adam/CrossReplicaSum""}, which is not implemented.
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_16451521731088977986/_6}}]]
Additional GRPC error information:
{""created"":""@1572537805.656904528"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":"" Compilation failure: Asked to propagate a dynamic dimension from hlo %scatter.14694 = f32[8333,256]{1,0} scatter(f32[8333,256]{1,0} %broadcast.14689, s32[320]{0} %reshape.2569, f32[320,256]{1,0} %reshape.14686), update_window_dims={1}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%scatter-combiner.14690, metadata={op_type=""UnsortedSegmentSum"" op_name=""Adam/CrossReplicaSum/input""}@{}@0 to hlo %all-reduce.14699 = f32[8333,256]{1,0} all-reduce(f32[8333,256]{1,0} %scatter.14694), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%sum.14695, metadata={op_type=""CrossReplicaSum"" op_name=""Adam/CrossReplicaSum""}, which is not implemented.\n\tTPU compilation failed\n\t [[{{node tpu_compile_succeeded_assert/_16451521731088977986/_6}}]]"",""grpc_status"":12} [Op:__inference_distributed_function_41790]

Function call stack:
distributed_function -> distributed_function
```
"
33888,Bug in saving model in hdf5 format,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOs Mojave version 10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
When try to save the below model in keras format, we get the following error:
ValueError: Unable to create group (name already exists)

This happens as this model has three layers with name as below:
tf_op_layer_Pad/paddings/0
tf_op_layer_Pad/paddings
tf_op_layer_Pad

Such name causes error in keras as described here - https://github.com/keras-team/keras/issues/12195

**Describe the expected behavior**
Model saving should not fail.

**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow import keras

x = keras.Input(shape=(None,10), dtype=""int32"", name=""input"")
T = tf.shape(x)[0]
to_pad = -T % 2
y = tf.pad(x, [[0, to_pad], [0, 0], [0, 0]])
model = keras.Model(inputs=[x,], outputs=[y,])
model.save(""model.h5"")
```

**Other info / logs**
This fix for this has been checked into keras few days ago it seems - https://github.com/keras-team/keras/pull/13477/commits/7dee298ebec503c6b0e1727dfd49b89a3fb002d7

But it seems TF has its own copy of this hdf5 saving, so it seems this fix will also have to be made there -
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/saving/hdf5_format.py#L624
"
33886,Problems with setting initial state in custom RNN cell,"Currently I am trying to reimplement a publication in TF2.0. For the architecture presented in said publication, I started to tweak and extend the ```SimpleRNNCell```class. Next to some changes in the call method, the main addition is to have an additional matrix that is saved in the cell state. Thus next to default hidden state (```shape=(units)```), I also carry around a matrix (```shape=(units, units)```) in the cell state. I worked out how to do this using the ```TensorShape```class, and the cell works fine, but I would now like to set custom initiale state to the matrix; to be more specific I want to initialise it as an identity matrix.  
I tried different method of supplying a ```initial_state```to the call method, but every time it seems there is a problem with how I supply it and an error of the type
```
ValueError: An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=ListWrapper([InputSpec(shape=(50,), ndim=1), InputSpec(shape=(50, 50), ndim=2)]); however `cell.state_size` is [TensorShape([50]), TensorShape([50, 50])]
```
is thrown.

Here is how I set up the cell state:
```python
self.state_size = NoDependency([TensorShape([self.units]),
                                        TensorShape([self.units, self.units])])

```
and this is how I try to initialise them when calling:
```python
x = rnn_layer(x, initial_state = [tf.zeros(self.units), tf.eye(self.units)]).
```

I believe this is due to the fact of using ```TensorShape```, but I did not find any other method to create a matrix (in contrast to a vector) in the cell state. Thank you in advance."
33884,GRU layer fails on single GPU when using MirroredStrategy,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows and linux
- TensorFlow installed from: binary
- TensorFlow version: 2.0
- Python version: 3.7

**Describe the current behavior**

Using single GPU and tf.keras.layers.GRU layer and model.fit with MirroredStrategy fails on error 

`Invalid argument:  var and delta do not have the same shape`

tf.keras.layers.LSTM works fine on one GPU.

On machine with more GPU, the GRU layers works fine.

I know it does not make much sense to run Mirrored Strategy on only one GPU but it is good for testing your code before uploading it to multi gpu machine.

It works in TF 1.5.

**Code to reproduce the issue**

On Google Colab, use GPU runtime and run this code
```
%tensorflow_version 2.x
# %tensorflow_version 1.x <- here it works

import tensorflow as tf

print(f'TensorFlow ver. {tf.__version__}')
print(f""Num GPUs Available: {len(tf.config.experimental.list_physical_devices('GPU'))}"")

ds = tf.data.Dataset.from_tensor_slices({
  'input': tf.zeros([64, 4]),
  'target': tf.zeros([64, 5])
})
ds = ds.batch(3)

strategy = tf.distribute.MirroredStrategy()

with strategy.scope():

  p_input = tf.keras.Input(shape=[4], name='input')
  p_target = tf.keras.Input(shape=[5], name='target')

  # gru = tf.keras.layers.LSTM(8) # <- this works
  gru = tf.keras.layers.GRU(8)

  x = p_input
  x = tf.expand_dims(x, axis=-1)
  x = gru(x)
  x = tf.keras.layers.Dense(5, activation='tanh')(x)

  model = tf.keras.Model([p_input, p_target], x)
  model.add_loss(tf.keras.losses.MSE(p_target, x))

  model.compile(optimizer=tf.keras.optimizers.SGD())
  model.fit(ds)
```

Other info / logs
```
TensorFlow ver. 2.0.0
Num GPUs Available: 1
WARNING:tensorflow:Output dense_9 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_9.
      1/Unknown - 3s 3s/step
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-10-e5114f02da9a> in <module>()
     32 
     33   model.compile(optimizer=tf.keras.optimizers.SGD())
---> 34   model.fit(ds)

11 frames
/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  var and delta do not have the same shape[8,24] [2,24]
	 [[node SGD/SGD/update_1/update_0/ResourceApplyGradientDescent (defined at /tensorflow-2.0.0/python3.6/tensorflow_core/python/framework/ops.py:1751) ]]
  (1) Invalid argument:  var and delta do not have the same shape[8,24] [2,24]
	 [[node SGD/SGD/update_1/update_0/ResourceApplyGradientDescent (defined at /tensorflow-2.0.0/python3.6/tensorflow_core/python/framework/ops.py:1751) ]]
	 [[ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_3/_18]]
0 successful operations.
0 derived errors ignored. [Op:__inference_distributed_function_24603]

Function call stack:
distributed_function -> distributed_function
```



"
33883,I am trying to edit tensorflow lite docs but not able to find source code,"link which I want to edit: [https://www.tensorflow.org/community/contribute/docs](https://www.tensorflow.org/community/contribute/docs)
The description of Digit classifier is incorrect"
33882,object detection tutorial not working,"Hi guys,
what is the error do you help
python 3.8.0
cuda 10.0
protoc 3.4.0 x32 

ERROR: Command errored out with exit status 1:
   command: 'C:\Users\mertk\Anaconda3\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\mertk\\AppData\\Local\\Temp\\pip-install-764_pxzy\\pycocotools\\setup.py'""'""'; __file__='""'""'C:\\Users\\mertk\\AppData\\Local\\Temp\\pip-install-764_pxzy\\pycocotools\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\mertk\AppData\Local\Temp\pip-wheel-_obwf5qn' --python-tag cp37
       cwd: C:\Users\mertk\AppData\Local\Temp\pip-install-764_pxzy\pycocotools\
  Complete output (13 lines):
  running bdist_wheel
  running build
  running build_py
  creating build
  creating build\lib.win-amd64-3.7
  creating build\lib.win-amd64-3.7\pycocotools
  copying pycocotools\coco.py -> build\lib.win-amd64-3.7\pycocotools
  copying pycocotools\cocoeval.py -> build\lib.win-amd64-3.7\pycocotools
  copying pycocotools\mask.py -> build\lib.win-amd64-3.7\pycocotools
  copying pycocotools\__init__.py -> build\lib.win-amd64-3.7\pycocotools
  running build_ext
  building 'pycocotools._mask' extension
  error: Microsoft Visual C++ 14.0 is required. Get it with ""Microsoft Visual C++ Build Tools"": https://visualstudio.microsoft.com/downloads/
  ----------------------------------------
  ERROR: Failed building wheel for pycocotools
    ERROR: Command errored out with exit status 1:
     command: 'C:\Users\mertk\Anaconda3\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\mertk\\AppData\\Local\\Temp\\pip-install-764_pxzy\\pycocotools\\setup.py'""'""'; __file__='""'""'C:\\Users\\mertk\\AppData\\Local\\Temp\\pip-install-764_pxzy\\pycocotools\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\mertk\AppData\Local\Temp\pip-record-m7t3yhyc\install-record.txt' --single-version-externally-managed --compile
         cwd: C:\Users\mertk\AppData\Local\Temp\pip-install-764_pxzy\pycocotools\
    Complete output (13 lines):
    running install
    running build
    running build_py
    creating build
    creating build\lib.win-amd64-3.7
    creating build\lib.win-amd64-3.7\pycocotools
    copying pycocotools\coco.py -> build\lib.win-amd64-3.7\pycocotools
    copying pycocotools\cocoeval.py -> build\lib.win-amd64-3.7\pycocotools
    copying pycocotools\mask.py -> build\lib.win-amd64-3.7\pycocotools
    copying pycocotools\__init__.py -> build\lib.win-amd64-3.7\pycocotools
    running build_ext
    building 'pycocotools._mask' extension
    error: Microsoft Visual C++ 14.0 is required. Get it with ""Microsoft Visual C++ Build Tools"": https://visualstudio.microsoft.com/downloads/
    ----------------------------------------
ERROR: Command errored out with exit status 1: 'C:\Users\mertk\Anaconda3\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\mertk\\AppData\\Local\\Temp\\pip-install-764_pxzy\\pycocotools\\setup.py'""'""'; __file__='""'""'C:\\Users\\mertk\\AppData\\Local\\Temp\\pip-install-764_pxzy\\pycocotools\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\mertk\AppData\Local\Temp\pip-record-m7t3yhyc\install-record.txt' --single-version-externally-managed --compile Check the logs for full command output.
"
33881,Setting Log Level via Java API?,"**System information**
- TensorFlow version: 1.14 (via Java API)

**Describe the current behavior**

When using the current Java bindings for TensorFlow, the log gets filled with output from every operation when a model is evaluated. I was unable to find a way to set the log level via the Java API. Is this at all possible?
"
33880, Support sparse inputs for Embedding layer,"**System information**
- TensorFlow version (you are using): 2.0.0
- Are you willing to contribute it (Yes/No): Yes. And the code change is ready.

**Describe the feature and the current behavior/state.**
The tf.keras.layers.Embedding only can be used with dense inputs. The user must customize a layer for sparse tensor inputs by using tf.nn.embedding_lookup_sparse.  Or, the user needs to use tf.feature_columns.embedding_columns to transform sparse inputs to tf.layer.DenseFeature.

**Will this change the current api? How?**
The Embedding layer should add the `combiner` argument for sparse inputs. The value of `combiner` can be ""sum"", ""mean"" and so on.

**Who will benefit with this feature?**
Embedding with sparse inputs is commonly used in advertising and recommendation system in which the input ids of a sample are very sparse. 

**Any Other info.**
"
33879,"ERROR: An error occurred during the fetch of repository 'local_config_cuda': Traceback (most recent call last): File ""/home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1266 _create_local_cuda_repository(repository_ctx) File ""/home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1199, in _create_local_cuda_repository _tpl(repository_ctx, ""crosstool:BUILD"", c...) File ""/home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl"", line 745, in _tpl repository_ctx.template(out, Label((""//third_party/gpus/%s...)), ...) class com.google.devtools.build.lib.syntax.SkylarkList$MutableList cannot be cast to class java.lang.String (com.google.devtools.build.lib.syntax.SkylarkList$MutableList is in unnamed module of loader 'app'; java.lang.String is in module java.base of loader 'bootstrap')","bazel version -- [bazel release 0.26.1]
cuda 10.0
cudnn 7
ubuntu 18.04
tensorflow r1.14

while building tensorflow, getting this error:
INFO: Call stack for the definition of repository 'local_config_cuda' which is a cuda_configure (rule definition at /home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl:1268:18):
 - /home/shaurya/Downloads/tensorflow/tensorflow/workspace.bzl:63:5
 - /home/shaurya/Downloads/tensorflow/WORKSPACE:94:1
ERROR: An error occurred during the fetch of repository 'local_config_cuda':
   Traceback (most recent call last):
	File ""/home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1266
		_create_local_cuda_repository(repository_ctx)
	File ""/home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1199, in _create_local_cuda_repository
		_tpl(repository_ctx, ""crosstool:BUILD"", c...)
	File ""/home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl"", line 745, in _tpl
		repository_ctx.template(out, Label((""//third_party/gpus/%s...)), ...)
class com.google.devtools.build.lib.syntax.SkylarkList$MutableList cannot be cast to class java.lang.String (com.google.devtools.build.lib.syntax.SkylarkList$MutableList is in unnamed module of loader 'app'; java.lang.String is in module java.base of loader 'bootstrap')
ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1266
		_create_local_cuda_repository(repository_ctx)
	File ""/home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1199, in _create_local_cuda_repository
		_tpl(repository_ctx, ""crosstool:BUILD"", c...)
	File ""/home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl"", line 745, in _tpl
		repository_ctx.template(out, Label((""//third_party/gpus/%s...)), ...)
class com.google.devtools.build.lib.syntax.SkylarkList$MutableList cannot be cast to class java.lang.String (com.google.devtools.build.lib.syntax.SkylarkList$MutableList is in unnamed module of loader 'app'; java.lang.String is in module java.base of loader 'bootstrap')
WARNING: Target pattern parsing failed.
ERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1266
		_create_local_cuda_repository(repository_ctx)
	File ""/home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1199, in _create_local_cuda_repository
		_tpl(repository_ctx, ""crosstool:BUILD"", c...)
	File ""/home/shaurya/Downloads/tensorflow/third_party/gpus/cuda_configure.bzl"", line 745, in _tpl
		repository_ctx.template(out, Label((""//third_party/gpus/%s...)), ...)
class com.google.devtools.build.lib.syntax.SkylarkList$MutableList cannot be cast to class java.lang.String (com.google.devtools.build.lib.syntax.SkylarkList$MutableList is in unnamed module of loader 'app'; java.lang.String is in module java.base of loader 'bootstrap')
INFO: Elapsed time: 0.485s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: tensorflow/tools/pip_package
"
33878,Strange behaviour of tf.sigmoid,"**System information**
- OS Platform and Distribution: Manjaro Linux testing
- TensorFlow installed from: binary (pip tf-nightly)
- TensorFlow version: v1.12.1-17077-ge9a3aa1 2.1.0-dev20191030
- Python version: 3.7.4
- CPU Model: Intel m3-6Y30

**Describe the current behavior**
It seems that `tf.sigmoid` returns different values for identical inputs.

**Describe the expected behavior**
Return identical outputs for identical inputs, regardless of the error scale.

**Code to reproduce the issue**
```
import tensorflow as tf

a = tf.convert_to_tensor(
    [[0.2, 0.2],
     [0.2, 0.2],
     [0.2, 0.2],
     [0.2, 0.2],
     [0.2, 0.2],],
    dtype=tf.float32)

sigm = tf.sigmoid(a)

if tf.__version__.startswith('1'):
  tf.InteractiveSession()
  sigm = sigm.eval()
elif tf.__version__.startswith('2'):
  sigm = sigm.numpy()
else:
  raise ValueError()

assert((sigm[0] == sigm[1]).all()); print(""*""*1)
assert((sigm[0] == sigm[2]).all()); print(""*""*2)
assert((sigm[0] == sigm[3]).all()); print(""*""*3)
assert((sigm[0] == sigm[4]).all()); print(""*""*4)
```

**Other info / logs**
I can reproduce this in TensorFlow 1.x, 2.0, on GPU and CPU, on my laptop or in Google Colab.
`1 / (1 + tf.exp(-a))` seems to return the expected output.

TensorFlow appears to use the sigmoid implementation from the Eigen library, so I am trying to notify the contributors listed in the source files @benoitsteiner @ebrevdo @ggael 
I know that the differences are very small, yet the sigmoid function is at the core of some stateful operations such as LSTM, posing the risk of error accumulation. Besides that, I am simply curious to find out what causes this difference."
33876,How to add an optimizer to tesorflow simple speech recognition,"I wanna know how to add an optimizer such as Adam, or Nadam optimizer to the simple speech recognition example in this repository? Because I don't know where to or how to add it in the code such as to ""model.py"" file or where and how?"
33875,slim.conv2d_transpose(),"**System information**
- OS Platform and Distribution: arm aarch64 cortex A A54:
- TensorFlow installed from (source or binary):  1.12.0 cross-compiled from source
- TensorFlow version (or github SHA if from source): tensorflow-lite/benchmark_model


**Provide the text output from tflite_convert**
using command 'TOCO' converted model sucessfully, but occur segment fault when run benchmark_model --graph=*.tflite(* is my model name)
```
# Copy and paste here
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33872,Failed to load native Tensorflow runtime. Rasbian buster.,"**System information**
- Rasbian buster
- TensorFlow installed whl file.
- TensorFlow version: 1.14.0
- Python version: 3.7
- Installed using Pip

**I was having trouble installing it as per issue #33838 . I was able to install it by renaming the file but I'm not getting a new error when trying to import the package. No, installing a newer version of tensorflow is not an option. Neither for python. I going to stick to these versions.**

```>>> import tensorflow
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.7/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.7/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /usr/local/lib/python3.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _PyThreadState_Current

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.7/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.7/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /usr/local/lib/python3.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _PyThreadState_Current


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
"
33871,how to run test case in ring_reducer_test.cc,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):CentOS Linux release 7.6.1810 (Core)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A
- TensorFlow installed from (source or binary):source
- TensorFlow version:1.14.0
- Python version:3.6.8
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source): 0.25.0
- GCC/Compiler version (if compiling from source):7.3.1
- CUDA/cuDNN version:cuda:10.0, cudnn:7.5.0.56
- GPU model and memory:Telas v100, 32GB

I want to run test case in tensorflow/core/common_runtime/ring_reducer_test.cc, so I try this:
```
bazel test -c opt --config=cuda //tensorflow/core:ring_reducer_test
```
but bazel give me a error messages:
```
debian ~/collective/tensorflow $ bazel test -c opt --config=cuda //tensorflow/core:ring_reducer_test
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
ERROR: Skipping '//tensorflow/core:ring_reducer_test': no such target '//tensorflow/core:ring_reducer_test': target 'ring_reducer_test' not declared in package 'tensorflow/core' defined by /home/zxy/collective/tensorflow/tensorflow/core/BUILD
ERROR: no such target '//tensorflow/core:ring_reducer_test': target 'ring_reducer_test' not declared in package 'tensorflow/core' defined by /home/zxy/collective/tensorflow/tensorflow/core/BUILD
INFO: Elapsed time: 0.212s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
FAILED: Build did NOT complete successfully (0 packages loaded)
```
bazel thinks that `ring_reducer_test` is not exist in `/home/zxy/collective/tensorflow/tensorflow/core/BUILD`, but I do find it. So can you help me to run test case in `ring_reducer_test.cc`?"
33870,[tf-nightly] unable to load saved functional model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **macos mohave**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tf-nightly
- TensorFlow version (use command below): **tf-nightly-2.1.0.dev20191029**
- Python version: **3.7**
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**

Loading functional model should pass in latest version of tf2. Everything works great in tensorflow==2.0.0.

**Describe the expected behavior**

Loading saved functional model raises exception.

**Code to reproduce the issue**

```python
import tensorflow as tf

shape = (224, 224, 3)

# sequential model
model1 = tf.keras.Sequential(
            [
                tf.keras.Input(shape=shape, name=""input""),
                tf.keras.applications.MobileNetV2(include_top=False, weights=""imagenet"", input_shape=shape),
                tf.keras.layers.GlobalAveragePooling2D(),
                tf.keras.layers.Dense(256, activation=""relu"", name=""descriptor""),
                tf.keras.layers.Dense(2, activation=""softmax"", name=""probs""),
            ]
        )

# functional model
base_model2 = tf.keras.applications.MobileNetV2(include_top=False, weights=""imagenet"", input_shape=shape)
inputs = tf.keras.Input(shape=shape, name=""input"")
x = base_model2(inputs)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(256, activation=""relu"", name=""descriptor"")(x)
outputs = tf.keras.layers.Dense(2, activation=""softmax"", name=""probs"")(x)
model2 = tf.keras.Model(inputs=inputs, outputs=outputs)

tf.saved_model.save(model1, ""test1"")
tf.saved_model.save(model2, ""test2"")
#model2.save(""test2"", include_optimizer=False, save_format=""tf"")

model_1 = tf.keras.models.load_model('test1')

# THIS RAISES exception 
model_2 = tf.keras.models.load_model('test2')

```


**Other info / logs**

```
2019-10-31 09:13:04.371282: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-31 09:13:04.384631: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcafda7be50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-10-31 09:13:04.384655: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-10-31 09:13:17.924297: W tensorflow/python/util/util.cc:309] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /Users/michallukac/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1785: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Traceback (most recent call last):
  File ""save.py"", line 32, in <module>
    model_2 = tf.keras.models.load_model('test2')
  File ""/Users/michallukac/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 150, in load_model
    return saved_model_load.load(filepath, compile)
  File ""/Users/michallukac/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 89, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""/Users/michallukac/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 543, in load_internal
    export_dir)
  File ""/Users/michallukac/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 119, in __init__
    self._finalize()
  File ""/Users/michallukac/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 157, in _finalize
    created_layers={layer.name: layer for layer in node.layers})
  File ""/Users/michallukac/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1885, in reconstruct_from_config
    process_node(layer, node_data)
  File ""/Users/michallukac/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1833, in process_node
    output_tensors = layer(input_tensors, **kwargs)
  File ""/Users/michallukac/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 773, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/Users/michallukac/env/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 712, in call
    raise NotImplementedError('When subclassing the `Model` class, you should'
NotImplementedError: When subclassing the `Model` class, you should implement a `call` method.
```"
33869,"How to save model, multi-worker training with Keras ","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary):  binary（pip install tensorflow-gpu）
- TensorFlow version (use command below):  2.0.0
- Python version: 3.7.4
- CUDA/cuDNN version:  CUDA-10.0/cuDNN 7 
- GPU model and memory: 1X1080TI+2X1070Ti    11GB   8GB

**Describe the current behavior**
Failure to save model

**Describe the expected behavior**
Save model

**Code to reproduce the issue**
`

    # multi worker strategy
    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
    with strategy.scope():
        train_dataset, validation_dataset, test_dataset = load_data()
        multi_worker_model = Alexnet()
        multi_worker_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,
                                   optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),
                                   metrics=['accuracy'])
    # fit
    multi_worker_model.fit(train_dataset,
                           epochs=EPOCHS,
                           validation_steps=6,
                           validation_data=validation_dataset,
                           steps_per_epoch=45000//BATCH_SIZE,
                           callbacks=callbacks,
                           verbose=2)

    # eval
    multi_worker_model.evaluate(test_dataset)

    # save model
    # multi_worker_model.save(os.path.join(OUTPUT_PATH, 'model'))
    tf.saved_model.save(multi_worker_model, os.path.join(OUTPUT_PATH, 'model'))
`
**Other info / logs**
Traceback (most recent call last):
  File ""training_cifar10_with_multi-woker.py"", line 197, in <module>
    tf.saved_model.save(multi_worker_model, os.path.join(OUTPUT_PATH, 'model'))
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py"", line 893, in save
    meta_graph_def, saveable_view, signatures, options.namespace_whitelist)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py"", line 596, in _fill_meta_graph_def
    saver_def = saver.to_proto()
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 150, in to_proto
    save_tensor = self._traced_save(filename_tensor)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 503, in _call
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 408, in _initialize
    *args, **kwds))
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1848, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2653, in bound_method_wrapper
    return wrapped_fn(weak_instance(), *args, **kwargs)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 162, in _traced_save
    save_op = self.save(file_prefix)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 230, in save
    sharded_saves.append(saver.save(shard_prefix))
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 69, in save
    tensors.append(spec.tensor)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object.py"", line 52, in tensor
    return self._tensor() if callable(self._tensor) else self._tensor
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py"", line 1151, in tensor
    return strategy.extended.read_var(sync_on_read_variable)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/mirrored_strategy.py"", line 736, in read_var
    return replica_local_var._get_cross_replica()  # pylint: disable=protected-access
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py"", line 1237, in _get_cross_replica
    self, axis=None)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 805, in reduce
    return self._extended._reduce(reduce_op, value)  # pylint: disable=protected-access
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1436, in _reduce
    device_util.current() or ""/device:CPU:0""))[0]
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/collective_all_reduce_strategy.py"", line 490, in _reduce_to
    reduce_op, value, destinations=destinations)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 282, in reduce
    destinations)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 1025, in reduce_implementation
    all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value])[0]
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 1091, in _batch_all_reduce
    dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 1120, in _do_batch_all_reduce_dense
    ""Id"")
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_utils.py"", line 345, in build_collective_reduce
    group_key = collective_keys.get_group_key(devices)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_utils.py"", line 295, in get_group_key
    names = sorted(['%s:%d' % (d.device_type, d.device_index) for d in parsed])
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_utils.py"", line 295, in <listcomp>
    names = sorted(['%s:%d' % (d.device_type, d.device_index) for d in parsed])
TypeError: %d format: a number is required, not NoneType
"
33868,Distribution Strategy running variables: NCCL error crashes CUDA ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0/7.6.2
- GPU model and memory: Titan XP 12 gb x 8

**Describe the current behavior**
When using distribution strategy, the following code runs in graph mode, but fails in eager mode resulting in an NCCL error. Since I need persistent Variables to normalize my loss, the loss function was implemented as a callable keras layer, instantiated as a property of the keras model for which is compute the loss.


```
class HierarchicalLoss(tf.keras.layers.Layer):
    def __init__(self):
        super(HierarchicalLoss, self).__init__()

        self.running_N = {}
        self.running_sum = {}
        self.running_mean = {}

    def build(self, input_shapes):
            for layer in input_shapes['nodes']:
                var_scope = ['local_delta_loss' +  ""_"" + layer]

                self.running_sum[var_scope] = tf.Variable(
                    initial_value = 1.0,
                    dtype = tf.float64,
                    name = var_scope + '_' + 'running_sum',
                    trainable = False,
                    aggregation = tf.VariableAggregation.SUM)

                self.running_N[var_scope] = tf.Variable(
                    initial_value = 1,
                    dtype = tf.int64,
                    name = var_scope + '_' + 'running_N',
                    trainable = False,
                    aggregation = tf.VariableAggregation.SUM)
    def call(self, model_outputs):
        total_loss = 0.0
        for layer in model_output['nodes']:
            loss, sum, N = compute_loss_and_running_values(model_outputs[layer]) 
            self.running_N[layer].assign_add(N)
            self.running_sum[layer].assign_add(sum
            total_loss += 0.0
        return total_loss * self.running_N/self.running_sum
```

```
2019-10-31 00:57:17.308231: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at nccl_ops.cc:104 : Unknown: Error invoking NCCL: unhandled cuda error
2019-10-31 00:57:17.308341: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: Error invoking NCCL: unhandled cuda error
         [[{{node NcclAllReduce_7}}]]
         [[NcclAllReduce_5/_26]]
2019-10-31 00:57:17.308471: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: Error invoking NCCL: unhandled cuda error
         [[{{node NcclAllReduce_7}}]]
```

 If I change the assign_add call to +=, the model runs in eager mode, but yields the following error in graph mode 

```
TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
```

Is there a preferred way to have persistent variables within your model that are aggregated across multiple GPUs?

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**

NCCL debug info
```
node05-ccncluster:220944:221234 [1] NCCL INFO NET/Socket : Using [0]enp96s0f0:10.102.2.200<0> [1]enp134s0:192.168.4.105<0>
node05-ccncluster:220944:221234 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
node05-ccncluster:220944:221234 [1] NCCL INFO NET/IB : No device found.
NCCL version 2.4.7+cudaCUDA_MAJOR.CUDA_MINOR
node05-ccncluster:220944:224168 [1] NCCL INFO Setting affinity for GPU 1 to 0f,ff000fff
node05-ccncluster:220944:224167 [0] NCCL INFO Setting affinity for GPU 0 to 0f,ff000fff
node05-ccncluster:220944:224167 [0] NCCL INFO Channel 00 :    0   1
node05-ccncluster:220944:224167 [0] NCCL INFO Ring 00 : 0[0] -> 1[1] via P2P/direct pointer
node05-ccncluster:220944:224168 [1] NCCL INFO Ring 00 : 1[1] -> 0[0] via P2P/direct pointer
node05-ccncluster:220944:224167 [0] NCCL INFO Using 256 threads, Min Comp Cap 6, Trees disabled
node05-ccncluster:220944:224167 [0] NCCL INFO comm 0x7f7e38001b30 rank 0 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE
node05-ccncluster:220944:224168 [1] NCCL INFO comm 0x7f7e3c0010b0 rank 1 nranks 2 cudaDev 1 nvmlDev 1 - Init COMPLETE
node05-ccncluster:220944:224164 [0] NCCL INFO Launch mode Group/CGMD
node05-ccncluster:220944:224189 [0] NCCL INFO Setting affinity for GPU 0 to 0f,ff000fff
node05-ccncluster:220944:224190 [0] NCCL INFO Setting affinity for GPU 0 to 0f,ff000fff
node05-ccncluster:220944:224189 [0] NCCL INFO Channel 00 :    0   1
node05-ccncluster:220944:224189 [0] NCCL INFO Ring 00 : 0 -> 1 via P2P/common device
node05-ccncluster:220944:224190 [0] NCCL INFO Ring 00 : 1 -> 0 via P2P/common device
node05-ccncluster:220944:224189 [0] NCCL INFO Using 256 threads, Min Comp Cap 6, Trees disabled
node05-ccncluster:220944:224189 [0] NCCL INFO comm 0x7f7e44001550 rank 0 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE
node05-ccncluster:220944:224190 [0] NCCL INFO comm 0x7f7e30001040 rank 1 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE

node05-ccncluster:220944:224164 [0] external/nccl_archive/src/enqueue.cc:74 NCCL WARN Cuda failure 'invalid device ordinal'
node05-ccncluster:220944:224164 [0] NCCL INFO external/nccl_archive/src/enqueue.cc:175 -> 1
node05-ccncluster:220944:224164 [0] NCCL INFO external/nccl_archive/src/enqueue.cc:437 -> 1
```
"
33867,How does the graphdef file provided in simple audio recognition tutorial can be converted to tflite file?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04
- TensorFlow installed from (source or binary):source
- TensorFlow version (or github SHA if from [source):tensorflow 1.14


**Provide the text output from tflite_convert**

```
# Copy and paste here
```ValueError: std_dev and mean must be defined when inference_input_type is QUANTIZED_UINT8.

where i dont know mean and std_dev values 

Also, please include a link to a GraphDef or the model if possible.
https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md
**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
tflite_convert \
--output_file=model.tflite \
--graph_def_file=/home/unizen/Downloads/my_frozen_graph.pb \
--inference_type=QUANTIZED_UINT8 \
--input_shapes=16000,1:  \
--input_arrays=decoded_sample_data,decoded_sample_data:1 \
--output_arrays=labels_softmax \
"
33866,How the tflite file has been created for a frozen file from the simple audio recognition tutorial?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (or github SHA if from source):1.14


**Provide the text output from tflite_convert**

```
# Copy and paste here
`` 
 Array AudioSpectrogram, which is an input to the (Unsupported TensorFlow op: Mfcc) operator producing the output array Mfcc, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.
Fatal Python error: Aborted
Also, please include a link to a GraphDef or the model if possible.
https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md

**Any other info / logs**


Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
tflite_convert \
--output_file=model.tflite \
--graph_def_file=/home/unizen/Downloads/my_frozen_graph.pb \
--inference_type=QUANTIZED_UINT8 \
--input_shapes=16000,1:1,1\
--input_arrays=decoded_sample_data,decoded_sample_data:1 \
--output_arrays=labels_softmax \
"
33865,TensorFlow GPU version uses Eigen for convolution.,"I am debugging the Tensorflow conv_ops_test in the core/kernel folder via VS code. 
I found that TensorFlow uses Eigen for GPU version convolution. Not sure why coz I heard that it should call cuBLAS library for GPU things. Hope someone could help me.

The settings and commands that I used are as follows:

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below): 1.4
Python version: 3.5
Bazel version (if compiling from source): 0.54
GCC/Compiler version (if compiling from source): 5.5
CUDA/cuDNN version: 8/6
GPU model and memory: GTX 1080Ti
Exact command to reproduce: bazel build --spawn_strategy=standalone --verbose_failures --config=cuda --copt=""-fPIC"" --copt=""-DNDEBUG"" --local_resources 11048,2.0,2.0 -c dbg --copt -g //tensorflow/tools/pip_package:build_pip_package
and then: bazel build --config=cuda -c dbg --copt -g //tensorflow/core/kernels:conv_ops_test"
33864,Windows fatal exception: access violation with tensorboard,"I met a [strange problem]( https://stackoverflow.com/questions/58636880/windows-fatal-exception-access-violation-with-tensorboard), It works well before, then I move all anaconda files from one disk to another SSD, the error occurs. I have tried to remove all the anaconda file and reinstall the whole thing, but still nothing."
33863,"Build breaks: The value 'REPOSITORY_NAME' has been removed in favor of 'repository_name()', please use the latter (https://docs.bazel.build/versions/master/skylark/lib/native.html#repository_name).","TF 2.0.0 fails to be built by bazel-1.1.0:

```
INFO: Found applicable config definition build:opt in file /usr/ports/science/py-tensorflow/work-py36/tensorflow-2.0.0/.tf_configure.bazelrc: --copt=-march=native --copt=-I/usr/local/include --host_copt=-march=native --define with_default_optimizations=true
ERROR: /usr/ports/science/py-tensorflow/work-py36/bazel_out/05d0f16da4b074c80492981824445ee0/external/com_google_protobuf/protobuf.bzl:274:40: The value 'REPOSITORY_NAME' has been removed in favor of 'repository_name()', please use the latter (https://docs.bazel.build/versions/master/skylark/lib/native.html#repository_name).
ERROR: /usr/ports/science/py-tensorflow/work-py36/bazel_out/05d0f16da4b074c80492981824445ee0/external/com_google_protobuf/protobuf.bzl:275:33: The value 'PACKAGE_NAME' has been removed in favor of 'package_name()', please use the latter (https://docs.bazel.build/versions/master/skylark/lib/native.html#package_name). 
ERROR: /usr/ports/science/py-tensorflow/work-py36/bazel_out/05d0f16da4b074c80492981824445ee0/external/com_google_protobuf/protobuf.bzl:275:11: The value 'PACKAGE_NAME' has been removed in favor of 'package_name()', please use the latter (https://docs.bazel.build/versions/master/skylark/lib/native.html#package_name). 
INFO: Call stack for the definition of repository 'local_config_syslibs' which is a syslibs_configure (rule definition at /usr/ports/science/py-tensorflow/work-py36/tensorflow-2.0.0/third_party/systemlibs/syslibs_configure.bzl:154:21):
 - /usr/ports/science/py-tensorflow/work-py36/tensorflow-2.0.0/tensorflow/workspace.bzl:73:5
 - /usr/ports/science/py-tensorflow/work-py36/tensorflow-2.0.0/WORKSPACE:19:1
ERROR: Skipping '//tensorflow:libtensorflow_cc.so': error loading package 'tensorflow': in /usr/ports/science/py-tensorflow/work-py36/tensorflow-2.0.0/tensorflow/core/platform/default/build_config.bzl: Extension 'protobuf.bzl' has errors
ERROR: error loading package 'tensorflow': in /usr/ports/science/py-tensorflow/work-py36/tensorflow-2.0.0/tensorflow/core/platform/default/build_config.bzl: Extension 'protobuf.bzl' has errors
```

Both bazel and TF are of the latest versions. What's going on?"
33862,Segfault on multiple writes to dynamically-sized TensorArray inside tf.function,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 1.15
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

This code reliably produces a segmentation fault:

```python
%tensorflow_version 1.x
import faulthandler
faulthandler.enable()
import tensorflow as tf
tf.enable_control_flow_v2()
from tensorflow.python.ops.tensor_array_ops import build_ta_with_new_flow as ta_like

num_iterations = 5

if True:
  # dynamic sizing; this is the broken case.
  initial_xs = tf.TensorArray(tf.float32, size=0,
                              dynamic_size=True, clear_after_read=False)
else:
  initial_xs = tf.TensorArray(tf.float32, size=chunk_size * num_iterations,
                              dynamic_size=False, clear_after_read=False)

z = tf.constant(0.)

@tf.function(autograph=False)
def body_fn(i, flow):
  xs = ta_like(initial_xs, flow)

  # write to the TensorArray multiple times in consecutive locations.
  # chunk_size > 1 is the broken case.
  chunk_size = 2
  for j in range(chunk_size):
    xs = xs.write(i * chunk_size + j, z)

  return i + 1, xs.flow

i, xs = tf.constant(0), initial_xs
for _ in range(num_iterations):
  i, flow = body_fn(i, xs.flow)
  xs = ta_like(initial_xs, flow)

# the second call to `tf.gradients` causes a segfault
tf.gradients(tf.reduce_mean(xs.stack()), z)
tf.gradients(tf.reduce_mean(xs.stack()), z)
```

The loop code is pretty hairy but in plain python, it would read like this:

```python
xs = []
for i in range(num_iterations):
  for j in range(chunk_size):
    xs.append(0)
```

The issue seems to be the combination of dynamic sizing of the `TensorArray` and multiple appends per iteration. Using `faulthandler` as above gives the following traceback at the point of the segfault:

```
 File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1607 in _create_c_op
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1770 in __init__
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 3426 in _create_op_internal
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 3357 in create_op
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py"", line 507 in new_func
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 794 in _apply_op_helper
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_functional_ops.py"", line 672 in stateful_partitioned_call
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/ops/functional_ops.py"", line 859 in partitioned_call
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 540 in call
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1230 in _call_flat
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 697 in _rewrite_forward_and_call_backward
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 715 in _registered_grad_fn
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 679 in <lambda>
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 350 in _MaybeCompile
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 679 in _GradientsHelper
  File ""/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/ops/gradients_impl.py"", line 158 in gradients
  File ""/home/tim/memoryhole/segfault.py"", line 39 in <module>
[...]
Segmentation fault (core dumped)
```

P.S., my use case is I'm trying to convert an existing `while_loop` into an unrolled sequence of `tf.function` calls in order to reduce graph size without giving up on second-order derivatives. It looks promising so far, but do let me know if this is wrong-headed."
33861,tf 1.14 compile error with gcc 4.9.2,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.14.0
- Python version: 2.7
- Installed using virtualenv? pip? conda?: 
- Bazel version (if compiling from source): 0.25.0
- GCC/Compiler version (if compiling from source): 4.9.2
- CUDA/cuDNN version: 
- GPU model and memory:



**Describe the problem**
`[944 / 2,400] Compiling external/protobuf_archive/src/google/protobuf/compiler/java/java_message_field_lite.cc [for host]; 0s local ... (47 actions running)
ERROR: /home/admin/tensorflow-1.14.0/tensorflow/lite/kernels/BUILD:403:1: C++ compilation of rule '//tensorflow/lite/kernels:lstm_eval' failed (Exit 1)
In file included from external/eigen_archive/Eigen/Core:161:0,
                 from ./third_party/eigen3/Eigen/Core:1,
                 from tensorflow/lite/kernels/lstm_eval.cc:23:
external/eigen_archive/Eigen/src/Core/arch/AVX512/PacketMath.h:124:1: error: 'Packet Eigen::internal::pset1(const typename Eigen::internal::unpacket_traits<Packet>::type&) [with Packet = __vector(16) float; typename Eigen::internal::unpacket_traits<Packet>::type = float]' conflicts with a previous declaration
 }
 ^
In file included from external/eigen_archive/Eigen/Core:158:0,
                 from ./third_party/eigen3/Eigen/Core:1,
                 from tensorflow/lite/kernels/lstm_eval.cc:23:
external/eigen_archive/Eigen/src/Core/arch/AVX/PacketMath.h:130:41: note: previous declaration 'Packet Eigen::internal::pset1(const typename Eigen::internal::unpacket_traits<Packet>::type&) [with Packet = __vector(8) float; typename Eigen::internal::unpacket_traits<Packet>::type = float]'
 template<> EIGEN_STRONG_INLINE Packet8f pset1<Packet8f>(const float&  from) { return _mm256_set1_ps(from); }
                                         ^
In file included from external/eigen_archive/Eigen/Core:161:0,
                 from ./third_party/eigen3/Eigen/Core:1,
                 from tensorflow/lite/kernels/lstm_eval.cc:23:
external/eigen_archive/Eigen/src/Core/arch/AVX512/PacketMath.h:122:31: note: -fabi-version=6 (or =0) avoids this error with a change in mangling
 EIGEN_STRONG_INLINE Packet16f pset1<Packet16f>(const float& from) {
                               ^
external/eigen_archive/Eigen/src/Core/arch/AVX512/PacketMath.h:128:1: error: 'Packet Eigen::internal::pset1(const typename Eigen::internal::unpacket_traits<Packet>::type&) [with Packet = __vector(8) double; typename Eigen::internal::unpacket_traits<Packet>::type = double]' conflicts with a previous declaration
 }
 ^
In file included from external/eigen_archive/Eigen/Core:158:0,
                 from ./third_party/eigen3/Eigen/Core:1,
                 from tensorflow/lite/kernels/lstm_eval.cc:23:
external/eigen_archive/Eigen/src/Core/arch/AVX/PacketMath.h:131:41: note: previous declaration 'Packet Eigen::internal::pset1(const typename Eigen::internal::unpacket_traits<Packet>::type&) [with Packet = __vector(4) double; typename Eigen::internal::unpacket_traits<Packet>::type = double]'
 template<> EIGEN_STRONG_INLINE Packet4d pset1<Packet4d>(const double& from) { return _mm256_set1_pd(from); }
                                         ^
In file included from external/eigen_archive/Eigen/Core:161:0,
                 from ./third_party/eigen3/Eigen/Core:1,
                 from tensorflow/lite/kernels/lstm_eval.cc:23:
external/eigen_archive/Eigen/src/Core/arch/AVX512/PacketMath.h:126:30: note: -fabi-version=6 (or =0) avoids this error with a change in mangling
 EIGEN_STRONG_INLINE Packet8d pset1<Packet8d>(const double& from) {
                                                           ^
external/eigen_archive/Eigen/src/Core/arch/AVX512/PacketMath.h:132:1: error: 'Packet Eigen::internal::pset1(const typename Eigen::internal::unpacket_traits<Packet>::type&) [with Packet = __vector(8) long long int; typename Eigen::internal::unpacket_traits<Packet>::type = int]' conflicts with a previous declaration
 }
 ^`
**Provide the exact sequence of commands / steps that you executed before running into the problem**

bazel build --config=opt --config=mkl --cxxopt=-mavx --cxxopt=-mavx2 --cxxopt=-msse3 --cxxopt=-msse4.1 --cxxopt=-msse4.2 --cxxopt=-mfma --copt=-mavx --copt=-mavx2 --copt=-msse3 --copt=-msse4.1 --copt=-msse4.2 --copt=-mfma --cxxopt=-fabi-version=6 --copt=-fabi-version=6 //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33859,Wrong error being thrown with keras.utils.get_file when using extract=True,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6.8

Following on the stackoverflow question [here](https://stackoverflow.com/questions/58634576/whats-the-error-when-importing-url-data-set-to-colab), it seems like `keras.utils.get_file` does not throw the right error message when trying to download a zip file with archive extraction enabled. It throws a 403 HTTP Error even if it works fine with `extract=False`.

**Describe the expected behavior**
It probably should throw an error explaining that the extraction failed.

**Code to reproduce the issue**

```python
import tensorflow as tf

_URL = 'http://iies.ucaldas.edu.co/biostratigraphy/Training_particles.zip'
tf.compat.v2.keras.utils.get_file('file.zip', origin=_URL, extract=True) ## HTTP Error 403
# tf.compat.v2.keras.utils.get_file('file.zip', origin=_URL) // but this works 
```

**Other info / logs**
```
Exception                                 Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/data_utils.py in get_file(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)
    251         urlretrieve(origin, fpath, dl_progress)
    252       except HTTPError as e:
--> 253         raise Exception(error_msg.format(origin, e.code, e.msg))
    254       except URLError as e:
    255         raise Exception(error_msg.format(origin, e.errno, e.reason))

Exception: URL fetch failure on http://iies.ucaldas.edu.co/biostratigraphy/Training_particles.zip: 403 -- Forbidden
```"
33857,Fail to invoke tflite_runtime.interpreter,"I'm trying to run the `tflite_runtime.interpreter` on an armv7 board. It doesn't support AVX instruction so this is the reason for using tflite rather than the tensorflow binary available for raspberry pi's.

As far as I can tell I'm setting the tensor input correctly. I've tested this by using the 'tensorflow.compat.v2.audio.decode_wav' function to compare against.

However when I go to run the interpreter I get the following error:
```
Traceback (most recent call last):
  File ""/home/debian/xo/keyword-demo/test/test__litewave.py"", line 62, in test_detect_keywords
    results = lite_wave.detect_keywords()
  File ""./handlers/__litewave.py"", line 66, in detect_keywords
    self.__interpreter.invoke()
  File ""/home/debian/xo/keyword-demo/venv/lib/python3.7/site-packages/tflite_runtime/interpreter.py"", line 453, in invoke
    self._interpreter.Invoke()
  File ""/home/debian/xo/keyword-demo/venv/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py"", line 109, in Invoke
    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_Invoke(self)
RuntimeError: tensorflow/lite/kernels/mfcc.cc:131 params->dct_coefficient_count != mfcc_output.size() (40 != 0)Node number 1 (Mfcc) failed to invoke.
```

I couldn't find a python example for the keyword spotting demo using Tensorflow Lite so I'm adapting the following two examples:
https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/raspberry_pi/detect_picamera.py
https://github.com/tensorflow/examples/blob/master/lite/examples/image_classification/raspberry_pi/classify_picamera.py

I'm using the following code to test:
```
import sys
import unittest

sys.path.append('./handlers')

from __litewave import LiteWaveHandle

import numpy as np
from tensorflow.compat.v2.audio import decode_wav
from tensorflow.compat.v2.io import read_file


class TestLiteWaveHandle(unittest.TestCase):

    def test_load_labels(self):
        lite_wave = LiteWaveHandle()

        labels = {0: '_silence_', 1: '_unknown_', 2: 'yes', 3: 'no', 4: 'up', 5: 'down', 6: 'left', 7: 'right', 8: 'on', 9: 'off', 10: 'stop', 11: 'go'}
        self.assertEqual(lite_wave.load_labels(""./models/speech_commands_lite/conv_actions_labels.txt""), labels)

    def test_decode_wav(self):
        lite_wave_tf = LiteWaveHandle()
        lite_wave_np = LiteWaveHandle()


        # set the input tensor using tf wave decoder
        audio, sample_rate = decode_wav(
            read_file(""./test/vectors/go/0a2b400e_nohash_0.wav""),
            desired_channels=1,
            desired_samples=16000,
        )
        lite_wave_tf.set_input_tensor_tf(audio)
        input_tensor_tf = lite_wave_tf.get_input_tensor()


        # set the input tensor using custom wave decoder
        audio = lite_wave_np.decode_wav('./test/vectors/go/0a2b400e_nohash_0.wav')
        lite_wave_np.set_input_tensor(audio)
        input_tensor_np = lite_wave_np.get_input_tensor() 

        self.assertTrue(np.array_equal(input_tensor_tf, input_tensor_np))

    def test_set_input_tensor(self):
        lite_wave = LiteWaveHandle()

        audio = lite_wave.decode_wav('./test/vectors/go/0a2b400e_nohash_0.wav')
        lite_wave.set_input_tensor(audio)
        self.assertTrue(np.array_equal(audio, lite_wave.get_input_tensor()))

    def test_get_output_tensor(self):
        lite_wave = LiteWaveHandle()

        output_details, output = lite_wave.get_output_tensor(0)
        self.assertEqual(output_details[""name""], 'labels_softmax')

    def test_detect_keywords(self):
        lite_wave = LiteWaveHandle()

        audio = lite_wave.decode_wav('./test/vectors/go/0a2b400e_nohash_0.wav')
        lite_wave.set_input_tensor(audio)

        label_id, prob = lite_wave.detect_keywords()[0]
        self.assertEqual(lite_wave.labels[label_id], 'go')
```

And this is the actual code for the LiteWaveHandle I'm trying to create
```
import os

import re
import wave
import struct

from tflite_runtime.interpreter import Interpreter
import numpy as np

class LiteWaveHandle:
    """"""A class to handle lite inferences on wave data""""""

    def __init__(self):
        self.labels = self.load_labels(""./models/speech_commands_lite/conv_actions_labels.txt"")

        self.__interpreter = Interpreter(model_path=""./models/speech_commands_lite/conv_actions_frozen.tflite"")
        self.__interpreter.allocate_tensors()

    def load_labels(self, file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            labels = {}
            for row_number, content in enumerate(lines):
                pair = re.split(r'[:\s]+', content.strip(), maxsplit=1)
                if len(pair) == 2 and pair[0].strip().isdigit():
                    labels[int(pair[0])] = pair[1].strip()
                else:
                    labels[row_number] = pair[0].strip()
        return labels

    def decode_wav(self, file_path):
        """"""wave file to a numpy array of floats limited size to 16000""""""
        with wave.open(file_path) as wf:
            astr = wf.readframes(wf.getnframes())
            # convert binary chunks to short 
            audio = struct.unpack(""%ih"" % (wf.getnframes()* wf.getnchannels()), astr)
            audio = [float(val) / pow(2, 15) for val in audio]
            audio = np.asarray(audio)
            return np.reshape(audio, (16000, 1))

    def set_input_tensor(self, audio):
        """"""Sets the input tensor.""""""
        tensor_index = self.__interpreter.get_input_details()[0]['index']
        input_tensor = self.__interpreter.tensor(tensor_index)()
        input_tensor[:] = audio

    def set_input_tensor_tf(self, audio):
        tensor_index = self.__interpreter.get_input_details()[0]['index']
        input_tensor = self.__interpreter.tensor(tensor_index)()[0]
        self.__interpreter.set_tensor(tensor_index, audio)

    def get_input_tensor(self):
        tensor_index = self.__interpreter.get_input_details()[0]['index']
        return self.__interpreter.get_tensor(tensor_index)

    def get_output_tensor(self, index):
        """"""Returns the output tensor at the given index.""""""
        output_details = self.__interpreter.get_output_details()[index]
        output = np.squeeze(self.__interpreter.get_tensor(output_details['index']))
        return output_details, output

    def detect_keywords(self, top_k=1):
        """"""Returns a list of detection results, each a dictionary of object info.""""""
        self.__interpreter.invoke()

        output_details, output = self.get_output_tensor(0)

        ordered = np.argpartition(-output, top_k)
        return [(i, output[i]) for i in ordered[:top_k]]
```

This is running on an armv7 with python3.7.3 built from source. tflite-runtime is 2.0.0. The tflite models used are these: https://storage.googleapis.com/download.tensorflow.org/models/tflite/conv_actions_tflite.zip

If there is anything else I can add to help debug let me know. 
"
33856,Outdated doc for tf.keras.Model.save,"## URL(s) with the issue:

[https://www.tensorflow.org/api_docs/python/tf/keras/Model#save](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save)

## Description of issue (what needs changing):

The following sentence is outdated and recommends to use a deprecated method:

> The 'tf' option is currently disabled (use [tf.keras.experimental.export_saved_model](https://www.tensorflow.org/api_docs/python/tf/keras/experimental/export_saved_model) instead)."
33855,Tensorflow 2 Integer Labels,"From the docs, it says if I want to use labels without one_hot encoding in advance, I should use SparseCategoricalCrossentropy. And the result is strange. 

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 1903 18362.418
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0
- Python version: Python 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)] :: Anaconda, Inc.
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cudart64_100.dll
- GPU model and memory:

**Describe the current behavior**
the model won't compile
using from_logits=False, reporting TypeError: Expected int32, got 1e-07 of type 'float' instead.
using from_logits=True, get TypeError: Value passed to parameter 'features' has DataType int32 not in list of allowed values: float16, bfloat16, float32, float64

```
Traceback (most recent call last):
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\framework\tensor_util.py"", line 324, in _AssertCompatible
    fn(values)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\framework\tensor_util.py"", line 263, in inner
    _ = [_check_failed(v) for v in nest.flatten(values)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\framework\tensor_util.py"", line 264, in <listcomp>
    if not isinstance(v, expected_types)]
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\framework\tensor_util.py"", line 248, in _check_failed
    raise ValueError(v)
ValueError: 1e-07

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/user/OneDrive/UH/cvxtest/main2.py"", line 84, in <module>
    metrics=[
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\training\tracking\base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 373, in compile
    self._compile_weights_loss_and_weighted_metrics()
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\training\tracking\base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 1653, in _compile_weights_loss_and_weighted_metrics
    self.total_loss = self._prepare_total_loss(masks)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 1713, in _prepare_total_loss
    per_sample_losses = loss_fn.call(y_true, y_pred)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\losses.py"", line 221, in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\losses.py"", line 978, in sparse_categorical_crossentropy
    y_true, y_pred, from_logits=from_logits, axis=axis)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 4504, in sparse_categorical_crossentropy
    epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 673, in _constant_to_tensor
    return constant_op.constant(x, dtype=dtype)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\framework\constant_op.py"", line 227, in constant
    allow_broadcast=True)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\framework\constant_op.py"", line 265, in _constant_impl
    allow_broadcast=allow_broadcast))
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\framework\tensor_util.py"", line 449, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\framework\tensor_util.py"", line 331, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected int32, got 1e-07 of type 'float' instead.
```

```
Traceback (most recent call last):
  File ""C:/Users/user/OneDrive/UH/cvxtest/main2.py"", line 84, in <module>
    metrics=[
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\training\tracking\base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 373, in compile
    self._compile_weights_loss_and_weighted_metrics()
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\training\tracking\base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 1653, in _compile_weights_loss_and_weighted_metrics
    self.total_loss = self._prepare_total_loss(masks)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 1713, in _prepare_total_loss
    per_sample_losses = loss_fn.call(y_true, y_pred)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\losses.py"", line 221, in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\losses.py"", line 978, in sparse_categorical_crossentropy
    y_true, y_pred, from_logits=from_logits, axis=axis)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 4546, in sparse_categorical_crossentropy
    labels=target, logits=output)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\ops\nn_ops.py"", line 3477, in sparse_softmax_cross_entropy_with_logits_v2
    labels=labels, logits=logits, name=name)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\ops\nn_ops.py"", line 3397, in sparse_softmax_cross_entropy_with_logits
    precise_logits, labels, name=name)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_nn_ops.py"", line 11842, in sparse_softmax_cross_entropy_with_logits
    labels=labels, name=name)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 631, in _apply_op_helper
    param_name=input_name)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 60, in _SatisfiesTypeConstraint
    "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))
TypeError: Value passed to parameter 'features' has DataType int32 not in list of allowed values: float16, bfloat16, float32, float64
```

**Describe the expected behavior**
Compile and run. It is a pretty simple model after all.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import numpy as np
import tensorflow as tf

from keras.datasets import fashion_mnist

tf.random.set_seed(1)
np.random.seed(1)


if __name__ == '__main__':
    (train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()

    train_X = train_X.reshape(-1, 28, 28, 1)
    test_X = test_X.reshape(-1, 28, 28, 1)

    train_X = train_X.astype('float32')
    test_X = test_X.astype('float32')
    train_X = train_X / 255
    test_X = test_X / 255

    train_L = len(train_X)
    test_L = len(test_X)

    print(train_Y[0], type(train_Y[0]))

    x_input = tf.keras.Input(dtype=tf.dtypes.float32, shape=[28, 28, 1])
    y_input = tf.keras.Input(dtype=tf.dtypes.int32, shape=[1])
    
    x = tf.keras.layers.Flatten()(x_input)
    y_target = tf.one_hot(y_input, 10)
    y_logits = tf.keras.layers.Dense(10)(x)
    y_probability = tf.keras.layers.Softmax()(y_logits)
    y_output = tf.math.argmax(
        input=y_probability,
        axis=1,
        output_type=tf.dtypes.int32
    )

    model = tf.keras.Model(inputs=[x_input, y_input], outputs=y_output)

    model.compile(
        optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),

        metrics=[
            # 'accuracy'
            #tf.keras.metrics.Accuracy()
        ]
    )

    # Trains for 5 epochs
    model.fit(x=train_X, y=train_Y, batch_size=32, epochs=5)

```


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33853,Tensorflow lite undefined reference on ARM64,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NVIDIA Drive PX2
- TensorFlow installed from (source or binary): source
- TensorFlow version: master
- GCC/Compiler version (if compiling from source): 5.5.0
- CUDA/cuDNN version: 9.2/7.1.2
- GPU model and memory: NVIDIA GP106


**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

I cloned the tensorflow repository, then executed (as specified [here](https://www.tensorflow.org/lite/guide/build_arm64)) : 
`./tensorflow/lite/tools/make/download_dependencies.sh`
`./tensorflow/lite/tools/make/build_aarch64_lib.sh`

Then I tried to compile [minimal.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/minimal/minimal.cc) with : 
`g++ minimal.cc -L /media/hdd/repositories/tensorflow/tensorflow/lite/tools/make/gen/aarch64_armv8-a/lib/libtensorflow-lite.a -o test -std=c++11 -I /media/hdd/repositories/tensorflow/ -I /media/hdd/repositories/flatbuffers/include`

This gives me the error :

`/tmp/cceONMdq.o: In function `main':
minimal.cc:(.text+0x6c): undefined reference to `tflite::DefaultErrorReporter()'
minimal.cc:(.text+0x80): undefined reference to `tflite::FlatBufferModel::BuildFromFile(char const*, tflite::ErrorReporter*)'
minimal.cc:(.text+0xe0): undefined reference to `tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()'
minimal.cc:(.text+0x100): undefined reference to `tflite::InterpreterBuilder::InterpreterBuilder(tflite::FlatBufferModel const&, tflite::OpResolver const&)'
minimal.cc:(.text+0x110): undefined reference to `tflite::InterpreterBuilder::operator()(std::unique_ptr<tflite::Interpreter, std::default_delete<tflite::Interpreter> >*)'
minimal.cc:(.text+0x174): undefined reference to `tflite::Interpreter::AllocateTensors()'
minimal.cc:(.text+0x1d8): undefined reference to `tflite::PrintInterpreterState(tflite::Interpreter*)'
minimal.cc:(.text+0x1e4): undefined reference to `tflite::Interpreter::Invoke()'
minimal.cc:(.text+0x248): undefined reference to `tflite::PrintInterpreterState(tflite::Interpreter*)'
minimal.cc:(.text+0x25c): undefined reference to `tflite::InterpreterBuilder::~InterpreterBuilder()'
minimal.cc:(.text+0x2a4): undefined reference to `tflite::InterpreterBuilder::~InterpreterBuilder()'
/tmp/cceONMdq.o: In function `std::default_delete<tflite::FlatBufferModel>::operator()(tflite::FlatBufferModel*) const':
minimal.cc:(.text._ZNKSt14default_deleteIN6tflite15FlatBufferModelEEclEPS1_[_ZNKSt14default_deleteIN6tflite15FlatBufferModelEEclEPS1_]+0x24): undefined reference to `tflite::FlatBufferModel::~FlatBufferModel()'
/tmp/cceONMdq.o: In function `std::default_delete<tflite::Interpreter>::operator()(tflite::Interpreter*) const':
minimal.cc:(.text._ZNKSt14default_deleteIN6tflite11InterpreterEEclEPS1_[_ZNKSt14default_deleteIN6tflite11InterpreterEEclEPS1_]+0x24): undefined reference to `tflite::Interpreter::~Interpreter()'
/tmp/cceONMdq.o: In function `tflite::MutableOpResolver::~MutableOpResolver()':
minimal.cc:(.text._ZN6tflite17MutableOpResolverD2Ev[_ZN6tflite17MutableOpResolverD5Ev]+0xc): undefined reference to `vtable for tflite::MutableOpResolver'
minimal.cc:(.text._ZN6tflite17MutableOpResolverD2Ev[_ZN6tflite17MutableOpResolverD5Ev]+0x10): undefined reference to `vtable for tflite::MutableOpResolver'
/tmp/cceONMdq.o: In function `tflite::ops::builtin::BuiltinOpResolver::~BuiltinOpResolver()':
minimal.cc:(.text._ZN6tflite3ops7builtin17BuiltinOpResolverD2Ev[_ZN6tflite3ops7builtin17BuiltinOpResolverD5Ev]+0xc): undefined reference to `vtable for tflite::ops::builtin::BuiltinOpResolver'
minimal.cc:(.text._ZN6tflite3ops7builtin17BuiltinOpResolverD2Ev[_ZN6tflite3ops7builtin17BuiltinOpResolverD5Ev]+0x10): undefined reference to `vtable for tflite::ops::builtin::BuiltinOpResolver'
collect2: error: ld returned 1 exit status`

I tried options from https://github.com/tensorflow/tensorflow/issues/27629 and https://github.com/tensorflow/tensorflow/issues/16219 but this had no effect.

I am not an expert in compiling, an idea what I should do ?
Thank you !
"
33852,[TF-Nightly-20191030] Import fails with SegFault on Custom-Op docker image,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 (Maybe others)
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): tf-nightly-20191030

**Describe the current behavior**
TensorFlow SegFaults on import

**Code to reproduce the issue**
```
docker run --rm -it tensorflow/tensorflow:custom-op-ubuntu16 /bin/bash
pip install tf-nightly==2.1.0.dev20191030
python -c 'import tensorflow as tf'
```

Produces:
```
2019-10-30 15:12:21.473867: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory
2019-10-30 15:12:21.473933: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Segmentation fault (core dumped)
```

I didn't see this behavior in colab so not sure whats causing this. Our GPU docker image imports successfully but downstream Addons GPU tests are breaking on this nightly so it would be helpful to identify the commit that is causing these issues.

cc @yifeif @gunan 
"
33851,TF lite Gpu delegate  E/libEGL: call to OpenGL ES API with no current context (logged once per thread),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Fllow this document 
[https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md)
and using this project in android studio.
https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) : virtual device Pixel 2 in Android Studio
- TensorFlow installed from (source or binary):java package
- TensorFlow version (use command below):   
org.tensorflow:tensorflow-lite:0.0.0-nightly
org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly
- Python version:---
- Bazel version (if compiling from source):---
- GCC/Compiler version (if compiling from source):---
- CUDA/cuDNN version:CUDA 10.0
- GPU model and memory: gpu 1080


**Describe the current behavior**
My retrain ssd_mobilenet_v2 model with my  own datasets--called detect.tflite 

Input shape
```
[{'name': 'normalized_input_image_tensor',
  'index': 308,
  'shape': array([  1, 300, 300,   3], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)}]

```

Output shape

```
[{'name': 'TFLite_Detection_PostProcess',
  'index': 300,
  'shape': array([ 1, 10,  4], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)},
 {'name': 'TFLite_Detection_PostProcess:1',
  'index': 301,
  'shape': array([ 1, 10], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)},
 {'name': 'TFLite_Detection_PostProcess:2',
  'index': 302,
  'shape': array([ 1, 10], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)},
 {'name': 'TFLite_Detection_PostProcess:3',
  'index': 303,
  'shape': array([1], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)}]

```

It could run object detect app using  `https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection` projects, Just modify path to tflite and labelmap.

However we want to Using Gpu delegate like  https://www.tensorflow.org/lite/performance/gpu.

so I just using mobile_ssd_v2_float_coco.tflite which download from https://www.tensorflow.org/lite/performance/gpu .

```
input_details
[{'name': 'normalized_input_image_tensor',
  'index': 306,
  'shape': array([  1, 320, 320,   3], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)}]

output_details                                                                          

[{'name': 'raw_outputs/box_encodings',
  'index': 307,
  'shape': array([   1, 2034,    4], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)},
 {'name': 'raw_outputs/class_predictions',
  'index': 308,
  'shape': array([   1, 2034,   91], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)}]

```


But report this error in Android Studio when using virtual devices pixel 2 to Debug.
```
E/libEGL: call to OpenGL ES API with no current context (logged once per thread)
E/AndroidRuntime: FATAL EXCEPTION: main
                  Process: org.tensorflow.lite.examples.detection, PID: 5063
                  java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: OpenCL library not loaded - dlopen failed: library ""libOpenCL-pixel.so"" not found
                  Falling back to OpenGL
                  TfLiteGpuDelegate Init: [GL_INVALID_ENUM]: An unacceptable value is specified for an enumerated argument.: glGetBufferParameteri64v in tensorflow/lite/delegates/gpu/gl/gl_buffer.cc:46
                  TfLiteGpuDelegate Prepare: delegate is not initialized
                  Node number 116 (TfLiteGpuDelegateV2) failed to prepare.

``` 

If I use my detect.tflite, error is 

```
delegate:
                  CUSTOM TFLite_Detection_PostProcess: Operation is not supported.
                  First 114 operations will run on the GPU, and the remaining 1 on the CPU.
                  OpenCL library not loaded - dlopen failed: library ""libOpenCL-pixel.so"" not found
```

And I modify TFLiteObjectDetectionAPIModel.java to use Gpu Delegate:

```
  private ByteBuffer imgData;

  private Interpreter tfLite;
 + private static GpuDelegate delegate = new GpuDelegate();
 + private static  Interpreter.Options options = (new Interpreter.Options()).addDelegate(delegate);
  private TFLiteObjectDetectionAPIModel() {}

.....
.....
public static Classifier create(
...

+d.tfLite = new Interpreter(loadModelFile(assetManager, modelFilename),options);


```


**Describe the expected behavior**

1.Why the mobile_ssd_v2_float_coco.tflite input shape and output shape is different from the model  retrained using object detection api ? 
2.The code  I modifyied  TFLiteObjectDetectionAPIModel.java to using Gpu delegate  is right?


"
33850,what is gen_rnn_ops in tensorflow/python/ops,"Hi, I am trying to create my own linear tanh&sigmoid activation functions for lstmblockfusedcell (in lstm_ops.py), thus I directly create my own activation functions in rnn_cell_impl.py file and import this file in my own lstm_ops.py file. 
Then I got an error msg as follows:
`File ""/home/git/DeepSpeech/lstm_ops_dpsp.py"", line 29, in <module>
    from tensorflow.python.ops import gen_rnn_ops
ImportError: cannot import name 'gen_rnn_ops'`

But there is no much useful information about this _gen_rnn_ops_, and also I want to know whether my way to change the activation function is okay. 

By the way, I'm using 
Ubuntu 16.04
python 3.5
tensorflow-estimator 1.13.0
tensorflow-gpu       1.13.1

Thank you 

"
33849,C API: Session Options for prediction on GPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes for training and prediction**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **no**
- TensorFlow installed from (source or binary): **compile from sources**
- TensorFlow version (use command below): **2.0**
- Python version: **3.6.8**
- Bazel version (if compiling from source): **0.24.1**
- GCC/Compiler version (if compiling from source): **Visual Studio 2017 with MSVC 14.16.27023**
- CUDA/cuDNN version: **CUDA 10.1.243 / cuDNN 7.6.4.38**
- GPU model and memory: **NVIDIA GeForce RTX 2060 6Go**

**Situation**
I create a C++ program to train a model with the aim to perform image segmentation. This part works perfectly on the GPU and I export the pb file. The final application have to be in C# so this pb file is imported and the prediction is performed with TensorFlow.NET.
The prediction works as expected on CPU but not on the GPU. This issue is probably not caused by TensorFlow.NET (https://github.com/SciSharp/TensorFlow.NET/issues/434) so I think it is caused by C API. I don't understand why the training can be performed on the GPU and the prediction on the same GPU give me an out of memory error when I run the session.

**Describe the current behavior**
I set the number of GPU to one to be sure and I set the configuration GpuOptions.
To not allocate all the GPU memory I set allow_growth option to true but the issue is still present.
To limit the usage of memory I set the parameter per_process_gpu_memory_fraction 0.2, 0.5 or 0.9 but nothing changes.
For the training I only use allow_growth option and there is not out of memory error. For information I use ClientSession for this part.

**Describe the expected behavior**
Using the C API or the original source code, the configuration of GPU must be the one defined with the code. I presume the issue is with the C API because the training in C++ works on GPU.

**Code to reproduce the issue**
Training in C++:
```
tensorflow::ConfigProto& config = _sessionOptions.config;
config.set_allow_soft_placement(true);
config.set_log_device_placement(true);
config.mutable_gpu_options()->set_allow_growth(true);
```
Prediction in C#:
```
ConfigProto config = new ConfigProto();
config.LogDevicePlacement = true;
config.AllowSoftPlacement = true;
GPUOptions gpuOptions = new GPUOptions();
gpuOptions.AllowGrowth = true;
gpuOptions.PerProcessGpuMemoryFraction = 0.5;
config.DeviceCount.Add(""GPU"", 1);
config.GpuOptions = gpuOptions;
```

**Other info / logs**
With the log placement option, I noticed the GPU memory is allocated twice when I call the run method. The first allocation take almost all the available GPU memory then the second one grows ""step by step"". So I presume allow_growth option is operational for the second memory allocation but not the first one.
"
33848,CUDNN_STATUS_INTERNAL_ERROR when running with CUDA 10.0 tensorflow-gpu on RTX2080 ubuntu18,"I have Geforce 2080, running latest nvidia drivers, Cuda 10.0, matching cudnn libs and I'm getting 
CUDNN_STATUS_INTERNAL_ERROR when running with tensorflow-gpu.


**System information**
- NVIDIA drivers:  NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1  
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Linux Ubuntu 18.04)
- TensorFlow installed from (source or binary): using pip install tensorflow
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38
- Python version: 3.7.4
- GCC/Compiler version (if compiling from source): 7.4
- CUDA: 10.0
- cuDNN version: 7.6.4.38
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Getting  CUDNN_STATUS_INTERNAL_ERROR when trying to run my tensorflow program.

```

> python classify_image2.py --image_file images/dakota/20262694-7620733-A_bit_of_skin_Scarlett_s_chicness_couldn_t_be_denied_as_she_step-a-3_1572251360982.jpg
> Tagging None images/dakota/20262694-7620733-A_bit_of_skin_Scarlett_s_chicness_couldn_t_be_denied_as_she_step-a-3_1572251360982.jpg image_vectors
> WARNING:tensorflow:From classify_image2.py:144: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use tf.gfile.GFile.
> W1030 11:25:26.150423 140076018012288 deprecation.py:323] From classify_image2.py:144: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use tf.gfile.GFile.
> Creating graph
> 2019-10-30 11:25:26.333540: W tensorflow/core/framework/op_def_util.cc:370] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
> 2019-10-30 11:25:26.419195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
> 2019-10-30 11:25:26.438190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2019-10-30 11:25:26.438444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
> name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
> pciBusID: 0000:02:00.0
> 2019-10-30 11:25:26.438552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
> 2019-10-30 11:25:26.439222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
> 2019-10-30 11:25:26.439782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
> 2019-10-30 11:25:26.439910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
> 2019-10-30 11:25:26.440597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
> 2019-10-30 11:25:26.441076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
> 2019-10-30 11:25:26.442559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
> 2019-10-30 11:25:26.442603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2019-10-30 11:25:26.442865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2019-10-30 11:25:26.443091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
> 2019-10-30 11:25:26.443293: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
> 2019-10-30 11:25:26.462892: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz
> 2019-10-30 11:25:26.463602: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa96c51240 executing computations on platform Host. Devices:
> 2019-10-30 11:25:26.463612: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
> 2019-10-30 11:25:26.530626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2019-10-30 11:25:26.530928: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa96c50af0 executing computations on platform CUDA. Devices:
> 2019-10-30 11:25:26.530940: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080, Compute Capability 7.5
> 2019-10-30 11:25:26.531026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2019-10-30 11:25:26.531249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
> name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
> pciBusID: 0000:02:00.0
> 2019-10-30 11:25:26.531267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
> 2019-10-30 11:25:26.531274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
> 2019-10-30 11:25:26.531280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
> 2019-10-30 11:25:26.531286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
> 2019-10-30 11:25:26.531292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
> 2019-10-30 11:25:26.531298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
> 2019-10-30 11:25:26.531305: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
> 2019-10-30 11:25:26.531328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2019-10-30 11:25:26.531555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2019-10-30 11:25:26.531763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
> 2019-10-30 11:25:26.531782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
> 2019-10-30 11:25:26.532197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
> 2019-10-30 11:25:26.532205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
> 2019-10-30 11:25:26.532208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
> 2019-10-30 11:25:26.532255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2019-10-30 11:25:26.532487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2019-10-30 11:25:26.532713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7150 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:02:00.0, compute capability: 7.5)
> 2019-10-30 11:25:27.283539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
> 2019-10-30 11:25:27.486979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
> 2019-10-30 11:25:27.996932: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
> 2019-10-30 11:25:27.998075: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
> Traceback (most recent call last):
>   File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call
>     return fn(*args)
>   File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn
>     target_list, run_metadata)
>   File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun
>     run_metadata)
> tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
>   (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
> 	 [[{{node conv/Conv2D}}]]
>   (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
> 	 [[{{node conv/Conv2D}}]]
> 	 [[softmax/_3]]
> 0 successful operations.
> 0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""classify_image2.py"", line 345, in <module>
    tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""classify_image2.py"", line 296, in main
    run_inference_on_image(image)
  File ""classify_image2.py"", line 162, in run_inference_on_image
    {'DecodeJpeg/contents:0': image_data})
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 956, in run
    run_metadata_ptr)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node conv/Conv2D (defined at /home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node conv/Conv2D (defined at /home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]
	 [[softmax/_3]]
0 successful operations.
0 derived errors ignored.

Original stack trace for 'conv/Conv2D':
  File ""classify_image2.py"", line 345, in <module>
    tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""classify_image2.py"", line 296, in main
    run_inference_on_image(image)
  File ""classify_image2.py"", line 149, in run_inference_on_image
    create_graph()
  File ""classify_image2.py"", line 129, in create_graph
    _ = tf.import_graph_def(graph_def, name='')
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def
    producer_op_list=producer_op_list)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py"", line 517, in _import_graph_def_internal
    _ProcessNewOps(graph)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py"", line 243, in _ProcessNewOps
    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3564, in _add_new_tf_operations
    for c_op in c_api_util.new_tf_operations(self)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3564, in <listcomp>
    for c_op in c_api_util.new_tf_operations(self)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3454, in _create_op_from_tf_operation
    ret = Operation(c_op, self)
  File ""/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__
    self._traceback = tf_stack.extract_stack()

```


**Describe the expected behavior**

It should not fail with this error  :-)



**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.


export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.0/lib64/
python classify.py --image_file  someimage.jpg

-----------classify.py--------------------

```

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import os.path
import re
import sys
import tarfile
from collections import defaultdict
import psutil

import numpy as np
from six.moves import urllib
import tensorflow as tf

FLAGS = None

# pylint: disable=line-too-long
DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'

def create_graph():
  """"""Creates a graph from saved GraphDef file and returns a saver.""""""
  # Creates graph from saved graph_def.pb.
  with tf.compat.v1.gfile.FastGFile(os.path.join(
      FLAGS.model_dir, 'classify_image_graph_def.pb'), 'rb') as f:
    graph_def = tf.compat.v1.GraphDef()
    graph_def.ParseFromString(f.read())
    _ = tf.import_graph_def(graph_def, name='')

def run_inference_on_image(image):
  if not tf.io.gfile.exists(image):
    tf.compat.v1.logging.fatal('File does not exist %s', image)
  image_data = tf.compat.v1.gfile.FastGFile(image, 'rb').read()

  print(""-----Creating graph"")
  create_graph()

  with tf.compat.v1.Session() as sess:
    print(""----Get softmax_tensor"")
    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')

    print(""-----Get predictions"")
    predictions = sess.run(softmax_tensor,
                           {'DecodeJpeg/contents:0': image_data})


def maybe_download_and_extract():
  """"""Download and extract model tar file.""""""
  dest_directory = FLAGS.model_dir
  if not os.path.exists(dest_directory):
    os.makedirs(dest_directory)
  filename = DATA_URL.split('/')[-1]
  filepath = os.path.join(dest_directory, filename)
  if not os.path.exists(filepath):
    def _progress(count, block_size, total_size):
      sys.stdout.write('\r>> Downloading %s %.1f%%' % (
          filename, float(count * block_size) / float(total_size) * 100.0))
      sys.stdout.flush()
    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)
    print()
    statinfo = os.stat(filepath)
    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')
  tarfile.open(filepath, 'r:gz').extractall(dest_directory)


def main(_):
  maybe_download_and_extract()
  image = FLAGS.image_file if FLAGS.image_file else None
           # else
           # os.path.join(FLAGS.model_dir, 'cropped_panda.jpg'))

  run_inference_on_image(image)


if __name__ == '__main__':
  parser = argparse.ArgumentParser()
  parser.add_argument(
      '--model_dir',
      type=str,
      default='/tmp/imagenet',
      help=""""""\
      Path to classify_image_graph_def.pb,
      imagenet_synset_to_human_label_map.txt, and
      imagenet_2012_challenge_label_map_proto.pbtxt.\
      """"""
  )
  parser.add_argument(
      '--image_file',
      type=str,
      default='',
      help='Absolute path to image file.'
  )
  FLAGS, unparsed = parser.parse_known_args()
  tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)
~                                                                              
```

"
33847,Support SelectV2 in grappler layout transposer,"This issue is extracted from the conversation in https://github.com/tensorflow/tensorflow/pull/33694#issuecomment-546124837

 `SelectV2` currently isn't added to `grappler/op_types.cc`
https://github.com/tensorflow/tensorflow/blob/543f61dcab11cc3461c97dcdce660536e3e498d7/tensorflow/core/grappler/op_types.cc#L460
which is used in the layout optimizer?
https://github.com/tensorflow/tensorflow/blob/543f61dcab11cc3461c97dcdce660536e3e498d7/tensorflow/core/grappler/optimizers/generic_layout_optimizer_transposer_factory.cc#L95-L97

Ideally the layout optimizer would support `SelectV2` as well so it should be added to `grappler/op_types.cc`.

@reedwm Mentioned that in `SelectV2`, the inputs do not need to be the same shape but only need to be broadcastable to each other, which might be problematic for the layout optimizer. @andyly, do you know?"
33844,[tf2] Callbacks used in self-defined training,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
For now,  callbacks can only be used in tf.keras.Model.fit method.
If one writes a self-defined loop, he has to write his own codes to save model, to show logs on tensorboard, and maybe many other things. 
I think if the callbacks are here, why can't we offer some methods to make it usable in self-defined loops ? Actually, self-defined loops also has concepts like batch_begin, epoch_end, etc.
This will make self-defined loops simple and easy to write. One can focus on many other things he has to do.
Thank you !

**Will this change the current api? How?**

I think there is no need to change the current api.

**Who will benefit with this feature?**

I think the people train with self-defined loops wil benefit.

**Any Other info.**
"
33842,Optimizer state gets automatically restored when loading weights from checkpoint and doesnt change when you compile the model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): TF 2.0.0(stable)
- Python version: 3.6
- Bazel version (if compiling from source):None
- GCC/Compiler version (if compiling from source): None


**Describe the current behavior**
Optimizer state is getting restored while loading weights from model checkpoint(tf.keras.callbacks.ModelCheckpoint). Later when you compile model with different learning rate(different from the restored optimizer state), it doesn't gets updated.  

**Describe the expected behavior**
Compiling the model should update the optimizer state

**Code to reproduce the issue**

```python
import tensorflow as tf
from tensorflow.python.keras import backend as K
import numpy as np

def get_data():
    images = np.zeros((64,224))
    labels = np.zeros((64,5))
    return images,labels

def create_model():
    input_layer = tf.keras.layers.Input(name='Image_input', shape=(224), dtype='float32')
    model = tf.keras.layers.Dense(5)(input_layer)
    model = tf.keras.layers.Activation('softmax', name = ""output-softmax"")(model)
    model = tf.keras.models.Model(inputs=input_layer, outputs=[model])
    return model

os.makedirs(""checkpoints/"")
checkpoint = tf.keras.callbacks.ModelCheckpoint(""checkpoints/"", monitor='loss',
                                                save_weights_only=True, save_freq='epoch')
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=1, verbose=1)
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=1)

model = create_model()
data = get_data()
​
optimizer = tf.keras.optimizers.Adadelta(learning_rate=1.0)
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
​
print (""learning_rate"",float(K.get_value(model.optimizer.lr)))
                                                       
model.fit(data[0], data[1], batch_size=16, epochs=10,callbacks=[checkpoint,reduce_lr,early_stopping])

print (""**learning_rate_1**"",float(K.get_value(model.optimizer.lr)))`

model = create_model()

model.load_weights('checkpoints/')

optimizer = tf.keras.optimizers.Adadelta(learning_rate=0.1)
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

print (""learning_rate"",float(K.get_value(model.optimizer.lr)))`
```

final learning rate should be **0.1** but it is equal to **learning_rate_1** ."
33841,Is there a documentation/tutorial on step by step process for object detection and customised training using tensorflow2.0,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
33840,tf.image.ssim_multiscale does not work in tf-2.0.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from: binary (pip)
- TensorFlow version: `2.0.0`
- Python version: `3.5.2`
- CUDA version: `10.1`
- GPU model and memory: GTX 1060, 6GB

``` python
# example image batches
video1 = tf.random.uniform(shape=[8, 64, 64, 1], minval=0, maxval=1)
video2 = tf.random.uniform(shape=[8, 64, 64, 1], minval=0, maxval=1)
```
ssim works fine but when I use the multiscale ssim, I am getting the following error message. What am I doing wrong? How do I fix this? 

**SSIM**
``` python
ssim_score = tf.image.ssim(img1=video1, img2=video1, max_val=1.0)
print(ssim_score) # tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1.], shape=(8,), dtype=float32)
```

**MS-SSIM**
``` python
ms_ssim_score = tf.image.ssim_multiscale(img1=video1, img2=video2, max_val=1.0)
```
``` python
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-9-cc68ceec0921> in <module>
----> 1 ms_ssim_score = tf.image.ssim_multiscale(img1=video1, img2=video2, max_val=1.0)

~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/image_ops_impl.py in ssim_multiscale(img1, img2, max_val, power_factors, filter_size, filter_sigma, k1, k2)
   3405             filter_sigma=filter_sigma,
   3406             k1=k1,
-> 3407             k2=k2)
   3408         mcs.append(nn_ops.relu(cs))
   3409 

~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/image_ops_impl.py in _ssim_per_channel(img1, img2, max_val, filter_size, filter_sigma, k1, k2)
   3174               math_ops.greater_equal(shape1[-3:-1], filter_size)),
   3175           [shape1, filter_size],
-> 3176           summarize=8),
   3177       control_flow_ops.Assert(
   3178           math_ops.reduce_all(

~/.local/lib/python3.5/site-packages/tensorflow_core/python/util/tf_should_use.py in wrapped(*args, **kwargs)
    196   """"""
    197   def wrapped(*args, **kwargs):
--> 198     return _add_should_use_warning(fn(*args, **kwargs))
    199   return tf_decorator.make_decorator(
    200       fn, wrapped, 'should_use_result',

~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/control_flow_ops.py in Assert(condition, data, summarize, name)
    154           op=None,
    155           message=""Expected '%s' to be true. Summarized data: %s"" %
--> 156           (condition, ""\n"".join(data_str)))
    157     return
    158 

InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: 8, 8, 8, 1
11

```
"
33839,tensorflow.linalg.norm document missing,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/ops/linalg_ops.py#L426

## Description of issue (what needs changing):
I can't find ```tensorflow.linalg.norm``` on official v2.0 API document

"
33838,pip missing all versions beyond 1.13.1,"- Rasbian 9 buster
- TensorFlow installed from binary
- TensorFlow version: 1.14.1
- Python version: 3.7
- Installed using pip

I need tensorflow version 1.14.0 specifically. Windows has the version I'm looking for. But when i run it on my pi pip says that 1.14.0 is missing and it only lists possible version numbers of 1.11.0, 1.12.0, and 1.13.1.

**sudo python3.7 -m pip install tensorflow==1.14.0**


**Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple
ERROR: Could not find a version that satisfies the requirement tensorflow==1.14.0 (from versions: 0.11.0, 1.12.0, 1.13.1)
ERROR: No matching distribution found for tensorflow==1.14.0**"
33837,Using intermediate layer outputs in custom loss function causes CUDA_ERROR_OUT_OF_MEMORY,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
**Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
**Ubuntu 19.10**
- TensorFlow installed from (source or binary):
**Binary*
- TensorFlow version (use command below):
**2.1.0-dev20191027 (same results in 2.0)**
- Python version:
**3.7.5rc1**
- CUDA/cuDNN version:
**10.1**
- GPU model and memory:
**2080 TI 12gb + driver 430.50**

**Describe the current behavior**
I'm trying to add a kl divergence regularizer which relies on 2 intermediate layers of the encoder model. This custom loss in Keras model returns a tensor instead of a scalar when using outputs of intermediate layers. This appears to be adding operators to the graph at each iteration until I get a CUDA out of memory error.  

```
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 32, 32, 32)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 16, 16, 32)   16416       conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 8, 8, 32)     16416       conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 4, 4, 32)     16416       conv2d_2[0][0]                   
__________________________________________________________________________________________________
flatten (Flatten)               (None, 512)          0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
dense (Dense)                   (None, 256)          131328      flatten[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 256)          65792       dense[0][0]                      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 32)           8224        dense_1[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 32)           8224        dense_1[0][0]                    
__________________________________________________________________________________________________
reparameterize (Reparameterize) (None, 32)           0           dense_2[0][0]                    
                                                                 dense_3[0][0]                    
__________________________________________________________________________________________________
model_1 (Model)                 (None, 64, 64, 3)    256611      reparameterize[0][0]             
==================================================================================================
Total params: 520,995
Trainable params: 520,995
Non-trainable params: 0
__________________________________________________________________________________________________
2019-10-29 20:54:07.009002: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-29 20:54:07.911330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
 |----------------------------------------| 0.0%  recon: 163.58 kl: 0.0 capacity (nats): 0.0 Epoch: 1/10 Loss: Tensor(""add_2:0"", shape=(), dtype=float32) SAMPLING FRAME 1
 |----------------------------------------| 0.1%  recon: 183.64 kl: 0.0 capacity (nats): 0.0 Epoch: 1/10 Loss: Tensor(""add_6:0"", shape=(), dtype=float32) SAMPLING FRAME 2
 |----------------------------------------| 0.3%  recon: 171.7 kl: 0.0 capacity (nats): 0.01 Epoch: 1/10 Loss: Tensor(""add_18:0"", shape=(), dtype=float32) SAMPLING FRAME 3
 |----------------------------------------| 0.6%  recon: 180.35 kl: 0.0 capacity (nats): 0.02 Epoch: 1/10 Loss: Tensor(""add_38:0"", shape=(), dtype=float32) SAMPLING FRAME 4
 |----------------------------------------| 1.1%  recon: 179.76 kl: 0.0 capacity (nats): 0.03 Epoch: 1/10 Loss: Tensor(""add_66:0"", shape=(), dtype=float32) SAMPLING FRAME 5
 |█---------------------------------------| 1.7%  recon: 182.14 kl: 0.0 capacity (nats): 0.04 Epoch: 1/10 Loss: Tensor(""add_102:0"", shape=(), dtype=float32) SAMPLING FRAME 6
 |█---------------------------------------| 2.4%  recon: 175.29 kl: 0.0 capacity (nats): 0.05 Epoch: 1/10 Loss: Tensor(""add_142:0"", shape=(), dtype=float32)2019-10-29 20:54:13.957278: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 1.18G (1263714304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
 |█---------------------------------------| 2.5%  recon: 182.22 kl: 0.0 capacity (nats): 0.05 Epoch: 1/10 Loss: Tensor(""add_146:0"", shape=(), dtype=float32) SAMPLING FRAME 7
 |█---------------------------------------| 2.7%  recon: 168.09 kl: 0.0 capacity (nats): 0.06 Epoch: 1/10 Loss: Tensor(""add_158:0"", shape=(), dtype=float32)2019-10-29 20:54:14.610518: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 120.52M (126371328 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-29 20:54:14.610906: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 120.52M (126371328 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
```
Notice that ""loss: "" prints something like Tensor(""add_146:0"", shape=(), dtype=float32) when I call train_on_batch. Previously this was just a scalar. 

**Describe the expected behavior**
I expect kl_divergence(X, X_pred) in my code to return a scalar, and no out of memory errors.

**Code to reproduce the issue**
``` bash
git clone https://github.com/alexbooth/Beta-VAE-Tensorflow-2.0.git  
cd Beta-VAE-Tensorflow-2.0  
python3 train.py --batch_size=512
```
Model + Loss
``` python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np
import tensorflow as tf

from tensorflow.keras import Model
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense
from tensorflow.keras.layers import Flatten, Reshape, Input
from tensorflow.keras.optimizers import Adam


def Conv(n_filters, filter_width, strides=2, activation=""relu"", name=None):
    return Conv2D(n_filters, filter_width, 
                  strides=strides, padding=""same"", activation=activation, name=name)


def Deconv(n_filters, filter_width, strides=2, activation=""relu"", name=None):
    return Conv2DTranspose(n_filters, filter_width, 
                  strides=strides, padding=""same"", activation=activation, name=name)


class Reparameterize(tf.keras.layers.Layer):
    """"""
    Custom layer.
     
    Reparameterization trick, sample random latent vectors Z from 
    the latent Gaussian distribution which has the following parameters 

    mean = Z_mu
    std = exp(0.5 * Z_logvar)
    """"""
    def call(self, inputs):
        Z_mu, Z_logvar = inputs
        epsilon = tf.random.normal(tf.shape(Z_mu))
        sigma = tf.math.exp(0.5 * Z_logvar)
        return Z_mu + sigma * epsilon


class BetaVAE:
    def __init__(self, input_shape, latent_dim=32, loss_type=""mse"", learning_rate=0.0005):
        self.latent_dim = latent_dim
        self.C = 0
        self.gamma = 100

        channels = input_shape[2]

        # create encoder
        encoder_input = Input(shape=input_shape)
        X = Conv(32, 4)(encoder_input)
        X = Conv(32, 4)(X)
        X = Conv(32, 4)(X)
        X = Conv(32, 4)(X)
        X = Flatten()(X)
        X = Dense(256, activation=""relu"")(X)
        X = Dense(256,  activation=""relu"")(X)
        Z_mu = Dense(self.latent_dim)(X)
        Z_logvar = Dense(self.latent_dim, activation=""relu"")(X)
        Z = Reparameterize()([Z_mu, Z_logvar])

        # create decoder
        output_activation = ""sigmoid"" if channels == 1 else None
        decoder_input = Input(shape=(self.latent_dim,))
        X = Dense(256,  activation=""relu"")(decoder_input)
        X = Dense(256,  activation=""relu"")(X)
        X = Dense(512,  activation=""relu"")(X)
        X = Reshape((4, 4, 32))(X)
        X = Deconv(32, 4)(X)
        X = Deconv(32, 4)(X)
        X = Deconv(32, 4)(X)
        decoder_output = Deconv(channels, 4, activation=output_activation)(X)

        # define vae losses
        def reconstruction_loss(X, X_pred):
            if loss_type == ""bce"":
                bce = tf.losses.BinaryCrossentropy() 
                return bce(X, X_pred) * np.prod(input_shape)
            elif loss_type == ""mse"":
                mse = tf.losses.MeanSquaredError()
                return mse(X, X_pred) * np.prod(input_shape)
            else:
                raise ValueError(""Unknown reconstruction loss type. Try 'bce' or 'mse'"")

        def kl_divergence(X, X_pred):
            self.C += (1/1440) # TODO use correct scalar
            self.C = min(self.C, 35) # TODO make variable
            kl = -0.5 * tf.reduce_mean(1 + Z_logvar - Z_mu**2 - tf.math.exp(Z_logvar))
            return self.gamma * tf.math.abs(kl - self.C)

        def loss(X, X_pred):
            return reconstruction_loss(X, X_pred) + kl_divergence(X, X_pred)

        # create models
        self.encoder = Model(encoder_input, [Z_mu, Z_logvar, Z])
        self.decoder = Model(decoder_input, decoder_output)
        self.vae = Model(encoder_input, self.decoder(Z))
        self.vae.compile(optimizer='adam', loss=loss, metrics=[reconstruction_loss, kl_divergence])

    def predict(self, inputs, mode=None):
        if mode == ""encode"":
            _, _, self.Z = self.encoder.predict(inputs)
            return self.Z
        if mode == ""decode"":
            return self.decoder.predict(inputs)
        if mode == None:
            return self.vae.predict(inputs) 
        raise ValueError(""Unsupported mode during call to model."") 
```"
33835,A bug in TF2.0 that prevents tf.int32 tensor to be placed on GPU (but tf.int16/64 or tf.float32 is fine),"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 'v2.0.0-rc2-26-g64c3d38' and '2.0.0' (GPU version)
- Python version: 3.x
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: Colab GPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Cannot put an int32 tensor on a GPU. But can put an int16/int64/float32 on a GPU.

**Describe the expected behavior**
Should be able to place an int32 tensor on a GPU.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

#####################################
with tf.device('GPU:0'):
&nbsp;&nbsp;&nbsp;&nbsp; var = tf.constant([1,2,3], dtype=tf.int32) #doesn't work
&nbsp;&nbsp;&nbsp;&nbsp; print(var.device) #wrongly puts on CPU
&nbsp;&nbsp;&nbsp;&nbsp; var = tf.constant([1,2,3], dtype=tf.int16) #works fine
&nbsp;&nbsp;&nbsp;&nbsp; print(var.device) #correctly puts on GPU

prints the following:
/job:localhost/replica:0/task:0/device:CPU:0
/job:localhost/replica:0/task:0/device:GPU:0
#####################################
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33834,Embedding Layer's mask operation with LSTM Layer Gives Wrong Results When Using a GPU,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0 GPU version
- Python version: 3.x
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When using a GPU, the mask operation of the embedding layer (with LSTM layer) gives wrong result. With mask_zero = True, anytime there is an input of 0 in one of the time steps, the output should be same as the previous time step's output. Which is what it does with a CPU. However, using a GPU, it just gives a zero output (which is not the expected behavior).

**Describe the expected behavior**
With mask_zero = True, anytime there is an input of 0 in one of the time steps, the output should be same as the previous time step's output. 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

########################################
import tensorflow as tf
tf.random.set_seed(0)

inputs = tf.keras.layers.Input(shape=(None,), dtype='int32')
x = tf.keras.layers.Embedding(input_dim=10, output_dim=3, mask_zero=True)(inputs)
outputs = tf.keras.layers.LSTM(2, return_sequences=True)(x)

model = tf.keras.Model(inputs, outputs)
padded_inputs = tf.constant([[1,3,0,0]])
print(model(padded_inputs))

It prints the following:
tf.Tensor(
[[[0.00727878 0.00290126]
  [0.00217528 0.00565582]
  [0.         0.        ]
  [0.         0.        ]]] 

instead of 

tf.Tensor(
[[[0.00727878 0.00290126]
  [0.00217528 0.00565582]
  [0.00217528 0.00565582]
  [0.00217528 0.00565582]]] (which is what it is supposed to print). 
Note that when only using a CPU, it gives the correct result.
########################################


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33833,Config value opt is not defined in any .rc file,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution windows 10:
- TensorFlow installed from source:
- Python version 3.7.5:
- Installed using virtualenv? pip? conda?:


- Bazel version 0.24.1:
- Visual studio 2019




**Describe the problem**
it always report CUSTOMBUILD : error : Config value opt is not defined in any .rc file.
I did use -c opt instead of -config=opt
I attached cmake file and building information below


INFO: Options provided by the client:
10>  Inherited 'common' options: --isatty=0 --terminal_columns=80
10>INFO: Options provided by the client:
10>  'build' options: --python_path=C:/Users/Lin.Xiang/AppData/Local/Microsoft/WindowsApps/python.exe
10>INFO: Reading rc options for 'build' from c:\users\lin.xiang\fast\build\external\tensorflow\src\tensorflow_download\.bazelrc:
10>  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
10>CUSTOMBUILD : error : Config value opt is not defined in any .rc file
10>Done building project ""tensorflow_CPU.vcxproj"" -- FAILED.

"
33832,How can I convert outputs or tflite tensors to swift multi-dimensional arrays to be able to perform mathematical computations on them?,"I am running posenet on swift with tflite.
The model has multiple output arrays with the following dimensions:
1x14x14x17, 1x14x14x34, 1x14x14x32, 1x14x14x32

How can I convert outputs or tflite tensors to swift ios multi-dimensional arrays to be able to perform mathematical computations on them?

[There was a similar question for java](https://github.com/tensorflow/tensorflow/issues/25841)"
33831,TF2.0.0 Error on InceptionV3,"Last Edit: This is too hard to reproduce.  It relies on a custom 'pylib' module.  Closing the issue.

I have updated this post to have a more user-friendly piece of code.  You need to run it with ipython or paste it in to a cell on jupyter notebook because the first three lines are bash script executed using the (!) magic command.
I have seen this code execute properly with Python 3.6 running on a CPU.
I can't get it to run on Python 3.7.  Not sure if it has anything to do with my GPU.
Sorry, I can't be more certain about this.
[code_inception.txt](https://github.com/tensorflow/tensorflow/files/3787021/code_inception.txt)

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7 conda environment
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: CUDA 10/ cuDNN 7.6.4
- GPU model and memory: NVidia RTX 2080 TI and RTX 2080 MaxQ

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Error produced on python 3.7 on GPU (not on python 3.6 TF2.0.0 on a CPU):

      1/Unknown - 0s 71ms/step
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-6-992b5c7b95cf> in <module>
      2 # BUMP EPOCHS to 50 for true training
      3 EPOCHS = 1  # 50
----> 4 model.fit(dataset, epochs=EPOCHS)

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    783         max_queue_size=max_queue_size,
    784         workers=workers,
--> 785         use_multiprocessing=use_multiprocessing)
    786 
    787   def evaluate(self,

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    335                 mode=ModeKeys.TRAIN,
    336                 training_context=training_context,
--> 337                 total_epochs=epochs)
    338             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    339 

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    125         step=step, mode=mode, size=current_batch_size) as batch_logs:
    126       try:
--> 127         batch_outs = execution_function(iterator)
    128       except (StopIteration, errors.OutOfRangeError):
    129         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
     84     # `numpy` translates Tensors to values in Eager mode.
     85     return nest.map_structure(_non_none_constant_value,
---> 86                               distributed_function(input_fn))
     87 
     88   return execution_function

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    613       # This is the first call of __call__, so we have to initialize.
    614       initializers = []
--> 615       self._initialize(args, kwds, add_initializers_to=initializers)
    616     finally:
    617       # At this point we know that the initialization is complete (or less

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    495     self._concrete_stateful_fn = (
    496         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 497             *args, **kwds))
    498 
    499     def invalid_creator_scope(*unused_args, **unused_kwds):

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2363       args, kwargs = None, None
   2364     with self._lock:
-> 2365       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2366     return graph_function
   2367 

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2671 
   2672       self._function_cache.missed.add(call_context_key)
-> 2673       graph_function = self._create_graph_function(args, kwargs)
   2674       self._function_cache.primary[cache_key] = graph_function
   2675       return graph_function, args, kwargs

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2561             arg_names=arg_names,
   2562             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2563             capture_by_value=self._capture_by_value),
   2564         self._function_attributes,
   2565         # Tell the ConcreteFunction to clean up its graph once it goes out of

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    956                                           converted_func)
    957 
--> 958       func_outputs = python_func(*func_args, **func_kwargs)
    959 
    960       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    438         # the function a weak reference to itself to avoid a reference cycle.
--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    440     weak_wrapped_fn = weakref.ref(wrapped_fn)
    441 

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in distributed_function(input_iterator)
     71     strategy = distribution_strategy_context.get_strategy()
     72     outputs = strategy.experimental_run_v2(
---> 73         per_replica_function, args=(x, y, sample_weights))
     74     # Out of PerReplica outputs reduce or pick values to return.
     75     all_outputs = dist_utils.unwrap_output_dict(

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py in experimental_run_v2(self, fn, args, kwargs)
    761       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),
    762                                 convert_by_default=False)
--> 763       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    764 
    765   def reduce(self, reduce_op, value, axis):

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)
   1817       kwargs = {}
   1818     with self._container_strategy().scope():
-> 1819       return self._call_for_each_replica(fn, args, kwargs)
   1820 
   1821   def _call_for_each_replica(self, fn, args, kwargs):

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)
   2162         self._container_strategy(),
   2163         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):
-> 2164       return fn(*args, **kwargs)
   2165 
   2166   def _reduce_to(self, reduce_op, value, destinations):

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    290   def wrapper(*args, **kwargs):
    291     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
--> 292       return func(*args, **kwargs)
    293 
    294   if inspect.isfunction(func) or inspect.ismethod(func):

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics)
    262       y,
    263       sample_weights=sample_weights,
--> 264       output_loss_metrics=model._output_loss_metrics)
    265 
    266   if reset_metrics:

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics)
    310           sample_weights=sample_weights,
    311           training=True,
--> 312           output_loss_metrics=output_loss_metrics))
    313   if not isinstance(outs, list):
    314     outs = [outs]

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py in _process_single_batch(model, inputs, targets, output_loss_metrics, sample_weights, training)
    251               output_loss_metrics=output_loss_metrics,
    252               sample_weights=sample_weights,
--> 253               training=training))
    254       if total_loss is None:
    255         raise ValueError('The model cannot be run '

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py in _model_loss(model, inputs, targets, output_loss_metrics, sample_weights, training)
    125     inputs = nest.map_structure(ops.convert_to_tensor, inputs)
    126 
--> 127   outs = model(inputs, **kwargs)
    128   outs = nest.flatten(outs)
    129 

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    776                     outputs = base_layer_utils.mark_as_return(outputs, acd)
    777                 else:
--> 778                   outputs = call_fn(cast_inputs, *args, **kwargs)
    779 
    780             except errors.OperatorNotAllowedInGraphError as e:

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in call(self, inputs, training, mask)
    715     return self._run_internal_graph(
    716         inputs, training=training, mask=mask,
--> 717         convert_kwargs_to_constants=base_layer_utils.call_context().saving)
    718 
    719   def compute_output_shape(self, input_shape):

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants)
    871 
    872           # Compute outputs.
--> 873           output_tensors = layer(computed_tensors, **kwargs)
    874 
    875           # Update tensor_dict.

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    776                     outputs = base_layer_utils.mark_as_return(outputs, acd)
    777                 else:
--> 778                   outputs = call_fn(cast_inputs, *args, **kwargs)
    779 
    780             except errors.OperatorNotAllowedInGraphError as e:

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in call(self, inputs, training, mask)
    715     return self._run_internal_graph(
    716         inputs, training=training, mask=mask,
--> 717         convert_kwargs_to_constants=base_layer_utils.call_context().saving)
    718 
    719   def compute_output_shape(self, input_shape):

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants)
    871 
    872           # Compute outputs.
--> 873           output_tensors = layer(computed_tensors, **kwargs)
    874 
    875           # Update tensor_dict.

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    776                     outputs = base_layer_utils.mark_as_return(outputs, acd)
    777                 else:
--> 778                   outputs = call_fn(cast_inputs, *args, **kwargs)
    779 
    780             except errors.OperatorNotAllowedInGraphError as e:

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py in call(self, inputs)
    191     # behavior.
    192     call_input_shape = inputs.get_shape()
--> 193     call_input_channel = self._get_input_channel(call_input_shape)
    194     if call_input_channel != self._build_input_channel:
    195       raise ValueError(

~/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py in _get_input_channel(self, input_shape)
    299     channel_axis = self._get_channel_axis()
    300     if input_shape.dims[channel_axis].value is None:
--> 301       raise ValueError('The channel dimension of the inputs '
    302                        'should be defined. Found `None`.')
    303     return int(input_shape[channel_axis])

ValueError: The channel dimension of the inputs should be defined. Found `None`.

**Describe the expected behavior**
No error.  It trains.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
See code_inception.txt attached

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Nil


"
33830,Typo in TensorFlow Core Tutorials - Image classification,"
## URL(s) with the issue:
https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb

## Description of issue (what needs changing):
Typo

### Clear description
```
Create the model
The model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 512 units on top of it thatr is activated by a relu activation function. 
```
In Create the model section,
```thatr``` should be ```that```

```
Create the model
The model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 512 units on top of it that is activated by a relu activation function. 
```
### Submit a pull request?
"
33829,Train in Keras with Stateless CuDNN GRU and infer using tensorflow with stateful CuDNN GRU,"Hi

I am facing a problem with using Stateful and Steteless CuDNN GRU

I trained my model in Keras with CuDNN GRU's using let's say 1000 time steps and stateful=False. 

During inference, to keep the model real-time, I changed the time_steps to 1, and stateful=true to load the model and it's weights. I converted this model to tensorflow protobuf using convert_variables_to_constants() function to freeze the graph and write_graph() to write it to a protobuf file.

The problem I am facing currently is that I am getting same results whether or not stateful = True or False during inference. which means I am missing something while converting keras model to tensorflow model. Is there any special consideration needed with the conversion process?

While running tensorflow session, along with the output, do I need to get states of all the CuDNN GRU layers and pass in these states with the next input? If yes, how can I get these states from the graph. It's not clear from the nodes of cudnn layer, which of it might contain state information. 

Or is there something very fundamental I am missing here? Any help is very much appreciated. 

Tensorflow version : 1.14.0
Keras version : 2.2.4

Thanks

"
33828,"Questions about the example ""Neural machine translation with attention""","There is one questions when I learned the  example ""Neural machine translation with attention""(https://www.tensorflow.org/tutorials/text/nmt_with_attention).
       Why the attention weight is calculated by encoder_output and encoder_hiiden and context vector is contacted with decoder_embedding.  In my opinion, the attention weight should be calculated by encoder_output and every single hiiden of decoder_output, and context vector should be contacted with decoder_output. Maybe I have not understood the seq2seq with attention completely?
"
33827,lowerbound not implemented (from searchsorted),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (or github SHA if from source): tensorflow           2.0.0


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: . Here is a list of operators for which you will need custom implementations: LowerBound.
Traceback (most recent call last):
  File ""/home/francis/dev/projects/cognisance/tensorflow/venv37/bin/toco_from_protos"", line 8, in 
    sys.exit(main())
  File ""/home/francis/dev/projects/cognisance/tensorflow/venv37/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/francis/dev/projects/cognisance/tensorflow/venv37/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/francis/dev/projects/cognisance/tensorflow/venv37/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/francis/dev/projects/cognisance/tensorflow/venv37/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/francis/dev/projects/cognisance/tensorflow/venv37/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)
```
"
33826,Calling train in SavedModelEstimator gives ValueError: At least two variables have the same name,"**System information**
- TensorFlow version (use command below): 1.12.0-rc2-3-ga6d8ffae09 1.12.0
- Python version: Python 3.6.9

**Describe the current behavior**

- Defining a model using tensorflow.keras
- Converting the compiled model to estimator
- Training estimator using train_and_evaluate
- Export all saved models for  ""TRAIN"", ""EVAL"" and ""PREDICT""

When I create a SavedModelEstimator from the previous exported data, I am able to call evaluate and predict successfully. However, if I call the method train I get an error ""ValueError: At least two variables have the same name: dense_1/bias/Adam)"".

**I can warm-start sucessfully if I change the line in _get_grouped_variables to:** https://github.com/tensorflow/tensorflow/blob/9c52e7ce02532c22a79ae7139f37c663add4c90f/tensorflow/python/training/warm_starting_util.py#L349

`ops.GraphKeys.TRAINABLE_VARIABLES, scope=v)`

**Code to reproduce the issue**

```python
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.estimator import model_to_estimator
import keras.backend as K
import numpy as np
import os


def model_fn():
    # 10 features
    input_layer = Input(shape=(10,), name=""inputs"", dtype=tf.float32)
    dense_1 = Dense(units=10, activation=""relu"", name=""dense_1"")(input_layer)
    dense_2 = Dense(units=1, activation=""linear"", name=""outputs"",
                    dtype=tf.float32)(dense_1)
    model = Model(inputs=input_layer, outputs=dense_2)
    model.compile(optimizer=tf.train.AdamOptimizer(),
                  loss=""mse"")
    return model


def synthetic_input_fn(num_examples, num_features):
    # dummy data
    return tf.data.Dataset.from_tensor_slices(({""inputs"": np.random.random((num_examples, num_features))}, np.random.randint(10, size=num_examples))) \
        .shuffle(512) \
        .batch(32) \
        .repeat(10)


if __name__ == ""__main__"":

    MODEL_DIR = ""./model""
    SAVED_MODEL_DIR = os.path.join(MODEL_DIR, ""saved"")

    def cust_train_input_fn():
        return synthetic_input_fn(1000, 10)

    def cust_eval_input_fn():
        return synthetic_input_fn(100, 10)

    tf.logging.set_verbosity(tf.logging.INFO)

    # define model and convert to estimator
    model = model_fn()
    estimator = model_to_estimator(
        keras_model=model,
        model_dir=MODEL_DIR
    )

    train_spec = tf.estimator.TrainSpec(input_fn=cust_train_input_fn)
    eval_spec = tf.estimator.EvalSpec(input_fn=cust_eval_input_fn)

    # train and evaluate dummy model
    tf.estimator.train_and_evaluate(
        estimator=estimator,
        train_spec=train_spec,
        eval_spec=eval_spec
    )

    # export all modes
    feature_spec = {""inputs"": tf.placeholder(tf.float64, (None, 10))}

    label_spec = tf.placeholder(dtype=tf.int64)

    serving_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_spec)
    training_fn = tf.contrib.estimator.build_raw_supervised_input_receiver_fn(feature_spec, label_spec)

    rcrv_fn_map = {
        tf.estimator.ModeKeys.TRAIN: training_fn,
        tf.estimator.ModeKeys.EVAL: training_fn,
        tf.estimator.ModeKeys.PREDICT: serving_fn
    }

    tf.contrib.estimator.export_all_saved_models(
        estimator,
        export_dir_base=SAVED_MODEL_DIR,
        input_receiver_fn_map=rcrv_fn_map
    )

    tf.keras.backend.clear_session()

    saved_estimator = tf.contrib.estimator.SavedModelEstimator(os.path.join(SAVED_MODEL_DIR, os.listdir(SAVED_MODEL_DIR)[0]))
    saved_estimator.train(cust_train_input_fn)
```


**Other info / logs**
Using TensorFlow backend.
INFO:tensorflow:Using default config.
INFO:tensorflow:Using the Keras model provided.
2019-10-29 14:26:59.280066: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
INFO:tensorflow:Using config: {'_model_dir': './model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x62b766be0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./model/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})
INFO:tensorflow:Warm-starting from: ('./model/keras/keras_model.ckpt',)
INFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged
INFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged
INFO:tensorflow:Warm-starting variable: outputs/kernel; prev_var_name: Unchanged
INFO:tensorflow:Warm-starting variable: outputs/bias; prev_var_name: Unchanged
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into ./model/model.ckpt.
INFO:tensorflow:loss = 32.57418, step = 1
INFO:tensorflow:global_step/sec: 1201.8
INFO:tensorflow:loss = 24.11268, step = 101 (0.083 sec)
INFO:tensorflow:global_step/sec: 1799.1
INFO:tensorflow:loss = 12.514932, step = 201 (0.056 sec)
INFO:tensorflow:global_step/sec: 1810.48
INFO:tensorflow:loss = 9.915621, step = 301 (0.055 sec)
INFO:tensorflow:Saving checkpoints for 320 into ./model/model.ckpt.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2019-10-29-14:27:00
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from ./model/model.ckpt-320
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
INFO:tensorflow:Finished evaluation at 2019-10-29-14:27:00
INFO:tensorflow:Saving dict for global step 320: global_step = 320, loss = 8.093195
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 320: ./model/model.ckpt-320
INFO:tensorflow:Loss for final step: 10.114872.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Signatures INCLUDED in export for Classify: None
INFO:tensorflow:Signatures INCLUDED in export for Regress: None
INFO:tensorflow:Signatures INCLUDED in export for Predict: None
INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']
INFO:tensorflow:Signatures INCLUDED in export for Eval: None
WARNING:tensorflow:Export includes no default signature!
INFO:tensorflow:Restoring parameters from ./model/model.ckpt-320
WARNING:tensorflow:From /anaconda3/envs/tf-abalone/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.
Instructions for updating:
Pass your op to the equivalent parameter main_op instead.
INFO:tensorflow:Assets added to graph.
INFO:tensorflow:No assets to write.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Signatures INCLUDED in export for Classify: None
INFO:tensorflow:Signatures INCLUDED in export for Regress: None
INFO:tensorflow:Signatures INCLUDED in export for Predict: None
INFO:tensorflow:Signatures INCLUDED in export for Train: None
INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']
WARNING:tensorflow:Export includes no default signature!
INFO:tensorflow:Restoring parameters from ./model/model.ckpt-320
WARNING:tensorflow:From /anaconda3/envs/tf-abalone/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1046: calling SavedModelBuilder.add_meta_graph (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.
Instructions for updating:
Pass your op to the equivalent parameter main_op instead.
INFO:tensorflow:Assets added to graph.
INFO:tensorflow:No assets to write.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Signatures INCLUDED in export for Classify: None
INFO:tensorflow:Signatures INCLUDED in export for Regress: None
INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']
INFO:tensorflow:Signatures INCLUDED in export for Train: None
INFO:tensorflow:Signatures INCLUDED in export for Eval: None
INFO:tensorflow:Restoring parameters from ./model/model.ckpt-320
INFO:tensorflow:Assets added to graph.
INFO:tensorflow:No assets to write.
INFO:tensorflow:SavedModel written to: ./model/saved/temp-b'1572359223'/saved_model.pb
INFO:tensorflow:Using default config.
WARNING:tensorflow:Using temporary folder as model directory: /var/folders/8s/tjdwdq296s5fdljp3p6jd9z40000gn/T/tmp7c0vhh49
INFO:tensorflow:Using config: {'_model_dir': '/var/folders/8s/tjdwdq296s5fdljp3p6jd9z40000gn/T/tmp7c0vhh49', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c316e6208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Checking available modes for SavedModelEstimator.
INFO:tensorflow:Available modes for Estimator: ['train', 'eval', 'infer']
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./model/saved/1572359223/variables/variables', vars_to_warm_start=['dense_1/bias', 'dense_1/bias/Adam', 'dense_1/bias/Adam_1', 'dense_1/kernel', 'dense_1/kernel/Adam', 'dense_1/kernel/Adam_1', 'global_step', 'outputs/bias', 'outputs/bias/Adam', 'outputs/bias/Adam_1', 'outputs/kernel', 'outputs/kernel/Adam', 'outputs/kernel/Adam_1', 'training/TFOptimizer/beta1_power', 'training/TFOptimizer/beta2_power'], var_name_to_vocab_info={}, var_name_to_prev_var_name={})
INFO:tensorflow:Warm-starting from: ('./model/saved/1572359223/variables/variables',)
INFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged
INFO:tensorflow:Warm-starting variable: dense_1/bias/Adam; prev_var_name: Unchanged
Traceback (most recent call last):
  File ""main.py"", line 83, in <module>
    saved_estimator.train(cust_train_input_fn)
  File ""/anaconda3/envs/tf-abalone/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 354, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/anaconda3/envs/tf-abalone/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1207, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/anaconda3/envs/tf-abalone/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1241, in _train_model_default
    saving_listeners)
  File ""/anaconda3/envs/tf-abalone/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1360, in _train_with_estimator_spec
    warm_starting_util.warm_start(*self._warm_start_settings)
  File ""/anaconda3/envs/tf-abalone/lib/python3.6/site-packages/tensorflow/python/training/warm_starting_util.py"", line 463, in warm_start
    _warm_start_var(variable, ckpt_to_initialize_from, prev_var_name)
  File ""/anaconda3/envs/tf-abalone/lib/python3.6/site-packages/tensorflow/python/training/warm_starting_util.py"", line 170, in _warm_start_var
    current_var_name = _infer_var_name(var)
  File ""/anaconda3/envs/tf-abalone/lib/python3.6/site-packages/tensorflow/python/training/warm_starting_util.py"", line 142, in _infer_var_name
    name_to_var_dict = saver.BaseSaverBuilder.OpListToDict(var)
  File ""/anaconda3/envs/tf-abalone/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 572, in OpListToDict
    name)
ValueError: At least two variables have the same name: dense_1/bias/Adam"
33825,Using metric SparseTopKCategoricalAccuracy on an RNN results in rank mismatch,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes. The code is given below to reproduce the issue.**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
**Linux Ubuntu 18.04**

- TensorFlow installed from (source or binary):
**Binary**, using pip

- TensorFlow version:
**v2.0.0-rc2-26-g64c3d38 2.0.0**

- Python version:
**3.6**

- CUDA/cuDNN version:
**10.1 / 7.6.2**

- GPU model and memory:
**GeForce GTX 1070 / 8GB**

**Describe the current behavior**

When I compile an RNN model with the metric `SparseTopKCategoricalAccuracy()`, the following error results. No error occurs if I use `SparseCategoricalAccuracy()` instead.

```
Traceback (most recent call last):
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1610, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 2 but is rank 3 for 'metrics/sparse_top_k_categorical_accuracy/in_top_k/InTopKV2' (op: 'InTopKV2') with input shapes: [?,?,10], [?,?], [].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""report.py"", line 12, in <module>
    metrics=[tf.keras.metrics.SparseTopKCategoricalAccuracy()])
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 366, in compile
    masks=self._prepare_output_masks())
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2063, in _handle_metrics
    target, output, output_mask))
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2014, in _handle_per_output_metrics
    metric_fn, y_true, y_pred, weights=weights, mask=mask)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py"", line 1067, in call_metric_function
    return metric_fn(y_true, y_pred, sample_weight=weights)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py"", line 193, in __call__
    replica_local_fn, *args, **kwargs)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py"", line 1135, in call_replica_local_fn
    return fn(*args, **kwargs)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py"", line 176, in replica_local_fn
    update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py"", line 75, in decorated
    update_op = update_state_fn(*args, **kwargs)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py"", line 581, in update_state
    matches = self._fn(y_true, y_pred, **self._fn_kwargs)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py"", line 2805, in sparse_top_k_categorical_accuracy
    nn.in_top_k(y_pred, math_ops.cast(y_true, 'int32'), k), K.floatx())
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 4843, in in_top_k
    return gen_nn_ops.in_top_kv2(predictions, targets, k, name=name)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 5043, in in_top_kv2
    ""InTopKV2"", predictions=predictions, targets=targets, k=k, name=name)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper
    op_def=op_def)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 548, in create_op
    compute_device)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal
    op_def=op_def)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1773, in __init__
    control_input_ops)
  File ""/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1613, in _create_c_op
    raise ValueError(str(e))
ValueError: Shape must be rank 2 but is rank 3 for 'metrics/sparse_top_k_categorical_accuracy/in_top_k/InTopKV2' (op: 'InTopKV2') with input shapes: [?,?,10], [?,?], [].
```

**Describe the expected behavior**

I expect no error. I suppose `SparseTopKCategoricalAccuracy()` can be used in exactly the same way as `SparseCategoricalAccuracy()`.

**Code to reproduce the issue**

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers

model = tf.keras.Sequential([
    layers.Embedding(input_dim=1000, output_dim=64),
    layers.LSTM(128, return_sequences=True),
    layers.Dense(10, activation='softmax')])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=[tf.keras.metrics.SparseTopKCategoricalAccuracy()])

data = np.random.randint(0, 1000, (32, 10))  # batch_size=32, seq_length=10
labels = np.random.randint(0, 10, (32, 10))

model.fit(data, labels, epochs=1, batch_size=32)
```

**Other info / logs**

I use this custom metric to get around the problem:

```python
class InTopK(tf.keras.metrics.Mean):
    def __init__(self, k, name='in_top_k', **kwargs):
        super(InTopK, self).__init__(name=name, **kwargs)
        self._k = k

    def update_state(self, y_true, y_pred, sample_weight=None):
        matches = tf.nn.in_top_k(
            # flatten tensors
            tf.reshape(tf.cast(y_true, tf.int32), [-1]),
            tf.reshape(y_pred, [-1, y_pred.shape[-1]]),
            k=self._k)

        return super(InTopK, self).update_state(
            matches, sample_weight=sample_weight)
```
"
33824,code and tutorial description mismatch on CNN,"## URL(s) with the issue:
https://www.tensorflow.org/tutorials/images/cnn
## Description of issue (what needs changing):
Two mismatchs between output shape on model summary and tutorial:
1""To complete our model, you will feed the last output tensor from the convolutional base (of shape (3, 3, 64))""
should be changed to
To complete our model, you will feed the last output tensor from the convolutional base (of shape (4, 4, 64))
  
2.""As you can see, our (3, 3, 64) outputs were flattened into vectors of shape (576) before going through two Dense layers.""
This should be changed to 
""As you can see, our (4, 4, 64) outputs were flattened into vectors of shape (1024) before going through two Dense layers.




"
33823,Missing TF 2.0 low-level API guide,"## URL(s) with the issue:

https://www.tensorflow.org/guide

## Description of issue (what needs changing):

In the TF1.* docs, a very helpful low-level API guide was provided which helped those of us interested in using TensorFlow for applications other than NN style models.  This appears to be entirely missing from the TF 2.0 documentation.  Is this omission on purpose, and if so how do we teach people how to use the low-level API?

Thanks,

Chris


"
33822,tf.contrib.rnn.OutputProjectionWrapper,"hi,
In tf 1.14.0,there is no new API for the function,
could you help me ?I want translate the Op in tflite .
thx"
33820,normalization in cosine similarity,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/losses/cosine_similarity
https://www.tensorflow.org/api_docs/python/tf/keras/losses/CosineSimilarity

## Description of issue (what needs changing):
The documentation for the cosine similarity does not state whether `y_true` and `y_pred`
are expected to be normalized vectors. The provided equation `loss = -sum(y_true * y_pred)`
suggests the need to be, but looking at the source, they are normalized as part of the computation.
```
y_true = nn.l2_normalize(y_true, axis=axis)
y_pred = nn.l2_normalize(y_pred, axis=axis)
return -math_ops.reduce_sum(y_true * y_pred, axis=axis)
```
As a special case, the doc does not state what happens in the case of either being zero.

(Also, isn't the above implementation suboptimal in terms of speed, as each element is divided by 
the norm, instead of simply dividing the result once?)
"
33819,get_default_graph,
33818,KMeans module not found in TensorFlow 2,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac 10.13.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: /
- TensorFlow installed from (source or binary): pip package manager
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.4
- Bazel version (if compiling from source): /
- GCC/Compiler version (if compiling from source): /
- CUDA/cuDNN version: /
- GPU model and memory: /

**Describe the current behavior**
I am following this TensorFlow documentation https://www.tensorflow.org/api_docs/python/tf/compat/v1/estimator/experimental/KMeans

When running the example I am getting the following error message:
```
AttributeError: module 'tensorflow_estimator.python.estimator.api._v2.estimator.experimental' has no attribute 'KMeans'
```

**Describe the expected behavior**
I expect a example which is possible to execute

**Code to reproduce the issue**
```
import numpy as np
import tensorflow as tf

num_points = 100
dimensions = 2
points = np.random.uniform(0, 1000, [num_points, dimensions])

def input_fn():
  return tf.train.limit_epochs(
      tf.convert_to_tensor(points, dtype=tf.float32), num_epochs=1)

num_clusters = 5
kmeans = tf.estimator.experimental.KMeans(
    num_clusters=num_clusters, use_mini_batch=False)

# train
num_iterations = 10
previous_centers = None
for _ in xrange(num_iterations):
  kmeans.train(input_fn)
  cluster_centers = kmeans.cluster_centers()
  if previous_centers is not None:
    print 'delta:', cluster_centers - previous_centers
  previous_centers = cluster_centers
  print 'score:', kmeans.score(input_fn)
print 'cluster centers:', cluster_centers

# map the input points to their clusters
cluster_indices = list(kmeans.predict_cluster_index(input_fn))
for i, point in enumerate(points):
  cluster_index = cluster_indices[i]
  center = cluster_centers[cluster_index]
  print 'point:', point, 'is in cluster', cluster_index, 'centered at', center
```

**Other info / logs**
I also tried to run it with the nightly version of TensorFlow 2, but I get the same results
"
33817,"Failure to install via 'pipenv install' with just ""tensorflow==2.0.0"" in requirements.txt","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.0.0
- Python version: 3.6.6
- Installed using virtualenv? pip? conda?: 'pipenv install' in a pyenv
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: not sure 



**Describe the problem**

I'm sorry if this is the wrong place to post this but I'm having trouble installing Tensorflow 2.0.0. I posted this problem on Super User [here](https://superuser.com/questions/1496530/difficulty-installing-tensorflow-using-requirements-txt-and-pipenv-install?noredirect=1#) but I'm not sure if that was the best place.

I have managed to install Tensorflow on my computer but I'm working on a [shared project](https://gitlab.com/neilwarrack/spinformation) and we want it to be installed using the 'pipenv install' command along with a `requirements.txt` file. If I have a one line requirements.txt file that looks like this: `tensorflow==2.0.0`, then I see a lot of python traceback output which I have attached here (and can be found in the [Super User question I posted](https://superuser.com/questions/1496530/difficulty-installing-tensorflow-using-requirements-txt-and-pipenv-install?noredirect=1#))
[tensor_pipenv.log](https://github.com/tensorflow/tensorflow/files/3782673/tensor_pipenv.log)

I have the following possibly helpful versions/locations of things:
> $ which pip
> /home/nw/.pyenv/shims/pip
> $ which pipenv
> home/nw/.local/bin/pipenv
> $ which python
> /home/nw/.pyenv/shims/python
> $ python --version
> 3.6.6
> $ pip --version
> pip 19.3.1 from /usr/local/lib/python3.5/dist-packages/pip (python 3.5)

I see the same output if I try this with [our full requirements.txt](https://gitlab.com/neilwarrack/spinformation/blob/master/requirements.txt) file: 
[requirements_orig.txt](https://github.com/tensorflow/tensorflow/files/3782698/requirements_orig.txt)
"
33815,"tensorflow1.14.0 , cuda 10, cudnn 7.4 , bazel 0.25, shell cmd：bazel build --config=opt --config=cuda //tensorflow:libtensorflow_cc.so ","/home/work/.cache/bazel/_bazel_work/4fa4430cecf16c459ae4d856e8ea7fba/external/zlib_archive/BUILD.bazel:5:1: undeclared inclusion(s) in rule '@zlib_archive//:zlib':
this rule is missing dependency declarations for the following files included by 'external/zlib_archive/compress.c':

'/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/stdc-predef.h'
  '/opt/compiler/gcc-4.8.2/lib/gcc/x86_64-baidu-linux-gnu/4.8.2/include/stddef.h'
  '/opt/compiler/gcc-4.8.2/lib/gcc/x86_64-baidu-linux-gnu/4.8.2/include-fixed/limits.h'
  '/opt/compiler/gcc-4.8.2/lib/gcc/x86_64-baidu-linux-gnu/4.8.2/include-fixed/syslimits.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/limits.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/features.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/sys/cdefs.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/wordsize.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/gnu/stubs.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/gnu/stubs-64.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/posix1_lim.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/local_lim.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/linux/limits.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/posix2_lim.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/sys/types.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/types.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/typesizes.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/time.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/endian.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/endian.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/byteswap.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/byteswap-16.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/sys/select.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/select.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/sigset.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/time.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/select2.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/sys/sysmacros.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/pthreadtypes.h'
  '/opt/compiler/gcc-4.8.2/lib/gcc/x86_64-baidu-linux-gnu/4.8.2/include/stdarg.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/unistd.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/posix_opt.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/environments.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/confname.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/getopt.h'
  '/opt/compiler/gcc-4.8.2/x86_64-baidu-linux-gnu/sys-root/include/bits/unistd.h'
Target //tensorflow:libtensorflow_cc.so failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 0.572s, Critical Path: 0.11s
INFO: 0 processes.
FAILED: Build did NOT complete successfully"
33814,Profile contains events with truncated names,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.4
- TensorFlow installed from (source or binary): Docker container
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.6.8
- CUDA/cuDNN version: 10.0
- GPU model and memory: K80

**Describe the current behavior**

When gathering a trace (via the supposedly only supported in TF2 method) the resulting trace file shows incomplete GPU op names. Validated in TensorBoard and deserializing the Protobuf message.
Examples:
```
GpuDevice>, long)
GpuDevice>, int)
Dimension<3>, unsigned int*)
reduced_divisor)
```

**Describe the expected behavior**

Trace shows complete function names (at least) and signatures (optional) or even better: Layers to which those activities/events belong.

**Code to reproduce the issue**

```
import datetime
import os
import tensorflow as tf
import tensorflow_datasets as tfds


def preprocess_for_mnist(image, label):
    image = tf.cast(image, tf.float32) / 255.0
    return image, label


datasets, info = tfds.load(name='mnist',
                           with_info=True,
                           as_supervised=True,
                           shuffle_files=False)

strategy = tf.distribute.OneDeviceStrategy(device='/gpu:0')

train_dataset = datasets['train'].map(preprocess_for_mnist).batch(32)

log_dir = os.path.join(os.path.expanduser('~/tf_logs'),
                       datetime.datetime.now().strftime(""%Y%m%d-%H%M%S""))

with strategy.scope():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32,
                               3,
                               activation='relu',
                               input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(10, activation='softmax')
    ])

    callbacks = [
        tf.keras.callbacks.TensorBoard(log_dir=log_dir,
                                       histogram_freq=0,
                                       profile_batch=2)
    ]

    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=tf.keras.optimizers.Adam(),
                  metrics=['accuracy'])
    model.fit(train_dataset, epochs=2, steps_per_epoch=10, callbacks=callbacks)
```

**Other info / logs**

Traces generated: [train.zip](https://github.com/tensorflow/tensorflow/files/3782526/train.zip)

"
33813,the relationship among optimize_for_inference.py quantize_graph.py graph_transforms,"Is graph_transforms  tool the newest tool to optimize and quantize for pb.
when I find tf < 1.11,has quantize_graph.py."
33811,"Got ""Data adapters should be mutually exclusive for handling inputs. Found multiple adapters to handle"" error when calling `model.fit` with ImageDataGenerator","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 aarch64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below) 2.0.0
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.29.0
- GCC/Compiler version (if compiling from source): 7.4
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
When fitting a model with ImageDataGenerator, it raises this error ""Data adapters should be mutually exclusive for handling inputs. Found multiple adapters 'GeneratorDataAdapter', 'KerasSequenceAdapter' to handle"". 

**Describe the expected behavior**
1. Log warning message if multiple data adapters found, instead of raising an error
2. Use the first available data adapter

**Code to reproduce the issue**
Please refer to link below:
https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l05c02_dogs_vs_cats_with_augmentation.ipynb

I connected to my local jupyter instance with Colab UI.

```python
BATCH_SIZE = 100
IMG_SHAPE  = 150

image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)
train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,
                                               directory=train_dir,
                                               shuffle=True,
                                               target_size=(IMG_SHAPE,IMG_SHAPE))
val_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,
                                               directory=val_dir,
                                               shuffle=True,
                                               target_size=(IMG_SHAPE,IMG_SHAPE))
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(2, activation='softmax')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
epochs = 100
model.fit(
    train_data_gen,
    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),
    epochs=epochs,
    validation_data=val_data_gen, 
    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))
)
```

To avoid this issue, I'll have to manually exclude ""KerasSequenceAdapter"" before calling `model.fit`

```python
from tensorflow.python.keras.engine import data_adapter
from tensorflow.python.keras.engine.data_adapter import ListsOfScalarsDataAdapter
from tensorflow.python.keras.engine.data_adapter import TensorLikeDataAdapter
from tensorflow.python.keras.engine.data_adapter import GenericArrayLikeDataAdapter
from tensorflow.python.keras.engine.data_adapter import DatasetAdapter
from tensorflow.python.keras.engine.data_adapter import GeneratorDataAdapter
from tensorflow.python.keras.engine.data_adapter import CompositeTensorDataAdapter

data_adapter.ALL_ADAPTER_CLS = [
 ListsOfScalarsDataAdapter,
 TensorLikeDataAdapter,
 GenericArrayLikeDataAdapter,
 DatasetAdapter,
 GeneratorDataAdapter,
#  tensorflow.python.keras.engine.data_adapter.KerasSequenceAdapter,
 CompositeTensorDataAdapter      
]

data_adapter.ALL_ADAPTER_CLS
```

**Other info / logs**
N/A.
"
33810,"Please add the ""reuse"" parameter to tf.keras.layers.Conv2D()","<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):

No

**Describe the feature and the current behavior/state.**
Unable to implement complex weight sharing
**Will this change the current api? How?**
will do！Add the ""reuse"" parameter to tf.keras.layers.Conv2D()
**Who will benefit with this feature?**
Every user
**Any Other info.**
Why remove the ‘reuse’ parameter from tf.keras.layers.Conv2D(), or do you provide other ways to share weights? The algorithm implemented in 1.x is now not implemented in 2.0. If there is no better way to share weights, please let the ‘reuse’ parameter come back.
"
33809,MirroredStrategy compared to OneDeviceStrategy slower and much weaker learning,"**System information**System information
- OS Platform and Distribution: Arch Linux, 5.3.7-arch1-1-ARCH
- TensorFlow installed from: binary
- TensorFlow version: 2.0.0
- Keras version: 2.2.4-tf
- Python version: 3.7.4
- CUDA/cuDNN version: CUDA 10.1.243 / cuDNN 7.6.2.24
- GPU model and memory: 2x GTX 1080 Ti 11GB""`

**Describe the current behavior**
If the model is trained with OneDeviceStrategy on one GPU an accuracy of 0.9988 is reached after 150 epochs in 5h 24min.
If the model is trained with MirroredStrategy on two GPUs an accuracy of 0 is reached after 150 epochs in 5h. The loss does not significantly drop.

**Describe the expected behavior**
With MirroredStrategy the same accuracy is reached as training on one GPU  in shorter time (ideally in half the time).
Might be related to issue #33767.

**Code to reproduce the issue**
The complete code with data is available in a git repo if required.
- Model:
```
class FeatureExtraction(Layer):
    def __init__(self, conv_filters, pool_size, name='feature-extraction', **kwargs):
        super(FeatureExtraction, self).__init__(name=name, **kwargs)
        self.conv1 = Conv2D(filters=conv_filters, kernel_size=(3, 3), padding='same', activation='relu', kernel_initializer='he_normal', name='conv1')
        self.conv2 = Conv2D(filters=conv_filters, kernel_size=(3, 3), padding='same', activation='relu', kernel_initializer='he_normal', name='conv2')
        self.max1 = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')
        self.max2 = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')

    def call(self, inputs):
        x = self.conv1(inputs)
        x = self.max1(x)
        x = self.conv2(x)
        return self.max2(x)

    def get_config(self):
        return super(FeatureExtraction, self).get_config()


class FeatureReduction(Layer):
    def __init__(self, img_w, img_h, pool_size, conv_filters, name='feature-reduction', **kwargs):
        super(FeatureReduction, self).__init__(name=name, **kwargs)
        target_shape = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)
        self.reshape = Reshape(target_shape=target_shape, name='reshape')
        self.dense = Dense(32, activation='relu', name='dense')

    def call(self, inputs):
        x = self.reshape(inputs)
        return self.dense(x)

    def get_config(self):
        return super(FeatureReduction, self).get_config()


class SequentialLearner(Layer):
    def __init__(self, name='sequential-learner', **kwargs):
        super(SequentialLearner, self).__init__(name=name, **kwargs)
        self.gru_1a = GRU(512, return_sequences=True, kernel_initializer='he_normal', name='gru_1a')
        self.gru_1b = GRU(512, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru_1b')
        self.gru_2a = GRU(512, return_sequences=True, kernel_initializer='he_normal', name='gru_2a')
        self.gru_2b = GRU(512, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru_2b')

    def call(self, inputs):
        x_1a = self.gru_1a(inputs)
        x_1b = self.gru_1b(inputs)
        x = add([x_1a, x_1b])
        x_2a = self.gru_2a(x)
        x_2b = self.gru_2b(x)
        return concatenate([x_2a, x_2b])

    def get_config(self):
        return super(SequentialLearner, self).get_config()


class Output(Layer):
    def __init__(self, output_size, name='output', **kwargs):
        super(Output, self).__init__(name=name, **kwargs)
        self.dense = Dense(output_size, kernel_initializer='he_normal', name='dense')
        self.softmax = Activation('softmax', name='softmax')

    def call(self, inputs):
        x = self.dense(inputs)
        return self.softmax(x)

    def get_config(self):
        return super(Output, self).get_config()


class OCRNet(Model):
    def __init__(self, output_size, img_w, img_h, max_text_len, name='OCRNet', **kwargs):
        # parameters
        conv_filters = 16
        pool_size = 2
        # define layers
        feature_extraction = FeatureExtraction(conv_filters=conv_filters, pool_size=pool_size)
        sequential_learner = SequentialLearner()
        feature_reduction = FeatureReduction(img_w=img_w, img_h=img_h, pool_size=pool_size, conv_filters=conv_filters)
        output = Output(output_size)
        # NHWC == channels_last NCHW == channels_first
        # initialize input shape
        if 'channels_first' == K.image_data_format():
            input_shape = (1, img_w, img_h)
        else:
            input_shape = (img_w, img_h, 1)
        # input
        inputs = Input(name='the_input', shape=input_shape, dtype='float32')
        labels = Input(name='the_labels', shape=[max_text_len], dtype='float32')
        input_length = Input(name='input_length', shape=[1], dtype='int64')
        label_length = Input(name='label_length', shape=[1], dtype='int64')
        # call layers
        x = feature_extraction(inputs)
        x = feature_reduction(x)
        x = sequential_learner(x)
        predictions = output(x)
        # Keras doesn't currently support loss funcs with extra parameters
        # so CTC loss is implemented in a lambda layer
        loss_out = Lambda(self._ctc_lambda_func, output_shape=(1,), name='ctc')([predictions, labels, input_length, label_length])
        super(OCRNet, self).__init__(
                inputs=[inputs, labels, input_length, label_length], outputs=loss_out,
                name=name, **kwargs)

        # ctc decoder
        flattened_input_length = K.reshape(input_length, (-1,))
        top_k_decoded, _ = K.ctc_decode(predictions, flattened_input_length)
        self.decoder = K.function([inputs, flattened_input_length], [top_k_decoded[0]])

    # loss and train functions, network architecture
    def _ctc_lambda_func(self, args):
        predictions, labels, input_length, label_length = args
        # the 2 is critical here since the first couple outputs of the RNN
        # tend to be garbage
        predictions = predictions[:, 2:, :]
        return K.ctc_batch_cost(labels, predictions, input_length, label_length)
```
- training (stripped):
```
    ...
    strategy = tf.distribute.MirroredStrategy() if 1 < ngpus else tf.distribute.OneDeviceStrategy(device=""/gpu:1"")
    batch_size = batch_size * strategy.num_replicas_in_sync
   ...
    with strategy.scope():
        model = OCRNet(train_gen.output_size, img_w, img_h, max_text_len)
        model.summary()
        adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)
        model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam, metrics=['accuracy'])
    callbacks = []
    start = time.perf_counter()
    model.fit(
            train_gen,
            validation_data=val_gen,
            epochs=epochs,
            shuffle=False,
            use_multiprocessing=True,
            workers=6,
            callbacks=callbacks)
    elapsed = time.perf_counter() - start
    logger.info('elapsed: {:0.3f}'.format(elapsed))
```


**Other info / logs**
- Output using OneDeviceStrategy:

> Train for 700 steps, validate for 150 steps                                                                                           
> Epoch 1/150  
> WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb63f70d170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'
> 2019-10-29 06:07:28,887 - WARNING - Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb63f70d170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'
> 2019-10-29 06:07:31.225908: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] function_optimizer failed: Invalid argument: Node 'OCRNet/sequential-learner/gru_1a/StatefulPartitionedCall_StatefulPartitionedCall_2_26': Connecting to invalid output 31 of source node OCRNet/sequential-learner/gru_1a/StatefulPartitionedCall which has 31 outputs.
> 2019-10-29 06:07:31.774256: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
> 2019-10-29 06:07:31.965277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
> 699/700 [============================>.] - ETA: 0s - loss: 41.7196 - accuracy: 0.0000e+002019-10-29 06:09:19.892252: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_gru_with_fallback_16142_specialized_for_OCRNet_sequential-learner_gru_2b_StatefulPartitionedCall_at___inference_distributed_function_16574' and '__inference_cudnn_gru_with_fallback_16142' both implement 'gru_939794c2-9fc6-48f9-8d2a-e319e349d493' but their signatures do not match.
> 700/700 [==============================] - 134s 191ms/step - loss: 41.6829 - accuracy: 0.0000e+00 - val_loss: 15.7647 - val_accuracy: 0.0000e+00
> Epoch 2/150
> 700/700 [==============================] - 129s 185ms/step - loss: 15.9857 - accuracy: 0.0000e+00 - val_loss: 15.0192 - val_accuracy: 0.0000e+00
> Epoch 3/150
> 700/700 [==============================] - 129s 184ms/step - loss: 14.3529 - accuracy: 0.0000e+00 - val_loss: 13.8274 - val_accuracy: 0.0000e+00
> Epoch 4/150
> 700/700 [==============================] - 129s 185ms/step - loss: 13.4774 - accuracy: 0.0000e+00 - val_loss: 13.1987 - val_accuracy: 0.0000e+00
> Epoch 5/150
> 700/700 [==============================] - 129s 185ms/step - loss: 12.9877 - accuracy: 0.0000e+00 - val_loss: 12.8102 - val_accuracy: 0.0000e+00
> ...
> Epoch 145/150
> 700/700 [==============================] - 130s 185ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0119 - val_accuracy: 0.9952
> Epoch 146/150
> 700/700 [==============================] - 130s 185ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0118 - val_accuracy: 0.9953
> Epoch 147/150
> 700/700 [==============================] - 130s 185ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0116 - val_accuracy: 0.9953
> Epoch 148/150
> 700/700 [==============================] - 129s 185ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0114 - val_accuracy: 0.9953
> Epoch 149/150
> 700/700 [==============================] - 129s 185ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0113 - val_accuracy: 0.9954
> Epoch 150/150
> 700/700 [==============================] - 129s 185ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0111 - val_accuracy: 0.9954
> 2019-10-28 04:33:15,026 - INFO - elapsed: 19429.327


- Output using MirroredStrategy:

> Train for 350 steps, validate for 75 steps 
> Epoch 1/150
> INFO:tensorflow:batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
> 2019-10-28 21:41:23,061 - INFO - batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> 2019-10-28 21:41:23,323 - INFO - Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> 2019-10-28 21:41:23,328 - INFO - Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> 2019-10-28 21:41:24,338 - INFO - Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> 2019-10-28 21:41:24,341 - INFO - Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f787c47b170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'
> 2019-10-28 21:41:24,385 - WARNING - Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f787c47b170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'
> INFO:tensorflow:batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
> 2019-10-28 21:41:28,827 - INFO - batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> 2019-10-28 21:41:29,117 - INFO - Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> 2019-10-28 21:41:29,120 - INFO - Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> 2019-10-28 21:41:29,128 - INFO - Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> 2019-10-28 21:41:29,130 - INFO - Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
> 2019-10-28 21:41:29.440363: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] function_optimizer failed: Invalid argument: Node 'replica_1/OCRNet/sequential-learner/gru_1a/StatefulPartitionedCall_replica_1/StatefulPartitionedCall_2_26': Connecting to invalid output 31 of source node replica_1/OCRNet/sequential-learner/gru_1a/StatefulPartitionedCall which has 31 outputs.
> 2019-10-28 21:41:30.730864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
> 2019-10-28 21:41:31.078427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
> 349/350 [============================>.] - ETA: 0s - loss: 89.5114 - accuracy: 0.0000e+002019-10-28 21:43:16.332927: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_gru_26258' and '__inference_cudnn_gru_with_fallback_26349_specialized_for_OCRNet_sequential-learner_gru_2b_StatefulPartitionedCall_at___inference_distributed_function_28787' both implement 'gru_d38ba96e-e1cb-43bd-a1af-2f107f6aab80' but their signatures do not match.
> 350/350 [==============================] - 138s 395ms/step - loss: 89.5000 - accuracy: 0.0000e+00 - val_loss: 86.4455 - val_accuracy: 0.0000e+00
> Epoch 2/150
> 350/350 [==============================] - 120s 342ms/step - loss: 83.2679 - accuracy: 0.0000e+00 - val_loss: 80.2358 - val_accuracy: 0.0000e+00
> Epoch 3/150
> 350/350 [==============================] - 120s 342ms/step - loss: 76.8871 - accuracy: 0.0000e+00 - val_loss: 73.5664 - val_accuracy: 0.0000e+00
> Epoch 4/150
> 350/350 [==============================] - 120s 342ms/step - loss: 69.5524 - accuracy: 0.0000e+00 - val_loss: 65.3586 - val_accuracy: 0.0000e+00
> Epoch 5/150
> 350/350 [==============================] - 120s 342ms/step - loss: 61.0491 - accuracy: 0.0000e+00 - val_loss: 57.3255 - val_accuracy: 0.0000e+00
> ...
> Epoch 145/150
> 350/350 [==============================] - 120s 343ms/step - loss: 9.9171 - accuracy: 0.0000e+00 - val_loss: 9.8855 - val_accuracy: 0.0000e+00
> Epoch 146/150
> 350/350 [==============================] - 120s 343ms/step - loss: 9.8615 - accuracy: 0.0000e+00 - val_loss: 9.8293 - val_accuracy: 0.0000e+00
> Epoch 147/150
> 350/350 [==============================] - 120s 342ms/step - loss: 9.8055 - accuracy: 0.0000e+00 - val_loss: 9.7728 - val_accuracy: 0.0000e+00
> Epoch 148/150
> 350/350 [==============================] - 120s 343ms/step - loss: 9.7491 - accuracy: 0.0000e+00 - val_loss: 9.7160 - val_accuracy: 0.0000e+00
> Epoch 149/150
> 350/350 [==============================] - 120s 343ms/step - loss: 9.6923 - accuracy: 0.0000e+00 - val_loss: 9.6588 - val_accuracy: 0.0000e+00
> Epoch 150/150
> 350/350 [==============================] - 120s 342ms/step - loss: 9.6351 - accuracy: 0.0000e+00 - val_loss: 9.6010 - val_accuracy: 0.0000e+00
> 2019-10-29 02:41:31,149 - INFO - elapsed: 18013.239"
33807,TensorFlow pre-built package not available for download,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): NA
- TensorFlow version: 2.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip using wheel
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: 
- GPU model and memory:



**Describe the problem**
We are not able to download the wheels given on page -> https://www.tensorflow.org/install/pip. We are getting the following error when we try to get the *.whl in a browser:

<Error>
<Code>NoSuchKey</Code>
<Message>The specified key does not exist.</Message>
<Details>
No such object: tensorflow/linux/gpu/tensorflow_gpu-2.0.0-cp36-cp36m-linux_x86_64.whl
</Details>
</Error>

The issue occurs with all the links. We tried wget command on linux and get 404 error.
 
**Provide the exact sequence of commands / steps that you executed before running into the problem**

wget https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-2.0.0-cp36-cp36m-linux_x86_64.whl

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33805,InTopKV2 cannot use k as a tensor,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
   Linux Ubuntu 16.04
- TensorFlow installed from (source or binary):
    binary
- TensorFlow version (use command below):
   TF 1.0

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
   I try to use k as a tensor in InTopKV2 however, it tells me the k must be a scalar.
   This is my code
`input = tf.constant([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8]])
 k = tf.constant([2, 3])
 output = gen_nn_ops.in_top_kv2(input,[2,2],k)
`
![image](https://user-images.githubusercontent.com/22829190/67732568-c31ac400-fa36-11e9-91af-b7084f915877.png)
   
**Describe the expected behavior**
   K can be used as 1-D tensor
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
![image](https://user-images.githubusercontent.com/22829190/67732046-24419800-fa35-11e9-8b40-e72d436ea757.png)
"
33804,Does Tensorflowlite model support GPU boost on PC?,"
Does Tensorflowlite model support GPU boost on PC? I can't find an example for supporting  GPU boost on PC, there're all examples for the mobile GPU boost or mobile CPU."
33802,Pull Requests: Map needed for request workflow,"At the moment external contributors don't have any way of knowing what the lifecycle of a pull request is. We have [documentation on contributing code](https://www.tensorflow.org/community/contribute/code), but it's silent on the details of what happens to a request once it's been submitted. Chandni presented a fantastic flowchart at the contributor's summit today that would be a great foundation for documentation explaining the stages that a PR goes through.

This would help external contributors understand what they need to do to successfully submit code to the project, and combined with https://github.com/tensorflow/tensorflow/issues/33801 will give them the visibility they need to be effective TensorFlow developers.

/cc @freddan80 @jenselofsson "
33801,Pull Requests: Status information should be available,"There is currently no way to tell who needs to take the next action on a pull request, or what state a PR is in. This delays external contributions and frustrates developers. Here is the sort of information that is needed to enable efficient contributions:

 - Who needs to take action? Is it the contributor, a member of the gtech team, or a Google TensorFlow engineer? This should be clearly and publicly visible on the request, so that stakeholders can communicate with the responsible individual.

 - Where is the request in the approval workflow? We'll need a map of the stages involved, and a way to map the current state to each node in the graph.

There are other pieces of information that would be nice to have, but these are essential to shepherding contributions through our process.

/cc @jenselofsson @freddan80"
33800,Pull Requests: Trusted committers should be able to approve,"@jenselofsson is a trusted external committer from Arm, but at least some of the PRs that he has approved have required an additional Google review on GitHub. I would expect that he would be able to review and approve pull requests. For an example, see PR https://github.com/tensorflow/tensorflow/pull/33420"
33799,TF 2.0.0 Python 3.8 TypeError: _logger_find_caller() takes from 0 to 1 positional arguments but 2 were given,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  See script from Tensorflow training session and uploaded file below.  Nb: There is no error with TF2.0.0 and python 3.6 or 3.7.  The error occurs with TF2.0.0 and python 3.8.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0.0
- Python version: 3.8
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: CUDA 10/cuDNN 7.6.4
- GPU model and memory: NVidia RTX 2080 TI and 2080 MaxQ

**Describe the current behavior**

After running the code below (with the attached file), you get the following error:

---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/api.py in converted_call(f, args, kwargs, caller_fn_scope, options)
    525         options=options, autograph_module=tf_inspect.getmodule(converted_call))
--> 526     converted_f = conversion.convert(target_entity, program_ctx)
    527 

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in convert(entity, program_ctx)
    324 
--> 325   converted_entity_info = _convert_with_cache(entity, program_ctx,
    326                                               free_nonglobal_var_names)

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in _convert_with_cache(entity, program_ctx, free_nonglobal_var_names)
    238 
--> 239     nodes, converted_name, entity_info = convert_entity_to_ast(
    240         entity, program_ctx)

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in convert_entity_to_ast(o, program_ctx)
    474   elif tf_inspect.ismethod(o):
--> 475     nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
    476   elif hasattr(o, '__class__'):

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in convert_func_to_ast(f, program_ctx, do_rename)
    672   context = converter.EntityContext(namer, entity_info, program_ctx, new_name)
--> 673   node = node_to_graph(node, context)
    674 

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in node_to_graph(node, context)
    702   node = converter.standard_analysis(node, context, is_initial=True)
--> 703   node = converter.apply_(node, context, function_scopes)
    704   node = converter.apply_(node, context, arg_defaults)

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/core/converter.py in apply_(node, context, converter_module)
    408   node = standard_analysis(node, context)
--> 409   node = converter_module.transform(node, context)
    410   return node

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py in transform(node, ctx)
    119 def transform(node, ctx):
--> 120   return FunctionBodyTransformer(ctx).visit(node)

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/core/converter.py in visit(self, node)
    345     try:
--> 346       return super(Base, self).visit(node)
    347     finally:

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/transformer.py in visit(self, node)
    479     if not anno.hasanno(node, anno.Basic.SKIP_PROCESSING):
--> 480       result = super(Base, self).visit(node)
    481     self.ctx.current_origin = parent_origin

/usr/local/lib/python3.8/ast.py in visit(self, node)
    359         visitor = getattr(self, method, self.generic_visit)
--> 360         return visitor(node)
    361 

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py in visit_FunctionDef(self, node)
    101     """"""
--> 102     wrapped_body = templates.replace(
    103         template,

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/templates.py in replace(template, **replacements)
    268   for node in nodes:
--> 269     node = ReplaceTransformer(replacements).visit(node)
    270     if isinstance(node, (list, tuple)):

/usr/local/lib/python3.8/ast.py in visit(self, node)
    359         visitor = getattr(self, method, self.generic_visit)
--> 360         return visitor(node)
    361 

/usr/local/lib/python3.8/ast.py in generic_visit(self, node)
    435                     if isinstance(value, AST):
--> 436                         value = self.visit(value)
    437                         if value is None:

/usr/local/lib/python3.8/ast.py in visit(self, node)
    359         visitor = getattr(self, method, self.generic_visit)
--> 360         return visitor(node)
    361 

/usr/local/lib/python3.8/ast.py in generic_visit(self, node)
    444             elif isinstance(old_value, AST):
--> 445                 new_node = self.visit(old_value)
    446                 if new_node is None:

/usr/local/lib/python3.8/ast.py in visit(self, node)
    359         visitor = getattr(self, method, self.generic_visit)
--> 360         return visitor(node)
    361 

/usr/local/lib/python3.8/ast.py in generic_visit(self, node)
    435                     if isinstance(value, AST):
--> 436                         value = self.visit(value)
    437                         if value is None:

/usr/local/lib/python3.8/ast.py in visit(self, node)
    359         visitor = getattr(self, method, self.generic_visit)
--> 360         return visitor(node)
    361 

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/templates.py in visit_Name(self, node)
    199 
--> 200     new_nodes = self._prepare_replacement(node, node.id)
    201 

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/templates.py in _prepare_replacement(self, replaced, key)
    138 
--> 139     new_nodes = ast_util.copy_clean(repl, preserve_annos=self.preserved_annos)
    140     if isinstance(new_nodes, gast.AST):

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py in copy_clean(node, preserve_annos)
     75   """"""
---> 76   return CleanCopier(preserve_annos).copy(node)
     77 

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py in copy(self, node)
     53       if not f.startswith('__') and hasattr(node, f):
---> 54         new_fields[f] = self.copy(getattr(node, f))
     55     new_node = type(node)(**new_fields)

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py in copy(self, node)
     40     if isinstance(node, list):
---> 41       return [self.copy(n) for n in node]
     42     elif isinstance(node, tuple):

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py in <listcomp>(.0)
     40     if isinstance(node, list):
---> 41       return [self.copy(n) for n in node]
     42     elif isinstance(node, tuple):

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py in copy(self, node)
     54         new_fields[f] = self.copy(getattr(node, f))
---> 55     new_node = type(node)(**new_fields)
     56 

~/tf38/lib/python3.8/site-packages/gast/gast.py in create_node(self, *args, **kwargs)
      9         nbparam = len(args) + len(kwargs)
---> 10         assert nbparam in (0, len(Fields)), \
     11             ""Bad argument number for {}: {}, expecting {}"".\

AssertionError: Bad argument number for keyword: 1, expecting 2

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
<ipython-input-10-8b26b7af23a7> in <module>
----> 1 tf_model.fit(Xs_train[:, 0:1], y_train.reshape(-1, 1));

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    613       # This is the first call of __call__, so we have to initialize.
    614       initializers = []
--> 615       self._initialize(args, kwds, add_initializers_to=initializers)
    616     finally:
    617       # At this point we know that the initialization is complete (or less

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    494     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)
    495     self._concrete_stateful_fn = (
--> 496         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
    497             *args, **kwds))
    498 

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2363       args, kwargs = None, None
   2364     with self._lock:
-> 2365       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2366     return graph_function
   2367 

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2671 
   2672       self._function_cache.missed.add(call_context_key)
-> 2673       graph_function = self._create_graph_function(args, kwargs)
   2674       self._function_cache.primary[cache_key] = graph_function
   2675       return graph_function, args, kwargs

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2551     arg_names = base_arg_names + missing_arg_names
   2552     graph_function = ConcreteFunction(
-> 2553         func_graph_module.func_graph_from_py_func(
   2554             self._name,
   2555             self._python_function,

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    956                                           converted_func)
    957 
--> 958       func_outputs = python_func(*func_args, **func_kwargs)
    959 
    960       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    438         # the function a weak reference to itself to avoid a reference cycle.
--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    440     weak_wrapped_fn = weakref.ref(wrapped_fn)
    441 

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in bound_method_wrapper(*args, **kwargs)
   3179     # However, the replacer is still responsible for attaching self properly.
   3180     # TODO(mdan): Is it possible to do it here instead?
-> 3181     return wrapped_fn(*args, **kwargs)
   3182   weak_bound_method_wrapper = weakref.ref(bound_method_wrapper)
   3183 

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
    935           # TODO(mdan): Push this block higher in tf.function's call stack.
    936           try:
--> 937             return autograph.converted_call(
    938                 original_func,
    939                 args,

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/api.py in converted_call(f, args, kwargs, caller_fn_scope, options)
    552           'Cause: %s', target_entity, e)
    553     else:
--> 554       logging.warn(
    555           'AutoGraph could not transform %s and will run it as-is.\n'
    556           'Please report this to the TensorFlow team. When filing the bug, set'

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/autograph/utils/ag_logging.py in warn(msg, *args, **kwargs)
    144 
    145 def warn(msg, *args, **kwargs):
--> 146   logging.warn(msg, *args, **kwargs)
    147   if echo_log_to_stdout:
    148     _output_to_stdout('WARNING: ' + msg, *args, **kwargs)

~/tf38/lib/python3.8/site-packages/tensorflow_core/python/platform/tf_logging.py in warn(msg, *args, **kwargs)
    159 @tf_export(v1=['logging.warn'])
    160 def warn(msg, *args, **kwargs):
--> 161   get_logger().warning(msg, *args, **kwargs)
    162 
    163 

/usr/local/lib/python3.8/logging/__init__.py in warning(self, msg, *args, **kwargs)
   1444         """"""
   1445         if self.isEnabledFor(WARNING):
-> 1446             self._log(WARNING, msg, args, **kwargs)
   1447 
   1448     def warn(self, msg, *args, **kwargs):

/usr/local/lib/python3.8/logging/__init__.py in _log(self, level, msg, args, exc_info, extra, stack_info, stacklevel)
   1563             #IronPython can use logging.
   1564             try:
-> 1565                 fn, lno, func, sinfo = self.findCaller(stack_info, stacklevel)
   1566             except ValueError: # pragma: no cover
   1567                 fn, lno, func = ""(unknown file)"", 0, ""(unknown function)""

TypeError: _logger_find_caller() takes from 0 to 1 positional arguments but 2 were given

**Describe the expected behavior**

There should be no error.  It works fine with TF2.0.0 and Python 3.6 or Python 3.7.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

import tensorflow as tf
import numpy as np
import gzip
import json
from sklearn.model_selection import ShuffleSplit

with gzip.open(""small_data/cal_house.json.gz"", ""r"") as fin:
    housing = json.load(fin)
    
for train, test in ShuffleSplit(1, 0.2, random_state=42).split(housing['data']):
    X_train = np.array(housing['data'])[train].astype(np.float32)
    y_train = np.array(housing['target'])[train].astype(np.float32)
    X_test = np.array(housing['data'])[test].astype(np.float32)
    y_test = np.array(housing['target'])[test].astype(np.float32)

X_mean = X_train.mean(axis=0)
X_std = X_train.std(axis=0)

Xs_train = (X_train - X_mean) / X_std
Xs_test = (X_test - X_mean) / X_std

class LinearRegressionTF():
    def __init__(self, eta=.1):
        self.W = tf.Variable(0.)
        self.b = tf.Variable(0.)
        self.opt = tf.keras.optimizers.SGD(learning_rate=eta)
    
    def loss(self, X, y, return_func=False):
        def loss_():
            return tf.reduce_mean(tf.square(X * self.W + self.b - y))
        
        if not return_func:
            return loss_()
        
        return loss_

    @tf.function
    def fit(self, X, y, steps=1):
        for _ in range(steps):
            self.opt.minimize(self.loss(X, y, return_func=True), [self.W, self.b])

tf_model = LinearRegressionTF()

tf_model.fit(Xs_train[:, 0:1], y_train.reshape(-1, 1));

[cal_house.json.gz](https://github.com/tensorflow/tensorflow/files/3780890/cal_house.json.gz)

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Nil"
33798,Pull Requests: Ubuntu CC test is flakey,"When testing pull requests the ""Ubuntu CC"" test seems to never(?) complete. See two examples here:

https://github.com/tensorflow/tensorflow/pull/33492
https://github.com/tensorflow/tensorflow/pull/32168

This makes it hard to for contributors to tell if their changes have broken the project, or if it's an unrelated flake (as it seems to be in these cases). This is the most obvious example of the problem, but we see many unrelated failures on the CI tests for PRs."
33797,Which ssd model to use to generate the smallest tflite for a lite>experimental>micro project?,"Hi, I have asked [this](https://stackoverflow.com/questions/58595004/how-to-obtain-a-small-tflite-file) question on stack overflow and I am going to ask the same thing here; Furthermore I would like to know if the lite>experimental>micro project is still under developing; In particular:

- I cannot execute the MUL operation, will it be ever available for the micro sub-project?
- If not, can I rely on previous ssd mobilenets (v1 or v2)  in order to execute an object-detection?
- Which ssd model do you suggest to generate the smallest object detection model?
- And more important, I would ask you if there is something that I have missed on the documentation/process that I have done (more details on the posted question) in order to generate the .cc file to be run on the microcontroller.

Thank you for your attention."
33796,tf.data.Dataset.from_generator triggers a SIGBUS signal when operating with numpy arrays,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
OSX Mojave 10.14.6 

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:

- TensorFlow installed from (source or binary):
Binray
- TensorFlow version (use command below):
GIT v2.0.0-rc2-26-g64c3d382ca 
Tensorflow 2.0.0

- Python version: 
Python 3.6.8

- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
On cpu
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Clean virtualenv with tensorflow==2.0.0 installed 
tf.data.Dataset.from_generator raises a SIGBUS when operating on large enough Numpy arrays 

Using 
tf_dataset = tf.data.Dataset.from_generator(gen_callable,
                                                output_types=(tf.float32),
                                                output_shapes=(None, 3))
with a function that generates and operates on medium sized numpy arrays triggers a SIGBUS signal.

**Describe the expected behavior**

No SIGUS should be raised

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

### NOT A CONTRIBUTION
```
import os

import numpy as np
import tensorflow as tf


def foo(x, R):
    return np.matmul(x, R)


def baz(x, R):
    return foo(x, R)


def bar(x, R):
    registered_x = baz(
        x, R
    )
    return registered_x


def gen_callable():
    for i in range(1):
        R = np.eye(3).astype(np.float32)
        x = np.random.randn(40000, 3).astype(np.float32)
        prod = bar(
            x, R
        )
        yield prod


def make_tf_generator():
    tf_dataset = tf.data.Dataset.from_generator(gen_callable,
                                                output_types=(tf.float32),
                                                output_shapes=(None, 3))

    for d in tf_dataset:
        print(d)

if __name__ == '__main__':
    make_tf_generator()
```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

output of pip freeze 

absl-py==0.8.1
astor==0.8.0
gast==0.2.2
google-pasta==0.1.7
grpcio==1.24.1
h5py==2.10.0
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
Markdown==3.1.1
numpy==1.17.2
opt-einsum==3.1.0
protobuf==3.10.0
six==1.12.0
tensorboard==2.0.0
tensorflow==2.0.0
tensorflow-estimator==2.0.0
termcolor==1.1.0
Werkzeug==0.16.0
wrapt==1.11.2
"
33795,Anaconda tensorflow-gpu faulty package?,"Using [`conda install -c anaconda tensorflow-gpu`](https://anaconda.org/anaconda/tensorflow-gpu) yields the pre-installation message below, showing that cuDNN 7.6.0 will be installed _against_ the TensorFlow GPU [compatibility table](https://www.tensorflow.org/install/source_windows#gpu). `pip` install does _not_ include cuDNN. Further, I already have cuDNN 7.4.2 installed per [official instructions](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-windows) with paths [set up](https://www.tensorflow.org/install/gpu#windows_setup).

Either the compatibility table is outdated, or the Anaconda package is faulty - which is it?

<hr>

<img src=""https://user-images.githubusercontent.com/16495490/67711092-ae104780-f9da-11e9-8651-dad5ff602319.png"" width=""550"">

<img src=""https://user-images.githubusercontent.com/16495490/67711269-13fccf00-f9db-11e9-9f13-53e5fab60bfc.png"" width=""650"">"
33794,[TF 2.0 API Docs] tf.keras.layers.simpleRNN,"## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/SimpleRNN

## Description of issue (what needs changing):

### Clear description

The document mentions nothing about call argument `inputs` when it takes 
`[[batch, timesteps, feature], [batch, state]]`. In case of `inputs` is a list, the elements of `inputs[1:]` work as initial_state in each batch.

Example)
```
import tensorflow as tf
from tensorflow.keras.layers import *


class foo(tf.keras.Model):
    def __init__(self, rnn_units, dense_units, **kwargs):
        super().__init__(**kwargs)
        self.r1 = SimpleRNN(rnn_units)
        self.r2 = SimpleRNN(rnn_units)
        self.flat = tf.keras.layers.Flatten()
        self.d1 = Dense(rnn_units)
        self.d2 = Dense(dense_units)

    def call(self, inputs, **kwargs):

        x = self.r1(inputs)
        state = self.d1(self.flat(x))
        x = self.r2([inputs, state])
        x = self.d2(x)

        return x


train_input = tf.random.normal(shape=(6, 5, 10))
train_target = tf.random.normal(shape=(6, 8))

a = foo(10, 8)
a.compile(tf.keras.optimizers.SGD(0.01), loss=tf.keras.losses.MeanSquaredError())
a.fit(train_input, train_target)


b = SimpleRNN(10)(train_input)
state = Dense(10)(tf.reshape(b, (tf.shape(b)[0], -1)))
b = SimpleRNN(10)([train_input, state])
```

It also should be noted that `initial_state` argument should be `None` when `inputs` has states.
Other recurrent layers have same issue.

### Submit a pull request?
If this issue was not intended or a bug,
I'm planning to submit a pull request to fix the doc issue in a week. May i?"
33793,DenseFeatures always returns float32,"(https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

Currently, a call to `tf.keras.layers.DenseFeatures` returns `float32` no matter what.
It doesn't respect its own `dtype` (e.g., `DenseFeatures(..., dtype=tf.float64)`
is not working). Using `tf.keras.backend.set_floatx('float64')` does not change
the behavior, either. It will be nice if a user can choose to return `float64`.
Or at least respect the setting of `tf.keras.backend.set_floatx(...)`.

This behavior is not mentioned in the API documentation:
https://www.tensorflow.org/api_docs/python/tf/keras/layers/DenseFeatures

But it is mentioned in the docstring of `DenseFeatures.call`:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/feature_column/dense_features.py#L119-L122

Here's a simple sample code:
```
import numpy
import tensorflow as tf

numpy.set_printoptions(15)

columns = [
    tf.feature_column.numeric_column(""a"", dtype=tf.float64),
    tf.feature_column.numeric_column(""b"", dtype=tf.float64)
]

layer = tf.keras.layers.DenseFeatures(columns, dtype=tf.float64)

data = {
    ""a"": tf.constant([1./3.], dtype=tf.float64),
    ""b"": tf.constant([numpy.pi], dtype=tf.float64)
}

print(""\n""+""-""*80)
print(""data[\""a\""]:"", data[""a""])
print(""data[\""b\""]:"", data[""b""])
print(""layer(data):"", layer(data))
print(""-""*80)
```

And the output:
```
--------------------------------------------------------------------------------
data[""a""]: tf.Tensor([0.333333333333333], shape=(1,), dtype=float64)
data[""b""]: tf.Tensor([3.141592653589793], shape=(1,), dtype=float64)
layer(data): tf.Tensor([[0.33333334 3.1415927 ]], shape=(1, 2), dtype=float32)
--------------------------------------------------------------------------------
```

**Will this change the current api? How?**

No.

**Who will benefit with this feature?**

Not sure. But who ever uses `tf.keras.backend.set_floatx('float64')` will
probably be happy.

**Any Other info.**

N/A"
33792,Several issues with saving model by averaging multiple models,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.13
- Python version: 2.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10
- GPU model and memory: 2080 ti

I try to average two models weights to form one final model. The two original models are initialized following the same setting up. The only difference is they are trained with different data. After train them, I load them and average them using the code below:

```
import tensorflow as tf
import os
sess1 = tf.Session()
sess2 = tf.Session()
# toy example, so load the same model twice and do averaging
saver1 = tf.train.import_meta_graph('model.meta')
saver2 = tf.train.import_meta_graph('model.meta')  
saver1.restore(sess1, 'model')
saver2.restore(sess2, 'model')
with tf.Session() as sess3:
    sess3.run(init_op)
    all_vars = tf.trainable_variables()
    values1 = sess1.run(all_vars)
    values2 = sess2.run(all_vars)
    all_assign = []
    for var, val1, val2 in zip(all_vars, values1, values2):
        all_assign.append(tf.assign(var, (val1 + val2)/ 2))
    sess3.run(all_assign)
    saver3 = tf.train.Saver()
    save_path = saver3.save(sess3, os.path.join('./debug/', 'model'))
```
Then it shows the error:
At least two variables have the same name: beta1_power

I have two questions:
1). is this way I do averaging right?
2). why I have the error?

Thank you very much!
"
33791,tflite operators support dependent on tf.shape,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): docker images
- TensorFlow version (use command below): 1.15.0-rc2 / 2.10.-dev20191027
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
I am trying to convert an variational autoencoder into a tflite model. During the process, I stumbled across a weird bug. When explicitly specifying the shape of the sampling layer like this: `tf.random.normal(shape=(10,))`, the model is convertible without any errors.

But in case of not hard-coding the shape into my model, e.g. by inferencing it from the input vector(s) like so:

```
dimension = tf.shape(z_mu)[1] #index 0 is batch size
eps = tf.random.normal(shape=(dim,))
```
I get the error that tf.random.normal is not supported by the TF Lite runtime:

> Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, EXP, FULLY_CONNECTED, LEAKY_RELU, LOG, MUL. Here is a list of operators for which you will need custom implementations: RandomStandardNormal.

**Describe the expected behavior**

It doesn't make sense to me that the possibly buggy inference of a shape influences whether an OP is supported or not. Also, I am not sure if the hard-coded model can be trusted or not.

**Code to reproduce the issue**
Just set the EXPLICIT flag to False to get the error.
```
import tensorflow as tf
import pandas as pd
import numpy as np
from tensorflow import keras

print(tf.__version__)

EXPLICIT = True

### DATA
training_data = np.random.rand(1000, 90)
train_dataset = tf.data.Dataset.from_tensor_slices((training_data, training_data))
train_dataset = train_dataset.shuffle(1000).batch(100)

### MODEL
x = keras.layers.Input(shape=(90,))
h = keras.layers.Dense(40, activation=tf.nn.relu)(x)
z_mu = keras.layers.Dense(10)(h)
z_sigma = keras.layers.Dense(10, activation=tf.nn.sigmoid)(h)

#########################################################################################
if EXPLICIT:
    eps = tf.random.normal(shape=(10,)) # this works

else:
    batch_size = tf.shape(z_mu)[0]
    dimension = tf.shape(z_mu)[1]
    eps = tf.random.normal(shape=(batch_size, dimension)) # this does NOT work, also tried using shape=(dimension,)

#########################################################################################
z = z_mu + eps * z_sigma

h_decoded = keras.layers.Dense(40, activation=tf.nn.relu)(z)
x_decoded = keras.layers.Dense(90)(h_decoded)

model = keras.models.Model(x, x_decoded)

### LOSS
recon_err = tf.reduce_sum(tf.abs(x - x_decoded), axis=1)
kl_div = -.5 * tf.reduce_sum(1 + 2 * tf.math.log(z_sigma) - tf.square(z_mu) - tf.square(z_sigma), axis=1)
total_loss = tf.reduce_mean(recon_err + kl_div)
model.add_loss(total_loss)

### TRAINING
model.compile(optimizer='adam')
print(model.summary())
model.fit(train_dataset, epochs=5)

### SAVE
keras_file = 'vae_test.h5'
keras.models.save_model(model, keras_file)

### CONVERSION
test_dataset = np.random.rand(100, 90).astype(np.float32)

def representative_dataset_gen():
    for i in range(100):
        yield [test_dataset[i:i+1]]

converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(keras_file)
converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
converter.optimizations = [tf.lite.Optimize.DEFAULT]

tflite_file_name = 'vae.tflite'
tflite_model = converter.convert()
open(tflite_file_name, 'wb').write(tflite_model)

```
Can you confirm the strange behavior and whether tf.random.normal is implemented or not?"
33790,"""Beginner Hello World"" Warning: WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D8DAF28> could not be transformed and will be executed as-is. ","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Windows 7:
- TensorFlow installed from: pip
- TensorFlow version: 2.0.0 v2.0.0-rc2-26-g64c3d382ca'
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

Getting a warning after executing the ""Hello World"" example for beginners from https://www.tensorflow.org/overview/?hl=es. Code:
```
import tensorflow as tf
tf.autograph.set_verbosity(10)

mnist = tf.keras.datasets.mnist

(x_train, y_train),(x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)
model.evaluate(x_test, y_test)
```

The initial message (without verbosity set to 10):
INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x000000002D042158>
    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>,)
    kwargs: {}

INFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x000000002D042158>: DoNotConvert rule for tensorflow
INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x0000000005166F28>
    args: (<tf.Tensor 'args_0:0' shape=(60000,) dtype=int64>,)
    kwargs: {}

INFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x0000000005166F28>: DoNotConvert rule for tensorflow
INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.grab_batch at 0x000000002CD55730>
    args: (<tf.Tensor 'args_0:0' shape=(32,) dtype=int64>, (<tf.Tensor 'args_1:0' shape=(60000, 28, 28) dtype=float64>, <tf.Tensor 'args_2:0' shape=(60000, 1) dtype=uint8>))
    kwargs: {}

INFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.grab_batch at 0x000000002CD55730>: DoNotConvert rule for tensorflow
Train on 60000 samples
INFO:tensorflow:Converted call: <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D8DAF28>
    args: ()
    kwargs: {}

INFO:tensorflow:Cache hit for entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D8DAF28> key <code object initialize_variables at 0x00000000096CE6F0, file ""C:\Users\cenic\Anaconda3\envs\tensorflow2env\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 603> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x000000002D4C2978>, frozenset({'initializer_map'})): _ConvertedEntityFactoryInfo(tf__initialize_variables in tmpupjy58ms)
INFO:tensorflow:Error transforming entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D8DAF28>
Traceback (most recent call last):
  File ""C:\Users\cenic\Anaconda3\envs\tensorflow2env\lib\site-packages\tensorflow_core\python\autograph\impl\api.py"", line 506, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""C:\Users\cenic\Anaconda3\envs\tensorflow2env\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 324, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""C:\Users\cenic\Anaconda3\envs\tensorflow2env\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 266, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""C:\Users\cenic\Anaconda3\envs\tensorflow2env\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 92, in get_factory
    assert self.module_name in sys.modules
AssertionError
WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D8DAF28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
60000/60000 [==============================] - 3s 52us/sample - loss: 0.2937 - accuracy: 0.9152
<tensorflow.python.keras.callbacks.History object at 0x000000002C5A0A20>


The console output with verbosity set to 10 looks as follows:
INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x000000002CD55510>
    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>,)
    kwargs: {}

INFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x000000002CD55510>: DoNotConvert rule for tensorflow
INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x000000002CD55950>
    args: (<tf.Tensor 'args_0:0' shape=(60000,) dtype=int64>,)
    kwargs: {}

INFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x000000002CD55950>: DoNotConvert rule for tensorflow
INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.grab_batch at 0x000000002CD55B70>
    args: (<tf.Tensor 'args_0:0' shape=(32,) dtype=int64>, (<tf.Tensor 'args_1:0' shape=(60000, 28, 28) dtype=float64>, <tf.Tensor 'args_2:0' shape=(60000, 1) dtype=uint8>))
    kwargs: {}

INFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.grab_batch at 0x000000002CD55B70>: DoNotConvert rule for tensorflow
Train on 60000 samples
INFO:tensorflow:Converted call: <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D0428C8>
    args: ()
    kwargs: {}

INFO:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D0428C8> is not cached for key <code object initialize_variables at 0x00000000096CE6F0, file ""C:\Users\cenic\Anaconda3\envs\tensorflow2env\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 603> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x000000002D866FD0>, frozenset({'initializer_map'}))
INFO:tensorflow:Converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D0428C8>
INFO:tensorflow:Source code of <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D0428C8>:

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
@function_lib.defun
def initialize_variables():
  op_map = object_identity.ObjectIdentityDictionary()
  for v, init in initializer_map.items():
    with ops.init_scope():
      if resource_variable_ops.var_is_initialized_op(v.handle):
        # Ignore variables which are already initialized at trace time.
        continue
    op_map = lift_to_graph.lift_to_graph(
        [init], ops.get_default_graph(), op_map=op_map)
    v.assign(op_map[init])


INFO:tensorflow:Compiled output of <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D0428C8>:

# coding=utf-8
def tf__initialize_variables():
  with ag__.FunctionScope('initialize_variables', 'initialize_variables_scope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as initialize_variables_scope:
    op_map = ag__.converted_call(object_identity.ObjectIdentityDictionary, initialize_variables_scope.callopts, (), None, initialize_variables_scope)

    def get_state_2():
      return ()

    def set_state_2(_):
      pass

    def loop_body(iterates, op_map):
      v, init = iterates
      continue_ = False
      with ops.init_scope():

        def get_state():
          return ()

        def set_state(_):
          pass

        def if_true():
          continue_ = True
          return continue_

        def if_false():
          return continue_
        cond = ag__.converted_call(resource_variable_ops.var_is_initialized_op, initialize_variables_scope.callopts, (v.handle,), None, initialize_variables_scope)
        continue_ = ag__.if_stmt(cond, if_true, if_false, get_state, set_state, ('continue_',), ())

      def get_state_1():
        return ()

      def set_state_1(_):
        pass

      def if_true_1():
        op_map_1, = op_map,
        op_map_1 = ag__.converted_call(lift_to_graph.lift_to_graph, initialize_variables_scope.callopts, ([init], ag__.converted_call(ops.get_default_graph, initialize_variables_scope.callopts, (), None, initialize_variables_scope)), {'op_map': op_map_1}, initialize_variables_scope)
        ag__.converted_call(v.assign, initialize_variables_scope.callopts, (op_map_1[init],), None, initialize_variables_scope)
        return op_map_1

      def if_false_1():
        return op_map
      cond_1 = ag__.not_(continue_)
      op_map = ag__.if_stmt(cond_1, if_true_1, if_false_1, get_state_1, set_state_1, ('op_map',), ())
      return op_map,
    op_map, = ag__.for_stmt(ag__.converted_call(initializer_map.items, initialize_variables_scope.callopts, (), None, initialize_variables_scope), None, loop_body, get_state_2, set_state_2, (op_map,), ('op_map',), ())


INFO:tensorflow:Compiled AST of <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000002D0428C8>:

FunctionDef:
| name=u""tf__initialize_variables""
| args=arguments:
| | args=[]
| | vararg=None
| | kwonlyargs=[]
| | kw_defaults=[]
| | kwarg=None
| | defaults=[]
| | ___pyct_anno={SCOPE: Scope{r=(), w=()}}
| body=[
| | With:
| | | items=[
| | | | withitem:
| | | | | context_expr=Call:
| | | | | | func=Attribute:
| | | | | | | value=Name:
| | | | | | | | id=u""ag__""
| | | | | | | | ctx=Load()
| | | | | | | | annotation=None
| | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: (), 'static_value': <module 'tensorflow.python.autograph.operators' from 'C:\\Users\\cenic\\Anaconda3\\envs\\tensorflow2env\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\__init__.py'>}
| | | | | | | attr=u""FunctionScope""
| | | | | | | ctx=Load()
| | | | | | | ___pyct_anno={QN: ag__.FunctionScope, 'static_value': <class 'tensorflow.python.autograph.core.function_wrappers.FunctionScope'>}
| | | | | | args=[
| | | | | | | Str:
| | | | | | | | s=u""initialize_variables""
| | | | | | | Str:
| | | | | | | | s=u""initialize_variables_scope""
| | | | | | | Call:
| | | | | | | | func=Attribute:
| | | | | | | | | value=Name:
| | | | | | | | | | id=u""ag__""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: (), 'static_value': <module 'tensorflow.python.autograph.operators' from 'C:\\Users\\cenic\\Anaconda3\\envs\\tensorflow2env\\lib\\site-packages\\tensorflow_core\\python\\autograph\\operators\\__init__.py'>}
| | | | | | | | | attr=u""ConversionOptions""
| | | | | | | | | ctx=Load()
| | | | | | | | | ___pyct_anno={QN: ag__.ConversionOptions, 'static_value': <class 'tensorflow.python.autograph.core.converter.ConversionOptions'>}
| | | | | | | | args=[]
| | | | | | | | keywords=[
| | | | | | | | | keyword:
| | | | | | | | | | arg=u""recursive""
| | | | | | | | | | value=NameConstant:
| | | | | | | | | | | value=True
| | | | | | | | | keyword:
| | | | | | | | | | arg=u""user_requested""
| | | | | | | | | | value=NameConstant:
| | | | | | | | | | | value=True
| | | | | | | | | keyword:
| | | | | | | | | | arg=u""optional_features""
| | | | | | | | | | value=Tuple:
| | | | | | | | | | | elts=[]
| | | | | | | | | | | ctx=Load()
| | | | | | | | | keyword:
| | | | | | | | | | arg=u""internal_convert_user_code""
| | | | | | | | | | value=NameConstant:
| | | | | | | | | | | value=True
| | | | | | | | ]
| | | | | | | | ___pyct_anno={ARGS_SCOPE: Scope{r=(), w=()}}
| | | | | | ]
| | | | | | keywords=[]
| | | | | | ___pyct_anno={ARGS_SCOPE: Scope{r=(ag__, ag__.ConversionOptions), w=()}}
| | | | | optional_vars=Name:
| | | | | | id=u""initialize_variables_scope""
| | | | | | ctx=Store()
| | | | | | annotation=None
| | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | ___pyct_anno={SCOPE: Scope{r=(ag__, ag__.FunctionScope, ag__.ConversionOptions), w=(initialize_variables_scope,)}}
| | | ]
| | | body=[
| | | | Assign:
| | | | | targets=[
| | | | | | Name:
| | | | | | | id=u""op_map""
| | | | | | | ctx=Store()
| | | | | | | annotation=None
| | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764323152],), ORIGIN: def_function.py:605:6, QN: op_map, DEFINITIONS: (AnnotatedDef[766997112],)}
| | | | | ]
| | | | | value=Call:
| | | | | | func=Attribute:
| | | | | | | value=Name:
| | | | | | | | id=u""ag__""
| | | | | | | | ctx=Load()
| | | | | | | | annotation=None
| | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}
| | | | | | | attr=u""converted_call""
| | | | | | | ctx=Load()
| | | | | | | ___pyct_anno={QN: ag__.converted_call}
| | | | | | args=[
| | | | | | | Attribute:
| | | | | | | | value=Name:
| | | | | | | | | id=u""object_identity""
| | | | | | | | | ctx=Load()
| | | | | | | | | annotation=None
| | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (), ORIGIN: def_function.py:605:15, QN: object_identity, DEFINITIONS: ()}
| | | | | | | | attr=u""ObjectIdentityDictionary""
| | | | | | | | ctx=Load()
| | | | | | | | ___pyct_anno={ORIGIN: def_function.py:605:15, QN: object_identity.ObjectIdentityDictionary}
| | | | | | | Attribute:
| | | | | | | | value=Name:
| | | | | | | | | id=u""initialize_variables_scope""
| | | | | | | | | ctx=Load()
| | | | | | | | | annotation=None
| | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | | | | attr=u""callopts""
| | | | | | | | ctx=Load()
| | | | | | | | ___pyct_anno={QN: initialize_variables_scope.callopts}
| | | | | | | Tuple:
| | | | | | | | elts=[]
| | | | | | | | ctx=Load()
| | | | | | | NameConstant:
| | | | | | | | value=None
| | | | | | | Name:
| | | | | | | | id=u""initialize_variables_scope""
| | | | | | | | ctx=Load()
| | | | | | | | annotation=None
| | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | | ]
| | | | | | keywords=[]
| | | | | | ___pyct_anno={ORIGIN: def_function.py:605:15, ARGS_SCOPE: Scope{r=(initialize_variables_scope.callopts, object_identity, object_identity.ObjectIdentityDictionary, initialize_variables_scope), w=()}}
| | | | | ___pyct_anno={ORIGIN: def_function.py:605:6, SCOPE: Scope{r=(object_identity.ObjectIdentityDictionary, ag__, object_identity, initialize_variables_scope, ag__.converted_call, initialize_variables_scope.callopts), w=(op_map,)}, LIVE_VARS_IN: frozenset({ops, object_identity.ObjectIdentityDictionary, object_identity, ops.init_scope, ag__.for_stmt, initializer_map, resource_variable_ops.var_is_initialized_op, initializer_map.items, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, initialize_variables_scope, ag__.converted_call, v.handle, v.assign})}
| | | | FunctionDef:
| | | | | name=u""get_state_2""
| | | | | args=arguments:
| | | | | | args=[]
| | | | | | vararg=None
| | | | | | kwonlyargs=[]
| | | | | | kw_defaults=[]
| | | | | | kwarg=None
| | | | | | defaults=[]
| | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}
| | | | | body=[
| | | | | | Return:
| | | | | | | value=Tuple:
| | | | | | | | elts=[]
| | | | | | | | ctx=Load()
| | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset()}
| | | | | ]
| | | | | decorator_list=[]
| | | | | returns=None
| | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(get_state_2,)}, BODY_SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset({ops, ops.init_scope, ag__.for_stmt, initializer_map, resource_variable_ops.var_is_initialized_op, initializer_map.items, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, initialize_variables_scope, op_map, ag__.converted_call, v.handle, v.assign})}
| | | | FunctionDef:
| | | | | name=u""set_state_2""
| | | | | args=arguments:
| | | | | | args=[
| | | | | | | Name:
| | | | | | | | id=u""_""
| | | | | | | | ctx=Param()
| | | | | | | | annotation=None
| | | | | | | | ___pyct_anno={QN: _, DEFINITIONS: (AnnotatedDef[767224408],)}
| | | | | | ]
| | | | | | vararg=None
| | | | | | kwonlyargs=[]
| | | | | | kw_defaults=[]
| | | | | | kwarg=None
| | | | | | defaults=[]
| | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=(_,)}}
| | | | | body=[
| | | | | | Pass:
| | | | | | | ___pyct_anno={LIVE_VARS_IN: frozenset()}
| | | | | ]
| | | | | decorator_list=[]
| | | | | returns=None
| | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(set_state_2,)}, BODY_SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, ops.init_scope, ag__.for_stmt, initializer_map, resource_variable_ops.var_is_initialized_op, initializer_map.items, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, get_state_2, ag__, resource_variable_ops, ag__.if_stmt, initialize_variables_scope, op_map, lift_to_graph, v.handle, v.assign})}
| | | | FunctionDef:
| | | | | name=u""loop_body""
| | | | | args=arguments:
| | | | | | args=[
| | | | | | | Name:
| | | | | | | | id=u""iterates""
| | | | | | | | ctx=Param()
| | | | | | | | annotation=None
| | | | | | | | ___pyct_anno={QN: iterates, DEFINITIONS: (AnnotatedDef[764742904],)}
| | | | | | | Name:
| | | | | | | | id=u""op_map""
| | | | | | | | ctx=Param()
| | | | | | | | annotation=None
| | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[764739824],)}
| | | | | | ]
| | | | | | vararg=None
| | | | | | kwonlyargs=[]
| | | | | | kw_defaults=[]
| | | | | | kwarg=None
| | | | | | defaults=[]
| | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=(op_map, iterates)}}
| | | | | body=[
| | | | | | Assign:
| | | | | | | targets=[
| | | | | | | | Tuple:
| | | | | | | | | elts=[
| | | | | | | | | | Name:
| | | | | | | | | | | id=u""v""
| | | | | | | | | | | ctx=Store()
| | | | | | | | | | | annotation=None
| | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764329320],), ORIGIN: def_function.py:606:10, QN: v, DEFINITIONS: (AnnotatedDef[764562792],)}
| | | | | | | | | | Name:
| | | | | | | | | | | id=u""init""
| | | | | | | | | | | ctx=Store()
| | | | | | | | | | | annotation=None
| | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764323320],), ORIGIN: def_function.py:606:13, QN: init, DEFINITIONS: (AnnotatedDef[767225528],)}
| | | | | | | | | ]
| | | | | | | | | ctx=Store()
| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:10}
| | | | | | | ]
| | | | | | | value=Name:
| | | | | | | | id=u""iterates""
| | | | | | | | ctx=Load()
| | | | | | | | annotation=None
| | | | | | | | ___pyct_anno={QN: iterates, DEFINITIONS: (AnnotatedDef[764742904],)}
| | | | | | | ___pyct_anno={SCOPE: Scope{r=(iterates,), w=(init, v)}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, ops.init_scope, resource_variable_ops.var_is_initialized_op, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, resource_variable_ops, ag__.if_stmt, initialize_variables_scope, op_map, lift_to_graph, v.handle, v.assign, iterates})}
| | | | | | Assign:
| | | | | | | targets=[
| | | | | | | | Name:
| | | | | | | | | id=u""continue_""
| | | | | | | | | ctx=Store()
| | | | | | | | | annotation=None
| | | | | | | | | ___pyct_anno={QN: continue_, DEFINITIONS: (AnnotatedDef[767225360],)}
| | | | | | | ]
| | | | | | | value=NameConstant:
| | | | | | | | value=False
| | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=(continue_,)}, LIVE_VARS_IN: frozenset({ops, ops.init_scope, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, ag__.converted_call, v.handle, v.assign})}
| | | | | | With:
| | | | | | | items=[
| | | | | | | | withitem:
| | | | | | | | | context_expr=Call:
| | | | | | | | | | func=Attribute:
| | | | | | | | | | | value=Name:
| | | | | | | | | | | | id=u""ops""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (), ORIGIN: def_function.py:607:13, QN: ops, DEFINITIONS: ()}
| | | | | | | | | | | attr=u""init_scope""
| | | | | | | | | | | ctx=Load()
| | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:607:13, QN: ops.init_scope}
| | | | | | | | | | args=[]
| | | | | | | | | | keywords=[]
| | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:607:13, ARGS_SCOPE: Scope{r=(), w=()}}
| | | | | | | | | optional_vars=None
| | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(ops, ops.init_scope), w=()}}
| | | | | | | ]
| | | | | | | body=[
| | | | | | | | FunctionDef:
| | | | | | | | | name=u""get_state""
| | | | | | | | | args=arguments:
| | | | | | | | | | args=[]
| | | | | | | | | | vararg=None
| | | | | | | | | | kwonlyargs=[]
| | | | | | | | | | kw_defaults=[]
| | | | | | | | | | kwarg=None
| | | | | | | | | | defaults=[]
| | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}
| | | | | | | | | body=[
| | | | | | | | | | Return:
| | | | | | | | | | | value=Tuple:
| | | | | | | | | | | | elts=[]
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset()}
| | | | | | | | | ]
| | | | | | | | | decorator_list=[]
| | | | | | | | | returns=None
| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:10, SCOPE: Scope{r=(), w=(get_state,)}, BODY_SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset({ops, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, ag__.converted_call, continue_, v.handle, v.assign})}
| | | | | | | | FunctionDef:
| | | | | | | | | name=u""set_state""
| | | | | | | | | args=arguments:
| | | | | | | | | | args=[
| | | | | | | | | | | Name:
| | | | | | | | | | | | id=u""_""
| | | | | | | | | | | | ctx=Param()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: _, DEFINITIONS: (AnnotatedDef[764743464],)}
| | | | | | | | | | ]
| | | | | | | | | | vararg=None
| | | | | | | | | | kwonlyargs=[]
| | | | | | | | | | kw_defaults=[]
| | | | | | | | | | kwarg=None
| | | | | | | | | | defaults=[]
| | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=(_,)}}
| | | | | | | | | body=[
| | | | | | | | | | Pass:
| | | | | | | | | | | ___pyct_anno={LIVE_VARS_IN: frozenset()}
| | | | | | | | | ]
| | | | | | | | | decorator_list=[]
| | | | | | | | | returns=None
| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:10, SCOPE: Scope{r=(), w=(set_state,)}, BODY_SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, lift_to_graph, continue_, get_state, v.handle, v.assign})}
| | | | | | | | FunctionDef:
| | | | | | | | | name=u""if_true""
| | | | | | | | | args=arguments:
| | | | | | | | | | args=[]
| | | | | | | | | | vararg=None
| | | | | | | | | | kwonlyargs=[]
| | | | | | | | | | kw_defaults=[]
| | | | | | | | | | kwarg=None
| | | | | | | | | | defaults=[]
| | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}
| | | | | | | | | body=[
| | | | | | | | | | Assign:
| | | | | | | | | | | targets=[
| | | | | | | | | | | | Name:
| | | | | | | | | | | | | id=u""continue_""
| | | | | | | | | | | | | ctx=Store()
| | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | ___pyct_anno={QN: continue_, DEFINITIONS: (AnnotatedDef[764740216],)}
| | | | | | | | | | | ]
| | | | | | | | | | | value=NameConstant:
| | | | | | | | | | | | value=True
| | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:610:12, SCOPE: Scope{r=(), w=(continue_,)}, LIVE_VARS_IN: frozenset()}
| | | | | | | | | | Return:
| | | | | | | | | | | value=Name:
| | | | | | | | | | | | id=u""continue_""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: continue_, DEFINITIONS: (AnnotatedDef[764740216],)}
| | | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(continue_,), w=()}, LIVE_VARS_IN: frozenset({continue_})}
| | | | | | | | | ]
| | | | | | | | | decorator_list=[]
| | | | | | | | | returns=None
| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:10, SCOPE: Scope{r=(), w=(if_true,)}, BODY_SCOPE: Scope{r=(continue_,), w=(continue_,)}, LIVE_VARS_IN: frozenset({ops, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, ag__.converted_call, continue_, set_state, v.handle, v.assign, get_state})}
| | | | | | | | FunctionDef:
| | | | | | | | | name=u""if_false""
| | | | | | | | | args=arguments:
| | | | | | | | | | args=[]
| | | | | | | | | | vararg=None
| | | | | | | | | | kwonlyargs=[]
| | | | | | | | | | kw_defaults=[]
| | | | | | | | | | kwarg=None
| | | | | | | | | | defaults=[]
| | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}
| | | | | | | | | body=[
| | | | | | | | | | Return:
| | | | | | | | | | | value=Name:
| | | | | | | | | | | | id=u""continue_""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: continue_, DEFINITIONS: (AnnotatedDef[767225360],)}
| | | | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(continue_,), w=()}, LIVE_VARS_IN: frozenset({continue_})}
| | | | | | | | | ]
| | | | | | | | | decorator_list=[]
| | | | | | | | | returns=None
| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:10, SCOPE: Scope{r=(), w=(if_false,)}, BODY_SCOPE: Scope{r=(continue_,), w=()}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, if_true, ag__.not_, lift_to_graph.lift_to_graph, ag__, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, lift_to_graph, continue_, set_state, v.handle, v.assign, get_state})}
| | | | | | | | Assign:
| | | | | | | | | targets=[
| | | | | | | | | | Name:
| | | | | | | | | | | id=u""cond""
| | | | | | | | | | | ctx=Store()
| | | | | | | | | | | annotation=None
| | | | | | | | | | | ___pyct_anno={QN: cond, DEFINITIONS: (AnnotatedDef[767225416],)}
| | | | | | | | | ]
| | | | | | | | | value=Call:
| | | | | | | | | | func=Attribute:
| | | | | | | | | | | value=Name:
| | | | | | | | | | | | id=u""ag__""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}
| | | | | | | | | | | attr=u""converted_call""
| | | | | | | | | | | ctx=Load()
| | | | | | | | | | | ___pyct_anno={QN: ag__.converted_call}
| | | | | | | | | | args=[
| | | | | | | | | | | Attribute:
| | | | | | | | | | | | value=Name:
| | | | | | | | | | | | | id=u""resource_variable_ops""
| | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (), ORIGIN: def_function.py:608:13, QN: resource_variable_ops, DEFINITIONS: ()}
| | | | | | | | | | | | attr=u""var_is_initialized_op""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:13, QN: resource_variable_ops.var_is_initialized_op}
| | | | | | | | | | | Attribute:
| | | | | | | | | | | | value=Name:
| | | | | | | | | | | | | id=u""initialize_variables_scope""
| | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | | | | | | | | attr=u""callopts""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope.callopts}
| | | | | | | | | | | Tuple:
| | | | | | | | | | | | elts=[
| | | | | | | | | | | | | Attribute:
| | | | | | | | | | | | | | value=Name:
| | | | | | | | | | | | | | | id=u""v""
| | | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764329320],), ORIGIN: def_function.py:608:57, QN: v, DEFINITIONS: (AnnotatedDef[764562792],)}
| | | | | | | | | | | | | | attr=u""handle""
| | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:57, QN: v.handle}
| | | | | | | | | | | | ]
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | NameConstant:
| | | | | | | | | | | | value=None
| | | | | | | | | | | Name:
| | | | | | | | | | | | id=u""initialize_variables_scope""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | | | | | | ]
| | | | | | | | | | keywords=[]
| | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:13, ARGS_SCOPE: Scope{r=(resource_variable_ops, v, initialize_variables_scope, resource_variable_ops.var_is_initialized_op, v.handle, initialize_variables_scope.callopts), w=()}}
| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:10, SCOPE: Scope{r=(ag__.converted_call, ag__, resource_variable_ops, v, initialize_variables_scope, resource_variable_ops.var_is_initialized_op, v.handle, initialize_variables_scope.callopts), w=(cond,)}, LIVE_VARS_IN: frozenset({ops, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, if_false, op_map_1[init], ops.get_default_graph, if_true, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, ag__.converted_call, set_state, v.handle, v.assign, get_state})}
| | | | | | | | Assign:
| | | | | | | | | targets=[
| | | | | | | | | | Name:
| | | | | | | | | | | id=u""continue_""
| | | | | | | | | | | ctx=Store()
| | | | | | | | | | | annotation=None
| | | | | | | | | | | ___pyct_anno={QN: continue_, DEFINITIONS: (AnnotatedDef[764785776],)}
| | | | | | | | | ]
| | | | | | | | | value=Call:
| | | | | | | | | | func=Attribute:
| | | | | | | | | | | value=Name:
| | | | | | | | | | | | id=u""ag__""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}
| | | | | | | | | | | attr=u""if_stmt""
| | | | | | | | | | | ctx=Load()
| | | | | | | | | | | ___pyct_anno={QN: ag__.if_stmt}
| | | | | | | | | | args=[
| | | | | | | | | | | Name:
| | | | | | | | | | | | id=u""cond""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: cond, DEFINITIONS: (AnnotatedDef[767225416],)}
| | | | | | | | | | | Name:
| | | | | | | | | | | | id=u""if_true""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: if_true, DEFINITIONS: (AnnotatedDef[767223904],)}
| | | | | | | | | | | Name:
| | | | | | | | | | | | id=u""if_false""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: if_false, DEFINITIONS: (AnnotatedDef[767223176],)}
| | | | | | | | | | | Name:
| | | | | | | | | | | | id=u""get_state""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: get_state, DEFINITIONS: (AnnotatedDef[764560608],)}
| | | | | | | | | | | Name:
| | | | | | | | | | | | id=u""set_state""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: set_state, DEFINITIONS: (AnnotatedDef[767225472],)}
| | | | | | | | | | | Tuple:
| | | | | | | | | | | | elts=[
| | | | | | | | | | | | | Str:
| | | | | | | | | | | | | | s=u""continue_""
| | | | | | | | | | | | ]
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | Tuple:
| | | | | | | | | | | | elts=[]
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | ]
| | | | | | | | | | keywords=[]
| | | | | | | | | | ___pyct_anno={ARGS_SCOPE: Scope{r=(if_true, cond, set_state, get_state, if_false), w=()}}
| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:608:10, SCOPE: Scope{r=(if_true, cond, ag__, set_state, ag__.if_stmt, get_state, if_false), w=(continue_,)}, LIVE_VARS_IN: frozenset({ops, cond, init, initialize_variables_scope.callopts, if_false, op_map_1[init], ops.get_default_graph, if_true, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, ag__.if_stmt, initialize_variables_scope, v, op_map, ag__.converted_call, set_state, v.assign, get_state})}
| | | | | | | ]
| | | | | | | ___pyct_anno={ORIGIN: def_function.py:607:8, BODY_SCOPE: Scope{r=(if_true, ops, ag__.converted_call, ag__, cond, resource_variable_ops, set_state, ag__.if_stmt, ops.init_scope, initialize_variables_scope, v, resource_variable_ops.var_is_initialized_op, continue_, get_state, v.handle, initialize_variables_scope.callopts, if_false), w=(if_true, cond, set_state, continue_, get_state, if_false)}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, ops.init_scope, resource_variable_ops.var_is_initialized_op, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, resource_variable_ops, ag__.if_stmt, v, initialize_variables_scope, op_map, lift_to_graph, continue_, v.handle, v.assign})}
| | | | | | FunctionDef:
| | | | | | | name=u""get_state_1""
| | | | | | | args=arguments:
| | | | | | | | args=[]
| | | | | | | | vararg=None
| | | | | | | | kwonlyargs=[]
| | | | | | | | kw_defaults=[]
| | | | | | | | kwarg=None
| | | | | | | | defaults=[]
| | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}
| | | | | | | body=[
| | | | | | | | Return:
| | | | | | | | | value=Tuple:
| | | | | | | | | | elts=[]
| | | | | | | | | | ctx=Load()
| | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset()}
| | | | | | | ]
| | | | | | | decorator_list=[]
| | | | | | | returns=None
| | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(get_state_1,)}, BODY_SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, ag__.if_stmt, initialize_variables_scope, v, op_map, lift_to_graph, continue_, v.assign})}
| | | | | | FunctionDef:
| | | | | | | name=u""set_state_1""
| | | | | | | args=arguments:
| | | | | | | | args=[
| | | | | | | | | Name:
| | | | | | | | | | id=u""_""
| | | | | | | | | | ctx=Param()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: _, DEFINITIONS: (AnnotatedDef[767302736],)}
| | | | | | | | ]
| | | | | | | | vararg=None
| | | | | | | | kwonlyargs=[]
| | | | | | | | kw_defaults=[]
| | | | | | | | kwarg=None
| | | | | | | | defaults=[]
| | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=(_,)}}
| | | | | | | body=[
| | | | | | | | Pass:
| | | | | | | | | ___pyct_anno={LIVE_VARS_IN: frozenset()}
| | | | | | | ]
| | | | | | | decorator_list=[]
| | | | | | | returns=None
| | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(set_state_1,)}, BODY_SCOPE: Scope{r=(), w=()}, LIVE_VARS_IN: frozenset({ops, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, lift_to_graph, ag__.if_stmt, initialize_variables_scope, v, op_map, get_state_1, ag__.converted_call, continue_, v.assign})}
| | | | | | FunctionDef:
| | | | | | | name=u""if_true_1""
| | | | | | | args=arguments:
| | | | | | | | args=[]
| | | | | | | | vararg=None
| | | | | | | | kwonlyargs=[]
| | | | | | | | kw_defaults=[]
| | | | | | | | kwarg=None
| | | | | | | | defaults=[]
| | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}
| | | | | | | body=[
| | | | | | | | Assign:
| | | | | | | | | targets=[
| | | | | | | | | | Tuple:
| | | | | | | | | | | elts=[
| | | | | | | | | | | | Name:
| | | | | | | | | | | | | id=u""op_map_1""
| | | | | | | | | | | | | ctx=Store()
| | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | ___pyct_anno={QN: op_map_1, DEFINITIONS: (AnnotatedDef[764640168],)}
| | | | | | | | | | | ]
| | | | | | | | | | | ctx=Store()
| | | | | | | | | ]
| | | | | | | | | value=Tuple:
| | | | | | | | | | elts=[
| | | | | | | | | | | Name:
| | | | | | | | | | | | id=u""op_map""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[764739824],)}
| | | | | | | | | | ]
| | | | | | | | | | ctx=Load()
| | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(op_map,), w=(op_map_1,)}, LIVE_VARS_IN: frozenset({lift_to_graph.lift_to_graph, ops, ag__, lift_to_graph, initialize_variables_scope, v, op_map, initialize_variables_scope.callopts, ag__.converted_call, init, op_map_1[init], v.assign, ops.get_default_graph})}
| | | | | | | | Assign:
| | | | | | | | | targets=[
| | | | | | | | | | Name:
| | | | | | | | | | | id=u""op_map_1""
| | | | | | | | | | | ctx=Store()
| | | | | | | | | | | annotation=None
| | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764329152],), ORIGIN: def_function.py:611:8, QN: op_map_1, DEFINITIONS: (AnnotatedDef[764641120],)}
| | | | | | | | | ]
| | | | | | | | | value=Call:
| | | | | | | | | | func=Attribute:
| | | | | | | | | | | value=Name:
| | | | | | | | | | | | id=u""ag__""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}
| | | | | | | | | | | attr=u""converted_call""
| | | | | | | | | | | ctx=Load()
| | | | | | | | | | | ___pyct_anno={QN: ag__.converted_call}
| | | | | | | | | | args=[
| | | | | | | | | | | Attribute:
| | | | | | | | | | | | value=Name:
| | | | | | | | | | | | | id=u""lift_to_graph""
| | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (), ORIGIN: def_function.py:611:17, QN: lift_to_graph, DEFINITIONS: ()}
| | | | | | | | | | | | attr=u""lift_to_graph""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:611:17, QN: lift_to_graph.lift_to_graph}
| | | | | | | | | | | Attribute:
| | | | | | | | | | | | value=Name:
| | | | | | | | | | | | | id=u""initialize_variables_scope""
| | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | | | | | | | | attr=u""callopts""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope.callopts}
| | | | | | | | | | | Tuple:
| | | | | | | | | | | | elts=[
| | | | | | | | | | | | | List:
| | | | | | | | | | | | | | elts=[
| | | | | | | | | | | | | | | Name:
| | | | | | | | | | | | | | | | id=u""init""
| | | | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764323320],), ORIGIN: def_function.py:612:13, QN: init, DEFINITIONS: (AnnotatedDef[767225528],)}
| | | | | | | | | | | | | | ]
| | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:612:12}
| | | | | | | | | | | | | Call:
| | | | | | | | | | | | | | func=Attribute:
| | | | | | | | | | | | | | | value=Name:
| | | | | | | | | | | | | | | | id=u""ag__""
| | | | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}
| | | | | | | | | | | | | | | attr=u""converted_call""
| | | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | | ___pyct_anno={QN: ag__.converted_call}
| | | | | | | | | | | | | | args=[
| | | | | | | | | | | | | | | Attribute:
| | | | | | | | | | | | | | | | value=Name:
| | | | | | | | | | | | | | | | | id=u""ops""
| | | | | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (), ORIGIN: def_function.py:612:20, QN: ops, DEFINITIONS: ()}
| | | | | | | | | | | | | | | | attr=u""get_default_graph""
| | | | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:612:20, QN: ops.get_default_graph}
| | | | | | | | | | | | | | | Attribute:
| | | | | | | | | | | | | | | | value=Name:
| | | | | | | | | | | | | | | | | id=u""initialize_variables_scope""
| | | | | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | | | | | | | | | | | | attr=u""callopts""
| | | | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope.callopts}
| | | | | | | | | | | | | | | Tuple:
| | | | | | | | | | | | | | | | elts=[]
| | | | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | | NameConstant:
| | | | | | | | | | | | | | | | value=None
| | | | | | | | | | | | | | | Name:
| | | | | | | | | | | | | | | | id=u""initialize_variables_scope""
| | | | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | | | | | | | | | | ]
| | | | | | | | | | | | | | keywords=[]
| | | | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:612:20, ARGS_SCOPE: Scope{r=(ops, initialize_variables_scope.callopts, ops.get_default_graph, initialize_variables_scope), w=()}}
| | | | | | | | | | | | ]
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | Dict:
| | | | | | | | | | | | keys=[
| | | | | | | | | | | | | Str:
| | | | | | | | | | | | | | s=u""op_map""
| | | | | | | | | | | | ]
| | | | | | | | | | | | values=[
| | | | | | | | | | | | | Name:
| | | | | | | | | | | | | | id=u""op_map_1""
| | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764329152], AnnotatedDef[764323152]), ORIGIN: def_function.py:612:52, QN: op_map_1, DEFINITIONS: (AnnotatedDef[764640168],)}
| | | | | | | | | | | | ]
| | | | | | | | | | | Name:
| | | | | | | | | | | | id=u""initialize_variables_scope""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | | | | | | ]
| | | | | | | | | | keywords=[]
| | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:611:17, ARGS_SCOPE: Scope{r=(lift_to_graph.lift_to_graph, ops, ag__.converted_call, ag__, op_map_1, initialize_variables_scope, lift_to_graph, init, initialize_variables_scope.callopts, ops.get_default_graph), w=()}}
| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:611:8, SCOPE: Scope{r=(lift_to_graph.lift_to_graph, ops, ag__.converted_call, ag__, op_map_1, initialize_variables_scope, lift_to_graph, init, initialize_variables_scope.callopts, ops.get_default_graph), w=(op_map_1,)}, LIVE_VARS_IN: frozenset({lift_to_graph.lift_to_graph, ops, ag__.converted_call, ag__, op_map_1[init], v.assign, op_map_1, initialize_variables_scope, v, lift_to_graph, init, initialize_variables_scope.callopts, ops.get_default_graph})}
| | | | | | | | Expr:
| | | | | | | | | value=Call:
| | | | | | | | | | func=Attribute:
| | | | | | | | | | | value=Name:
| | | | | | | | | | | | id=u""ag__""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}
| | | | | | | | | | | attr=u""converted_call""
| | | | | | | | | | | ctx=Load()
| | | | | | | | | | | ___pyct_anno={QN: ag__.converted_call}
| | | | | | | | | | args=[
| | | | | | | | | | | Attribute:
| | | | | | | | | | | | value=Name:
| | | | | | | | | | | | | id=u""v""
| | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764329320],), ORIGIN: def_function.py:613:8, QN: v, DEFINITIONS: (AnnotatedDef[764562792],)}
| | | | | | | | | | | | attr=u""assign""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:613:8, QN: v.assign}
| | | | | | | | | | | Attribute:
| | | | | | | | | | | | value=Name:
| | | | | | | | | | | | | id=u""initialize_variables_scope""
| | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | | | | | | | | attr=u""callopts""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope.callopts}
| | | | | | | | | | | Tuple:
| | | | | | | | | | | | elts=[
| | | | | | | | | | | | | Subscript:
| | | | | | | | | | | | | | value=Name:
| | | | | | | | | | | | | | | id=u""op_map_1""
| | | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764329152],), ORIGIN: def_function.py:613:17, QN: op_map_1, DEFINITIONS: (AnnotatedDef[764641120],)}
| | | | | | | | | | | | | | slice=Index:
| | | | | | | | | | | | | | | value=Name:
| | | | | | | | | | | | | | | | id=u""init""
| | | | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | | | annotation=None
| | | | | | | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (AnnotatedDef[764323320],), ORIGIN: def_function.py:613:24, QN: init, DEFINITIONS: (AnnotatedDef[767225528],)}
| | | | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:613:17, QN: op_map_1[init]}
| | | | | | | | | | | | ]
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | NameConstant:
| | | | | | | | | | | | value=None
| | | | | | | | | | | Name:
| | | | | | | | | | | | id=u""initialize_variables_scope""
| | | | | | | | | | | | ctx=Load()
| | | | | | | | | | | | annotation=None
| | | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | | | | | | ]
| | | | | | | | | | keywords=[]
| | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:613:8, ARGS_SCOPE: Scope{r=(op_map_1[init], op_map_1, initialize_variables_scope, v, init, initialize_variables_scope.callopts, v.assign), w=()}}
| | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:613:8, SCOPE: Scope{r=(ag__, op_map_1[init], op_map_1, initialize_variables_scope, v, ag__.converted_call, init, initialize_variables_scope.callopts, v.assign), w=()}, LIVE_VARS_OUT: frozenset({op_map_1}), LIVE_VARS_IN: frozenset({ag__, op_map_1[init], op_map_1, initialize_variables_scope, v, ag__.converted_call, init, initialize_variables_scope.callopts, v.assign})}
| | | | | | | | Return:
| | | | | | | | | value=Name:
| | | | | | | | | | id=u""op_map_1""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: op_map_1, DEFINITIONS: (AnnotatedDef[764641120],)}
| | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(op_map_1,), w=()}, LIVE_VARS_IN: frozenset({op_map_1})}
| | | | | | | ]
| | | | | | | decorator_list=[]
| | | | | | | returns=None
| | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(if_true_1,)}, BODY_SCOPE: Scope{r=(lift_to_graph.lift_to_graph, ops, ag__.converted_call, ag__, v.assign, op_map_1[init], op_map_1, initialize_variables_scope, v, op_map, lift_to_graph, init, initialize_variables_scope.callopts, ops.get_default_graph), w=(op_map_1,)}, LIVE_VARS_IN: frozenset({ops, ag__.converted_call, set_state_1, init, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, ag__.if_stmt, initialize_variables_scope, v, op_map, get_state_1, lift_to_graph, continue_, v.assign})}
| | | | | | FunctionDef:
| | | | | | | name=u""if_false_1""
| | | | | | | args=arguments:
| | | | | | | | args=[]
| | | | | | | | vararg=None
| | | | | | | | kwonlyargs=[]
| | | | | | | | kw_defaults=[]
| | | | | | | | kwarg=None
| | | | | | | | defaults=[]
| | | | | | | | ___pyct_anno={SCOPE: Scope{r=(), w=()}}
| | | | | | | body=[
| | | | | | | | Return:
| | | | | | | | | value=Name:
| | | | | | | | | | id=u""op_map""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[764739824],)}
| | | | | | | | | ___pyct_anno={SCOPE: Scope{r=(op_map,), w=()}, LIVE_VARS_IN: frozenset({op_map})}
| | | | | | | ]
| | | | | | | decorator_list=[]
| | | | | | | returns=None
| | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(if_false_1,)}, BODY_SCOPE: Scope{r=(op_map,), w=()}, LIVE_VARS_IN: frozenset({ag__.not_, if_true_1, ag__, set_state_1, ag__.if_stmt, get_state_1, op_map, continue_})}
| | | | | | Assign:
| | | | | | | targets=[
| | | | | | | | Name:
| | | | | | | | | id=u""cond_1""
| | | | | | | | | ctx=Store()
| | | | | | | | | annotation=None
| | | | | | | | | ___pyct_anno={QN: cond_1, DEFINITIONS: (AnnotatedDef[764788296],)}
| | | | | | | ]
| | | | | | | value=Call:
| | | | | | | | func=Attribute:
| | | | | | | | | value=Name:
| | | | | | | | | | id=u""ag__""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}
| | | | | | | | | attr=u""not_""
| | | | | | | | | ctx=Load()
| | | | | | | | | ___pyct_anno={QN: ag__.not_}
| | | | | | | | args=[
| | | | | | | | | Name:
| | | | | | | | | | id=u""continue_""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: continue_, DEFINITIONS: (AnnotatedDef[764785776],)}
| | | | | | | | ]
| | | | | | | | keywords=[]
| | | | | | | | ___pyct_anno={ARGS_SCOPE: Scope{r=(continue_,), w=()}}
| | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(ag__, continue_, ag__.not_), w=(cond_1,)}, LIVE_VARS_IN: frozenset({ag__.not_, if_true_1, ag__, set_state_1, ag__.if_stmt, get_state_1, if_false_1, continue_})}
| | | | | | Assign:
| | | | | | | targets=[
| | | | | | | | Name:
| | | | | | | | | id=u""op_map""
| | | | | | | | | ctx=Store()
| | | | | | | | | annotation=None
| | | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[764562848],)}
| | | | | | | ]
| | | | | | | value=Call:
| | | | | | | | func=Attribute:
| | | | | | | | | value=Name:
| | | | | | | | | | id=u""ag__""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}
| | | | | | | | | attr=u""if_stmt""
| | | | | | | | | ctx=Load()
| | | | | | | | | ___pyct_anno={QN: ag__.if_stmt}
| | | | | | | | args=[
| | | | | | | | | Name:
| | | | | | | | | | id=u""cond_1""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: cond_1, DEFINITIONS: (AnnotatedDef[764788296],)}
| | | | | | | | | Name:
| | | | | | | | | | id=u""if_true_1""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: if_true_1, DEFINITIONS: (AnnotatedDef[764786224],)}
| | | | | | | | | Name:
| | | | | | | | | | id=u""if_false_1""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: if_false_1, DEFINITIONS: (AnnotatedDef[764788576],)}
| | | | | | | | | Name:
| | | | | | | | | | id=u""get_state_1""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: get_state_1, DEFINITIONS: (AnnotatedDef[764787344],)}
| | | | | | | | | Name:
| | | | | | | | | | id=u""set_state_1""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: set_state_1, DEFINITIONS: (AnnotatedDef[764787960],)}
| | | | | | | | | Tuple:
| | | | | | | | | | elts=[
| | | | | | | | | | | Str:
| | | | | | | | | | | | s=u""op_map""
| | | | | | | | | | ]
| | | | | | | | | | ctx=Load()
| | | | | | | | | Tuple:
| | | | | | | | | | elts=[]
| | | | | | | | | | ctx=Load()
| | | | | | | | ]
| | | | | | | | keywords=[]
| | | | | | | | ___pyct_anno={ARGS_SCOPE: Scope{r=(if_true_1, set_state_1, get_state_1, if_false_1, cond_1), w=()}}
| | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(if_true_1, set_state_1, ag__, ag__.if_stmt, get_state_1, if_false_1, cond_1), w=(op_map,)}, LIVE_VARS_IN: frozenset({cond_1, if_true_1, if_false_1, set_state_1, ag__, ag__.if_stmt, get_state_1})}
| | | | | | Return:
| | | | | | | value=Tuple:
| | | | | | | | elts=[
| | | | | | | | | Name:
| | | | | | | | | | id=u""op_map""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[764562848],)}
| | | | | | | | ]
| | | | | | | | ctx=Load()
| | | | | | | ___pyct_anno={SCOPE: Scope{r=(op_map,), w=()}, LIVE_VARS_IN: frozenset({op_map})}
| | | | | ]
| | | | | decorator_list=[]
| | | | | returns=None
| | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(), w=(loop_body,)}, BODY_SCOPE: Scope{r=(ops, if_true_1, cond, op_map_1, ops.init_scope, init, initialize_variables_scope.callopts, if_false, if_true, ag__, ag__.if_stmt, initialize_variables_scope, v, op_map, get_state_1, lift_to_graph, if_false_1, set_state, v.assign, iterates, set_state_1, resource_variable_ops.var_is_initialized_op, cond_1, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, resource_variable_ops, ag__.converted_call, continue_, get_state, v.handle), w=(if_true, continue_, if_true_1, cond, set_state_1, set_state, v, get_state_1, op_map, if_false_1, cond_1, init, get_state, if_false)}, LIVE_VARS_IN: frozenset({ops, ops.init_scope, set_state_2, ag__.for_stmt, initializer_map, resource_variable_ops.var_is_initialized_op, initializer_map.items, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, get_state_2, ag__, lift_to_graph, resource_variable_ops, ag__.if_stmt, initialize_variables_scope, op_map, ag__.converted_call, v.handle, v.assign})}
| | | | Assign:
| | | | | targets=[
| | | | | | Tuple:
| | | | | | | elts=[
| | | | | | | | Name:
| | | | | | | | | id=u""op_map""
| | | | | | | | | ctx=Store()
| | | | | | | | | annotation=None
| | | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[767039808],)}
| | | | | | | ]
| | | | | | | ctx=Store()
| | | | | ]
| | | | | value=Call:
| | | | | | func=Attribute:
| | | | | | | value=Name:
| | | | | | | | id=u""ag__""
| | | | | | | | ctx=Load()
| | | | | | | | annotation=None
| | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}
| | | | | | | attr=u""for_stmt""
| | | | | | | ctx=Load()
| | | | | | | ___pyct_anno={QN: ag__.for_stmt}
| | | | | | args=[
| | | | | | | Call:
| | | | | | | | func=Attribute:
| | | | | | | | | value=Name:
| | | | | | | | | | id=u""ag__""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: ag__, DEFINITIONS: ()}
| | | | | | | | | attr=u""converted_call""
| | | | | | | | | ctx=Load()
| | | | | | | | | ___pyct_anno={QN: ag__.converted_call}
| | | | | | | | args=[
| | | | | | | | | Attribute:
| | | | | | | | | | value=Name:
| | | | | | | | | | | id=u""initializer_map""
| | | | | | | | | | | ctx=Load()
| | | | | | | | | | | annotation=None
| | | | | | | | | | | ___pyct_anno={ORIG_DEFINITIONS: (), ORIGIN: def_function.py:606:21, QN: initializer_map, DEFINITIONS: ()}
| | | | | | | | | | attr=u""items""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:21, QN: initializer_map.items}
| | | | | | | | | Attribute:
| | | | | | | | | | value=Name:
| | | | | | | | | | | id=u""initialize_variables_scope""
| | | | | | | | | | | ctx=Load()
| | | | | | | | | | | annotation=None
| | | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | | | | | | attr=u""callopts""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope.callopts}
| | | | | | | | | Tuple:
| | | | | | | | | | elts=[]
| | | | | | | | | | ctx=Load()
| | | | | | | | | NameConstant:
| | | | | | | | | | value=None
| | | | | | | | | Name:
| | | | | | | | | | id=u""initialize_variables_scope""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: initialize_variables_scope, DEFINITIONS: (AnnotatedDef[766997784],)}
| | | | | | | | ]
| | | | | | | | keywords=[]
| | | | | | | | ___pyct_anno={ORIGIN: def_function.py:606:21, ARGS_SCOPE: Scope{r=(initializer_map.items, initialize_variables_scope.callopts, initializer_map, initialize_variables_scope), w=()}}
| | | | | | | NameConstant:
| | | | | | | | value=None
| | | | | | | Name:
| | | | | | | | id=u""loop_body""
| | | | | | | | ctx=Load()
| | | | | | | | annotation=None
| | | | | | | | ___pyct_anno={QN: loop_body, DEFINITIONS: (AnnotatedDef[766998064],)}
| | | | | | | Name:
| | | | | | | | id=u""get_state_2""
| | | | | | | | ctx=Load()
| | | | | | | | annotation=None
| | | | | | | | ___pyct_anno={QN: get_state_2, DEFINITIONS: (AnnotatedDef[766999576],)}
| | | | | | | Name:
| | | | | | | | id=u""set_state_2""
| | | | | | | | ctx=Load()
| | | | | | | | annotation=None
| | | | | | | | ___pyct_anno={QN: set_state_2, DEFINITIONS: (AnnotatedDef[767000416],)}
| | | | | | | Tuple:
| | | | | | | | elts=[
| | | | | | | | | Name:
| | | | | | | | | | id=u""op_map""
| | | | | | | | | | ctx=Load()
| | | | | | | | | | annotation=None
| | | | | | | | | | ___pyct_anno={QN: op_map, DEFINITIONS: (AnnotatedDef[766997112],)}
| | | | | | | | ]
| | | | | | | | ctx=Load()
| | | | | | | Tuple:
| | | | | | | | elts=[
| | | | | | | | | Str:
| | | | | | | | | | s=u""op_map""
| | | | | | | | ]
| | | | | | | | ctx=Load()
| | | | | | | Tuple:
| | | | | | | | elts=[]
| | | | | | | | ctx=Load()
| | | | | | ]
| | | | | | keywords=[]
| | | | | | ___pyct_anno={ARGS_SCOPE: Scope{r=(get_state_2, ag__, initialize_variables_scope, loop_body, set_state_2, op_map, initializer_map, ag__.converted_call, initializer_map.items, initialize_variables_scope.callopts), w=()}}
| | | | | ___pyct_anno={ORIGIN: def_function.py:606:6, SCOPE: Scope{r=(get_state_2, ag__, initialize_variables_scope, loop_body, set_state_2, op_map, ag__.for_stmt, initializer_map, ag__.converted_call, initializer_map.items, initialize_variables_scope.callopts), w=(op_map,)}, LIVE_VARS_IN: frozenset({get_state_2, ag__, initialize_variables_scope, loop_body, set_state_2, op_map, ag__.for_stmt, initializer_map, ag__.converted_call, initializer_map.items, initialize_variables_scope.callopts})}
| | | ]
| | | ___pyct_anno={BODY_SCOPE: Scope{r=(ops, object_identity.ObjectIdentityDictionary, if_true_1, cond, op_map_1, ops.init_scope, set_state_2, initializer_map, init, initializer_map.items, initialize_variables_scope.callopts, if_false, if_true, ag__, ag__.if_stmt, initialize_variables_scope, v, op_map, get_state_1, lift_to_graph, if_false_1, set_state, v.assign, iterates, set_state_1, object_identity, loop_body, ag__.for_stmt, resource_variable_ops.var_is_initialized_op, cond_1, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, get_state_2, resource_variable_ops, ag__.ConversionOptions, ag__.converted_call, continue_, ag__.FunctionScope, get_state, v.handle), w=(get_state_2, set_state_2, loop_body, op_map, initialize_variables_scope)}, LIVE_VARS_IN: frozenset({ops, object_identity.ObjectIdentityDictionary, ag__.converted_call, object_identity, ops.init_scope, ag__.for_stmt, initializer_map, resource_variable_ops.var_is_initialized_op, initializer_map.items, initialize_variables_scope.callopts, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, ag__, resource_variable_ops, ag__.if_stmt, ag__.ConversionOptions, lift_to_graph, ag__.FunctionScope, v.handle, v.assign})}
| ]
| decorator_list=[]
| returns=None
| ___pyct_anno={'lineno': 4, ORIGIN: def_function.py:603:4, SCOPE: Scope{r=(), w=(initialize_variables,)}, BODY_SCOPE: Scope{r=(ops, object_identity.ObjectIdentityDictionary, if_true_1, cond, op_map_1, ops.init_scope, set_state_2, initializer_map, init, initializer_map.items, initialize_variables_scope.callopts, if_false, if_true, ag__, ag__.if_stmt, initialize_variables_scope, v, op_map, get_state_1, lift_to_graph, if_false_1, set_state, v.assign, iterates, set_state_1, object_identity, loop_body, ag__.for_stmt, resource_variable_ops.var_is_initialized_op, cond_1, op_map_1[init], ops.get_default_graph, ag__.not_, lift_to_graph.lift_to_graph, get_state_2, resource_variable_ops, ag__.ConversionOptions, ag__.converted_call, continue_, ag__.FunctionScope, get_state, v.handle), w=(get_state_2, set_state_2, loop_body, op_map, initialize_variables_scope)}, 'function_context_name': 'initialize_variables_scope'}



INFO:tensorflow:Defaults of <function create_converted_entity_factory.<locals>.create_converted_entity.<locals>.tf__initialize_variables at 0x000000002D8DAE18> : None
INFO:tensorflow:KW defaults of <function create_converted_entity_factory.<locals>.create_converted_entity.<locals>.tf__initialize_variables at 0x000000002D8DAE18> : None
INFO:tensorflow:Calling <function create_converted_entity_factory.<locals>.create_converted_entity.<locals>.tf__initialize_variables at 0x000000002D8DAE18> with


INFO:tensorflow:Converted call: <class 'tensorflow.python.util.object_identity.ObjectIdentityDictionary'>
    args: ()
    kwargs: None

INFO:tensorflow:Permanently whitelisted: <class 'tensorflow.python.util.object_identity.ObjectIdentityDictionary'>: constructor
INFO:tensorflow:Converted call: <bound method Mapping.items of ObjectIdentityDictionary({})>
    args: ()
    kwargs: None

INFO:tensorflow:Whitelisted: <bound method Mapping.items of ObjectIdentityDictionary({})>: DoNotConvert rule for collections
60000/60000 [==============================] - 4s 59us/sample - loss: 0.2964 - accuracy: 0.9143
<tensorflow.python.keras.callbacks.History object at 0x000000002D05D1D0>
"
33789, Model created by tf.keras.models.Model does not have attribute 'metrics_tensors',"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.14 and 2.0 (GPU)
- Python version: 3.6.1
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10/6.7.4
- GPU model and memory: RTX 2060

After switching to tf.keras from Keras I cannot append to metrics_tensors.
Code from https://github.com/matterport/Mask_RCNN
```
# Add metrics for losses
        for name in loss_names:
            if name in self.keras_model.metrics_names:
                continue
            layer = self.keras_model.get_layer(name)
            self.keras_model.metrics_names.append(name)
            loss = (
                tf.reduce_mean(layer.output, keepdims=True)
                * self.config.LOSS_WEIGHTS.get(name, 1.))
            self.keras_model.metrics_tensors.append(loss)
```
result:
```
  File ""C:\Project\mrcnn\model.py"", line 35, in build_mrcnn_network
    maskRcnn = MaskRCNN(mode, config, common_services, depth, service_version)
  File ""C:\Project\mrcnn\model.py"", line 52, in __init__
    self.compile()
  File ""C:\Project\mrcnn\model.py"", line 270, in compile
    self.keras_model.metrics_tensors.append(loss)
AttributeError: 'Model' object has no attribute 'metrics_tensors'
```"
33788,TFLiteConverter from_keras_model TypeError: call() got an unexpected keyword argument 'training',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Custom code
- Arch Linux Kernel 5.3.7
- TensorFlow installed via pip
- TensorFlow version v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.7.4

**Describe the current behavior**
When trying to convert a Keras CNN to TFlite file I get an error at the following line: `converter = tf.lite.TFLiteConverter.from_keras_model(model)`

**Describe the expected behavior**
A TFlite file is expected to be created and written to the local directory.

**Code to reproduce the issue**
```
# Importing the Keras libraries and packages
from keras.models import Sequential, save_model
from keras.layers.core import Dense, Dropout, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.preprocessing import image
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
import numpy as np

imageResX, imageResY = 256, 256

def CNNmodel():
	classifier = Sequential()
	classifier.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', input_shape=(imageResX, imageResY, 3)))
	classifier.add(MaxPooling2D(pool_size=(3,3)))
	classifier.add(Flatten())
	classifier.add(Dense(units=128, activation='relu'))
	classifier.add(Dropout(rate=0.5))
	classifier.add(Dense(units=4, activation='softmax'))
	classifier.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])
	return classifier

# create a data generators
train_datagen = image.ImageDataGenerator(rescale=1./255)
test_datagen = image.ImageDataGenerator(rescale=1./255) 

training_set = train_datagen.flow_from_directory('MY DATA/Training', target_size = (imageResX, imageResY), batch_size = 64, class_mode = 'categorical')
evaluate_set = train_datagen.flow_from_directory('MY DATA/Evaluation', target_size = (imageResX, imageResY), batch_size = 64, class_mode = 'categorical')
test_set = test_datagen.flow_from_directory('MY DATA/Testing', target_size = (imageResX, imageResY), batch_size = 64, class_mode = 'categorical', shuffle=False)

step_size_train=training_set.n//training_set.batch_size
step_size_evaluate=evaluate_set.n//evaluate_set.batch_size
step_size_test=test_set.n//test_set.batch_size

model = CNNmodel()
history = model.fit_generator(generator=training_set, steps_per_epoch=step_size_train, epochs=1, validation_data=evaluate_set, validation_steps=step_size_evaluate)

labels = (training_set.class_indices)
labels = dict((v,k) for k,v in labels.items())

# Save KERAS model
modelName = ""ST-AI-Model""
save_model(model, str(modelName+"".h5""))

# Convert KERAS model
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open(str(modelName+"".tflite""), ""wb"").write(tflite_model)

prediction = model.predict_generator(generator=test_set, verbose=1)
classes = test_set.classes[test_set.index_array]
predicted_class_indices = np.argmax(prediction, axis=1)
target_names = [labels[k] for k in range(len(training_set.class_indices))]


print('Confusion Matrix')
print(confusion_matrix(test_set.classes[test_set.index_array], predicted_class_indices))
print('Classification Report')
print(sum(predicted_class_indices==classes)/len(test_set.classes))
print(classification_report(test_set.classes[test_set.index_array], predicted_class_indices, target_names=target_names))
```

**Other info / logs**

> Traceback (most recent call last):
  File ""/home/user/code/classifier.py"", line 98, in <module>
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
  File ""/usr/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py"", line 383, in from_keras_model
    concrete_func = func.get_concrete_function()
  File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 776, in get_concrete_function
    self._initialize(args, kwargs, add_initializers_to=initializer_map)
  File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 408, in _initialize
    *args, **kwds))
  File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1848, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saving_utils.py"", line 143, in _wrapped_model
    outputs_list = nest.flatten(model(inputs=inputs, training=False))
  File ""/usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 75, in symbolic_fn_wrapper
    return func(*args, **kwargs)
  File ""/usr/lib/python3.7/site-packages/keras/engine/base_layer.py"", line 489, in __call__
    output = self.call(inputs, **kwargs)
TypeError: call() got an unexpected keyword argument 'training'
[Finished in 666.7s with exit code 1]"
33787,Using tf.keras.backend.zeros in while loops.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Arch Linux**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): **Binary**
- TensorFlow version (use command below): **2.0.0**
- Python version: **3.7**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: **N/A**
- GPU model and memory: **N/A**

**Describe the current behavior**
The effect of `tf.zeros` and `tf.keras.backend.zeros` is not the same and results in some inconsistent behaviour. This also holds for other functions such as `tf.keras.backend.ones` and others like it.

Specifically, using `tf.keras.backend.zeros` in a `tf.map_fn` function (or something similar) breaks because `tf.keras.backend.zeros` has a `tf.init_scope` which causes it to be created out of the context of the while loop.

**Describe the expected behavior**
Expected behaviour would be that `tf.zeros` and `tf.keras.backend.zeros` are identical and that they follow the usage of `tf.zeros`; meaning not changing the scope in which they are created.

**Code to reproduce the issue**
```python
import tensorflow as tf

tf.compat.v1.disable_v2_behavior()

# Works because we don't change the scope.
def works(inputs):
	return tf.zeros((tf.keras.backend.shape(inputs[0])[0],))

# Works because both tf.zeros and its inputs are in the same scope.
## This function helps explain the root of the issue.
def works2(inputs):
	with tf.init_scope():
		return tf.zeros((tf.keras.backend.shape(inputs[0])[0],))

# Breaks because tf.keras.backend.zeros is being created in a different scope from tf.keras.backend.shape.
def breaks(inputs):
	return tf.keras.backend.zeros((tf.keras.backend.shape(inputs[0])[0],))

# Breaks because the shape is created outside of the context of the tf.zeros.
## This function helps explain the root of the issue.
## This is an extract of how tf.keras.backend.zeros is implemented.
def breaks2(inputs):
	shape = (tf.keras.backend.shape(inputs[0])[0],)
	with tf.init_scope():
		return tf.zeros(shape)

inputs = [tf.keras.layers.Input(shape=(5, 5))]

# This works when using tf.zeros because it doesn't change the scope.
tf.map_fn(works, elems=inputs, dtype=tf.keras.backend.floatx())

# This works when tf.zeros and its inputs are in the same scope (using tf.init_scope).
tf.map_fn(works2, elems=inputs, dtype=tf.keras.backend.floatx())

# This breaks when using tf.keras.backend.zeros because it creates the zeros in a new scope.
try:
	tf.map_fn(breaks, elems=inputs, dtype=tf.keras.backend.floatx())
except ValueError as e:
	print(""Caught error: {}"".format(e))

# This breaks when using tf.zeros when its inputs are defined in a different scope.
try:
	tf.map_fn(breaks2, elems=inputs, dtype=tf.keras.backend.floatx())
except ValueError as e:
	print(""Caught error: {}"".format(e))
```

**Other info / logs**
This change was introduced in https://github.com/tensorflow/tensorflow/commit/1d91f3532ee4df36749dda1a39b8a2a78232dd74 by @rjpower . It would be great if I could get some feedback on why this `init_scope` got added there and if it should be changed."
33786,Cannot import tf.keras.engine,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.14 and 2.0 (gpu)
- Python version: 3.6.1
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10/6.7.4
- GPU model and memory: RTX 2060 6GB

After switching my code to tf.keras I cannot import tf.keras.engine:
with Keras:
```
import keras.layers as KL
import keras.models as KM
import keras.engine as KE
```
`>>>OK`


with tf.keras:
```
import tensorflow.keras.layers as KL
import tensorflow.keras.models as KM
import tensorflow.keras.engine as KE
```

```
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-2-004966c96ded> in <module>
      1 import tensorflow.keras.layers as KL
      2 import tensorflow.keras.models as KM
----> 3 import tensorflow.keras.engine as KE

ModuleNotFoundError: No module named 'tensorflow.keras.engine'
```


"
33785,The inheriting keras.layers.Layer does not call a compute_output_shape after switching to tf.keras from keras,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.14, 1.15 and 2.0 (gpu)
- Keras version: 2.2.4 and 2.2.4-tf
- Python version: 3.6.1
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10/6.7.4
- GPU model and memory: RTX 2060 6GB

You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` unknown 1.14.0

After switching to tf.keras from keras my project witch use Mask_RCNN does not work.
I noticed that TimeDistributed returns a different tensor shape in keras (1.) and tf.keras (2.):
1.` Tensor(""mrcnn_class_bn1/Reshape_1:0"", shape=(?, 1000, 1, 1, 256), dtype=float32)`
2. `Tensor(""mrcnn_class_bn1/Reshape_1:0"", shape=(?, ?, 1, 1, 256), dtype=float32)`

```
x = PyramidROIAlign([pool_size, pool_size], feature_levels,
                        name=""roi_align_classifier"")([rois, image_meta] + feature_maps)
x = KL.TimeDistributed(KL.Conv2D(fc_layers_size, (pool_size, pool_size), padding=""valid""),
                           name=""mrcnn_class_conv1"")(x)
```

where rois is generated by ProposalLayer from Mask_RCNN module (https://github.com/matterport/Mask_RCNN)

ProposalLayer inherits from the class keras.layers.Layer.
In Keras the overwritten function compute_output_shape is called, but not in the tf.keras.

Additionally, the rois created in the tf.keras does not have the parameter _keras_shape that is most likely needed in the function TimeDistributed to create a proper shape.
"
33784,tfp.sts.AutoregressiveStateSpaceModel noise mean should be settable,"**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

in tfp.sts.AutoregressiveStateSpaceModel you cant currently set the mean of the normally distributed noise. this would be nice to add as some auto-regressive models may add a constant term at each time step. the math would then be :

```python
level[t+1] = (sum(coefficients * levels[t:t-order:-1]) +
              Normal(level_mean, level_scale))
```

**Will this change the current api? How?**
this would require an additional parameter

**Who will benefit with this feature?**
people who want to do auto-regressive models with a constant term

**Any Other info.**
"
33782,Executing genrule @nccl_archive//:device_code_sm_61 failed (Exit 1): bash failed: error executing command ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.13
- **Python version**: 3.7
- **Bazel version (if compiling from source)**: 0.193
- **GCC/Compiler version (if compiling from source)**: 5.5
- **CUDA/cuDNN version**: 10.0/7
- **GPU model and memory**: GTX 1080Ti
- **Exact command to reproduce**: bazel build --spawn_strategy=standalone --verbose_failures --config=cuda --copt=""-fPIC"" --copt=""-DNDEBUG"" --local_resources 11048,2.0,2.0 -c dbg --copt -g //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
When I ran the upper command, I got the error as follows: nvlink fatal   : No input files specified; use option --help for more information
Hope someone could help me.

### Source code / logs
ERROR: /home/yunxiang/.cache/bazel/_bazel_yunxiang/6e00d14c3b41ff4ee29863f700329782/external/nccl_archive/BUILD.bazel:139:1: Executing genrule @nccl_archive//:device_code_sm_61 failed (Exit 1): bash failed: error executing command 
  (cd /home/yunxiang/.cache/bazel/_bazel_yunxiang/6e00d14c3b41ff4ee29863f700329782/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda \
    CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \
    LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64: \
    PATH=/home/yunxiang/.local/bin:/usr/local/python3.7/bin:/usr/local/cuda-10.0/bin:/home/yunxiang/bin:/home/yunxiang/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/python3.7/lib/python3.7/site-packages \
    TF_CUDA_CLANG=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=6.1 \
    TF_CUDA_VERSION=10.0 \
    TF_CUDNN_VERSION=7 \
    TF_NCCL_VERSION='' \
    TF_NEED_CUDA=1 \
    TF_NEED_OPENCL_SYCL=0 \
    TF_NEED_ROCM=0 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; external/local_config_nccl/nvlink --cpu-arch=X86_64 --arch=sm_61  --register-link-binaries=bazel-out/k8-dbg/genfiles/external/nccl_archive/device_code_sm_61.h --output-file=bazel-out/k8-dbg/genfiles/external/nccl_archive/device_code_sm_61.cubin')
nvlink fatal   : No input files specified; use option --help for more information
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 6494.760s, Critical Path: 459.04s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]
INFO: 13376 processes: 13376 local."
33780,core dump when call SetShapeFn in custom op under 2.0,
33779,tf 1.15.0  retrained ssdlite_mobilenet_v2_coco+focal loss to quantization,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu18.04
- TensorFlow installed from (source or binary):  source
- TensorFlow version (or github SHA if from source): 1.15.0


Step1:retrain ssdlite_mobilenet_v2_coco model using focal loss,get model.ckpt
Step2:using export_inference_graph.py to get frozen_inference_graph.pb and saved_model
Step3:using tflite 

```
import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model(path/to/saved_model_dir)
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
tflite_quant_model = converter.convert()
```

```
//error
array.data_type==array.final_data_type Array ""image_tensor"" has mis-matching .....(data_type=uint8,final_data_type=float)
```

Then, using `saved_model_cli show --dir=./saved_model --all` 

ouput is

```
signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['inputs'] tensor_info:
        dtype: DT_UINT8
        shape: (-1, -1, -1, 3)
        name: image_tensor:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['detection_boxes'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 100, 4)
        name: detection_boxes:0
    outputs['detection_classes'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 100)
        name: detection_classes:0
    outputs['detection_scores'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 100)
        name: detection_scores:0
    outputs['num_detections'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1)
        name: num_detections:0
  Method name is: tensorflow/serving/predict
```

1.Just means , my saved_model input is unit8 and output is float32, could not using tf-lite to quantization?
2. Could get ssd_mobilenet_v2 quantized model without config parameter,it means train again!!
`graph_rewriter {quantization {....}}`

"
33778,"Example of ""audio recognition"" trained in tf-1.15.0 isn't able to recognize sound ""Yes"" on SparkFun Edge development board.","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.
- TensorFlow installed from (source or binary):
Created a docker container from docker image: tensorflow/tensorflow:1.15.0-gpu-py3-jupyter.
Inside the container, got tensorflow source tree through the following steps:
```
mkdir tensorflow
cd tensorflow
git init
git remote add origin https://github.com/tensorflow/tensorflow.git
git ls-remote --tags origin | grep 1.15.0
38ea9bbfea423eb968fcc70bc454471277c9537c	refs/tags/v1.15.0
git pull origin refs/tags/v1.15.0
```
- TensorFlow version (use command below): v1.15.0.
- Python version: 3.6.8.
- Bazel version (if compiling from source): neither installed nor used. 
- GCC/Compiler version (if compiling from source): gcc version 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1). 
- CUDA/cuDNN version:  compute capability: 5.2. 
- GPU model and memory: GeForce GTX 960. 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

v1.15.0-rc3-22-g590d6ee 1.15.0

**Describe the current behavior**
Going through the following steps (for all the steps in details, please see **Code to reproduce the issue** ), SparkFun Edge board was be flashed successfully. But it wasn't able to recognize the sound “Yes” :-(

**Describe the expected behavior**
If flashing the board with [the binary tf model](tensorflow/tensorflow/lite/experimental/micro/examples/micro_speech/simple_features/tiny_conv_simple_features_model_data.cc) that tf source tree brings, the sound “Yes” was recognized perfectly.
Could you let us know the exact environment and procedure that your tiny_conv_simple_features_model_data.cc was generated in? 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
### 1, Training model (refer to [Training model on your local machine](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/micro_speech#use-your-local-machine)). 
#### 1.1, In the same container that we got in “**System information**”.
#### 1.2, 
```
python tensorflow/tensorflow/examples/speech_commands/train.py \
--model_architecture=tiny_conv --window_stride=20 --preprocess=micro \
--wanted_words=""yes,no"" --silence_percentage=25 --unknown_percentage=25 \
--quantize=1 --verbosity=INFO --how_many_training_steps=""15000,3000"" \
--learning_rate=""0.001,0.0001"" --summaries_dir=/tmp/retrain_logs \
--data_dir=/tmp/speech_dataset –train_dir=/tmp/speech_commands_train
```
The training reached ~90%  accuracy, see [191028.log](https://github.com/tensorflow/tensorflow/files/3778241/191028.log.tar.gz) as attached.

#### 1.3, 
```
python tensorflow/tensorflow/examples/speech_commands/freeze.py \
--model_architecture=tiny_conv --window_stride=20 --preprocess=micro \
--wanted_words=""yes,no"" --quantize=1 --output_file=/tmp/tiny_conv.pb \
--start_checkpoint=/tmp/speech_commands_train/tiny_conv.ckpt-18000
```
#### 1.4, 
```
toco \
--graph_def_file=/tmp/tiny_conv.pb --output_file=/tmp/tiny_conv.tflite \
--input_shapes=1,49,40,1 --input_arrays=Reshape_2 --output_arrays='labels_softmax' \
--inference_type=QUANTIZED_UINT8 --mean_values=0 --std_dev_values=9.8077
```
#### 1.5,   
```
xxd -i /tmp/tiny_conv.tflite > /tmp/tiny_conv_micro_features_model_data.cc
```
#### 1.6,
Modified the binary model file to [tiny_conv_micro_features_model_data.new.cc](https://github.com/tensorflow/tensorflow/files/3778266/tiny_conv_micro_features_model_data.new.cc.gz) as attached, put it into tensorflow/lite/experimental/micro/examples/micro_speech/micro_features
### 2, Flashed the model, (refer to [Deploy to SparkFun Edge](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/micro_speech#deploy-to-sparkfun-edge)).
#### 2.1, 
```
make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=sparkfun_edge TAGS=""CMSIS"" micro_speech_bin
```
#### 2.2, 
```
cp tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/keys_info0.py \
tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/keys_info.py
```
#### 2.3,
```
python3 tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/create_cust_image_blob.py \
--bin tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/micro_speech.bin \
--load-address 0xC000 \
--magic-num 0xCB \
-o main_nonsecure_ota \
--version 0x0
```
#### 2.4, 
```
python3 tensorflow/lite/experimental/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/create_cust_wireupdate_blob.py \
--load-address 0x20000 \
--bin main_nonsecure_ota.bin \
-i 6 \
-o main_nonsecure_wire \
--options 0x1
```
#### 2.5,
Walked through [AI on a microcontroller with TensorFlow Lite and SparkFun Edge](https://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#0), flashed our program and bootloader into the board. 
Test it then. 

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33777,Tensorflow Probability distributions HiddenMarkovModel not working with tf.function,"using tensorflow 2.0 on cpu

the following function works with no errors when executing in eager mode, but if it is decorated with `@tf.function` i get the error at the bottom.

```python
def generate_data(size, p_0, p_0_0, p_1_1, mu0, s0, mu1, s1):
    states = tfd.Categorical(probs=[p_0, 1-p_0])

    transition = tfd.Categorical(probs=[[p_0_0, 1 - p_0_0],
                                        [1 - p_1_1, p_1_1]])

    emission = tfd.Normal(loc=[mu0, mu1], scale=[s0, s1])

    model = tfd.HiddenMarkovModel(states, transition, emission, size)

    return model.sample()

data = generate_data(50, 0.01, 0.3, 0.7, -10, 2, 10, 3)

print(data)
```
and the error
```
traceback (most recent call last):
  File ""/home/abaka/Abaka.FIN.Apis/test.py"", line 21, in <module>
    data = generate_data(50, 0.01, 0.3, 0.7, -10, 2, 10, 3)
  File ""/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 503, in _call
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 408, in _initialize
    *args, **kwds))
  File ""/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1848, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/abaka/venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 905, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:
    relative to /home/abaka:

    Abaka.FIN.Apis/test.py:19 generate_data  *
        return model.sample()
    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_probability/python/distributions/distribution.py:848 sample
        return self._call_sample_n(sample_shape, seed, name, **kwargs)
    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_probability/python/distributions/distribution.py:826 _call_sample_n
        samples = self._sample_n(n, seed, **kwargs)
    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_probability/python/distributions/hidden_markov_model.py:406 _sample_n
        lambda: init_state[tf.newaxis, ...])
    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_probability/python/internal/prefer_static.py:176 cond
        return true_fn()
    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_probability/python/distributions/hidden_markov_model.py:397 _scan_multiple_steps
        initializer=init_state)
    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/ops/functional_ops.py:508 scan
        maximum_iterations=n)
    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py:2675 while_loop
        back_prop=back_prop)
    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/ops/while_v2.py:234 while_loop
        len_orig_loop_vars], expand_composites=True))
    venv/Abaka.FIN.Apis/lib/python3.6/site-packages/tensorflow_core/python/ops/while_v2.py:1068 _check_shapes_compat
        ""specify a less-specific shape."" % (input_t.name, shape, t.shape))

    ValueError: Input tensor 'HiddenMarkovModel_1/sample/Reshape:0' enters the loop with shape (1, 1), but has shape (1, None) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.
```
"
33776,LSTMCell name is ignored in trainable_variables when wrapped in keras.layers.RNN,"I created a model with several LSTMCell cells, wrapped in keras.layers.RNN.
When I print trainable_variables, cell names are ignored, which results into duplicate variable names (several same recurrent_kernel/etc), which confuses Tensorboard for example.

Collab notebook to reproduce: https://colab.research.google.com/drive/11W6ntLFGj4gqh5sS09CeVgb0LMNb_Fiu
Environment: tensorflow 2 release"
33775,"For tf2.0, why both tf.keras and tf.nn exist in the new version of Tensorflow? ","I found that tf.keras and tf.nn could do the same thing, so why keep both tf.keras and tf.nn existed in the new version of tf2.0?"
33774,"tflite_convert always required '--saved_model_dir --keras_model_file' arguments, even I specified '--graph_def_file'","## Computer spec:
-  Windows 10 update 1903 (build 18362.449)
-  Python 3.7 (run with venv)
-  Powershell Core console under VS Code
- Tensorflow 2.0.0 (install with `pip`)

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/lite/convert/cmdline_examples

## Description of issue (what needs changing):

Example defined what I can't follow, and the result always error with no specific arguments `--saved_model_dir` or `--keras_model_file`. 
Moreover, if I specified `--keras_model_file` with file name, it won't count as a file, it turn out the code logic count as it a folder path. 

### Clear description

In my case: Basic example -> [Convert a Tensorflow Graphdef](https://www.tensorflow.org/lite/convert/cmdline_examples#convert_a_tensorflow_graphdef_). I did download file as specify in `curl` command then extracted it to `./tmp`. Copy all you code in example code frame and run it. `tflite_convert --output_file=./tmp/foo.tflite --graph_def_file=./tmp/mobilenet_v1_0.50_128/frozen_graph.pb --input_arrays=input --output_arrays=MobilenetV1/Predictions/Reshape_1` then it throw with error. 
```
usage: tflite_convert [-h] --output_file OUTPUT_FILE
                      (--saved_model_dir SAVED_MODEL_DIR | --keras_model_file KERAS_MODEL_FILE)
tflite_convert: error: one of the arguments --saved_model_dir --keras_model_file is required
```

### Correct links

**Basic** example should no some kind like this error. And I'm the beginner here who need to learn from basic example code you prepared.

### Parameters defined

As you can see above, that was the command defined in you document page and I just copy + paste into command console.

### Returns defined

No, but it shouldn't error like this.

### Raises listed and defined

Above, I wrote it.

### Usage example

Above, I wrote it.

### Request visuals, if applicable

Run yourself, you will see what I got.

### Submit a pull request?

No.
"
33772,Init node weights/Assign doesn't exist in graph happens when convert to tflite model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 
the same code as 
https://colab.research.google.com/gist/jvishnuvardhan/bc515f885097fc6fd01076a3859e7e5b/tf_31609_tflite.ipynb#scrollTo=XVatsdZZuL_x

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.15.0
- Python version: 3.6.9


**Describe the current behavior**

cannot convert tf model to tf lite model, with this error: Init node weights/Assign doesn't exist in graph

**Code to reproduce the issue**

import tensorflow as tf

img = tf.placeholder(name=""img"", dtype=tf.float32, shape=(1, 64, 64, 3))
var = tf.get_variable(name=""weights"", dtype=tf.float32, shape=(1, 64, 64, 3))
val = img + var
out = tf.identity(val, name=""out"")

with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  converter = tf.lite.TFLiteConverter.from_session(sess, [img], [out])
  tflite_model = converter.convert()
  open(""converted_model.tflite"", ""wb"").write(tflite_model)

**Other info / logs**
WARNING:tensorflow:From /Users/dragonx/code/dcscn-super-resolution-master/test/tf_converter_test.py:3: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Users/dragonx/code/dcscn-super-resolution-master/test/tf_converter_test.py:4: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /Users/dragonx/code/dcscn-super-resolution-master/test/tf_converter_test.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-10-28 11:53:03.451728: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-28 11:53:03.461136: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8f442dc3f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-10-28 11:53:03.461147: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Users/dragonx/code/dcscn-super-resolution-master/test/tf_converter_test.py:9: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

2019-10-28 11:53:03.471663: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-10-28 11:53:03.471717: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-10-28 11:53:03.472863: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize
2019-10-28 11:53:03.472873: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2019-10-28 11:53:03.472877: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0ms.
WARNING:tensorflow:From /Users/dragonx/anaconda3/envs/scripts_env/lib/python3.6/site-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /Users/dragonx/anaconda3/envs/scripts_env/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
2019-10-28 11:53:03.478324: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-10-28 11:53:03.478372: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-10-28 11:53:03.479042: E tensorflow/core/grappler/grappler_item_builder.cc:656] Init node weights/Assign doesn't exist in graph"
33771,Val loss behaves strange while using custom training loop in tensorflow 2.0,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes, I defined my own training and validation loop and also my own keras model.

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
windows 10

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
No.

- TensorFlow installed from (source or binary):
From source.

- TensorFlow version (use command below):
Tensorflow 2.0.0 (gpu version)

- Python version:
Python 3.6.2

**Describe the current behavior**
I'm using a VGG16 model written in tf2.0 to train on my own datasets. Some BatchNormalization layers were included in the model and the ""training"" argument were set to True during training time and False during validation time as described in many tutorials. The train_loss decreased to a certain level during training as expected.
However, the val_loss behaves really strange. I checked out the output of the model after training and found out that, if I set the training argument to True, the output is quite correct, but if I set it to False, the result is incorrect at all. According to the tutorials in tensorflow website, when training is set to False , the model will normalize its inputs using the mean and variance of its moving statistics learned during training but it doesn't seem so. Am I missing something?

**Describe the expected behavior**
I think in the validation step if I set ```training``` to ```False``` the model should use the learned moving mean and variance as expected but it doesnt seem so.

**Code to reproduce the issue**
```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
import matplotlib.pyplot as plt
from PIL import Image
from tensorflow.keras.preprocessing import image
import glob
from tensorflow.keras.layers import BatchNormalization, Conv2D, ReLU, Conv2DTranspose, add, concatenate
from scipy.io import loadmat
import numpy as np
# from mobilev3 import MobileNetV3Large
from vgg_pr import VGG_PR
from tensorflow.keras.callbacks import TensorBoard
import logging
import cv2

# parameters
img_size = (299,299)
batch_size = 8
num_label = 20
initial_lr = 0.001
total_epoch = 100
repeat_times = 5
# case number
case_num = 9

os.chdir(os.getcwd())

train_img_list = sorted(glob.glob('../dataset/train/intensity/*.mat'))
train_label_list = sorted(glob.glob('../dataset/train/phase/*.txt'))
val_img_list = sorted(glob.glob('../dataset/validate/intensity/*.mat'))
val_label_list = sorted(glob.glob('../dataset/validate/phase/*.txt'))
ckpt_path = '../checkpoints/VGG-{epoch}.ckpt'
log_path = '../log/{}/'
if not os.path.exists(log_path.format(case_num)):
    os.mkdir(log_path.format(case_num))

# read data
def read_img(filename):
    image_dict = loadmat(filename.decode('utf-8'))
    exp_thresh = 1e4
    image_decoded = image_dict['Iz']
    image_decoded = cv2.resize(image_decoded, img_size, interpolation=cv2.INTER_AREA)
    image_decoded[image_decoded>exp_thresh] = exp_thresh
    image_decoded /= exp_thresh
    image_resized = np.float32(np.expand_dims(image_decoded, axis=-1))
    return image_resized

def read_label(filename):
    label = open(filename).read()
    label = label.strip().split(' ')
    label = [np.float32(i) for i in label if i!='']
    label = np.reshape(label, [1,1,-1])
    label = np.array(label) + 0.5  
    return label
def parse_function(image_filename, label_filename):
    img = tf.numpy_function(read_img, [image_filename], tf.float32)
    label = tf.numpy_function(read_label, [label_filename], tf.float32)
    return img, label
def train():
    logging.basicConfig(level=logging.INFO)
    tdataset = tf.data.Dataset.from_tensor_slices((train_img_list[:200], train_label_list[:200]))
    tdataset = tdataset.map(parse_function, 3).shuffle(buffer_size=200).batch(batch_size).repeat(repeat_times)
    vdataset = tf.data.Dataset.from_tensor_slices((val_img_list[:100], val_label_list[:100]))
    vdataset = vdataset.map(parse_function, 3).batch(batch_size)

    ### Vgg model
    model = VGG_PR(num_classes=num_label)

    logging.info('Model loaded')

    start_epoch = 0
    latest_ckpt = tf.train.latest_checkpoint(os.path.dirname(ckpt_path))
    if latest_ckpt:
        start_epoch = int(latest_ckpt.split('-')[1].split('.')[0])
        model.load_weights(latest_ckpt)
        logging.info('model resumed from: {}, start at epoch: {}'.format(latest_ckpt, start_epoch))
    else:
        logging.info('training from scratch since weights no there')

    ######## training loop ########
    loss_object = tf.keras.losses.MeanSquaredError()
    val_loss_object = tf.keras.losses.MeanSquaredError()
    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)
    train_loss = tf.metrics.Mean(name='train_loss') 
    val_loss = tf.metrics.Mean(name='val_loss')
    writer = tf.summary.create_file_writer(log_path.format(case_num))

    with writer.as_default():
        for epoch in range(start_epoch, total_epoch):
            print('start training')
            try:
                for batch, data in enumerate(tdataset):
                    images, labels = data
                    with tf.GradientTape() as tape:
                        pred = model(images, training=True)
                        if len(pred.shape) == 2:
                            pred = tf.reshape(pred,[-1, 1, 1, num_label])
                        loss = loss_object(pred, labels)
                    gradients = tape.gradient(loss, model.trainable_variables)
                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
                    if batch % 20 ==0:
                        logging.info('Epoch: {}, iter: {}, loss:{}'.format(epoch, batch, loss.numpy()))
                    tf.summary.scalar('train_loss', loss.numpy(), step=epoch*1250*repeat_times+batch)      # the tdataset has been repeated 5 times..
                    tf.summary.text('Zernike_coe_pred', tf.as_string(tf.squeeze(pred)), step=epoch*1250*repeat_times+batch)
                    tf.summary.text('Zernike_coe_gt', tf.as_string(tf.squeeze(labels)), step=epoch*1250*repeat_times+batch)

                    writer.flush()
                    train_loss(loss)
                model.save_weights(ckpt_path.format(epoch=epoch))
            except KeyboardInterrupt:
                logging.info('interrupted.')
                model.save_weights(ckpt_path.format(epoch=epoch))
                logging.info('model saved into {}'.format(ckpt_path.format(epoch=epoch)))
                exit(0)
            # validation step
            for batch, data in enumerate(vdataset):
                images, labels = data
                val_pred = model(images, training=False)
                if len(val_pred.shape) == 2:
                    val_pred = tf.reshape(val_pred,[-1, 1, 1, num_label])
                v_loss = val_loss_object(val_pred, labels)
                val_loss(v_loss)
            logging.info('Epoch: {}, average train_loss:{}, val_loss: {}'.format(epoch, train_loss.result(), val_loss.result()))
            tf.summary.scalar('val_loss', val_loss.result(), step = epoch)
            writer.flush()
            train_loss.reset_states()
            val_loss.reset_states()
        model.save_weights(ckpt_path.format(epoch=epoch))
```
And here is my vgg_pr model:
```python
import tensorflow as tf

# ------------------------------- Layers part -------------------------------
class BatchNormalization(tf.keras.layers.Layer):
    """"""All our convolutional layers use batch-normalization
    layers with average decay of 0.99.
    """"""

    def __init__(self):
        super().__init__(name=""BatchNormalization"")
        self.bn = tf.keras.layers.BatchNormalization(
            momentum=0.99,
            name=""BatchNorm"")

    def call(self, input, training):
        return self.bn(input, training)

class ConvBnAct(tf.keras.layers.Layer):
    def __init__(
            self,
            filters=64,
            kernel_size=(3,3),
            activation='relu',
            padding='same',
            name='conv'):
        super().__init__(name=""ConvBnAct"")

        self.conv = tf.keras.layers.Conv2D(
            filters=filters,
            kernel_size=kernel_size,
            activation=activation,
            padding=padding,
            name=name)
        # self.norm = BatchNormalization()
        self.norm = tf.keras.layers.BatchNormalization(name='BatchNorm')

    def call(self, input, training):
        x = self.conv(input)
        x = self.norm(x,training=training)
        return x

class Block_1(tf.keras.layers.Layer):
    def __init__(
            self):
        super().__init__(name=""Block_1"")
        self.conv1 = ConvBnAct(64,name='block1_conv1')
        self.conv2 = ConvBnAct(64,name='block1_conv2')
        self.pool = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')

    def call(self, input,training=False):
        x = self.conv1(input,training)
        x = self.conv2(x,training)
        x = self.pool(x)
        return x

class Block_2(tf.keras.layers.Layer):
    def __init__(
            self):
        super().__init__(name=""Block_2"")
        self.conv1 = ConvBnAct(128,name='block2_conv1')
        self.conv2 = ConvBnAct(128,name='block2_conv2')
        self.pool = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')

    def call(self, input,training=False):
        x = self.conv1(input,training)
        x = self.conv2(x,training)
        x = self.pool(x)
        return x

class Block_3(tf.keras.layers.Layer):
    def __init__(
            self):
        super().__init__(name=""Block_3"")
        self.conv1 = ConvBnAct(256,name='block3_conv1')
        self.conv2 = ConvBnAct(256,name='block3_conv2')
        self.conv3 = ConvBnAct(256,name='block3_conv3')
        self.pool = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')

    def call(self, input ,training=False):
        x = self.conv1(input,training)
        x = self.conv2(x,training)
        x = self.conv3(x,training)
        x = self.pool(x)
        return x

class Block_4(tf.keras.layers.Layer):
    def __init__(
            self):
        super().__init__(name=""Block_4"")
        self.conv1 = ConvBnAct(512,name='block4_conv1')
        self.conv2 = ConvBnAct(512,name='block4_conv2')
        self.conv3 = ConvBnAct(512,name='block4_conv3')
        self.pool = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')

    def call(self, input,training=False):
        x = self.conv1(input,training)
        x = self.conv2(x,training)
        x = self.conv3(x,training)
        x = self.pool(x)
        return x

class Block_5(tf.keras.layers.Layer):
    def __init__(
            self):
        super().__init__(name=""Block_5"")
        self.conv1 = ConvBnAct(512,name='block5_conv1')
        self.conv2 = ConvBnAct(512,name='block5_conv2')
        self.conv3 = ConvBnAct(512,name='block5_conv3')
        self.pool = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')

    def call(self, input,training=False):
        x = self.conv1(input,training)
        x = self.conv2(x,training)
        x = self.conv3(x,training)
        x = self.pool(x)
        return x

class VGG_PR(tf.keras.Model):
    def __init__(self,num_classes):
        super(VGG_PR, self).__init__()
        self.block1 = Block_1()
        self.block2 = Block_2()
        self.block3 = Block_3()
        self.block4 = Block_4()
        self.block5 = Block_5()
        self.avg = tf.keras.layers.GlobalAveragePooling2D()
        self.fc1 = tf.keras.layers.Dense(256, activation='relu', name='fc1')
        self.fc2 = tf.keras.layers.Dense(128, activation='relu', name='fc2')
        self.fc3 = tf.keras.layers.Dense(num_classes,activation='linear',name='predictions')

    def call(self, input, training=False):
        x = self.block1(input,training)
        x = self.block2(x,training)
        x = self.block3(x,training)
        x = self.block4(x,training)
        x = self.block5(x,training)
        x = self.avg(x)
        # print(""output1:{}"".format(x))
        x = self.fc1(x)
        # print(""output2:{}"".format(x))
        x = self.fc2(x)
        x = self.fc3(x)
        return x

```
"
33770,Is it possible to support gif images in ImageDataGenerator?,"**System information**
- TensorFlow version (you are using):
 2.0.0
- Are you willing to contribute it (Yes/No):
Not sure how to :(


**Describe the feature and the current behavior/state.**
ImageDataGenerator currently ignores gif images in its methods (like `flow_from_directory`), why doesn't it take gif? As gif is also widely used over the Internet it should be supported too.
**Will this change the current api? How?**
No
**Who will benefit with this feature?**
Whoever that has a bunch of gif in their dataset
"
33769,For tensorflow1.15: undefined symbol: ncclBroadcast,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.15.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip3.7
- Bazel version (if compiling from source): 0.26.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda10.0/cuDNN7.5.1
- GPU model and memory:



**Describe the problem**
This has happened after install  Tensorflow1.15.0 from the source
1. bazel build:
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
and then:
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow-1.15
we got:
/tmp/tensorflow-1.15/tensorflow-1.15.0-cp37-cp37m-linux_x86_64.whl

2. install tensorflow:
pip install /tmp/tensorflow-1.15/tensorflow-1.15.0-cp37-cp37m-linux_x86_64.whl

3. Check if the installation is successful:
#python -c ""import tensorflow as tf; print(tf.__version__)""

Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/local/lib/python3.7/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/local/lib/python3.7/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /usr/local/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so: undefined symbol: ncclBroadcast

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py"", line 99, in <module>
    from tensorflow_core import *
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""/usr/local/lib/python3.7/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/local/lib/python3.7/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/local/lib/python3.7/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /usr/local/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so: undefined symbol: ncclBroadcast


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33768,Metrics disappear on subclassed Keras model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab TPU
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.7

**Code to reproduce the issue**

```python
%tensorflow_version 2.x

inputs = tf.keras.Input((10,))
outputs = tf.keras.layers.Dense(10)(inputs)
unsubclassed = tf.keras.Model(inputs=inputs, outputs=outputs)
unsubclassed.compile(loss='categorical_crossentropy', metrics=['accuracy'])
_ = unsubclassed(tf.random.uniform((10, 10)))

class Subclassed(tf.keras.Model):
    def __init__(self,  **kwargs):
        super().__init__(**kwargs)
        self.dense = tf.keras.layers.Dense(10)

    @tf.function
    def call(self, x, training=None):
        return self.dense(x)

subclassed = Subclassed()
subclassed.compile(loss='categorical_crossentropy', metrics=['accuracy'])
_ = subclassed(tf.random.uniform((10, 10)))

print(unsubclassed.metrics_names, unsubclassed.metrics)
print(subclassed.metrics_names, subclassed.metrics)
```

gives:

```
['loss', 'accuracy'] [<tensorflow.python.keras.metrics.MeanMetricWrapper object at 0x7ffa0a6c53c8>]
['loss'] []
```

**Expected Result**

Subclassed model should not eat metrics."
33767,"AutoGraph: Error transforming entity / AssertionError: Bad argument number for Name: 3, expecting 4","**System information**
- OS Platform and Distribution: Arch Linux, 5.3.7-arch1-1-ARCH
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Kerasversion (use command below): 2.2.4-tf
- Python version: 3.7.4
- CUDA/cuDNN version: CUDA 10.1.243 / cuDNN 7.6.2.24
- GPU model and memory: 2x GTX 1080 Ti 11GB""`

various errors/warnings as: ""Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0f2846c320> could not be transformed and will be executed as-is""

> 2019-10-27 22:54:04,017 - INFO - Error transforming entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0f2846c320>
> Traceback (most recent call last):
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 506, in converted_call
>     converted_f = conversion.convert(target_entity, program_ctx)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 322, in convert
>     free_nonglobal_var_names)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 240, in _convert_with_cache
>     entity, program_ctx)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 469, in convert_entity_to_ast
>     nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 669, in convert_func_to_ast
>     node = node_to_graph(node, context)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 698, in node_to_graph
>     node = converter.standard_analysis(node, context, is_initial=True)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/core/converter.py"", line 383, in standard_analysis
>     node = qual_names.resolve(node)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/qual_names.py"", line 254, in resolve
>     return QnResolver().visit(node)
>   File ""/usr/lib/python3.7/ast.py"", line 262, in visit
>     return visitor(node)
>   File ""/usr/lib/python3.7/ast.py"", line 317, in generic_visit
>     value = self.visit(value)
>   File ""/usr/lib/python3.7/ast.py"", line 262, in visit
>     return visitor(node)
>   File ""/usr/lib/python3.7/ast.py"", line 317, in generic_visit
>     value = self.visit(value)
>   File ""/usr/lib/python3.7/ast.py"", line 262, in visit
>     return visitor(node)
>   File ""/usr/lib/python3.7/ast.py"", line 326, in generic_visit
>     new_node = self.visit(old_value)
>   File ""/usr/lib/python3.7/ast.py"", line 262, in visit
>     return visitor(node)
>   File ""/usr/lib/python3.7/ast.py"", line 317, in generic_visit
>     value = self.visit(value)
>   File ""/usr/lib/python3.7/ast.py"", line 262, in visit
>     return visitor(node)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/qual_names.py"", line 236, in visit_Subscript
>     if isinstance(s.value, gast.Num):
> AttributeError: module 'gast' has no attribute 'Num'
> WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0f2846c320> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'
> 2019-10-27 22:54:04,017 - WARNING - Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f0f2846c320> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'
> 2019-10-27 22:54:06.670890: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_gru_10450_11011' and '__inference___backward_cudnn_gru_with_fallback_9300_9441_specialized_for_StatefulPartitionedCall_1_at___inference_distributed_function_12398' both implement 'gru_ee50c0e8-e326-45b7-b98e-88e06e2f6f01' but their signatures do not match.
> 


> 2019-10-27 22:54:01,401 - INFO - Error transforming entity <bound method Output.call of <model.Output object at 0x7f0f3c96aa90>>
> Traceback (most recent call last):
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 506, in converted_call
>     converted_f = conversion.convert(target_entity, program_ctx)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 322, in convert
>     free_nonglobal_var_names)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 240, in _convert_with_cache
>     entity, program_ctx)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 471, in convert_entity_to_ast
>     nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 669, in convert_func_to_ast
>     node = node_to_graph(node, context)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py"", line 699, in node_to_graph
>     node = converter.apply_(node, context, function_scopes)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/core/converter.py"", line 409, in apply_
>     node = converter_module.transform(node, context)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py"", line 120, in transform
>     return FunctionBodyTransformer(ctx).visit(node)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/core/converter.py"", line 346, in visit
>     return super(Base, self).visit(node)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/transformer.py"", line 480, in visit
>     result = super(Base, self).visit(node)
>   File ""/usr/lib/python3.7/ast.py"", line 262, in visit
>     return visitor(node)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py"", line 87, in visit_FunctionDef
>     node = self.generic_visit(node)
>   File ""/usr/lib/python3.7/ast.py"", line 317, in generic_visit
>     value = self.visit(value)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/core/converter.py"", line 346, in visit
>     return super(Base, self).visit(node)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/transformer.py"", line 480, in visit
>     result = super(Base, self).visit(node)
>   File ""/usr/lib/python3.7/ast.py"", line 262, in visit
>     return visitor(node)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py"", line 44, in visit_Return
>     value=node.value)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/templates.py"", line 261, in replace
>     replacements[k] = _convert_to_ast(replacements[k])
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/templates.py"", line 223, in _convert_to_ast
>     return gast.Name(id=n, ctx=None, annotation=None)
>   File ""/usr/lib/python3.7/site-packages/gast/gast.py"", line 19, in create_node
>     format(Name, nbparam, len(Fields))
> AssertionError: Bad argument number for Name: 3, expecting 4
> WARNING:tensorflow:Entity <bound method Output.call of <model.Output object at 0x7f0f3c96aa90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4
> 2019-10-27 22:54:01,401 - WARNING - Entity <bound method Output.call of <model.Output object at 0x7f0f3c96aa90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4
> WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py:5783: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version"
33766, Failed to place the graph without changing the devices of some resources. ,"- Have I written custom code :NO
- Linux Ubuntu 18
- TensorFlow installed from (source or binary): from pip install 
- TensorFlow version (use command below): 
```
print(tf.version.GIT_VERSION, tf.version.VERSION)""
 ('v2.0.0-rc2-26-g64c3d38', '2.0.0')
```
Hi, 

I followed the guide of https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/cityscapes.md

after converting the data, I gave the provided command for trainin:
```# From tensorflow/models/research/

python deeplab/train.py \
    --logtostderr \
    --training_number_of_steps=90000 \
    --train_split=""train"" \
    --model_variant=""xception_65"" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --train_crop_size=""769,769"" \
    --train_batch_size=1 \
    --dataset=""cityscapes"" \
    --tf_initial_checkpoint=${PATH_TO_INITIAL_CHECKPOINT} \
    --train_logdir=${PATH_TO_TRAIN_DIR} \
    --dataset_dir=${PATH_TO_DATASET}
```

But I got an error of ""Failed to place the graph without changing the devices of some resources"":

```
W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:`

Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ApplyMomentum: CPU 
IsVariableInitialized: CPU 
Assign: CPU 
Identity: CPU XLA_CPU 
VariableV2: CPU 
Const: CPU XLA_CPU 
```

here is the following output information I got, I think it says only ""Segmentation fault""
```
Colocation members, user-requested devices, and framework assigned devices, if any:
  logits/semantic/biases/Initializer/zeros (Const) 
  logits/semantic/biases (VariableV2) /device:GPU:0
  logits/semantic/biases/Assign (Assign) /device:GPU:0
  logits/semantic/biases/read (Identity) /device:GPU:0
  logits/semantic/biases/Momentum/Initializer/zeros (Const) /device:GPU:0
  logits/semantic/biases/Momentum (VariableV2) /device:GPU:0
  logits/semantic/biases/Momentum/Assign (Assign) /device:GPU:0
  logits/semantic/biases/Momentum/read (Identity) /device:GPU:0
  Momentum/update_logits/semantic/biases/ApplyMomentum (ApplyMomentum) /device:GPU:0
  report_uninitialized_variables/IsVariableInitialized_732 (IsVariableInitialized) /device:GPU:0
  report_uninitialized_variables/IsVariableInitialized_1172 (IsVariableInitialized) /device:GPU:0
  report_uninitialized_variables_1/IsVariableInitialized_732 (IsVariableInitialized) /device:GPU:0
  report_uninitialized_variables_1/IsVariableInitialized_1172 (IsVariableInitialized) /device:GPU:0
  save/Assign_113 (Assign) /device:GPU:0
  save/Assign_114 (Assign) /device:GPU:0

INFO:tensorflow:Running local_init_op.
I1027 21:25:31.706468 140671729727296 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1027 21:25:31.916163 140671729727296 session_manager.py:502] Done running local_init_op.
Fatal Python error: Segmentation fault

Thread 0x00007ff0b07af740 (most recent call first):
  File ""/home/zwang/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1429 in _call_tf_sessionrun
  File ""/home/zwang/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1341 in _run_fn
  File ""/home/zwang/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1356 in _do_call
  File ""/home/zwang/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1350 in _do_run
  File ""/home/zwang/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1173 in _run
  File ""/home/zwang/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 950 in run
  File ""/home/zwang/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1169 in run
  File ""/home/zwang/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1411 in run
  File ""/home/zwang/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1338 in run
  File ""/home/zwang/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1252 in run
  File ""/home/zwang/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 754 in run
  File ""deeplab/train.py"", line 513 in main
  File ""/home/zwang/.local/lib/python3.6/site-packages/absl/app.py"", line 250 in _run_main
  File ""/home/zwang/.local/lib/python3.6/site-packages/absl/app.py"", line 299 in run
  File ""/home/zwang/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40 in run
  File ""deeplab/train.py"", line 519 in <module>
Segmentation fault
```"
33765,Problem   trying to convert from tf keras model to tflite does not work/let save,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO --I can save the tensorflow keras model to an h5 file but, when subsequently try to convert to TFLite using code below it fails. Following directions at https://www.tensorflow.org/tutorials/keras/save_and_load to perform conversion to TFLite (see code below)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.0 and nightly version(today)
- Python version: 3.6.1
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
have done locally (pip install) and recently trying anaconda 
` conda create -n tf-n python  
 conda activate tf-n  
 pip install tf-nightly`

**Describe the current behavior**
Here is error --says save method is not available.  
`Model: ""sequential_2""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 148, 148, 32)      896       
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 74, 74, 32)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 72, 72, 64)        18496     
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 36, 36, 64)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 34, 34, 128)       73856     
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 17, 17, 128)       0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 15, 15, 128)       147584    
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 7, 7, 128)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 7, 7, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 6272)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 512)               3211776   
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1026      
=================================================================
Total params: 3,453,634
Trainable params: 3,453,634
Non-trainable params: 0
_________________________________________________________________
 want to save tflite_fileC:\Grewe\Classes\CS663\Mat\TensorFlow\cats_and_dogs_filtered\my_tflite_model.h5
converter = <tensorflow.lite.python.lite.TFLiteConverterV2 object at 0x00000225A2142240>
IOPub data rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
--NotebookApp.iopub_data_rate_limit.

Current values:
NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)
NotebookApp.rate_limit_window=3.0 (secs)


---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-20-f45b37f63b2a> in <module>()
     13 
     14 #now save the tflite model to the file
---> 15 tflite_model.save(tflite_file)

AttributeError: 'bytes' object has no attribute 'save'
`

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
`#print out model summary so can see it for bug report
model.summary()

#from tensorflow import lite
tflite_file  = os.path.join(BASE_DIRECTORY, 'my_tflite_model.h5')
print("" want to save tflite_file"" + tflite_file)
# Convert the model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
print(""converter = "" + str(converter))
tflite_model = converter.convert()
print(tflite_model)


#now save the tflite model to the file
tflite_model.save(tflite_file)`
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33764,Unnecessary tf.distribute.MirroredStrategy() scopes in the distributed custom training tutorial,"##  URL(s) with the issue: 
https://www.tensorflow.org/tutorials/distribute/custom_training

## Description of issue (what needs changing):
In the tutorial, `with strategy.scope()` appears almost everywhere, which gives the impression that it is required that those locations. However, when checking [this example](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/densenet/distributed_train.py), I found that the scope is not required at all! Only `strategy.experimental_run_v2` and `strategy.reduce` suffice. Therefore, I would propose to modify the tutorial code to keep only a minimum amount of `with strategy.scope()` when necessary (e.g. when defining the model).

### Submit a pull request?

Yes, I can create a PR but only when you have approved that this is valid. Thanks.
"
33763,Better (simpler!) model checkpointing,"**System information**
- TensorFlow version (you are using): 2.0.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
The current `tf.train.Checkpoint` is really a bit too complicated and not easy to use. Suppose that I want to save **the best model** (that has the best validation accuracy) during my **custom training loop**, and that I want to save **only the best model because I don't want to waste disk space**. My common sense tells me that this is so simple, just like in all other libraries:

```
if best_acc < epoch_acc:
    best_acc = epoch_acc
    checkpoint.save(os.path.join(checkpoint_dir, 'best'))
```

Results after 3 epochs:
```
best-1.index
best-1.data-00001-of-00002
best-1.data-00000-of-00002
best-2.index
best-2.data-00001-of-00002
best-2.data-00000-of-00002
best-3.index
best-3.data-00001-of-00002
best-3.data-00000-of-00002
```
Oops... My disk does not like this! And there's no option to turn off the counter and choose the exact file names that I want!

Same problem for **saving only the last checkpoint**. You would tell me that one can use `tf.train.CheckpointManager` for this task (by setting `max_to_keep = 1`), but, **a checkpoint object and then a checkpoint manager object to manage checkpoints, seriously?** Yet another additional layer of complexity! (Not to say that `CheckpointManager` cannot deal with the best model saving described above).

I think one of the major limitations of TensorFlow was complexity, really. In TensorFlow 2 this has been significantly reduced, but I believe we can do more.

It would be best to give the users the simplest option to `save(filepath)` and `restore(filepath)` in a **single file** (instead of *.index plus a bunch of data files), with whatever `filepath` they want. Just like in any other libraries such as PyTorch or Keras! (Keras's usage cannot be applied here because the model may not be compiled in a custom training loop). 

Finally: my apologies if such a solution already exists and I am not aware of that because of my lack of knowledge! (I have wrestled with `tf.train.Checkpoint` over the last days, and have checked the official [guide](https://www.tensorflow.org/guide) and [tutorials](https://www.tensorflow.org/tutorials) but could not find anything like that.)

I am just a TF beginner but will try to contribute, if you are open to changes. Thanks.

**Will this change the current api? How?**
I guess. I don't know how exactly, though.

**Who will benefit with this feature?**
Every user who wants to manually save checkpoints."
33762,Cannot Get Older Versions to Build,"**System information**
- Arch Linux
- TensorFlow installed from source
- TensorFlow version: 1.13.0
- Python version: 3.7
- Not Installed using virtualenv, pip or conda
- Bazel version: 0.25.3
- GCC/Compiler version: 9.2.0
- CUDA/cuDNN version: N/A
- GPU model and memory: RS880M (Mobility Radeon HD 4225/4250) (256MB)

I've been trying to build version 1.13.0 of tensorflow for the past two days. I need a build that was compiled with ""-mno-avx"" because my CPU does not support the AVX instruction set and tensorflow crashes when I run it. I need tensorflow for a project I'm trying to install.

I read that new versions of glibc conflict with the source code and that the source code must be patched to build with as newer version of glibc. I am getting errors about ""gettid()"" being ambiguous. I found reference to someone patching the source code and changing gettid() to sys_gettid(), but I cannot find the patch that was used.

I also tried changing the function calls manually in the ~/.cache/bazel directory but Bazel will not compile with the cached source code. It seems to redownload the source code before every build. 

The command that I used to start the build:
```
bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
```

Error:
```
ERROR: /home/***/.cache/bazel/_bazel_***/06b70ca2a990d8a0456251480c3991dd/external/grpc/BUILD:507:1: C++ compilation of rule '@grpc//:gpr_base' failed (Exit 1)
                 external/grpc/src/core/lib/gpr/log_linux.cc:43:13: error: ambiguating new declaration of 'long int gettid()'
43 | static long gettid(void) { return syscall(__NR_gettid); }        |             ^~~~~~                                         
In file included from /usr/include/unistd.h:1170,                                   from external/grpc/src/core/lib/gpr/log_linux.cc:41:                                                                 
/usr/include/bits/unistd_ext.h:34:16: note: old declaration '__pid_t gettid()'                                                           
34 | extern __pid_t gettid (void) __THROW;                            |                ^~~~~~                                      
external/grpc/src/core/lib/gpr/log_linux.cc:43:13: warning: 'long int gettid()' defined but not used [-Wunused-function]                 
43 | static long gettid(void) { return syscall(__NR_gettid); }        |             ^~~~~~                                         
Target //tensorflow/tools/pip_package:build_pip_package failed to build                                                               
Use --verbose_failures to see the command lines of failed build steps.                                                                INFO: Elapsed time: 14263.127s, Critical Path: 457.22s
INFO: 4301 processes: 4301 local.
FAILED: Build did NOT complete successfully
```

![Screenshot_20191027-114439](https://user-images.githubusercontent.com/19521547/67638409-11eb2100-f8b2-11e9-8767-aed639721262.png)
"
33759,What is the right way to use coverage.py with Tensorflow?,"I apologize if this is the wrong way to ask this question. I'm the maintainer of coverage.py, for measuring code coverage in Python projects.  A user wrote an issue for me: https://github.com/nedbat/coveragepy/issues/856

After digging into it, I see that his tf.keras.Model.call() function is not executed directly, but is transformed into a temporary file, and executed there.  So coverage.py reports that his code is unexecuted, even though he can see the effects of its execution.

I also see that the transformed code has an `ag_source_map__` parameter which can be used to map back from the transformed code to the original code.  A coverage.py plugin could use that information to report coverage usefully.

My questions are:
1. Is there a reason people haven't reported this to coverage.py before? Is there a existing known way to get coverage reports on this kind of code?
2. What is a stable public API for getting the transformation mapping?
3. Would TensorFlow be interested in maintaining a coverage.py plugin to make this work properly?"
33758,Update grpc dependency for glibc 2.30 compatibility,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Arch Linux**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **n/A**
- TensorFlow installed from (source or binary): **source**
- TensorFlow version: **2.0.0**
- Python version: **3.7.4**
- Installed using virtualenv? pip? conda?: **n/A**
- Bazel version (if compiling from source): **bazel 0.29.1- (@non-git)**
- GCC/Compiler version (if compiling from source): **gcc-8 (GCC) 8.3.0**
- CUDA/cuDNN version: **10.1.243-1**/**7.6.4.38-1**
- GPU model and memory: **NVIDIA GeForce GTX 760 4GB**

**Describe the problem**

When building tensorflow 2.0.0 on a system with `glibc` version 2.30, the build fails due to a function name clash issue in grpc, which is already fixed (in https://github.com/grpc/grpc/pull/18950) and there are grpc releases available with this fix. I believe updating the grpc dependency should fix this issue in Tensorflow.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

On Arch Linux:
```
cd $(mktemp -d /tmp/tensorflow-test-build-XXX)
curl -L -o PKGBUILD 'https://git.archlinux.org/svntogit/community.git/plain/trunk/PKGBUILD?h=packages/tensorflow'
makepkg
```

If you're not on Arch Linux, have a look at the build script in the [PKGBUILD](https://git.archlinux.org/svntogit/community.git/tree/trunk/PKGBUILD?h=packages/tensorflow) file - it contains all the environment variable definitions and build commands, and is very readable.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

End of build log:

```
...
INFO: From Compiling external/llvm/lib/DebugInfo/CodeView/TypeRecordMapping.cpp:
external/llvm/lib/DebugInfo/CodeView/TypeRecordMapping.cpp: In member function 'virtual llvm::Error llvm::codeview::TypeRecordMapping::visitKnownRecord(llvm::codeview::CVType&, llvm::codeview::VFTableShapeRecord&)':
external/llvm/lib/DebugInfo/CodeView/TypeRecordMapping.cpp:293:61: warning: 'Byte' may be used uninitialized in this function [-Wmaybe-uninitialized]
  293 |         Record.Slots.push_back(static_cast<VFTableSlotKind>(Byte >> 4));
      |                                                             ^~~~
ERROR: /tmp/bazel/michiel/output/41c10338046435fcb3c7d7f27ec34951/external/grpc/BUILD:507:1: C++ compilation of rule '@grpc//:gpr_base' failed (Exit 1)
external/grpc/src/core/lib/gpr/log_linux.cc:43:13: error: ambiguating new declaration of 'long int gettid()'
   43 | static long gettid(void) { return syscall(__NR_gettid); }
      |             ^~~~~~
In file included from /usr/include/unistd.h:1170,
                 from external/grpc/src/core/lib/gpr/log_linux.cc:41:
/usr/include/bits/unistd_ext.h:34:16: note: old declaration '__pid_t gettid()'
   34 | extern __pid_t gettid (void) __THROW;
      |                ^~~~~~
external/grpc/src/core/lib/gpr/log_linux.cc:43:13: warning: 'long int gettid()' defined but not used [-Wunused-function]
   43 | static long gettid(void) { return syscall(__NR_gettid); }
      |             ^~~~~~
INFO: Elapsed time: 744.187s, Critical Path: 41.65s
INFO: 3096 processes: 3096 local.
FAILED: Build did NOT complete successfully
==> ERROR: A failure occurred in build().
    Aborting...
```

**What I've tried so far to fix this**
I tried to emulate the grpc version update from https://github.com/tensorflow/tensorflow/commit/061c3597b84d45a9878b8adf831e39a5573859ec and bump grpc to v1.24.3. Since v1.19.x, which the currently referenced grpc version seems to be from, grpc has added a dependency on https://github.com/protocolbuffers/upb, and it wasn't clear to me how to add and initialise this dependency correctly in a way that's consistent with tensorflow's use of bazel. I specifically wasn't sure where to call `grpc_deps()`/`upb_deps()` from, or what equivalent action was required instead.

**Context**
In case it matters, I'm trying to build the Arch Linux Package from source, so that I can add 3.0 to `TF_CUDA_COMPUTE_CAPABILITIES`, which is required for my graphics card. I managed to do this for an earlier version of tensorflow some time ago without too much difficulty."
33757,Inclusion of a model re-training example,"## URL(s) with the issue: [https://www.tensorflow.org/tutorials/keras/save_and_load](https://www.tensorflow.org/tutorials/keras/save_and_load)

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/tutorials/keras/save_and_load

## Description of issue (what needs changing):

Since model re-training is quite vital in both applied and research-based environments, I think it would be great to include an example on the same in this tutorial. 

### Clear description

The tutorial shows how to save and load models using various options. It does mention that using the model checkpoints it is possible to train the model from the point it was left off. However, currently, there is no section in the tutorial that shows how to do that in the correct way. 

For example, why should someone use this method? How is it useful?

There are several instances where a model may have to be retrained:
- There is new data and the model needs to re-trained on that
- If we are on local machines and if there is a power failure or bottlenecks that cause the training process to stop, we can always load up the latest checkpoints and re-train the models from there. "
33756,Docs do not link to source,"One really useful feature in the sklearn docs is that each and every item has a link back to its source on GitHub. For example, see [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html):

> class sklearn.ensemble.RandomForestRegressor(n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;--> **[[source]](https://github.com/scikit-learn/scikit-learn/blob/1495f6924/sklearn/ensemble/forest.py#L1046)** <--

Would be nice if the TF docs could do the same."
33755,Dense variable constraints are not allowed with sparse gradients,"I'm training a simple document embedding model with the Keras API in TF 2.0. When I try to add `embeddings_constraint=tf.keras.constraints.UnitNorm(axis=1)` to an `Embedding` layer, I get the following error (truncated):

```
File ""C:\Users\Steven\Miniconda3\lib\site-packages\tensorflow_core\python\keras\optimizer_v2\optimizer_v2.py"", line 459, in apply_grad_to_update_var
    ""Cannot use a constraint function on a sparse variable."")
```

I have verified that the variable is not sparse; the `Embedding` layer creates a dense matrix to hold the embeddings. However, reading [the code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/optimizer.py#L126) shows that this error is raised when the *gradients* are sparse, which seems normal for embedding layers and should not (AFAIK) affect the application of constraints to the dense variable after the gradient update.

**In summary, variable constraints should be allowed in this context, and it is a bug that they are not.**"
33754,[BUG] The gradient computed for bias in tf.contrib.slim.conv2d + tf.contrib.slim.batch_norm and tf.contrib.slim.conv2d(normalizer=tf.contrib.slim.batch_norm) are different!,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- TensorFlow version (use command below): tensorflow==1.15.0rc2
- Python version: 3.6.8
- CUDA/cuDNN version: 10.1/7.5
- GPU model and memory: RTX 2080 Ti

**Describe the current behavior**
The gradient computed for bias in tf.contrib.slim.conv2d + tf.contrib.slim.batch_norm and tf.contrib.slim.conv2d(normalizer=tf.contrib.slim.batch_norm) are different!

**Describe the expected behavior**
The gradients should be the same. Right now, it seems like `tf.contrib.slim.conv2d + tf.contrib.slim.batch_norm` gives the correct gradient.

**Code to reproduce the issue**

```
import tensorflow as tf
import tensorflow.contrib.slim as slim
import numpy as np

# tf.enable_eager_execution()

print(""GRAPH 1"")
graph_1 = tf.Graph()
with graph_1.as_default():
    input_placeholder_1 = tf.placeholder(tf.float32, shape=([1, 10, 10, 3]))
    target_placeholder_1 = tf.placeholder(tf.float32, shape=([1, 10, 10, 1]))

    input_tensor_1 = tf.pad(input_placeholder_1, [[0, 0], [1, 1], [1, 1], [0, 0]])
    # forward_op = slim.conv2d(inputs=input_tensor, num_outputs=1, kernel_size=3, stride=1, padding=""VALID"", normalizer_fn=slim.batch_norm, normalizer_params={""center"": True, ""scale"": True}, weights_initializer=tf.constant_initializer(value=0.0), biases_initializer=None)
    forward_op_1 = slim.conv2d(inputs=input_tensor_1, num_outputs=1, kernel_size=3, stride=1, padding=""VALID"", normalizer_fn=None, weights_initializer=tf.constant_initializer(value=0), biases_initializer=None)
    forward_op_1 = slim.batch_norm(forward_op_1, scale=True)
    forward_op_1 = tf.sigmoid(forward_op_1)

    loss_1 = tf.losses.sigmoid_cross_entropy(target_placeholder_1, forward_op_1, reduction=""weighted_sum"")
    backward_op_1 = tf.gradients(loss_1, tf.trainable_variables())
    sess_1 = tf.Session(graph=graph_1)
    sess_1.run(tf.global_variables_initializer())
    train_vars_1 = sess_1.run(tf.trainable_variables())
    for train_var_1 in train_vars_1:
        print(train_var_1)

print(""GRAPH 2"")
graph_2 = tf.Graph()
with graph_2.as_default():
    input_placeholder_2 = tf.placeholder(tf.float32, shape=([1, 10, 10, 3]))
    target_placeholder_2 = tf.placeholder(tf.float32, shape=([1, 10, 10, 1]))

    input_tensor_2 = tf.pad(input_placeholder_2, [[0, 0], [1, 1], [1, 1], [0, 0]])
    forward_op_2 = slim.conv2d(inputs=input_tensor_2, num_outputs=1, kernel_size=3, stride=1, padding=""VALID"", normalizer_fn=slim.batch_norm, normalizer_params={""center"": True, ""scale"": True}, weights_initializer=tf.constant_initializer(value=0.0), biases_initializer=None)
    # forward_op_2 = slim.conv2d(inputs=input_tensor_2, num_outputs=1, kernel_size=3, stride=1, padding=""VALID"", normalizer_fn=None, weights_initializer=tf.constant_initializer(value=0), biases_initializer=tf.constant_initializer(value=0))
    # forward_op_2 = slim.batch_norm(forward_op_2, scale=True)
    forward_op_2 = tf.sigmoid(forward_op_2)

    loss_2 = tf.losses.sigmoid_cross_entropy(target_placeholder_2, forward_op_2, reduction=""weighted_sum"")
    backward_op_2 = tf.gradients(loss_2, tf.trainable_variables())
    sess_2 = tf.Session(graph=graph_2)
    sess_2.run(tf.global_variables_initializer())
    train_vars_2 = sess_2.run(tf.trainable_variables())
    for train_var_2 in train_vars_2:
        print(train_var_2)

for i in range(10):
    print(""RUN "", i)
    input_ = np.random.randn(1, 10, 10, 3)
    target = np.random.randint(2, size=(1, 10, 10, 1))
    grad_1 = sess_1.run(backward_op_1, feed_dict={input_placeholder_1: input_, target_placeholder_1: target})
    print(len(grad_1))
    print(grad_1)
    grad_2 = sess_2.run(backward_op_2, feed_dict={input_placeholder_2: input_, target_placeholder_2: target})
    print(len(grad_2))
    print(grad_2)
```
**logs**
```
GRAPH 1
[[[[0.]
   [0.]
   [0.]]

  [[0.]
   [0.]
   [0.]]

  [[0.]
   [0.]
   [0.]]]


 [[[0.]
   [0.]
   [0.]]

  [[0.]
   [0.]
   [0.]]

  [[0.]
   [0.]
   [0.]]]


 [[[0.]
   [0.]
   [0.]]

  [[0.]
   [0.]
   [0.]]

  [[0.]
   [0.]
   [0.]]]]
[1.]
[0.]
GRAPH 2
[[[[0.]
   [0.]
   [0.]]

  [[0.]
   [0.]
   [0.]]

  [[0.]
   [0.]
   [0.]]]


 [[[0.]
   [0.]
   [0.]]

  [[0.]
   [0.]
   [0.]]

  [[0.]
   [0.]
   [0.]]]


 [[[0.]
   [0.]
   [0.]]

  [[0.]
   [0.]
   [0.]]

  [[0.]
   [0.]
   [0.]]]]
[1.]
[0.]
RUN  0
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([3.8114848], dtype=float32)]]
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32)]]
RUN  1
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([1.3114842], dtype=float32)]]
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32)]]
RUN  2
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([1.3114835], dtype=float32)]]
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32)]]
RUN  3
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([4.811485], dtype=float32)]]
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32)]]
RUN  4
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([0.8114846], dtype=float32)]]
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32)]]
RUN  5
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([4.3114843], dtype=float32)]]
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32)]]
RUN  6
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([1.8114848], dtype=float32)]]
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32)]]
RUN  7
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([0.06148279], dtype=float32)]]
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32)]]
RUN  8
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([3.0614848], dtype=float32)]]
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32)]]
RUN  9
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([4.0614843], dtype=float32)]]
1
[[array([[[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]],


       [[[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.]]]], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32)]]
```

**Other info **
I understand that tf.contrib.slim is no longer being maintained but I just want to know if it is really a bug or a misuse. Right now, based on my minimal testing code, it seems like a bug.
"
33752,"Invalid loop structure: Loop ""Preprocessor/map/while/while_context""","I'm trying to map the output of one graph to the input of another but I'm getting following error while trying to do so. I'm using `export_meta_graph` and `import_scoped_meta_graph` with `input_map`. Following is my code :

```
import tensorflow as tf
import numpy as np
import cv2

grid_shape = (5,5)
image_shape=(150, 150)
num_channels=3

img = cv2.imread(""/Users/vedanshu/test.jpeg"")
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

def get_frozen_graph(graph_file):
    """"""Read Frozen Graph file from disk.""""""
    with tf.gfile.GFile(graph_file, ""rb"") as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
    return graph_def

# Import frozen graph for level 1
pb_fname1 = ""/Users/vedanshu/frozen_graph/ssd_tomato_l1_frozen_graph.pb""
trt_graph1 = get_frozen_graph(pb_fname1)
detection_graph1 = tf.Graph()
with detection_graph1.as_default():
    tf.import_graph_def(trt_graph1, name='')
    tf_sess1 = tf.Session(graph=detection_graph1)

# Import frozen graph for level 2
pb_fname2 = ""/Users/vedanshu/frozen_graph/faster_rcnn_tomato_l2_frozen_graph.pb""
trt_graph2 = get_frozen_graph(pb_fname2)
detection_graph2 = tf.Graph()
with detection_graph2.as_default():
    tf.import_graph_def(trt_graph2, name='')
    tf_sess2 = tf.Session(graph=detection_graph2)

from tensorflow.python.framework import meta_graph

graph = tf.get_default_graph()
tf_sess_main = tf.Session(graph=graph)

# Importing Level 1 graph to the default graph with namespace of ved_graph1
meta_graph1 = tf.train.export_meta_graph(graph=detection_graph1)
meta_graph.import_scoped_meta_graph(meta_graph1, import_scope='ved_graph1',)

tf_input1 = graph.get_tensor_by_name('ved_graph1/image_tensor:0')
tf_scores1 = graph.get_tensor_by_name('ved_graph1/detection_scores:0')
tf_boxes1 = graph.get_tensor_by_name('ved_graph1/detection_boxes:0')
tf_classes1 = graph.get_tensor_by_name('ved_graph1/detection_classes:0')
tf_num_detections1 = graph.get_tensor_by_name('ved_graph1/num_detections:0')

boxes1 = tf_boxes1[0]  # index by 0 to remove batch dimension
scores1 = tf_scores1[0]
classes1 = tf_classes1[0]
num_detections1 = tf.dtypes.cast(tf_num_detections1[0], tf.int32)

def image_grid(input_tensor, grid_shape=(5,5), image_shape=(150, 150), num_channels=3):
    # https://github.com/tensorflow/tensorflow/blob/23c218785eac5bfe737eec4f8081fd0ef8e0684d/tensorflow/contrib/gan/python/eval/python/eval_utils_impl.py#L34
    height, width = grid_shape[0] * image_shape[0], grid_shape[1] * image_shape[1]
    input_tensor = tf.reshape(
      input_tensor, tuple(grid_shape) + tuple(image_shape) + (num_channels,))
    input_tensor = tf.transpose(input_tensor, [0, 1, 3, 2, 4])
    input_tensor = tf.reshape(
      input_tensor, [grid_shape[0], width, image_shape[0], num_channels])
    input_tensor = tf.transpose(input_tensor, [0, 2, 1, 3])
    input_tensor = tf.reshape(
      input_tensor, [height, width, num_channels])
    return input_tensor

def get_grid_roies():
    def condition1(i, boxes_pixels):
        return tf.less(i, num_detections1)
    def body1(i, boxes_pixels):
        normalizer = [tf.shape(tf_input1[0])[0], tf.shape(tf_input1[0])[1], tf.shape(tf_input1[0])[0], tf.shape(tf_input1[0])[1]]
        box = tf.multiply(boxes1[i], tf.dtypes.cast(normalizer, tf.float32))
        box = tf.dtypes.cast(tf.round(box), tf.int32)
        boxes_pixels = boxes_pixels.write(i, box)
        return [tf.add(i, 1), boxes_pixels]

    i = tf.constant(0)
    boxes_pixels = tf.TensorArray(dtype=tf.int32,size=1,dynamic_size=True,clear_after_read=False)

    _, boxes_pixels = tf.while_loop(condition1,body1,[i, boxes_pixels])
    boxes_pixels = boxes_pixels.stack()

    def condition2(j, boxes_pixels, roies):
        return tf.less(j, tf.shape(boxes_pixels)[0])
    def body2(j, boxes_pixels, roies):
        startY =  boxes_pixels[j][0]
        startX =  boxes_pixels[j][1]
        endY =  boxes_pixels[j][2]
        endX =  boxes_pixels[j][3]
        roi = tf_input1[0, startY:endY, startX:endX] # batch: 0
        roi = tf.image.resize_image_with_pad(roi,image_shape[0],image_shape[1])
        roi = tf.dtypes.cast(roi, tf.uint8)
        roies = roies.write(j, roi)
        return [tf.add(j, 1), boxes_pixels, roies]

    j = tf.constant(0)
    roies = tf.TensorArray(dtype=tf.uint8,size=1,dynamic_size=True,clear_after_read=False,
                           infer_shape=False)

    _, _, roies = tf.while_loop(condition2,body2,[j, boxes_pixels, roies])

    # Adding padding for making grid
    roies = roies.stack()
    zero_pad = tf.zeros([1,image_shape[0],image_shape[1],num_channels], tf.uint8)
    _no_pad = tf.mod(tf.shape(roies)[0], tf.constant(grid_shape[0]*grid_shape[1]))
    no_pad = tf.cond(tf.equal(_no_pad, tf.constant(0)), lambda: tf.constant(0), 
                     lambda: tf.subtract(tf.constant(grid_shape[0]*grid_shape[1]), _no_pad))
    zero_pad = tf.tile(zero_pad, [no_pad,1,1,1])
    roies = tf.concat([roies, zero_pad], axis=0)

    # Creating batch of images of size grid_shape[0]*image_shape[0]
    size = grid_shape[0]*grid_shape[1]
    n_iter = tf.dtypes.cast(tf.divide(tf.shape(roies)[0], tf.constant(size)), tf.int32)
    k = tf.constant(0)
    grid_roies = tf.TensorArray(dtype=tf.uint8,size=1,dynamic_size=True,clear_after_read=False,infer_shape=False)

    def condition3(k, grid_roies):
        return tf.less(k, n_iter)

    def body3(k, grid_roies):
        grid_roi = image_grid(roies[size*k:size*(k+1)], grid_shape, image_shape, num_channels)
        grid_roies = grid_roies.write(k, grid_roi)
        return [tf.add(k, 1), grid_roies]

    _, grid_roies = tf.while_loop(condition3, body3, [k, grid_roies])

    grid_roies = grid_roies.stack() 

    return grid_roies

def create_empty_grid():
    grid_roies = tf.zeros([1,image_shape[0]*grid_shape[0],image_shape[1]*grid_shape[1],num_channels], tf.uint8)
    return grid_roies

# Grid is filled along the column first
grid_roies = tf.cond(tf.equal(num_detections1, tf.constant(0)), create_empty_grid, get_grid_roies)

# Importing Level 1 graph to the default graph with namespace of ved_graph2
meta_graph2 = tf.train.export_meta_graph(graph=detection_graph2)
meta_graph.import_scoped_meta_graph(meta_graph2, input_map={'image_tensor': grid_roies}, import_scope='ved_graph2',)

tf_scores2 = graph.get_tensor_by_name('ved_graph2/detection_scores:0')
tf_boxes2 = graph.get_tensor_by_name('ved_graph2/detection_boxes:0')
tf_classes2 = graph.get_tensor_by_name('ved_graph2/detection_classes:0')
tf_num_detections2 = graph.get_tensor_by_name('ved_graph2/num_detections:0')

num_detections2 = tf_sess_main.run(tf_num_detections2, feed_dict={tf_input1: img[None, ...]})
```

The last line is throwing me following error:

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1333     try:
-> 1334       return fn(*args)
   1335     except errors.OpError as e:

/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1318       return self._call_tf_sessionrun(
-> 1319           options, feed_dict, fetch_list, target_list, run_metadata)
   1320 

/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)
   1406         self._session, options, feed_dict, fetch_list, target_list,
-> 1407         run_metadata)
   1408 

InvalidArgumentError: Invalid loop structure: Loop ""Preprocessor/map/while/while_context"" has more than one LoopCond node: {{node ved_graph2/Preprocessor/map/while/LoopCond}} and {{node ved_graph1/Preprocessor/map/while/LoopCond}}. This is an internal bug, please file a bug report with instructions on how to reproduce the error.

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-19-f4ccb146461b> in <module>
----> 1 num_detections2 = tf_sess_main.run(tf_num_detections2, feed_dict={tf_input1: img[None, ...]})

/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    927     try:
    928       result = self._run(None, fetches, feed_dict, options_ptr,
--> 929                          run_metadata_ptr)
    930       if run_metadata:
    931         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1150     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1151       results = self._do_run(handle, final_targets, final_fetches,
-> 1152                              feed_dict_tensor, options, run_metadata)
   1153     else:
   1154       results = []

/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1326     if handle is None:
   1327       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1328                            run_metadata)
   1329     else:
   1330       return self._do_call(_prun_fn, handle, feeds, fetches)

/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1346           pass
   1347       message = error_interpolation.interpolate(message, self._graph)
-> 1348       raise type(e)(node_def, op, message)
   1349 
   1350   def _extend_graph(self):

InvalidArgumentError: Invalid loop structure: Loop ""Preprocessor/map/while/while_context"" has more than one LoopCond node: node ved_graph2/Preprocessor/map/while/LoopCond (defined at <ipython-input-16-efb8693a303c>:3)  and node ved_graph1/Preprocessor/map/while/LoopCond (defined at <ipython-input-7-ce9e14bfefad>:8) . This is an internal bug, please file a bug report with instructions on how to reproduce the error.
```

My specifications are:
OS : Mac 10.13.6
TF version: 1.13.1"
33751,Resize layers in model producing LookupError when computing gradients,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04
- TensorFlow version (use command below):2.0
- Python version:3.6.8
- CUDA/cuDNN version:10.0/6.7.0
- GPU model and memory:GTX 1080ti

**Describe the current behavior**
Currently, I'm getting `LookupError: gradient registry has no entry for ResizeBilinearGrad` when its computing tape.gradient(d_loss, D.trainable_variables) in the code below.

**Describe the expected behavior**
The code should just run and update the parameters per usual.

**Code to reproduce the issue**
~~~~
from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, ReLU, Lambda, MaxPool2D, BatchNormalization
from tensorflow.keras import Model, Sequential
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import argparse
import os
import glob
import sys
import time
sys.path.append('..')

########################
## MAKE YOUR NET HERE ##
########################
def conv_mean_pool(inputs, filters, kernel_size):
    INPUT = Input(shape=inputs.shape[1:])
    x = Conv2D(filters, kernel_size, padding='same')(INPUT)
    OUTPUT= (x[::2, ::2, :] + x[::2, 1::2, :] + x[1::2, ::2, :] + x[1::2, 1::2, :])/4
    return Model(inputs = INPUT, outputs = OUTPUT)

def upsample_conv(inputs, filters, kernel_size, input_shape):
    INPUT=Input(shape = inputs.shape[1:])
    x=tf.concat([INPUT, INPUT, INPUT, INPUT], axis = -1)
    x=tf.nn.depth_to_space(x, 2)
    OUTPUT=Conv2D(filters, kernel_size, padding = 'same')(x)
    return Model(inputs = INPUT, outputs = OUTPUT)


def residual_block(name, inputs, filters, kernel_size, strides, input_shape, output_shape, upsample = False):
    INPUT=Input(shape = inputs.shape[1:])
    x=BatchNormalization()(INPUT)
    x=ReLU()(x)

    if upsample == True:
        x=upsample_conv(x, filters, kernel_size, input_shape)(x)
        x=Lambda(lambda z: tf.image.resize(z, size=output_shape, method='nearest'))(x)
        original_scaled= x
        x= BatchNormalization()(x)
        x= ReLU()(x)
        OUTPUT= Conv2D(filters, 3, padding='same')(x) + original_scaled
        return Model(inputs=INPUT, outputs=OUTPUT, name=name)
    else:
        x= Conv2D(filters, 3)(x)
        x=Lambda(lambda z: tf.image.resize(z, size=output_shape))(x)
        original_scaled= x
        x= BatchNormalization()(x)
        x= ReLU()(x)
        OUTPUT= conv_mean_pool(x, filters, kernel_size)(x)
        OUTPUT= Conv2D(filters, 3, padding='same')(x) + original_scaled
        return Model(inputs=INPUT, outputs=OUTPUT, name=name)


def create_discriminator(z_dim, name='Discriminator'):
    INPUT= Input(shape=[100, 100, 3])
    x=Lambda(lambda z: tf.image.resize(z, size=[128, 128]))(INPUT)
    x=Conv2D(3, 3, padding='same')(x)
    x=residual_block('res1', x, 32, 3, 1, [128, 128], [64, 64])(x)
    x=residual_block('res2', x, 32, 3, 1, [64, 64], [32, 32])(x)
    x=residual_block('res3', x, 32, 3, 1, [32, 32], [16, 16])(x)
    x=residual_block('res4', x, 32, 3, 1, [16, 16], [8, 8])(x)
    x=residual_block('res5', x, 32, 3, 1, [8, 8], [8, 8])(x)
    x=Flatten()(x)
    OUTPUT=Dense(1)(x)
    return Model(inputs=INPUT, outputs=OUTPUT)


def create_generator(z_dim, name='Generator'):
    INPUT=Input((z_dim,))
    x=Dense(z_dim*4*4)(INPUT)
    x=tf.reshape(x, (-1, 8, 8, 1))
    x=residual_block('res1', x, 64, 3, 1, [8, 8], [8, 8], upsample = True)(x)
    x=residual_block('res2', x, 32, 3, 1, [8, 8], [16, 16], upsample = True)(x)
    x=residual_block('res3', x, 16, 3, 1, [16, 16], [32, 32], upsample = True)(x)
    x=residual_block('res4', x, 8, 3, 1, [32, 32], [64, 64], upsample = True)(x)
    x=residual_block('res5', x, 4, 3, 1, [64, 64], [128, 128], upsample = True)(x)
    x=BatchNormalization()(x)
    x=ReLU()(x)
    x=Conv2D(3, 3, padding = 'same', activation = 'sigmoid')(x)
    OUTPUT=Lambda(lambda z: tf.image.resize(z, size=[100, 100]))(x)
    return Model(inputs=INPUT, outputs=OUTPUT, name=name)

if __name__ == '__main__':
    parser= argparse.ArgumentParser(description = 'Inputs')
    parser.add_argument('--epochs', type = int, default =100)
    parser.add_argument('--batch_size', type = int, default =64)
    parser.add_argument('--z_dim', type = int, default =128)
    parser.add_argument('--n_critic', type = int, default=5)
    parser.add_argument('--LAMBDA', type=float, default=10)
    parser.add_argument('--shuffle', type = bool, default =True)
    parser.add_argument('--num_parallel_calls', type = int, default =4)
    parser.add_argument('--buffer_size', type = int, default =1000)
    parser.add_argument('--prefetch', type = int, default =1000)
    parser.add_argument('--learning_rate', type = float, default =0.001)
    parser.add_argument('--beta_1', type = float, default =0.0)
    parser.add_argument('--beta_2', type = float, default =0.999)
    args=parser.parse_args('')

    ##########################################################
    ## MAKING DATALOADERS FOR TRAINING, VALIDATION, TESTING ##
    ##########################################################
    train_data = tf.random.normal(shape=(1, 100, 100, 3))
    train_dataloader = tf.data.Dataset.from_tensor_slices(train_data).batch(1)

    #######################################
    ## INITIALIZE MODEL, LOSSES, METRICS ##
    #######################################
    G=create_generator(args.z_dim, 'Generator')
    D=create_discriminator(args.z_dim, 'Discriminator')
    fixed_noise=tf.random.normal(shape=(16, args.z_dim))

    loss_object=tf.keras.losses.BinaryCrossentropy()
    train_loss= tf.keras.metrics.Mean(name = 'train_loss')
    test_accuracy= tf.keras.metrics.Accuracy(name = 'test_accuracy')
    optimizerG=tf.keras.optimizers.Adam(
        learning_rate=args.learning_rate,
        beta_1=args.beta_1,
        beta_2=args.beta_2,
    )
    optimizerD = tf.keras.optimizers.Adam(
        learning_rate=args.learning_rate,
        beta_1=args.beta_1,
        beta_2=args.beta_2,
    )

    G.summary(print_fn=logging.info)
    D.summary(print_fn=logging.info)

    ##############################################
    ## Loss computations and training functions ##
    ##############################################
    @tf.function
    def discriminator_step(fake_image, real_image):
        with tf.GradientTape() as tape:
            epsilon = tf.random.uniform(
                shape=[fake_image.shape[0], 1, 1, 1], minval=0, maxval=1)
            interpolated_image = epsilon*fake_image + (1-epsilon)*real_image
            d_interpolated = D(interpolated_image)
            d_fake = D(fake_image)
            d_real = D(real_image)

            grad_d = tf.gradients(d_interpolated, [interpolated_image])[0]
            slopes = tf.sqrt(
                1e-8 + tf.reduce_sum(tf.square(grad_d), axis=[1, 2, 3]))
            gradient_penalty = tf.reduce_mean((slopes-1.) ** 2)

            d_loss = tf.reduce_mean(
                d_fake) - tf.reduce_mean(d_real) + args.LAMBDA * gradient_penalty

            gradients = tape.gradient(d_loss, D.trainable_variables)
            optimizerD.apply_gradients(
                zip(gradients, D.trainable_variables))

            return d_loss

    @tf.function
    def generator_step(fake_image):
        with tf.GradientTape() as tape:
            d_fake = -D(fake_image)
            g_loss = tf.reduce_mean(d_fake)

            gradients = tape.gradient(g_loss, G.trainable_variables)
            optimizerG.apply_gradients(
                zip(gradients, G.trainable_variables))

            return g_loss

    ###################
    ## TRAINING LOOP ##
    ###################
    iter = 0
    d_loss = 0
    g_loss = 0
    for epoch in range(args.epochs):
        start = time.time()
        for real_image in train_dataloader:
            z = tf.random.normal(shape=(real_image.shape[0], args.z_dim))
            fake_image = G(z)
            d_loss = discriminator_step(fake_image, real_image)

            if iter % args.n_critic == 0:
                z = tf.random.normal()
                fake_image = G(z)
                g_loss = generator_step(fake_image)
~~~~

**Other info / logs**
~~~~
Traceback (most recent call last):
  File ""code/WGAN-GP_issues.py"", line 191, in <module>
    d_loss = discriminator_step(fake_image, real_image)
  File ""/home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 503, in _call
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""/home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 408, in _initialize
    *args, **kwds))
  File ""/home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1848, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 905, in wrapper
    raise e.ag_error_metadata.to_exception(e)
tensorflow.python.autograph.impl.api.StagingError: in converted code:

    code/WGAN-GP_issues.py:162 discriminator_step  *
        gradients = tape.gradient(d_loss, D.trainable_variables)
    /home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py:1014 gradient
        unconnected_gradients=unconnected_gradients)
    /home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/imperative_grad.py:76 imperative_grad
        compat.as_str(unconnected_gradients.value))
    /home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py:134 _gradient_function
        grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access
    /home/xiavatar/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/registry.py:97 lookup
        ""%s registry has no entry for: %s"" % (self._name, name))

    LookupError: gradient registry has no entry for: ResizeBilinearGrad
~~~~"
33749,Pretrained Inception V4 to Keras Application Folder,"Would it be possible to add Inception V4 to the Keras Applications folder?

System/User Specifics: Tensorflow 2.0 with `tf.keras` module

Due to recent discoveries made in neural networks and also according to many benchmarking standards, Inception V4 is one of the best networks available with very high accuracies in both Top 5 and Top 1. 

Inception V4 should be included because it has been consistently proven to be one of the most accurate networks for Image Recognition. It will benefit many users who want a network with very high accuracy and also have the resources to run it. "
33748,Using tf.contrib.framework.nest functions in TF2.0,"The tf.contrib.framework.nest module seems to have been moved to tf.nest after contrib has been deprecated in TF2.0.

However, not all the functions have been exported.
tf.contrib.framework.nest (https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/framework/nest) has the following functions:
assert_same_structure(...)
assert_shallow_structure(..)
flatten(...)
flatten_dict_items(...)
flatten_up_to(...)
flatten_with_joined_string_paths(...)
flatten_with_tuple_paths(...)
flatten_with_tuple_paths_up_to(...)
get_traverse_shallow_structure(...)
is_nested(...)
is_sequence(...)
is_sequence_or_composite(...)
map_structure(...)
map_structure_up_to(...)
map_structure_with_paths(...)
map_structure_with_tuple_paths(...)
map_structure_with_tuple_paths_up_to(...)
pack_sequence_as(...)
yield_flat_paths(...)

where tf.nest (https://www.tensorflow.org/api_docs/python/tf/nest/map_structure) only has the following:
assert_same_structure(...)
flatten(...)
is_nested(...)
map_structure(...)
pack_sequence_as(...)


This is limiting to our application since we depend on specifying a flat structure to limit the nesting of the functions.
More specifically, we would like to use the *_up_to variants and the *_with_paths variants which seems to have been removed in tf.nest

Is there a way to use the previous API (the contrib one) for these functions in TF2.0"
33747,TF2.0 TPU Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run AutoShardDataset: Unable to parse tensor proto,"I am trying to run the MNIST example on the TPU using tf2.0. However, the following error occurred.
InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run AutoShardDataset: Unable to parse tensor proto
Additional GRPC error information:
{""created"":""@1572103296.361904413"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Unable to parse tensor proto"",""grpc_status"":3} [Op:AutoShardDataset]

code: 
```
import os

# # TF 1.x
# resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
# tf.tpu.experimental.initialize_tpu_system(resolver)
# strategy = tf.distribute.experimental.TPUStrategy(resolver)

# TF 2.0
resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_host(resolver.master())
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

with strategy.scope():
  model = create_model()
  model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
    loss=tf.keras.losses.sparse_categorical_crossentropy,
    metrics=[tf.keras.metrics.sparse_categorical_accuracy])

model.fit(
  x_train.astype(np.float32), y_train.astype(np.float32),
  epochs=5,
  steps_per_epoch=60,
  validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),
  validation_freq=5
)

model.save_weights('./fashion_mnist.h5', overwrite=True)
```"
33746,cannot import tensor flow at newest Mac OS X system catalina!,"

**System information**
- OS Platform and Distribution (e.g., Mac OS X catalina):
- TensorFlow installed from ( binary PyPi):
- TensorFlow version: 2.0.0
- Python version: 3.7
- Installed using pip


import tensorflow 

[libprotobuf ERROR google/protobuf/descriptor_database.cc:394] Invalid file descriptor data passed to EncodedDescriptorDatabase::Add().
[libprotobuf FATAL google/protobuf/descriptor.cc:1359] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size):
libc++abi.dylib: terminating with uncaught exception of type google::protobuf::FatalException: CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size):
"
33744,"Tensor zero_padding2d_1_input:0, specified in either feed_devices or fetch_devices was not found in the Graph","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
_custom_
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
```
PRETTY_NAME=""Debian GNU/Linux 10 (buster)""
NAME=""Debian GNU/Linux""
VERSION_ID=""10""
VERSION=""10 (buster)""
VERSION_CODENAME=buster
ID=debian
```
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
none
- TensorFlow installed from (source or binary):
_binary_
- TensorFlow version (use command below):
`v1.14.0-rc1-22-gaf24dc9 1.14.0`
- Python version:
Python 3.7.4
- Bazel version (if compiling from source):
_none_
- GCC/Compiler version (if compiling from source):
_none_
- CUDA/cuDNN version:
_none_
- GPU model and memory:
CPU model

**Describe the current behavior**
This issue happens when running the Tensorflow model inference in a Tornado server started as a Thread.
```python
class WebServer(threading.Thread):
    def run(self):
        application.listen(8888)
        #asyncio.set_event_loop(asyncio.new_event_loop())
        asyncio.set_event_loop(AnyThreadEventLoopPolicy())
        tornado.ioloop.IOLoop.instance().start()
WebServer.start()
```



**Describe the expected behavior**

**Code to reproduce the issue**
Inference running without any issue. The issue does not occur when it starts running on the main thread instead:

```python
application.listen(8888)
application.listen(8888)
tornado.ioloop.IOLoop.instance().start()
```


**Other info / logs**
This error happens on both Tensorflow models I run, so I assume it's a threading problem when running the Graph in a thread that it is not the main thread.

The only error logging I get is
` Tensor zero_padding2d_1_input:0, specified in either feed_devices or fetch_devices was not found in the Graph`"
33743,Hyperlink in codelab redirects to a 404 page,"#32417  URL(s) with the issue:

https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/?utm_campaign=chrome_series_machinelearning_063016&utm_source=gdev&utm_medium=yt-desc#1

## Description of issue (what needs changing):
Update the link to redirect to the latest version of Tensorflow

### Clear description

Always better to redirect to a page that helps out a user, rather than keep links to 404 pages.

### Correct links

Is the link to the source code correct?

### Raises listed and defined

Server raises a 404 Page, which is an error.

### Usage example

It isn't exactly a use case. Just a QoL change.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?
<img width=""1440"" alt=""Screenshot 2019-10-26 at 4 36 23 PM"" src=""https://user-images.githubusercontent.com/41414202/67618592-17435f80-f80f-11e9-9cb1-2b4d9a44ab34.png"">
<img width=""1440"" alt=""Screenshot 2019-10-26 at 4 36 31 PM"" src=""https://user-images.githubusercontent.com/41414202/67618594-1a3e5000-f80f-11e9-92f4-6716b871496f.png"">



### Submit a pull request?
 Yes. I love contributing in small ways, since I'm still a rather newbie developer. Errors even small should be dealt with I presume?

"
33742,"Cannot import tensorflow.math, tensorflow.linalg and much more","
**System information**


**Describe the current behavior**

2.0.0 behavior

```python3
>>> import tensorflow
>>> tensorflow.__version__
'2.0.0'
>>> import tensorflow.linalg
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorflow.linalg'
```

I am unable to import as above, but only `tensorflow.math.sin` works when I import tensorflow.

**Describe the expected behavior**

1.13 and 1.14 behavior
```python3
>>> import tensorflow
>>> tensorflow.__version__
'1.13.1'
>>> import tensorflow.math
>>> import tensorflow.linalg
>>> from tensorflow.math import sin
```
```python3
>>> import tensorflow
>>> tensorflow.__version__
'1.14.0'
>>> import tensorflow.math
>>> import tensorflow.linalg
>>> from tensorflow.math import sin
```

**Code to reproduce the issue**

**Other info / logs**
"
33741,Copy one graph to another,"I want to copy a loaded graph to another one. Here, is what I'm trying to do

```
import tensorflow as tf
import numpy as np
import cv2

input_names = ['image_tensor']
pb_fname1 = ""/Users/vedanshu/frozen_graph/ssd_tomato_l1_frozen_graph.pb""

def get_frozen_graph(graph_file):
    """"""Read Frozen Graph file from disk.""""""
    with tf.gfile.FastGFile(graph_file, ""rb"") as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
    return graph_def

trt_graph1 = get_frozen_graph(pb_fname1)

detection_graph1 = tf.Graph()
with detection_graph1.as_default():
    tf.import_graph_def(trt_graph1, name='')
    tf_sess1 = tf.Session(graph=detection_graph1)

tf_input1 = tf_sess1.graph.get_tensor_by_name(input_names[0] + ':0')
tf_scores1 = tf_sess1.graph.get_tensor_by_name('detection_scores:0')
tf_boxes1 = tf_sess1.graph.get_tensor_by_name('detection_boxes:0')
tf_classes1 = tf_sess1.graph.get_tensor_by_name('detection_classes:0')
tf_num_detections1 = tf_sess1.graph.get_tensor_by_name('num_detections:0')
```

Now I want to copy `tf_input1`, `tf_scores1`, `tf_boxes1`, `tf_num_detections1` to another graph. Currently I'm trying to use `copy_op_to_graph` (depricated) as follows:

```
import sys

detection_graph2 = tf.Graph()

namespace = ""Ved""
copied_variables = []
sys.setrecursionlimit(10000000)

tf_num_detections1_copy = tf.contrib.copy_graph.copy_op_to_graph(tf_num_detections1, detection_graph2,copied_variables, namespace)
```

But the python kernel is getting killed without any error. 

System informations:
OS: Mac OS 10.13.6
Tf veriosn: 1.13.1
RAM: 8GB
"
33740,Why Isn't TensorFlow Website Accessible from Iranian IP Addresses?,"
![Screenshot from 2019-10-26 10-34-20](https://user-images.githubusercontent.com/14098141/67616056-f9f79c80-f7e0-11e9-9499-fb4c3d008fee.png)

I'm Iranian, from Iranian IP address, TensorFlow.org is not accessible?

Now, I have the following questions:

- If I use TensorFlow in my projects, is it illegal? 
- Can you address the article that base on that you have prohibited access to TensorFlow.org for Iranian?
- Is it fair to prohibiting a project that the contributors all around the world are contributing to it?
"
33739,add a new class for realizing Early Stopping,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0 but this is for keras.
- Are you willing to contribute it (Yes/No): yes. I have already realized it and now I am using it.

**Describe the feature and the current behavior/state.**

I want to add a new class for realizing Early Stopping. 

They are based on 3 metrics from paper ""Early Stopping - but when? Lutz Prechelt, University Karlsrhe"". 

1. **Generalization Loss**(GL). GL can be described as a metric that can measure how much current validation loss exceeds the lowest validation loss. Training will stop as soon as GL exceeds a certain threshold. 

2. **Progress Quotient**(PQ).  It considers training strip of length `k`. Progress means how much was the average training error during the strip larger than the minimum training error during the strip. Quotient means use the quotient of GL and Progress. Thus, training will stop as soon as the PQ exceeds a certain threshold. 

3. **UP**. This is simple. Training will stop when the generalization error increased in `s` successive strips.

Combining these metrics, there are 5 modes for doing early stopping. 1, 2, 3, 1+3, 2+3.

Now the EarlyStopping class of Keras can only stop training based on patience and delta, whereas there are advanced and useful early stopping methods.

**Will this change the current api? How?**

No. Only a new class will be added.

**Who will benefit with this feature?**

Basically all workers using Keras.

**Any Other info.**

This idea comes from others paper, I just realized it. For further info, please refer to the paper.
[early stopping - but when.pdf](https://github.com/tensorflow/tensorflow/files/3774558/early.stopping.-.but.when.pdf)

"
33738,"TypeError: expected str, bytes or os.PathLike object, not NoneType","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
pip install tensorflow-gpu
- TensorFlow version:
2
- Python version:
3.7
- Installed using virtualenv? pip? conda?:
pip in a conda env
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
cuda 10.0.1
- GPU model and memory:
GeForce GTX 1050 Ti with Max-Q Design/PCIe/SSE2


**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
import tensorflow as tf

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow/__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/__init__.py"", line 45, in <module>
    from . _api.v2 import compat
  File ""/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/_api/v2/compat/__init__.py"", line 23, in <module>
    from . import v1
  File ""/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/_api/v2/compat/v1/__init__.py"", line 666, in <module>
    [_module_util.get_parent_dir(estimator)] + _current_module.__path__)
  File ""/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/tools/module_util.py"", line 24, in get_parent_dir
    return os.path.abspath(os.path.join(os.path.dirname(module.__file__), ""..""))
  File ""/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/posixpath.py"", line 156, in dirname
    p = os.fspath(p)
TypeError: expected str, bytes or os.PathLike object, not NoneType
"
33737,AttributeError: module 'tensorflow' has no attribute 'matrix_band_part',"There is a past issue #30297, but no updates. The reproducible example is here.

https://github.com/bojone/bert4keras/blob/eb4dcffd72b9ba08a7ccfb11aee8cdfaeed2d1df/bert4keras/bert.py#L292-L300

I get this error `AttributeError: module 'tensorflow' has no attribute 'matrix_band_part'`, when I run sorta code in Jupyter notebook.
Surely, I install 2.0.0 Tensorflow on Windows 7.  Here is my session information.

<details>
<summary>Session Info</summary>

```bash
# packages in environment at D:\install\miniconda:
#
# Name                    Version                   Build  Channel
absl-py                   0.8.1                    pypi_0    pypi
asn1crypto                0.24.0                   py37_0  
astor                     0.8.0                    pypi_0    pypi
atomicwrites              1.3.0                    pypi_0    pypi
attrs                     19.1.0                   py37_1  
backcall                  0.1.0                    py37_0  
bert-tensorflow           1.0.1                    pypi_0    pypi
blas                      1.0                         mkl    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
bleach                    3.1.0                    py37_0  
blis                      0.4.1                    pypi_0    pypi
boto                      2.49.0                   pypi_0    pypi
boto3                     1.9.252                  pypi_0    pypi
botocore                  1.12.252                 pypi_0    pypi
bzip2                     1.0.8                he774522_0  
ca-certificates           2019.5.15                     0  
certifi                   2019.6.16                py37_1  
cffi                      1.12.3           py37h7a1dbc1_0  
chardet                   3.0.4                    py37_1  
colorama                  0.4.1                    py37_0  
conda                     4.7.10                   py37_0  
conda-package-handling    1.3.11                   py37_0  
console_shortcut          0.1.1                         3  
cryptography              2.7              py37h7a1dbc1_0  
cycler                    0.10.0                   pypi_0    pypi
cymem                     2.0.2                    pypi_0    pypi
decorator                 4.4.0                    py37_1  
defusedxml                0.6.0                      py_0  
docutils                  0.15.2                   pypi_0    pypi
entrypoints               0.3                      py37_0  
fastprogress              0.1.21                   pypi_0    pypi
freetype                  2.9.1                ha9979f8_1  
funcy                     1.13                     pypi_0    pypi
future                    0.18.1                   pypi_0    pypi
gast                      0.2.2                    pypi_0    pypi
gensim                    3.8.1                    pypi_0    pypi
google-pasta              0.1.7                    pypi_0    pypi
grpcio                    1.24.1                   pypi_0    pypi
h5py                      2.10.0                   pypi_0    pypi
icc_rt                    2019.0.0             h0cc432a_1  
icu                       58.2                 ha66f8fd_1  
idna                      2.8                      py37_0  
importlib-metadata        0.23                     pypi_0    pypi
intel-openmp              2019.4                      245  
ipykernel                 5.1.1            py37h39e3cac_0  
ipython                   7.7.0            py37h39e3cac_0  
ipython_genutils          0.2.0                    py37_0  
ipywidgets                7.5.0                      py_0  
jedi                      0.13.3                   py37_0  
jieba                     0.39                     pypi_0    pypi
jinja2                    2.10.1                   py37_0  
jmespath                  0.9.4                    pypi_0    pypi
joblib                    0.14.0                   pypi_0    pypi
jpeg                      9b                   hb83a4c4_2  
jsonschema                3.0.1                    py37_0  
jupyter                   1.0.0                    py37_7  
jupyter_client            5.3.1                      py_0  
jupyter_console           6.0.0                    py37_0  
jupyter_core              4.5.0                      py_0  
keras                     2.3.1                    pypi_0    pypi
keras-applications        1.0.8                    pypi_0    pypi
keras-bert                0.80.0                   pypi_0    pypi
keras-embed-sim           0.7.0                    pypi_0    pypi
keras-layer-normalization 0.13.0                   pypi_0    pypi
keras-multi-head          0.22.0                   pypi_0    pypi
keras-pos-embd            0.11.0                   pypi_0    pypi
keras-position-wise-feed-forward 0.6.0                    pypi_0    pypi
keras-preprocessing       1.1.0                    pypi_0    pypi
keras-rectified-adam      0.17.0                   pypi_0    pypi
keras-self-attention      0.41.0                   pypi_0    pypi
keras-transformer         0.31.0                   pypi_0    pypi
kiwisolver                1.1.0                    pypi_0    pypi
libarchive                3.3.3                h0643e63_5  
libiconv                  1.15                 h1df5818_7  
libpng                    1.6.37               h2a8f88b_0  
libsodium                 1.0.16               h9d3ae62_0  
libtiff                   4.0.10               hb898794_2  
libxml2                   2.9.9                h464c3ec_0  
lightgbm                  2.3.0                    pypi_0    pypi
lz4-c                     1.8.1.2              h2fa13f4_0  
lzo                       2.10                 h6df0209_2  
m2w64-gcc-libgfortran     5.3.0                         6  
m2w64-gcc-libs            5.3.0                         7  
m2w64-gcc-libs-core       5.3.0                         7  
m2w64-gmp                 6.1.0                         2  
m2w64-libwinpthread-git   5.0.0.4634.697f757               2  
markdown                  3.1.1                    pypi_0    pypi
markupsafe                1.1.1            py37he774522_0  
matplotlib                3.1.1                    pypi_0    pypi
menuinst                  1.4.16           py37he774522_0  
mistune                   0.8.4            py37he774522_0  
mkl                       2019.4                      245  
mkl_fft                   1.0.12           py37h14836fe_0  
mkl_random                1.0.2            py37h343c172_0  
more-itertools            7.2.0                    pypi_0    pypi
msys2-conda-epoch         20160418                      1  
murmurhash                1.0.2                    pypi_0    pypi
nbconvert                 5.5.0                      py_0  
nbformat                  4.4.0                    py37_0  
ninja                     1.7.2                         0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
notebook                  6.0.0                    py37_0  
numexpr                   2.7.0                    pypi_0    pypi
numpy                     1.16.4           py37h19fb1c0_0  
numpy-base                1.16.4           py37hc3f5095_0  
olefile                   0.46                     py37_0  
opencv-python             4.1.0.25                 pypi_0    pypi
openssl                   1.1.1c               he774522_1  
opt-einsum                3.1.0                    pypi_0    pypi
packaging                 19.2                     pypi_0    pypi
pandas                    0.25.0           py37ha925a31_0  
pandoc                    1.19.2.1                      1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
pandocfilters             1.4.2                    py37_1  
parso                     0.5.0                      py_0  
pickleshare               0.7.5                    py37_0  
pillow                    6.1.0            py37hdc69c19_0  
pip                       19.1.1                   py37_0  
plac                      0.9.6                    pypi_0    pypi
pluggy                    0.13.0                   pypi_0    pypi
powershell_shortcut       0.0.1                         2  
preshed                   3.0.2                    pypi_0    pypi
prometheus_client         0.7.1                      py_0  
prompt_toolkit            2.0.9                    py37_0  
protobuf                  3.10.0                   pypi_0    pypi
py                        1.8.0                    pypi_0    pypi
pycosat                   0.6.3            py37hfa6e2cd_0  
pycparser                 2.19                     py37_0  
pygments                  2.4.2                      py_0  
pyks                      1.1.3                    pypi_0    pypi
pyldavis                  2.1.2                    pypi_0    pypi
pyopenssl                 19.0.0                   py37_0  
pyparsing                 2.4.2                    pypi_0    pypi
pyqt                      5.9.2            py37h6538335_2  
pyrsistent                0.14.11          py37he774522_0  
pysocks                   1.7.0                    py37_0  
pytest                    5.2.1                    pypi_0    pypi
python                    3.7.3                h8c8aaf0_1  
python-dateutil           2.8.0                    py37_0  
python-libarchive-c       2.8                     py37_11  
pytorch-cpu               1.1.0               py3.7_cpu_1    pytorch
pytz                      2019.1                     py_0  
pywin32                   223              py37hfa6e2cd_1  
pywinpty                  0.5.5                 py37_1000  
pyyaml                    5.1.2                    pypi_0    pypi
pyzmq                     18.0.0           py37ha925a31_0  
qt                        5.9.7            vc14h73c81de_0  
qtconsole                 4.5.2                      py_0  
requests                  2.22.0                   py37_0  
ruamel_yaml               0.15.46          py37hfa6e2cd_0  
s3transfer                0.2.1                    pypi_0    pypi
scikit-learn              0.21.3                   pypi_0    pypi
scipy                     1.3.1                    pypi_0    pypi
seaborn                   0.9.0                    pypi_0    pypi
send2trash                1.5.0                    py37_0  
setuptools                41.0.1                   py37_0  
sip                       4.19.8           py37h6538335_0  
six                       1.12.0                   py37_0  
smart-open                1.8.4                    pypi_0    pypi
spacy                     2.2.1                    pypi_0    pypi
sqlite                    3.29.0               he774522_0  
srsly                     0.1.0                    pypi_0    pypi
tensorboard               2.0.0                    pypi_0    pypi
tensorflow                2.0.0                    pypi_0    pypi
tensorflow-estimator      2.0.1                    pypi_0    pypi
tensorflow-hub            0.6.0                    pypi_0    pypi
termcolor                 1.1.0                    pypi_0    pypi
terminado                 0.8.2                    py37_0  
testpath                  0.4.2                    py37_0  
thinc                     7.1.1                    pypi_0    pypi
tk                        8.6.8                hfa6e2cd_0  
torchvision-cpu           0.3.0             py37_cuNone_1    pytorch
tornado                   6.0.3            py37he774522_0  
tqdm                      4.32.1                     py_0  
traitlets                 4.3.2                    py37_0  
urllib3                   1.24.2                   py37_0  
vc                        14.1                 h0510ff6_4  
vs2015_runtime            14.15.26706          h3a45250_4  
wasabi                    0.2.2                    pypi_0    pypi
wcwidth                   0.1.7                    py37_0  
webencodings              0.5.1                    py37_1  
werkzeug                  0.16.0                   pypi_0    pypi
wheel                     0.33.4                   py37_0  
widgetsnbextension        3.5.0                    py37_0  
win_inet_pton             1.1.0                    py37_0  
wincertstore              0.2                      py37_0  
winpty                    0.4.3                         4  
wrapt                     1.11.1                   pypi_0    pypi
xlrd                      1.2.0                    pypi_0    pypi
xz                        5.2.4                h2fa13f4_4  
yaml                      0.1.7                hc54c509_2  
zeromq                    4.3.1                h33f27b4_3  
zipp                      0.6.0                    pypi_0    pypi
zlib                      1.2.11               h62dcd97_3  
zstd                      1.3.7                h508b16e_0  
```

</details>"
33736,AttributeError: module 'tensorflow_core._api.v2.image' has no attribute 'resize_images',"I am trying to load pspnet pretrained model and encountered the said error.
AttributeError: module 'tensorflow_core._api.v2.image' has no attribute 'resize_images'
Could please guide me how resolve this?
Config: Windows10
using Juyter notebook
tensorflow version: 2.0.0
code source : https://github.com/divamgupta/image-segmentation-keras
The code used to reproduce the issue is:
import keras_segmentation
model = keras_segmentation.pretrained.pspnet_101_voc12()"
33735,Large bias values for Inception V4 TFLite model,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.

Model: Inception V4
Dataset: Dog 120. 
Calibration images: 10 images of resolution 299x299

Steps to convert to TFLite model:
- converter = tf.lite.TFLiteConverter.from_frozen_graph(model_file,  [input_node], [output_node])
- converter.optimizations = [tf.lite.Optimize.DEFAULT]
- converter.representative_dataset = representative_dataset_gen
- with open(tflite_model_file, ""wb"") as w:
	w.write(converter.convert())

I see the bias values of most of the convolution having values such as ""-2147483647"". Below is an example. 

![image](https://user-images.githubusercontent.com/5778892/67609304-e137aa00-f740-11e9-86a6-ddb9ff382f39.png)

The corresponding frozen protobuf value is:

![image](https://user-images.githubusercontent.com/5778892/67609341-147a3900-f741-11e9-89b0-2a817c476dde.png)

Can someone help me understand why the quantization is happening in such a way for the INT32 biases ? 


"
33734,RuntimeError:Data adapters should be mutually exclusive,"Today I run [transfer_learning_with_hub.ipynb](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb) **on Google Colab**, It show errors info below.
**But yesterday I run this jupyter nootbook successfully.**

It seems that  using the latest TensorFlow version **2.1.0-dev20191025** cause the problem

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**Linux 5c32dbcf8bfd 4.14.137+ #1 SMP Thu Aug 8 02:47:02 PDT 2019 x86_64 x86_64 x86_64 GNU/Linux**
- TensorFlow version (use command below):**'2.1.0-dev20191025'**
- Python version:**Python 3.6.8**
- GCC/Compiler version (if compiling from source): **[GCC 8.3.0] on linux**
- CUDA/cuDNN version:
- GPU model and memory:12.72GB


**Describe the current behavior**
errors is below

**Describe the expected behavior**
Yesterday, I run this jupyter nootbook successfully.

**Code to reproduce the issue**
when runnig codes below it show errors
```
steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)
batch_stats_callback = CollectBatchStats()
history = model.fit_generator(image_data, epochs=2,
                              steps_per_epoch=steps_per_epoch,
                              callbacks = [batch_stats_callback])
```


**Other info / logs**
```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-52-dd38f4e8ca03> in <module>()
      5 history = model.fit_generator(image_data, epochs=2,
      6                               steps_per_epoch=steps_per_epoch,
----> 7                               callbacks = [batch_stats_callback])

5 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py in select_data_adapter(x, y)
    979         ""handling inputs. Found multiple adapters {} to handle ""
    980         ""input: {}, {}"".format(
--> 981             adapter_cls, _type_name(x), _type_name(y)))
    982   return adapter_cls[0]
    983 

RuntimeError: Data adapters should be mutually exclusive for handling inputs. Found multiple adapters [<class 'tensorflow.python.keras.engine.data_adapter.GeneratorDataAdapter'>, <class 'tensorflow.python.keras.engine.data_adapter.KerasSequenceAdapter'>] to handle input: <class 'keras_preprocessing.image.directory_iterator.DirectoryIterator'>, <class 'NoneType'>
```
"
33733,TF2 compilation of rule //tensorflow/lite/experimental/ruy:pack failed,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source, git clone
- TensorFlow version: r2.0
- Python version: Python 3.6.8
- Installed using virtualenv? pip? condo?: git clone https://github.com/tensorflow/tensorflow.git
- Bazel version (if compiling from source): 0.26.0, Build timestamp: 1559032514
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
- CUDA/cuDNN version: Not part of the compilation.
- GPU model and memory: No GPU support

This is built on AWS r5.large server, 16 GB RAM



**Describe the problem**
ERROR: /srv/projects/tf2/tfgit/tensorflow/lite/experimental/ruy/BUILD:297:1: C++ compilation of rule '//tensorflow/lite/experimental/ruy:pack' failed (Exit 1)
In file included from tensorflow/lite/experimental/ruy/pack_avx512.cc:16:0:
./tensorflow/lite/experimental/ruy/pack.h:489:9: warning: multi-line comment [-Wcomment]
 #endif  // (RUY_PLATFORM(NEON_64) || RUY_PLATFORM(NEON_32)) && \

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached."
33730,"TypeError: expected str, bytes or os.PathLike object, not NoneType","
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow/__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/__init__.py"", line 45, in <module>
    from . _api.v2 import compat
  File ""/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/_api/v2/compat/__init__.py"", line 23, in <module>
    from . import v1
  File ""/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/_api/v2/compat/v1/__init__.py"", line 666, in <module>
    [_module_util.get_parent_dir(estimator)] + _current_module.__path__)
  File ""/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/tools/module_util.py"", line 24, in get_parent_dir
    return os.path.abspath(os.path.join(os.path.dirname(module.__file__), ""..""))
  File ""/home/aswin/anaconda3/envs/tfgpu/lib/python3.7/posixpath.py"", line 156, in dirname
    p = os.fspath(p)
TypeError: expected str, bytes or os.PathLike object, not NoneType"
33729,TypeError: An op outside of the function building code is being passed a Graph tensor,"**System information**
- Have I written custom code: Yes.
- OS Platform and Distribution: Mac OS Catalina: 10.15 (19A602)
- TensorFlow installed from: binary
- TensorFlow version: 2.0.0
- Python version: 3.7.4
- GPU model and memory: Intel Iris Pro 1536 MB

**Describe the current behavior**

I am getting the error

> tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'conv2d_flipout/divergence_kernel:0' shape=() dtype=float32>]

After having gotten the exception

> TypeError: An op outside of the function building code is being passed a Graph tensor

See the detailed traceback below.

**Describe the expected behavior**

No error.

**Code to reproduce the issue**

```
from __future__ import print_function

import tensorflow as tf
import tensorflow_probability as tfp

# tf.compat.v1.disable_eager_execution()

def get_bayesian_model(input_shape=None, num_classes=10):
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.Input(shape=input_shape))
    model.add(tfp.layers.Convolution2DFlipout(6, kernel_size=5, padding=""SAME"", activation=tf.nn.relu))
    model.add(tf.keras.layers.Flatten())
    model.add(tfp.layers.DenseFlipout(84, activation=tf.nn.relu))
    model.add(tfp.layers.DenseFlipout(num_classes))
    return model

def get_mnist_data(normalize=True):
    img_rows, img_cols = 28, 28
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

    if tf.keras.backend.image_data_format() == 'channels_first':
        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
        input_shape = (1, img_rows, img_cols)
    else:
        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
        input_shape = (img_rows, img_cols, 1)

    x_train = x_train.astype('float32')
    x_test = x_test.astype('float32')

    if normalize:
        x_train /= 255
        x_test /= 255

    return x_train, y_train, x_test, y_test, input_shape


def train():
    # Hyper-parameters.
    batch_size = 128
    num_classes = 10
    epochs = 1

    # Get the training data.
    x_train, y_train, x_test, y_test, input_shape = get_mnist_data()

    # Get the model.
    model = get_bayesian_model(input_shape=input_shape, num_classes=num_classes)

    # Prepare the model for training.
    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=""sparse_categorical_crossentropy"",
                  metrics=['accuracy'])

    # Train the model.
    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)
    model.evaluate(x_test, y_test, verbose=0)


if __name__ == ""__main__"":
    train()
```

**Other info / logs**

```
WARNING:tensorflow:From /Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_probability/python/layers/util.py:104: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.add_weight` method instead.
2019-10-25 20:38:32.504579: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-25 20:38:32.517426: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe25e59f290 executing computations on platform Host. Devices:
2019-10-25 20:38:32.517438: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
Train on 60000 samples
Traceback (most recent call last):
  128/60000 [..............................] - ETA: 7:32  File ""/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py"", line 61, in quick_execute
    num_outputs)
TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: conv2d_flipout/divergence_kernel:0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/nbro/Desktop/my_project/my_module.py"", line 63, in <module>
    train()
  File ""/Users/nbro/Desktop/my_project/my_module.py"", line 58, in train
    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)
  File ""/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1823, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File ""/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 511, in call
    ctx=ctx)
  File ""/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py"", line 75, in quick_execute
    ""tensors, but found {}"".format(keras_symbolic_tensors))
tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'conv2d_flipout/divergence_kernel:0' shape=() dtype=float32>]
```

The problem is apparently related to the layer `tfp.layers.Convolution2DFlipout`. I know that if I use `tf.compat.v1.disable_eager_execution()` after having imported TensorFlow, I do not get the mentioned error anymore, but I would like to use TensorFlow's eager execution, avoid sessions or placeholders.

I opened the same issue here: https://github.com/tensorflow/probability/issues/620."
33727,Disabling eager execution while training ~90 layers of BatchNormalization exhausts RAM,"Disabling eager execution while training a network with a number of BatchNormalization will take unreasonable amount of RAM before training happens. It might be related that BatchNormalization lacks an `_XlaCompiler` attribute.
I find that I am in an awkward state: my script is a long-running script, and if I enable eager execution, GPU RAM will be used up due to some unknown memory leakage + my script will run ULTRA SLOWLY due to unbatched nature of queries of model.predict (GPU usage 30% in disabling eager execution mode v.s. 9% in enabling eager execution mode); if I disable eager execution, then this bug takes up my CPU RAM. 

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- TensorFlow installed from (source or binary): docker: tensorflow/tensorflow latest-gpu-py3       f7932d1761bd
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.6.8

**Describe the current behavior**
Writing ~90 layers of BatchNormalization takes around 8G RAM before training when disabling eager mode, even with matrix dimension small. Like 100M per BatchNormalization in python3.6.8, regardless of dimensions.
EDIT: I did some experiment and found that the memory usage is approximately linear to the number of `BatchNormalization`s.

**Describe the expected behavior**
Writing ~90 layers of BatchNormalization should take smaller amount of RAM.

**Code to reproduce the issue**
```
from tensorflow.python.framework.ops import disable_eager_execution
import numpy as np
DISABLE_EAGER = 1
resnet_depth = 96

if DISABLE_EAGER:
    disable_eager_execution()
if True:
    from tensorflow.keras.optimizers import *
    from tensorflow.keras.layers import *
    from tensorflow.keras.models import *


def init():
    # game params
    board_x, board_y = 3, 3
    action_size = 10
    depth_dim = 2

    input_boards = Input(
        shape=(board_x, board_y, depth_dim))
    num_chan = 4
    h_conv1 = Activation('relu')(BatchNormalization(axis=3)(
        Conv2D(num_chan, 1, padding='same', use_bias=False)(input_boards)))
    for i in range(resnet_depth):
        h_conv1 = Activation('relu')(BatchNormalization(axis=3)(
            Conv2D(num_chan, 1, padding='same', use_bias=False)(h_conv1)))
    hf = Flatten()(h_conv1)
    s_fc1 = Dropout(0.3)(Activation('relu')(BatchNormalization(axis=1)(
        Dense(16, use_bias=False)(hf))))
    pi = Dense(action_size, activation='softmax', name='pi')(
        s_fc1)

    model = Model(inputs=input_boards, outputs=pi)
    model.compile(
        loss=['categorical_crossentropy'], optimizer=Adam(0.001))
    return model


m = init()
print('inited model')
m.fit(x=np.zeros((1, 3, 3, 2)), y=np.zeros((1, 10)))

```

**Other info / logs**
None
"
33725,`fit_generator` (tf.keras.utils.Sequence) is not supported for models compiled with tf.distribute.Strategy,"**System information**
- OS Platform and Distribution: Arch Linux (Linux-5.3.7-arch1-1-ARCH-x86_64-with-arch)
- TensorFlow installed from (source or binary): binary
- TensorFlow version:  2.0.0
- Keras version: 2.2.4-tf
- Python version: 3.7.4
- GCC/Compiler version: 9.2.0
- CUDA/cuDNN version: cuda 10.1.243-1 / cudnn 7.6.4.38-1
- GPU model and memory: 2x GeForce GTX 1080 Ti 11GB

**Describe the current behavior**
- Model.fit_generator() invoked with generator dervied from tf.keras.utils.Sequence
- execution fails with NotImplementedError

```
strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
         model = OCRNet.build(train_gen.output_size, img_w, img_h, max_text_len)
         adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)
         model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam, metrics=['accuracy'])
history = model.fit_generator(
         generator=train_gen,
         epochs=epochs,
         validation_data=val_gen,
         use_multiprocessing=True,
         workers=6,
         callbacks=callbacks)
```

**Other info / logs**

> Traceback (most recent call last):
>   File ""src/models/train.py"", line 119, in <module>
>     main()
>   File ""src/models/train.py"", line 112, in main
>     fit(model, train_gen, val_gen, epochs, callbacks)
>   File ""src/models/train.py"", line 39, in fit
>     callbacks=callbacks)
>   File ""/usr/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1277, in fit_generator
>     raise NotImplementedError('`fit_generator` is not supported for '
> NotImplementedError: `fit_generator` is not supported for models compiled with tf.distribute.Strategy."
33724,Infinite loop with generators wrapping a dataset in tf.function,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): `v2.0.0-rc2-26-g64c3d38 2.0.0`
- Python version: 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0 / 7.6.3
- GPU model and memory: TITAN Xp, 12196MiB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

My use case was to use `tqdm` to track progress on a training loop over a `tf.data.Dataset`:

```python
@tf.function
def train_one_epoch(model, dataset):
    for x in tqdm(dataset):
        train_step(model, x)
```

However, when the function `train_one_epoch` is wrapped in a `tf.function`, the AutoGraph is stuck in an infinite loop. 

**Describe the expected behavior**

The expected behavior would be that using `tf.function` results in the same behavior than the eager mode.

The current issue is that AutoGraph doesn't recognize `tqdm(dataset)` as a `tf.data.Dataset` (which is normal). However, iterating infinitely over the dataset in AutoGraph is weird and shouldn't happen. Maybe it should give an exception.

Maybe the easiest fix would be to prevent `dataset.__iter__` being called inside `tf.function` if it is not in a loop.  
So `for x in dataset` would be fine, but `for x in tqdm(dataset)` wouldn't.


**Code to reproduce the issue**

```python
import tensorflow as tf


class Iterable():
    def __init__(self, iterable):
        self.iterable = iterable

    def __iter__(self):
        for obj in self.iterable:
            yield obj

@tf.function
def f(dataset):
    for x in Iterable(dataset):
        print(x)

dataset = tf.data.Dataset.range(5)
f(dataset)
```

The minimal `Iterable` class can be replaced by `tqdm` (`from tqdm import tqdm`), and this should yield the same results.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


Without the `@tf.function`, the wrapped dataset `Iterable(dataset)` is iterated over in eager mode:
```
tf.Tensor(0, shape=(), dtype=int64)
tf.Tensor(1, shape=(), dtype=int64)
tf.Tensor(2, shape=(), dtype=int64)
tf.Tensor(3, shape=(), dtype=int64)
tf.Tensor(4, shape=(), dtype=int64)
```

With the `@tf.function`, the AutoGraph mode doesn't recognize the wrapped `Iterable(dataset)` as a `tf.data.Dataset`, so it tries to iterate over it in python to trace the graph. However, it looks like the `Iterable(dataset).__iter__` infinitely yields a next element named `IteratorGetNext`.

This results in an infinite iteration over the dataset:
```
Tensor(""IteratorGetNext:0"", shape=(), dtype=int64)
Tensor(""IteratorGetNext_1:0"", shape=(), dtype=int64)
Tensor(""IteratorGetNext_2:0"", shape=(), dtype=int64)
Tensor(""IteratorGetNext_3:0"", shape=(), dtype=int64)
Tensor(""IteratorGetNext_4:0"", shape=(), dtype=int64)
Tensor(""IteratorGetNext_5:0"", shape=(), dtype=int64)
Tensor(""IteratorGetNext_6:0"", shape=(), dtype=int64)
Tensor(""IteratorGetNext_7:0"", shape=(), dtype=int64)
...
```"
33723,Training loop freezes and then stops when try to run Cycle-GAN on multi-GPU system on Google GCP using 'tf.distribute.MirroredStrategy()' .,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NaN
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0.0
- Python version:3.6
- Bazel version (if compiling from source): NaN
- GCC/Compiler version (if compiling from source): NaN
- CUDA/cuDNN version: 10
- GPU model and memory: 4 Nvidia Tesla K80's of 11GB each

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Training loop stops after few steps in the first epoch itself.
**Describe the expected behavior**
Training loop should run smoothly.

**Other info / logs**
The link below contains a zip file in which the python scripts which I used to train this model on Multi GPU using 'tf.distribute.MirroredStrategy()' is stored.
[The python scripts can be found here](https://drive.google.com/file/d/17TBNfs1h0Lnolq5ZaomqE9pTzdoGjEWb/view?usp=sharing)

> Running 'download.py' will download the dataset that I used.

> 'model.py' contains code for the architecture of the generator and the discriminator that  I used for training this Cycle-GAN

> 'utils.py' contains code that I used for preprocessing the images 

> 'main.py' contains the code in which I used 'tf.distribute.MirroredStrategy()' for multi-GPU training but it stops after few steps in the first epoch."
33722,Tensorflow 2.0 error when used via pyinstaller build - ImportError: cannot import name 'pywrap_tensorflow' from 'tensorflow_core.python',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
This has happened after upgrade to Tensorflow 2.0 . 

On executing the EXE file generated by Pyinstaller for Tensorflow 2.0, we get the following error:

'ImportError: cannot import name 'pywrap_tensorflow' from 'tensorflow_core.python'

The scripts work okay in PyCharm or Jupyter. The same version of scripts when run under Tensorflow 1.x execute correctly




**Provide the exact sequence of commands / steps that you executed before running into the problem**
1.  upgraded tensorflow to 2.0
2. Adjusted python code to accommodate module dependence from Keras to tf.keras
3. Build exe --onefile via pyinstaller
4. on execution of exe get the following error 
""ImportError: cannot import name 'pywrap_tensorflow' from 'tensorflow_core.python' ""


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33721,CancelledError:  [_Derived_]RecvAsync is cancelled. 	 [[{{node Reshape_17/_52}}]] 	 [[GroupCrossDeviceControlEdges_0/RMSprop/RMSprop/Const/_57]] [Op:__inference_distributed_function_24912],"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NaN
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: v10.1
- GPU model and memory: GTX 1060 6GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
During fitting the data, it gives Cancelled Error in the very first batch
**Describe the expected behavior**
To ""Fit"" the model without error
**Code to reproduce the issue**
`max_len_text=275`
`max_len_summary=28`
`from keras import backend as K `
`K.clear_session() `
`latent_dim = 500 `
`encoder_inputs = Input(shape=(max_len_text,)) `
`enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs)` 
`encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True)` 
`encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) `
`encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True)` 
`encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) `
`encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True)` 
`encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)`  
`decoder_inputs = Input(shape=(None,)) `
`dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True)` 
`dec_emb = dec_emb_layer(decoder_inputs) `
`decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)` 
`decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) `
`attn_layer = AttentionLayer(name='attention_layer') `
`attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])`
`decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])`
`decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) `
`decoder_outputs = decoder_dense(decoder_concat_input) `
`model = Model([encoder_inputs, decoder_inputs], decoder_outputs) `
`model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')`
`es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)`
`Model_training=model.fit([X_train,Y_train[:,:-1]], Y_train.reshape(Y_train.shape[0],Y_train.shape[1], 1)[:,1:]  ,epochs=50,callbacks=[es],batch_size=256, validation_data=([X_test,Y_test[:,:-1]],Y_test.reshape(Y_test.shape[0],Y_test.shape[1], 1)[:,1:]))`

Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Train on 314860 samples, validate on 78716 samples
Epoch 1/50
   256/314860 [..............................] - ETA: 5:22WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: 

---------------------------------------------------------------------------
CancelledError                            Traceback (most recent call last)
<ipython-input-30-8fb3a6c938b7> in <module>
      1 Model_training=model.fit([X_train,Y_train[:,:-1]], Y_train.reshape(Y_train.shape[0],Y_train.shape[1], 1)[:,1:] 
      2                          ,epochs=50,callbacks=[es],batch_size=256, validation_data=([X_test,Y_test[:,:-1]], 
----> 3                          Y_test.reshape(Y_test.shape[0],Y_test.shape[1], 1)[:,1:]))

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--> 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    322                 mode=ModeKeys.TRAIN,
    323                 training_context=training_context,
--> 324                 total_epochs=epochs)
    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    326 

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    121         step=step, mode=mode, size=current_batch_size) as batch_logs:
    122       try:
--> 123         batch_outs = execution_function(iterator)
    124       except (StopIteration, errors.OutOfRangeError):
    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in execution_function(input_fn)
     84     # `numpy` translates Tensors to values in Eager mode.
     85     return nest.map_structure(_non_none_constant_value,
---> 86                               distributed_function(input_fn))
     87 
     88   return execution_function

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--> 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    485       # In this case we have created variables on the first call, so we run the
    486       # defunned version which is guaranteed to never create variables.
--> 487       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
    488     elif self._stateful_fn is not None:
    489       # Release the lock early so that multiple threads can perform the call

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   1821     """"""Calls a graph function specialized to the inputs.""""""
   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   1824 
   1825   @property

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
   1139          if isinstance(t, (ops.Tensor,
   1140                            resource_variable_ops.BaseResourceVariable))),
-> 1141         self.captured_inputs)
   1142 
   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1222     if executing_eagerly:
   1223       flat_outputs = forward_function.call(
-> 1224           ctx, args, cancellation_manager=cancellation_manager)
   1225     else:
   1226       gradient_name = self._delayed_rewrite_functions.register()

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    509               inputs=args,
    510               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 511               ctx=ctx)
    512         else:
    513           outputs = execute.execute_with_cancellation(

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

C:\ProgramData\Anaconda3\lib\site-packages\six.py in raise_from(value, from_value)

CancelledError:  [_Derived_]RecvAsync is cancelled.
	 [[{{node Reshape_17/_52}}]]
	 [[GroupCrossDeviceControlEdges_0/RMSprop/RMSprop/Const/_57]] [Op:__inference_distributed_function_24912]

Function call stack:
distributed_function"
33720,Generating Arduino Libraries error,"**System information**
- OS Platform and Distribution : macOS 10.14.6
- TensorFlow version: 1.15.0
- Python version: 2.7.10 and 3.7.4 

**Describe the problem**
When i run the command ""sh test_arduino.sh"" it gaves me that error:
```
...
Finished patching kissfft
Traceback (most recent call last):
  File ""tensorflow/lite/experimental/micro/tools/make/generate_keil_project.py"", line 121, in <module>
    parse_args()
  File ""tensorflow/lite/experimental/micro/tools/make/generate_keil_project.py"", line 117, in parse_args
    main(unparsed, flags)
  File ""tensorflow/lite/experimental/micro/tools/make/generate_keil_project.py"", line 39, in main
    six.ensure_str(flags.executable),
AttributeError: 'module' object has no attribute 'ensure_str'
make: *** [tensorflow/lite/experimental/micro/examples/person_detection/Makefile.inc:56: tensorflow/lite/experimental/micro/tools/make/gen/arduino_x86_64/prj/person_detection_test/keil/keil_project.uvprojx] Error 1
```
I tried to use python3, changing the line 304 in ""/tensorflow/tensorflow/lite/experimental/micro/tools/make/Makefile"", but nothing change.
"
33719,same code run on different versions of tf cost large different gpu memory consumption.,"HI,
In my two system(P40, CUDA9, CUDNN7), tf1.8 and tf1.12 are installed respectively, and the same piece of code runs in tf1.12 almost double the allocated gpu memory as in tf1.8.

I wrote the following code to simplify the comparison. At this time in tf1.8, 1241MiB gpu memory is allocated and in tf1.12, 737MiB gpu memory is allocated. How could I optimize the gpu memory allocation in tf? Any suggestion would be appreciated.
```
import tensorflow as tf                                                                                                              
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
config.allow_soft_placement = True
a=tf.get_variable('a',(100,100))
b=tf.get_variable('b',(10000,10000))
sess=tf.Session(config=config)
sess.run(tf.global_variables_initializer())
```

"
33718,"[TFLite, Converter] BERT conversion error in later version","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Yes
- TensorFlow version (use command below): firsrt git version: 9edecf8, second git verison: f9c7eb4
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): GCC 8.3.0
- CUDA/cuDNN version: No
- GPU model and memory: No

**Describe the current behavior**
When I convert BERT from tensorflow/models to tflite format by tensorflow that was built at commit with hash 9edecf8, it works. But when I do the same by tensorflow that was built at later commit with hash f9c7eb4, it doesn't work. The error in logs (Unsupported operation: Einsum).

**Code to reproduce the issue**
```
import tensorflow as tf

import json
import os

from absl import app
from absl import flags

from official.nlp.bert_models import classifier_model
from official.nlp.bert_modeling import BertConfig

flags.DEFINE_string('output_dir', default=None, help='Directory for tflite models')
flags.DEFINE_string('config_path', default=None, help='Path to config file')

FLAGS = flags.FLAGS
def convert_bert(model, output_dir):
  if not os.path.exists(output_dir):
    os.mkdir(output_dir)
  converter = tf.lite.TFLiteConverter.from_keras_model(model)
  tflite_model = converter.convert()
  output_path = os.path.join(output_dir, 'bert.tflite')
  with open(output_path, ""wb"") as f:
    f.write(tflite_model)

def main(_):
  output_dir = FLAGS.output_dir
  config_path = FLAGS.config_path
  with open(config_path, 'r') as f:
    config = json.load(f)
  model = classifier_model(BertConfig.from_dict(config), tf.float32, 2, 128)[0]
  convert_bert(model, output_dir)

if _name_ == '_main_':
  app.run(main)
```

**Other info / logs**
```
2019-10-25 11:49:08.546343: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3100000000 Hz
2019-10-25 11:49:08.548499: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x434ae80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-10-25 11:49:08.548520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-10-25 11:49:11.490358: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-10-25 11:49:11.490631: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-10-25 11:49:11.503750: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812] Optimization results for grappler item: graph_to_optimize
2019-10-25 11:49:11.503785: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814]   function_optimizer: function_optimizer did nothing. time = 0.005ms.
2019-10-25 11:49:11.503790: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-10-25 11:49:17.635192: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-10-25 11:49:17.635327: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-10-25 11:49:20.802742: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812] Optimization results for grappler item: graph_to_optimize
2019-10-25 11:49:20.802785: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814]   constant_folding: Graph size after: 1225 nodes (-299), 1515 edges (-396), time = 1677.46204ms.
2019-10-25 11:49:20.802790: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814]   constant_folding: Graph size after: 1225 nodes (0), 1515 edges (0), time = 496.749ms.
Traceback (most recent call last):
  File ""convert_bert.py"", line 39, in <module>
    app.run(main)
  File ""/workspace/.local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/workspace/.local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""convert_bert.py"", line 36, in main
    convert_bert(model, output_dir)
  File ""convert_bert.py"", line 22, in convert_bert
    tflite_model = converter.convert()
  File ""/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 464, in convert
    **converter_kwargs)
  File ""/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 452, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 203, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2019-10-25 11:49:24.764527: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764589: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764613: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764622: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764632: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764641: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764659: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764673: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764690: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764698: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764705: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764713: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764734: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764741: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764756: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764768: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764784: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764791: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764798: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764806: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764815: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764821: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764837: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764849: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764864: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764871: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764877: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764885: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764895: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764901: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764918: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.790537: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 716 operators, 1029 arrays (0 quantized)
2019-10-25 11:49:24.802635: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 716 operators, 1029 arrays (0 quantized)
2019-10-25 11:49:24.816756: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 564 operators, 862 arrays (0 quantized)
2019-10-25 11:49:24.829191: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 564 operators, 862 arrays (0 quantized)
2019-10-25 11:49:24.841886: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 563 operators, 860 arrays (0 quantized)
2019-10-25 11:49:24.854403: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 4: 563 operators, 860 arrays (0 quantized)
2019-10-25 11:49:24.866851: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 5: 563 operators, 860 arrays (0 quantized)
2019-10-25 11:49:24.879295: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 6: 563 operators, 860 arrays (0 quantized)
2019-10-25 11:49:24.891707: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 563 operators, 860 arrays (0 quantized)
2019-10-25 11:49:24.900833: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 563 operators, 860 arrays (0 quantized)
2019-10-25 11:49:24.915554: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 2032640 bytes, theoretical optimal value: 1179648 bytes.
2019-10-25 11:49:24.917162: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 107896686
2019-10-25 11:49:24.930715: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, FULLY_CONNECTED, GATHER, MEAN, MUL, NEG, POW, RESHAPE, RSQRT, SOFTMAX, SQUARED_DIFFERENCE, SQUEEZE, STRIDED_SLICE, SUB, TANH. Here is a list of operators for which you will need custom implementations: Einsum.
Traceback (most recent call last):
  File ""/workspace/.local/bin//toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/workspace/.local/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/workspace/.local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/workspace/.local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, FULLY_CONNECTED, GATHER, MEAN, MUL, NEG, POW, RESHAPE, RSQRT, SOFTMAX, SQUARED_DIFFERENCE, SQUEEZE, STRIDED_SLICE, SUB, TANH. Here is a list of operators for which you will need custom implementations: Einsum
```"
33717,Unable to compute gradients efficiently in TF 1.14,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04
- TensorFlow version (use command below): 1.14
- Python version: 3.7.3
- GPU model: Titan X (Pascal) 
- CUDA Version: 10.1

**Problem Statement**

So, I am trying to find the gradients of outputs with respect to inputs but my decoder model is a GRU.  First, I used the code below, which works but is quite slow since my input is a 56 dimension vector but the output is of (276,77) dimensional matrix:

```
        def get_gradients(i):
            return tf.gradients(self.decoder_output[:, i], self.decoder_input)[0]
        
        output_dim = self.decoder_output.shape[1].value
        J = [get_gradients(i) for i in tqdm_notebook(range(output_dim))] 
```

Then, I looked to change it to while loop but apparently it gave me this error which means I cant have a nested while loop in which I am calculating gradients. 

```
INFO:tensorflow:Cannot use 'while_1/gradients/f_count' as input to 'while_1/gradients/f_count_1' because they are in different while loops.

while_1/gradients/f_count_1 while context: gru_3/while/while_context
while_1/gradients/f_count while context: while_1/while_context
```

- Is there way around this? Isn't there any other way in tensorflow to compute gradients?"
33716,How to change dropout rate at runtime,"I am trying to switch to tf2.0. From the documentation of Dropout it is possible to set dropout rate in the declaration. When I call the dropout operation it does not seem possible to change the dropout rateo anymore. 

Suppose I would like to soften my dropout rate along training how can I do? Is there a walkaround?

```
class mymodel(Model):
    def __init__(self, units=128):
        super(mymodel, self).__init__()
        self.conv1_1 = tf.keras.layers.Conv2D(filters=units, kernel_size=3, strides=1)
        self.dropout1 = tf.keras.layers.Dropout(0.5)

        self.fc = tf.keras.layers.Dense(units=10)


    def call(self, x, training=False):

        x = tf.pad(x, paddings=[[0, 0], [1, 1], [1, 1], [0, 0]])
        x = self.conv1_1(x, training=training)
        x = tf.keras.activations.relu(x)
        x = self.dropout1(x) # how to change the rateo?
        x = self.fc(x)
```"
33715,TF Keras fails to concatenate batches in predict when using distributed strategy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): -
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): HPC Cluster
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): via pip
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.1
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: cuDNN 7.6.4, CUDA 10.0.130 
- GPU model and memory: 8x GeForce GTX 1080 Ti with 10479 MB memory each

**Describe the current behavior**
When using the distributed mirrored strategy to train the network on multiple GPU's, the predict step fails with this error code:

> File ""/cluster/home/user/localization/base_model.py"", line 76, in predict
>     prediction = self.model.predict(x, use_multiprocessing = False)
>   File ""/cluster/home/cspreche/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 909, in predict
>     use_multiprocessing=use_multiprocessing)
>   File ""/cluster/home/user/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 462, in predict
>     steps=steps, callbacks=callbacks, **kwargs)
>   File ""/cluster/home/user/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 444, in _model_iteration
>     total_epochs=1)
>   File ""/cluster/home/user/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 161, in run_one_epoch
>     batch_outs = _aggregate_predict_results(strategy, batch_outs, model)
>   File ""/cluster/home/user/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 631, in _aggregate_predict_results
>     dist_utils.concat_along_batch_dimension(nest.flatten(nested_outs)))
>   File ""/cluster/home/user/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py"", line 1205, in concat_along_batch_dimension
>     return np.concatenate(outputs)
> ValueError: all the input array dimensions except for the concatenation axis must match exactly

When I print the dimensions of the elements in the concatenation, I get the following output:

> (32, 320, 320, 1)
> (32, 320, 320, 1)
> (32, 320, 320, 1)
> (32, 320, 320, 1)
> (32, 320, 320, 1)
> (32, 320, 320, 1)
> (32, 320, 320, 1)
> (32, 320, 320, 1)
> (32, 320, 320, 1)
> (32, 320, 320, 1)
> (32, 320, 320, 1)
> (32, 320, 320, 1)
> (10, 320, 320, 1)
> (0, 0, 0, 1)
> (0, 0, 0, 1)
> (0, 0, 0, 1)

It seems, that the empty sets do not inherit the dimensions of full ones and lead therefore to a crash with the numpy concatenate function.

I could solve the issue with replacing
> return np.concatenate(outputs)

with

> out = [z for z in outputs if z.shape[0] > 0]
> return np.concatenate(out)

**Code to reproduce the issue**

> ds_train = tfds.load(..)
> ds_val = tfds.load(..)
> 
> strategy = tf.distribute.MirroredStrategy()
> num_gpu = strategy.num_replicas_in_sync
> 
> ds_train = ds_train.batch(32 * num_gpu)
> ds_val = ds_val.batch(32 * num_gpu)
> 
> with strategy.scope():
>    input_image = Input(...)
>    ....
>    output = ....
>    model = tf.keras.Model(inputs=[input_image], outputs=[output])
>    model.compile(...)
> model.fit(ds_train, validation_data = ds_val)
> model.predict(ds_val, use_multiprocessing = True)
"
33714,AdamOptimizer with Dropout is good or bad?,"**AdamOptimizer with Dropout? is it good or bad?

I am doing CNN for image recognition.

They said using Adamoptimizer with dropout is bad idea.

is it true?

Why?**  

    def get_training_model():
    x, conv_layer, conv_vars = convolutional_layers()
    # dropout
    keep_rate = 0.8
    keep_prob = tf.placeholder(tf.float32)

    # fully connected layer -(densely connected layer)
    W_fc1 = weight_variable([32 * 8 * 128, 2048]) 
    b_fc1 = bias_variable([2048])             

    conv_layer_flat = tf.reshape(conv_layer, [-1, 32 * 8 * 128])
    # h_fc1 -Fully connected layer
    h_fc1 = tf.nn.relu(tf.matmul(conv_layer_flat, W_fc1) + b_fc1) 

    # Output layer
    W_fc2 = weight_variable([2048, 1 + 7 * len(common.CHARS)]) 
    b_fc2 = bias_variable([1 + 7 * len(common.CHARS)])          

    #dropout
    h_fc1 = tf.nn.dropout(h_fc1, keep_rate)

    #output
    y = tf.matmul(h_fc1, W_fc2) + b_fc2      # h_fc1 -Fully connected layer
                                             # W_fc2 -weights output layer
                                             # b_fc2 -biases output layer
                                             # y -output
    #output
    return (x, y, conv_vars + [W_fc1, b_fc1, W_fc2, b_fc2])
            # output to training.py

**AdamOptimizer with Dropout? is it good or bad?

I am doing CNN for image recognition.

They said using Adamoptimizer with dropout is bad idea.

is it true?

Why?**"
33713,ArithmeticOptimizer produced AlreadyExistsError for certain architectures when run on CPU,
33712,Conversion to TFLite model does not work -error ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (but, from example at taken from https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l05c02_dogs_vs_cats_with_augmentation.ipynb)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):  2.0.0
- Python version: 3.6.1  (via Jupyter notebook)
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I can save the tensorflow keras model to an h5 file but, when subsequently try to convert to TFLite using code below it fails.   Following directions at https://www.tensorflow.org/tutorials/keras/save_and_load  to perform conversion to TFLite (see code below) 

**Describe the expected behavior**
Should save a TFLite file after conversion

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
`tflite_file  = os.path.join(BASE_DIRECTORY, 'my_tflite_model.h5')
print("" want to save tflite_file"" + tflite_file)
# Convert the model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
print(""converter = "" + str(converter))
tflite_model = converter.convert()

#no save the tflight model to the file
tflite_model.save(tflite_file)`
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Error I am getting:-------------------------------
---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-49-fc606e1e0a8b> in <module>()
      5 converter = tf.lite.TFLiteConverter.from_keras_model(model)
      6 print(""converter = "" + str(converter))
----> 7 tflite_model = converter.convert()
      8 
      9 #no save the tflight model to the file

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\lite\python\lite.py in convert(self)
    444         input_tensors=input_tensors,
    445         output_tensors=output_tensors,
--> 446         **converter_kwargs)
    447 
    448     if self._is_calibration_quantize():

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\lite\python\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    447       input_data.SerializeToString(),
    448       debug_info_str=debug_info_str,
--> 449       enable_mlir_converter=enable_mlir_converter)
    450   return data
    451 

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    198       stdout = _try_convert_to_unicode(stdout)
    199       stderr = _try_convert_to_unicode(stderr)
--> 200       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    201   finally:
    202     # Must manually cleanup files.

ConverterError: See console for info.
Traceback (most recent call last):
  File ""c:\python36\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""c:\python36\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Python36\Scripts\toco_from_protos.exe\__main__.py"", line 5, in <module>
ModuleNotFoundError: No module named 'tensorflow.contrib'

"
33711,TFLITE MODEL INPUT DYNAMIC INPUT SIZE,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**: 1.14
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
When I am resizing input tensor in tflite model and allocating the tensors I am getting error )Node number 0 (RESHAPE) failed to prepare.


### Source code / logs
 File ""tflite_inference.py"", line 176, in <module>
    inference_from_tflite(path_to_tflite,path_to_input)	
  File ""tflite_inference.py"", line 118, in inference_from_tflite
    interpreter.allocate_tensors()
  File ""/home/asus/miniconda/espnet/tools/venv/lib/python3.7/site-packages/tensorflow/lite/python/interpreter.py"", line 95, in allocate_tensors
    return self._interpreter.AllocateTensors()
  File ""/home/asus/miniconda/espnet/tools/venv/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py"", line 106, in AllocateTensors
    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
RuntimeError: tensorflow/lite/kernels/reshape.cc:58 num_input_elements != num_output_elements (44000 != 4000)Node number 0 (RESHAPE) failed to prepare.


Source Code:
        interpreter = tf.lite.Interpreter(model_path=tflite_model)
        #Getting the input data
        input_data = np.load(input_mel)
        print(input_data.shape)
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        input_data_resized = np.reshape(input_data,(1,input_data.shape[0],80))
        interpreter.resize_tensor_input(input_details[0]['index'], (1, input_data.shape[0], 80))
        interpreter.allocate_tensors()
        interpreter.set_tensor(input_details[0]['index'],input_data_resized)
        interpreter.invoke()

"
33710,Is is possible to run Tensorflow Lite with threading disables / without Pthreads / only 1 thread,"I am trying to compile TensorflowLite for emscripten (I am aware of TensorflowJS) and pthreads are currently disabled. Is there a way to use it without pthreads?

"
33709,K.batch_dot work not right when dims >3,"In TF 2.0 the  K.batch_dot  output dim is wrong
`import tensorflow.keras.backend as K
import tensorflow as tf

a = K.ones((7, 4, 2))
b = K.ones((7, 2, 5))
c = K.batch_dot(a, b)
print(c.shape)

a1 = K.ones((8, 7, 4, 2))
b1 = K.ones((8, 7, 2, 5))
c1 = K.batch_dot(a1, b1)
print(""K.batch_dot(a1, b1): "", c1.shape)
c2 = tf.matmul(a1, b1)
print(""tf.matmul(a1, b1): "", c2.shape)`

output:
`(7, 4, 5)
K.batch_dot(a1, b1):  (8, 7, 4, 7, 5)
tf.matmul(a1, b1):  (8, 7, 4, 5)
`

"
33708,non_max_suppression GPU version is 3x slower than CPU version in  TF 1.15,"<em>
</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.15
- Python version:3.0
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10
- GPU model and memory:K80

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
non_max_suppression GPU version is 3x slower than CPU version.
**Describe the expected behavior**
GPU version is expected to be faster ( or at the least same ) than CPU version.

**Code to reproduce the issue
```
from __future__ import absolute_import                                                                                                                                  
from __future__ import division                                                                                                                                         
from __future__ import print_function                                                                                                                                   
                                                                                                                                                                        
import tensorflow as tf                                                                                                                                                 
from tensorflow.python.framework import load_library                                                                                                                    
from tensorflow.python.platform import resource_loader                                                                                                                  
                                                                                                                                                                        
import numpy as np                                                                                                                                                      
import os                                                                                                                                                               
import argparse                                                                                                                                                         
                                                                                                                                                                        
from tensorflow.python.platform import test                                                                                                                             
import time                                                                                                                                                             
from tensorflow.python.ops import gen_image_ops                                                                                                                         
                                                                                                                                                                                                                                                                
                                                                                                                                                                        
def yolo_non_max_suppression(boxes, scores, classes, sess, max_boxes = 10, iou_threshold = 0.5, rundevice=""cpu:0""):                                                                              
    """"""                                                                                                                                                                                          
    Applies Non-max suppression (NMS) to set of boxes                                                                                                                                            
                                                                                                                                                                                                 
    Arguments:                                                                                                                                                                                   
    scores -- tensor of shape (None,), output of yolo_filter_boxes()                                                                                                                             
    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)                                                                        
    classes -- tensor of shape (None,), output of yolo_filter_boxes()                                                                                                                            
    max_boxes -- integer, maximum number of predicted boxes you'd like                                                                                                                           
    iou_threshold -- real value, ""intersection over union"" threshold used for NMS filtering                                                                                                      
                                                                                                                                                                                                 
    Returns:                                                                                                                                                                                     
    scores -- tensor of shape (, None), predicted score for each box                                                                                                                             
    boxes -- tensor of shape (4, None), predicted box coordinates                                                                                                                                
    classes -- tensor of shape (, None), predicted class for each box                                                                                                                            
                                                                                                                                                                                                 
    Note: The ""None"" dimension of the output tensors has obviously to be less than max_boxes. Note also that this                                                                                
    function will transpose the shapes of scores, boxes, classes. This is made for convenience.                                                                                                  
    """"""                                                                                                                                                                                          
                                                                                                                                                                                                 
    init_val_np = np.array ( [max_boxes], dtype=np.int32)                                                                                                                                        
    max_boxes_tensor = tf.Variable(max_boxes,  dtype='int32')     # tensor to be used in tf.image.non_max_suppression()                                                                          
    sess.run(tf.variables_initializer([max_boxes_tensor])) # initialize variable max_boxes_tensor                                                                                                
                                                                                                                                                                                                 
    # Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep                                                                                              
    ### START CODE HERE ### (~ 1 line)                                                                                                                                                           
    with tf.device(rundevice):                                                                                                                                                                   
        score_threshold = 0.1                                                                                                                                                                    
        soft_nms_sigma=0.0                                                                                                                                                                       
        pad_to_max_output_size=False                                                                                                                                                             
        if True:                                                                                                                                                                                 
            nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, )                                                                                                        
            #nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)                                                                            
            #nms_indices = nms(boxes_np, 0.5)                                                                                                                                                    
            #nms_indices = gen_image_ops.non_max_suppression_v2(boxes, scores, max_boxes_tensor, iou_threshold, )                                                                                
            #nms_indices = tf.image.non_max_suppression_v2(boxes, scores, max_boxes_tensor, iou_threshold, )                                                                                     
            #nms_indices = gen_image_ops.non_max_suppression_v3(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold)                                                                 
            #nms_indices,_ = gen_image_ops.non_max_suppression_v4(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold, pad_to_max_output_size)                                       
            #nms_indices = gen_image_ops.non_max_suppression_v5(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold, soft_nms_sigma)                                                 
            #nms_indices,_,_ = non_max_suppression_ops.non_max_suppression_v5(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold, soft_nms_sigma)                                   
            #nms_indices,_,_ = tf.image.non_max_suppression_with_scores(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold, soft_nms_sigma)                                         
        ### END CODE HERE ###                                                                                                                                                                    
                                                                                                                                                                                                 
        ### START CODE HERE ### (~ 3 lines)                                                                                                                                                      
        scoreso = tf.gather(scores, nms_indices)                                                                                                                                                 
        boxeso = tf.gather(boxes, nms_indices)                                                                                                                                                   
        classeso = tf.gather(classes, nms_indices)                                                                                                                                               
        summary_writer = tf.summary.FileWriter(os.getenv('TENSORBOARD_DIR'), sess.graph)                                                                                                         
        ### END CODE HERE ###                                                                                                                                                                    
                                                                                                                                                                                                 
    return scoreso, boxeso, classeso

def test_yolo_non_max_suppression(rundevice=""cpu:0"", roinum=300):                                                                                                                                
    with tf.device(""cpu:0""):                                                                                                                                                                     
        with tf.Session() as test_b:                                                                                                                                                             
            roinum = 300                                                                                                                                                                         
            scoresi = tf.random_normal([roinum,], mean=1, stddev=4, seed = 1)                                                                                                                    
            boxesi = tf.random_normal([roinum, 4], mean=1, dtype = tf.float32, stddev=4, seed = 1)                                                                                               
            classesi = tf.random_normal([roinum,], mean=1, dtype = tf.float32, stddev=4, seed = 1)                                                                                               
            scorest, boxest, classest = yolo_non_max_suppression(boxesi, scoresi, classesi, test_b, rundevice=rundevice, )                                                                       
            time0 = time.time()                                                                                                                                                                  
            for i in range(1,10001):                                                                                                                                                             
                scores, boxes, classes = test_b.run([scorest, boxest, classest])                                                                                                                 
                if i%2000 == 0:                                                                                                                                                                  
                    print (i, (time.time() - time0)/i )                                                                                                                                          
            time_taken = (time.time() - time0)/i                                                                                                                                                 
            print (i, time_taken)                                                                                                                                                                
            print(""scores[2] = "" + str(scores[2]))                                                                                                                                               
            print(""boxes[2] = "" + str(boxes[2]))                                                                                                                                                 
            print(""classes[2] = "" + str(classes[2]))                                                                                                                                             
            print(""scores.shape = "" + str(scores.shape))                                                                                                                                         
            print(""boxes.shape = "" + str(boxes.shape))                                                                                                                                           
            print(""classes.shape = "" + str(classes.shape))                                                                                                                                       
                                                                                                                                                                                                 
            return time_taken

if __name__ == '__main__':                                                                                                                                                                       
    print (tf.__version__)                                                                                                                                                                       
    from tensorflow.python.client import device_lib                                                                                                                                              
    print (""devices: "", device_lib.list_local_devices())                                                                                                                                         
    cpu_time_taken = test_yolo_non_max_suppression(rundevice=""cpu:0"", roinum=300)                                                                                                                
    gpu_time_taken = test_yolo_non_max_suppression(rundevice=""gpu:0"", roinum=300)                                                                                                                
    print(""========  cpu vs gpu time per batch ================="")                                                                                                                               
    print ( ""cpu: "", cpu_time_taken, "" gpu: "", gpu_time_taken, "" cpu/gpu :"", cpu_time_taken/gpu_time_taken,)

1.15.0
devices:  [name: ""/device:CPU:0""
device_type: ""CPU""
memory_limit: 268435456
locality {
}
incarnation: 7555561621581721093
, name: ""/device:XLA_CPU:0""
device_type: ""XLA_CPU""
memory_limit: 17179869184
locality {
}
incarnation: 8901332661850439463
physical_device_desc: ""device: XLA_CPU device""
, name: ""/device:XLA_GPU:0""
device_type: ""XLA_GPU""
memory_limit: 17179869184
locality {
}
incarnation: 740119289257596209
physical_device_desc: ""device: XLA_GPU device""
, name: ""/device:GPU:0""
device_type: ""GPU""
memory_limit: 11330115994
locality {
  bus_id: 1
  links {
  }
}
incarnation: 8545750488051512624
physical_device_desc: ""device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7""
]
2000 0.000534496068954
4000 0.000523755788803
6000 0.000520971179008
8000 0.000516991376877
10000 0.000515855407715
10000 0.000515921497345
scores[2] = 10.583145
boxes[2] = [ 9.513624   -1.2187521   2.245485    0.23083931]
classes[2] = 10.583145
scores.shape = (10,)
boxes.shape = (10, 4)
classes.shape = (10,)
2000 0.00289141702652
4000 0.00219018751383
6000 0.0019565414985
8000 0.00184808599949
10000 0.00177410800457
10000 0.00177413899899
scores[2] = 10.583145
boxes[2] = [ 9.513624   -1.2187521   2.245485    0.23083931]
classes[2] = 10.583145
scores.shape = (10,)
boxes.shape = (10, 4)
classes.shape = (10,)
========  cpu vs gpu time per batch =================
cpu:  0.000515921497345  gpu:  0.00177413899899  cpu/gpu : 0.290801057662
```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33705,"File ""C:\Users\idzha\Anaconda3\lib\sqlite3\__init__.py"", line 23, in <module> from sqlite3.dbapi2 import *   File ""C:\Users\idzha\Anaconda3\lib\sqlite3\dbapi2.py"", line 27, in <module>     from _sqlite3 import *ImportError: DLL load failed: The specified module could not be found.",
33704,relu6,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
33702,build tensorflow on mac failed,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS high sierra
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: source on branch r1.13
- **Python version**: 3.6.5(Anaconda)
- **Bazel version (if compiling from source)**: 0.21.0
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.1.0 (clang-902.0.39.2)
- **CUDA/cuDNN version**: No
- **GPU model and memory**: No
- **Exact command to reproduce**:
```
git checkout r1.13
./configure
only XLA support is enabled
bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures
```

### Describe the problem
build tensoeflow from source failed.

> ImportError: dlopen(/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: __ZN10tensorflow19XlaCompilationCache28kDefaultCompilationThresholdE

### Source code / logs
INFO: From Linking tensorflow/core/libgpu_runtime_impl.lo:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libgpu_runtime_impl.lo(gpu_device.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libgpu_runtime_impl.lo(gpu_device_factory.o) has no symbols
ERROR: /Users/dongxiao/working/tensorflow/tensorflow/BUILD:579:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1): bash failed: error executing command
  (cd /private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow && \
  exec env - \
    PATH=/bin:/usr/bin \
    PYTHON_BIN_PATH=/Users/dongxiao/anaconda3/bin/python \
    PYTHON_LIB_PATH=/Users/dongxiao/anaconda3/lib/python3.6/site-packages \
    TF_DOWNLOAD_CLANG=0 \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL_SYCL=0 \
    TF_NEED_ROCM=0 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1 --root_init_template=tensorflow/api_template_v1.__init__.py --apidir=bazel-out/darwin-opt/genfiles/tensorflow_api/v1/ --apiname=tensorflow --apiversion=1 --compat_apiversion=1  --compat_init_template=tensorflow/compat_template_v1.__init__.py --package=tensorflow.python,tensorflow.lite.python.lite --output_package=tensorflow._api.v1 bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/v1.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/app/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/autograph/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/autograph/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/bitwise/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/data/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/data/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/debugging/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/distribute/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/distributions/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/dtypes/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/errors/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/feature_column/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/gfile/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/io/gfile/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/graph_util/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/image/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/io/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/queue/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/initializers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/activations/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/densenet/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_v3/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet_v2/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/nasnet/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/resnet50/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg16/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg19/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/applications/xception/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/backend/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/callbacks/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/constraints/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/boston_housing/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar10/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar100/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/fashion_mnist/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/imdb/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/mnist/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/datasets/reuters/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/estimator/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/initializers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/layers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/losses/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/metrics/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/models/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/optimizers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/image/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/sequence/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/text/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/regularizers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/utils/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/wrappers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/keras/wrappers/scikit_learn/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/layers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/layers/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/linalg/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/lite/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/lite/constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/logging/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/losses/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/manip/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/math/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/metrics/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/nn/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/nn/rnn_cell/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/profiler/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/python_io/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/quantization/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/ragged/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/random/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/resource_loader/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/strings/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/builder/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/loader/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/main_op/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/signature_constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/signature_def_utils/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/tag_constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/saved_model/utils/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/sets/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/signal/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/sparse/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/spectral/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/summary/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/sysconfig/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/test/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/train/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/train/queue_runner/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/user_ops/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/version/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/app/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/autograph/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/autograph/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/bitwise/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/compat/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/data/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/data/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/debugging/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/distribute/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/distributions/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/dtypes/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/errors/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/feature_column/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/gfile/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/io/gfile/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/graph_util/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/image/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/io/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/queue/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/initializers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/activations/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/densenet/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/inception_v3/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/mobilenet/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/mobilenet_v2/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/nasnet/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/resnet50/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/vgg16/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/vgg19/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/applications/xception/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/backend/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/callbacks/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/constraints/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/boston_housing/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/cifar10/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/cifar100/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/fashion_mnist/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/imdb/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/mnist/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/datasets/reuters/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/estimator/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/initializers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/layers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/losses/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/metrics/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/models/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/optimizers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/preprocessing/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/preprocessing/image/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/preprocessing/sequence/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/preprocessing/text/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/regularizers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/utils/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/wrappers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/keras/wrappers/scikit_learn/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/layers/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/layers/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/linalg/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/lite/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/lite/constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/logging/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/losses/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/manip/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/math/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/metrics/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/nn/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/nn/rnn_cell/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/profiler/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/python_io/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/quantization/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/ragged/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/random/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/resource_loader/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/strings/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/builder/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/experimental/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/loader/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/main_op/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/signature_constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/signature_def_utils/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/tag_constants/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/saved_model/utils/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/sets/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/signal/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/sparse/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/spectral/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/summary/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/sysconfig/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/test/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/train/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/train/queue_runner/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/user_ops/__init__.py bazel-out/darwin-opt/genfiles/tensorflow/_api/v1/compat/v1/version/__init__.py')
Execution platform: @bazel_tools//platforms:host_platform
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/Users/dongxiao/anaconda3/lib/python3.6/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/Users/dongxiao/anaconda3/lib/python3.6/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: dlopen(/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: __ZN10tensorflow19XlaCompilationCache28kDefaultCompilationThresholdE
  Referenced from: /private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so
  Expected in: flat namespace
 in /private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/Users/dongxiao/anaconda3/lib/python3.6/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/Users/dongxiao/anaconda3/lib/python3.6/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: dlopen(/private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: __ZN10tensorflow19XlaCompilationCache28kDefaultCompilationThresholdE
  Referenced from: /private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so
  Expected in: flat namespace
 in /private/var/tmp/_bazel_dongxiao/c0c832007eb15ba2db0e9df6a49eabb9/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Target //tensorflow/tools/pip_package:build_pip_package failed to build

"
33697,The value of the validation accuracy is very low ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):1.13.1
- Python version:3.6.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:9/7.5
- GPU model and memory: Nvidia Geforce 840m

I have a trained model that detects an eye region with landmarks, this model gives good results:

![image](https://user-images.githubusercontent.com/19480228/67513317-e0e4d380-f69a-11e9-88b6-aa8327d4bc58.png)

But when I evaluate this model using this code:
```python
def _eval_input_fn():
    """"""Function for evaluating.""""""
    return input_fn(
        record_file=""./validiris.record"",
        batch_size=2,
        num_epochs=1,
        shuffle=False)
def main(unused_argv):
    """"""MAIN""""""
    # Create the Estimator
    estimator = tf.estimator.Estimator(
        model_fn=cnn_model_fn, model_dir=""./irismodel"")

    # Choose mode between Train, Evaluate and Predict
    mode_dict = {
        'train': tf.estimator.ModeKeys.TRAIN,
        'eval': tf.estimator.ModeKeys.EVAL,
        'predict': tf.estimator.ModeKeys.PREDICT
    }
    mode = mode_dict['eval']
if mode == tf.estimator.ModeKeys.TRAIN:
        estimator.train(input_fn=_train_input_fn, steps=200000)

        # Export result as SavedModel.
        estimator.export_savedmodel('./saved_model', serving_input_receiver_fn)
 elif mode == tf.estimator.ModeKeys.EVAL:
        evaluation = estimator.evaluate(input_fn=_eval_input_fn)
        print(evaluation)

```

I got an unbelievable value of accuracy, as you can see that was the logs that I have got:

**Other info / logs**
>2019-10-24 19:51:54.628843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-10-24 19:53:57.017603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 19:53:57.026100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-10-24 19:53:57.033023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-10-24 19:53:58.438331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3058 MB memory) -> physical GPU (device: 0, name: GeForce 840M, pci bus id: 0000:03:00.0, compute capability: 5.0)
WARNING:tensorflow:From C:\Users\starinfo\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
INFO:tensorflow:Restoring parameters from ./irismodel\model.ckpt-146849
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
2019-10-24 19:54:10.280447: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library cublas64_100.dll locally
INFO:tensorflow:Finished evaluation at 2019-10-24-18:00:00
INFO:tensorflow:Saving dict for global step 146849: accuracy = 1.5903983e-06, global_step = 146849, loss = 0.00016725865
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 146849: ./irismodel\model.ckpt-146849
{'accuracy': 1.5903983e-06, 'loss': 0.00016725865, 'global_step': 146849}


What is the problem here?
"
33696,GpuLaunchKernel errors with Internal: invalid device function,"**System information**
- Windows 10
- TensorFlow GPU installed from PIP installer:
- TensorFlow version: 2.0.0
- Python version:  3.7.4
- CUDA/cuDNN version: 10.1
- GPU model and memory: Geforce GTX 1050 4GB

**Describe the current behavior**

I'm trying to run a facial recognition project and the message bellow appears

Using TensorFlow backend.

```
2019-10-24 14:32:44.154323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2019-10-24 14:32:51.960166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2019-10-24 14:32:52.321115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493
pciBusID: 0000:01:00.0
2019-10-24 14:32:52.325985: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-10-24 14:32:52.331740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-24 14:32:52.335877: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-10-24 14:32:52.342803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493
pciBusID: 0000:01:00.0
2019-10-24 14:32:52.346290: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-10-24 14:32:52.350583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-24 14:32:52.458458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 14:32:52.461435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0
2019-10-24 14:32:52.462925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N
2019-10-24 14:32:52.467353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3083 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-10-24 14:32:52.647343: F .\tensorflow/core/kernels/random_op_gpu.h:227] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: invalid device function
```"
33695,Do I need the NVIDIA CUDA Toolkit along with conda installation of the CUDA toolkit?,"Version mismatch issues encountered at the installation of Tensorflow with local GPU support led me **question the need for the coexistence on the same machine of both CUDA packages**, namely: 

The NVIDIA **CUDA Toolkit** along with **CUDNN**

<img width=""257"" alt=""Annotation 2019-10-24 122829"" src=""https://user-images.githubusercontent.com/39677929/67505904-1ae1b580-f65a-11e9-9c18-78c22b4266e2.png"">

and the `conda` installation of the **cudatoolkit** along with **cudnn** 

<img width=""311"" alt=""Annotation 2019-10-24 121845"" src=""https://user-images.githubusercontent.com/39677929/67506044-5c726080-f65a-11e9-8f24-d1286d9da45d.png"">

As shown above, on my machine these packages have different versions but tensorflow is configured for GPU support and is working:

`sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))`

outputs something along the lines:

<img width=""401"" alt=""Annotation 2019-10-24 124233"" src=""https://user-images.githubusercontent.com/39677929/67507285-99d7ed80-f65c-11e9-8de5-ba3fa440b3b4.png"">

Conda installation of tensorflow-gpu via 

` conda create -n tensorflow tensorflow-gpu`

seems to resolve version mismatch issues encountered with `pip install`, `keras::install_keras()` or with `tensorflow::install_tensorflow()`


The reason for my question is twofold: 

1. Beside CUDA,  the NVIDIA CUDA Toolkit installs a plethora of tools that may not be used by everyone therefore, a guide to the custom installation of the CUDA Toolkit would be more than welcome;

2. The _cudart64-100.dll cannot be found_ error popping at version mismatch between CUDA/CUDNN, Python and Tensorflow  refers to the _dll_ library located in the `conda` environment and not to the NVIDIA CUDA installation (which in my case contains the _cudart64-101.dll_ and still works)

"
33693,"TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (Dimension(None), -1, Dimension(2048)). Consider casting elements to a supported type.","I am getting these error when trying to run my model:

```
""Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py"", line 558, in make_tensor_proto
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py"", line 558, in <listcomp>
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/compat.py"", line 65, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got Dimension(None)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.5/runpy.py"", line 184, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.5/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/root/.local/lib/python3.5/site-packages/trainer/image_captioning.py"", line 123, in <module>
    (batch_features.shape[0], -1, batch_features.shape[3]))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 7715, in reshape
    ""Reshape"", tensor=tensor, shape=shape, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 530, in _apply_op_helper
    raise err
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 527, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 1224, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py"", line 305, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py"", line 246, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py"", line 284, in _constant_impl
    allow_broadcast=allow_broadcast))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py"", line 562, in make_tensor_proto
    ""supported type."" % (type(values), values))
TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (Dimension(None), -1, Dimension(2048)). Consider casting elements to a supported type.
```


And i believe the issue is in this bit of code:

```
# Get unique images
encode_train = sorted(set(img_name_vector))

image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)
image_dataset = image_dataset.map(
  load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)

for img, path in image_dataset:
  batch_features = image_features_extract_model(img)
  batch_features = tf.reshape(batch_features,
                              (batch_features.shape[0], -1, batch_features.shape[3]))

  for bf, p in zip(batch_features, path):
    np.save(file_io.FileIO(IMG_PATH, 'w'), bf.numpy())
```

So it seems that batch_features.shape[0] is returning None - how can I handle this?

I have tried to use `tf.shape(batch_features)[0]` instead of `batch_features.shape[0]` but then the error is:
```
TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.
```"
33692,How can i predict on image classifier?,"https://www.tensorflow.org/tutorials/images/classification
"
33691,ResizeBilinear op mismatch in TF2.0/TFLite,"There have been changes in how ResizeBilinear works across the last few versions and its causing issues.

- Originally ResizeBilinear op (what you get with tf.image.resize) was completely wrong (see the weird shift below)
- This was made less-wrong with the align_corners=True param (defaults to False for compat which makes sense).
- None of these match OpenCV, align_corners is not completely terrible but still not right.
- for TF2.0 a newer version of the op was made that is really nice and matches OpenCV. PyTorch also matches this version too. The antialias=False (default) param only matters for downscaling. 
- The `tf.keras.layers.UpScaling2D` layer calls `tf.keras.backend.resize_images`
- In TF1.x, `tf.keras.backend.resize_images` called `tf.image.resize_bilinear` with default args, so got the broken op.
- After r1.14 was branched off master, `tf.keras.backed.resize_images` was changed to use the V2 op.
- TF2.0 was branched off master, so has the new good op
- TF1.15 was branched off master, so also has the new good op, but is backwards incompatible
- TOCO/TFLiteConverter forces any resize_bilinear to use the old broken resize op. In fact it forces align_corners=False without even looking at what the input model has.

TFLite needs to have the new op implemented, and TFLiteConverter needs to distinguish and error if the wrong op is used.

Reproducer:
```
#!/usr/bin/env python3

import cv2
import numpy as np
import tensorflow as tf
import tensorflow.compat.v1 as tf1
import tensorflow.compat.v2 as tf2

assert tf.version.VERSION == '2.0.0'
np.set_printoptions(precision=2, suppress=True)

start_shape = (2, 2)
resize_shape = (10, 10)
upsample_size = (resize_shape[0] // start_shape[0], resize_shape[1] // start_shape[1])

# A 2x2 image with diagonal corners = 5
a = np.ones((1, start_shape[0], start_shape[1], 1), dtype=np.float32)
a[0, 0, 0, 0] = 5.0
a[0, -1, -1, 0] = 5.0


b = tf.constant(a, dtype=tf.float32)
c = tf1.image.resize(b, resize_shape,
                     method=tf1.image.ResizeMethod.BILINEAR,
                     align_corners=False)
d = tf1.image.resize(b, resize_shape,
                     method=tf1.image.ResizeMethod.BILINEAR,
                     align_corners=True)

e = tf2.image.resize(b, resize_shape,
                     method=tf2.image.ResizeMethod.BILINEAR,
                     antialias=False)
f = tf2.image.resize(b, resize_shape,
                     method=tf2.image.ResizeMethod.BILINEAR,
                     antialias=True)

z = cv2.resize(a[0], resize_shape, interpolation=cv2.INTER_LINEAR)


print(""Input: b"")
print(b.numpy()[0, :, :, 0])

print(""\nTensorflow: c, tf1 align corners False"")
print(c.numpy()[0, :, :, 0])

print(""\nTensorflow: d, tf1 align corners True"")
print(d.numpy()[0, :, :, 0])

print(""\nTensorflow: e, tf2 antialias False"")
print(e.numpy()[0, :, :, 0])

print(""\nTensorflow: f, tf2 antialias True"")
print(f.numpy()[0, :, :, 0])

print(""OpenCV:"")
print(z)


# for TF2.0, the UpSampling2D layer uses tf2 antialias=False
input_layer = tf.keras.layers.Input(shape=(start_shape[0], start_shape[1], 1), batch_size=1)
x = tf.keras.layers.UpSampling2D(size=upsample_size, interpolation='bilinear')(input_layer)
model = tf.keras.models.Model(input_layer, x)

# Convert the model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test the TensorFlow Lite model on random input data.
input_shape = input_details[0]['shape']
interpreter.set_tensor(input_details[0]['index'], a)

interpreter.invoke()

# The function `get_tensor()` returns a copy of the tensor data.
# Use `tensor()` in order to get a pointer to the tensor.
tflite_results = interpreter.get_tensor(output_details[0]['index'])

# Test the TensorFlow model on random input data.
tf_results = model(b)

print(""tflite results shape:"", tflite_results.shape, ""TF results shape:"", tf_results.shape)
print(""TFLite results:"")
print(tflite_results[0, :, :, 0])

print(""\nTF results:"")
print(tf_results.numpy()[0, :, :, 0])

print(""\ntf1 align_corners=False matches tflite:"", np.allclose(c, tflite_results))
print(""UpSampling2D: TF matches TFLite:"", np.allclose(tf_results, tflite_results))
```

Output:

```
Input: b
[[5. 1.]
 [1. 5.]]

Tensorflow: c, tf1 align corners False
[[5.   4.2  3.4  2.6  1.8  1.   1.   1.   1.   1.  ]
 [4.2  3.72 3.24 2.76 2.28 1.8  1.8  1.8  1.8  1.8 ]
 [3.4  3.24 3.08 2.92 2.76 2.6  2.6  2.6  2.6  2.6 ]
 [2.6  2.76 2.92 3.08 3.24 3.4  3.4  3.4  3.4  3.4 ]
 [1.8  2.28 2.76 3.24 3.72 4.2  4.2  4.2  4.2  4.2 ]
 [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]
 [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]
 [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]
 [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]
 [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]]

Tensorflow: d, tf1 align corners True
[[5.   4.56 4.11 3.67 3.22 2.78 2.33 1.89 1.44 1.  ]
 [4.56 4.21 3.86 3.52 3.17 2.83 2.48 2.14 1.79 1.44]
 [4.11 3.86 3.62 3.37 3.12 2.88 2.63 2.38 2.14 1.89]
 [3.67 3.52 3.37 3.22 3.07 2.93 2.78 2.63 2.48 2.33]
 [3.22 3.17 3.12 3.07 3.02 2.98 2.93 2.88 2.83 2.78]
 [2.78 2.83 2.88 2.93 2.98 3.02 3.07 3.12 3.17 3.22]
 [2.33 2.48 2.63 2.78 2.93 3.07 3.22 3.37 3.52 3.67]
 [1.89 2.14 2.38 2.63 2.88 3.12 3.37 3.62 3.86 4.11]
 [1.44 1.79 2.14 2.48 2.83 3.17 3.52 3.86 4.21 4.56]
 [1.   1.44 1.89 2.33 2.78 3.22 3.67 4.11 4.56 5.  ]]

Tensorflow: e, tf2 antialias False
[[5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]
 [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]
 [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]
 [4.2  4.2  4.2  3.72 3.24 2.76 2.28 1.8  1.8  1.8 ]
 [3.4  3.4  3.4  3.24 3.08 2.92 2.76 2.6  2.6  2.6 ]
 [2.6  2.6  2.6  2.76 2.92 3.08 3.24 3.4  3.4  3.4 ]
 [1.8  1.8  1.8  2.28 2.76 3.24 3.72 4.2  4.2  4.2 ]
 [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]
 [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]
 [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]]

Tensorflow: f, tf2 antialias True
[[5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]
 [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]
 [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]
 [4.2  4.2  4.2  3.72 3.24 2.76 2.28 1.8  1.8  1.8 ]
 [3.4  3.4  3.4  3.24 3.08 2.92 2.76 2.6  2.6  2.6 ]
 [2.6  2.6  2.6  2.76 2.92 3.08 3.24 3.4  3.4  3.4 ]
 [1.8  1.8  1.8  2.28 2.76 3.24 3.72 4.2  4.2  4.2 ]
 [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]
 [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]
 [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]]
OpenCV:
[[5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]
 [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]
 [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]
 [4.2  4.2  4.2  3.72 3.24 2.76 2.28 1.8  1.8  1.8 ]
 [3.4  3.4  3.4  3.24 3.08 2.92 2.76 2.6  2.6  2.6 ]
 [2.6  2.6  2.6  2.76 2.92 3.08 3.24 3.4  3.4  3.4 ]
 [1.8  1.8  1.8  2.28 2.76 3.24 3.72 4.2  4.2  4.2 ]
 [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]
 [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]
 [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]]
tflite results shape: (1, 10, 10, 1) TF results shape: (1, 10, 10, 1)
TFLite results:
[[5.   4.2  3.4  2.6  1.8  1.   1.   1.   1.   1.  ]
 [4.2  3.72 3.24 2.76 2.28 1.8  1.8  1.8  1.8  1.8 ]
 [3.4  3.24 3.08 2.92 2.76 2.6  2.6  2.6  2.6  2.6 ]
 [2.6  2.76 2.92 3.08 3.24 3.4  3.4  3.4  3.4  3.4 ]
 [1.8  2.28 2.76 3.24 3.72 4.2  4.2  4.2  4.2  4.2 ]
 [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]
 [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]
 [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]
 [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]
 [1.   1.8  2.6  3.4  4.2  5.   5.   5.   5.   5.  ]]

TF results:
[[5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]
 [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]
 [5.   5.   5.   4.2  3.4  2.6  1.8  1.   1.   1.  ]
 [4.2  4.2  4.2  3.72 3.24 2.76 2.28 1.8  1.8  1.8 ]
 [3.4  3.4  3.4  3.24 3.08 2.92 2.76 2.6  2.6  2.6 ]
 [2.6  2.6  2.6  2.76 2.92 3.08 3.24 3.4  3.4  3.4 ]
 [1.8  1.8  1.8  2.28 2.76 3.24 3.72 4.2  4.2  4.2 ]
 [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]
 [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]
 [1.   1.   1.   1.8  2.6  3.4  4.2  5.   5.   5.  ]]

tf1 align_corners=False matches tflite: True
UpSampling2D: TF matches TFLite: False
```
"
33690,RNNCellDropoutWrapper applies dropout on the LSTM c state,"**System information**
- Have I written custom code: No
- TensorFlow installed from: source (pip)
- TensorFlow version: v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.7.4

**Describe the current behavior**
The `_call_wrapped_cell` method of the `DropoutWrapperBase` class applies dropout on both `c` and `h` states of an LSTM cell. Its default method to determine if a state should take dropout, `_default_dropout_state_filter_visitor`, only works correctly with LSTM states packed as a `LSTMStateTuple` namedtuple. This was fine in TensorFlow 1.x, where the LSTM state is passed around as a `LSTMStateTuple`. However, in TensorFlow 2.0 the state is a Python tuple, and the method returns `True` for both substates.

**Describe the expected behavior**
Exclude the LSTM `c` state from the list of dropout candidates.

"
33689,tf.function strange behavior with global variables,"Hi, I'm trying to migrate the following function form TF 1.x to TF 2.0.
```
def bar(value=None):
    if value is not None:
        result = tf.constant(value)
    else:
        result = tf.Variable(1)
    return result
bar()
```
 at a first attempt I wrote the folowing code:
```
foo = None

@tf.function
def bar(value=None):
   global foo
    if value is not None:
        result = tf.constant(value)
        return result
    else:
        if foo is None:
            foo = tf.Variable(1)
        return foo

bar()
```
but it raised an error ` ValueError: tf.function-decorated function tried to create variables on non-first call.`
Rewriting the code in the one bellow it works but I can't understand why the first solution dosen't work. Could you please give me an explication?

```
foo = None

@tf.function
def bar(value=None):
    if value is not None:
        result = tf.constant(value)
        return result
    else:
        global foo
        if foo is None:
            foo = tf.Variable(1)
        return foo

bar()
```

"
33688,GradientTape: Allow to execute backward functions on same device as forward functions,"**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Currently GradientTape.gradient() is executed on the device of the scope it is called in. Have a look at the following code:

```
with tf.GradientTape() as tape:
    with tf.device('/gpu:1'):
        x = f1(input)
    with tf.device('/gpu:2'):
        x = f2(x)
    with tf.device('/gpu:0'):
        g = tape.gradient(x, f_vars)
```

Here all gradient calculations will be carried out by GPU:0 and all variables needed for the gradient calculation will also be allocated on GPU:0. This is a problem if these temporary variables are too large to fit into the VRAM of GPU:0.

Please provide a way to execute the backward functions on the device of the corresponding forward function and allocate temporary variables for gradient calculation there. This allows to split a large model and distribute it among as many GPUs as necessary.

**Will this change the current api? How?**
It will add a parameter to tf.GradientTape that controls if the user wants the current or the suggested behavior.

**Who will benefit with this feature?**
Anyone who wants to train large models that do not fit into the VRAM of a single GPU."
33687,"Unsure as to compile options for Intel i7 930, Bloomfield CPU for when rebuilding Tensorflow from source","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 7

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
PC

- TensorFlow installed from (source or binary):
Trying to recompile TensorFlow 2.0 for my older machine without AVX support

- TensorFlow version: 2
- Python version:  3.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 0.28.1
- GCC/Compiler version (if compiling from source): latest
- CUDA/cuDNN version:  n/a I have an older GTS-250 card that does not support
- GPU model and memory:
CPU is an Intel i7 930 which I believe is a Bloomfield model

**Describe the problem**
I'm at the step during the rebuild that is asking me for optimization flags.  I want to make sure that I am picking the correct ones with my CPU and GPU.

some of the previous options were:

Found possible Python library paths:
  C:\Users\Bill\AppData\Local\Programs\Python\Python37\lib\site-packages
Please input the desired Python library path to use.  Default is [C:\Users\Bill\AppData\Local\Programs\Python\Python37\lib\site-packages]

Do you wish to build TensorFlow with XLA JIT support? [y/N]: y
XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: N
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: N
No CUDA support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]:

So I'm at this point and I'm not sure if I should use --config-opt or something like -march core2 I checked to see if there was a -march bloomfield but no option exists... 

Would someone be able to spell out the exact options that I should be using.  Many thanks ahead of time!


**Provide the exact sequence of commands / steps that you executed before running into the problem**
listed above


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33686,TF 2.0 tf.keras.models.load_model won't load models compiled with a loss dictionary,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): docker image (tensorflow/tensorflow:2.0.0-gpu-py3)
- TensorFlow version (use command below):  v2.0.0-rc2-26-g64c3d38 2.0.0     
- Python version: 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10
- GPU model and memory: N/A

**Describe the current behavior**

Attempting to load a keras model which has been compiled with a loss dictionary fails, throwing the following error:
ValueError: Unknown entries in loss dictionary: ['MyLoss']. Only expected following keys: ['dense_1']

**Describe the expected behavior**
The model should load.


**Code to reproduce the issue**

EDIT - _refer to latest gist below_

**Other info / logs**
N/A
"
33685,Could not find valid device for node. Node: {{node NonMaxSuppressionV4}},"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **tensorflow 1.14.0**
- Python version: **3.7.3**

i was trying to use `tf.image.non_max_suppression_padded()`, but i got an error, maybe i write a wrong code, hope somebody can help.

test code:

```python
import tensorflow as tf
import numpy as np

np.random.seed(0)

num_objs_per_img = 10

boxes = np.sort(np.random.rand(num_objs_per_img, 4))
scores = np.random.rand(num_objs_per_img)

idx = tf.image.non_max_suppression_padded(boxes, scores, max_output_size=7, iou_threshold=0.7)
print(idx)
```

terminal log:

```text
Traceback (most recent call last):
  File ""draft.py"", line 11, in <module>
    idx = tf.image.non_max_suppression_padded(boxes, scores, max_output_size=7, iou_threshold=0.7)
  File ""/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/image_ops_impl.py"", line 2646, in non_max_suppression_padded
    pad_to_max_output_size)
  File ""/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_image_ops.py"", line 2561, in non_max_suppression_v4
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: Could not find valid device for node.
Node: {{node NonMaxSuppressionV4}}
All kernels registered for op NonMaxSuppressionV4 :
  device='XLA_GPU'; T in [DT_FLOAT, DT_HALF]
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_HALF]
  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_HALF]
  device='XLA_CPU'; T in [DT_FLOAT, DT_HALF]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]
 [Op:NonMaxSuppressionV4]
```"
33684,[TF 2.0 Nightly] Tensorflow 2.0 nightly build doesn't work with colab TPUs,"TPU strategy can't be instantiated in colab. I am aware that this issue might be more suitable for colaboratory  github but there many issues are not getting a response very fast so I thought it will be better to ask you about a potential solution (if there is a bug related to the last build and not google colab environment) or whether it is planned that colab will have this support in the nearby future.

The following link demonstrates the issue: https://colab.research.google.com/drive/1DsM_lsZXvBnlz3weymB8GHQ6cjoaxPgq

TPU runtime was selected and the version of the installed tf2.0 is '2.1.0-dev20191024'. Thanks!"
33683,How to replace contrib.rnn.stack_bidirectional_dynamic_rnn in tf2.0,"I use contrib.rnn.stack_bidirectional_dynamic_rnn in my code, but I upgrade my tf to 2.0 now, how to replace it?"
33682,Example from tf.data.Dataset.window() raises error,"**System information**
- TensorFlow version (use command below):
v2.0.0-rc2-26-g64c3d382ca 2.0.0
- Python version:
3.7

**Describe the current behavior**
`tf.data.Dataset.from_tensor_slices((range(4), range(4))).window(2)` gives error, see logs.

**Describe the expected behavior**
Should produce `{({0, 1}, {0, 1}), ({2, 3}, {2, 3})}` according to `tf.data.Dataset.window()` docs

**Code to reproduce the issue**
`tf.data.Dataset.from_tensor_slices((range(4), range(4))).window(2)`

**Other info / logs**


```python
TypeError                                 Traceback (most recent call last)
<ipython-input-66-6565779b5dcd> in <module>
----> 1 tf.data.Dataset.from_tensor_slices((range(4), range(4))).window(2)

~/anaconda3/envs/tf2-ray-keras/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in from_tensor_slices(tensors)
    433       Dataset: A `Dataset`.
    434     """"""
--> 435     return TensorSliceDataset(tensors)
    436 
    437   class _GeneratorState(object):

~/anaconda3/envs/tf2-ray-keras/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in __init__(self, element)
   2352   def __init__(self, element):
   2353     """"""See `Dataset.from_tensor_slices()` for details.""""""
-> 2354     element = structure.normalize_element(element)
   2355     batched_spec = structure.type_spec_from_value(element)
   2356     self._tensors = structure.to_batched_tensor_list(batched_spec, element)

~/anaconda3/envs/tf2-ray-keras/lib/python3.7/site-packages/tensorflow_core/python/data/util/structure.py in normalize_element(element)
    110           normalized_components.append(
    111               ops.convert_to_tensor(t, name=""component_%d"" % i))
--> 112   return nest.pack_sequence_as(element, normalized_components)
    113 
    114 

~/anaconda3/envs/tf2-ray-keras/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py in pack_sequence_as(structure, flat_sequence)
    189         % (len(flat_structure), len(flat_sequence), structure, flat_sequence))
    190 
--> 191   _, packed = _packed_nest_with_indices(structure, flat_sequence, 0)
    192   return _sequence_like(structure, packed)
    193 

~/anaconda3/envs/tf2-ray-keras/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py in _packed_nest_with_indices(structure, flat, index)
    147     if is_sequence(s):
    148       new_index, child = _packed_nest_with_indices(s, flat, index)
--> 149       packed.append(_sequence_like(s, child))
    150       index = new_index
    151     else:

~/anaconda3/envs/tf2-ray-keras/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py in _sequence_like(instance, args)
     76   else:
     77     # Not a namedtuple
---> 78     return type(instance)(args)
     79 
     80 

TypeError: 'list' object cannot be interpreted as an integer
```"
33681,_num_elements(grad) difference between Tensor and IndexedSlices behavior,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux-4.4.0-87-generic-x86_64-with-Ubuntu-16.04-xenial
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0
- Python version: 3.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When training a model (which I can't make public at the moment), I've got an error: `<built-in function len> returned a result with an error set`. Debugging showed the reason was in
https://github.com/tensorflow/tensorflow/blob/0d76b0f988d3d7b06f16da950b3ed95e4ec59e82/tensorflow/python/eager/backprop.py#L615-L624
Namely, my code ended up with `grad` being an instance of `IndexedSlices`, but `grad.values._shape_tuple()` was `(None, 16)`. 

Changing code to
```
    shape_tuple = grad.values._shape_tuple()  # pylint: disable=protected-access
    if shape_tuple is None or None in shape_tuple:
      return 0
    return functools.reduce(operator.mul, shape_tuple, 1)
```
by analogy with the `Tensor` case appears to work and let my model train, but I am not certain whether that's correct.

**Describe the expected behavior**
Either handle the case where `grad.values._shape_tuple()` is/contains `None`, or explicitly throw `ValueError` if it shouldn't be allowed.

**Code to reproduce the issue**
(Will try to do this later)

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33679,TensorFlow Lite Support for LSTM Models,"**System information**
- TensorFlow version (you are using): 2.0.0
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
As mentioned in the TensorFlow Lite 2019 roadmap, a full support for LSTM and RNN models is expected. When this support is expected to be released? will it also support LSTM layers from Keras? 

**Will this change the current api? How?**
Not sure 

**Who will benefit with this feature?**
Everyone which would like to convert TensorFlow LSTM models to the TensorFlow lite format 

**Any Other info.**
"
33677,tflite:experimental:micro:riscv: the default build target is wrong.,"The intended target ( `make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=riscv32_mcu`) should be `all` , as in the README.md
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/README.md.
But in fact it's not `all' by default."
33676,TF lite GPU delegates should use the same linker script as main library,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android/Ubuntu
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.15.0
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: ip
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): NDK r17b clang
- CUDA/cuDNN version: -
- GPU model and memory: -


**Describe the problem**
Currently libtensorflowlite.so is build with `""-Wl,--version-script,$(location //tensorflow/lite:tflite_version_script.lds)""`

The same is not done for gpu delegates.
Is there any particular reason for that?
I believe it should be applied to gpu delegate libraries too, as currently you'll need 
I don't believe any symbol other than tflite related symbols are necessary.
If `visibility=hidden` by default is ok (since I think we only need C API from GPU Delegate), then shouldn't it be default flag for the library?

Inconsistent symbol hiding makes it confusing when building both main library and gpu delegates
Would it be acceptable to hide symbols by default or use linker script as in main tflite library?

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33675,"tf.keras.callbacks.ReduceLROnPlateau -  min_delta parameter should be percentage, not absolute  ","
**System information**
- TensorFlow version 2.0:



**Describe the feature and the current behavior/state.**
Regarding tf.keras.callbacks.ReduceLROnPlateau: The min_delta parameter is currently an absolute number which indicates when a meaningful reduction in the monitored loss has accrued. It makes no sense to use an absolute number for two reasons - 
1. Every loss has a different dynamic range and hence a different definition for a meaningful reduction
2. A ""meaningful reduction"" decreases as the training progresses. The higher the epoch the smaller of a change in loss is expected.  

For these two reasons I think that a percentage of change in the monitored loss is much more useful. 

**Will this change the current api? How?**
Maybe, if the implantation is by adding a new parameter to the callback named ""min_delta_percent"".
**Who will benefit with this feature?**
Everyone using this callback.
"
33674,os.path.join adding \ to the existing path instead of /,"require path : 
C:/Users/user/Documents/TensorFlow/workspace/training_demo/images/train/bandhook.png
path formed 
C:/Users/user/Documents/TensorFlow/workspace/training_demo/images/train\bandhook.png 
using : os.path.join(path, '{}'.format(group.filename)) or os.path.join(path,"""",group.filename)) as per below docs where path is C:/Users/user/Documents/TensorFlow/workspace/training_demo/images/train
and group.filename is bandhook.png.
Following below link 
https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html"
33673,[tf2.0] LSTMCell get_initial_state went wrong when batch_size is a Tensor,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
Not Clear
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
2.0.0
- Python version:
3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
10.0
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
LSTMCell get_initial_state went wrong when batch_size is a Tensor
**Describe the expected behavior**
I think it should gives a good result
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
import tensorflow as tf

a = tf.keras.Input(shape=(10,), batch_size=2)
batch_size = tf.shape(a)[0]
cell = tf.keras.layers.LSTMCell(units=1024)
b = cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py"", line 2355, in zeros
    tensor_shape.TensorShape(shape))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py"", line 776, in __init__
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py"", line 776, in <listcomp>
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py"", line 718, in as_dimension
    return Dimension(value)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py"", line 193, in __init__
    self._value = int(value)
TypeError: int() argument must be a string, a bytes-like object or a number, not 'Tensor'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1610, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Duplicate node name in graph: 'zeros/packed'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test7.py"", line 10, in <module>
    b = cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/recurrent.py"", line 2314, in get_initial_state
    self, inputs, batch_size, dtype))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/recurrent.py"", line 2752, in _generate_zero_filled_state_for_cell
    return _generate_zero_filled_state(batch_size, cell.state_size, dtype)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/recurrent.py"", line 2768, in _generate_zero_filled_state
    return nest.map_structure(create_zeros, state_size)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/nest.py"", line 535, in map_structure
    structure[0], [func(*x) for x in entries],
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/nest.py"", line 535, in <listcomp>
    structure[0], [func(*x) for x in entries],
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/recurrent.py"", line 2765, in create_zeros
    return array_ops.zeros(init_state_size, dtype=dtype)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py"", line 2358, in zeros
    shape = ops.convert_to_tensor(shape, dtype=dtypes.int32)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1184, in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1242, in convert_to_tensor_v2
    as_ref=False)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1296, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py"", line 1278, in _autopacking_conversion_function
    return _autopacking_helper(v, dtype, name or ""packed"")
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py"", line 1214, in _autopacking_helper
    return gen_array_ops.pack(elems_as_tensors, name=scope)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_array_ops.py"", line 6304, in pack
    ""Pack"", values=values, axis=axis, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py"", line 548, in create_op
    compute_device)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1773, in __init__
    control_input_ops)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1613, in _create_c_op
    raise ValueError(str(e))
ValueError: Duplicate node name in graph: 'zeros/packed'"
33672,Conv3D nodes not converted to float16 although automatic mixed precision is on.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): **pip install tf-nightly-gpu**
- TensorFlow version (use command below): **tf-nightly-gpu-2.1.0.dev20191023**
- Python version: **Python 3.7.4**
- CUDA/cuDNN version: **CUDA 10.0, cuDNN 7.6.4**
- GPU model and memory: **2x NVIDIA TITAN RTX**

**Describe the current behavior**
When automatic precision is active, 3D convolution ops are not converted to float16 and no performance gain is observed. 

In the output of the provided example, we can see that most of the nodes are not converted to float16:
`Converted 9/854 nodes to float16 precision using 2 cast(s) to float16 (excluding Const and Variable casts)`

Apart from the warmup delay during the first epoch of the training without AMP, there is no difference in the duration of epochs with and without AMP.

**Describe the expected behavior**
According to `tensorflow/tensorflow/core/grappler/optimizer/auto_mixed_precision_lists.h` and cuDNN release notes, 3D convolution operations on Volta architecture should benefit from AMP training with the tested versions of TF, CUDA and cuDNN.

When debugging with `TF_CPP_MIN_VLOG_LEVEL=2`, I can see why the ops are not optimized:
`I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1076] Skipping ReadVariableOp node model/conv3d/Conv3D/ReadVariableOp because it must be preserved`
I can't figure out why those items must be preserved. In the source code, I think they are marked as nodes to preserve in `GrapplerItem::NodesToPreserve()` in `tensorflow/core/grappler/grappler_item.cc`, but I could not find out the exact reason.

**Code to reproduce the issue**
```
import time
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.python.client import device_lib

print(""TensorFlow version is"", tf.__version__)

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
NUM_SAMPLES = 1000
x_train = x_train[:NUM_SAMPLES]
y_train = y_train[:NUM_SAMPLES]
x_test = x_test[:NUM_SAMPLES]
y_test = y_test[:NUM_SAMPLES]

def fake3d(x):
    return np.repeat(x[:, np.newaxis], 8, axis=1)

x_train = fake3d(x_train)
x_test = fake3d(x_test)

num_classes = np.max(y_train) + 1
y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_test = tf.keras.utils.to_categorical(y_test, num_classes)

def normalize(ndarray):
    ndarray = ndarray.astype(""float32"")
    ndarray = ndarray/255.0
    return ndarray

x_train = normalize(x_train)
x_test = normalize(x_test)

def create_model(num_classes=10):
    # model parameters
    act = ""relu""
    pad = ""same""
    ini = ""he_uniform""

    model = tf.keras.models.Sequential([
        Conv3D(128, (3,3,3), activation=act, padding=pad, kernel_initializer=ini,
               input_shape=(8,32,32,3)),
        Conv3D(256, (3,3,3), activation=act, padding=pad, kernel_initializer=ini),
        Conv3D(256, (3,3,3), activation=act, padding=pad, kernel_initializer=ini),
        Conv3D(256, (3,3,3), activation=act, padding=pad, kernel_initializer=ini),
        MaxPooling3D(pool_size=(2,2,2)),
        Conv3D(256, (3,3,3), activation=act, padding=pad, kernel_initializer=ini),
        Conv3D(256, (3,3,3), activation=act, padding=pad, kernel_initializer=ini),
        Conv3D(512, (3,3,3), activation=act, padding=pad, kernel_initializer=ini),
        Conv3D(512, (3,3,3), activation=act, padding=pad, kernel_initializer=ini),
        MaxPooling3D(pool_size=(2,2,2)),
        Conv3D(256, (3,3,3), activation=act, padding=pad, kernel_initializer=ini),
        Conv3D(256, (3,3,3), activation=act, padding=pad, kernel_initializer=ini),
        Conv3D(256, (3,3,3), activation=act, padding=pad, kernel_initializer=ini),
        Conv3D(128, (3,3,3), activation=act, padding=pad, kernel_initializer=ini),
        MaxPooling3D(pool_size=(2,4,4)),
        Flatten(),
        BatchNormalization(),
        Dense(512, activation='relu'),
        Dense(num_classes, activation=""softmax"")
    ])

    return model

model = create_model(num_classes)
model.summary()
BATCH_SIZE = 320
N_EPOCHS = 6
opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.5)

def train_model(mixed_precision, optimizer):
    model = create_model(num_classes)

    if mixed_precision:
        import tensorflow
        optimizer = tf.train.experimental.enable_mixed_precision_graph_rewrite(optimizer)

    model.compile(loss=""categorical_crossentropy"",
                  optimizer=optimizer,
                  metrics=[""accuracy""])

    train_start = time.time()

    train_log = model.fit(x_train, y_train,
                          batch_size=BATCH_SIZE,
                          epochs=N_EPOCHS,
                          use_multiprocessing=True,
                          workers=2)

    train_end = time.time()

    results = {
               ""train_time"": train_end-train_start,
               ""train_log"": train_log}

    return results

fp32_results = train_model(mixed_precision=False, optimizer=opt)
train_time = round(fp32_results[""train_time""], 1)
print(""achieved in"", train_time, ""seconds"")

tf.keras.backend.clear_session()
time.sleep(10)

mp_results = train_model(mixed_precision=True, optimizer=opt)
train_time = round(mp_results[""train_time""], 1)
print(""achieved in"", train_time, ""seconds"")
```"
33671,"TFLite Raspberry Pi object detection example code does not work with tensorflow.lite.python.interpreter, only works with tflite_runtime.interpreter","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian Buster
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Raspberry Pi 4 4GB
- TensorFlow installed from (source or binary): Binary (pip3 install tensorflow)
- TensorFlow version (use command below): v1.12.1-3892-g127aae0 1.13.1
- Python version: 3.7.3
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the behavior**
I am following the TFLite object detection on Raspberry Pi guide (https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/raspberry_pi) using a Raspberry Pi 4 4GB model. The guide says to download and install the tflite_runtime from the [Python quickstart page](https://www.tensorflow.org/lite/guide/python). However, I tried using it with my existing installation of TensorFlow since I already have it installed on my Pi 4, and the script exits with the error shown below.

It also doesn't work if I have regular TensorFlow and the tflite_runtime package installed at the same time. It does work if I uninstall TensorFlow using `pip3 uninstall tensorflow` and then install the tflite_runtime package. 

**Describe the expected behavior**
It would be nice if the object detection example code worked without having to remove my existing TensorFlow install.

**Code to reproduce the issue**
I used the example code given [here](https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/raspberry_pi/detect_picamera.py). When trying to use regular TensorFlow (rather than just the tflite_runtime package), I changed line 33 from `from tflite_runtime.interpreter import Interpreter` to `from tensorflow.lite.python.interpreter import Interpreter`.

I called the script using:
```
python3 detect_picamera.py \
  --model /tmp/detect.tflite \
  --labels /tmp/coco_labels.txt
```

**Other info / logs**
Traceback for the error I am getting:

Traceback (most recent call last):
  File ""TFLite_detection_picamera.py"", line 113, in <module>
    interpreter = Interpreter(model_path=PATH_TO_CKPT)
  File ""/home/pi/.local/lib/python3.7/site-packages/tflite_runtime/interpreter.py"", line 205, in __init__
    _interpreter_wrapper.InterpreterWrapper_CreateWrapperCPPFromFile(
  File ""/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/python/util/lazy_loader.py"", line 62, in __getattr__
    module = self._load()
  File ""/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/python/util/lazy_loader.py"", line 45, in _load
    module = importlib.import_module(self.__name__)
  File ""/usr/lib/python3.7/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py"", line 28, in <module>
    _tensorflow_wrap_interpreter_wrapper = swig_import_helper()
  File ""/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_tensorflow_wrap_interpreter_wrapper', fp, pathname, description)
  File ""/usr/lib/python3.7/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.7/imp.py"", line 342, in load_dynamic
    return _load(spec)
  File ""<frozen importlib._bootstrap>"", line 696, in _load
  File ""<frozen importlib._bootstrap>"", line 670, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 583, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 1043, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: /home/pi/.local/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so: undefined symbol: _ZN6tflite12tensor_utils24NeonVectorScalarMultiplyEPKaifPf
"
33669,tf.keras.callbacks.ProgbarLogger not works as expected,"I was tried to use tf.keras instead of keras, and I found that tf.keras.callbacks.ProgbarLogger not works as expected, or as the old keras did.
In keras, at the end of one-epoch's training, the ProgbarLogger will just wait until the validation done, and the final info on the screen would be like 
>[training-progress-bar] training-metrics validation-metrics

But In keras, at the end of one-epoch's training, the training-progress-bar will disappear and the validation-progress-bar will show on the screen. And when validation progress finished, the final info on the screen would be like 
> [validation-progress-bar] validation-metrics 
> [training-progress-bar] training-metrics validation-metrics

 As I expected, the training-progress-bar should stay on the screen during validation, and the final info should be 
> [training-progress-bar] training-metrics
> [validation-progress-bar] validation-metrics "
33668,[Simple Bug] 'name' should be a variable,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- TensorFlow version 1.13
- Python version: 3.6.8

**Describe the current behavior**
I want build two convLSTMCell and use them. like follow [Code to reproduce the issue]
tensorflow talk to me: `ValueError: Variable kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at xxxx.`


**Describe the expected behavior**
the code can run without error.

**Code to reproduce the issue**
```
import tensorflow as tf
import tensorflow.contrib.rnn as rnn
import numpy as np

npa = np.array([[[[1,2,3],[4,5,6],[4,5,6]],[[7,8,9],[10,11,12],[10,11,12]],[[13,14,15],[16,17,18],[16,17,18]]]])
print(npa.shape)
x = tf.constant(npa, dtype=tf.float32)
print(x)
# first cell
cell_encoder = rnn.Conv2DLSTMCell(input_shape=[x.shape[1], x.shape[2], x.shape[3]], output_channels=4,kernel_shape=[3, 3], name='encoder')
initial1 = cell_encoder.zero_state(batch_size=x.shape[0],dtype=tf.float32)
x1, fs1 = cell_encoder.call(inputs=x, state=initial1)
# second cell
cell_decoder = rnn.Conv2DLSTMCell(input_shape=[x.shape[1], x.shape[2], x.shape[3]], output_channels=4, kernel_shape=[3, 3], name='decoder')
initial2 = cell_decoder.zero_state(batch_size=x.shape[0], dtype=tf.float32)
x2, fs2 = cell_decoder.call(inputs=x, state=initial2)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    x = sess.run(x2)
    print(x)
```
[minimal standalone code ]

**Other info / logs**
When system execution `[cell_decoder.call]`,  tensorflow talk to me: `ValueError: Variable kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at xxxx`.
then ,i tack the code find `tensorflow/contrib/rnn/python/ops/rnn_cell.py line: 2215 & 2228, vs.get_variable function `name of the function should be a variable, not a constant.
the issue is simple. If the name  is a constant, the second cell, cell_decoder, will use the same one variable.

Thanks to tensorflow for providing AI open source framework.  O(∩_∩)O


"
33667,Potential redundancy in using np.array,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry:
https://www.tensorflow.org/tutorials/generative/deepdream

## Description of the issue (what needs changing):
In this example, we are already performing this: `original_img = np.array(original_img)` in the beginning. Then, what is the point of repeating it here: `img = tf.constant(np.array(original_img))` and here: `shift_down, shift_right, img_rolled = random_roll(np.array(original_img), 512)`? "
33666,"tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node my_model/conv2d/Conv2D (defined at /wang/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_train_step_638]","Code:

```
from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf

from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

# Add a channels dimension
x_train = x_train[..., tf.newaxis]
x_test = x_test[..., tf.newaxis]

train_ds = tf.data.Dataset.from_tensor_slices(
    (x_train, y_train)).shuffle(10000).batch(32)

test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)

class MyModel(Model):
  def __init__(self):
    super(MyModel, self).__init__()
    self.conv1 = Conv2D(32, 3, activation='relu')
    self.flatten = Flatten()
    self.d1 = Dense(128, activation='relu')
    self.d2 = Dense(10, activation='softmax')

  def call(self, x):
    x = self.conv1(x)
    x = self.flatten(x)
    x = self.d1(x)
    return self.d2(x)

# Create an instance of the model
model = MyModel()

loss_object = tf.keras.losses.SparseCategoricalCrossentropy()

optimizer = tf.keras.optimizers.Adam()

train_loss = tf.keras.metrics.Mean(name='train_loss')
train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')

test_loss = tf.keras.metrics.Mean(name='test_loss')
test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')

@tf.function
def train_step(images, labels):
  with tf.GradientTape() as tape:
    predictions = model(images)
    loss = loss_object(labels, predictions)
  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))

  train_loss(loss)
  train_accuracy(labels, predictions)

@tf.function
def test_step(images, labels):
    predictions = model(images)
    t_loss = loss_object(labels, predictions)

    test_loss(t_loss)
    test_accuracy(labels, predictions)


EPOCHS = 5

for epoch in range(EPOCHS):
  for images, labels in train_ds:
    train_step(images, labels)

  for test_images, test_labels in test_ds:
    test_step(test_images, test_labels)

  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'
  print(template.format(epoch+1,
                        train_loss.result(),
                        train_accuracy.result()*100,
                        test_loss.result(),
                        test_accuracy.result()*100))

  # Reset the metrics for the next epoch
  train_loss.reset_states()
  train_accuracy.reset_states()
  test_loss.reset_states()
  test_accuracy.reset_states()

```



**System information**

    OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
    Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
    TensorFlow installed from (source or binary): Source and Binary (tried both)
    TensorFlow version: 2.0
    Python version: 3.7.4
GPU: 1080 Ti
    Installed using virtualenv? pip? conda?: conda
    Bazel version (if compiling from source): 0.18
    GCC/Compiler version (if compiling from source): gcc 5.4.0

**Package:**
# Name                    Version                   Build  Channel
_libgcc_mutex             0.1                        main  
absl-py                   0.8.1                    pypi_0    pypi
astor                     0.8.0                    pypi_0    pypi
blas                      1.0                         mkl  
ca-certificates           2019.10.16                    0  
certifi                   2019.9.11                py37_0  
cudatoolkit               10.1.168                      0  
cudnn                     7.6.0                cuda10.1_0  
cycler                    0.10.0                   py37_0  
dbus                      1.13.6               h746ee38_0  
expat                     2.2.6                he6710b0_0  
fontconfig                2.13.0               h9420a91_0  
freetype                  2.9.1                h8a8886c_1  
gast                      0.2.2                    pypi_0    pypi
glib                      2.56.2               hd408876_0  
google-pasta              0.1.7                    pypi_0    pypi
grpcio                    1.24.3                   pypi_0    pypi
gst-plugins-base          1.14.0               hbbd80ab_1  
gstreamer                 1.14.0               hb453b48_1  
h5py                      2.10.0                   pypi_0    pypi
icu                       58.2                 h9c2bf20_1  
intel-openmp              2019.4                      243  
jpeg                      9b                   h024ee3a_2  
keras-applications        1.0.8                    pypi_0    pypi
keras-preprocessing       1.1.0                    pypi_0    pypi
kiwisolver                1.1.0            py37he6710b0_0  
libedit                   3.1.20181209         hc058e9b_0  
libffi                    3.2.1                hd88cf55_4  
libgcc-ng                 9.1.0                hdf63c60_0  
libgfortran-ng            7.3.0                hdf63c60_0  
libpng                    1.6.37               hbc83047_0  
libstdcxx-ng              9.1.0                hdf63c60_0  
libuuid                   1.0.3                h1bed415_2  
libxcb                    1.13                 h1bed415_1  
libxml2                   2.9.9                hea5a465_1  
markdown                  3.1.1                    pypi_0    pypi
matplotlib                3.1.1            py37h5429711_0  
mkl                       2019.4                      243  
mkl-service               2.3.0            py37he904b0f_0  
mkl_fft                   1.0.14           py37ha843d7b_0  
mkl_random                1.1.0            py37hd6b4f25_0  
ncurses                   6.1                  he6710b0_1  
numpy                     1.17.3                   pypi_0    pypi
numpy-base                1.17.2           py37hde5b4d6_0  
openssl                   1.1.1d               h7b6447c_3  
opt-einsum                3.1.0                    pypi_0    pypi
pandas                    0.25.2           py37he6710b0_0  
pcre                      8.43                 he6710b0_0  
pip                       19.3.1                   py37_0  
protobuf                  3.10.0                   pypi_0    pypi
pyparsing                 2.4.2                      py_0  
pyqt                      5.9.2            py37h05f1152_2  
python                    3.7.4                h265db76_1  
python-dateutil           2.8.0                    py37_0  
pytz                      2019.3                     py_0  
qt                        5.9.7                h5867ecd_1  
readline                  7.0                  h7b6447c_5  
setuptools                41.4.0                   py37_0  
sip                       4.19.8           py37hf484d3e_0  
six                       1.12.0                   pypi_0    pypi
sqlite                    3.30.0               h7b6447c_0  
tensorboard               2.0.0                    pypi_0    pypi
tensorflow-estimator      2.0.1                    pypi_0    pypi
tensorflow-gpu            2.0.0                    pypi_0    pypi
termcolor                 1.1.0                    pypi_0    pypi
tk                        8.6.8                hbc83047_0  
tornado                   6.0.3            py37h7b6447c_0  
werkzeug                  0.16.0                   pypi_0    pypi
wheel                     0.33.6                   py37_0  
wrapt                     1.11.2                   pypi_0    pypi
xz                        5.2.4                h14c3975_4  
zlib                      1.2.11               h7b6447c_3  


**Error**
2019-10-24 00:02:55.586964: E tensorflow/stream_executor/cuda/cuda_dnn.cc:319] Loaded runtime CuDNN library: 7.5.0 but source was compiled with: 7.6.0.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
2019-10-24 00:02:55.588179: E tensorflow/stream_executor/cuda/cuda_dnn.cc:319] Loaded runtime CuDNN library: 7.5.0 but source was compiled with: 7.6.0.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
2019-10-24 00:02:55.588889: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node my_model/conv2d/Conv2D}}]]
Traceback (most recent call last):
  File ""/home/jiahao/Documents/little_fun/test.py"", line 73, in <module>
    train_step(images, labels)
  File ""/home/jiahao/wang/lib/python3.5/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/home/jiahao/wang/lib/python3.5/site-packages/tensorflow_core/python/eager/def_function.py"", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/jiahao/wang/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py"", line 1823, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/home/jiahao/wang/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File ""/home/jiahao/wang/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""/home/jiahao/wang/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py"", line 511, in call
    ctx=ctx)
  File ""/home/jiahao/wang/lib/python3.5/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node my_model/conv2d/Conv2D (defined at /wang/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_train_step_638]

Function call stack:
train_step
"
33665,[Docker] The 'tensorflow/tensorflow:1.15.0-py3' is missing on DockerHub,All other combinations of `tensorflow:1.15.0[-gpu][-py3][-jupyter]` are available.
33664,Some errors when running keras-yolo3 as a child process ,"Hello! I am confronted with some errors and don't know how to solve them When running keras-yolo3 module as a child process. By setting breakpoints, I found erors appearing at the statement in yolo.py ""sout_boxes, out_scores, out_classes = self.sess()"". Concrete errors are shown as follows:
1 [tensorflow/core/grappler/clusters/utils.cc:82] Failed to get device properties, error code: 3
2 Python failed to enqueue async from host to device: cuda _error_not_initialized;
GPU dst: …… ; host src: …… ;size: ……

I am looking forward to getting replys from warm-hearted you, thanks!"
33663,Can not build debug wheel due to OverflowError: Size does not fit in an unsigned int,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.13
- Python version: 3.5
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.19
- GCC/Compiler version (if compiling from source): 4.8
- CUDA/cuDNN version: 10.0
- GPU model and memory: 


**Describe the problem**

I cannot create the wheel file for a TensorFlow build with debug symbols. According to #25026, it seems that the target file is too big for pip to generate. I have to debug the TensorFlow inner c++ code, is there anyone know the solution for this problem plz?

command: 
bazel build --spawn_strategy=standalone --verbose_failures --config=cuda --copt=""-fPIC"" --copt=""-DNDEBUG"" --local_resources 11048,2.0,2.0 -c dbg --copt -g //tensorflow/tools/pip_package:build_pip_package
and then
./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg

output:
data = co.compress(data) + co.flush()
OverflowError: Size does not fit in an unsigned int

Traceback (most recent call last):
  File ""setup.py"", line 294, in <module>
    keywords='tensorflow tensor machine learning',
  File ""/usr/local/lib/python3.5/dist-packages/setuptools/__init__.py"", line 145, in setup
    return distutils.core.setup(**attrs)
  File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup
    dist.run_commands()
  File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands
    self.run_command(cmd)
  File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command
    cmd_obj.run()
  File ""/usr/local/lib/python3.5/dist-packages/wheel/bdist_wheel.py"", line 250, in run
    wf.write_files(archive_root)
  File ""/usr/local/lib/python3.5/dist-packages/wheel/wheelfile.py"", line 122, in write_files
    self.write(path, arcname)
  File ""/usr/local/lib/python3.5/dist-packages/wheel/wheelfile.py"", line 136, in write
    self.writestr(zinfo, data, compress_type)
  File ""/usr/local/lib/python3.5/dist-packages/wheel/wheelfile.py"", line 139, in writestr
    ZipFile.writestr(self, zinfo_or_arcname, bytes, compress_type)
  File ""/usr/lib/python3.5/zipfile.py"", line 1573, in writestr
    data = co.compress(data) + co.flush()
OverflowError: Size does not fit in an unsigned int
"
33662,How to write a dataset of serialized examples directly to a tfrecords file?,"I tried asking the broader community for this, but nothing came back, so I'm asking it here.

I have a `tf.data.Dataset` that contains serialized tfrecord/protobuf examples:

```python
>>> example = ds.make_one_shot_iterator().get_next()
>>> example
<tf.Tensor: id=42, shape=(), dtype=string, numpy=b'\n\xdd:\n\r\n\x01y\x12\x08\x12\x06\n\x...'>
```
So each example in the dataset `ds` is just a flat byte string.

What I'd like to do is to write these byte strings to disk (tfrecords file). The way I know to do this is to go through python land. For instance, using a tf1 session, this would look like:
```python
example = ds.make_one_shot_iterator().get_next()

with tf.io.TFRecordWriter(""/path/to/output/data.tfrecords"") as w:
    with tf.Session() as sess:
        w.write(sess.run(example))
```
This doesn't feel very efficient to me. So my question is:

- Is there a way that I can write this to a file without having to go through the python layer?
"
33661,"Iterator initialization fails on GPU, sometimes segfaults on creating next batch","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.14
- Python version: 3.6.9
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: 10.1/7.6
- GPU model and memory: 2 Tesla K80s

**Describe the current behavior**
session fails to initialize iterable dataset on GPU with message `tensorflow.python.framework.errors_impl.NotFoundError: No registered 'Const' OpKernel for GPU devices compatible with node {{node compression_type}}`.  No such issue occurs on CPU.  In some cases, the dataset initializes, but fetching the next set of data causes a segfault.  I have been unable to create simple code which reproduces the second effect.

**Describe the expected behavior**
dataset initializes and no segfault when creating next batch

**Code to reproduce the issue**
```python
import tensorflow as tf

from tensorflow.python.client import device_lib

def parse_line(line):
    items = tf.string_split([line])
    token_ids = tf.string_to_number(items.values, out_type=tf.int32)
    return token_ids

def get_gpu_name():
    devices = device_lib.list_local_devices()
    for device in devices:
        if device.device_type == ""GPU"":
            return device.name

def main():
    data_file = ""data_file.txt""
    with open(data_file, 'w', encoding='utf-8') as f:
        f.write(""0 1 2 3 4 5 6 7 8"")
    dataset = tf.data.TextLineDataset(data_file).map(parse_line)
    data_iter = dataset.make_initializable_iterator()
    gpu_device = get_gpu_name()
    
    with tf.device(gpu_device):
        features = data_iter.get_next()

    with tf.Session() as session:
        session.run(data_iter.initializer) # <- tensorflow fails on this line
        session.run(features) # <- tensorflow sometimes segfaults on this line
```

**Other info / logs**
[gpu.log](https://github.com/tensorflow/tensorflow/files/3765376/gpu.log)

"
33660,tf.test.compute_gradient (v2) expects wrong empty gradient shape,"**System Information**

- Have I written custom code: YES (see below)
- OS Platform and Distribution: Ubuntu 18.04.3 LTS (inside `tensorflow/tensorflow:2.0.0-gpu`)
- Mobile device: N/A
- TensorFlow installed from: binary (inside `tensorflow/tensorflow:2.0.0-gpu`)
- TensorFlow version: 2.0.0
- Python version: 2.7.15+
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.0
- GPU model and memory: TITANV 12GB

**Current Behavior**
When the gradient tensors are totally empty (i.e. all their dimensions are zero), and more than one input is considered at the same time,  the shape of an expected gradient tensor does not match the actual shape produced by the op's gradient function. This case is not currently tested in `tensorflow/python/ops/gradient_checker_v2_test.py` (see `testEmptyMatMul`).

*UPDATE*: I also tried the configuration in `testEmptyMatMul` (see additional code below) and found that this also tickles the apparent bug. Surprisingly, `//tensorflow/python:gradient_checker_v2_test` passes when running on tag v2.0.0; I don't currently understand why.

I have tested
  * with two different ops, each with two inputs (both fail).
  * cases where not all of the gradient tensors are empty (as in `testEmptyMatMul`).
  * `tf.compat.v1.test.compute_gradient` with more than one empty input does **not** exhibit this behavior, so it was probably not present in `tensorflow/python/ops/gradient_checker.py` but was introduced in `tensorflow/python/ops/gradient_checker_v2.py`. See code at the end, in the ""TensorFlow Version 1 API"" section, that demonstrates this.

I have **not** tested
  * using ops with more than two inputs

**Expected Behavior**
These exceptions should not be produced when using built-in ops. Either the ops' gradient functions are producing the wrong shaped tensors (which would be a bug), or, more likely, the code in `gradient_checker_v2.py` is expecting the wrong shape.

**Code to reproduce the issue**
```
import numpy as np
import tensorflow as tf

def empty(rank):
  shape = (0,) * rank
  return np.array([]).reshape(shape)

# comment-out the first to run the second
tf.test.compute_gradient(tf.nn.bias_add, [empty(3), empty(1)])
tf.test.compute_gradient(tf.linalg.matmul, [empty(2), empty(3)])
```

The following is essentially the same as the code in `testEmptyMatMul` in `tensorflow/python/ops/gradient_checker_v2_test.py`: 
```
import numpy as np
import tensorflow as tf

def random_tensor(shape):
  return tf.constant(np.random.random_sample(shape))

def f(x, y):
  return tf.linalg.matmul(x, y)

x = random_tensor((0, 3))
y = random_tensor((3, 4))

jacobians = tf.test.compute_gradient(f, [x, y])
```

**Other info / logs**

Output from the above code:
```
Traceback (most recent call last):
  File ""repro_eager_issue.py"", line 24, in <module>
    tf.test.compute_gradient(tf.nn.bias_add, [empty(3), empty(1)])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py"", line 332, in compute_gradient
    return _compute_gradient_list(f, x, delta)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py"", line 293, in _compute_gradient_list
    xs, i, delta) for i in range(len(xs))])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py"", line 278, in _compute_gradient
    xs, param)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py"", line 187, in _compute_theoretical_jacobian
    (x.shape, grad.shape))
ValueError: Empty gradient has wrong shape: expected (0,), got (0, 0, 0)

Traceback (most recent call last):
  File ""repro_eager_issue.py"", line 25, in <module>
    tf.test.compute_gradient(tf.linalg.matmul, [empty(2), empty(3)])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py"", line 332, in compute_gradient
    return _compute_gradient_list(f, x, delta)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py"", line 293, in _compute_gradient_list
    xs, i, delta) for i in range(len(xs))])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py"", line 278, in _compute_gradient
    xs, param)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py"", line 187, in _compute_theoretical_jacobian
    (x.shape, grad.shape))
ValueError: Empty gradient has wrong shape: expected (0, 0, 0), got (0, 0)

Traceback (most recent call last):
  File ""tf_issue_33660.py"", line 77, in <module>
    existing_test_repro()
  File ""tf_issue_33660.py"", line 71, in existing_test_repro
    jacobians = tf.test.compute_gradient(f, [x, y])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py"", line 332, in compute_gradient
    return _compute_gradient_list(f, x, delta)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py"", line 293, in _compute_gradient_list
    xs, i, delta) for i in range(len(xs))])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py"", line 278, in _compute_gradient
    xs, param)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py"", line 187, in _compute_theoretical_jacobian
    (x.shape, grad.shape))
ValueError: Empty gradient has wrong shape: expected (3, 4), got (0, 3)
```

**Work-Around**

`compute_gradient` can be called multiple times, once for each input, to get the analytical and numerical jacobians for each input separately. As, follows:

```
import numpy as np
import tensorflow as tf

def empty(rank):
  shape = (0,) * rank
  return np.array([]).reshape(shape)

input_val = empty(3)
bias_val = empty(1)

def bias_add_1(input_val):
  return tf.nn.bias_add(input_val, bias_val)

def bias_add_2(bias_val):
  return tf.nn.bias_add(input_val, bias_val)

input_jacobians = tf.test.compute_gradient(bias_add_1, [input_val])
bias_jacobians = tf.test.compute_gradient(bias_add_2, [bias_val])
```

**TensorFlow Version 1 API**

The following code **does not** throw an exception, demonstrating that this problem does not exist with `tf.compat.v1.test.compute_gradient`.

```
import numpy as np
import tensorflow as tf

def empty_tensor(shape):
  return tf.constant([], shape=shape)

tf.compat.v1.disable_eager_execution()
input_shape = output_shape = (0, 0, 0)
bias_shape = (0,)
input_tensor = empty_tensor(input_shape)
bias_tensor = empty_tensor(bias_shape)
output_tensor = tf.nn.bias_add(input_tensor, bias_tensor)
with tf.compat.v1.Session() as sess:
  jacobians = tf.compat.v1.test.compute_gradient(
      [input_tensor, bias_tensor], [input_shape, bias_shape], output_tensor,
      output_shape)
```"
33658,Allow Keras ModelCheckpoint to save the best N checkpoints,"The callback tf.keras.callbacks.ModelCheckpoint allows to save the best checkpoint using save_best_only=True. In the Estimator API we can use tf.estimator.BestExporter that saves the top N checkpoints (parameter exports_to_keep). 

It seems using the Estimator API is becoming discouraged, for example I need to use compat v1 symbols to use the BestExporter.

Is it possible to update the Keras ModelCheckpoint class to allow to save the top N models instead of just the best?

**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**
Yes, the constructor of tf.keras.callbacks.ModelCheckpoint needs a new parameter which is the equivalent of tf.estimator.BestExporter exports_to_keep. We can keep save_best_only but the two parameters can't be used as the same time.

**Who will benefit with this feature?**
Everybody that wants to save several models. For example for model averaging.

**Any Other info.**
"
33657,TPUStrategy breaks on subclassed keras models,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab TPU
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.7

**Code to reproduce the issue**

```python
%tensorflow_version 2.x

# setup

import tensorflow as tf
import os

tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']
cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)
tf.config.experimental_connect_to_cluster(cluster_resolver)
tf.tpu.experimental.initialize_tpu_system(cluster_resolver)
STRATEGY = tf.compat.v1.distribute.experimental.TPUStrategy(cluster_resolver)

# define a subclassed keras model
class Simple(tf.keras.Model):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.dense = tf.keras.layers.Dense(10)

    def call(self, x, training=None):
        return self.dense(x, training=training)

# a fake dataset
data = tf.data.Dataset.from_tensor_slices((
    tf.random.uniform((10, 10)),
    tf.random.uniform((10, 10))
)).batch(10).repeat()

# outside the TPUStrategy scope, the model works fine...
model = Simple()
model.compile(loss='categorical_crossentropy')
model.evaluate(data, steps=1)
# ==> 1/1 [==============================] - 0s 62ms/step - loss: 40.6148

# but if we try and use the model in the scope...
with STRATEGY.scope():
    model = Simple()
    model.compile(loss='categorical_crossentropy')

model.evaluate(data, steps=1)

# we get an error:
# 
# ValueError                                Traceback (most recent call last)
# 
# <ipython-input-17-56ee0b4381e4> in <module>()
#      29     model = Nested(model)
#      30     model.compile(loss='categorical_crossentropy')
# ---> 31 model.evaluate(data, steps=1)
# 
# ... 12 frames ...
# 
# /tensorflow-2.0.0/python3.6/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
#     903           except Exception as e:  # pylint:disable=broad-except
#     904             if hasattr(e, ""ag_error_metadata""):
# --> 905               raise e.ag_error_metadata.to_exception(e)
#     906             else:
#     907               raise
# 
# ValueError: in converted code:
#     relative to /tensorflow-2.0.0/python3.6/tensorflow_core/python/keras:
# 
#     distribute/distributed_training_utils.py:862 distributed_function  *
#         x, y, sample_weights = input_fn()
#     engine/training_arrays.py:516 get_distributed_inputs
#         model, inputs, targets, sample_weights, mode)
#     distribute/distributed_training_utils.py:638 _prepare_feed_values
#         inputs, targets, sample_weights = _get_input_from_iterator(inputs, model)
#     distribute/distributed_training_utils.py:616 _get_input_from_iterator
#         x, y, sample_weights = next_element
# 
#     ValueError: not enough values to unpack (expected 3, got 2)
```

**Expected behavior**

This should not throw any error.
"
33656,Error: No OpKernel was registered to support Op 'NcclAllReduce',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom code/ but copy from the stock example (nothing out of the ordinary)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win10 1903
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.0.0
- **Python version**: 3.7
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 10.0/7.6
- **GPU model and memory**: 4x GTX780ti 3GB each
- **Exact command to reproduce**: model_distributed.fit(X_train, y_train, epochs=4, batch_size=25)

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request. 4x GPUs are recognised. but failed to train. The train on the CPU works well, but then when moving to do it with the distributed strategy shows the error below. I've uninstalled and re-installed ""pip install tensorflow-gpu"" twice. Updated drivers. nothing seems to help. Code below. Any help will be highly appreciated. Thanks.

import time
import numpy as np
import tensorflow as tf

print(tf.__version__)

(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()

X_train = X_train / 255.
X_test = X_test / 255.

X_train = X_train.reshape(-1, 28*28)
X_test = X_test.reshape(-1, 28*28)

model_normal = tf.keras.models.Sequential()
model_normal.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(784,)))
model_normal.add(tf.keras.layers.Dropout(rate=0.2))
model_normal.add(tf.keras.layers.Dense(units=10, activation='softmax'))
model_normal.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])

strategy = tf.distribute.MirroredStrategy()
print('Number of devices: {}'.format(strategy.num_replicas_in_sync))


with strategy.scope():
  model_distributed = tf.keras.Sequential([
      tf.keras.layers.Dense(units=128, activation='relu', input_shape=(784,)),
      tf.keras.layers.Dropout(rate=0.2),
      tf.keras.layers.Dense(units=10, activation='softmax'),
      ])
  model_distributed.compile(loss='sparse_categorical_crossentropy',
                optimizer=tf.keras.optimizers.Adam(),
                metrics=['accuracy'])

start_time = time.time()
model_normal.fit(X_train, y_train, epochs=4, batch_size=25)
print(""Normal training took: {}"".format(time.time() - start_time))

start_time = time.time()
model_distributed.fit(X_train, y_train, epochs=4, batch_size=25)
print(""Distributed training took: {}"".format(time.time() - start_time))


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

2019-10-24 07:50:25.464075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2.0.0
2019-10-24 07:50:29.987980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2019-10-24 07:50:30.090327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 780 Ti major: 3 minor: 5 memoryClockRate(GHz): 1.15
pciBusID: 0000:01:00.0
2019-10-24 07:50:30.097223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:
name: GeForce GTX 780 Ti major: 3 minor: 5 memoryClockRate(GHz): 1.0455
pciBusID: 0000:02:00.0
2019-10-24 07:50:30.104573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties:
name: GeForce GTX 780 Ti major: 3 minor: 5 memoryClockRate(GHz): 1.0845
pciBusID: 0000:03:00.0
2019-10-24 07:50:30.111754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties:
name: GeForce GTX 780 Ti major: 3 minor: 5 memoryClockRate(GHz): 1.15
pciBusID: 0000:04:00.0
2019-10-24 07:50:30.118501: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-10-24 07:50:30.126709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3
2019-10-24 07:50:30.131151: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-10-24 07:50:30.809583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 780 Ti major: 3 minor: 5 memoryClockRate(GHz): 1.15
pciBusID: 0000:01:00.0
2019-10-24 07:50:30.816475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:
name: GeForce GTX 780 Ti major: 3 minor: 5 memoryClockRate(GHz): 1.0455
pciBusID: 0000:02:00.0
2019-10-24 07:50:30.823594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties:
name: GeForce GTX 780 Ti major: 3 minor: 5 memoryClockRate(GHz): 1.0845
pciBusID: 0000:03:00.0
2019-10-24 07:50:30.831552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties:
name: GeForce GTX 780 Ti major: 3 minor: 5 memoryClockRate(GHz): 1.15
pciBusID: 0000:04:00.0
2019-10-24 07:50:30.839507: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-10-24 07:50:30.848211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3
2019-10-24 07:50:32.420376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 07:50:32.465449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3
2019-10-24 07:50:32.491610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N N N
2019-10-24 07:50:32.494431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N N N
2019-10-24 07:50:32.506160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   N N N N
2019-10-24 07:50:32.544545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   N N N N
2019-10-24 07:50:32.572199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2154 MB memory) -> physical GPU (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:01:00.0, compute capability: 3.5)
2019-10-24 07:50:32.614321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 2154 MB memory) -> physical GPU (device: 1, name: GeForce GTX 780 Ti, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-24 07:50:32.670375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 2154 MB memory) -> physical GPU (device: 2, name: GeForce GTX 780 Ti, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-24 07:50:32.725417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 2154 MB memory) -> physical GPU (device: 3, name: GeForce GTX 780 Ti, pci bus id: 0000:04:00.0, compute capability: 3.5)
2019-10-24 07:50:33.211267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 780 Ti major: 3 minor: 5 memoryClockRate(GHz): 1.15
pciBusID: 0000:01:00.0
2019-10-24 07:50:33.310413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:
name: GeForce GTX 780 Ti major: 3 minor: 5 memoryClockRate(GHz): 1.0455
pciBusID: 0000:02:00.0
2019-10-24 07:50:33.383430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties:
name: GeForce GTX 780 Ti major: 3 minor: 5 memoryClockRate(GHz): 1.0845
pciBusID: 0000:03:00.0
2019-10-24 07:50:33.423598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties:
name: GeForce GTX 780 Ti major: 3 minor: 5 memoryClockRate(GHz): 1.15
pciBusID: 0000:04:00.0
2019-10-24 07:50:33.446267: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-10-24 07:50:33.463455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3
2019-10-24 07:50:33.467760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 07:50:33.472212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3
2019-10-24 07:50:33.475053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N N N
2019-10-24 07:50:33.478236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N N N
2019-10-24 07:50:33.481176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   N N N N
2019-10-24 07:50:33.486383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   N N N N
2019-10-24 07:50:33.492208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 2154 MB memory) -> physical GPU (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:01:00.0, compute capability: 3.5)
2019-10-24 07:50:33.501615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:1 with 2154 MB memory) -> physical GPU (device: 1, name: GeForce GTX 780 Ti, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-24 07:50:33.510891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:2 with 2154 MB memory) -> physical GPU (device: 2, name: GeForce GTX 780 Ti, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-24 07:50:33.520186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:3 with 2154 MB memory) -> physical GPU (device: 3, name: GeForce GTX 780 Ti, pci bus id: 0000:04:00.0, compute capability: 3.5)
Number of devices: 4
Train on 60000 samples
Epoch 1/4
2019-10-24 07:50:35.783397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2019-10-24 07:50:35.958561: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2019-10-24 07:50:35.963318: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2019-10-24 07:50:35.967782: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2019-10-24 07:50:35.974357: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
60000/60000 [==============================] - 10s 165us/sample - loss: 0.2815 - sparse_categorical_accuracy: 0.9183
Epoch 2/4
60000/60000 [==============================] - 8s 132us/sample - loss: 0.1353 - sparse_categorical_accuracy: 0.9603
Epoch 3/4
60000/60000 [==============================] - 8s 133us/sample - loss: 0.1052 - sparse_categorical_accuracy: 0.9674
Epoch 4/4
60000/60000 [==============================] - 8s 131us/sample - loss: 0.0841 - sparse_categorical_accuracy: 0.9741
Normal training took: 33.73987317085266
Train on 60000 samples
Epoch 1/4
   25/60000 [..............................] - ETA: 3:18:14Traceback (most recent call last):
  File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\ptvsd_launcher.py"", line 119, in <module>
    vspd.debug(filename, port_num, debug_id, debug_options, run_as)
  File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\Packages\ptvsd\debugger.py"", line 39, in debug
    run()
  File ""c:\program files (x86)\microsoft visual studio\2019\community\common7\ide\extensions\microsoft\python\core\Packages\ptvsd\__main__.py"", line 316, in run_file
    runpy.run_path(target, run_name='__main__')
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\Javier\Desktop\Personal files\VS\TensorFlow 2.0 Complete guide\distributed training.py"", line 53, in <module>
    model_distributed.fit(X_train, y_train, epochs=4, batch_size=25)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1823, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\eager\function.py"", line 511, in call
    ctx=ctx)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\eager\execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'NcclAllReduce' used by {{node Adam/NcclAllReduce}}with these attrs: [reduction=""sum"", shared_name=""c1"", T=DT_FLOAT, num_devices=4]
Registered devices: [CPU, GPU]
Registered kernels:
  <no registered kernels>

         [[Adam/NcclAllReduce]] [Op:__inference_distributed_function_33245]
Press any key to continue . . .
"
33655,"Exception in thread ""main"" java.lang.IllegalStateException: Table not initialized.","When training model in tensorflow using tf.contrib.lookup.HashTable and tf.contrib.lookup.KeyValueTensorInitializer, and then save model as .pb, it works when load .pb and predict in tensorflow,
but when importGraphDef in java and predict, an error occurred as below:

2019-10-24 07:24:29.753767: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at lookup_table_op.cc:674 : Failed precondition: Table not initialized.
2019-10-24 07:24:29.753768: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at lookup_table_op.cc:674 : Failed precondition: Table not initialized.
2019-10-24 07:24:29.753784: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at lookup_table_op.cc:674 : Failed precondition: Table not initialized.
2019-10-24 07:24:29.753840: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at lookup_table_op.cc:674 : Failed precondition: Table not initialized.
2019-10-24 07:24:29.753852: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at lookup_table_op.cc:674 : Failed precondition: Table not initialized.
2019-10-24 07:24:29.753865: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at lookup_table_op.cc:674 : Failed precondition: Table not initialized.
2019-10-24 07:24:29.753852: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at lookup_table_op.cc:674 : Failed precondition: Table not initialized.
2019-10-24 07:24:29.753905: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at lookup_table_op.cc:674 : Failed precondition: Table not initialized.
2019-10-24 07:24:29.753905: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at lookup_table_op.cc:674 : Failed precondition: Table not initialized.
2019-10-24 07:24:29.753933: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at lookup_table_op.cc:674 : Failed precondition: Table not initialized.
Exception in thread ""main"" java.lang.IllegalStateException: Table not initialized."
33654,Strange behavior when importing `from` TF submodules,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, but have tested in a standalone bare Python script
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OS X 10.14
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.5
- CUDA/cuDNN version: None
- GPU model and memory: None

**Describe the current behavior**
```python
from tensorflow import data  # ==> imports the tf.data submodule
from tensorflow.data import Dataset  # ==> Raises: ImportError: No module named 'tensorflow.data'
```

**Describe the expected behavior**
I would expect the Dataset class to be imported.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python
from tensorflow.data import Dataset
```"
33653,1.14,
33651,An issue with the code in the  Custom training with tf.distribute.Strategy tutorial,"##  URL(s) with the issue:
https://www.tensorflow.org/tutorials/distribute/custom_training

## Description of issue (what needs changing):

I am not sure if this is a bug or an issue with the tutorial, but when I apply the [Custom training with tf.distribute.Strategy][1] tutorial to the [Image segmentation][2] (I just copy-pasted the code of the two tutorials), the scale of the training loss is not good:

    Epoch 1, Loss: 35478.49609375, Accuracy: 48.560935974121094, Test Loss: 0.8764073252677917, Test Accuracy: 57.97665023803711
    Epoch 2, Loss: 20161.634765625, Accuracy: 74.82583618164062, Test Loss: 0.6519305109977722, Test Accuracy: 77.33595275878906
    Epoch 3, Loss: 15657.2880859375, Accuracy: 81.60499572753906, Test Loss: 0.5801540017127991, Test Accuracy: 79.94847106933594
    Epoch 4, Loss: 13322.1689453125, Accuracy: 84.52685546875, Test Loss: 0.5113006830215454, Test Accuracy: 82.27192687988281
    Epoch 5, Loss: 11845.38671875, Accuracy: 85.9767837524414, Test Loss: 0.4614977538585663, Test Accuracy: 83.19354248046875
    Epoch 6, Loss: 10827.380859375, Accuracy: 86.9468002319336, Test Loss: 0.43975135684013367, Test Accuracy: 83.65667724609375
    Epoch 7, Loss: 10006.4892578125, Accuracy: 87.75154113769531, Test Loss: 0.4181833863258362, Test Accuracy: 83.8880386352539
    Epoch 8, Loss: 9534.9345703125, Accuracy: 88.15916442871094, Test Loss: 0.40620285272598267, Test Accuracy: 84.22107696533203
    Epoch 9, Loss: 8993.767578125, Accuracy: 88.73575592041016, Test Loss: 0.3957768976688385, Test Accuracy: 84.42972564697266
    Epoch 10, Loss: 8425.7080078125, Accuracy: 89.38662719726562, Test Loss: 0.37987643480300903, Test Accuracy: 84.94923400878906

The full code to reproduce is appended below. It looks like the training loss is scaled by `image_height*image_width`.

**Code:**

    import sys, os
    import tensorflow as tf
    from tensorflow_examples.models.pix2pix import pix2pix
    
    import tensorflow_datasets as tfds
    
    import time
    
    
    def normalize(input_image, input_mask):
      input_image = tf.cast(input_image, tf.float32) / 255.0
      input_mask -= 1
      return input_image, input_mask
    
    @tf.function
    def load_image_train(datapoint):
      input_image = tf.image.resize(datapoint['image'], (128, 128))
      input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))
    
      if tf.random.uniform(()) > 0.5:
        input_image = tf.image.flip_left_right(input_image)
        input_mask = tf.image.flip_left_right(input_mask)
    
      input_image, input_mask = normalize(input_image, input_mask)
    
      return input_image, input_mask
    
    def load_image_test(datapoint):
      input_image = tf.image.resize(datapoint['image'], (128, 128))
      input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))
    
      input_image, input_mask = normalize(input_image, input_mask)
    
      return input_image, input_mask
    
    
    def main():
        dataset, info = tfds.load('oxford_iiit_pet:3.0.0', with_info=True)
        TRAIN_LENGTH = info.splits['train'].num_examples
        BATCH_SIZE = 192
        BUFFER_SIZE = 1000
        STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE
        train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)
        test = dataset['test'].map(load_image_test)
        train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()
        train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
        test_dataset = test.batch(BATCH_SIZE)
    
    
    
        OUTPUT_CHANNELS = 3
    
        strategy = tf.distribute.MirroredStrategy()
    
        with strategy.scope():
    
            base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)
    
            # Use the activations of these layers
            layer_names = [
                'block_1_expand_relu',   # 64x64
                'block_3_expand_relu',   # 32x32
                'block_6_expand_relu',   # 16x16
                'block_13_expand_relu',  # 8x8
                'block_16_project',      # 4x4
            ]
            layers = [base_model.get_layer(name).output for name in layer_names]
    
            # Create the feature extraction model
            down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)
    
            down_stack.trainable = False
    
            up_stack = [
                pix2pix.upsample(512, 3),  # 4x4 -> 8x8
                pix2pix.upsample(256, 3),  # 8x8 -> 16x16
                pix2pix.upsample(128, 3),  # 16x16 -> 32x32
                pix2pix.upsample(64, 3),   # 32x32 -> 64x64
            ]
            def unet_model(output_channels):
    
                # This is the last layer of the model
                last = tf.keras.layers.Conv2DTranspose(
                    output_channels, 3, strides=2,
                    padding='same', activation='softmax')  #64x64 -> 128x128
    
                inputs = tf.keras.layers.Input(shape=[128, 128, 3])
                x = inputs
    
                # Downsampling through the model
                skips = down_stack(x)
                x = skips[-1]
                skips = reversed(skips[:-1])
    
                # Upsampling and establishing the skip connections
                for up, skip in zip(up_stack, skips):
                    x = up(x)
                    concat = tf.keras.layers.Concatenate()
                    x = concat([x, skip])
    
                x = last(x)
    
                return tf.keras.Model(inputs=inputs, outputs=x)
    
        
            model = unet_model(OUTPUT_CHANNELS)
            # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
            #             metrics=['accuracy'])
    
            # model.compile(optimizer=tf.keras.optimizers.Adam(3e-4),
            #             loss=tf.keras.losses.SparseCategoricalCrossentropy(tf.keras.losses.Reduction.NONE),
            #             metrics=['sparse_categorical_accuracy'])
    
            optimizer=tf.keras.optimizers.Adam(3e-4)
            metrics = [tf.keras.metrics.MeanIoU(num_classes=3)]
    
        EPOCHS = 2
        VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE
    
        print('Start training')
        start = time.time()
    
        epochs = EPOCHS; steps = STEPS_PER_EPOCH; GLOBAL_BATCH_SIZE = BATCH_SIZE
    
        # Distribute the datasets
    
        train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)
        test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)
    
        with strategy.scope():
            # Set reduction to `none` so we can do the reduction afterwards and divide by
            # global batch size.
            loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
                reduction=tf.keras.losses.Reduction.NONE)
            # or loss_fn = tf.keras.losses.sparse_categorical_crossentropy
            def compute_loss(labels, predictions):
                per_example_loss = loss_object(labels, predictions)
                return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)
    
        with strategy.scope():
            test_loss = tf.keras.metrics.Mean(name='test_loss')
    
            train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
                name='train_accuracy')
            test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
                name='test_accuracy')
    
    
        with strategy.scope():
            def train_step(inputs):
                images, labels = inputs
    
                with tf.GradientTape() as tape:
                    predictions = model(images, training=True)
                    loss = compute_loss(labels, predictions)
    
                gradients = tape.gradient(loss, model.trainable_variables)
                optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    
                train_accuracy.update_state(labels, predictions)
                return loss 
    
            def test_step(inputs):
                images, labels = inputs
    
                predictions = model(images, training=False)
                t_loss = loss_object(labels, predictions)
    
                test_loss.update_state(t_loss)
                test_accuracy.update_state(labels, predictions)
    
        with strategy.scope():
            # `experimental_run_v2` replicates the provided computation and runs it
            # with the distributed input.
            @tf.function
            def distributed_train_step(dataset_inputs):
                per_replica_losses = strategy.experimental_run_v2(train_step,
                                                                args=(dataset_inputs,))
                return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,
                                    axis=None)
            
            @tf.function
            def distributed_test_step(dataset_inputs):
                return strategy.experimental_run_v2(test_step, args=(dataset_inputs,))
    
            train_iter = iter(train_dataset)
            for epoch in range(EPOCHS):
                # TRAIN LOOP
                total_loss = 0.0
                num_batches = 0
                while True:
                    x = next(train_iter)
                    total_loss += distributed_train_step(x)
                    num_batches += 1
                    if num_batches >= steps:
                        break
                train_loss = total_loss / num_batches
    
                # TEST LOOP
                for x in test_dist_dataset:
                    distributed_test_step(x)
    
                # if epoch % 2 == 0:
                #     checkpoint.save(checkpoint_prefix)
    
                template = (""Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, ""
                            ""Test Accuracy: {}"")
                print (template.format(epoch+1, train_loss,
                                    train_accuracy.result()*100, test_loss.result(),
                                    test_accuracy.result()*100))
    
                test_loss.reset_states()
                train_accuracy.reset_states()
                test_accuracy.reset_states()
    
    if __name__ == ""__main__"":
        main()

  [1]: https://www.tensorflow.org/tutorials/distribute/custom_training
  [2]: https://www.tensorflow.org/tutorials/images/segmentation
"
33649,Simple custom metric caused tf.function retracing when training on multiple GPUs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): `v2.0.0-rc2-26-g64c3d38 2.0.0`
- Python version: `3.5.2`
- CUDA/cuDNN version: `9.2`
- GPU model and memory: GTX 1080 Ti

**Describe the current behavior**

Using the following custom metric (event without the commented part):

```
import tensorflow as tf

class MeanIoUIgnoreLabel(tf.keras.metrics.MeanIoU):
    """"""Mean Intersection-over-Union with an ignored label
    """"""
    def __init__(self, num_classes, ignore_label=None, name='mIoU_ignore_label', **kwargs):
      super(MeanIoUIgnoreLabel, self).__init__(num_classes, name=name, **kwargs)
      self.ignore_label = ignore_label

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_pred = tf.argmax(y_pred, axis=-1)
        # if self.ignore_label is not None:
        #     if sample_weight is not None:
        #         # sample_weight = tf.where(y_true == self.ignore_label, 0, sample_weight)
        #         sample_weight = tf.where(tf.math.equal(y_true, self.ignore_label), 0, sample_weight)
        #     else:
        #         # sample_weight = y_true != self.ignore_label
        #         sample_weight = tf.math.not_equal(y_true, self.ignore_label)
        return super(MeanIoUIgnoreLabel, self).update_state(y_true, y_pred, sample_weight)   
```

I obtained the following warning:

> 2019-10-23 22:27:58.600906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
> WARNING:tensorflow:5 out of the last 9 calls to <bound method MeanIoUIgnoreLabel.update_state of <metrics.MeanIoUIgnoreLabel object at 0x7fc0ac1f86a0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.

I am using `tf.distribute.MirroredStrategy()` to train on multiple GPUs.

I guess this is a bug?

Thanks.

"
33648,Can save but not load custom metrics with a variable named 'weights' in the tf saved model format,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7

**Describe the current behavior**
AttributeError occurs when trying to load a tf saved model using  tf.keras.models.load_model with a custom metric with a variable named 'weights'.

**Describe the expected behavior**
Either an error gets thrown during assignment or saving that you are not allowed to save a variable with the name 'weights', or no attribute error occurs and load_model loads the metric successfully.

**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.metrics import Metric
import numpy as np

class CustomMetric(Metric):
  def __init__(self,
               name='score',
               dtype=tf.float32):
    super(CustomMetric, self).__init__(name=name)
    self.true_positives = self.add_weight(
        'true_positives',
        shape=[10],
        initializer='zeros',
        dtype=self.dtype)
    self.weights_intermediate = self.add_weight(
        'weights',
        shape=[10],
        initializer='zeros',
        dtype=self.dtype)

  def update_state(self, y_true, y_pred, sample_weight=None):
    pass

  def result(self):
    return 0

  def get_config(self):
    """"""Returns the serializable config of the metric.""""""
    config = {}
    base_config = super(CustomMetric, self).get_config()
    return dict(list(base_config.items()) + list(config.items()))

  def reset_states(self):
    self.true_positives.assign(np.zeros(10), np.float32)
    self.weights_intermediate.assign(
        np.zeros(10), np.float32)
            
inputs = keras.Input(shape=(784,), name='digits')
x = layers.Dense(64, activation='relu', name='dense_1')(inputs)
x = layers.Dense(64, activation='relu', name='dense_2')(x)
outputs = layers.Dense(10, activation='softmax', name='predictions')(x)
model = keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')

model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=.001), metrics=[CustomMetric()])

model.save(""model/"", save_format='tf')

new_model = keras.models.load_model('model/', custom_objects={'score': CustomMetric})
```

**Other info / logs**
```
Traceback (most recent call last):
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 2256, in __setattr__
    super(tracking.AutoTrackable, self).__setattr__(name, value)
AttributeError: can't set attribute

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/sentim/Website/model_prediction/test_load_saved_model.py"", line 50, in <module>
    new_model = keras.models.load_model('model/', custom_objects={'score': CustomMetric})
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 150, in load_model
    return saved_model_load.load(filepath, compile)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 86, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 541, in load_internal
    export_dir)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 102, in __init__
    super(KerasObjectLoader, self).__init__(*args, **kwargs)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 121, in __init__
    self._load_all()
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 265, in _load_all
    setter(obj, reference.local_name, nodes[reference.node_id])
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 234, in _revive_setter
    setattr(self, name, value)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 2261, in __setattr__
    'different name.').format(name))
AttributeError: Can't set the attribute ""weights"", likely because it conflicts with an existing read-only @property of the object. Please choose a different name.
```

"
33646,ValueError: Unknown metric function: CustomMetric using custom metrics when loading tf saved model type with tf.keras.models.load_model ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7

**Describe the current behavior**
ValueError: Unknown metric function: CustomMetric occurs when trying to load a tf saved model using  tf.keras.models.load_model with a custom metric. If you look at the code for load_model, it is clear the load_model currently ignores the custom_objects dict for the tf saved model format.

**Describe the expected behavior**
load_model loads the custom metric successfully either just implicitly or through the custom_objects dict. 

**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.metrics import Metric
import numpy as np

class CustomMetric(Metric):
  def __init__(self,
               name='score',
               dtype=tf.float32):
    super(CustomMetric, self).__init__(name=name)
    self.true_positives = self.add_weight(
        'true_positives',
        shape=[10],
        initializer='zeros',
        dtype=self.dtype)


  def update_state(self, y_true, y_pred, sample_weight=None):
    pass

  def result(self):
    return 0

  def get_config(self):
    """"""Returns the serializable config of the metric.""""""
    config = {}
    base_config = super(CustomMetric, self).get_config()
    return dict(list(base_config.items()) + list(config.items()))

  def reset_states(self):
    self.true_positives.assign(np.zeros(self.num_classes), np.float32)
    self.weights_intermediate.assign(
        np.zeros(self.num_classes), np.float32)
            
inputs = keras.Input(shape=(784,), name='digits')
x = layers.Dense(64, activation='relu', name='dense_1')(inputs)
x = layers.Dense(64, activation='relu', name='dense_2')(x)
outputs = layers.Dense(10, activation='softmax', name='predictions')(x)
model = keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')

model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=.001), metrics=[CustomMetric()])

model.save(""model/"", save_format='tf')

new_model = keras.models.load_model('model/',  tf.keras.models.load_model ={'score': CustomMetric})
```

**Other info / logs**
```
Traceback (most recent call last):
  File ""/home/sentim/Website/model_prediction/test_load_saved_model.py"", line 46, in <module>
    new_model = keras.models.load_model('model/', custom_objects={'score': CustomMetric})
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 150, in load_model
    return saved_model_load.load(filepath, compile)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 93, in load
    model._training_config))  # pylint: disable=protected-access
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 356, in compile
    self._cache_output_metric_attributes(metrics, weighted_metrics)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1901, in _cache_output_metric_attributes
    metrics, self.output_names, output_shapes, self.loss_functions)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py"", line 813, in collect_per_output_metric_info
    metric_name = get_metric_name(metric, is_weighted)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py"", line 987, in get_metric_name
    metric = metrics_module.get(metric)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py"", line 2857, in get
    return deserialize(identifier)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py"", line 2851, in deserialize
    printable_module_name='metric function')
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py"", line 180, in deserialize_keras_object
    config, module_objects, custom_objects, printable_module_name)
  File ""/home/sentim/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py"", line 165, in class_and_config_for_serialized_keras_object
    raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)
ValueError: Unknown metric function: CustomMetric
```

"
33645,Allow device groups / CPU in MirroredStrategy,"**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

My neural network is too large to be trained on a single GPU. In this specific case I have one layer that needs a lot of memory but does not perform expensive computations.
I can train the network if I place this layer on the CPU (so that it uses main memory) or on another GPU.

But I still would like to use MirroredStrategy to distribute the training across multiple GPUs.
Currently this combination is not possible.

Therefore I would like to request a feature to place parts of the computations inside a cross-replica context on the CPU. In a more generic case MirroredStrategy could distribute computations across device groups (instead of devices) and allow the user to place operations on different devices inside the group.

This could look like follows:
```
strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
        x = f1()
    with tf.device('/cpu:0'):
        y = f2(x)
```

Or like this in the general case:
```
strategy = tf.distribute.MirroredStrategy(devices=[['/gpu:0', '/gpu:1'], ['/gpu:3', '/gpu:4']])
with strategy.scope():
    with tf.device('/vgpu:0'):
        x = f1()
    with tf.device('/vgpu:1'):
        y = f2(x)
```

**Will this change the current api? How?**
The general case (device groups) needs a way to specify which devices are inside which group. See above for an example.

**Who will benefit with this feature?**
Everyone who wants to train larger models that do not fit into the VRAM of a single GPU but who still wants to use MirroredStrategy."
33644,"update tutorial for tensorflow object detection api , generate_tf_record is giving a tough time","https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html

update generate_tf_record file according to running version in tensor flow."
33642,portable deep feed forward neural network for regression and classification with less than 100 lines of code.,"Dear All: 
 This message is just a ""ad"" to my new project at
https://github.com/wangyi-fudan/wymlp
Sorry for the trouble since I have no idea to post it elsewhere. :-)"
33641,Output names lost when loading Keras model in SavedModel format,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux-5.0.0-25-generic-x86_64-with-Ubuntu-18.04-bionic
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.4

**Describe the current behavior**
When loading a Keras model saved in the `SavedModel` format the output names are lost. Losing the output names causes loading to fail if using dictionaries for configuring loss or metrics.

**Describe the expected behavior**
Output names to be restored when loading the model and dictionaries for losses to be working when loading the model.

**Code to reproduce the issue**
`output_names` is not restored and outputs are given new auto-generated names:
```py
import tensorflow as tf

i = tf.keras.layers.Input((1,))
x = tf.keras.layers.Dense(1, name='my-output')(i)
m = tf.keras.Model(i, x)
m.compile(loss='mse')

m.save('my-saved-model')
m2 = tf.keras.models.load_model('my-saved-model')
assert m2.output_names[0] == 'my-output'  # AssertionError
```

Model fails to load when using dictionaries for losses:
```py
import tensorflow as tf

i = tf.keras.layers.Input((1,))
x = tf.keras.layers.Dense(1, name='my-output')(i)
m = tf.keras.Model(i, x)
m.compile(loss={'my-output': 'mse'})
assert m.output_names[0] == 'my-output'

m.save('my-saved-model')
m2 = tf.keras.models.load_model('my-saved-model') # ValueError: Unknown entries in loss dictionary: ['my-output']. Only expected following keys: ['output_1']
```"
33640,Feature_column  to surport  weighted_categorical_column  in sequence;  and   sequence or normal categorical_column in shared_embeddings.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
for example:

weighted_categorical_column  in sequence:

```python
import tensorflow as tf
from tensorflow.python.feature_column.feature_column_v2 import SequenceCategoricalColumn

batch_tensor_dict = {'dog': [[-1,-1],[1,1],[2,-1],[0,1]],
                     'dog_weight': [[0.0,0.0],[1.0,2.0],[3.0,0.0],[4.0,5.0]]
                     }

fc_cat_dog = tf.feature_column.categorical_column_with_identity(key='dog',num_buckets=3)
fc_wei_dog = tf.feature_column.weighted_categorical_column(fc_cat_dog, 'dog_weight')

seq_dog = SequenceCategoricalColumn(fc_wei_dog)
seq_dog2 = tf.feature_column.sequence_categorical_column_with_identity('dog', 3)

ind_dog = tf.feature_column.indicator_column(seq_dog)
input_layer = tf.keras.experimental.SequenceFeatures([ind_dog])
seq_input, seq_len = input_layer(batch_tensor_dict)
seq_len_mask = tf.sequence_mask(seq_len)

print(seq_input)
pass
```


sequence or normal categorical_column in shared_embeddings: 
```python
import tensorflow as tf
import tensorflow.feature_column as fc


batch_tensor_dict = {'item_id': [-1,1,2,0],
                     'history_item_id_list': [[-1,-1],[1,1],[2,-1],[0,1]]
                     }

fc_cat_item_id = fc.categorical_column_with_identity('item_id', 3)
fc_seq_cat_history_item_id_list = fc.sequence_categorical_column_with_identity('history_item_id_list', 3)

fc_shared_emb_cols = fc.shared_embeddings(categorical_columns=[fc_cat_item_id, fc_seq_cat_history_item_id_list])
```
tf.keras.experimental.SequenceFeatures and tf.keras.layers.DenseFeatures  both are not suitable for fc_shared_emb_cols.



**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
33639,tf.io.write_file truncates the file everytime,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
tf.io.write_file is not able to append to the file. I have a scenario where I want to write the output of the network (text generation) to a file. However I use sharded execution of tf.function which writes to different files (suffixed by the shard range) so that I can handle the total billion range. This is not possible through current available API

**Will this change the current api? How?** A parameter to tf.io.write_file to append to the file.

**Who will benefit with this feature?** All users

**Any Other info.**
"
33637,TFLite C++ example for Raspberry Pi,"Having followed this guide: https://www.tensorflow.org/lite/guide/build_rpi I end up with a static library called `libtensorflow-lite.a`. 

There doesn't seem to be any instruction, documentation or examples available on how to actually use this for C++ on ARM. Some says to have a look at the `minimal.cc` example, but this does not include the static library nor does it include any compile instruction for ARM.

Can someone provide a working example?"
33636,MultiLabel Metric Support,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.15+ 
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

# Issue
In my comments on [issue](https://github.com/tensorflow/tensorflow/issues/28074) #28074 I outline that although it was suggested multi-label metric support exists, it does not. The reasons stands as

1. The utility function `update_confusion_matrix_variables` is called without a user-exposed option resulting in the default argument `multi_label=False` to be used.

2. `tf.keras.metrics.Metric` generally take in `y_pred` and `y_true`. Multi-label classification might use a loss like `tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)`, which applies a sigmoid during the loss calculation. This suggests that the user should not have the output (logits) of their model undergo a sigmoid transformation, as the loss would then be calculated using `sigmoid(sigmoid(...))`.  While a putative solution to is to make a multi-tailed model (one with and one without the sigmoid transformation), a collective guide on these more nuanced use cases does not exist.

pseudo-code of the solution

```python

inputs = ...
y = tf.keras.layer.SomeLayer(...)(inputs)
y = tf.keras.layer.SomeLayer(...)(y)
output = tf.sigmoid(y)


model = tf.keras.Model(inputs=inputs, outputs={
    'logits': output,
    'raw_out_for_loss': y
})

model.compile(
    ...
    metrics={
        'logits': [MultiLabelMetric(...), ...], 
        'raw_out_for_loss': [],
    }
```

This issue does not arise in the [image segmentation guide](https://www.tensorflow.org/tutorials/images/segmentation#define_the_model) as the labels are no independent, so `sparse_categorical_crossentropy` loss is used. As reflected in the corresponding [`tf.keras.losses.SparseCategoricalCrossentropy` documentation](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy), while multiple labels exists, the input is expect to confirm to a single label.

Mini-rant aside, even if a user does use a multi-tail model to address this, it does not get around that the current `tf.keras.metrics` do not expose the `multi_label` option, despite it existing in the underlying utility code.

# Feature

At bare minimum expose `multi_label` option to relevant metrics (e.g. `Precision`). 

It would also be nice if a transformation could be applied to the automatically feed in `y_pred` (e.g. sigmoid transformation), so that a multi-tailed model is not required. This might be done with an optional `transformation` argument which will accept a label.

## other option
move multilabel metrics to separate classes, e.g. 

```python
class MultiLabelMacroSpecificity(tf.keras.metrics.Metric):
    
    def __init__(self, name='multi_label_macro_specificity', threshold=0.5, **kwargs):        
        super(MultiLabelMacroSpecificity, self).__init__(name=name, **kwargs)
        self.specificity = self.add_weight(name='mlm_spec', initializer='zeros')        
        self.threshold       = tf.constant(threshold)

        # replace this with tf confusion_matrix utils
        self.true_negatives  = self.add_weight(name='tn', initializer='zeros')
        self.false_positives = self.add_weight(name='fp', initializer='zeros')
    
    def update_state(self, y_true, y_pred):
        
        # Compare predictions and threshold.        
        pred_is_pos  = tf.greater(tf.cast(y_pred, tf.float32), self.threshold)            
        pred_is_neg  = tf.logical_not(tf.cast(pred_is_pos, tf.bool))
        # |-- in case of soft labeling        
        label_is_pos = tf.greater(tf.cast(y_true, tf.float32), self.threshold)                
        label_is_neg = tf.logical_not(tf.cast(label_is_pos, tf.bool))
        
        self.true_negatives.assign_add(tf.reduce_sum(tf.cast(tf.logical_and(pred_is_neg, label_is_neg), tf.float32)))
        self.false_positives.assign_add(
            tf.reduce_sum(tf.cast(tf.logical_and(pred_is_pos, label_is_neg), tf.float32))
        )
        
        tn = self.true_negatives
        fp = self.false_positives
        specificity = tf.div_no_nan(tn, tf.add(tn, fp))
        self.specificity.assign(specificity)
        return specificity
    
    def result(self):
        return self.specificity        

```


**Will this change the current api? How?**
Yes, but barely.  Expose at least `multi_label` on relevant metrics and maybe add / expose a `transformation` argument.



**Who will benefit with this feature?**
If bare minimum is done, those requiring multi-label metrics but do not which to write their own function / subclass `tf.keras.metric.Metric`.

If `transformation` is also added to all metrics, then anyone using tf metrics could make existing metrics work with minimum overhead instead of redesigning their model to meet metric requirements.

**Any Other info.**


"
33635,Adding regularization losses to models after they are built does not show up in model.losses,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- TensorFlow version (use command below): 2.0
- Python version: 3.6

**Describe the current behavior**
For a prebuilt model, for example, keras_applications models and other models if they are already built, manually adding regularization to layers does not show up in model.losses

**Code to reproduce the issue**
```
import tensorflow as tf
import numpy as np
print('TensorFlow', tf.__version__)

'''
Case 1: Simple model without any regularization
'''
input_layer = tf.keras.Input(shape=[10])
x = tf.keras.layers.Dense(units=16, activation='relu')(input_layer)
x = tf.keras.layers.Dense(units=16, activation='relu')(x)
output_layer = tf.keras.layers.Dense(units=4, activation=None)(x)
model_a = tf.keras.Model(inputs=[input_layer], outputs=[output_layer])

assert model_a.losses == []


'''
Case 2: Simple model with regularization added
        during layer creation
'''
input_layer = tf.keras.Input(shape=[10])
x = tf.keras.layers.Dense(units=16, activation='relu',
                          kernel_regularizer=tf.keras.regularizers.l2(l=1e-5))(input_layer)
x = tf.keras.layers.Dense(units=16, activation='relu', 
                          kernel_regularizer=tf.keras.regularizers.l2(l=1e-5))(x)
output_layer = tf.keras.layers.Dense(units=4, activation=None, 
                                     kernel_regularizer=tf.keras.regularizers.l2(l=1e-5))(x)
model_b = tf.keras.Model(inputs=[input_layer], outputs=[output_layer])

assert model_b.losses != []


'''
Case 3: For a prebuilt model, for example, keras_applications models
        and other models if they are already built, manually adding regularization
        to layers does not show up in model.losses
'''
input_layer = tf.keras.Input(shape=[10])
x = tf.keras.layers.Dense(units=16, activation='relu')(input_layer)
x = tf.keras.layers.Dense(units=16, activation='relu')(x)
output_layer = tf.keras.layers.Dense(units=4, activation=None)(x)
model_c = tf.keras.Model(inputs=[input_layer], outputs=[output_layer])

for layer in model_c.layers:
    if hasattr(layer, 'kernel_regularizer'):
        setattr(layer, 'kernel_regularizer', tf.keras.regularizers.l2(l=1e-5))
        
for layer in model_c.layers:
    if hasattr(layer, 'kernel_regularizer'):
        assert getattr(layer, 'kernel_regularizer').l2 == np.array([1e-5], dtype='float32')
        
assert model_c.losses == []
```"
33634,Tensorflow lite dll build failed on Windows,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home
- TensorFlow installed from (source or binary): source (master)
- TensorFlow version: 2.0 (master)
- Python version: 3.8.0
- Installed using virtualenv? pip? conda?: VirtualBoxVM
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): Visual Studio Build Tools 201

**Describe the problem**

I have a code base successfully running on Linux/MacOS/Android & iOS.

Now I need to run tflite model inference under Windows system.
For this, I need to compile a tensorflowlite dll for Windows (I've not found any precompiled version)

Unfortunately, the build fails at the link step... (see logs below).

Apparently, even if the build fails, a libtensorflowlite.so file is stil generated (and is indeed a dll), but it contains no exported symbols, so I cannot use it.
After checking at the tensorflow/lite/BUILD file it appears that no .def file is generated for the tflite Windows link step, as it is done for tensorflow.dll (seen in tensorflow/BUILD), which explains why no symbols are exported.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

In Windows command prompt (Run as Administrator):

python configure.py
bazel build -s tensorflow/lite:libtensorflowlite.so

**Any other info / logs**

C:\Users\soule\Downloads\tensorflow> bazel build -s tensorflow/lite:libtensorflowlite.so
[...]
  C:/Program Files (x86)/Microsoft Visual Studio/2019/BuildTools/VC/Tools/MSVC/14.23.28105/bin/HostX64/x64/link.exe /nologo /DLL /SUBSYSTEM:CONSOLE -s -ignore:4221 -ignore:4221 -ignore:4221 -ignore:4221 /MACHINE:X64 @bazel-out/x64_windows-opt/bin/tensorflow/lite/libtensorflowlite.so-2.params /OPT:ICF /OPT:REF
INFO: From Linking tensorflow/lite/libtensorflowlite.so:
LINK : warning LNK4044: unrecognized option '/s'; ignored
ERROR: C:/users/soule/downloads/tensorflow/tensorflow/lite/BUILD:442:1: output 'tensorflow/lite/libtensorflowlite.so.if.lib' was not created
ERROR: C:/users/soule/downloads/tensorflow/tensorflow/lite/BUILD:442:1: not all outputs were created or valid
Target //tensorflow/lite:libtensorflowlite.so failed to build
INFO: Elapsed time: 920.482s, Critical Path: 84.10s
INFO: 235 processes: 235 local.
FAILED: Build did NOT complete successfully

C:\Users\soule\Downloads\tensorflow> dumpbin /exports bazel-out\x64_windows-opt\bin\tensorflow\lite\libtensorflowlite.so
Microsoft (R) COFF/PE Dumper Version 14.23.28106.4
Copyright (C) Microsoft Corporation.  All rights reserved.


Dump of file bazel-out\x64_windows-opt\bin\tensorflow\lite\libtensorflowlite.so

File Type: DLL

  Summary

        1000 .data
        1000 .pdata
        1000 .rdata
        1000 .reloc
        2000 .text
        1000 _RDATA
"
33633,Build Tensorflow with Bazel not working,"I would like build tensorflow with Bazel to use the compiled libary in c++. I run the following commands in cmd.
```
C:\Users\Furkan\Desktop\tensorflow-1.14.0>bazel build --config=opt
WARNING: Usage: bazel build <options> <targets>.
Invoke `bazel help build` for full description of usage and options.
Your request is correct, but requested an empty set of targets. Nothing will be built.
INFO: Build option --define has changed, discarding analysis cache.
INFO: Analyzed 0 targets (0 packages loaded, 0 targets configured).
INFO: Found 0 targets...
INFO: Elapsed time: 0.124s, Critical Path: 0.01s
INFO: 0 processes.
INFO: Build completed successfully, 1 total action
```
After that they create the folders in tensorflow, but the folders are empty.. What I do wrong??

bazel: 0.25.2
tensorflow: 1.14.0"
33631,tf.data.Dataset.from_tensor_slices creates infinite loop in https://www.tensorflow.org/tutorials/load_data/pandas_dataframe ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- TensorFlow tutorial 
- TensorFlow installed from: Source
- TensorFlow version: 1.14
- Python version: 3.7.3

**Describe the current behaviour**

Attempting to create a batched dataset to train an RNN-LSTM using the logic from the [TensorFlow Time Series Forecasting tutorial ](https://www.tensorflow.org/tutorials/structured_data/time_series) and the [load Pandas.DataFrame logic](https://www.tensorflow.org/tutorials/load_data/pandas_dataframe).

When I execute these lines on my Pandas Dataframe of shape (1661, 5):

```
dataset = tf.data.Dataset.from_tensor_slices((df.values, target.values))
for feat, targ in dataset.take(5):
  print ('Features: {}, Target: {}'.format(feat, targ))

```
The loop runs as an infinite loop and does not produce the same out as that in the tutorial. The only difference with my dataframe is that it has a DateTimeIndex.

The output 
**Describe the expected behaviour**

I would expect a batch of size 5 as per dataset.take(5) in the format below:

Features: [ 63.    1.    1.  145.  233.    1.    2.  150.    0.    2.3   3.    0.
   2. ], Target: 0


**Code to reproduce the issue**
`df.head(10)`

Out:[1]
	index	col_1         col_2        col_3       col_4        col_5
2016-10-03	0.017647	0.000000	0.048040	0.334455	0.132643
2016-10-04	0.017647	0.000925	0.047372	0.334455	0.174480
2016-10-05	0.017647	0.001849	0.046696	0.334455	0.142559
2016-10-06	0.017647	0.002774	0.046011	0.334455	0.148387
2016-10-07	0.017647	0.003699	0.045317	0.334455	0.142472
2016-10-10	0.017647	0.004624	0.044615	0.333301	0.129686
2016-10-11	0.017647	0.005548	0.043905	0.331875	0.120031
2016-10-12	0.017647	0.006473	0.043185	0.324570	0.120031
2016-10-13	0.017647	0.007398	0.042458	0.324327	0.105506
2016-10-14	0.017647	0.008323	0.041721	0.341778	0.129425

`
target = final_df.pop('col_1')
dataset = tf.data.Dataset.from_tensor_slices((final_df.values, final_df.values))
for feat, targ in dataset.take(5):
  print ('Features: {}, Target: {}'.format(feat, targ))
`
Out[2]:

Features: Tensor(""IteratorGetNext:0"", shape=(4,), dtype=float64), Target: Tensor(""IteratorGetNext:1"", shape=(4,), dtype=float64)
Features: Tensor(""IteratorGetNext_1:0"", shape=(4,), dtype=float64), Target: Tensor(""IteratorGetNext_1:1"", shape=(4,), dtype=float64)
target: Tensor(""IteratorGetNext_9:1"", shape=(4,), dtype=float64)

Output in an infinite loop.
"
33630,MKL is not enabled after building from source,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.15
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): 7.4.0

**Describe the problem**
MKL is not enabled after building from source with -config=mkl. I have checked with the function tensorflow.pywrap_tensorflow.IsMklEnabled(). It returns ""False"".
**Provide the exact sequence of commands / steps that you executed before running into the problem**
I followed the installation guide on https://www.tensorflow.org/install/source. I build with:
`bazel build -c opt --copt=-march=native --copt=-mfpmath=both --config=mkl //tensorflow/tools/pip_package:build_pip_package`

How can I build correct with mkl enabled. Thank you in advance"
33629,Is it possible to provide a demo of the uvccamera object detection in android by tensorflow lite ? ,"this demo ""https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android""
is android camera , i  need to use in uvccamera in android to detection object , i copy code to my uvccamera in android project , it is not detection right , so Is it possible to provide a demo of the uvccamera object detection in android by tensorflow lite ? "
33627,TF 1.14 Python CPU single thread configuration,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution**: Ubuntu 18.04
- **TensorFlow installed from**: pip2 install intel-tensorflow==1.14.0
- **TensorFlow version (use command below)**: 1.14
- **Python version**: 2.7

### Describe the problem
I'm going to participate in submissions limited to use CPU single thread. My implementation is in Python and I found that when construct tf.Session, a threadpool is created. However, I can't set it to single threaded even with the following suggested configuration:
```python
sess = tf.Session(config=tf.ConfigProto(
    intra_op_parallelism_threads=1,
    inter_op_parallelism_threads=1,
    device_count = {'CPU': 1}
))
```
How can I reach single threaded?  
Thank you !!

"
33626,tf-lite 2.0 python,I'd like to have TensorFlow-lite python module. So is it and how to build from source?
33624,TF Inverse operations fail on 2080ti GPU with a cublas error,"I'm trying to use a loss function which needs an inverse op, but fails on tf 2.0 with the following error:

![image](https://user-images.githubusercontent.com/1873401/67357639-c08a0d00-f512-11e9-960b-ed54e7378ebc.png)

Other models/loss functions that don't use inverse ops train as expected using the GPU. Any pointers would be most appreciated."
33623,tf.strings.split bug,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.15.0
- Python version:3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'to_sparse'
**Describe the expected behavior**
The op should return SparseTensor or RaggedTensor
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python
import tensorflow as tf
tf.strings.split('a b')
```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

[colab](https://colab.research.google.com/drive/1PrFuL7hC25yRGmFfbwwRK1if9N8d1M9A)"
33622,Pack() used in mixed precision ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): 1.13
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10
- GPU model and memory: Tesla-V100-SXM2

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I want to use the clip_by_global_norm, but it does not work when the variables are mixed precision: float32 and float16 because it used Pack() function somewhere. 
If I cast all the vars into float16 or float32,  it brings up other problems like 'can not add float32 with float16' in other operations.

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33621,"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ABS, ADD, BATCH_TO_SPACE_ND, CAST, CONCATENATION, CONV_2D, EXPAND_DIMS, GREATER, LESS, LOGICAL_AND, LOGICAL_NOT, MAXIMUM, MAX_POOL_2D, MINIMUM, MUL, NEG, PACK, PAD, RELU, RESHAPE, RSQRT, SELECT, SOFTMAX, SPACE_TO_BATCH_ND, SQUARE, STRIDED_SLICE, SUB, SUM, TOPK_V2. Here is a list of operators for which you will need custom implementations: FIFOQueueV2, QueueDequeueV2, SparseSoftmaxCrossEntropyWithLogits.","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33619,Unable to execute python program  with Keras / Tensorflow ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
PC
- TensorFlow installed from (source or binary):
Keras                2.3.1
Keras-Applications   1.0.8
Keras-Preprocessing  1.1.0
tensorboard          2.0.0
tensorflow           2.0.0
tensorflow-estimator 2.0.1
Installed Python version from pip within Visual Studio
- TensorFlow version:  above
- Python version:   3.7.4 64-bit
- Installed using virtualenv? pip? conda?:   installed via pip
- Bazel version (if compiling from source):    n/a
- GCC/Compiler version (if compiling from source):  n/a
- CUDA/cuDNN version:   do not have Cuda installed, want to run this on the CPU as my GPA is a Nvid GTS-250
- GPU model and memory:
Nvid GTS-250 @ 2 cards
CPU is an i7 Intel 930 @ 2.8GHz, Quad Core
System has 12G of RAM

**Describe the problem**
I am able to import keras and numpy into my python program, however when I attempt to run the program I see the following error...

H:\Python\Projects\Machine_Learning>C:/Users/Userid/AppData/Local/Programs/Python/Python37/python.exe ""h:/Python/Projects/Machine_Learning/44 - first_deep_learning_example.py""
Using TensorFlow backend.
Traceback (most recent call last):
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed with error code 3221225501

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""h:/Python/Projects/Machine_Learning/44 - first_deep_learning_example.py"", line 2, in <module>
    from keras.models import Sequential
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\__init__.py"", line 1, in <module>
    from .load_backend import epsilon
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\load_backend.py"", line 90, in <module>
    from .tensorflow_backend import *
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Userid\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed with error code 3221225501

Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors




**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33618,massive c++14 warning during build,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 1903 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0.0
- Python version: 3.7.4 x64
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source):   VS 2017 build tools
- CUDA/cuDNN version: 10.1 / 7.6.4
- GPU model and memory: RTX 2080Ti GDDR6 11GB



**Describe the problem**
massive unknown option warning from compiler

the option '-std=c++14' should not be used

**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel build //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
cl : Command line warning D9002 : ignoring unknown option '-std=c++14'
```
"
33616,TFLiteConverter StridedSlice Error for Transformer Example Notebook,"**System information**
- Linux Ubuntu 18.04.2
- Installed from binary
- TensorFlow version 2.0.0

**Provide the text output from tflite_convert**

```
---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-82-0b556551beac> in <module>()
      3 
      4 converter = tf.lite.TFLiteConverter.from_concrete_functions([to_save])
----> 5 tflite_model = converter.convert()

~/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py in convert(self)
    444         input_tensors=input_tensors,
    445         output_tensors=output_tensors,
--> 446         **converter_kwargs)
    447 
    448     if self._is_calibration_quantize():

~/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    447       input_data.SerializeToString(),
    448       debug_info_str=debug_info_str,
--> 449       enable_mlir_converter=enable_mlir_converter)
    450   return data
    451 

~/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    198       stdout = _try_convert_to_unicode(stdout)
    199       stderr = _try_convert_to_unicode(stderr)
--> 200       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    201   finally:
    202     # Must manually cleanup files.

ConverterError: See console for info.
2019-10-22 12:59:50.304931: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 915 operators, 1487 arrays (0 quantized)
2019-10-22 12:59:50.337611: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 915 operators, 1487 arrays (0 quantized)
2019-10-22 12:59:50.397450: F tensorflow/lite/toco/graph_transformations/resolve_strided_slice_attributes.cc:95] Check failed: start_indices_size <= num_input_axes (4 vs. 2)StridedSlice op requires no more than 2 start indices
Fatal Python error: Aborted

Current thread 0x00007f2d4bb1e740 (most recent call first):
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52 in execute
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/absl/app.py"", line 251 in _run_main
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/absl/app.py"", line 300 in run
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40 in run
  File ""/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89 in main
  File ""/home/mattc/anaconda3/envs/main/bin/toco_from_protos"", line 10 in <module>
Aborted (core dumped)
```

**Any other info / logs**

I am following this notebook: https://www.tensorflow.org/tutorials/text/transformer
I am interested in doing NMT on an Android device with TFLite. The NMT Attention notebook uses an LSTM which is not supported yet for TF Lite conversion so I am looking into this approach that only uses Attention, Embeddings, and Dense layers in hope that it is convertible. 

I haven't edited the code from that notebook at all, but created a new inference concrete function and am trying to convert it. I am getting this vague error about the StridedSlice op.

Looking for some guidance on what I can do from here.

```python
tf.random.set_seed(1234)

eval_step_signature = [
    tf.TensorSpec(shape=(BATCH_SIZE, 64), dtype=tf.int64),
    tf.TensorSpec(shape=(BATCH_SIZE, 26), dtype=tf.int64),
]

@tf.function(input_signature=eval_step_signature)
def eval_step(inp, tar):

    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar)
    
    predictions, _ = transformer(inp, tar, 
                                 True, 
                                 enc_padding_mask, 
                                 combined_mask, 
                                 dec_padding_mask)
    return predictions

ckpt.f = eval_step
to_save = ckpt.f.get_concrete_function()

converter = tf.lite.TFLiteConverter.from_concrete_functions([to_save])
tflite_model = converter.convert()
```

Thank you!"
33615,Include path problem when compiling TensorFlow from source using compiler in non-standard system location.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.6
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0 master
- Python version: 3.6
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: 10.1.1 / 7.5
- GPU model and memory: V100 (32 GB)

**Describe the problem**
There is a major issue in installing TensorFlow when using compiler(s) in non-standard system locations. There is no provided tutorial or documentation on how to configure bazel and tensorflow in order to compile TensorFlow using different compilers.

In my case,  I have been struggling to compile TensorFlow from source using gcc/8.3.0 which is installed in a non-standard systm locations. I invoke this compiler by using 
`module load gcc/8.3.0`
All the include and library paths to this compiler are set properly as I use it for compiling many other programs. For clarity I display the configuration of this compiler below 

```
(tensorflow2.0-master) -bash-4.2$ module show gcc/8.3.0/gcc-4.8.5 
-------------------------------------------------------------------
/gpfslocalsup/pub/modules-idris/modulefiles/linux-rhel7-x86_64/gcc/8.3.0/gcc-4.8.5:

module-whatis	 The GNU Compiler Collection includes front ends for C, C++, Objective-C, Fortran, Ada, and Go, as well as libraries for these languages. 
conflict	 gcc 
prepend-path	 PATH /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/bin 
prepend-path	 MANPATH /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/share/man 
prepend-path	 LD_LIBRARY_PATH /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/lib 
prepend-path	 LIBRARY_PATH /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/lib 
prepend-path	 LD_LIBRARY_PATH /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/lib64 
prepend-path	 LIBRARY_PATH /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/lib64 
prepend-path	 CPATH /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/include 
prepend-path	 CMAKE_PREFIX_PATH /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/ 
setenv		 CC /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/bin/gcc 
setenv		 CXX /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/bin/g++ 
setenv		 FC /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/bin/gfortran 
setenv		 F77 /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/bin/gfortran 
setenv		 F90 /gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/bin/gfortran 
-------------------------------------------------------------------
```
I compile bazel-0.29.1 after modifying ` tools/cpp/cc_toolchain_config.bzl` to set the hardcoded path to `gcc`, `cpp`, `ar` and `nm`. I also add the include directories to `cxx_builtin_include_directories` in the file. 

I compile TensorFlow using the following command : 

`CC=/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/bin/gcc bazel --output_user_root=/tmp/ujjwal-builds build --action_env=PATH --action_env=LD_LIBRARY_PATH --config=opt --config=cuda --config=mkl --config=numa //tensorflow/tools/pip_package:build_pip_package --verbose_failures`

And then I get an error as shown below : 
```
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
ERROR: /tmp/ujjwal-builds/7d993f307acf01aa765c32a6dcabd368/external/com_google_absl/absl/strings/BUILD.bazel:83:1: undeclared inclusion(s) in rule '@com_google_absl//absl/strings:internal':
this rule is missing dependency declarations for the following files included by 'external/com_google_absl/absl/strings/internal/utf8.cc':
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/include/c++/8.3.0/cstddef'
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/include/c++/8.3.0/x86_64-pc-linux-gnu/bits/c++config.h'
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/include/c++/8.3.0/x86_64-pc-linux-gnu/bits/os_defines.h'
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/include/c++/8.3.0/x86_64-pc-linux-gnu/bits/cpu_defines.h'
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/lib/gcc/x86_64-pc-linux-gnu/8.3.0/include/stddef.h'
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/include/c++/8.3.0/cstdint'
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/lib/gcc/x86_64-pc-linux-gnu/8.3.0/include/stdint.h'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: /tmp/ujjwal/tensorflow/tensorflow/tools/pip_package/BUILD:49:1 undeclared inclusion(s) in rule '@com_google_absl//absl/strings:internal':
this rule is missing dependency declarations for the following files included by 'external/com_google_absl/absl/strings/internal/utf8.cc':
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/include/c++/8.3.0/cstddef'
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/include/c++/8.3.0/x86_64-pc-linux-gnu/bits/c++config.h'
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/include/c++/8.3.0/x86_64-pc-linux-gnu/bits/os_defines.h'
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/include/c++/8.3.0/x86_64-pc-linux-gnu/bits/cpu_defines.h'
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/lib/gcc/x86_64-pc-linux-gnu/8.3.0/include/stddef.h'
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/include/c++/8.3.0/cstdint'
  '/gpfslocalsup/spack_soft/gcc/8.3.0/gcc-4.8.5-opnwtdjumg2hxo4ljvnx77ugb6afmvj3/lib/gcc/x86_64-pc-linux-gnu/8.3.0/include/stdint.h'
INFO: Elapsed time: 0.745s, Critical Path: 0.26s
INFO: 4 processes: 4 local.
FAILED: Build did NOT complete successfully
```
Bazel is being updated too frequently and there is no documentation or explanation on how to configure it to compile TensorFlow using other compilers. 

This should be addressed for the benefits of users.
"
33614,[TF-Nighly] Keras object serialization breaks for certain object names,"## System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, but seq2seq maintained by Google
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: All
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: tf-nightly > 20191018

### Describe the problem
Since b22fd65247633edfbc000c3bd9b9008502aedc33 serialization breaks if the name attribute of an object matches the name of a keras registered object. The check added compares `key,items` in a config and checks if the `item` matches the name of a registered object. This is brittle because `{'name': 'ObjectNameAttribute'}` appears in that config. Below I've attached a way to break the test case. 

This breaks all Attention mechanism serializations from seq2seq. E.g:
https://github.com/tensorflow/addons/blob/master/tensorflow_addons/seq2seq/attention_wrapper.py#L687
https://github.com/tensorflow/addons/blob/master/tensorflow_addons/seq2seq/attention_wrapper_test.py#L155

But also our activation layers who's default name matches the registered activation name:
https://github.com/tensorflow/addons/blob/master/tensorflow_addons/layers/sparsemax.py#L27
https://github.com/tensorflow/addons/blob/master/tensorflow_addons/activations/sparsemax.py#L27

I believe adding a check that `key` != `name` would fix this, but haven't thought through all of the implications.

### Source code / logs
Modified test case that breaks. Notice the `name` of Dense Layer matches a `custom_object` and thus breaks. 

```
import tensorflow as tf
import tensorflow.keras as keras


class SerDeTest(tf.test.TestCase):
    def test_nested_serializable_fn(self):
        def serializable_fn(x):
            """"""A serializable function to pass out of a test layer's config.""""""
            return x

        class SerializableNestedInt(int):
            """"""A serializable object containing a serializable function.""""""

            def __new__(cls, value, fn):
                obj = int.__new__(cls, value)
                obj.fn = fn
                return obj

            def get_config(self):
                return {'value': int(self), 'fn': self.fn}

            @classmethod
            def from_config(cls, config):
                return cls(**config)

        layer = keras.layers.Dense(
            SerializableNestedInt(3, serializable_fn),
            name='SerializableNestedInt',
            activation='relu',
            kernel_initializer='ones',
            bias_regularizer='l2')
        config = keras.layers.serialize(layer)
        new_layer = keras.layers.deserialize(
            config,
            custom_objects={
                'serializable_fn': serializable_fn,
                'SerializableNestedInt': SerializableNestedInt
            })
        self.assertEqual(new_layer.activation, keras.activations.relu)
        self.assertIsInstance(new_layer.bias_regularizer, keras.regularizers.L1L2)
        self.assertIsInstance(new_layer.units, SerializableNestedInt)
        self.assertEqual(new_layer.units, 3)
        self.assertIs(new_layer.units.fn, serializable_fn)


if __name__ == ""__main__"":
    tf.test.main()
```

`TypeError: __new__() missing 2 required positional arguments: 'value' and 'fn'`

cc @qlzh727 as owner for the seq2seq code that is breaking.
"
33613,"[TFLite, Bug] Unexpected weights changes after conversion","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): VERSION=2.0.0, GIT_VERSION=v1.12.1-15611-g025365a736
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): GCC 8.3.0
- CUDA/cuDNN version: CUDA Version: 10.1
- GPU model and memory: GeForce GTX 1080 Titan 11GB

**Describe the current behavior**
In this issue code from tensorflow/models is used (tensorflow/models/official/nlp/bert_modeling.py). After conversion weights of model seriously changes. After some minimal fixes in source code of tensorflow/models it is solved but program mustn't changes. Below I show some cases. Code of keras layer EmbeddingPostprocessor:
```
def call(self, inputs):
    """"""Implements call() for the layer.""""""
    unpacked_inputs = tf_utils.unpack_inputs(inputs)
    word_embeddings = unpacked_inputs[0]
    token_type_ids = unpacked_inputs[1]
    input_shape = tf_utils.get_shape_list(word_embeddings, expected_rank=3)
    batch_size = input_shape[0]
    seq_length = input_shape[1]
    width = input_shape[2]

    output = word_embeddings
    if self.use_type_embeddings:
      flat_token_type_ids = tf.reshape(token_type_ids, [-1])
      one_hot_ids = tf.one_hot(
          flat_token_type_ids,
          depth=self.token_type_vocab_size,
          dtype=self.dtype)
      token_type_embeddings = tf.matmul(one_hot_ids, self.type_embeddings)
      token_type_embeddings = tf.reshape(token_type_embeddings,
                                         [batch_size, seq_length, width])
      output += token_type_embeddings

    if self.use_position_embeddings:
      position_embeddings = tf.expand_dims(
          tf.slice(self.position_embeddings, [0, 0], [seq_length, width]),
          axis=0)

      output += position_embeddings

    output = self.output_layer_norm(output)
    output = self.output_dropout(output)

    return output
```

1) Without changes in source code. Weights are incorrect.
2) Fixes are shown under this point. In this case weights are correct.
```
if self.use_type_embeddings:
      flat_token_type_ids = tf.reshape(token_type_ids, [-1])
      token_type_embeddings = tf.gather(self.type_embeddings, flat_token_type_embeddings)
      token_type_embeddings = tf.reshape(token_type_embeddings,
                                         [batch_size, seq_length, width])
      output += token_type_embeddings
```
3) Use EmbeddingPostprocessor without position_embeddings. In this case weights are correct. Example with full code is in the part ""Code to reproduce the issue""
```
outputs = EmbeddingPostprocessor(
    use_type_embeddings=True,
    token_type_vocab_size=2,
    use_position_embeddings=False,
    dtype=tf.float32)(input1, input2)
```

**Code to reproduce the issue**
```
import tensorflow as tf
import numpy as np

from official.nlp.bert_modeling import EmbeddingPostprocessor

size = 100

input1 = tf.keras.layers.Input(shape=(size, size), dtype=tf.float32, name='1')
input2 = tf.keras.layers.Input(shape=(size,), dtype=tf.int32, name='2')
outputs = EmbeddingPostprocessor(
    use_type_embeddings=True,
    token_type_vocab_size=2,
    dtype=tf.float32)(input1, input2)
model = tf.keras.Model(inputs=[input1, input2], outputs=outputs)

example1 = tf.constant(np.random.random_sample(size=(1, size, size)), dtype=tf.float32)
example2 = tf.constant(np.random.randint(2, size=(1, size), dtype=np.int32))
example = {'1': example1, '2': example2}

output1 = model.predict(example)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.reset_all_variables()
interpreter.set_tensor(input_details[0]['index'], example[input_details[0]['name']])
interpreter.set_tensor(input_details[1]['index'], example[input_details[1]['name']])
interpreter.invoke()

output2 = interpreter.get_tensor(output_details[0]['index'])

print(np.sum(np.abs(output1 - output2)))
```

**Other info / logs**
* With error:
```
*** INFO MESSAGES ***
691.0672
```
* Without error:
```
*** INFO MESSAGES ***
0.0021286607
```"
33611,An error occurred in build  quantized model to lite ,"tensorflow 1.14.0

when I build quantized SSD MobileNetV2 model, haapen error.  reference documentation: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md
```
bazel run -c opt tensorflow/lite/toco:toco -- \
--input_file=/home/zengpr/lite/model/tflite_graph.pb \
--output_file=/home/zengpr/lite/model/ssd_mobilenet_v2.tflite \
--input_shapes=1,300,300,3 \
--input_arrays=normalized_input_image_tensor \
--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \
--inference_type=QUANTIZED_UINT8 \
--mean_values=128 \
--std_values=128 \
--change_concat_input_ranges=false \
--allow_custom_ops
```

```
Array FeatureExtractor/MobilenetV2/Conv/Relu6, which is an input to the DepthwiseConv operator 
producing the output array FeatureExtractor/MobilenetV2/expanded_conv/depthwise/Relu6, is 
lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-
quantized output format, or run quantized training with your model from a floating point checkpoint
 to change the input graph to contain min/max information. If you don't care about accuracy, you can 
pass --default_ranges_min= and --default_ranges_max= for easy experimentation.
```


But I used  --default_ranges_min= and --default_ranges_max= ,   model canit detection in predict.
```
bazel run -c opt tensorflow/lite/toco:toco -- \
--input_file=/home/zengpr/lite/model/tflite_graph.pb \
--output_file=/home/zengpr/lite/model/ssd_mobilenet_v2.tflite \
--input_shapes=1,300,300,3 \
--input_arrays=normalized_input_image_tensor \
--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \
--inference_type=QUANTIZED_UINT8 \
--mean_values=128 \
--std_values=128 \
--change_concat_input_ranges=false \
--default_ranges_min=0 \
--default_ranges_max=6 \
--allow_custom_ops
```"
33609,"Arduino compilation fail : error: macro ""max"" requires 2 arguments, but only 1 given  max(0.0f),","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arduino Nano 33 IOT

**Describe the problem**

There is a compilation issue :
Documents/Arduino/libraries/Arduino_TensorFlowLite/src/tensorflow/lite/schema/schema_generated.h:6761:17: error: macro ""max"" requires 2 arguments, but only 1 given
         max(0.0f),

Documents/Arduino/libraries/Arduino_TensorFlowLite/src/tensorflow/lite/schema/schema_generated.h:6778:13: error: macro ""max"" requires 2 arguments, but only 1 given
   float max() const {



**Provide the exact sequence of commands / steps that you executed before running into the problem**

Arduino IDE upload button


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33608,"""Failed to call mkldnn_sgemm. Error code: 3"" Error when training a simple CNN model","
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):2.1.0-dev20191021, 2.0.0
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:
Trying to build a model that uses CNN over text. 
minimal code to reproduce the error:

```
import tensorflow
from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Lambda, Conv1D, GlobalMaxPool1D, concatenate
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras import Input
import string

CHARS = string.punctuation + string.digits + string.ascii_letters + string.whitespace
CHAR_MAP = tensorflow.lookup.StaticHashTable(tensorflow.lookup.KeyValueTensorInitializer(list(CHARS), list(range(1, len(CHARS)+1)), 'string', 'int32'), 0)


def string_to_vec(s):
    return tensorflow.ragged.map_flat_values (CHAR_MAP.lookup, tensorflow.strings.unicode_split(s, 'UTF-8')).to_tensor()


input_layer = Input(shape=tuple(), ragged=False, dtype='string')
feature_layer = Lambda(string_to_vec)(input_layer)
embedding_layer = Embedding(input_dim=len(CHARS)+1, output_dim=10, name='char_embeddings')(feature_layer)
cnn_layer = concatenate([Conv1D(10, kernel_size, activation='relu', padding='same')(embedding_layer) for kernel_size in range(5)])
max_pool = GlobalMaxPool1D()(cnn_layer)
dense_layer = Dense(1, activation='relu')(max_pool)
model = Model(inputs=[input_layer], outputs=[dense_layer])
model.compile(optimizer='adam', loss='binary_crossentropy')

print(tensorflow.__version__)

x = ['hello world', 'this is a test']
y = [0] * len(x)
print(model.predict(x))
model.fit(x,y)

```

Output:
```
2.1.0-dev20191021
[[0.]
 [0.]]
Train on 2 samples
2019-10-22 15:29:13.322033: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: Failed to call mkldnn_sgemm. Error code: 3
	 [[{{node Conv2DBackpropInput}}]]
2/2 [==============================] - 1s 285ms/sample
Traceback (most recent call last):
  File ""/usr/local/miniconda3/envs/zr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-64494552324e>"", line 4, in <module>
    runfile('/Users/ophir/dev/ophir/cnn_error.py', wdir='/Users/ophir/dev/ophir')
  File ""/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_bundle/pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/Users/ophir/dev/ophir/cnn_error.py"", line 29, in <module>
    model.fit(x,y)
  File ""/usr/local/miniconda3/envs/zr/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 777, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/miniconda3/envs/zr/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 337, in fit
    total_epochs=epochs)
  File ""/usr/local/miniconda3/envs/zr/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 127, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/usr/local/miniconda3/envs/zr/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""/usr/local/miniconda3/envs/zr/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/miniconda3/envs/zr/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 632, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/usr/local/miniconda3/envs/zr/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2339, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/usr/local/miniconda3/envs/zr/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1589, in _filtered_call
    self.captured_inputs)
  File ""/usr/local/miniconda3/envs/zr/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1670, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/usr/local/miniconda3/envs/zr/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 521, in call
    ctx=ctx)
  File ""/usr/local/miniconda3/envs/zr/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError:  Failed to call mkldnn_sgemm. Error code: 3
	 [[node Conv2DBackpropInput (defined at /Users/ophir/dev/ophir/cnn_error.py:29) ]] [Op:__inference_distributed_function_1725]
Function call stack:
distributed_function

```
"
33607,Coral Dev Board runtime error during prediction,"I'm working on a classification problem. I used Inception v3 model in Keras for classification. I did post training quantization and converted my hdf5 model to TFLite. Further, I compiled my TFLite model to use it on TPU instead of CPU on dev board. It's giving runtime error when I run this code during prediction on dev board

**Describe the current behavior**
```
Traceback (most recent call last):
  File ""inference_try.py"", line 25, in <module>
    interpreter.allocate_tensors()
  File ""/home/mendel/.local/lib/python3.5/site-packages/tflite_runtime/interpreter.py"", line 244, in allocate_tensors
    return self._interpreter.AllocateTensors()
  File ""/home/mendel/.local/lib/python3.5/site-packages/tflite_runtime/interpreter_wrapper.py"", line 114, in AllocateTensors
    return _interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
RuntimeError: Internal: :71 tf_lite_type != kTfLiteUInt8 (9 != 3)Node number 5 (EdgeTpuDelegateForCustomOp) failed to `prepare.`
```
**Describe the expected behavior**
Should predict the outcomes successfully and not give error on `interpreter.allocate_tensors()` statement.

**Code to reproduce the issue**
```
from tflite_runtime.interpreter import Interpreter
from tflite_runtime.interpreter import load_delegate

interpreter = Interpreter(
      model_path=""/home/mendel/classification/inceptionV3Q_edgetpu.tflite"",
      experimental_delegates=[load_delegate('libedgetpu.so.1.0')])

interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.set_tensor(input_details[0]['index'], img)
interpreter.invoke()
output_details1 = interpreter.get_output_details()[0]
answer= np.squeeze(interpreter.get_tensor(output_details1['index']))
```
"
33606,TFLite_Micro: Implementing version 3 of convolutional layers for Post-training fully-integer quantization,"**System information**
- TensorFlow version (you are using): 2.0.0, up to date with master
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
By following the second part of the tutorial on [Post-training integer quantization](https://www.tensorflow.org/lite/performance/post_training_integer_quant),  thus providing also a representative dataset and setting
```python
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
```
the resulting converted model is fully quantized, including inputs and outputs.
However, if there are convolutions operations in the model, the converted versions will be ""Version 3"", which is not currently supported by Tflite for Microcontrollers, as shown in all_ops_resolver.cc lines 22 and 30
```c++
  AddBuiltin(BuiltinOperator_DEPTHWISE_CONV_2D, Register_DEPTHWISE_CONV_2D());
 ...
 AddBuiltin(BuiltinOperator_CONV_2D, Register_CONV_2D());
```


**Will this change the current api? How?**
The current tflite micro api will be changed by including support to fully quantized convolutional layers as currently happens in TFLite
**Who will benefit with this feature?**
Everyone who wants to deploy fully quantized convolutional layers on a microcontroller without floating point support (or in all those situations where due to energy constraints, FPU cannot be used)
**Any Other info.**
"
33605,OUT_OF_MEMORY error on Mali GPU.,"Hey there!
In my project I try to run inference on a simple one input model via GPU delegate and SSBO.

I have 5 devices: Nexus 5X, Xiaomi Mi A1, Xiaomi Mi T9 Pro, Honor 10 and Huawei Mate 20.

First three devices are on Adreno GPU and everything works perfectly, but in Huawei and Honor it turned out that during the intertpreter invoke method OpenGL ES OUT_OF_MEMORY error tracked on glGetUniformLocation call. I tried out different approaches to avoid this, but it didn't help. 

At the moment of crash usage of Graphics memory is about 256 MB out of 1 GB.

Maybe you could help me with that?"
33604,"Pip install with --no-binary ""No matching distribution found for tensorflow"" ","**System information**
- python 3.6
- pip 19.3.1

**Describe the problem**

Installing Tensorflow through Pip with the --no-binary option throws a `No matching distribution found` error.

This is, for example, currently causing an issue with Apache Beam which uses the `--no-binary` flag to download external dependencies based on a requirements.txt file.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```pip install tensorflow --no-binary :all:```

**Any other info / logs**

From Pip:
>ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
>ERROR: No matching distribution found for tensorflow

From Beam:
>subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'download', '--dest', '/tmp/dataflow-requirements-cache', '-r', 'config/dataflow/requirements.txt', '--exists-action', 'i', '--no-binary', ':all:']' returned non-zero exit status 1.\n""

Side note, until yesterday this was working fine."
33603,tf.pow() overflow??,"Env:
* Colab (with gpu on)
* TF 2.0
* Python3

Running tf.pow() with integer powers greater than 5 returns wrong results and to me it looks like an overflow.
```python
a = tf.constant(50)
b = tf.constant(6)
tf.pow(a,b)
```
The above returns:
```
tf.Tensor(-1554869184, shape=(), dtype=int32)
```
Which is mathematically wrong. Here is the result (the correct one) when using python's math library.
```python
import math
math.pow(50,6)
```
The above returns ```15625000000.0```

Using python's math library gives correct results for higher powers which I'd expect tf.pow() to do for integer inputs. 
Any explanation for this discrepancy!!"
33602,evalSpec 'NoneType' object is not subscriptable,"tensorflow=2.0.0
python 3.6.8

i followed this guide: https://www.tensorflow.org/tutorials/distribute/multi_worker_with_estimator

I wanted to replicate this code with my data set:
```python
BUFFER_SIZE = 10000
BATCH_SIZE = 64
def input_fn(mode, input_context=None):
  datasets, info = tfds.load(name='mnist',
                                with_info=True,
                                as_supervised=True)
  mnist_dataset = (datasets['train'] if mode == tf.estimator.ModeKeys.TRAIN else
                   datasets['test'])

  def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255
    return image, label

  if input_context:
    mnist_dataset = mnist_dataset.shard(input_context.num_input_pipelines,
                                        input_context.input_pipeline_id)
  return mnist_dataset.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
```


my code is: 
```python
batch_size=16
def input_fn(mode,input_context=None):
    dataset = (tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train, np.float32), Y_train)).repeat() 
               if mode == tf.estimator.ModeKeys.TRAIN else
                   tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_valid, np.float32), Y_valid)))
    if input_context:
      dataset = dataset.shard(input_context.num_input_pipelines,
                                        input_context.input_pipeline_id)
    return dataset.batch(batch_size)

strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
config = tf.estimator.RunConfig(train_distribute=strategy, save_checkpoints_steps=100)
classifier=tf.keras.estimator.model_to_estimator(
    keras_model=my_model, model_dir=""model"")

tf.estimator.train_and_evaluate(
    classifier,
    train_spec=tf.estimator.TrainSpec(input_fn=input_fn),
    eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)
)
```
my dataset input is this:

/>> type(X_train)
numpy.ndarray
/>> X_train.shape
(480, 224, 224, 3)
/>>tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train, np.float32), Y_train)).shuffle(1000).repeat().batch(batch_size)
<DatasetV1Adapter shapes: ((?, 224, 224, 3), (?, 16)), types: (tf.float32, tf.float32)>

/>>Y_train.shape
(480, 16)
/>>type(Y_train)
numpy.ndarray

/>>X_valid.shape
(160, 224, 224, 3)
/>>tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_valid, np.float32), Y_valid)).repeat().batch(batch_size)
<DatasetV1Adapter shapes: ((?, 224, 224, 3), (?, 16)), types: (tf.float32, tf.float32)>

/>>Y_valid.shape
(160, 16)
/>>type(Y_valid)
numpy.ndarray




logs:
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-46-dfcb7e52174e> in <module>()
     27     classifier,
     28     train_spec=tf.estimator.TrainSpec(input_fn=input_fn),
---> 29     eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)
     30     # eval_spec=tf.estimator.EvalSpec(input_fn=input_fn, exporters=exporter)
     31 )

14 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py in get_metric_function(metric, output_shape, loss_fn)
   1029 
   1030   if metric in ['accuracy', 'acc']:
-> 1031     if output_shape[-1] == 1 or is_binary_crossentropy:
   1032       return metrics_module.binary_accuracy
   1033     elif is_sparse_categorical_crossentropy:

TypeError: 'NoneType' object is not subscriptable"
33601,"Model loaded with tensorflow.keras.Model.load_model is slower (if GRU cells are used), than the original constructed model","Tensorflow 2.0, CUDA 10.0, CuDNN 7.6, Python 3.6.8 in a clean environment

The model loaded from a checkpoint does not use cudnn. You can see this in the line after `Epoch 1/2` in the outputs. When the model is loaded from checkpoint it misses
`2019-10-22 12:25:01.298965: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
`
and the code is slower. (Much slower if I am using real long data, not just the broken down bugreport file)


Code to reproduce:
```
import argparse
from tensorflow.keras import Model
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.layers import Activation, Embedding, Dense, Input
from tensorflow.keras.layers import SimpleRNN, GRU, LSTM
from tensorflow.keras.utils import to_categorical
import numpy as np

parser = argparse.ArgumentParser(description='train recurrent net.')
parser.add_argument('--epochs', dest='epochs',  type=int, default=2)
parser.add_argument('--hidden_size', dest='hidden_size',  type=int, default=50)
parser.add_argument('--RNN_type', dest='RNN_type',  type=str, default='GRU')
parser.add_argument('--epoch_size', dest='epoch_size',  type=int, default=1000)
parser.add_argument('--pretrained_name', dest='pretrained_name',  type=str, default=None)

args = parser.parse_args()

RNN_type = {}

RNN_type['LSTM'] = LSTM
RNN_type['GRU'] = GRU
RNN_type['SimpleRNN'] = SimpleRNN

LSTM_use = RNN_type[args.RNN_type]

max_output = 10
full_python_file_string = [1,3,2,4,5,3,2,3,4,5]
class KerasBatchGenerator(object):
    def __init__(self, data_set):
        self.data_set = data_set
            
    def generate(self):
        while True:
            tmp_x = np.array([full_python_file_string], dtype=int)
            tmp_y = np.array([full_python_file_string], dtype=int)
            yield tmp_x, to_categorical(tmp_y, num_classes=max_output)

train_data_generator = KerasBatchGenerator(0)
test_data_generator = KerasBatchGenerator(0)

hidden_size = args.hidden_size

if args.pretrained_name is not None:
  from tensorflow.keras.models import load_model
  model = load_model(args.pretrained_name)
else:
  inputs = Input(batch_shape=(1,None,))
  embeds = Embedding(max_output, max_output, embeddings_initializer='identity', trainable=True)(inputs)
  lstm1 = LSTM_use(hidden_size, return_sequences=True, stateful = True)(embeds)
  x = Dense(max_output)(lstm1)
  predictions = Activation('softmax')(x)
  model = Model(inputs=inputs, outputs=predictions)

checkpointer = ModelCheckpoint(filepath='checkpoints/model-{epoch:02d}.hdf5', verbose=1)

model.compile(loss='categorical_crossentropy', optimizer = 'SGD', metrics=['categorical_accuracy'])
model.fit_generator(train_data_generator.generate(), args.epoch_size, args.epochs, 
                    validation_data=test_data_generator.generate(), 
                    validation_steps=args.epoch_size / 10, callbacks=[checkpointer])

```

You have to start it two times (you will need a subdirectory checkpoints), the first time generates the checkpoint model file:

```
(tf2-gpu) detlef@ubuntu-i7:~/AutomaticProgramming$ python BugReport.py
2019-10-22 12:25:00.253047: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-10-22 12:25:00.276364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:25:00.277095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
2019-10-22 12:25:00.277424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 12:25:00.278925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 12:25:00.279799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 12:25:00.280014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 12:25:00.281396: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 12:25:00.282247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 12:25:00.286830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-22 12:25:00.287072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:25:00.287628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:25:00.288014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-22 12:25:00.288241: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-22 12:25:00.310514: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3999620000 Hz
2019-10-22 12:25:00.310931: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x44a3ae0 executing computations on platform Host. Devices:
2019-10-22 12:25:00.310946: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-10-22 12:25:00.413265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:25:00.413738: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x44a5940 executing computations on platform CUDA. Devices:
2019-10-22 12:25:00.413751: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1070 Ti, Compute Capability 6.1
2019-10-22 12:25:00.413908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:25:00.414331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
2019-10-22 12:25:00.414378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 12:25:00.414387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 12:25:00.414394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 12:25:00.414401: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 12:25:00.414408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 12:25:00.414414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 12:25:00.414421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-22 12:25:00.414467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:25:00.414924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:25:00.415391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-22 12:25:00.415430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 12:25:00.416258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-22 12:25:00.416267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-10-22 12:25:00.416282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-10-22 12:25:00.416464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:25:00.417126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:25:00.417832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6219 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
Epoch 1/2
2019-10-22 12:25:01.298965: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-22 12:25:02.108956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
 999/1000 [============================>.] - ETA: 0s - loss: 1.1246 - categorical_accuracy: 0.7498   
Epoch 00001: saving model to checkpoints/model-01.hdf5
1000/1000 [==============================] - 38s 38ms/step - loss: 1.1238 - categorical_accuracy: 0.7501 - val_loss: 0.3462 - val_categorical_accuracy: 1.0000
Epoch 2/2
 999/1000 [============================>.] - ETA: 0s - loss: 0.1313 - categorical_accuracy: 1.0000  
Epoch 00002: saving model to checkpoints/model-02.hdf5
1000/1000 [==============================] - 38s 38ms/step - loss: 0.1312 - categorical_accuracy: 1.0000 - val_loss: 0.0470 - val_categorical_accuracy: 1.0000
(tf2-gpu) detlef@ubuntu-i7:~/AutomaticProgramming$ 

```
the second time we load a checkpoint:
```

(tf2-gpu) detlef@ubuntu-i7:~/AutomaticProgramming$ python BugReport.py --pretrained_name checkpoints/model-02.hdf5
2019-10-22 12:27:35.436227: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-10-22 12:27:35.456340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:27:35.456789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
2019-10-22 12:27:35.456974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 12:27:35.457883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 12:27:35.458700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 12:27:35.458896: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 12:27:35.459886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 12:27:35.460658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 12:27:35.462926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-22 12:27:35.463040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:27:35.463511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:27:35.463922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-22 12:27:35.464170: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-22 12:27:35.486520: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3999620000 Hz
2019-10-22 12:27:35.487009: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a23e30 executing computations on platform Host. Devices:
2019-10-22 12:27:35.487026: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-10-22 12:27:35.597273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:27:35.597738: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a25c90 executing computations on platform CUDA. Devices:
2019-10-22 12:27:35.597754: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1070 Ti, Compute Capability 6.1
2019-10-22 12:27:35.597930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:27:35.598350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
2019-10-22 12:27:35.598405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 12:27:35.598420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 12:27:35.598434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 12:27:35.598446: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 12:27:35.598460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 12:27:35.598473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 12:27:35.598486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-22 12:27:35.598535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:27:35.599208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:27:35.599699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-22 12:27:35.599745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 12:27:35.600327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-22 12:27:35.600337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-10-22 12:27:35.600342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-10-22 12:27:35.600521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:27:35.601467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-22 12:27:35.602241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6189 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
Epoch 1/2
2019-10-22 12:27:36.894279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
 999/1000 [============================>.] - ETA: 0s - loss: 0.0299 - categorical_accuracy: 1.0000  
Epoch 00001: saving model to checkpoints/model-01.hdf5
1000/1000 [==============================] - 84s 84ms/step - loss: 0.0299 - categorical_accuracy: 1.0000 - val_loss: 0.0195 - val_categorical_accuracy: 1.0000
Epoch 2/2
 999/1000 [============================>.] - ETA: 0s - loss: 0.0150 - categorical_accuracy: 1.0000  
Epoch 00002: saving model to checkpoints/model-02.hdf5
1000/1000 [==============================] - 83s 83ms/step - loss: 0.0150 - categorical_accuracy: 1.0000 - val_loss: 0.0116 - val_categorical_accuracy: 1.0000
(tf2-gpu) detlef@ubuntu-i7:~/AutomaticProgramming$ 

```
"
33600,AttributeError: module 'tensorflow.python.keras' has no attribute 'Model',"Running code from object Detection
not a custom code
I am using Window 10
Tensorflow 1.4 CPU
I am getting this error, while running below code.
i want to rectify the error, without updating Tensorflow,

import tensorflow as tf

BOX_ENCODINGS = 'box_encodings'
CLASS_PREDICTIONS_WITH_BACKGROUND = 'class_predictions_with_background'
MASK_PREDICTIONS = 'mask_predictions'


class BoxPredictor(object):
  """"""BoxPredictor.""""""

  def __init__(self, is_training, num_classes):
    """"""Constructor.

    Args:
      is_training: Indicates whether the BoxPredictor is in training mode.
      num_classes: number of classes.  Note that num_classes *does not*
        include the background category, so if groundtruth labels take values
        in {0, 1, .., K-1}, num_classes=K (and not K+1, even though the
        assigned classification targets can range from {0,... K}).
    """"""
    self._is_training = is_training
    self._num_classes = num_classes

  @property
  def is_keras_model(self):
    return False

  @property
  def num_classes(self):
    return self._num_classes

  def predict(self, image_features, num_predictions_per_location,
              scope=None, **params):
    """"""Computes encoded object locations and corresponding confidences.

    Takes a list of high level image feature maps as input and produces a list
    of box encodings and a list of class scores where each element in the output
    lists correspond to the feature maps in the input list.

    Args:
      image_features: A list of float tensors of shape [batch_size, height_i,
      width_i, channels_i] containing features for a batch of images.
      num_predictions_per_location: A list of integers representing the number
        of box predictions to be made per spatial location for each feature map.
      scope: Variable and Op scope name.
      **params: Additional keyword arguments for specific implementations of
              BoxPredictor.

    Returns:
      A dictionary containing at least the following tensors.
        box_encodings: A list of float tensors. Each entry in the list
          corresponds to a feature map in the input `image_features` list. All
          tensors in the list have one of the two following shapes:
          a. [batch_size, num_anchors_i, q, code_size] representing the location
            of the objects, where q is 1 or the number of classes.
          b. [batch_size, num_anchors_i, code_size].
        class_predictions_with_background: A list of float tensors of shape
          [batch_size, num_anchors_i, num_classes + 1] representing the class
          predictions for the proposals. Each entry in the list corresponds to a
          feature map in the input `image_features` list.

    Raises:
      ValueError: If length of `image_features` is not equal to length of
        `num_predictions_per_location`.
    """"""
    if len(image_features) != len(num_predictions_per_location):
      raise ValueError('image_feature and num_predictions_per_location must '
                       'be of same length, found: {} vs {}'.
                       format(len(image_features),
                              len(num_predictions_per_location)))
    if scope is not None:
      with tf.variable_scope(scope):
        return self._predict(image_features, num_predictions_per_location,
                             **params)
    return self._predict(image_features, num_predictions_per_location,
                         **params)

  # TODO(rathodv): num_predictions_per_location could be moved to constructor.
  # This is currently only used by ConvolutionalBoxPredictor.
  @abstractmethod
  def _predict(self, image_features, num_predictions_per_location, **params):
    """"""Implementations must override this method.

    Args:
      image_features: A list of float tensors of shape [batch_size, height_i,
        width_i, channels_i] containing features for a batch of images.
      num_predictions_per_location: A list of integers representing the number
        of box predictions to be made per spatial location for each feature map.
      **params: Additional keyword arguments for specific implementations of
              BoxPredictor.

    Returns:
      A dictionary containing at least the following tensors.
        box_encodings: A list of float tensors. Each entry in the list
          corresponds to a feature map in the input `image_features` list. All
          tensors in the list have one of the two following shapes:
          a. [batch_size, num_anchors_i, q, code_size] representing the location
            of the objects, where q is 1 or the number of classes.
          b. [batch_size, num_anchors_i, code_size].
        class_predictions_with_background: A list of float tensors of shape
          [batch_size, num_anchors_i, num_classes + 1] representing the class
          predictions for the proposals. Each entry in the list corresponds to a
          feature map in the input `image_features` list.
    """"""
    pass


class KerasBoxPredictor(tf.keras.Model):
  """"""Keras-based BoxPredictor.""""""

  def __init__(self, is_training, num_classes, freeze_batchnorm,
               inplace_batchnorm_update, name=None):
    """"""Constructor.

    Args:
      is_training: Indicates whether the BoxPredictor is in training mode.
      num_classes: number of classes.  Note that num_classes *does not*
        include the background category, so if groundtruth labels take values
        in {0, 1, .., K-1}, num_classes=K (and not K+1, even though the
        assigned classification targets can range from {0,... K}).
      freeze_batchnorm: Whether to freeze batch norm parameters during
        training or not. When training with a small batch size (e.g. 1), it is
        desirable to freeze batch norm update and use pretrained batch norm
        params.
      inplace_batchnorm_update: Whether to update batch norm moving average
        values inplace. When this is false train op must add a control
        dependency on tf.graphkeys.UPDATE_OPS collection in order to update
        batch norm statistics.
      name: A string name scope to assign to the model. If `None`, Keras
        will auto-generate one from the class name.
    """"""
    super(KerasBoxPredictor, self).__init__(name=name)

    self._is_training = is_training
    self._num_classes = num_classes
    self._freeze_batchnorm = freeze_batchnorm
    self._inplace_batchnorm_update = inplace_batchnorm_update

  @property
  def is_keras_model(self):
    return True

  @property
  def num_classes(self):
    return self._num_classes

  def call(self, image_features, **kwargs):
    """"""Computes encoded object locations and corresponding confidences.

    Takes a list of high level image feature maps as input and produces a list
    of box encodings and a list of class scores where each element in the output
    lists correspond to the feature maps in the input list.

    Args:
      image_features: A list of float tensors of shape [batch_size, height_i,
      width_i, channels_i] containing features for a batch of images.
      **kwargs: Additional keyword arguments for specific implementations of
            BoxPredictor.

    Returns:
      A dictionary containing at least the following tensors.
        box_encodings: A list of float tensors. Each entry in the list
          corresponds to a feature map in the input `image_features` list. All
          tensors in the list have one of the two following shapes:
          a. [batch_size, num_anchors_i, q, code_size] representing the location
            of the objects, where q is 1 or the number of classes.
          b. [batch_size, num_anchors_i, code_size].
        class_predictions_with_background: A list of float tensors of shape
          [batch_size, num_anchors_i, num_classes + 1] representing the class
          predictions for the proposals. Each entry in the list corresponds to a
          feature map in the input `image_features` list.
    """"""
    return self._predict(image_features, **kwargs)

  @abstractmethod
  def _predict(self, image_features, **kwargs):
    """"""Implementations must override this method.

    Args:
      image_features: A list of float tensors of shape [batch_size, height_i,
        width_i, channels_i] containing features for a batch of images.
      **kwargs: Additional keyword arguments for specific implementations of
              BoxPredictor.

    Returns:
      A dictionary containing at least the following tensors.
        box_encodings: A list of float tensors. Each entry in the list
          corresponds to a feature map in the input `image_features` list. All
          tensors in the list have one of the two following shapes:
          a. [batch_size, num_anchors_i, q, code_size] representing the location
            of the objects, where q is 1 or the number of classes.
          b. [batch_size, num_anchors_i, code_size].
        class_predictions_with_background: A list of float tensors of shape
          [batch_size, num_anchors_i, num_classes + 1] representing the class
          predictions for the proposals. Each entry in the list corresponds to a
          feature map in the input `image_features` list.
    """"""
    raise NotImplementedError

"
33599,C binding for tensorflow 2.0,Is there a release date for `c binding` for `tf2`?
33598,about tf.gradients() API,"The API `tf.gradients` has a parameter `gate_gradients`
```gate_gradients: If True, add a tuple around the gradients returned for an operations. This avoids some race conditions.```

In case of op has more than one in_grads, it makes a barrier, grads will not propagate until the whole grad subGraph was computed. It make sense.

But, in case of op has more than one in_grads and the upstream ops are not Variable, the barrier seems redundant. The OP parallelism can be improved.

thanks"
33597,how to realize batch convolutional operation,"hello,
    i want to use batch convolutional operation, is said:
   input shape:  [batch_size, height, width, channel], and i have a group of kernels:
    kernel shape:  [batch_size, kernel_size_height, kernel_size_width, out_channel]
i want to use this set of kernels to convolute the batch data: for each data in the batch, corresponding a kernel, like:

data[0] (shape: [ height, width, channel]) ---use-- ->  kernels[0] (shape: [kernel_size_height, kernel_size_width, out_channel])
data[1] (shape: [ height, width, channel])  ---use-- ->  kernels[1] (shape: [kernel_size_height, kernel_size_width, out_channel])

but, i failed to find the correlative function.   i use tensorflow1.13, does any function realize that??？
thanks！"
33595,`tf.summary.FileWriter` overwrites existing events file if reopened in same `logdir`quickly.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15.0
- Python version: 3.6.3
- CUDA/cuDNN version: 10.0.130
- GPU model and memory: GeForce 940MX, 2GB

**Current behaviour**
If `tf.summary.FileWriter` is closed and then reopened in the same `logdir`, `FileWriter` overwrites events file created right before closure. If I add a delay (expr `time.sleep(1)`) before reopening `FileWriter`, reopened `FileWriter` creates new events file. 

**Expected behaviour**
I expect `FileWriter` creating new events file regardless of how recently `logdir` was used.

**Code to reproduce the issue**
```python
import os
import time

import tensorflow.compat.v1 as tf


def print_dir_contents(path, msg):
    print()
    print(msg)
    print(""Summary dir contents:"", os.listdir(path))
    print(""Size of events files:"", [os.stat(os.path.join(path, f))[-4] for f in os.listdir(path)])


path = 'summary_dir'

pl = tf.placeholder(tf.float32)

s = tf.summary.tensor_summary('tsum', pl)

os.makedirs(path, exist_ok=True)
print_dir_contents(path, ""Before summarizing:"")
with tf.Session() as sess:
    w = tf.summary.FileWriter(logdir=path)
    for i in range(10):
        s_ = sess.run(s, feed_dict={pl: i})
        w.add_summary(s_, global_step=i)
    w.flush()
    w.close()
    print_dir_contents(path, ""After first writer shutdown:"")
    # time.sleep(1)  # If uncomment, snippet works correctly.
    w = tf.summary.FileWriter(logdir=path)
    for i in range(10, 20):
        s_ = sess.run(s, feed_dict={pl: i})
        w.add_summary(s_, global_step=i)
    w.flush()
time.sleep(1)
print_dir_contents(path, ""After second flush:"")
```

**Other info / logs**
```

Before summarizing:
Summary dir contents: []
Size of events files: []
2019-10-22 10:22:34.689307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-10-22 10:22:35.800362: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error
2019-10-22 10:22:35.800561: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: aenima
2019-10-22 10:22:35.800639: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: aenima
2019-10-22 10:22:35.800881: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 418.67.0
2019-10-22 10:22:35.801044: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.67.0
2019-10-22 10:22:35.801107: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 418.67.0
2019-10-22 10:22:35.844875: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-22 10:22:36.569070: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2711950000 Hz
2019-10-22 10:22:36.570320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564451333fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-10-22 10:22:36.570411: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version

After first writer shutdown:
Summary dir contents: ['events.out.tfevents.1571728959.aenima']
Size of events files: [530]

After second flush:
Summary dir contents: ['events.out.tfevents.1571728959.aenima']
Size of events files: [532]
```
"
33594,graph_transforms build has error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install
- TensorFlow version: 1.13
- Python version: 3.6
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source):0.21,I download deb file
- GCC/Compiler version (if compiling from source):Ubuntu default gcc,gcc version 7.4.0
- CUDA/cuDNN version: no
- GPU model and memory:no



I want to know,which version with tensorflow and bazel can build sucess?


"
33593,distributed training with MirroredStrategy crashes when input shapes are variable,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip binary
- TensorFlow version (use command below): tf2.0.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda 10.0 cudnn 7.6.4
- GPU model and memory: rtx titan / 24gb

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Tensorflow raise error (ValueError: When input_signature is provided, all inputs to the Python function must be convertible to tensors:) when checking input signature of a tf.function if input shape is variable in a distributed training environment. The training works without any error when I train it with single GPU or input with fixed shape, or I delete a path to cuda from my environment path. 


**Describe the expected behavior**

**Code to reproduce the issue**

```
import tensorflow as tf
import tensorflow.keras as keras
import random
import os
os.environ[""CUDA_VISIBLE_DEVICES""]=""2,3""
class Model(keras.Model):
    def __init__(self):
        super(Model, self).__init__()
        self.emb = keras.layers.Embedding(51,100)
        self.layer = keras.layers.Dense(51)
    def call(self,x):
        x = self.emb(x)
        x = self.layer(x)
        return x
@tf.function(input_signature=(tf.TensorSpec(shape=[None, None], dtype=tf.int64),
                              tf.TensorSpec(shape=[None, None], dtype=tf.int64)))
def multi_gpu_step(x,y):
    def example_update_step(x, y):
        with tf.GradientTape() as tape:
            y_ = model(x)
            batch_loss = keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_, from_logits=True)`
            losses = batch_loss / strategy.num_replicas_in_sync
        step_grad = tape.gradient(losses, model.trainable_variables)
        optimizer.apply_gradients(zip(step_grad, model.trainable_variables))
        return tf.reduce_mean(batch_loss,1)
    example_loss = strategy.experimental_run_v2(
        example_update_step, args=(x, y))
    losses_sum = strategy.reduce(
        tf.distribute.ReduceOp.SUM, example_loss, axis=0)
    return losses_sum


strategy = tf.distribute.MirroredStrategy()

data = [[i for i in range(random.randint(10,50))] for j in range(400)]


def iterator():
    for i in range(len(data)):
        yield data[i], data[i]


with strategy.scope():
    model = Model()
    optimizer = keras.optimizers.Adam()

dataset = tf.data.Dataset.from_generator(iterator, output_types=(tf.int64, tf.int64))
batchfier = dataset.padded_batch(4, padded_shapes=([None], [None]))
batchfier = strategy.experimental_distribute_dataset(batchfier)

for x,y in batchfier:
    l = multi_gpu_step(x,y)
```
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
**Other info / logs**
```ssh://bj1123@121.78.112.79:2222/home/bj1123/anaconda3/bin/python -u /home/bj1123/pycharms/GPT2/multi_test_variable.py
2019-10-22 14:21:01.879166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-10-22 14:21:02.010621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:b2:00.0
2019-10-22 14:21:02.011936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:db:00.0
2019-10-22 14:21:02.012174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 14:21:02.013811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 14:21:02.015315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 14:21:02.015650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 14:21:02.017535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 14:21:02.019038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 14:21:02.023539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-22 14:21:02.028529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2019-10-22 14:21:02.028935: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-10-22 14:21:02.058997: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2019-10-22 14:21:02.062760: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d0eb1f8ad0 executing computations on platform Host. Devices:
2019-10-22 14:21:02.062799: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-10-22 14:21:02.415212: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d0eb25ba20 executing computations on platform CUDA. Devices:
2019-10-22 14:21:02.415251: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
2019-10-22 14:21:02.415260: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN RTX, Compute Capability 7.5
2019-10-22 14:21:02.417153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:b2:00.0
2019-10-22 14:21:02.418575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:db:00.0
2019-10-22 14:21:02.418622: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 14:21:02.418637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 14:21:02.418652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 14:21:02.418667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 14:21:02.418682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 14:21:02.418697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 14:21:02.418714: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-22 14:21:02.424652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2019-10-22 14:21:02.424697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 14:21:02.428615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-22 14:21:02.428630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 
2019-10-22 14:21:02.428636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N 
2019-10-22 14:21:02.428641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N 
2019-10-22 14:21:02.432235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22846 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:b2:00.0, compute capability: 7.5)
2019-10-22 14:21:02.434469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22846 MB memory) -> physical GPU (device: 1, name: TITAN RTX, pci bus id: 0000:db:00.0, compute capability: 7.5)
2019-10-22 14:21:02.445038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:b2:00.0
2019-10-22 14:21:02.448745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:db:00.0
2019-10-22 14:21:02.448816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 14:21:02.448856: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 14:21:02.448907: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 14:21:02.448953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 14:21:02.449004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 14:21:02.449045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 14:21:02.449095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-22 14:21:02.459964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2019-10-22 14:21:02.460089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-22 14:21:02.460116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 
2019-10-22 14:21:02.460136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N 
2019-10-22 14:21:02.460156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N 
2019-10-22 14:21:02.466303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 22846 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:b2:00.0, compute capability: 7.5)
2019-10-22 14:21:02.468400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:1 with 22846 MB memory) -> physical GPU (device: 1, name: TITAN RTX, pci bus id: 0000:db:00.0, compute capability: 7.5)
WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices
Traceback (most recent call last):
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1704, in _convert_inputs_to_signature
    value, dtype_hint=spec.dtype)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1184, in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1242, in convert_to_tensor_v2
    as_ref=False)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1296, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py"", line 286, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py"", line 227, in constant
    allow_broadcast=True)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py"", line 235, in _constant_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py"", line 96, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
ValueError: Attempt to convert a value (PerReplica:{
  0 /job:localhost/replica:0/task:0/device:GPU:0: <tf.Tensor: id=145, shape=(2, 49), dtype=int64, numpy=
array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,
        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0],
       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,
        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
        48]])>,
  1 /job:localhost/replica:0/task:0/device:GPU:1: <tf.Tensor: id=148, shape=(2, 27), dtype=int64, numpy=
array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,
        16, 17, 18,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,
        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]])>
}) with an unsupported type (<class 'tensorflow.python.distribute.values.PerReplica'>) to a Tensor.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/bj1123/pycharms/GPT2/multi_test_variable.py"", line 54, in <module>
    l = multi_gpu_step(x,y)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1822, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2107, in _maybe_define_function
    *args, **kwargs)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1650, in canonicalize_function_inputs
    self._flat_input_signature)
  File ""/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1710, in _convert_inputs_to_signature
    format_error_message(inputs, input_signature))
ValueError: When input_signature is provided, all inputs to the Python function must be convertible to tensors:
  inputs: (
    PerReplica:{
  0 /job:localhost/replica:0/task:0/device:GPU:0: tf.Tensor(
[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
  24 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0]
 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
  48]], shape=(2, 49), dtype=int64),
  1 /job:localhost/replica:0/task:0/device:GPU:1: tf.Tensor(
[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18  0  0  0  0  0
   0  0  0]
 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
  24 25 26]], shape=(2, 27), dtype=int64)
},
    PerReplica:{
  0 /job:localhost/replica:0/task:0/device:GPU:0: tf.Tensor(
[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
  24 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0]
 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
  48]], shape=(2, 49), dtype=int64),
  1 /job:localhost/replica:0/task:0/device:GPU:1: tf.Tensor(
[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18  0  0  0  0  0
   0  0  0]
 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
  24 25 26]], shape=(2, 27), dtype=int64)
})
  input_signature: (
    TensorSpec(shape=(None, None), dtype=tf.int64, name=None),
    TensorSpec(shape=(None, None), dtype=tf.int64, name=None))

Process finished with exit code 1
```

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33592,"TensorFlow Models Installation on wondows 10 using protobuf ,cmake fails","Following tutorial on below link to train few pics.

https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html.

But protobuf lib is not getting created , following below link for windows 10 :
https://github.com/protocolbuffers/protobuf/blob/master/cmake/README.md

while , executing below command  , getting error : 
LINK : fatal error LNK1104: cannot open file 'LIBCMT.lib'

command:
cmake -G ""NMake Makefiles"" -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=../../../../install ../..

Attached are error and output files :
[CMakeError.log](https://github.com/tensorflow/tensorflow/files/3753881/CMakeError.log)
[CMakeOutput.log](https://github.com/tensorflow/tensorflow/files/3753882/CMakeOutput.log)

Please help.Need to get this done urgently

"
33591,Person_detection.zip not present after update in reference to issue  #33552 and PR #33579 ,"This is issue is made in reference to Issue #33552 and the PR #33579:
when I click on the person_detection.zip link after update this pops out:
`
This XML file does not appear to have any style information associated with it. The document tree is shown below.
<Error nighteye=""disabled"">
<Code>NoSuchKey</Code>
<Message>The specified key does not exist.</Message>
<Details>
No such object: tensorflow-nightly/github/tensorflow/tensorflow/lite/experimental/micro/tools/make/gen/arduino_x86_64/prj/person_detection/person_detection.zip
</Details>
</Error>
` 
"
33588,tflite interpreter makes huge difference in output for tf.reduce_mean() when it is quantized,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from source
- TensorFlow version (use command below): ('v2.0.0-0-g64c3d38', '2.0.0') & ('v2.0.0-rc2-26-g64c3d38', '2.0.0')
- Python version: 2.7.12
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
- CUDA/cuDNN version: 10.0 / 7.0
- GPU model and memory: GeForce GTX TITAN

**Describe the current behavior**
When I quantize the graph with tf.reduce_mean, it makes huge difference in outputs, compared original tf function and tflite model (not quantized).

**Describe the expected behavior**
the quantized model gives similar output values with the original tf graph.

With quantization=True,
```
INFO: Initialized TensorFlow Lite runtime.
INFO: Initialized TensorFlow Lite runtime.
input_x:
[[[[7. 7. 3.]
   [0. 2. 3.]
   [6. 3. 8.]]

  [[5. 2. 9.]
   [7. 3. 7.]
   [9. 9. 8.]]

  [[3. 2. 0.]
   [6. 8. 7.]
   [2. 0. 7.]]]]
output (tf.function):
tf.Tensor(
[[[[5.6666665]
   [1.6666666]
   [5.6666665]]

  [[5.3333335]
   [5.6666665]
   [8.666667 ]]

  [[1.6666666]
   [7.       ]
   [3.       ]]]], shape=(1, 3, 3, 1), dtype=float32)
output (tflite):
[[[[5.011765 ]
   [4.5176473]
   [4.5176473]]

  [[4.5176473]
   [4.5176473]
   [4.5176473]]

  [[4.5176473]
   [4.5176473]
   [0.6      ]]]]
```
The output of the tflite model seems too different with that of the original tf function.

When quantization=False,
```
INFO: Initialized TensorFlow Lite runtime.
input_x:
[[[[3. 6. 5.]
   [4. 8. 9.]
   [1. 7. 9.]]

  [[6. 8. 0.]
   [5. 0. 9.]
   [6. 2. 0.]]

  [[5. 2. 6.]
   [3. 7. 0.]
   [9. 0. 3.]]]]
output (tf.function):
tf.Tensor(
[[[[4.6666665]
   [7.       ]
   [5.6666665]]

  [[4.6666665]
   [4.6666665]
   [2.6666667]]

  [[4.3333335]
   [3.3333333]
   [4.       ]]]], shape=(1, 3, 3, 1), dtype=float32)
output (tflite):
[[[[4.6666665]
   [7.       ]
   [5.6666665]]

  [[4.6666665]
   [4.6666665]
   [2.6666667]]

  [[4.3333335]
   [3.3333333]
   [4.       ]]]]
```
the their outputs looks the same.

It does not seem normal that the quantization gives too much differences in output values.

**Code to reproduce the issue**
```
import tensorflow as tf
import numpy as np

@tf.function(input_signature=[
    tf.TensorSpec(shape=[None,3,3,3], dtype=tf.float32, name='x')])
def model(x, epsilon=1e-6):
  mean = tf.reduce_mean(x, axis=[-1], keepdims=True)
  #variance = tf.reduce_mean(tf.square(x - mean), axis=[-1], keepdims=True)
  #norm_x = (x - mean) * tf.math.rsqrt(variance + epsilon)
  #print(norm_x.shape)
  #return norm_x
  return mean

def run():
  def _representative_dataset_gen():
    for i in range(100):
      yield [np.random.random_integers(0, 9, size=[1,3,3,3]).astype('float32'),]

  np.random.seed(1234)
  quantization=True
  cfunc = model.get_concrete_function()
  converter = tf.lite.TFLiteConverter.from_concrete_functions([cfunc])
  if quantization:
         converter.representative_dataset = _representative_dataset_gen
         converter.optimizations = [tf.lite.Optimize.DEFAULT]



  tflite_model = converter.convert()
  model_file = ""tflite_mean_4D_v2.tflite""
  open(model_file, ""wb"").write(tflite_model)

  interpreter = tf.lite.Interpreter(model_path=model_file)
  interpreter.allocate_tensors()
  input_details = interpreter.get_input_details()
  output_details = interpreter.get_output_details()

  # test values
  input_x = np.random.random_integers(0, 9, size=[1,3,3,3]).astype('float32')

  print(""input_x:"")
  print(input_x)

  output_fun = cfunc(tf.constant(input_x))
  print(""output (tf.function):"")
  print(output_fun)

  # tflite test
  interpreter.set_tensor(input_details[0]['index'], input_x)
  output_tflite = interpreter.get_tensor(output_details[0]['index'])
  print(""output (tflite):"")
  print(output_tflite)

if __name__ == '__main__':
  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)
  run()
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33587,Performant (distributed) tf dataset creation from replay buffer using distribute strategies?,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0
- Python version: 3.7.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0/7.6.2
- GPU model and memory: Titan XP

**Describe the current behavior**

Currently, there is a lot of overhead in making and distributing a dataset from a replay buffer (for RL) as this requires, pulling data from an Actor's queue, creating the dataset (tf.experimental_make_numpy_dataset), batching, distributing (self.strategy.experimental_distribute_dataset), and building the iterator upon each update to the replay buffer. See below for an example.

```     
    def gather_data(self):
        self.output_queue = Queue(maxsize=self.data_params[""num_envs""])
        self.data_provider = DataProvider( 
                    self.policy,
                    self.output_queue,
                    self.strategy,
                    self.train_summary_writer,
                )
        for i in range(self.replay_buffer_len):
            self.data_provider.collect_episode()

    def get_batch(self):
        with self.strategy.scope():
            batch = self.output_queue.get()
            dataset = self.strategy.experimental_make_numpy_dataset(batch)
            dataset = dataset.batch(self.train_params[""global_batch_size""])
            dataset = self.strategy.experimental_distribute_dataset(dataset)
            self.iter = iter(dataset)

    def distributed_train(self):
        self.gather_data()
        self.get_batch()
        while step < self.train_steps:
            if step > 0 and (step % train_steps_per_buffer_refresh == 0):
                self.data_provider.collect_episode()
                self.get_batch()
            with self.strategy.scope():
                train_res = self.train_step(
                    next(self.iter),
                    self.policy,
                    self.strategy,
                )
            self.log_hook(train_res, step)
            self.save_hook(step)
            step += 1
                                                                                                                                                        
```

This follows the recommendation of the current docs. It takes a very long time (4s, 8x longer than each train step) to rebuild the dataset after adding to the replay buffer, distributed roughly evenly between self.strategy.experimental_make_numpy_dataset, self.strategy.experimental_distribute_dataset, and iter(dataset). Given than I updated the replay buffer every 4 train steps, this adds up to a significant performance hit.

It seems like tf-agents has an [implementation](https://github.com/tensorflow/agents/blob/e084e5184757dd84374e9b67176b8623d4b18a0f/tf_agents/replay_buffers/tf_uniform_replay_buffer.py#L301-L324) of a replay buffer to dataset Class method involving using tf.Counter and map, however, I haven't tested it's performance when calling distribute dataset on it. Is this the recommended way to have a Dataset does not have to be rebuilt after the replay buffer is updated? "
33586,non_max_suppression GPU version not working on TF 1.15,"Getting the following error on trying to place non_max_suppression() on GPU. 

```
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/ops.py"", line 5407, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation non_max_suppression/NonMaxSuppressionV3: node non_max_suppression/NonMaxSuppressionV3 (defined at /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/ops.py:1748)  was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.
         [[non_max_suppression/NonMaxSuppressionV3]]

```

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15
- Python version: 2.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: T4

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Get the above error on  placing the op in GPU.

**Describe the expected behavior**

Not see that error.

**Code to reproduce the issue**
```
import tensorflow as tf
import numpy as np
import os

import time
from tensorflow.python.ops import gen_image_ops


def yolo_non_max_suppression(scores, boxes, classes, sess, max_boxes = 10, iou_threshold = 0.5):
    """"""
    Applies Non-max suppression (NMS) to set of boxes
    
    Arguments:
    scores -- tensor of shape (None,), output of yolo_filter_boxes()
    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)
    classes -- tensor of shape (None,), output of yolo_filter_boxes()
    max_boxes -- integer, maximum number of predicted boxes you'd like
    iou_threshold -- real value, ""intersection over union"" threshold used for NMS filtering
    
    Returns:
    scores -- tensor of shape (, None), predicted score for each box
    boxes -- tensor of shape (4, None), predicted box coordinates
    classes -- tensor of shape (, None), predicted class for each box
    
    Note: The ""None"" dimension of the output tensors has obviously to be less than max_boxes. Note also that this
    function will transpose the shapes of scores, boxes, classes. This is made for convenience.
    """"""
   
    init_val_np = np.array ( [max_boxes], dtype=np.int32) 
    max_boxes_tensor = tf.Variable(max_boxes,  dtype='int32')     # tensor to be used in tf.image.non_max_suppression()
    sess.run(tf.variables_initializer([max_boxes_tensor])) # initialize variable max_boxes_tensor
    
    # Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep
    ### START CODE HERE ### (~ 1 line)
    with tf.device(""gpu:0""):
        boxes_np = boxes.eval() 
        time0 = time.time()
        score_threshold = 0.1
        soft_nms_sigma=0.0
        pad_to_max_output_size=False
        for i in range(1,2):
            nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)
            #nms_indices = nms(boxes_np, 0.5)
            #nms_indices = gen_image_ops.non_max_suppression_v2(boxes, scores, max_boxes_tensor, iou_threshold, )
            #nms_indices = gen_image_ops.non_max_suppression_v3(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold)
            #nms_indices = gen_image_ops.non_max_suppression_v4(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold, pad_to_max_output_size)
            #nms_indices = gen_image_ops.non_max_suppression_v5(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold, soft_nms_sigma)
            if i%100 == 0:
                print (i, (time.time() - time0)/i )
        ### END CODE HERE ###

        ### START CODE HERE ### (~ 3 lines)
        scores = tf.gather(scores, nms_indices)
        boxes = tf.gather(boxes, nms_indices)
        classes = tf.gather(classes, nms_indices)
        summary_writer = tf.summary.FileWriter(os.getenv('TENSORBOARD_DIR'), sess.graph)
        ### END CODE HERE ###

    return scores, boxes, classes

def test_yolo_non_max_suppression():
    with tf.device(""cpu:0""):
        with tf.Session() as test_b:
            scores = tf.random_normal([54,], mean=1, stddev=4, seed = 1)
            boxes = tf.random_normal([54, 4], mean=1, stddev=4, seed = 1)
            classes = tf.random_normal([54,], mean=1, stddev=4, seed = 1)
            scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, test_b)
            #scores, boxes, classes = yolo_non_max_suppression0(scores, boxes, classes)
            print(""scores[2] = "" + str(scores[2].eval()))
            print(""boxes[2] = "" + str(boxes[2].eval()))
            print(""classes[2] = "" + str(classes[2].eval()))
            print(""scores.shape = "" + str(scores.eval().shape))
            print(""boxes.shape = "" + str(boxes.eval().shape))
            print(""classes.shape = "" + str(classes.eval().shape))


test_yolo_non_max_suppression()

```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33585,tf.compat.v1.wrap_function throws error when creating variable in tf.distribute scope,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab TPU
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.6

**Code to reproduce the issue**
```python
%tensorflow_version 2.x
import tensorflow as tf

# define a function that uses tf.compat.v1.get_variable with some initializer
def f():
    v = tf.compat.v1.get_variable(
      'v',
      initializer=tf.compat.v1.variance_scaling_initializer(), shape=(1), trainable=True
    )
    return v

# this works:
wrapped = tf.compat.v1.wrap_function(f, [])

# but, connect to a TPU...
tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']
cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)
tf.config.experimental_connect_to_cluster(cluster_resolver)
tf.tpu.experimental.initialize_tpu_system(cluster_resolver)
with tf.distribute.experimental.TPUStrategy(cluster_resolver).scope():
    # ...and, this throws:
    # ValueError: Tensor-typed variable initializers must either be
    # wrapped in an init_scope or callable
    wrapped = tf.compat.v1.wrap_function(f, [])
```

It seems like wrapped_function variable creation is interacting poorly with distribute somehow.

Note, a simple `lambda: 0` initializer doesn't seem to cause this to happen. Not sure why. 

**Expected behavior**
This should ""just work"", unless these features aren't intended to be used together."
33578,"tensorflow model installation fails on windows10,using cmake3.15.4win64 , visual studio anyversion","following https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html
and https://github.com/protocolbuffers/protobuf/blob/master/cmake/README.md 
 protobuf failing while using command 

cmake -G ""NMake Makefiles"" -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=../../../../install ../..

error says : /out:CMakeCCompilerId.exe 
CMakeCCompilerId.obj 
LINK : fatal error LNK1104: cannot open file 'LIBCMT.lib'

lib path is given in environment variables.
running from command prompt.
attached are error and output files
[CMakeError.log](https://github.com/tensorflow/tensorflow/files/3752000/CMakeError.log)
[CMakeOutput.log](https://github.com/tensorflow/tensorflow/files/3752002/CMakeOutput.log)



"
33577,"additional ""axis"" parameter and different default values of keras.layers.LayerNormalization","Hello,


**System Info**

Tensorflow Version 2.0 

**Describe the feature and the current behavior/state.**

The current (tensorflow 2.0) implementation of keras.layers.LayerNormalization accepts one argument, ""axis"", specifying the axis that should be normalized. The ""center"" and ""scale"" parameter tensors are created with the same shape as the axis that is normalized. The default of this parameter is '-1', i.e. the normalization, re-centering and re-scaling is over the last axis only.

I think it would be great to adapt the implementation to the behavior of the Tensorflow 1.x implementation in contrib.layers.layer_norm. There, 2 arguments ""begin_norm_axis"" and ""begin_params_axis"" where used. The former specifying the axis to normalize over, the latter to specify the axis to build the center and scale parameters (there called beta and gamma). The default values where ""begin_norm_axis=1"" (i.e. normalize over all axis but the first) and ""begin_param_axis=-1"", i.e. only re-scale and re-center along the last axis. 

**Will this change the current api? How?**

Only the implementation of keras.layers.LayerNormalization would be affected.  Note that keras.layers.LayerNormalization is not part of the ""official"" Keras API so it would not create any conflicts. 

The ""axis"" argument would be replaced by two arguments ""norm_axis"" and ""param_axis"".

**Who will benefit with this feature?**

This is especially relevant for convolutional networks. 
In my experience, the aforementioned default configuration works way better than normalizing, re-scaling and re-centering over a common set of axes.



Best wishes,
Philipp

"
33576,Decorated function tried to create variables on non-first call,"I am training a TM model using transfer and whin I executing the fit(dataset, epochs=3) I got the following error

```
`---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-38-c3f14a31606c> in <module>
      2 EPOCHS = 1
      3 
----> 4 model.fit(dataset, epochs=EPOCHS)

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--> 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    322                 mode=ModeKeys.TRAIN,
    323                 training_context=training_context,
--> 324                 total_epochs=epochs)
    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    326 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    121         step=step, mode=mode, size=current_batch_size) as batch_logs:
    122       try:
--> 123         batch_outs = execution_function(iterator)
    124       except (StopIteration, errors.OutOfRangeError):
    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
     84     # `numpy` translates Tensors to values in Eager mode.
     85     return nest.map_structure(_non_none_constant_value,
---> 86                               distributed_function(input_fn))
     87 
     88   return execution_function

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--> 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    518         # Lifting succeeded, so variables are initialized and we can run the
    519         # stateless function.
--> 520         return self._stateless_fn(*args, **kwds)
    521     else:
    522       canon_args, canon_kwds = \

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   1820   def __call__(self, *args, **kwargs):
   1821     """"""Calls a graph function specialized to the inputs.""""""
-> 1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
   1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   1824 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2148         graph_function = self._function_cache.primary.get(cache_key, None)
   2149         if graph_function is None:
-> 2150           graph_function = self._create_graph_function(args, kwargs)
   2151           self._function_cache.primary[cache_key] = graph_function
   2152         return graph_function, args, kwargs

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2039             arg_names=arg_names,
   2040             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2041             capture_by_value=self._capture_by_value),
   2042         self._function_attributes,
   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    913                                           converted_func)
    914 
--> 915       func_outputs = python_func(*func_args, **func_kwargs)
    916 
    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    356         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    357         # the function a weak reference to itself to avoid a reference cycle.
--> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    359     weak_wrapped_fn = weakref.ref(wrapped_fn)
    360 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in distributed_function(input_iterator)
     71     strategy = distribution_strategy_context.get_strategy()
     72     outputs = strategy.experimental_run_v2(
---> 73         per_replica_function, args=(model, x, y, sample_weights))
     74     # Out of PerReplica outputs reduce or pick values to return.
     75     all_outputs = dist_utils.unwrap_output_dict(

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in experimental_run_v2(self, fn, args, kwargs)
    758       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),
    759                                 convert_by_default=False)
--> 760       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    761 
    762   def reduce(self, reduce_op, value, axis):

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)
   1785       kwargs = {}
   1786     with self._container_strategy().scope():
-> 1787       return self._call_for_each_replica(fn, args, kwargs)
   1788 
   1789   def _call_for_each_replica(self, fn, args, kwargs):

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)
   2130         self._container_strategy(),
   2131         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):
-> 2132       return fn(*args, **kwargs)
   2133 
   2134   def _reduce_to(self, reduce_op, value, destinations):

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    290   def wrapper(*args, **kwargs):
    291     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
--> 292       return func(*args, **kwargs)
    293 
    294   if inspect.isfunction(func) or inspect.ismethod(func):

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics)
    262       y,
    263       sample_weights=sample_weights,
--> 264       output_loss_metrics=model._output_loss_metrics)
    265 
    266   if reset_metrics:

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics)
    313     outs = [outs]
    314   metrics_results = _eager_metrics_fn(
--> 315       model, outs, targets, sample_weights=sample_weights, masks=masks)
    316   total_loss = nest.flatten(total_loss)
    317   return {'total_loss': total_loss,

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py in _eager_metrics_fn(model, outputs, targets, sample_weights, masks)
     72         masks=masks,
     73         return_weighted_and_unweighted_metrics=True,
---> 74         skip_target_masks=model._prepare_skip_target_masks())
     75 
     76   # Add metric results from the `add_metric` metrics.

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in _handle_metrics(self, outputs, targets, skip_target_masks, sample_weights, masks, return_weighted_metrics, return_weighted_and_unweighted_metrics)
   2061           metric_results.extend(
   2062               self._handle_per_output_metrics(self._per_output_metrics[i],
-> 2063                                               target, output, output_mask))
   2064         if return_weighted_and_unweighted_metrics or return_weighted_metrics:
   2065           metric_results.extend(

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in _handle_per_output_metrics(self, metrics_dict, y_true, y_pred, mask, weights)
   2012       with K.name_scope(metric_name):
   2013         metric_result = training_utils.call_metric_function(
-> 2014             metric_fn, y_true, y_pred, weights=weights, mask=mask)
   2015         metric_results.append(metric_result)
   2016     return metric_results

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py in call_metric_function(metric_fn, y_true, y_pred, weights, mask)
   1065 
   1066   if y_pred is not None:
-> 1067     return metric_fn(y_true, y_pred, sample_weight=weights)
   1068   # `Mean` metric only takes a single value.
   1069   return metric_fn(y_true, sample_weight=weights)

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in __call__(self, *args, **kwargs)
    191     from tensorflow.python.keras.distribute import distributed_training_utils  # pylint:disable=g-import-not-at-top
    192     return distributed_training_utils.call_replica_local_fn(
--> 193         replica_local_fn, *args, **kwargs)
    194 
    195   @property

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py in call_replica_local_fn(fn, *args, **kwargs)
   1133     with strategy.scope():
   1134       return strategy.extended.call_for_each_replica(fn, args, kwargs)
-> 1135   return fn(*args, **kwargs)
   1136 
   1137 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in replica_local_fn(*args, **kwargs)
    174     def replica_local_fn(*args, **kwargs):
    175       """"""Updates the state of the metric in a replica-local context.""""""
--> 176       update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable
    177       with ops.control_dependencies([update_op]):
    178         result_t = self.result()  # pylint: disable=not-callable

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py in decorated(metric_obj, *args, **kwargs)
     73 
     74     with tf_utils.graph_context_for_symbolic_tensors(*args, **kwargs):
---> 75       update_op = update_state_fn(*args, **kwargs)
     76     if update_op is not None:  # update_op will be None in eager execution.
     77       metric_obj.add_update(update_op)

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in update_state(self, y_true, y_pred, sample_weight)
    579         y_pred, y_true)
    580 
--> 581     matches = self._fn(y_true, y_pred, **self._fn_kwargs)
    582     return super(MeanMetricWrapper, self).update_state(
    583         matches, sample_weight=sample_weight)

<ipython-input-37-0d57172496e6> in accuracy(y_true, y_pred)
      8     # ensure labels have shape (batch_size, MAX_LENGTH - 1)
      9     y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))
---> 10     accuracy = tf.metrics.SparseCategoricalAccuracy()(y_true, y_pred)
     11     return accuracy
     12 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in __init__(self, name, dtype)
    762   def __init__(self, name='sparse_categorical_accuracy', dtype=None):
    763     super(SparseCategoricalAccuracy, self).__init__(
--> 764         sparse_categorical_accuracy, name, dtype=dtype)
    765 
    766 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in __init__(self, fn, name, dtype, **kwargs)
    552       **kwargs: The keyword arguments that are passed on to `fn`.
    553     """"""
--> 554     super(MeanMetricWrapper, self).__init__(name=name, dtype=dtype)
    555     self._fn = fn
    556     self._fn_kwargs = kwargs

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in __init__(self, name, dtype)
    452     """"""
    453     super(Mean, self).__init__(
--> 454         reduction=metrics_utils.Reduction.WEIGHTED_MEAN, name=name, dtype=dtype)
    455 
    456 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in __init__(self, reduction, name, dtype)
    291     with ops.init_scope():
    292       self.total = self.add_weight(
--> 293           'total', initializer=init_ops.zeros_initializer)
    294       if reduction in [metrics_utils.Reduction.SUM_OVER_BATCH_SIZE,
    295                        metrics_utils.Reduction.WEIGHTED_MEAN]:

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in add_weight(self, name, shape, aggregation, synchronization, initializer, dtype)
    271         collections=[],
    272         synchronization=synchronization,
--> 273         aggregation=aggregation)
    274 
    275   ### End: For use by subclasses ###

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)
    520         collections=collections_arg,
    521         synchronization=synchronization,
--> 522         aggregation=aggregation)
    523     backend.track_variable(variable)
    524 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)
    742         dtype=dtype,
    743         initializer=initializer,
--> 744         **kwargs_for_getter)
    745 
    746     # If we set an initializer and the variable processed it, tracking will not

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in make_variable(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)
    137       synchronization=synchronization,
    138       aggregation=aggregation,
--> 139       shape=variable_shape if variable_shape else None)
    140 
    141 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py in __call__(cls, *args, **kwargs)
    256   def __call__(cls, *args, **kwargs):
    257     if cls is VariableV1:
--> 258       return cls._variable_v1_call(*args, **kwargs)
    259     elif cls is Variable:
    260       return cls._variable_v2_call(*args, **kwargs)

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py in _variable_v1_call(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)
    217         synchronization=synchronization,
    218         aggregation=aggregation,
--> 219         shape=shape)
    220 
    221   def _variable_v2_call(cls,

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py in getter(**kwargs)
     63 
     64   def getter(**kwargs):
---> 65     return captured_getter(captured_previous, **kwargs)
     66 
     67   return getter

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in creator(next_creator, *args, **kwargs)
   2046     def creator(next_creator, *args, **kwargs):
   2047       _require_strategy_scope_strategy(strategy)
-> 2048       return next_creator(*args, **kwargs)
   2049 
   2050     self._var_creator_scope = variable_scope.variable_creator_scope(creator)

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py in getter(**kwargs)
     63 
     64   def getter(**kwargs):
---> 65     return captured_getter(captured_previous, **kwargs)
     66 
     67   return getter

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in creator(next_creator, *args, **kwargs)
   2046     def creator(next_creator, *args, **kwargs):
   2047       _require_strategy_scope_strategy(strategy)
-> 2048       return next_creator(*args, **kwargs)
   2049 
   2050     self._var_creator_scope = variable_scope.variable_creator_scope(creator)

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py in getter(**kwargs)
     63 
     64   def getter(**kwargs):
---> 65     return captured_getter(captured_previous, **kwargs)
     66 
     67   return getter

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in creator(next_creator, *args, **kwargs)
   2046     def creator(next_creator, *args, **kwargs):
   2047       _require_strategy_scope_strategy(strategy)
-> 2048       return next_creator(*args, **kwargs)
   2049 
   2050     self._var_creator_scope = variable_scope.variable_creator_scope(creator)

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py in getter(**kwargs)
     63 
     64   def getter(**kwargs):
---> 65     return captured_getter(captured_previous, **kwargs)
     66 
     67   return getter

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in invalid_creator_scope(*unused_args, **unused_kwds)
    411       """"""Disables variable creation.""""""
    412       raise ValueError(
--> 413           ""tf.function-decorated function tried to create ""
    414           ""variables on non-first call."")
    415 

ValueError: tf.function-decorated function tried to create variables on non-first call.
```"
33574,The choice of the values of the batch size,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):1.13.1
- Python version:3.6.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:9.0/7.5
- GPU model and memory:Nvidia Geforce 840m



**Describe the current behavior**
Scientists over the past years have made significant progress in increasing the speed of neural networks by dividing the data into different patches and their number in the thousands or sometimes millions of images and other data
The splitting into batches makes the neural network more efficient, but .....
In spite of this, the large size of the patches leads to weak results of the neural network often
It is not clear why the size of patches is sometimes appropriate when it is large and sometimes it is appropriate when it is small
But after research, it was concluded that the gradient noise scale can be useful in determining the appropriate patch size
Since it calculates the noise size approximate to the size of the patch and so it can calculate the size of variation in our data from the model point of view

When the noise scale is small, checking and studying a lot of data in parallel becomes fast, while when its volume is large, we can still learn a lot from large batches.
I have a dataset and I would like to train my own dataset to detect the eye region of human with landmarks.
In order to perform a good prediction after training , I would like to know if is it possible to calculate the gradient noise scale and adjust this variable with Tensorflow library to get a good value of the batch size?

**Code to reproduce the issue**
I used this simple CNN to detect the eye region:
https://github.com/yinguobing/cnn-facial-landmark


Thanks.
"
33573,Cannot find the placeholder op that is an input to ReadVariableOp.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 4.15.0-62-generic
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary
- TensorFlow version: tensorflow-gpu 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source): no
- GCC/Compiler version (if compiling from source): no
- CUDA/cuDNN version:  V10.0.130
- GPU model and memory: rtx 2060 6gb


**Describe the current behavior**
I'm unable to perform post-training quantization on my V2 model. 

**Code to reproduce the issue**
```
from tensorflow.keras import layers
from tensorflow.keras import optimizers
from tensorflow.keras.datasets import cifar100
import numpy as np
import tensorflow as tf
from tensorflow import keras
keras.backend.clear_session()
keras.backend.set_learning_phase(0)
from tensorflow.python.compiler.tensorrt import trt_convert as trt
import os

os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

(x_train, y_train), (x_test, y_test) = cifar100.load_data()
x_train = np.float32(x_train)[:64*(x_train.shape[0]//64)]
x_train /= 255.0
i_shape = x_train[0].shape

inputs = layers.Input(i_shape)
base_model = keras.models.Sequential([
    layers.Conv2D(128, 3, padding='same', strides=(2, 2)),
    layers.BatchNormalization(),
    layers.LeakyReLU(0.2),

    layers.Conv2D(256, 3, padding='same', strides=(2, 2)),
    layers.BatchNormalization(),
    layers.LeakyReLU(0.2),

    layers.Conv2D(512*100, 3, padding='same', strides=(2, 2)),
    layers.BatchNormalization(),
    layers.LeakyReLU(0.2),
    layers.Flatten(),
    layers.Dense(5*128),
    layers.Reshape((5, 128)),
    layers.LSTM(128),
    layers.Flatten(),
])(inputs)

prediction = layers.Dense(100, activation='softmax')(base_model)
model = keras.Model(inputs=inputs, outputs=prediction)
optimizer = optimizers.Adam(0.00001)
model.compile(optimizer, 'categorical_crossentropy', metrics=['accuracy'])
print(model.summary())
saved_model_dir = os.getcwd()
output_directory = os.getcwd()
tf.saved_model.save(model, saved_model_dir)

# graph quantization
loaded = tf.saved_model.load(saved_model_dir)

params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(
    precision_mode='FP16',
    is_dynamic_op=True,
    maximum_cached_engines=16)
converter = trt.TrtGraphConverterV2(
    input_saved_model_dir=saved_model_dir,
    input_saved_model_tags=""serve"",
    input_saved_model_signature_key=""serving_default"",
    conversion_params=params)
converter.convert()
saved_model_dir_trt = output_directory
converter.save(saved_model_dir_trt)
```

**Other info / logs**
```
Traceback (most recent call last):
  File ""optimize_graphv2.py"", line 33, in <module>
    main(args)
  File ""optimize_graphv2.py"", line 22, in main
    converter.convert()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/compiler/tensorrt/trt_convert.py"", line 960, in convert
    frozen_func = convert_to_constants.convert_variables_to_constants_v2(func)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/convert_to_constants.py"", line 479, in convert_variables_to_constants_v2
    raise ValueError(""Cannot find the Placeholder op that is an input ""
ValueError: Cannot find the Placeholder op that is an input to the ReadVariableOp.
```"
33572,[tflite] Support INT8 quantization for PACK with TFLITE_BUILTINS_INT8 OpsSet,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14 
- Python version: 3.6

**Describe the current behavior**
Similar to the UNPACK node issue in https://github.com/tensorflow/tensorflow/issues/31902, the new TFLiteConverter post-training quantisation flow, as described in https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization_of_weights_and_activations, does not support quantization of PACK/STACK operation when only integer operations are requested in the output model. When such conversion is attempted the following error is reported:
> RuntimeError: Quantization not yet supported for op: PACK

**Code to reproduce the issue**
For example, the script below:
```python
import tensorflow as tf
import numpy as np

def representative_dataset_gen():
	input_1 = np.ones([1, 10],dtype=np.float32)
	input_2 = np.ones([1, 10],dtype=np.float32)
	for _ in range(10):
		yield [input_1, input_2]

# tf Graph Input
foo = tf.compat.v1.placeholder(""float32"", [1, 10])
bar = tf.compat.v1.placeholder(""float32"", [1, 10])
out_stacked = tf.stack([foo, bar], axis=0)

with tf.compat.v1.Session() as sess:
	tf.io.write_graph(tf.compat.v1.get_default_graph(), '.','pack.pb', as_text=False)

input_name = [""Placeholder"", ""Placeholder_1""]
output_name = [""stack""]

tflite_model_name = ""int8_pack.tflite""
converter = tf.lite.TFLiteConverter.from_frozen_graph(""pack.pb"", input_name, output_name)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.representative_dataset = representative_dataset_gen
tflite_model = converter.convert()
open(tflite_model_name, ""wb"").write(tflite_model)

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(tflite_model_name)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test model on random input data.
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)
interpreter.invoke()`
```
produces errors as follows:
```
2019-10-21 14:02:33.682706: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-21 14:02:33.708278: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz
2019-10-21 14:02:33.708892: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x33f5a60 executing computations on platform Host. Devices:
2019-10-21 14:02:33.708924: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 14:02:33.717107: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-10-21 14:02:33.717228: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
INFO: Initialized TensorFlow Lite runtime.
Traceback (most recent call last):
  File ""pack_example.py"", line 26, in <module>
    tflite_model = converter.convert()
  File ""/home/jaszha02/Work/venvs/audio/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 908, in convert
    inference_output_type)
  File ""/home/jaszha02/Work/venvs/audio/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 200, in _calibrate_quantize_model
    inference_output_type, allow_float)
  File ""/home/jaszha02/Work/venvs/audio/lib/python3.6/site-packages/tensorflow/lite/python/optimize/calibrator.py"", line 78, in calibrate_and_quantize
    np.dtype(output_type.as_numpy_dtype()).num, allow_float)
  File ""/home/jaszha02/Work/venvs/audio/lib/python3.6/site-packages/tensorflow/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py"", line 115, in QuantizeModel
    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, input_py_type, output_py_type, allow_float)
RuntimeError: Quantization not yet supported for op: PACK
```
Both kTfLiteUInt8 and kTfLiteInt8 version of the PACK operator is already implemented in TFLite (see [pack.cc](https://github.com/tensorflow/tensorflow/blob/186e794d71c17b52deb52ace151ec5add8525f2c/tensorflow/lite/kernels/pack.cc)), so it should be straightforward to support PACK as well in the TFLite Converter."
33571,Tracing of first batch does not collect compute events,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: unknown
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version: 3.6.9
- CUDA/cuDNN version: none
- GPU model and memory: none

**Describe the current behavior**

Using `profile_batch=1` for `tf.keras.callbacks.TensorBoard` does not collect any compute calls in the profile/trace

**Describe the expected behavior**

Similar timeline shown as for e.g. `profile_batch=2`.

**Code to reproduce the issue**
```
import tensorflow_datasets as tfds
import tensorflow as tf
import datetime
import os

tf.config.threading.set_inter_op_parallelism_threads(1)

datasets, info = tfds.load(name='mnist',
                           with_info=True,
                           as_supervised=True,
                           shuffle_files=False)

mnist_train, mnist_test = datasets['train'], datasets['test']
strategy = tf.distribute.OneDeviceStrategy(""/cpu:0"")

num_train_examples = info.splits['train'].num_examples

BATCH_SIZE_PER_REPLICA = 64
BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync


def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255
    return image, label


train_dataset = mnist_train.map(scale).cache().shuffle(
    num_train_examples).batch(BATCH_SIZE)
eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)

log_dir = ""/tmp/tf_logs/fit/"" + datetime.datetime.now().strftime(
    ""%Y%m%d-%H%M%S"")

with strategy.scope():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32,
                               3,
                               activation='relu',
                               input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])

    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=tf.keras.optimizers.Adam(),
                  metrics=['accuracy'])

    callbacks = [
            tf.keras.callbacks.TensorBoard(log_dir=log_dir,
                                           histogram_freq=0,
                                           profile_batch=1)
    ]
    model.fit(train_dataset, epochs=3, steps_per_epoch=20, callbacks=callbacks)
```

**Other info / logs**
[epoch1.zip](https://github.com/tensorflow/tensorflow/files/3750929/epoch1.zip)
[epoch2.zip](https://github.com/tensorflow/tensorflow/files/3750930/epoch2.zip)

When opening the trace in TensorBoard there is a lot of ""stuff"" in epoch1, but no ""tf_compute"" section as with epoch2"
33570, different results in inference between python and c++ ,"
hi, i'm doing a re identification network, implementing a triplet-loss function, at that point everything is fine. the networks works fine in python, I implemented the network on keras with tensorflow as backend, I passed the .hd5 to a .pb file to make inference in tensorflow c++, the probmes is that with the same images the result is difference between python and c++ and I don't know why anyone to help me? 
here is the the model in python: 

import keras
import keras.applications
import keras.layers as layer
import tensorflow as tf
from keras import backend as K
from keras.backend.tensorflow_backend import set_session
from keras.models import Model as md

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
config.log_device_placement = True
sess = tf.Session(config=config)
set_session(sess)


class Model:
    def __init__(self, shape):
        self.shape = shape
        self.params = {
            'optimizer': 'sgd',
            'first_neuron': 12,
            'first_max_pooling': 2,
            'second_neuron': 12,
            'second_max_pooling': 2,
            'third_neuron': 20,
            'third_max_pooling': 3,
            'dense_neuron': 64,
            'final_neuron': 128,
        }
        self.feature_model = self.create_features_model()
        self.triplet_model = self.create_model()

    def create_features_model(self):
        # Define the vision modules
        img_input = layer.Input(shape=(self.shape))
        x = layer.Conv2D(self.params['first_neuron'], (3, 3), activation='relu')(img_input)
        x = layer.MaxPooling2D((self.params['first_max_pooling'], self.params['first_max_pooling']))(x)
        x = layer.Conv2D(self.params['second_neuron'], (3, 3), activation='relu')(x)
        x = layer.MaxPooling2D((self.params['second_max_pooling'], self.params['second_max_pooling']))(x)

        x = layer.Conv2D(self.params['third_neuron'], (3, 3), activation='relu')(x)
        x = layer.MaxPooling2D((self.params['third_max_pooling'], self.params['third_max_pooling']))(x)

        x = layer.Flatten()(x)
        x = layer.Dense(self.params['dense_neuron'], activation='relu')(x)
        x = layer.Dense(self.params['final_neuron'], activation='relu')(x)
        out = layer.Lambda(lambda x: K.l2_normalize(x, axis=1), name='t_emb_1_lnorm')(x)
        features_model = md(img_input, out)

        features_model.summary()
        return features_model

    def create_model(self):
        base_model = self.feature_model
        # triplet framework, shared weights
        input_shape = (self.shape)
        input_target = layer.Input(shape=input_shape, name='input_target')
        input_positive = layer.Input(shape=input_shape, name='input_pos')
        input_negative = layer.Input(shape=input_shape, name='input_neg')

        net_target = base_model(input_target)
        net_positive = base_model(input_positive)
        net_negative = base_model(input_negative)

        # The Lamda layer produces output using given function. Here its Euclidean distance.
        positive_distance = layer.Lambda(self.euclidean_distance, name='pos_dist')([net_target, net_positive])
        negative_distance = layer.Lambda(self.euclidean_distance, name='neg_dist')([net_target, net_negative])
        diference = layer.Lambda(self.euclidean_distance, name='dif')([net_positive, net_negative])

        # This lambda layer simply stacks outputs so both distances are available to the objective
        distances = layer.Lambda(lambda vects: K.stack(vects, axis=1), name='distance')(
            [positive_distance, negative_distance, diference])

        model = md([input_target, input_positive, input_negative], distances, name='result')

        # Setting up optimizer designed for variable learning rate

        model.compile(optimizer=keras.optimizers.Adam(lr=0.001, decay=0.00002),
                      loss=self.triplet_loss, metrics=[self.accuracy])

        return model

    def triplet_loss(self, _, y_pred):
        margin = K.constant(0.5)
        return K.mean(K.maximum(K.constant(0), K.square(y_pred[:, 0, 0]) - 0.5 * (
                K.square(y_pred[:, 1, 0]) + K.square(y_pred[:, 2, 0])) + margin))

    def accuracy(self, _, y_pred):
        return K.mean(y_pred[:, 0, 0] < y_pred[:, 1, 0])

    def lnorm(self, x):
        return K.l2_normalize(x, axis=-1)

    def euclidean_distance(self, vects):
        x, y = vects
        return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))

and this si how I made inference in python:


from model import Model as model
from keras.utils import HDF5Matrix
import numpy as np
import cv2
from keras.backend.tensorflow_backend import set_session
import tensorflow as tf

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
config.log_device_placement = True
sess = tf.Session(config=config)
set_session(sess)


def load_datasets(in_h5_path, partition='train'):
    if partition == 'train':
        target = HDF5Matrix(datapath=in_h5_path, dataset=""targets"")
        positive = HDF5Matrix(datapath=in_h5_path, dataset=""positives"")
        negative = HDF5Matrix(datapath=in_h5_path, dataset=""negatives"")
        return target, positive, negative

    else:
        print(""Invalid 'partition' parameter: Valid values: ['train', 'test']"")


tar = cv2.imread(""/home/amejia/PycharmProjects/triplet_loss/tra1.png"")
nega = cv2.imread(""/home/amejia/PycharmProjects/triplet_loss/dec1.png"")

tar = cv2.resize(tar, (32, 32), interpolation=cv2.INTER_CUBIC)
nega = cv2.resize(nega, (32, 32), interpolation=cv2.INTER_CUBIC)
t1 = np.array(tar).reshape((1, 32, 32, 3))
t2 = np.array(nega).reshape((1, 32, 32, 3))
target, positive, negative = load_datasets('/home/amejia/PycharmProjects/lossDatasetGenerator/test/test32.h5')
net = model((32, 32, 3))
net.triplet_model.load_weights(""/home/amejia/PycharmProjects/triplet_loss/simple-grande.hdf5"")
enter = [t1, t2, t1]
a = net.triplet_model.predict(x=enter, batch_size=1)
print(a)

in c++ this si how I made inference:

 tensorflow::Tensor target(tensorflow::DT_FLOAT,
                              tensorflow::TensorShape(
                                      {1, image_size, image_size, 3}));
    tensorflow::Tensor positive(tensorflow::DT_FLOAT,
                                tensorflow::TensorShape(
                                        {1, image_size, image_size, 3}));

    img_to_float2(tracks, detections, target, positive, frame);


    std::vector<std::pair<std::string, tensorflow::Tensor>> Input = {{""input_target:0"", target},
                                                                     {""input_pos:0"",    positive},
                                                                     {""input_neg:0"",    target}};
    std::vector<tensorflow::Tensor> Outputs;

    tensorflow::Status Status = session->Run(Input, {""distance/stack:0""}, {}, &Outputs);

    auto data = Outputs[0].flat<float>();

    std::cout << Outputs[0].DebugString() << std::endl;

and this is the fucntion to put the imges into the tensors:

void LossModel::img_to_float2(Track &tracks, Detection &detections, tensorflow::Tensor &tracksTensor,
                              tensorflow::Tensor &detectionsTensor, cv::Mat &frame) {


    auto *tar = tracksTensor.flat<float>().data();
    auto *dec = detectionsTensor.flat<float>().data();
    cv::Mat detectionImg = frame(detections.getBox()).clone();

    resize(detectionImg, detectionImg, cv::Size(FEATURES_IMG_SIZE, FEATURES_IMG_SIZE), 0, 0,
           cv::INTER_CUBIC);
    cv::Mat resizedImage(FEATURES_IMG_SIZE, FEATURES_IMG_SIZE, CV_32FC3, dec);
    detectionImg.convertTo(resizedImage, CV_32FC3);

    cv::Mat trackImg = tracks.get_img().clone();

    resize(trackImg, trackImg, cv::Size(FEATURES_IMG_SIZE, FEATURES_IMG_SIZE), 0, 0,
           cv::INTER_CUBIC);
    cv::Mat resizedImage2(FEATURES_IMG_SIZE, FEATURES_IMG_SIZE, CV_32FC3, tar);
    trackImg.convertTo(resizedImage2, CV_32FC3);

I hope someone can help me thanks "
33569,tensorflow-1.15.0 manylinux wheel on PyPi is invalid,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.7.1908 (Core)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 1.15.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: virtualenv pip
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the problem**

The published manylinux wheel of tensorflow 1.15.0 on Pypi is invalid:
https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl

(1.14.0 & 2.0.0 manylinux wheels work fine)

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
[f.horing] ~/tmp $python3.6 -m venv venv
[f.horing] ~/tmp $. venv/bin/activate
(venv) [f.horing] ~/tmp $pip install wheel
Collecting wheel
  Downloading http://build-nexus.prod.crto.in/repository/pypi/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl
Installing collected packages: wheel
Successfully installed wheel-0.33.6
You are using pip version 9.0.3, however version 19.3.1 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.
(venv) [f.horing] ~/tmp $python
Python 3.6.8 (default, Aug  7 2019, 17:28:10)
[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from wheel.wheelfile import WheelFile
>>> wf = WheelFile(""tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl"")
>>> wf.extractall(""/tmp"")
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/lib64/python3.6/zipfile.py"", line 1524, in extractall
    self._extract_member(zipinfo, path, pwd)
  File ""/usr/lib64/python3.6/zipfile.py"", line 1579, in _extract_member
    shutil.copyfileobj(source, target)
  File ""/usr/lib64/python3.6/shutil.py"", line 79, in copyfileobj
    buf = fsrc.read(length)
  File ""/usr/lib64/python3.6/zipfile.py"", line 872, in read
    data = self._read1(n)
  File ""/usr/lib64/python3.6/zipfile.py"", line 962, in _read1
    self._update_crc(data)
  File ""/home/f.horing/tmp/venv/lib64/python3.6/site-packages/wheel/wheelfile.py"", line 91, in _update_crc
    raise WheelError(""Hash mismatch for file '{}'"".format(native(ef_name)))
wheel.cli.WheelError: Hash mismatch for file 'tensorflow-1.15.0.dist-info/METADATA'
>>> wf = WheelFile(""tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl"")
>>> wf.extractall(""/tmp"")
>>> wf = WheelFile(""tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl"")
>>> wf.extractall(""/tmp"")
>>>

```


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

We would like to upgrade to tf 1.15 first before upgrading to 2.0.0
"
33567,Failure to load and remap a 2-D Tensor from checkpoint when variance scaling initializer is used,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution:
os: Darwin
os kernel version: Darwin Kernel Version 17.7.0: Wed Feb 27 00:43:23 PST 2019; root:xnu-4570.71.35~1/RELEASE_X86_64
os release version: 17.7.0
os platform: Darwin-17.7.0-x86_64-i386-64bit
linux distribution: ('', '', '')
linux os distribution: ('', '', '')
mac version: ('10.13.6', ('', '', ''), 'x86_64')
- TensorFlow installed from (source or binary): NO
- TensorFlow version (use command below):
tf.version.VERSION = 1.14.0
tf.version.GIT_VERSION = v1.14.0-rc1-22-gaf24dc91b5
tf.version.COMPILER_VERSION = 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.5)
- Python version:
(major, minor, micro, releaselevel, serial)
(2, 7, 15, 'final', 0)
- Bazel version (if compiling from source): NO
- GCC/Compiler version (if compiling from source): NO
- CUDA/cuDNN version: NO
- GPU model and memory: NO

**Describe the current behavior**
I train with the estimator api and I wish to warm start a 2d variable (which I use as embedding). My old model has different embedding vocabulary than the new one so I pass a WarmStartSettings structure including tf.estimator.VocabInfo.
If I pass tf.estimator.VocabInfo without specifying a backup_initializer, the 0 initializer is used as default and the warm start and training finish successfully. However when I pass a backup_initializer, like tf.compat.v1.initializers.variance_scaling, I get a TypeError, which it looks like is caused because the initializer requires that its shape is a non Tensor, but the gen_checkpoint_ops.generate_vocab_remapping returns Tensors which are passed to the initilizer as shape.

**Describe the expected behavior**
Ability to load and remap a 2-D Tensor from a checkpoint when a custom initializer is used. So eventually be able to warm start whenever my new model embeddings have different vocabularies than the old

**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow.python.training import checkpoint_ops

if __name__ == '__main__':
    initializer = tf.compat.v1.initializers.variance_scaling(scale=0.175, mode=""fan_in"", distribution='uniform')

    old_row_vocab_file = './old_vocab_path'  # text file with 2 rows
    new_row_vocab_file = './new_vocab_path'  # text file with 2 rows

    checkpoint_ops._load_and_remap_matrix(ckpt_path='', old_tensor_name='old_tensor/name', new_row_vocab_offset=0,
                                          num_rows_to_load=2, new_col_vocab_size=3, initializer=initializer,
                                          old_row_vocab_size=-1, old_row_vocab_file=old_row_vocab_file,
                                          new_row_vocab_file=new_row_vocab_file)
```

**Other info / logs**
```
File ""/env/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1365, in _train_with_estimator_spec
    warm_starting_util.warm_start(*self._warm_start_settings)
  File ""/env/lib/python2.7/site-packages/tensorflow/python/training/warm_starting_util.py"", line 460, in warm_start
    axis=vocab_info.axis)
  File ""/env/lib/python2.7/site-packages/tensorflow/python/training/warm_starting_util.py"", line 301, in _warm_start_var_with_vocab
    init(shape=v_shape, partition_info=partition_info))
  File ""/env/lib/python2.7/site-packages/tensorflow/python/training/checkpoint_ops.py"", line 414, in _initializer
    max_rows_in_memory=max_rows_in_memory)
  File ""/env/lib/python2.7/site-packages/tensorflow/python/training/checkpoint_ops.py"", line 179, in _load_and_remap_matrix
    num_rows_present * num_cols_present, 1
  File ""/env/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py"", line 515, in __call__
    fan_in, fan_out = _compute_fans(scale_shape)
  File ""/env/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py"", line 1447, in _compute_fans
    return int(fan_in), int(fan_out)
TypeError: int() argument must be a string or a number, not 'Tensor'
```
"
33566,TimeseriesGenerator for labeled time-series such as sensor data,"**System information**
- TensorFlow version: v2.0.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
Currently,  `TimeseriesGenerator` gets `data` and `target` as input and return a generator that can be used for iterating over a time-series with a sliding window.
- If `row` is the current time-point,  then for each time-window of length `[row - self.length, ..., row`] , the  `target` is chosen as the`self.targets[row]`.  This means the `target` (label) for a time-window is chosen to be the last observed label.

Sometimes, this is not the right assumption. For example, consider this time-series and the related labels:
```python
data    = [a,a,a,a,a,a,a,a,a,a,a,b,b,b,b,b,b,b,b,b,b,b,b,b,c,c,c,c,c,c,c,c]
target =  [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2]
```
If we choose `length=8` and `stride=4`, then it generates these windows:
```python
a,a,a,a,a,a,a,a >  0  (Good label!)
a,a,a,a,a,a,a,b >  1  (Bad label!)
a,a,a,b,b,b,b,b > 1 (Not Good label!)
b,b,b,b,b,b,b,b > 1 (Good label!)
b,b,b,b, c,c,c,c > 2 (Bad label!)
c,c,c,c,c,c,c,c, > 2 (Good label!)
```
So, as you see, if I use this method in training (e.g. for an activity recognition method based on accelerometer time-seires) then some windows will be labeled in a Not Good way!

**There should be a feature to choose if we want this behavior or not!**

There are two ideas:
1. to simply ignore these windows with an inconsistent label in the beginning and the end! I mean just jump over them until we get a window that label is same for all the time-points. like this:
```python
targets = np.array([self.targets[row] for row in rows if self.targets[row - self.length] == self.targets[row]])
```
2. Using the `mode` of the target window as the label. like this:
```python 
targets = np.array([ max(set(self.targets[row - self.length:row:self.sampling_rate] ), key=list.count) for row in rows])
```

**Will this change the current api? How?**
There are two ways to handle this:
1.  To add more options to the current `TimeseriesGenerator` that will change the current api for this class.
2. To add another class and call it something like ""LabeledTimeseriesGenerator"" that extends the `TimeseriesGenerator` and overrides the `__getitem__` function.

**Who will benefit with this feature?**
People who use Tensorflow for training a classifier on labeled time-series of mobile and wearable sensors or using financial data time-series."
33565,Keras Model cannot be saved as .h5 when tf.keras.backend.clip is used,"
**System information**
- Tensorflow 2.0.0
- Python 3.7.4

**Current behavior**
I'm using the `tf.keras.backend.clip` function in a model and cannot save it because of a naming problem: Two layers have the same name (see `tf_op_layer_clib_by_value_16` in the ModelToDot output below). This causes a problem when exporting it to hdf5.

Couldn't find a workaround or way to rename one of the two layers.

**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow import keras

input1 = keras.layers.Input(shape = (16,), name = iname)
dense1 = keras.layers.Dense(1, name = 'dense1', activation = None, # relu
                       #kernel_initializer=keras.initializers.constant(dAB1_kernel),
                       #kernel_constraint=keras.constraints.NonNeg(),
                       use_bias=True)(input1)
dense1_clip = tf.keras.backend.clip(dense1,min_value = 0, max_value = 1000)

model1 = keras.Model(input1, dense1_clip)

```

![bug](https://user-images.githubusercontent.com/47213738/67195858-0606e700-f3fa-11e9-8ad4-80d6f425fe63.PNG)



**Other info / logs**
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-179-97bae6c176be> in <module>
      7 
      8 model1 = keras.Model(input1, dense1_clip)
----> 9 model1.save('m1.h5')

d:\programme\python37\lib\site-packages\tensorflow_core\python\keras\engine\network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
    973     """"""
    974     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,
--> 975                       signatures, options)
    976 
    977   def save_weights(self, filepath, overwrite=True, save_format=None):

d:\programme\python37\lib\site-packages\tensorflow_core\python\keras\saving\save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    110           'or using `save_weights`.')
    111     hdf5_format.save_model_to_hdf5(
--> 112         model, filepath, overwrite, include_optimizer)
    113   else:
    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,

d:\programme\python37\lib\site-packages\tensorflow_core\python\keras\saving\hdf5_format.py in save_model_to_hdf5(model, filepath, overwrite, include_optimizer)
    107     model_weights_group = f.create_group('model_weights')
    108     model_layers = model.layers
--> 109     save_weights_to_hdf5_group(model_weights_group, model_layers)
    110 
    111     # TODO(b/128683857): Add integration tests between tf.keras and external

d:\programme\python37\lib\site-packages\tensorflow_core\python\keras\saving\hdf5_format.py in save_weights_to_hdf5_group(f, layers)
    623 
    624   for layer in layers:
--> 625     g = f.create_group(layer.name)
    626     weights = _legacy_weights(layer)
    627     weight_values = K.batch_get_value(weights)

d:\programme\python37\lib\site-packages\h5py\_hl\group.py in create_group(self, name, track_order)
     66             name, lcpl = self._e(name, lcpl=True)
     67             gcpl = Group._gcpl_crt_order if track_order else None
---> 68             gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
     69             return Group(gid)
     70 

h5py\_objects.pyx in h5py._objects.with_phil.wrapper()

h5py\_objects.pyx in h5py._objects.with_phil.wrapper()

h5py\h5g.pyx in h5py.h5g.create()

ValueError: Unable to create group (name already exists)
```

"
33564,TFLite metal delegate can't share MTLDevice,"**System information**
- TensorFlow version (you are using):master branch
- Are you willing to contribute it (Yes/No):Yes

**Describe the feature and the current behavior/state.**
As Apple [the official document](https://developer.apple.com/library/archive/documentation/3DDrawing/Conceptual/MTLBestPracticesGuide/PersistentObjects.html) mentioned, all apps should create only one MTLDevice object.

> All apps should create only one MTLDevice object per GPU and reuse it for all your Metal work on that GPU. Most apps should create only one MTLCommandQueue object per GPU, though you may want more if each command queue represents different Metal work (for example, non-real-time compute processing and real-time graphics rendering)..

However, the current TFLite implementation doesn't have the interface to share MTLDevice as [metal_delegate.mm](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/metal_delegate.mm) shows.

```mm
  explicit Delegate(const TFLGpuDelegateOptions* options) {
    if (options) {
      options_ = *options;
    } else {
      // Default options.
      options_.allow_precision_loss = false;
      options_.wait_type = TFLGpuDelegateWaitType::TFLGpuDelegateWaitTypePassive;
    }
    metal_device_ = MTLCreateSystemDefaultDevice();
```
This issue is critical for me since I should integrate TFLite into the existing metal application.
Would you like to improve this initialization function?
One of my idea is that adds default MTLDevice parameter to TFLGpuDelegateOptions.
If you need, I will send PR.
"
33563,tf.io.GFIle not working correctly with UTF-8 files and Python3,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu
- TensorFlow installed from (source or binary): source internal Google
- TensorFlow version (use command below): 1.5.0, internal Google
- Python version: 3.6.7

**Describe the current behavior**
Calling 'read(X)' on the text files opened with GFile in python3 doesn't work properly (it fetches X bytes rather than X characters). This often results with the UnicodeDecodeError (as the read can happen in the middle of the unicode character).

**Describe the expected behavior**
It should behave like python3: reading the X characters.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
my_text = 'Bären'
with open('/tmp/ex1', 'w') as f:
  f.write(my_text)

// Will read the whole string correctly.
with open('/tmp/ex1', 'r') as f:
  print(f.read())

// This will print 2 chars Ba
with open('/tmp/ex1', 'r') as f:
 print(f.read(2))

// This will print 3 chars: Bar
with open('/tmp/ex1', 'r') as f:
 print(f.read(3))

// This will print the whole thing.
with tf.io.gfile.GFile('/tmp/ex1', 'r') as f:
  print(f.read())

// This will crash.. :-(
with tf.io.gfile.GFile('/tmp/ex1', 'r') as f:
  print(f.read(2))
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

The error will be:
```
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 1: unexpected end of data
```
"
33562,"symbol ""_SaverDef_default_instance_"" becomes undefined after updating tensorflow from 1.2 to 1.12","symbol ""_SaverDef_default_instance_"" becomes undefined after updating tensorflow from 1.2 to 1.12

what dependency shoud i add to BUILD file?

_SaverDef_default_instance_ is in cc file generated by tensorflow/core/framework/saver.proto in 1.2

in 1.12, saver.proto is not compiled. has the target changed?

the dependency targets in BUILD are:
       ""//tensorflow/cc:cc_ops"",
        ""//tensorflow/cc:client_session"",
        ""//tensorflow/core:tensorflow""



Env Info:
tensorflow:  HEAD detached at v1.12.1
                    https://github.com/tensorflow/tensorflow.git

```shell
commit c20310273f663b1dbf9ca9e68068784d44a95ae2
Merge: cc494ee f303882
Author: TensorFlower Gardener <gardener@tensorflow.org>
Date:   Thu Apr 18 06:15:58 2019 -0700

    Merge pull request #27699 from yongtang:27497-ragged-axis
    
    PiperOrigin-RevId: 244173513
```

bazel:  get from https://releases.bazel.build/0.25.0/rc3/index.html

os: centos7 
kernel: 3.10.107 
gcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC)
cpu:
```shell
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                8
On-line CPU(s) list:   0-7
Thread(s) per core:    1
Core(s) per socket:    8
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 94
Model name:            Intel(R) Xeon(R) Gold 61xx CPU
Stepping:              3
CPU MHz:               2494.140
BogoMIPS:              4988.28
Hypervisor vendor:     KVM
Virtualization type:   full
L1d cache:             32K
L1i cache:             32K
L2 cache:              4096K
NUMA node0 CPU(s):     0-7
```


dir structure: tensorflow-1.12(git root)/tensorflow/my_implement/BUILD
BUILD file:
```shell
cc_binary(
    name = ""libMyImplement.so"",
    srcs = [""my_implement.h"",
            ""my_implement.cc"",
            ],
    linkshared = 1,
    deps = [
        ""//tensorflow/cc:cc_ops"",
        ""//tensorflow/cc:client_session"",
        ""//tensorflow/core:tensorflow""
        ],
)
```




it reports symbol ""_SaverDef_default_instance_"" undefined while loading libMyImplement.so which compiled in v1.12.1

i think maybe something i forget to add to deps list. or should i execute some ./configure command with any special parameter before compiling?

there is no errors loading libMyImplement.so compiled in tensorflow v1.2.0

and i have tried compile libMyImplement.so in tensorflow v1.13, and there is still this error"
33561, python 3.8 package,"please release python 3.8 package.
"
33560,BatchMatmul on GPU Wrong Result,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
-  Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): pip install tensorflow-gpu
- TensorFlow version (use command below): 2.0
- Python version: 3.7.3
- CUDA/cuDNN version:
- GPU model and memory:Quadro P4000 8GB

**Describe the current behavior**

batchmatmul on gpu gives wrong result.

**Describe the expected behavior**

batchmatmul should give correct result.

**Code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf
H, W = 480, 640
xs = tf.random.normal((H, W, 3))
m = tf.random.normal((3, 3))
with tf.device('/gpu:0'):
  mvgpu = tf.linalg.matvec(m[None, None, None, :, : ], xs[None])

with tf.device('cpu:0'):
  mvcpu = tf.linalg.matvec(m[None, None, None, :, : ], xs[None])

diff = mvgpu - mvcpu
print(diff) # a lot of large differences
assert not np.allclose(diff, 0)
```

**Other info / logs**
python diff.py 
tf.Tensor(
[[[[ 0.          0.          0.        ]
   [ 0.          0.          0.        ]
   [ 0.          0.          0.        ]
   ...
   [ 0.          0.          0.        ]
   [ 0.          0.          0.        ]
   [ 0.          0.          0.        ]]

  [[ 0.          0.          0.        ]
   [ 0.          0.          0.        ]
   [ 0.          0.          0.        ]
   ...
   [ 0.          0.          0.        ]
   [ 0.          0.          0.        ]
   [ 0.          0.          0.        ]]

  [[ 0.          0.          0.        ]
   [ 0.          0.          0.        ]
   [ 0.          0.          0.        ]
   ...
   [ 0.          0.          0.        ]
   [ 0.          0.          0.        ]
   [ 0.          0.          0.        ]]

  ...

  [[ 2.7437444  -2.3577256   3.3067198 ]
   [ 1.0874022  -0.7325933   2.4926019 ]
   [-2.3672104   1.6497741  -2.1795664 ]
   ...
   [-1.4023315   0.68545413 -1.9975882 ]
   [-0.44164103 -1.6766946  -0.6477224 ]
   [ 2.5612988   0.7603723   4.286979  ]]

  [[-0.9761815   1.5332515  -0.12404668]
   [ 1.871354   -0.73664904 -1.0545558 ]
   [-1.2774239   1.6571116  -2.36473   ]
   ...
   [ 2.4847538  -1.5389507   1.5169847 ]
   [ 2.2117858  -3.3593345  -0.15468699]
   [ 0.82464755 -2.0175495  -0.11506134]]

  [[ 2.8697317   0.54362947 -0.10824746]
   [ 1.6531861  -4.2324843   0.97695297]
   [ 4.3966837  -3.0250916   1.8032213 ]
   ...
   [ 4.5854487  -2.0374475  -1.1027236 ]
   [-2.7206469   0.864337   -1.3582373 ]
   [-0.98220587  0.53226703 -4.277097  ]]]], shape=(1, 480, 640, 3), dtype=float32)

"
33558,Dev-board Interpretere Runtime Error,"I am working on the Coral dev board. I'm trying to deploy a segmentation model on it. When I'm running my deep lab segmentation model it is giving me the following error-

```
Traceback (most recent call last):
  File ""infer.py"", line 17, in <module>
    interpreter.allocate_tensors()
  File ""/home/mendel/.local/lib/python3.5/site-packages/tflite_runtime/interpreter.py"", line 244, in allocate_tensors
    return self._interpreter.AllocateTensors()
  File ""/home/mendel/.local/lib/python3.5/site-packages/tflite_runtime/interpreter_wrapper.py"", line 114, in AllocateTensors
    return _interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
RuntimeError: Internal: :71 tf_lite_type != kTfLiteUInt8 (9 != 3)Node number 79 (EdgeTpuDelegateForCustomOp) failed to prepare.
```
The model and script are working fine if I don't make it TPU compatible using edgetpu_compiler.

**Code to reproduce the issue**
```
from tqdm import tqdm
import numpy as np
from tflite_runtime.interpreter import Interpreter
from tflite_runtime.interpreter import load_delegate

test_data = np.random.rand(480,480,3)
img = np.array([test_data], dtype=np.float32)

interpreter = Interpreter(
      model_path=""deep_lab_quant_edgetpu.tflite"",
      experimental_delegates=[load_delegate('libedgetpu.so.1.0')])

interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
interpreter.set_tensor(input_details[0]['index'], img)
interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
```


"
33557,Support for Mediapipe tflite ops.,"**System information**
- TensorFlow version (you are using): 2.0 
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Mediapipe gives some custom implementation for few operators that can run only in Android GPU (Maxunpooling, Maxpoolingwithargmax2d, Convolution2dtransposebias). In tensorflow github repository, they have been mentioned as custom ops. But could not find out implementation for the same.Android GPU delegate does not run the model, and fails with error it is unresolved custom op.

**Will this change the current api? How?**
No. It will be one another addition to the already existing operators in TFLite GPU delegate.

**Who will benefit with this feature?**
Mediapipe, Tensorflow and Android researchers

**Any Other info.**
Attached with this is the sample hair segmentation TFLite, that they are using.

[hair_segmentation.tflite.zip](https://github.com/tensorflow/tensorflow/files/3749221/hair_segmentation.tflite.zip)
"
33556,model.losses return null ?,"I want to use regularization loss to improve model accuracy, so I follow the official tutorial, but model.losses return **[]**, and got ""**ValueError: inputs must be a list of at least one Tensor/IndexedSlices with the same dtype and shape**"", Is there something wrong and how to fix it?
```
def train_step(images, labels):
    with tf.GradientTape() as tape:
        predictions = model(images, training=True)
        pred_loss = loss_object(labels, predictions)
        print(""model.losses:"", model.losses)  
        regularization_loss = tf.math.add_n(model.losses)
        total_loss = pred_loss + regularization_loss
    gradients = tape.gradient(total_loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
```
"
33555,[TF 2.0] repeatdataset has no attribute 'make_one_shot_iterator',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):window10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):2.0.0
- Python version:3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:colab

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
when I tried to train with estimator object, i can see this error below.
AttributeError: 'RepeatDataset' object has no attribute 'make_one_shot_iterator'
def mapping_fn(X,Y):
  input, labels = {'x':X},Y
  return input,labels

def train_input_fn():
  dataset = tf.data.Dataset.from_tensor_slices((input_train, label_train))
  dataset = dataset.shuffle(buffer_size = len(input_train))
  dataset = dataset.batch(BATCH_SIZE)
  dataset = dataset.map(mapping_fn)
  dataset = dataset.repeat(count = NUM_EPOCHS)
  iterator = dataset.make_one_shot_iterator()

  return iterator.get_next()

def eval_input_fn():
  dataset = tf.data.Dataset.from_tensor_slices((input_eval, label_eval))
  dataset = dataset.shuffle(buffer_size = len(input_eval))
  dataset = dataset.batch(16)
  dataset = dataset.map(mapping_fn)
  iterator =dataset.make_one_shot_iterator()

  return iterator.get_next()

wirh model_fn = CNN, RNN model 
est = tf.estimator.Estimator(model_fn, model_dir = ""/content/gdrive/checkpoint/cnn_model"")
est.train(train_input_fn)


**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33554,"I have installed tensorflow 2.0 through Anaconda prompt, however the jupyternotebook can't find the tf2.0 module.","**System information**
- Window 10 operation system
- TensorFlow 2.0:
- Python 3.6:
- Installed using pip;
- Downloaded from pypi.org.

**Problem**
I have installed TensorFlow 2.0 through Anaconda prompt, however, the jupyter notebook can't find the TensorFlow module. The detailed error is 

> ModuleNotFoundError: No module named 'tensorflow'.

Through the command 'pip list', I can find the TF 2.0.0 in my env. Meanwhile, when I using PyCharm in the env with TF 2.0.0, the PyCharm can find the TF 2.0.0 module.

"
33552,Incorrect Arduino Person Detection .zip package,"## URL(s) with the issue:
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/person_detection
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/person_detection#obtain-and-import-the-library

## Description of issue (what needs changing):
Under the heading ""Obtain and Import the Library"", the link incorrectly refers to the micro_speech.zip package instead of a person_detection example. 

"
33551,Failure to build tensorflow in Ubuntu,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: master 0f752f7368f88b61916a3d1700685d01aff835cc
- Python version: Python 3.6.8
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 1.0.0
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
I am unable to rebuild the tensorflow library.




**Provide the exact sequence of commands / steps that you executed before running into the problem**
Cloned the repository as per instructions on https://www.tensorflow.org/lite/microcontrollers/library. When I tried to build using this command

make -f tensorflow/lite/experimental/micro/tools/make/Makefile test

The build fails:
```
g++ -O3 -DNDEBUG -std=c++11 -g -DTF_LITE_STATIC_MEMORY -DTF_LITE_DISABLE_X86_NEON -I. -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -Itensorflow/lite/experimental/micro/tools/make/downloads/kissfft -c tensorflow/lite/experimental/micro/kernels/logical.cc -o tensorflow/lite/experimental/micro/tools/make/gen/linux_x86_64/obj/tensorflow/lite/experimental/micro/kernels/logical.o
In file included from ./tensorflow/lite/kernels/internal/reference/binary_function.h:18:0,
                 from tensorflow/lite/experimental/micro/kernels/logical.cc:16:
./tensorflow/lite/kernels/internal/common.h:24:10: fatal error: fixedpoint/fixedpoint.h: No such file or directory
 #include ""fixedpoint/fixedpoint.h""
          ^~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
tensorflow/lite/experimental/micro/tools/make/Makefile:244: recipe for target 'tensorflow/lite/experimental/micro/tools/make/gen/linux_x86_64/obj/tensorflow/lite/experimental/micro/kernels/logical.o' failed
make: *** [tensorflow/lite/experimental/micro/tools/make/gen/linux_x86_64/obj/tensorflow/lite/experimental/micro/kernels/logical.o] Error 1
```

"
33550,tf.keras.Model.fit ignores class_weight when passed tf.data.Dataset,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.14.6 or Colab
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0, 1.15.0-rc3
- Python version: 3.7
- CUDA/cuDNN version:
- GPU model and memory: None or Colab

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

`tf.keras.Model.fit` ignores `class_weight` when passed a `tf.data.Dataset`.  When passed an instance of `tf.data.Dataset` and a `class_weight` dictionary with nonsensical label keys, it runs without exception, whereas it correctly raises `ValueError` when passed a pair of `np.ndarray`.

**Describe the expected behavior**

`tf.keras.Model.fit` should apply `class_weight` when passed a `tf.data.Dataset`.  It should raise an exception for incorrect `class_weight` keys.

**Code to reproduce the issue**

```python
import tensorflow as tf
import numpy as np

features = np.array([[-1.], [1.]], dtype=np.float32)
labels = np.array([[0], [1]], dtype=np.int32)

dataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(1)

model = tf.keras.Sequential([tf.keras.layers.Dense(1, activation='sigmoid')])

model.compile(optimizer='sgd', loss='binary_crossentropy')

class_weight = {'bad_negative_label': 0.5, 'bad_positive_label': 0.5}

fit_ops = (('tf.data.Dataset', lambda: model.fit(dataset, class_weight=class_weight, verbose=0)),
           ('np.ndarray', lambda: model.fit(features, labels, class_weight=class_weight, verbose=0)))

for key, fit_op in fit_ops:
    try:
        print(f'fitting {key} with bad class_weight label')
        fit_op()
    except ValueError as e:
        print('failed as it should have')
        raise ValueError from e
    else:
        print('succeded but should have failed')
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
fitting tf.data.Dataset with bad class_weight label
succeded but should have failed
fitting np.ndarray with bad class_weight label
failed as it should have
Traceback (most recent call last):
  File ""scratch.py"", line 22, in <module>
    fit_op()
  File ""scratch.py"", line 17, in <lambda>
    ('np.ndarray', lambda: model.fit(features, labels, class_weight=class_weight, verbose=0)))
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 224, in fit
    distribution_strategy=strategy)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 547, in _process_training_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 594, in _process_inputs
    steps=steps)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2530, in _standardize_user_data
    feed_sample_weight_modes)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2529, in <listcomp>
    for (ref, sw, cw, mode) in zip(y, sample_weights, class_weights,
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py"", line 946, in standardize_weights
    '`class_weight`.' % (existing_classes - existing_class_weight))
ValueError: `class_weight` must contain all classes in the data. The classes {0, 1} exist in the data but not in `class_weight`.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""scratch.py"", line 25, in <module>
    raise ValueError from e
ValueError

Process finished with exit code 1
```
"
33549,"I want to train my model on gpu. So i installed everything which given in tensorflow-gpu. But now i want to go back on cpu. So, how to come back on cpu ? ","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33548,Getting error following steps in 'Building Standard TensorFlow ModelServer',"## URL(s) with the issue:

https://www.tensorflow.org/tfx/serving/serving_advanced

## Description of issue (what needs changing):

When I attempt to execute  the 
```
tools/run_in_docker.sh python tensorflow_serving/example/mnist_saved_model.py \
  --training_iteration=100 --model_version=1 /tmp/mnist
```
step in the in the tutorial I get the this error:

```
serving % tools/run_in_docker.sh python tensorflow_serving/example/mnist_saved_model.py \
  --training_iteration=100 --model_version=1 /tmp/mnist
== Pulling docker image: tensorflow/serving:nightly-devel
nightly-devel: Pulling from tensorflow/serving
22e816666fd6: Already exists 
079b6d2a1e53: Already exists 
11048ebae908: Already exists 
c58094023a2e: Already exists 
e9d1145448f7: Pull complete 
3b2b266356de: Pull complete 
9f9b2b982b72: Pull complete 
ede8854b3a01: Pull complete 
7bb55a638df9: Pull complete 
bdd9b510b8a7: Pull complete 
90a5454f6928: Pull complete 
1941316fdbd3: Pull complete 
c9c9a434ee49: Pull complete 
Digest: sha256:3b52152115c73a6be79a86cda94c4c94569df9b490a3e40c2530d5a9a007afac
Status: Downloaded newer image for tensorflow/serving:nightly-devel
docker.io/tensorflow/serving:nightly-devel
== Running cmd: sh -c 'cd /Users/***REMOVED***/GitHub/serving; python tensorflow_serving/example/mnist_saved_model.py --training_iteration=100 --model_version=1 /tmp/mnist'
Traceback (most recent call last):
  File ""tensorflow_serving/example/mnist_saved_model.py"", line 39, in <module>
    tf.app.flags.DEFINE_integer('training_iteration', 1000,
AttributeError: 'module' object has no attribute 'app'
```
I am running this on Mac OS Catalina w/ 8GB RAM allocated to the Docker Engine.
"
33545,"TypeError: Expected Operation, Variable, or Tensor, got 0","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):NONE
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NONE
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):2.0
- Python version:3.6
- Bazel version (if compiling from source):NONE
- GCC/Compiler version (if compiling from source):NONE
- CUDA/cuDNN version:NONE
- GPU model and memory:NONE

**Describe the current behavior**
```
File ""keras_to_tensorflow.py"", line 186, in <module>
    app.run(main)
  File ""/home/venv/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/venv/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""keras_to_tensorflow.py"", line 132, in main
    model = load_model(FLAGS.input_model, FLAGS.input_model_json, FLAGS.input_model_yaml)
  File ""keras_to_tensorflow.py"", line 65, in load_model
    model = vgg_blstm_ctc.model(is_training=False, img_size=(256,32), num_classes=11, max_label_length=26)
  File ""/home/keras_to_tensorflow/vgg_blstm_ctc.py"", line 70, in model
    y = Bidirectional(LSTM(256, kernel_initializer=initializer, return_sequences=True), merge_mode='sum', name='LSTM_1')(rnn_input) # 32*512
  File ""/usr/local/lib/python3.6/dist-packages/keras/layers/wrappers.py"", line 437, in __call__
    return super(Bidirectional, self).__call__(inputs, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py"", line 75, in symbolic_fn_wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py"", line 489, in __call__
    output = self.call(inputs, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/keras/layers/wrappers.py"", line 530, in call
    initial_state=forward_state, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py"", line 2247, in call
    initial_state=initial_state)
  File ""/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py"", line 682, in call
    input_length=timesteps)
  File ""/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py"", line 3105, in rnn
    targets=[last_output])
  File ""/home/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py"", line 134, in get_reachable_from_inputs
    raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))
TypeError: Expected Operation, Variable, or Tensor, got 0
```

**Describe the expected behavior**
when I convert the keras model to the tensorflow model, but I get an error above. anybody can help me?

**Code to reproduce the issue**

the `keras_to_tensorflow.py` file is from [here](https://github.com/amir-abdi/keras_to_tensorflow),  the `vgg_blstm_ctc.py` file is from [here](https://github.com/DevilExileSu/BankCardOCR), the input model is from [here](https://github.com/DevilExileSu/BankCardOCR/tree/master/train/model).I has changed the `keras_to_tensorflow.py` file like this:

```
def load_model(input_model_path, input_json_path=None, input_yaml_path=None):
    if not Path(input_model_path).exists():
        raise FileNotFoundError(
            'Model file `{}` does not exist.'.format(input_model_path))
    try:
        #model = keras.models.load_model(input_model_path)
        model = vgg_blstm_ctc.model(is_training=False, img_size=(256,32), num_classes=11, max_label_length=26)
        return model 
    except FileNotFoundError as err:
        logging.error('Input mode file (%s) does not exist.', FLAGS.input_model)
        raise err
```
"
33544,TF2.0 for compute capability 3.0,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): no



**Describe the feature and the current behavior/state.**
would like to use TF2.0 gpu with old cards Geforce GTX 870m

**Will this change the current api? How?**
non

**Who will benefit with this feature?**
all users with older gpu cards

**Any Other info.**
"
33543,[tf2.0.0] Fails to build on Python 3.8 - suggested fix (change nullptr to 0 in source),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0.0 with cuda and TensorRT
- Python version: 3.8
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: CUDA 10.0, CUDNN 7.6.4
- GPU model and memory: NVidia RTX 2080 Ti

**Describe the problem**

While building from source:
ERROR: /home/daniel/tensorflow/tensorflow/python/BUILD:341:1: C++ compilation of rule '//tensorflow/python:ndarray_tensor_bridge' failed (Exit 1) tensorflow/python/lib/core/ndarray_tensor_bridge.cc:108:1: error: cannot convert ‘std::nullptr_t’ to ‘Py_ssize_t {aka long int}’ in initialization

**Provide the exact sequence of commands / steps that you executed before running into the problem**

git checkout r2.0

bazel build --config=opt --config=cuda --config=v2 --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //tensorflow/tools/pip_package:build_pip_package

Fix:

In Python 3.8, the reserved ""tp_print"" slot was changed from a function pointer to a number, `Py_ssize_t tp_vectorcall_offset`.
In C, there is no ""nullptr""; either a 0 or NULL casts automatically to both pointers and numbers.
Use 0 instead of ""nullptr"" in the slot to be source-compatible both with Python 3.8 and previous versions.

Search for ""tp_print"" in the files listed below.  Change nullptr to 0 where tp_print is in the comment:
i.e. 
change:
`    nullptr,                                      /* tp_print */     `
to:
`    0,                                      /* tp_print */     `
List of files that need this change:
/tensorflow/tensorflow/python/lib/core/ndarray_tensor_bridge.cc     ----> 1 change
/tensorflow/tensorflow/python/lib/core/bfloat16.cc                -----> 1 change
/tensorflow/tensorflow/python/eager/pywrap_tfe_src.cc      -------> 2 changes ( /* tp_print */ occurs twice)"
33541,Training freezes when adding tf.function,"

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): `v2.0.0-rc2-26-g64c3d38 2.0.0`
- Python version: 3.5.2
- CUDA/cuDNN version: 9.2
- GPU model and memory: GTX 1080 Ti

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

When adding the `tf.function` decorator to the `_epoch_train` (in the code below), it freezes.

**Code to reproduce the issue**
Code taken from this tutorial: https://www.tensorflow.org/tutorials/images/segmentation
Except that, instead of using `model.fit()`, I used the following custom class for the training loop:

```
import tensorflow as tf
class Trainer(object):
    def __init__(self, model, dataloaders, epochs=None,
                 steps=-1, log_interval=1):
        """"""
        dataloaders: {'train': train_loader, 'val': val_loader}
        Here we assume that the model has been compiled, i.e. it contains
            an optimizer and a loss function
        """"""
        self.model = model
        self.dataloaders = dataloaders
        self.epochs = epochs
        self.log_interval = log_interval
    
    def train(self):
        for epoch in range(self.epochs):
            message = '{}/{}:\t'.format(epoch, self.epochs)

            # Training phase
            self._epoch_train()
            # Tensorboard: https://www.tensorflow.org/tensorboard/get_started
            # Display metrics at the end of each epoch.
            for metric in self.model.metrics:
                metric_value = float(metric.result())
                message += 'train_{}: {}\t'.format(metric.name, metric_value)
                metric.reset_states()

            # Validation phase
            self._epoch_val()
            for metric in self.model.metrics:
                metric_value = float(metric.result())
                message += 'val_{}: {}\t'.format(metric.name, metric_value)
                metric.reset_states()

            print(message)

    @tf.function
    def _epoch_train(self):
        """"""
        Perform one training epoch
        """"""
        # Iterate over the batches of the dataset.
        # Note: use ds.enumerate() instead of enumerate(ds)
        # https://github.com/tensorflow/tensorflow/issues/30802
        for step, (x_batch, y_batch) in self.dataloaders['train'].enumerate():
            # Open a GradientTape to record the operations run
            # during the forward pass, which enables autodifferentiation.
            with tf.GradientTape() as tape:
                # Run the forward pass of the layer.
                # The operations that the layer applies
                # to its inputs are going to be recorded
                # on the GradientTape.
                logits = self.model(x_batch)  # Logits for this minibatch

                # Compute the loss value for this minibatch.
                loss_value = self.model.loss(y_batch, logits)

            # Use the gradient tape to automatically retrieve
            # the gradients of the trainable variables with respect to the loss.
            grads = tape.gradient(loss_value, self.model.trainable_weights)

            # Run one step of gradient descent by updating
            # the value of the variables to minimize the loss.
            self.model.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))

            # Update metrics
            for metric in self.model.metrics:
                metric(y_batch, logits)

    def _epoch_val(self):
        """"""
        Perform one validation epoch
        """"""
        # Run a validation loop at the end of each epoch.
        for x_batch, y_batch in self.dataloaders['val']:
            logits = self.model(x_batch)
            # Update metrics
            for metric in self.model.metrics:
                metric(y_batch, logits)
```

"
33539,Not build 1.15 windows,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10
- Python version: 3.7
- Bazel version (if compiling from source): 0.26.1
- CUDA/cuDNN version:10.1.243_426.00
- GPU model and memory:7.6.4.38

> bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package

```
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (392 packages loaded, 21941 targets configured).
INFO: Found 1 target...
INFO: Deleting stale sandbox base C:/users/rty/_bazel_rty/26orbg4z/sandbox
INFO: From Compiling tensorflow/lite/kernels/internal/tensor_utils.cc:
cl : Command line warning D9002 : ignoring unknown option '-O3'
INFO: From Executing genrule //tensorflow/core:version_info_gen:
fatal: Invalid path '/c/users/rty/_bazel_rty/26orbg4z/execroot/org_tensorflow/C:': No such file or directory
ERROR: missing input file '@local_config_mlir//:include/mlir/TableGen/OpInterfaces.h'
ERROR: C:/users/rty/_bazel_rty/26orbg4z/external/local_config_mlir/BUILD:1714:1: @local_config_mlir//:TableGen: missing input file '@local_config_mlir//:include/mlir/TableGen/OpInterfaces.h'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: C:/users/rty/_bazel_rty/26orbg4z/external/local_config_mlir/BUILD:1714:1 1 input file(s) do not exist
INFO: Elapsed time: 219.352s, Critical Path: 26.02s
INFO: 300 processes: 300 local.
FAILED: Build did NOT complete successfully
```"
33536,failed to query event: CUDA_ERROR_LAUNCH_FAILED,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10 Enterprise, 64bit (1903)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
NA
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
tensorflow-gpu-2.0
- Python version:
3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
10 / 7.6.0 (also have tried 7.6.1, 7.6.2, 7.6.3, 7.6.4)
- GPU model and memory:
2 * RTX 2080 8G

**Describe the current behavior**
```
2019-10-20 01:32:26.104969: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2019-10-20 01:32:26.110674: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
```

This error randomly occurs in training. 
Some times occurs in the first epoch, some times after a few epochs.

When showing this error, also pop-up ""python has stopped working"" message.

I ran the same code on google cloab, it seems alright.
I also re-install python, tensorflow, cuda, cudnn, and GPU driver, nothing help

**Code to reproduce the issue**
There are 353 samples in my dataset, all samples are padded to the same length (about 100000).
And it just a simple LSTM model

```
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Masking, TimeDistributed, LSTM, Bidirectional
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras import backend as K

DUMMY_VALUE = -1.0

model = Sequential()
model.add(Masking(mask_value=DUMMY_VALUE, input_shape=(None, 100)))
model.add(Bidirectional(LSTM(100, return_sequences=True, implementation=1)))
model.add(TimeDistributed(Dense(1, activation='sigmoid')))
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy', K_precision, K_recall],
              sample_weight_mode='temporal')
model.summary()

modelName = 'test'
checkpoint = ModelCheckpoint(filepath='./model_checkpoints/{epoch:02d}-{val_loss:.4f}_' + modelName + '.h5', verbose=1, save_best_only=True, mode='min')
es = EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1)

histories = []
histories.append( model.fit(padding_x, padding_y, epochs=30, batch_size=2, validation_split=0.1, callbacks=[es, checkpoint], sample_weight=w) )
model.save(modelName + '.h5')
```
"
33535,Using tf.data.Dataset.from_generator with tf.keras,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

I am referring to [this `tf.data` example](https://www.tensorflow.org/guide/data) where it has been shown how to wrap a `tf.keras.preprocessing.image.ImageDataGenerator` object with `tf.data.Dataset`. I am trying to supply this object to a Keras model and I am getting the following issue:

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-12-f2c206e4a521> in <module>()
      1 model.fit(ds, 
----> 2          steps_per_epoch=total_data//32)

11 frames
/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  TypeError: endswith first arg must be bytes or a tuple of bytes, not str
Traceback (most recent call last):

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 464, in get_iterator
    return self._iterators[iterator_id]

KeyError: 2


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py"", line 221, in __call__
    ret = func(*args)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 585, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 466, in get_iterator
    iterator = iter(self._generator(*self._args.pop(iterator_id)))

  File ""/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py"", line 540, in flow_from_directory
    interpolation=interpolation

  File ""/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py"", line 126, in __init__
    classes, filenames = res.get()

  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 644, in get
    raise self._value

  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))

  File ""/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py"", line 216, in _list_valid_filenames_in_directory
    for root, fname in valid_files:

  File ""/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py"", line 172, in _iter_valid_files
    if fname.lower().endswith('.tiff'):

TypeError: endswith first arg must be bytes or a tuple of bytes, not str


	 [[{{node PyFunc}}]]
	 [[IteratorGetNext]]
	 [[IteratorGetNext/_4]]
  (1) Invalid argument:  TypeError: endswith first arg must be bytes or a tuple of bytes, not str
Traceback (most recent call last):

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 464, in get_iterator
    return self._iterators[iterator_id]

KeyError: 2


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py"", line 221, in __call__
    ret = func(*args)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 585, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 466, in get_iterator
    iterator = iter(self._generator(*self._args.pop(iterator_id)))

  File ""/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py"", line 540, in flow_from_directory
    interpolation=interpolation

  File ""/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py"", line 126, in __init__
    classes, filenames = res.get()

  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 644, in get
    raise self._value

  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))

  File ""/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py"", line 216, in _list_valid_filenames_in_directory
    for root, fname in valid_files:

  File ""/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py"", line 172, in _iter_valid_files
    if fname.lower().endswith('.tiff'):

TypeError: endswith first arg must be bytes or a tuple of bytes, not str


	 [[{{node PyFunc}}]]
	 [[IteratorGetNext]]
0 successful operations.
0 derived errors ignored. [Op:__inference_distributed_function_1435]

Function call stack:
distributed_function -> distributed_function
```

**Describe the expected behavior**

How to use this type of `tf.data.Dataset` objects along with Keras?

**Code to reproduce the issue**
[Link](https://colab.research.google.com/drive/1evx-qKG1vPSUE5tfsFLgG8ukAEczJSkN) to the Colab notebook.
"
33534,Finish making strided_slice equivalent to numpy's strided_slice,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.14
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**

Currently, Tensorflow uses a slicing syntax very similar to Numpy's: for example, x[...,:,0:-4] would work equivalently in both TF and Numpy. However, more advanced indexing does not work; for example, trying to use [this approach](https://matthewmcgonagle.github.io/blog/2017/10/13/SelectingSubsquaresWithNumpyIndexing) to get sub-squares from a Tensorflow tensor does not work, and in fact as far as I can tell, clever advanced indexing like this is currently impossible. As a researcher, I'm often trying to do somewhat non-standard things, and I've encountered these indexing issues several times. With TF reaching maturity, it would be good to have these advanced indexing features implemented so that slicing is fully on-par with Numpy.

**Will this change the current api? How?**

No, it will integrate seamlessly, simply providing more functionality.

**Who will benefit with this feature?**

Most advanced users of Tensorflow (especially researchers) will get a lot of benefit from this.

**Any Other info.**

Numpy has already implemented this, so it shouldn't be too difficult to port that code to TF."
33533,Bcapak,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33532,Operators not supported by Lite routine,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33531,MultiWorkerMirroredStrategy does not work with Keras + accuracy metric,"**System information**
The same environment as in https://github.com/tensorflow/tensorflow/issues/32654
But with 2 machines instead of 1 **and** Tensorflow 2.0 release from PyPi.

**Describe the current behavior**

I am training DenseNet121 on Imagenet with standard Keras code and custom dataset pipeline. `model.compile` is called with the only ""accuracy"" metric. I am using `MultiWorkerMirroredStrategy` as described in the tutorial. Here is the log. I had to erase ~7,000 warnings which are all the same: `2019-10-19 12:23:10.615259: W tensorflow/core/framework/op_kernel.cc:309] OpKernelContext is tracking allocations but they are not being consumed by the StepStatsCollector.`

```
Compiling with RMSprop
Fitting...
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
2019-10-19 03:57:05.813768: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:400] Cannot find shardable dataset, adding a shard node at the end of the dataset instead. This may have performance implications.
2019-10-19 03:57:19.342401: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:400] Cannot find shardable dataset, adding a shard node at the end of the dataset instead. This may have performance implications.
2019-10-19 03:59:48.236258: I tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:316] Abandoning ScopedAllocatorOptimizer because input FusedBatchNormGradV3_99 output 1 is already assigned to scope_id 132
2019-10-19 03:59:48.236611: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:381] error: Internal: Abandoning ScopedAllocatorOptimizer because input FusedBatchNormGradV3_99 output 1 is already assigned to scope_id 132
2019-10-19 03:59:48.236834: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:990] error: Internal: Abandoning ScopedAllocatorOptimizer because input FusedBatchNormGradV3_99 output 1 is already assigned to scope_id 132
2019-10-19 03:59:48.237468: E tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:1007] ScopedAllocatorOptimizer: Internal: Abandoning ScopedAllocatorOptimizer because input FusedBatchNormGradV3_99 output 1 is already assigned to scope_id 132
2019-10-19 03:59:48.237593: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:782] error: Internal: Abandoning ScopedAllocatorOptimizer because input FusedBatchNormGradV3_99 output 1 is already assigned to scope_id 132
2019-10-19 03:59:48.299255: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] scoped_allocator_optimizer failed: Internal: Abandoning ScopedAllocatorOptimizer because input FusedBatchNormGradV3_99 output 1 is already assigned to scope_id 132
2019-10-19 04:00:01.523007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-19 04:00:11.506609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-19 04:00:19.689077: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
2019-10-19 04:00:29.848332: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-19 04:00:29.848931: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.0'; dlerror: libcupti.so.10.0: cannot open shared object file: No such file or directory
2019-10-19 04:00:29.849025: W tensorflow/core/profiler/lib/profiler_session.cc:192] Encountered error while starting profiler: Unavailable: CUPTI error: CUPTI could not be loaded or symbol could not be found.
Train for 15974.0 steps

Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009375.
Epoch 1/400
2019-10-19 04:00:34.268294: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 0 kernel records, 0 memcpy records.
2019-10-19 04:00:34.314465: E tensorflow/core/platform/default/device_tracer.cc:70] CUPTI error: CUPTI could not be loaded or symbol could not be found.
15973/15974 [============================>.] - ETA: 1s - loss: 8.3656 - accuracy: 0.01342019-10-19 12:14:21.634609: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:21.635077: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:21.635164: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:21.635253: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[replica_3/metrics/accuracy/AssignAddVariableOp_1/_55]]
2019-10-19 12:14:21.635336: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Cancelled: [_Derived_]Cancelled
Additional GRPC error information:
{""created"":""@1571487261.635191370"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Cancelled"",""grpc_status"":1}
2019-10-19 12:14:21.635412: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:21.635529: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:21.635680: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[replica_3/metrics/accuracy/AssignAddVariableOp_1/_43]]
2019-10-19 12:14:21.635764: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]Cancelled
Additional GRPC error information:
{""created"":""@1571487261.635191370"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Cancelled"",""grpc_status"":1}
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:21.635930: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[replica_1/metrics/accuracy/AssignAddVariableOp_1/_63]]
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
Additional GRPC error information:
{""created"":""@1571487261.635191370"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Cancelled"",""grpc_status"":1}
2019-10-19 12:14:21.636135: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence
	 [[{{node IteratorGetNext_3}}]]
2019-10-19 12:14:23.196391: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:23.196583: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:23.196683: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:23.196964: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:23.197197: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:23.197232: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
	 [[CollectiveReduce_3]]
	 [[CollectiveReduce_1/_16]]
2019-10-19 12:14:23.197283: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
	 [[CollectiveReduce_2]]
2019-10-19 12:14:23.197353: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
	 [[CollectiveReduce_3]]
	 [[CollectiveReduce/ReadVariableOp/_18]]
2019-10-19 12:14:23.197395: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:23.197460: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:23.197507: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
	 [[CollectiveReduce_3]]
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:23.197742: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
2019-10-19 12:14:23.197870: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
	 [[CollectiveReduce_1]]
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 668, in on_start
    yield
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 372, in fit
    prefix='val_')
  File ""/usr/lib/python3.6/contextlib.py"", line 88, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 685, in on_epoch
    self.callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 298, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 963, in on_epoch_end
    self._save_model(epoch=epoch, logs=logs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 1001, in _save_model
    self.model.save(filepath, overwrite=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py"", line 975, in save
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py"", line 112, in save_model
    model, filepath, overwrite, include_optimizer)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 109, in save_model_to_hdf5
    save_weights_to_hdf5_group(model_weights_group, model_layers)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 627, in save_weights_to_hdf5_group
    weight_values = K.batch_get_value(weights)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py"", line 3296, in batch_get_value
    return [x.numpy() for x in tensors]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py"", line 3296, in <listcomp>
    return [x.numpy() for x in tensors]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/values.py"", line 389, in __getattr__
    return getattr(self.get(), name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/values.py"", line 322, in get
    return self._get_cross_replica()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/values.py"", line 1237, in _get_cross_replica
    self, axis=None)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 805, in reduce
    return self._extended._reduce(reduce_op, value)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1436, in _reduce
    device_util.current() or ""/device:CPU:0""))[0]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/collective_all_reduce_strategy.py"", line 490, in _reduce_to
    reduce_op, value, destinations=destinations)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 282, in reduce
    destinations)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 1025, in reduce_implementation
    all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value])[0]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 1091, in _batch_all_reduce
    dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 1120, in _do_batch_all_reduce_dense
    ""Id"")
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_utils.py"", line 365, in build_collective_reduce
    return collective_all_reduce()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 526, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 511, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.OutOfRangeError:  [_Derived_]End of sequence
	 [[{{node IteratorGetNext_3}}]]
	 [[GroupCrossDeviceControlEdges_1/metrics/accuracy/div_no_nan/_127]]
	 [[CollectiveReduce_2]] [Op:__inference_collective_all_reduce_2894985]

Function call stack:
collective_all_reduce


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/user/vmarkovtsev/images/efficientoffice/efficientoffice/__main__.py"", line 5, in <module>
    sys.exit(main())
  File ""/user/vmarkovtsev/images/efficientoffice/efficientoffice/main.py"", line 221, in main
    callbacks=[tensorboard_callback, checkpoint_callback, scheduler])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 789, in fit
    *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 776, in wrapper
    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 853, in run_distribute_coordinator
    task_id, session_config, rpc_layer)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 360, in _run_single_worker
    return worker_fn(strategy)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 771, in _worker_fn
    return method(model, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 372, in fit
    prefix='val_')
  File ""/usr/lib/python3.6/contextlib.py"", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 671, in on_start
    self.callbacks._call_end_hook(mode)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 258, in _call_end_hook
    self.on_train_end()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 375, in on_train_end
    callback.on_train_end(logs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 940, in on_train_end
    self._training_state.delete_backup()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/distribute/multi_worker_training_state.py"", line 161, in delete_backup
    tracking.AutoTrackable.__delattr__(self._model, CKPT_SAVED_EPOCH)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/tracking.py"", line 94, in __delattr__
    super(AutoTrackable, self).__delattr__(name)
AttributeError: _ckpt_saved_epoch

Epoch 00001: loss improved from inf to 8.36576, saving model to model/DenseNet121-0001-8.366.hdf5
2019-10-19 12:14:33.567096: W tensorflow/core/common_runtime/eager/context.cc:290] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
```

**Describe the expected behavior**

The expected behavior is a successful epoch ending.

**Code to reproduce the issue**

```python
#!/usr/bin/env python3
import sys
import tensorflow as tf
# Otherwise nothing works, and it really sucks, but is declared in the docs
multi_worker_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

def main():
    batch_size = 12
    features_shape = 372, 558, 3
    labels = 10
    sample = tf.random.uniform(features_shape)

    def with_shape(t, shape):
        t = tf.squeeze(t)
        t.set_shape(shape)
        return t

    ds_train = tf.data.Dataset.from_tensors([sample]).map(lambda s: (s, tf.ones((labels,)))) \
        .repeat().batch(batch_size).map(lambda s, l: (with_shape(s, (batch_size,) + features_shape),
                                                      with_shape(l, (batch_size, labels))))
    ds_val = tf.data.Dataset.from_tensors([sample]).map(lambda s: (s, tf.ones((labels,)))) \
        .repeat().batch(batch_size).take(10).map(
        lambda s, l: (with_shape(s, (batch_size,) + features_shape), with_shape(l, (batch_size, labels))))
    with multi_worker_strategy.scope():
        model = tf.keras.applications.DenseNet121(
            weights=None, input_shape=features_shape, classes=labels)
        model.build((batch_size,) + features_shape)
        model.summary()
        optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)
        cross_entropy = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)
        model.compile(optimizer=optimizer, loss=cross_entropy, metrics=[""accuracy""])
    model.fit(ds_train, validation_data=ds_val, epochs=1, steps_per_epoch=100)


if __name__ == ""__main__"":
    sys.exit(main())
```"
33528,Broken Link,"Hi

Following URL seems to be down:

https://mirror.bazel.build/github.com/pybind/pybind11/archive/v2.3.0.tar.gz

Bazel uses that to download pybind11 and for some unknown reason fallback link (https://github.com/pybind/pybind11/archive/v2.3.0.tar.gz) is never being used as an alternative. (Is that a fallback btw?)

Build logs:

```
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (192 packages loaded, 2655 targets configured)                              
INFO: Call stack for the definition of repository 'pybind11' which is a tf_http_archive (rule definition at /root/tensorflow-1.15.0/third_party/repo.bzl:124:19):                                                                                                                             
 - /root/tensorflow-1.15.0/tensorflow/workspace.bzl:925:5                                                                                      
 - /root/tensorflow-1.15.0/WORKSPACE:19:1                                                                                                      
ERROR: An error occurred during the fetch of repository 'pybind11':                                                                            
   java.io.IOException: Error downloading [https://mirror.bazel.build/github.com/pybind/pybind11/archive/v2.3.0.tar.gz, https://github.com/pybind/pybind11/archive/v2.3.0.tar.gz] to /root/.cache/bazel/_bazel_root/a0cf5ef42c8f00571631f8815d38246b/external/pybind11/v2.3.0.tar.gz: All mirrors are down: [GET returned 404 Not Found, connect timed out]       
```                                                                           

Any workaround? 

**System information**
- OS Platform and Distribution: Ubuntu 19.10
- TensorFlow version: 1.15.0
- Python version: 3.7
- Bazel version: 0.26.1"
33527,Custom tf.keras.Model memory footprint drastically affects performance,"
**System information**
16.04.6 LTS
Python 3.5.2
GPU TITAN X (Pascal) 13GB

**Describe the current behavior**

The memory footprint of a custom tf.keras.Model object affects training performance by almost two orders of magnitude.


**Code to reproduce the issue**

The following is a stripped-down implementation of an RNN for text data loosely resembling the one in the [Effective Tensorflow 2.0 Tutorial](https://www.tensorflow.org/guide/effective_tf2)

```ruby
class DynamicRNN(tf.keras.Model): 

  def __init__(self, state_size, embedding_size, vocab_size, something):
    super(DynamicRNN, self).__init__(self)

    self.state_size = state_size
    self.embedding_size = embedding_size
    self.vocab_size = vocab_size
    self.something = something

    # The internal GRU
    self.cell = tf.keras.layers.GRUCell(state_size)
    
    # Input embedding and softmax parameters
    emb_initializer = tf.initializers.RandomUniform(-0.5, 0.5)
    self.emb = tf.Variable(emb_initializer(shape=[self.vocab_size, self.embedding_size]), name=""emb"")
    softmax_w_initializer = tf.initializers.GlorotUniform()
    self.softmax_w = tf.Variable(softmax_w_initializer(shape=[self.vocab_size, self.state_size]), name=""softmax_w"")
    self.softmax_b = tf.Variable(tf.zeros([self.vocab_size]), name=""softmax_b"")


  @tf.function
  def _step(self, last_state, last_symbol):
    # Embed last symbol
    last_symbol_emb = tf.nn.embedding_lookup(self.emb, last_symbol)
    
    # Compute new state
    _, state = self.cell(last_symbol_emb, [last_state], training=False)
    state = state[0]
 
    # Predict new symbol
    logits = tf.matmul(state, self.softmax_w, transpose_b=True) + self.softmax_b

    return state, logits
  

  @tf.function
  def __call__(self, inputs):
    batch_size, L = tf.shape(inputs)[0], tf.shape(inputs)[1]

    last_state = self.cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)
    last_symbol = tf.fill([batch_size], 0)

    # One loss term per time-step
    total_loss = 0.0
    for i in tf.range(L):
      last_state, logits = self._step(last_state, last_symbol)
      last_symbol = inputs[:, i]
  
      batch_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=inputs[:,i])
      total_loss += tf.reduce_mean(batch_loss)
      
    total_loss /= tf.cast(L, tf.float32)

    return total_loss
```

To rule out one culprit, the `TensorArray`s have been removed. Clearly, an efficient model would not perform embedding and loss computation in every step but that's not relevant here.

To perform training I use a standard tensorflow 2.0 loop (with dummy input for simplicity)

```python
# Parameters
batch_size = 64
vocab_size = 30000
seq_length = 28

# Model
something = {str(i) : i for i in range(400000)}
rnn = DynamicRNN(512, 100, vocab_size, something)
# Optimizer
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipvalue=0.5)

# Dummy input
seq = tf.ones([batch_size, seq_length], dtype=tf.int32)

# Training loop
for step in tqdm.tqdm(range(100000)):
  with tf.GradientTape() as tape:
    loss = rnn(seq)
  grads = tape.gradient(loss, rnn.trainable_variables)
  optimizer.apply_gradients(zip(grads, rnn.trainable_variables))
```

The crucial part here is the `something` object which is passed to the model. Note that the object is never used inside the model, hence we can also pass `None` instead.

My point is that the training performance on GPU and CPU is significantly degraded when the relatively memory costly  `something` object is passed instead of `None`. Precisely, I get a slowdown from 0.13s/it to 7.7s/it on the GPU and 2s/it to 9s/it on the CPU. Utilization drops from ~65% to %5 on the GPU and from 800% to 300% (24 cores available) on the cpu.

The above makes me suspicious that the model is being copied in *every* training step. I found this behavior nowhere documented. Is it? Also note that such an `something` dictionary is entirely realistic if what you do is NLP and you need to carry your vocabulary around. If that object is being used internally, a more efficient alternative might be to pass it as a function argument, instead of storing it internally."
33526,Error while trying to use tf.broadcast_weights ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Google Colab)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Google Colab
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0
- Python version: 3.x
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: - 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Unable to import tf.broadcast_weights in TF 2.0. 

**Describe the expected behavior**
Should be able to import tf.broadcast_weights in TF 2.0

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

Method 1: Plain python + TF 2.0
```
import tensorflow as tf     # version 2.0
tf.broadcast_weights
```
_throws_ ** AttributeError: module 'tensorflow' has no attribute 'broadcast_weights'**

Method 2: Codelab
I found this error in a recent TF 2.0 + Keras tutorial - https://colab.sandbox.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO

- Search for ""broadcast_weights"" in this codelab. 
- Run all cells before this.
- Modify code ""m.update_state([0, 1, 1, 1], [0, 1, 0, 0])"" to ""m.update_state([0, 1, 1, 1], [0, 1, 0, 0]), sample_weight=[0.1,0.2,0.3,0.4]""
- Run this cell
- throws AttributeError: module 'tensorflow' has no attribute 'broadcast_weights'

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33525,how can tf.image.crop_and_resize receive a tensor as crop box? ,"### I have a proble with tf.image.crop_and_resize()
I have two tensor now, one with a dimension of (4,4,1), the other with a dimension of (1732,1732,3). I tried to get the index of maximum of the first tensor. and use the index multiply 433 as an index to crop the other tensor. But when I use tf.where to get the index, it returns a tensor, the tf.image.crop_and_resize just receive float32 as the box, I use keras to build a model, how can I transform the tensor index into value without run a session. 



"
33519,"TensorFlow models example hangs after changing to ""bazel build --config=v2""","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0.0
- Python version: 2.7.12
- Bazel version (if compiling from source): 0.26.0
- GCC/Compiler version (if compiling from source): g++ 5.4.0 20160609
- CUDA/cuDNN version: CUDA 10.0 / cuDNN 7.5.1.10-1+cuda10.0 (+ additional CUDA 10.1 runtime needed for NCCL libs)
- GPU model and memory: NVIDIA Tesla K40m

**Describe the current behavior**
Observed within [Mellanox TensorFlow CI](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/ci_build#mellanox-tensorflow-ci) after https://github.com/tensorflow/tensorflow/commit/2a8e8706a423a141bbdb7a8f99276c8aff172b4f commit.
We run TensorFlow models example on a 2-node cluster (1 GPU per a host): https://github.com/tensorflow/models/blob/master/official/r1/resnet/imagenet_test.py
```
python imagenet_main.py \
    --num_gpus=1 \
    --use_synthetic_data \
    --train_epochs=1 \
    --max_train_steps=100 \
    --use_train_and_evaluate=True \
    --all_reduce_alg=nccl \
    --worker_hosts ""host1:12346,host2:12346"" \
    --task_index ${TASK_INDEX} \
    --distribution_strategy=multi_worker_mirrored \
    --clean
```
**NOTE**: Custom version of NCCL is used. If needed I can try to reproduce the issue with the public NCCL version.
TensorFlow build scenario:
```
$ cat ./.tf_configure.bazelrc
build --host_force_python=PY2
build --action_env PYTHON_BIN_PATH=""/usr/bin/python""
build --action_env PYTHON_LIB_PATH=""/usr/local/lib/python2.7/dist-packages""
build --python_path=""/usr/bin/python""
build:xla --define with_xla_support=true
build --action_env TF_CUDA_VERSION=""10.0""
build --action_env TF_CUDNN_VERSION=""7""
build --action_env TF_NCCL_VERSION=""2.4.7""
build --action_env CUDA_TOOLKIT_PATH=""<localpath>/cuda10.0""
build --action_env CUDNN_INSTALL_PATH=""/usr""
build --action_env NCCL_INSTALL_PATH=""<localpath>""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""3.5""
build --action_env LD_LIBRARY_PATH=""<localpath>""
build --action_env GCC_HOST_COMPILER_PATH=""/usr/bin/gcc""
build --config=cuda
build:opt --copt=-march=native
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_tag_filters=-benchmark-test,-no_oss,-oss_serial
test --build_tag_filters=-benchmark-test,-no_oss
test --test_tag_filters=-no_gpu
test --build_tag_filters=-no_gpu
test --test_env=LD_LIBRARY_PATH
build --action_env TF_CONFIGURE_IOS=""0""
$ ./configure
$ bazel build --config=opt --config=cuda --config=v2 //tensorflow/tools/pip_package:build_pip_package
$ ./bazel-bin/tensorflow/tools/pip_package/build_pip_package --nightly_flag /tmp/tensorflow_pkg_$$
```
**NOTE**: the scenario works fine with `bazel build ... --config=v1 ...`

**Describe the expected behavior**
Mentioned test scenario should not hang.

**Code to reproduce the issue**
See above.

**Other info / logs**
Log files from the hanging test run (`bazel build ... --config=v2 ...`):
[run_tf_models_imagenet_host1_bad.log](https://github.com/tensorflow/tensorflow/files/3745290/run_tf_models_imagenet_host1_bad.log)
[run_tf_models_imagenet_host2_bad.log](https://github.com/tensorflow/tensorflow/files/3745292/run_tf_models_imagenet_host2_bad.log)
Log files from the working test run (`bazel build ... --config=v1 ...`):
[run_tf_models_imagenet_host1_good.log](https://github.com/tensorflow/tensorflow/files/3745291/run_tf_models_imagenet_host1_good.log)
[run_tf_models_imagenet_host2_good.log](https://github.com/tensorflow/tensorflow/files/3745293/run_tf_models_imagenet_host2_good.log)
"
33517,[TF 2.0] Using keras.metrics in TPU training results in error,"I am trying to train a BERT model from https://github.com/tensorflow/models/tree/master/official/nlp on TPU in google colab. I changed the metrics list passed to model in compile method to:
```
bert_model.compile(optimizer=optimizer, loss=loss_fn, metrics=get_metrics())
```
where _get_metrics_ is a function which returns a list of metrics (""accuracy"" and instance for Recall and Precision built in _tensorflow.keras.metrics_):

```
from tensorflow.keras.metrics import Recall, Precision

def get_metrics():
    return [""accuracy"",
            Recall(),
            Precision(), ]
```

Training results in the following error (after one epoch ends, before validation statistics are displayed):

```
I1018 16:34:07.313311 140541208393600 remote.py:151] Entering into master device scope: /job:worker/replica:0/task:0
2019-10-18 16:34:07.359467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-10-18 16:34:07.465723: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-18 16:34:07.465842: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7b6f1b4d4089): /proc/driver/nvidia/version does not exist
2019-10-18 16:34:07.466260: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-18 16:34:07.472748: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-10-18 16:34:07.473076: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3172f40 executing computations on platform Host. Devices:
2019-10-18 16:34:07.473114: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-10-18 16:34:07.475920: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job worker -> {0 -> 10.29.203.98:8470}
2019-10-18 16:34:07.475955: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30501}
2019-10-18 16:34:07.476742: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:30501
2019-10-18 16:34:07.497844: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job worker -> {0 -> 10.29.203.98:8470}
2019-10-18 16:34:07.497905: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30501}
INFO:tensorflow:Initializing the TPU system: 10.29.203.98:8470
I1018 16:34:07.499603 140541208393600 tpu_strategy_util.py:70] Initializing the TPU system: 10.29.203.98:8470
INFO:tensorflow:Clearing out eager caches
I1018 16:34:15.119202 140541208393600 tpu_strategy_util.py:94] Clearing out eager caches
INFO:tensorflow:Finished initializing TPU system.
I1018 16:34:15.121769 140541208393600 tpu_strategy_util.py:114] Finished initializing TPU system.
INFO:tensorflow:Found TPU system:
I1018 16:34:15.128222 140541208393600 tpu_system_metadata.py:148] Found TPU system:
INFO:tensorflow:*** Num TPU Cores: 8
I1018 16:34:15.128440 140541208393600 tpu_system_metadata.py:149] *** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Workers: 1
I1018 16:34:15.129121 140541208393600 tpu_system_metadata.py:150] *** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
I1018 16:34:15.129209 140541208393600 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
I1018 16:34:15.129295 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
I1018 16:34:15.129720 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
I1018 16:34:15.129811 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
I1018 16:34:15.129892 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
I1018 16:34:15.129969 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
I1018 16:34:15.130045 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
I1018 16:34:15.130121 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
I1018 16:34:15.130197 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
I1018 16:34:15.130281 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
I1018 16:34:15.130358 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
I1018 16:34:15.130436 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
I1018 16:34:15.130511 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
I1018 16:34:15.130593 140541208393600 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
I1018 16:34:15.248266 140541208393600 train.py:212] Training using TF 2.0 Keras compile/fit API with distrubuted strategy.
WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.
W1018 16:35:33.236943 140541208393600 training_utils.py:1547] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.
Train on 129 steps, validate on 65 steps
Epoch 1/5
2019-10-18 16:38:03.018892: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-18 16:38:03.020371: E tensorflow/core/platform/default/device_tracer.cc:70] CUDA error: CUDA_ERROR_NO_DEVICE
  1/129 [..............................] - ETA: 5:12:28 - loss: 1.0083 - accuracy: 0.2031 - recall: 0.1719 - precision: 0.2619WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.610206). Check your callbacks.
W1018 16:38:06.456197 140541208393600 callbacks.py:244] Method (on_train_batch_end) is slow compared to the batch update (1.610206). Check your callbacks.
128/129 [============================>.] - ETA: 1s - loss: 0.5022 - accuracy: 0.7563 - recall: 0.5862 - precision: 0.81392019-10-18 16:38:45.271991: E tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:50] Unable to destroy remote tensor handles: Unable to find the relevant tensor remote_handle: Op ID: 55877, Output num: 0
Additional GRPC error information:
{""created"":""@1571416725.271891392"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Unable to find the relevant tensor remote_handle: Op ID: 55877, Output num: 0"",""grpc_status"":3}
2019-10-18 16:38:45.272429: E tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:50] Unable to destroy remote tensor handles: Unable to find the relevant tensor remote_handle: Op ID: 55877, Output num: 1
Additional GRPC error information:
{""created"":""@1571416725.272350919"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Unable to find the relevant tensor remote_handle: Op ID: 55877, Output num: 1"",""grpc_status"":3}
2019-10-18 16:38:45.272841: E tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:50] Unable to destroy remote tensor handles: Unable to find the relevant tensor remote_handle: Op ID: 55877, Output num: 2
Additional GRPC error information:
{""created"":""@1571416725.272756237"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Unable to find the relevant tensor remote_handle: Op ID: 55877, Output num: 2"",""grpc_status"":3}
2019-10-18 16:38:45.273165: E tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:50] Unable to destroy remote tensor handles: Unable to find the relevant tensor remote_handle: Op ID: 55877, Output num: 3
Additional GRPC error information:
{""created"":""@1571416725.273105048"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Unable to find the relevant tensor remote_handle: Op ID: 55877, Output num: 3"",""grpc_status"":3}
Traceback (most recent call last):
  File ""/usr/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/gdrive/My Drive/DeepLearningBERT/nn/train.py"", line 340, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/gdrive/My Drive/DeepLearningBERT/nn/train.py"", line 332, in main
    run_bert(strategy, input_meta_data)
  File ""/gdrive/My Drive/DeepLearningBERT/nn/train.py"", line 287, in run_bert
    use_keras_compile_fit=FLAGS.use_keras_compile_fit)
  File ""/gdrive/My Drive/DeepLearningBERT/nn/train.py"", line 226, in run_bert_classifier
    custom_callbacks=None)
  File ""/gdrive/My Drive/DeepLearningBERT/nn/train.py"", line 143, in run_keras_compile_fit
    callbacks=custom_callbacks)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 685, in fit
    steps_name='steps_per_epoch')
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py"", line 439, in model_iteration
    steps_name='validation_steps')
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py"", line 299, in model_iteration
    batch_outs = f(actual_inputs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py"", line 878, in execution_function
    return [out.numpy() for out in distributed_function(input_fn)]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 526, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 511, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.UnimplementedError:  Compilation failure: Asked to propagate a dynamic dimension from hlo %tuple.5198 = (pred[], f32[4,2]{1,0}) tuple(pred[] %convert.5196, f32[4,2]{1,0} %add.5004), metadata={op_type=""If"" op_name=""metrics/precision/assert_greater_equal/Assert/AssertGuard""}@{1}@0 to hlo %conditional.5209 = (pred[]) conditional(pred[] %convert.5196, (pred[], f32[4,2]{1,0}) %tuple.5198, (pred[], f32[4,2]{1,0}) %tuple.5198), true_computation=%metrics_precision_assert_greater_equal_Assert_AssertGuard_true_127733_const_0__.5199, false_computation=%metrics_precision_assert_greater_equal_Assert_AssertGuard_false_127734_const_0__.5204, metadata={op_type=""If"" op_name=""metrics/precision/assert_greater_equal/Assert/AssertGuard""}, which is not implemented.
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_6193329545322784681/_7}}]]
Additional GRPC error information:
{""created"":""@1571416725.270929013"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":"" Compilation failure: Asked to propagate a dynamic dimension from hlo %tuple.5198 = (pred[], f32[4,2]{1,0}) tuple(pred[] %convert.5196, f32[4,2]{1,0} %add.5004), metadata={op_type=""If"" op_name=""metrics/precision/assert_greater_equal/Assert/AssertGuard""}@{1}@0 to hlo %conditional.5209 = (pred[]) conditional(pred[] %convert.5196, (pred[], f32[4,2]{1,0}) %tuple.5198, (pred[], f32[4,2]{1,0}) %tuple.5198), true_computation=%metrics_precision_assert_greater_equal_Assert_AssertGuard_true_127733_const_0__.5199, false_computation=%metrics_precision_assert_greater_equal_Assert_AssertGuard_false_127734_const_0__.5204, metadata={op_type=""If"" op_name=""metrics/precision/assert_greater_equal/Assert/AssertGuard""}, which is not implemented.\n\tTPU compilation failed\n\t [[{{node tpu_compile_succeeded_assert/_6193329545322784681/_7}}]]"",""grpc_status"":12} [Op:__inference_distributed_function_127913]

Function call stack:
distributed_function -> distributed_function

2019-10-18 16:38:53.401848: E tensorflow/core/distributed_runtime/rpc/eager/grpc_eager_client.cc:72] Remote EagerContext with id 6450803200035565614 does not seem to exist.
```

With only ""accuracy"" returned it works well finishing all epochs. With custom metrics like:
```
def precision(y_true, y_pred):
    y_pred = tf.math.rint(y_pred)
    TP = tf.math.reduce_sum(y_pred * y_true)
    FP = tf.math.reduce_sum(y_pred * (1 - y_true))

    _precision = tf.math.divide(TP, (TP + FP + eps))
    return _precision
```
it works as well, but the values returned are not correct. I suppose this is happening because on the TPU there are X steps per loop computed and somehow (I didn't dig too much into it) messes up the output metric. I tried with builtin functions to verify the behavior but it resulted in the error previously mentioned.

Snippet of the training call (the function is called _run_keras_compile_fit_ in the github link I provided and it can be found in _bert/run_classifier.py_ with almost none custom code added):
```
    with strategy.scope():
        training_dataset = train_input_fn()
        evaluation_dataset = eval_input_fn()
        bert_model, sub_model = model_fn()
        optimizer = bert_model.optimizer

        if init_checkpoint:
            checkpoint = tf.train.Checkpoint(model=sub_model)
            checkpoint.restore(init_checkpoint).assert_existing_objects_matched()

        bert_model.compile(optimizer=optimizer, loss=loss_fn, metrics=get_metrics())

        summary_dir = os.path.join(model_dir, 'summaries')
        summary_callback = tf.keras.callbacks.TensorBoard(summary_dir)
        checkpoint_path = os.path.join(model_dir, 'checkpoint')
        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
            checkpoint_path, save_weights_only=True, save_best_only=True, mode='min')

        if custom_callbacks is not None:
            custom_callbacks += [summary_callback, checkpoint_callback]
        else:
            custom_callbacks = [summary_callback, checkpoint_callback]

        bert_model.fit(
            x=training_dataset,
            validation_data=evaluation_dataset,
            steps_per_epoch=steps_per_epoch,
            epochs=epochs,
            validation_steps=eval_steps,
            callbacks=custom_callbacks)

        return bert_model
```
In colab I installed the stable release of tensorflow 2.0 as the nightly version doesn't work well with colab's TPU's for now. The keras metrics are supposed to work with TPUs or this is not yet a feature?"
33516,Dataset.map() with tf.data.experimental.AUTOTUNE runs out of memory when using batch size=1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 19.04 Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not tried on Mobile
- TensorFlow installed from (source or binary): BINARY
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7
- Bazel version (if compiling from source): NO
- GCC/Compiler version (if compiling from source): NO
- CUDA/cuDNN version: CUDA 10.0 cuDNN 7.6
- GPU model and memory: RTX2070 8GB

**Describe the current behavior**
I use Dataset.map to normalize images. When using tf.data.experimental.AUTOTUNE and BATCH_SIZE of 1, memory consumption grows up till the program is killed. The most intriguing part is that when setting the BATCH_SIZE to greater than 1, the program works correctly

This issue happens both with tensorflow 2.0.0 and tensorflow-gpu 2.0.0

**Describe the expected behavior**
Code should work for batch size of 1

**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow.keras.layers import Flatten, Dense, Reshape
from tensorflow.keras.losses import MeanSquaredError


(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()
train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')

# Setting this here to True will break the code
TOGGLE_ERROR = True
if TOGGLE_ERROR:
    BATCH_SIZE = 1
else:
    BATCH_SIZE = 3


def map_function(train_image):
    return (train_image - 127.5) / 127.5


train_dataset = tf.data.Dataset.from_tensor_slices(train_images)
train_dataset = train_dataset.repeat()
train_dataset = train_dataset.map(map_function, tf.data.experimental.AUTOTUNE)
train_dataset = train_dataset.batch(BATCH_SIZE)
train_dataset = train_dataset.prefetch(64)


class AutoEncoder(tf.keras.Model):
    def __init__(self):
        super(AutoEncoder, self).__init__()
        self.flatten = Flatten()
        self.dense_1 = Dense(128, activation=""relu"")
        self.dense_2 = Dense(784, activation=""relu"")
        self.reshape = Reshape((28, 28, 1))

    @tf.function
    def call(self, inputs):
        flatten = self.flatten(inputs)
        encoded = self.dense_1(flatten)
        decoded = self.dense_2(encoded)
        return self.reshape(decoded)


auto_encoder = AutoEncoder()
mse = MeanSquaredError()
optimizer = tf.keras.optimizers.Adam(1e-5)


@tf.function
def train_step(batch):
    with tf.GradientTape() as tape:
        auto_encoded = auto_encoder(batch)
        loss = mse(batch, auto_encoded)

    grads = tape.gradient(loss, auto_encoder.trainable_variables)
    optimizer.apply_gradients(zip(grads, auto_encoder.trainable_variables))
    return loss


for step, image_batch in enumerate(train_dataset):
    loss = train_step(image_batch)
    if step % 1000 == 0:
        print(loss)
```
**Other info / logs**
Might be related to [Issue #32052](https://github.com/tensorflow/tensorflow/issues/32052)"
33515,"tf.lite operators missing for `tf.nn.ctc_loss`: `Empty`, `InplaceAdd` and `While`","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.0.0


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_o
ps, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXP, EXPAND_DIMS, FLOOR_DIV, FULLY_CONNECTED, GATHER,
 LESS, LOG, LOG_SOFTMAX, MAXIMUM, MAX_POOL_2D, MEAN, MUL, NEG, ONE_HOT, PACK, PAD, PADV2, RANGE, RESHAPE, SHAPE, SPLIT_V, SQRT, SQUARE, SQUEEZE, STRIDED_SLICE, SUB, SUM, TILE, TRANSPOSE. Here is a list of operators for which
 you will need custom implementations: Empty, InplaceAdd, While.
Traceback (most recent call last):
  File ""/Users/ben/miniconda3/envs/wakeword/bin/toco_from_protos"", line 10, in <module>
    sys.exit(main())
  File ""/Users/ben/miniconda3/envs/wakeword/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main                                                                                
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/Users/ben/miniconda3/envs/wakeword/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run                                                                                               
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/ben/miniconda3/envs/wakeword/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/ben/miniconda3/envs/wakeword/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/ben/miniconda3/envs/wakeword/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute                                                                             
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflo
w/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_o
ps, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXP, EXPAND_DIMS, FLOOR_DIV, FULLY_CONNECTED, GATHER,
 LESS, LOG, LOG_SOFTMAX, MAXIMUM, MAX_POOL_2D, MEAN, MUL, NEG, ONE_HOT, PACK, PAD, PADV2, RANGE, RESHAPE, SHAPE, SPLIT_V, SQRT, SQUARE, SQUEEZE, STRIDED_SLICE, SUB, SUM, TILE, TRANSPOSE. Here is a list of operators for which
 you will need custom implementations: Empty, InplaceAdd, While.
```

**Any other info / logs**

I'm trying to convert a keras model using tf.lite. The last layer of the model uses the `tf.nn.ctc_loss` in its `call` method. When I leave this layer off the model, the conversion works just fine.

Apparantly, only three operators are missing from making this work: `Empty`, `InplaceAdd` and `While`.

The error message also says this:
```
2019-10-18 18:19:25.694843: W tensorflow/lite/toco/tflite/operator.cc:2692] Op Empty is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.                                                 
2019-10-18 18:19:25.694848: W tensorflow/lite/toco/tflite/operator.cc:2692] Op InplaceAdd is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.                                            
2019-10-18 18:19:25.694852: W tensorflow/lite/toco/tflite/operator.cc:2692] Op While is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set. 
```
Does this mean that the only thing missing from making this work is to somehow add these operators to the whitelist? Is this something that users can do? How are the chances that these operators are going to be included in tf.lite by default in the near feature?

Thanks!"
33513,Cannot build libtensorflowlite_c.so -- problem with bazel build,"**System information**
- Windows 10 64-bit
- TensorFlow installed from (source or binary): source
- TensorFlow version: v2.0.0
- Python version: 3.7.4
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): v1.0.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the problem**

I am trying to build libtensorflowlite_c.so following the instructions at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/examples/unity/TensorFlowLitePlugin/README.md but the build is failing the the following log.

**Any other info / logs**
First run log:
```
C:\Users\Lorenzo\Documents\tensorflow>bazel build -c opt --cxxopt=--std=c++11 \
INFO: Writing tracer profile to 'C:/users/lorenzo/_bazel_lorenzo/6xammqtc/command.profile.gz'
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=172
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/Lorenzo/AppData/Local/Programs/Python/Python37/python.exe
INFO: Reading rc options for 'build' from c:\users\lorenzo\documents\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --config=v2
INFO: Found applicable config definition build:v2 in file c:\users\lorenzo\documents\tensorflow\.bazelrc: --define=tf_api_version=2
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/bazelbuild/bazel-toolchains/archive/92dd8a7a518a2fb7ba992d47c8b38299fe0be825.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at C:/users/lorenzo/_bazel_lorenzo/6xammqtc/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):
 - C:/users/lorenzo/_bazel_lorenzo/6xammqtc/external/bazel_toolchains/repositories/repositories.bzl:37:9
 - C:/users/lorenzo/documents/tensorflow/WORKSPACE:37:1
ERROR: Skipping '\': Bad target pattern '\': package names may contain A-Z, a-z, 0-9, or any of ' !""#$%&'()*+,-./;<=>?[]^_`{|}~' (most 7-bit ascii characters except 0-31, 127, ':', or '\')
WARNING: Target pattern parsing failed.
ERROR: Bad target pattern '\': package names may contain A-Z, a-z, 0-9, or any of ' !""#$%&'()*+,-./;<=>?[]^_`{|}~' (most 7-bit ascii characters except 0-31, 127, ':', or '\')
INFO: Elapsed time: 0.139s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
```

Second run log:
```
C:\Users\Lorenzo\Documents\tensorflow>bazel build -c opt --cxxopt=--std=c++11 //tensorflow/lite/experimental/c:libtensorflowlite_c.so
INFO: Writing tracer profile to 'C:/users/lorenzo/_bazel_lorenzo/6xammqtc/command.profile.gz'
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=172
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/Lorenzo/AppData/Local/Programs/Python/Python37/python.exe
INFO: Reading rc options for 'build' from c:\users\lorenzo\documents\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --config=v2
INFO: Found applicable config definition build:v2 in file c:\users\lorenzo\documents\tensorflow\.bazelrc: --define=tf_api_version=2
INFO: Build options --cxxopt, --host_cxxopt, --host_java_toolchain, and 1 more have changed, discarding analysis cache.
INFO: Call stack for the definition of repository 'com_google_protobuf' which is a tf_http_archive (rule definition at C:/users/lorenzo/documents/tensorflow/third_party/repo.bzl:124:19):
 - C:/users/lorenzo/documents/tensorflow/tensorflow/workspace.bzl:432:5
 - C:/users/lorenzo/documents/tensorflow/WORKSPACE:19:1
INFO: Repository 'com_google_protobuf' used the following cache hits instead of downloading the corresponding file.
 * Hash 'b9e92f9af8819bbbc514e2902aec860415b70209f31dfc8c4fa72515a5df9d59' for https://storage.googleapis.com/mirror.tensorflow.org/github.com/protocolbuffers/protobuf/archive/310ba5ee72661c081129eb878c1bbcec936b20f0.tar.gz
If the definition of 'com_google_protobuf' was updated, verify that the hashes were also updated.
ERROR: An error occurred during the fetch of repository 'com_google_protobuf':
   Traceback (most recent call last):
        File ""C:/users/lorenzo/documents/tensorflow/third_party/repo.bzl"", line 104
                _apply_patch(ctx, ctx.attr.patch_file)
        File ""C:/users/lorenzo/documents/tensorflow/third_party/repo.bzl"", line 70, in _apply_patch
                _wrap_bash_cmd(ctx, patch_command)
        File ""C:/users/lorenzo/documents/tensorflow/third_party/repo.bzl"", line 28, in _wrap_bash_cmd
                fail(""BAZEL_SH environment variable i..."")
BAZEL_SH environment variable is not set
ERROR: Analysis of target '//tensorflow/lite/experimental/c:libtensorflowlite_c.so' failed; build aborted: no such package '@com_google_protobuf//': Traceback (most recent call last):
        File ""C:/users/lorenzo/documents/tensorflow/third_party/repo.bzl"", line 104
                _apply_patch(ctx, ctx.attr.patch_file)
        File ""C:/users/lorenzo/documents/tensorflow/third_party/repo.bzl"", line 70, in _apply_patch
                _wrap_bash_cmd(ctx, patch_command)
        File ""C:/users/lorenzo/documents/tensorflow/third_party/repo.bzl"", line 28, in _wrap_bash_cmd
                fail(""BAZEL_SH environment variable i..."")
BAZEL_SH environment variable is not set
INFO: Elapsed time: 4.906s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (1 packages loaded, 0 targets configured)
    currently loading: tensorflow
```
"
33512,OutOfRangeError: End of sequence [Op:IteratorGetNextSync] with tf.data,"TensorFlow version: 2.0.0
Platform: Jupyter Notebook (macOS)

**Description**: I am trying to determine the time it takes to load the entire FashionMNIST dataset in a batch-wise manner with `td.data`. I am using the following utility script taken from [here](https://www.tensorflow.org/tutorials/load_data/images#performance):

```python
import time
default_timeit_steps = 1000

def timeit(ds, steps=default_timeit_steps):
  start = time.time()
  it = iter(ds)
  for i in range(steps):
    batch = next(it)
    if i%10 == 0:
      print('.',end='')
  print()
  end = time.time()

  duration = end-start
  print(""{} batches: {} s"".format(steps, duration))
  print(""{:0.5f} Images/s"".format(BATCH_SIZE*steps/duration))
```

Here's the [Jupyter Notebook](https://colab.research.google.com/drive/1jX30MMQmEbiNfz15a-UXmGk8v5KPD76V) with which the error can be reproduced. Following is the error trace:

```
---------------------------------------------------------------------------
OutOfRangeError                           Traceback (most recent call last)
/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in next(self)
    665     try:
--> 666       return self._next_internal()
    667     except errors.OutOfRangeError:

/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in _next_internal(self)
    650             output_types=self._flat_output_types,
--> 651             output_shapes=self._flat_output_shapes)
    652 

/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py in iterator_get_next_sync(iterator, output_types, output_shapes, name)
   2672         message = e.message
-> 2673       _six.raise_from(_core._status_to_exception(e.code, message), None)
   2674   # Add nodes to the TensorFlow graph.

/miniconda3/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

OutOfRangeError: End of sequence [Op:IteratorGetNextSync]

During handling of the above exception, another exception occurred:

StopIteration                             Traceback (most recent call last)
<ipython-input-8-7ac545d60e99> in <module>
      1 # `tf.data`
----> 2 timeit(train_dataset)

<ipython-input-6-386e91380544> in timeit(ds, steps)
      6     it = iter(ds)
      7     for i in range(steps):
----> 8         batch = next(it)
      9         if i%10 == 0:
     10             print('.',end='')

/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in __next__(self)
    620 
    621   def __next__(self):  # For Python 3 compatibility
--> 622     return self.next()
    623 
    624   def _next_internal(self):

/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in next(self)
    666       return self._next_internal()
    667     except errors.OutOfRangeError:
--> 668       raise StopIteration
    669 
    670   @property

StopIteration: 
```

"
33511,Using GPU for Tflite on Android,"My first problem was it this post #33011  So for now I have code which works according to answers from the previousl post.  
                float[] masked = coreResult.getMasked();
                float[] inverted = coreResult.getInverted();

                byteBufferMasked.asFloatBuffer().put(masked);
                byteBufferInverted.asFloatBuffer().put(inverted);
                Object[] inputs = new Object[]{byteBufferMasked, byteBufferInverted};
                Map<Integer, Object> outputs = new HashMap();
                outputs.put(0, byteBufferOutput);

                interpreter.runForMultipleInputsOutputs(inputs, outputs);

                byteBufferOutput.rewind();
                byteBufferOutput.asFloatBuffer().get(output);
                initializeSecond(coreRequest, output);
                interpreter.close();
output is resulf float array and method initializeSecond() make the bitmap from this array.
This code takes about 16-20 sec.And almost all this time is working of the model in the following line:
                interpreter.runForMultipleInputsOutputs(inputs, outputs);
I have added some threads through: 
               new Interpreter.Options().setNumThreads(4)
And now it works faster in 2 times(interesting thing - if I put for example 4 threads or 20 threads - result the same). And this results are only for strong phones, for old models - it is about 20 sec after adding threads.(without it - about 35 sec)
So it  I am trying to add GPU delegate supporting for my Interpreter. According to Tflite docs from here https://www.tensorflow.org/lite/performance/gpu_advanced I am trying the following
                GpuDelegate delegateGPU = new GpuDelegate();
                interpreter = new Interpreter(map,  new 
                Interpreter.Options().addDelegate(delegateGPU).setNumThreads(4));
And result is the same.(But in the demo from docs it is enough for GPU supporting) And the one thing that I did not do - adding OpenGL Shader (SSBO). And the main my problem I can not completry understant how I can implement it for my case. First of all I have two inputs and one output.  The code from tflite GPU demo is about getting bitmap from camera, in my case I already have the two inputs as images. I have seens in the docs that we can do it for only inputs or for only outputs, right? 
If yes I do not know maybe in my case it will be better for output considering that I have two inputs. Also if I run  runForMultipleInputsOutputs(inputs, null); I will have the exception about null parameter. 
And only now I understand that method interpreter.runInference(null, outputArray); from GPU docs is from Tflite demo. And I think it is not so good for understanding. Also if I should do it for output I can not understand what is means the method from GPU docs : renderOutputSsbo(outputSsboId); There is not this function in the demo."
33510,Using GPU for Tflite on Android,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33509,Not allowed to load local resource on chrome,"I have downloaded the examples/Iris file from github, and follow REAMME.md.
But when I enter the link
`yarn watch`
The server was built, and the chrome came automatically. 
But the css file and js file wasn't called successfully.
 When I read the console, it was said that
**"" Not allowed to load local resource file:///C:/Program%20Files/Git/tfjs-examples.44bb3400.css ""**
I spent two days finding the answers but i failed. Hope someone could help me.."
33506,How do we need to slice tensor in forward pass for writing the custom loss function.,"I have created on a network for which input will be 

input shape is : (20, 16, 240, 320, 3)
output (logits is ) : Tensor(""logits:0"", shape=(?, 1), dtype=float32)
i,e  output in forward pass  for my network is 
`[array([[ -3.8974638 ],
       [ -5.2204075 ],
       [ -3.105205  ],
       [ -3.4843988 ],
       [ -4.0670795 ],
       [ -2.097713  ],
       [  2.6989975 ],
       [  3.1498132 ],
       [  2.3710475 ],
       [  2.0358462 ],
       [ -9.698921  ],
       [ -3.48162   ],
       [ -3.4569516 ],
       [ -2.9997227 ],
       [ -6.9699297 ],
       [-10.641993  ],
       [  2.6629193 ],
       [ -0.03444159],
       [ -1.6006284 ],
       [ -4.1530366 ]], dtype=float32)]
`
Now I want write loss functions on this logits as below mentioned 

loss = max(0,1-max(logits[0:10])+max(logits[10:20]) so that I can proceed for back prop.

How can I do this in  : tensorflow==1.14.0

"
33504,module 'tensorflow' has no attribute 'ConfigProto',"```python
import tensorflow as tf
import os
config = tf.ConfigProto()

AttributeError: module 'tensorflow' has no attribute 'ConfigProto'
```"
33503,Model.fit displays wrong information on progress bars for attrs classes,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes, a minimal self-contained python script demonstrating the bug

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
OSX

- TensorFlow installed from (source or binary):
Installed from anaconda

- TensorFlow version (use command below):
1.14

- Python version:
3.6.9

**Describe the current behavior**
Wrong progress bar information [1000/12] overly long progress bar

**Describe the expected behavior**
Correct progress bar information [100/100] progress bar reasonably short

**Code to reproduce the issue**
```python
import attr
import numpy as np

from tensorflow.python.keras import Input, Model
from tensorflow.python.keras.layers import Dense
from tensorflow.python.keras.optimizers import SGD
from tensorflow.python.keras.utils import Sequence


def make_model(D):
    x = Input(shape=[D])
    y = Dense(1, activation=None)(x)
    model = Model(inputs=x, outputs=y)
    model.compile(optimizer=SGD(), loss=""mean_squared_error"")
    return model


@attr.s
class Feed(Sequence):
    foo = attr.ib(default=np.arange(12))  # Remove this attribute to get the expected behaviour
    batch_size = attr.ib(default=10)
    feature_dimension = attr.ib(default=3)

    def __getitem__(self, idx):
        features = np.random.randn(self.batch_size, self.feature_dimension)
        targets = np.sum(features, axis=1, keepdims=True)
        return features, targets

    def __len__(self):
        return 100


if __name__ == ""__main__"":
    feed = Feed()
    model = make_model(feed.feature_dimension)
    model.fit(x=feed, epochs=10)
```

**Other info / logs**
The bug is caused by 
```python
def _get_num_samples_or_steps(data, steps_per_epoch):
  """"""Returns number of samples or steps, and whether to use steps count mode.""""""
  flat_inputs = nest.flatten(data)
  if hasattr(flat_inputs[0], 'shape'):
    return int(flat_inputs[0].shape[0]), False
  return steps_per_epoch, True
```
in module `tensorflow.python.keras.engine.training_generator`.

`_get_num_samples_or_steps` should always return `steps_per_epoch, True` for a `Sequence` irrespective of the `attrs.Attributes` of the class implementing the `Sequence` interface. 

The statement `if data_utils.is_generator_or_sequence(x):` in module `tensorflow.python.keras.engine.training` is already ensuring that the passed object is a `Sequence` and therefore the call to function `_get_num_samples_or_steps` seems superfluous.
"
33502,please fix docs  converter = tf.lite.TFLiteConverter.from_keras_model(model) doesn't work,"Please update docs this example doesn't work

https://www.tensorflow.org/lite/convert/python_api#converting_a_keras_model_

Converting a Keras model 
The following example shows how to convert a tf.keras model into a TensorFlow Lite FlatBuffer.

import tensorflow as tf

# Create a simple Keras model.
x = [-1, 0, 1, 2, 3, 4]
y = [-3, -1, 1, 3, 5, 7]

model = tf.keras.models.Sequential(
    [tf.keras.layers.Dense(units=1, input_shape=[1])])
model.compile(optimizer='sgd', loss='mean_squared_error')
model.fit(x, y, epochs=50)

# Convert the model.
**converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()**

tf.__version__
'1.15.0-rc3'

output in colab 

AttributeError                            Traceback (most recent call last)
<ipython-input-31-68e491526aaa> in <module>()
     11 
     12 # Convert the model.
---> 13 converter = tf.lite.TFLiteConverter.get_input_arrays(model)
     14 tflite_model = converter.convert()

/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py in get_input_arrays(self)
   1001       List of strings.
   1002     """"""
-> 1003     if self._has_valid_tensors():
   1004       return [_get_tensor_name(tensor) for tensor in self._input_tensors]
   1005     else:

AttributeError: 'Sequential' object has no attribute '_has_valid_tensors'
"
33501,tf.keras.applications download path should be made configurable.,"The download path for the models downloaded using tf.keras.applications seems to be hardcoded to `~/.keras/models`.  
This path should be made configurable. 
It will benefit people who have less storage space in their home folder, which is a feature in many large-scale computational clusters."
33500,"In eager mode, how to achieve weight attenuation during training, and how to customize a layer learning rate？","My environment:
Tensorflow1.14-gpu
Hello, I have set up a CNN model in eager mode. Now, I want to set a weight decay, which I did on the old version:
`       
reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)

print(""Regularization losses:"")

opt_loss = loss + args.weight_decay*sum(reg_losses) 
 `
But in eager mode, this method is not very suitable. Is there any new way to provide it? I did not find a tutorial.

In addition, I want to customize the learning rate of some layers. For example, the feature extraction part of the network (such as mobilenetv3) only needs to use a small learning rate, while other parts need a large learning rate. How to achieve this?

I hope someone can help me, thank you very much."
33498,TFLite slower than Keras on RPi 4,"When doing inference on a Raspberry Pi 4 with Keras and Tensorflow installed using `pip`, the inference time is slower using TFLite. 

The initial Keras model is about 20 mb - after converting it to TFLite it is about 2.4 mb. During inference the Keras model processes a sample in about 50 ms and TFLite does it in about 80 ms. 

Initially the pip-installed version of Tensorflow caused errors with TFLite, so I installed TFLite-runtime using this information: https://www.tensorflow.org/lite/guide/python



During inference in TFLite I use the following snippet:
```python
interpreter = tflite.Interpreter(model_path=CHECKPOINT)
interpreter.allocate_tensors()

input_index = interpreter.get_input_details()[0][""index""]
output_index = interpreter.get_output_details()[0][""index""]

for im in images:
	t = time.time()
	
	inp = np.expand_dims(np.expand_dims(im,-1),0)

	interpreter.set_tensor(input_index, inp)
	interpreter.invoke()
	
	predictions = interpreter.get_tensor(output_index)

	print(""Time: {}"".format(time.time()-t),end=""\r"")
```

Does anybody have any experience with TFLite on Raspberry Pi? Am I missing something in order accelerate inference further? It seems wrong that inference should be faster in Keras with 10x model size."
33496,//tensorflow/python/kernel_tests:decode_raw_op_test fails with Assertion error,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 19.04 s390x
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 2.0.0
- Python version: 2.7.16
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 8.3.0-6ubuntu1) 8.3.0
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
The above test fails with the output array mismatch in [testToComplex64](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/kernel_tests/decode_raw_op_test.py#L105) and [testToComplex128](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/kernel_tests/decode_raw_op_test.py#L118).

The cause of failure seems to be in the byte swapping code to solve endianness problem [here](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/core/kernels/decode_raw_op.cc#L88). The code doesn't seem to work as intentioned for **complex data**.


**Describe the expected behavior**
The test should pass on s390x.

**Code to reproduce the issue**
```
bazel test //tensorflow/python/kernel_tests:decode_raw_op_test
```

**Other info / logs**
```
AssertionError:
Arrays are not equal

not equal where = (array([0, 0]), array([1, 2]))
not equal lhs = [[ 2.-2.j -3.+3.j]]
not equal rhs = [-2.+2.j  3.-3.j]
Mismatch: 0%
Max absolute difference: 8.48528137
Max relative difference: 2.
 x: matrix([[ 1.+1.j,  2.-2.j, -3.+3.j, -4.-4.j]])
 y: array([[ 1.+1.j, -2.+2.j,  3.-3.j, -4.-4.j]])

======================================================================
FAIL: testToComplex64 (__main__.DecodeRawOpTest)
testToComplex64 (__main__.DecodeRawOpTest)
----------------------------------------------------------------------
AssertionError:
Arrays are not equal

not equal where = (array([0, 0]), array([1, 2]))
not equal lhs = [[ 2.-2.j -3.+3.j]]
not equal rhs = [-2.+2.j  3.-3.j]
Mismatch: 0%
Max absolute difference: 8.485281
Max relative difference: 2.
 x: matrix([[ 1.+1.j,  2.-2.j, -3.+3.j, -4.-4.j]], dtype=complex64)
 y: array([[ 1.+1.j, -2.+2.j,  3.-3.j, -4.-4.j]], dtype=complex64)

----------------------------------------------------------------------
```
"
33495,Simple Audio Recognition validation seems error,"my tf version is 1.14.0. I download the code from the newest git for the example Simple Audio Recognition, and run the train.py, but after running several steps, the validation  acc seems not change at all, alse the confusion matrix, all the predict result is the first class. but the training acc is normal, after 8000 steps, about 80%.
![image](https://user-images.githubusercontent.com/31615877/67067057-7f5acb80-f1a7-11e9-852a-ca218bebd8a3.png)
![image](https://user-images.githubusercontent.com/31615877/67067081-939ec880-f1a7-11e9-85d2-f027f4a8749d.png)
"
33494,CTC tensorflow lite conversion problem,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 19.04
- TensorFlow installed from (source or binary):binary
- TensorFlow version (or github SHA if from source): 2.0


**Provide the text output from tflite_convert**
```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: . Here is a list of operators for which you will need custom implementations: CTC_BEAM_SEARCH_DECODER.```

Also, please include a link to a GraphDef or the model if possible.
import tensorflow as tf
class BasicModel(tf.Module):
  def __init__(self):
    self.const = None
  @tf.function(input_signature=[tf.TensorSpec(shape=[None,500,28], dtype=tf.float32),tf.TensorSpec(shape=[None,], dtype=tf.int32)])
  def decoder(self, logits,seq_len):
    decoded, log_prob = tf.nn.ctc_beam_search_decoder(logits, seq_len)
    return decoded
# Create the tf.Module object.
root = BasicModel()
# Get the concrete function.
concrete_func = root.decoder.get_concrete_function()
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.allow_custom_ops = False
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model =converter.convert()

open(""ctc_greedy_decoder.tflite"",'wb').write(tflite_model)

**Any other info / logs**

But according to this link https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/lite/experimental/kernels ctc_beam_search_decoder is registered as tflite op.

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33491,[TF2.0.0]ValueError: The two structures don't have the same nested structure.,"I can run my code in tensorflow==2.0.0b1, but when I update tensorflow to 2.0.0; I got an error;
This is my code:
```python
import tensorflow as tf
from tensorflow import feature_column

print('tf version:', tf.__version__)

feature_description = {
    'h_k_u_watchanch_his': tf.io.VarLenFeature(tf.string),
    'a_gender': tf.io.FixedLenFeature(shape=(1,), dtype=tf.int64),
    'l_label': tf.io.FixedLenFeature([], tf.int64)
}
feature_columns = []
thal = feature_column.categorical_column_with_hash_bucket(
    'h_k_u_watchanch_his', hash_bucket_size=100
)
thal_one_hot = feature_column.embedding_column(thal, dimension=10, combiner='mean')
feature_columns.append(thal_one_hot)

dataSet = tf.data.TFRecordDataset(
    ""/Users/lyx/projects/recommend/embedding/tmp/PUSH.TFRecords/dt=20191012/hour=10/part-r-00000"")


def _parse_function(serilized_example):
    feature = tf.io.parse_single_example(
        serilized_example,
        feature_description
    )
    label = feature.get('l_label')
    return feature, label


parsed_dataset = dataSet.map(_parse_function)

input1 = tf.keras.Input(shape=(), name='h_k_u_watchanch_his', sparse=True, dtype=tf.string)
input2 = tf.keras.Input(shape=(), name='a_gender', dtype=tf.int64)

input_layers = {'h_k_u_watchanch_his': input1, 'a_gender': input2}
feature_layer = tf.keras.layers.DenseFeatures(feature_columns, name='DenseFeatures')(input_layers)
outputs = tf.keras.layers.Dense(1, activation='sigmoid')(feature_layer)
model = tf.keras.Model(inputs=[input1, input2], outputs=outputs)

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.fit(
    x=parsed_dataset,
    validation_data=parsed_dataset,
    epochs=5,
)

loss, accuracy = model.evaluate(parsed_dataset)
print(""Accuracy"", accuracy)
```

Error output:
```
tf version: 2.0.0
2019-10-18 09:59:10.095365: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-18 09:59:10.118556: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbcd9c21e00 executing computations on platform Host. Devices:
2019-10-18 09:59:10.118572: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py"", line 318, in assert_same_structure
    expand_composites)
ValueError: The two structures don't have the same nested structure.

First structure: type=TensorSpec str=TensorSpec(shape=(1,), dtype=tf.int64, name=None)

Second structure: type=SparseTensor str=SparseTensor(indices=Tensor(""h_k_u_watchanch_his/indices:0"", shape=(None, 1), dtype=int64), values=Tensor(""h_k_u_watchanch_his/values:0"", shape=(None,), dtype=string), dense_shape=Tensor(""h_k_u_watchanch_his/shape:0"", shape=(1,), dtype=int64))

More specifically: Substructure ""type=SparseTensor str=SparseTensor(indices=Tensor(""h_k_u_watchanch_his/indices:0"", shape=(None, 1), dtype=int64), values=Tensor(""h_k_u_watchanch_his/values:0"", shape=(None,), dtype=string), dense_shape=Tensor(""h_k_u_watchanch_his/shape:0"", shape=(1,), dtype=int64))"" is a sequence, while substructure ""type=TensorSpec str=TensorSpec(shape=(1,), dtype=tf.int64, name=None)"" is not

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/lyx/projects/recommend/embedding/tmp/test.py"", line 52, in <module>
    epochs=5,
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 224, in fit
    distribution_strategy=strategy)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 547, in _process_training_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 594, in _process_inputs
    steps=steps)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2497, in _standardize_user_data
    nest.assert_same_structure(a, b, expand_composites=True)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py"", line 325, in assert_same_structure
    % (str(e), str1, str2))
ValueError: The two structures don't have the same nested structure.

First structure: type=TensorSpec str=TensorSpec(shape=(1,), dtype=tf.int64, name=None)

Second structure: type=SparseTensor str=SparseTensor(indices=Tensor(""h_k_u_watchanch_his/indices:0"", shape=(None, 1), dtype=int64), values=Tensor(""h_k_u_watchanch_his/values:0"", shape=(None,), dtype=string), dense_shape=Tensor(""h_k_u_watchanch_his/shape:0"", shape=(1,), dtype=int64))

More specifically: Substructure ""type=SparseTensor str=SparseTensor(indices=Tensor(""h_k_u_watchanch_his/indices:0"", shape=(None, 1), dtype=int64), values=Tensor(""h_k_u_watchanch_his/values:0"", shape=(None,), dtype=string), dense_shape=Tensor(""h_k_u_watchanch_his/shape:0"", shape=(1,), dtype=int64))"" is a sequence, while substructure ""type=TensorSpec str=TensorSpec(shape=(1,), dtype=tf.int64, name=None)"" is not
Entire first structure:
.
Entire second structure:
.

```

Looking forward to your reply!"
33490,Some of the operators in the model are not supported by the standard TensorFlow Lite runtime!!!,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):

 OS Platform and Distribution: **WIn10**
 TensorFlow installed from  **binary**
  TensorFlow version  **TF2.0 '2.1.0-dev20191015'**


**Provide the text output from tflite_convert**

 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, FILL, LEAKY_RELU, MEAN, MUL, PACK, RESHAPE, REVERSE_V2, SHAPE, STRIDED_SLICE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.
Traceback (most recent call last):
  File ""d:\users\zhenk\anaconda3\envs\tensorflow2.0\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""d:\users\zhenk\anaconda3\envs\tensorflow2.0\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""D:\Users\zhenk\Anaconda3\envs\tensorflow2.0\Scripts\toco_from_protos.exe\__main__.py"", line 9, in <module>
  File ""d:\users\zhenk\anaconda3\envs\tensorflow2.0\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""d:\users\zhenk\anaconda3\envs\tensorflow2.0\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""d:\users\zhenk\anaconda3\envs\tensorflow2.0\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""d:\users\zhenk\anaconda3\envs\tensorflow2.0\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""d:\users\zhenk\anaconda3\envs\tensorflow2.0\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, FILL, LEAKY_RELU, MEAN, MUL, PACK, RESHAPE, REVERSE_V2, SHAPE, STRIDED_SLICE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.


Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Can you help me ? If I want to use this model in TensorFlow Lite , what shall I do? 

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33489,Issue building on OSX 10.13,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.13.6 High Sierra
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.14.0
- Python version: 3.7
- Bazel version (if compiling from source): 0.25.2
- GCC/Compiler version (if compiling from source): clang
- CUDA/cuDNN version: 10.1
- GPU model and memory: NVIDIA GeForce GTX 1080 ti

**Describe the problem**

Hi,
I am building Tensorflow 1.14.0 on my High Sierra, but I am facing an issue during the build time, I try also the latest 1.15.0 and I have exactly the same trouble, I try to find a solution but so far no luck, any idea or suggestion ?

It seems the issue is related to absl but looking and trying to modify the compressed_tuple.h do not seems to change anything.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
bazel build --config=cuda --config=opt --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env PATH --action_env LD_LIBRARY_PATH --action_env DYLD_LIBRARY_PATH //tensorflow/tools/pip_package:build_pip_package --verbose_failures --config=nonccl
```

**Any other info / logs**

```
external/com_google_absl/absl/container/internal/compressed_tuple.h:170:53: error: use 'template' keyword to treat 'Storage' as a dependent template name
return (std::move(*this).internal_compressed_tuple::Storage< CompressedTuple, I> ::get());
                                                    ^
                                                    template
external/com_google_absl/absl/container/internal/compressed_tuple.h:176:54: error: use 'template' keyword to treat 'Storage' as a dependent template name
return (absl::move(*this).internal_compressed_tuple::Storage< CompressedTuple, I> ::get());
                                                     ^
                                                     template
```"
33487,Why is TensorFlow 2 much slower than TensorFlow 1?,"It's been cited by many users as the reason for switching to Pytorch, but I've yet to find a justification / explanation for sacrificing the most important practical quality, speed, for eager execution.

Below is code benchmarking performance, TF1 vs. TF2 - with TF1 running anywhere from **47% to 276% faster**.

My question is: _what is it, at the graph or hardware level, that yields such a significant slowdown?_

<hr>

Looking for a detailed answer - am already familiar with broad concepts.  [Relevant SO](https://stackoverflow.com/questions/58441514/why-is-tensorflow-2-much-slower-than-tensorflow-1)

**Specs**: CUDA 10.0.130, cuDNN 7.4.2, Python 3.7.4, Windows 10, GTX 1070

<hr>

**Benchmark results**:

<img src=""https://i.stack.imgur.com/ayBCS.png"" width=""530"">

<hr>

**Benchmark code**:

```python
# use tensorflow.keras... to benchmark tf.keras; used GPU for all above benchmarks
from keras.layers import Input, Dense, LSTM, Bidirectional, Conv1D
from keras.layers import Flatten, Dropout
from keras.models import Model
from keras.optimizers import Adam
import keras.backend as K
import numpy as np
from time import time

batch_shape = (32, 400, 16)
X, y = make_data(batch_shape)

model_small = make_small_model(batch_shape)
model_small.train_on_batch(X, y)  # skip first iteration which builds graph
timeit(model_small.train_on_batch, 200, X, y)

K.clear_session()  # in my testing, kernel was restarted instead

model_medium = make_medium_model(batch_shape)
model_medium.train_on_batch(X, y)  # skip first iteration which builds graph
timeit(model_medium.train_on_batch, 10, X, y)
```

<hr>

**Functions used**:

```python
def timeit(func, iterations, *args):
    t0 = time()
    for _ in range(iterations):
        func(*args)
    print(""Time/iter: %.4f sec"" % ((time() - t0) / iterations))

def make_small_model(batch_shape):
    ipt   = Input(batch_shape=batch_shape)
    x     = Conv1D(128, 400, strides=4, padding='same')(ipt)
    x     = Flatten()(x)
    x     = Dropout(0.5)(x)
    x     = Dense(64, activation='relu')(x)
    out   = Dense(1,  activation='sigmoid')(x)
    model = Model(ipt, out)
    model.compile(Adam(lr=1e-4), 'binary_crossentropy')
    return model

def make_medium_model(batch_shape):
    ipt   = Input(batch_shape=batch_shape)
    x     = Bidirectional(LSTM(512, activation='relu', return_sequences=True))(ipt)
    x     = LSTM(512, activation='relu', return_sequences=True)(x)
    x     = Conv1D(128, 400, strides=4, padding='same')(x)
    x     = Flatten()(x)
    x     = Dense(256, activation='relu')(x)
    x     = Dropout(0.5)(x)
    x     = Dense(128, activation='relu')(x)
    x     = Dense(64,  activation='relu')(x)
    out   = Dense(1,   activation='sigmoid')(x)
    model = Model(ipt, out)
    model.compile(Adam(lr=1e-4), 'binary_crossentropy')
    return model
    
def make_data(batch_shape):
    return np.random.randn(*batch_shape), np.random.randint(0, 2, (batch_shape[0], 1))
```"
33486,Out of date BERT Tutorial Link,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue: https://www.tensorflow.org/guide/distributed_training
## Description of issue (what needs changing): Out of date link to BERT tutorial
### Clear description
The above URL contains an out of date link:
BERT Tutorial: https://github.com/tensorflow/models/blob/master/official/bert/run_classifier.py 
This is the correct link: https://github.com/tensorflow/models/blob/master/official/nlp/bert/run_classifier.py

Are you planning to also submit a pull request to fix the issue?  Yes"
33484,Issue with tf.keras.mixed_precision.experimental.LossScaleOptimizer,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0, 7.5
- GPU model and memory: Titian RTX 24gb

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When attempting to use tf.keras.mixed_precision.experimental.LossScaleOptimizer it fails to cast a matmul to float16
**Describe the expected behavior**
Matmul should cast to float16
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
import tensorflow as tf
import numpy as np
from tensorflow.keras.datasets import mnist

gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), ""Physical GPUS,"", len(logical_gpus), ""Logical GPUS"")
    except RuntimeError as e:
        print(e)

tf.keras.backend.set_floatx('float16')
tf.keras.backend.set_epsilon(1e-4)

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(tf.keras.layers.MaxPooling2D((2, 2), padding=""same""))
model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding=""same""))

model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(64, activation='relu'))
model.add(tf.keras.layers.Dense(10, activation='softmax'))

model.summary()

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

train_images = train_images.reshape((60000, 28, 28, 1))
train_images = train_images.astype(np.float16) / 255

test_images = test_images.reshape((10000, 28, 28, 1))
test_images = test_images.astype(np.float16) / 255

train_labels = tf.keras.utils.to_categorical(train_labels, dtype='float16')
test_labels = tf.keras.utils.to_categorical(test_labels, dtype='float16')

opt = tf.keras.optimizers.RMSprop()
opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt, ""dynamic"")

model.compile(optimizer=opt,
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.fit(tf.dtypes.cast(train_images, tf.float16), tf.dtypes.cast(train_labels, tf.float16), epochs=50, batch_size=64, steps_per_epoch=200)

test_loss, test_acc = model.evaluate(test_images, test_labels)

test_acc


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33482,"In the pix2pix tutorial, the dimension of upsample within up_stack looks wrong. Only the image size is doubled, not filters!","This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
33479,Error in loading a keras model saved by tf 1.15 from tf 1.14,"I saved the keras model by tf 1.15.
when loading from  tf 1.14, occurs:

> ValueError: ('Unrecognized keyword arguments:', dict_keys(['ragged']))

how to fix it?"
33478,Need a way to get Intermediate Layer Inputs/Activations for tf.keras Models,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
2.0
- Are you willing to contribute it (Yes/No):
Yes, if there is a consensus on how it should be designed. 


**Describe the feature and the current behavior/state.**
In eager mode, there is no way to access a tf.keras model's layer inputs/outputs during training (as far as I can tell, please correct me if I'm wrong). In TF 1.x (graph mode), this was not a problem, since you could use <s>[`layer.input`](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/base_layer.py#L1541-L1558) or [`layer.output`](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/base_layer.py#L1560-L1577)</s> [`layer.inbound_nodes` or `layer.outbound_nodes`](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/base_layer.py#L1663-L1673) to get these tensors and use those values, but this is no longer possible in eager mode. 

PyTorch solves this issue by allowing users to register hooks on layers, which is essentially a function that is called before/after the forward/backward pass on a layer. [Here](https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_forward_hook) is the code for `register_forward_hook` in PyTorch.

Alternatively, the input/output properties of a layer could store a reference to the tensors used in the most recent forward pass.

**Will this change the current api? How?**
Yes, depending on how this is implemented. If a hooks approach is used, this public method would have to be added to `tf.keras.layers.Layer`. If the input/output property approach is used, these properties would have new behavior in eager mode.

**Who will benefit with this feature?**
Being able to access, record, manipulate, or otherwise use layer inputs and outputs for models during training/inference is generally very useful. 

A specific example is the [K-FAC](https://arxiv.org/abs/1503.05671) optimization algorithm, which uses each layer's inputs and pre-activation gradients to approximate the Fisher information matrix. The [current implementation](https://github.com/tensorflow/kfac) does not support eager. PyTorch implementations (e.g. [this one](https://github.com/alecwangcq/KFAC-Pytorch/blob/master/optimizers/kfac.py#L81-L82)) of this algorithm use hooks to do this.

Another use case is visualizing intermediate activations of CNNs. [This example](https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0) uses layer.outputs in TF 1.x + Keras to grab the right tensors then creating an augmented model. This process would be greatly simplified by allowing access to intermediate activations without augmenting the model. 
  
**Any Other info.**
[Here](https://github.com/tensorflow/tensorflow/issues/33129) is a related issue about getting intermediate activations.


**EDIT (2019-10-20):** I learned that `layer.inbound_nodes `and `layer.outbound_nodes` used to have this behavior, not `layer.input` and `layer.output`. `layer.input` and `layer.output` track the tensors that are created when [`model.build(input_shape)`](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/base_layer.py#L365-L379) is called. When you use the model as a callable on your own input (i.e. `predictions = model(inputs)`), new tensors are created (reusing the model's weights/architecture). In TF 1.x, `inputs` would be added to the `inbound_nodes` list and `predictions` would be added to the `outbound_nodes` list during this call. Now, since in eager mode the model is called on a new `EagerTensor` for every training step, it is not reasonable to add that many new tensors to these lists, so the property was deprecated. Since this feature used to exist, I think it's important for a reasonable replacement to exist in TF2 (such as hooks or a layer property tracking the most recent inputs/outputs)."
33477,Problem with manually updating matrix in a custom layer.,"## System information:
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: MacOs 10.14.6
TensorFlow installed from: pip
TensorFlow version: 2.0

## Describe the current behavior and expected behavior
I am really new to Tensorflow, so maybe this is quite obvious, but what I am trying to do is to basically create my own layer, where I introduce an additional matrix that I update manually each call. I started off with a copy of a SimpleRNNCell from recurrent.py and my idea was to simply extend this SimpleRNN (Layer) into what I need. This extensions would not be a lot of effort, since it would only include
a) Initialising a matrix when the cell is created (with zeros),
b) Manually updating this matrix in the call() function. (this is done by simple building the output product of the recurrent layers activation and adding it to the to the matrix in question),
c) Adding it onto the normal reservoir activity.

My Problem is that when trying to manually updating this matrix, I get presented the following error:

TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
```
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: add_1
```

## Code to reproduce the issue
- Initialisation of the matrix:
```
self.A = K.variable(value=tf.zeros((self.units, self.units)),
        dtype='float32', name='fast_weights')
```
- Manual update
```
self.A = self.l * self.A + self.e * K.dot(K.transpose(h), h)
```
, where h is the activation of the hidden, recurrent layer. This is where the error is thrown.

- Addition to update step:
```
h = self.activation(K.bias_add(K.dot(inputs, self.kernel), self.bias) + K.dot(h, self.recurrent_kernel)) + K.dot(h, self.A)
```
where ```K.dot(h, self.A)``` is what I added.

Thank you in advance."
33476,empirical mean from tf.random.gamma does not match theoretical expectation,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 16.04.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
Not sure, came pre-installed so probably binary
- TensorFlow version (use command below):
1.13.1
- Python version:
3.5.5
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
CUDA: 10.0.130
cuDNN: 7
- GPU model and memory:
Tesla K80, total memory = 11441 MiB

**Describe the current behavior**
If I sample many values from `tf.random.gamma` with shape=A and beta=B and compute their mean, I get a value which isn't close to A/B.

If I use the script below, computing the mean absolute difference between the empirical and theoretical mean, I get ~7.26 (with 500 tries, 50k samples from the gamma distribution each time).

**Describe the expected behavior**
The expected value of a Gamma-distributed random variable with shape parameter A and inverse scale parameter B is A/B, so the empirical mean should be close to A/B. 

So I would expect the output of my script to be close to 0.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

Code to report the mean absolute discrepancy between the empirical and theoretical means:
```
def check_gamma(n_sample=50000, n_iter=500):
    shape_ph = tf.placeholder(tf.float32)
    beta_ph = tf.placeholder(tf.float32)
    gamma_mean = tf.reduce_mean(tf.random.gamma(shape=[n_sample], alpha=shape_ph, beta=beta_ph))
    mean_difference = np.zeros(shape=n_iter)
    mean_difference_np = np.zeros(shape=n_iter)
    with tf.Session() as sess:
        for i in range(n_iter):
            # sample a shape (non-negative)
            shape_parameter = np.random.uniform(1, 5)
            # sample a scale (non-negative)
            scale_parameter = np.random.uniform(1, 5)
            # the gamma distribution in tensorflow takes the inverse scale parameter
            beta = 1.0/scale_parameter
            # theoretical mean of gamma distribution:
            expected_mean = shape_parameter*scale_parameter
            # sample it!
            sample_mean = sess.run(gamma_mean, feed_dict={shape_ph: shape_parameter, beta_ph: beta})
            mean_difference[i] = np.abs(expected_mean - sample_mean)
            mean_difference_np[i] = np.abs(expected_mean - np.mean(np.random.gamma(size=n_sample, shape=shape_parameter, scale=scale_parameter)))
    print('average absolute difference in empirical and theoretical means, using tensorflow:', np.mean(mean_difference))
    print('...using numpy:', np.mean(mean_difference_np))
    return True
```

Code to visualise the distribution:
```def visualise_distribution(n_sample=10000, shape_parameter=1, scale_parameter=2):
    with tf.Session() as sess:
        gamma_samples = sess.run(tf.random.gamma(shape=[n_sample], alpha=shape_parameter, beta=1.0/scale_parameter))
    expected_mean = shape_parameter * scale_parameter
    empirical_mean = np.mean(gamma_samples)
    sns.distplot(gamma_samples, kde=False)
    plt.axvline(x=expected_mean, label='theoretical mean', color='black')
    plt.axvline(x=empirical_mean, label='empirical mean')
    plt.legend()
    return True
```


**Other info / logs**

Visualisation of distribution produced by above code, with shape = 1, scale = 2:
![image](https://user-images.githubusercontent.com/4471845/67024197-ea4ec880-f0fb-11e9-809d-8b9f338598cf.png)"
33474,Can't Load tf.keras Saved h5 Model in TF 2.0 CPU Version,"I can't load tf.keras h5 Model in TF 2.0 CPU Version.
* OS: MacOS Catalina 10.15
* Python version: 3.7.4
* Env: virtualenv as described in TF official website
* TF Version: 2.0 Stable **CPU** version installed with `pip install tensorflow`

![Screen Shot 2019-10-17 at 21 51 06](https://user-images.githubusercontent.com/32727188/67023093-3f083880-f128-11e9-9448-c9c898c0bf62.png)


First, I trained the model in google colab with **gpu** by installing `!pip install tensorflow-gpu` and saved the model in google colab with **`model.save(main.h5)`** 
And, I can load the saved h5 model in colab, so I downloaded the saved h5 model from google colab but I **cannot** load the saved h5 model in the local system with 
**`model = tf.keras.models.load_model(""main.h5"")`**

![Screen Shot 2019-10-17 at 21 10 35](https://user-images.githubusercontent.com/32727188/67022943-023c4180-f128-11e9-8918-2cefa7eda157.png)

[Colab Notebook Here](https://nbviewer.jupyter.org/github/ydcjeff/cvify/blob/master/main.ipynb)

Thank You"
33473,build fails when choosing clang/llvm compiler instead of nvcc compiler,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution Linux Ubuntu 18.04):
- TensorFlow installed from (source or binary): Source
- TensorFlow version: r2.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): clang version 6.0.0-1ubuntu2 (tags/RELEASE_600/final)
- CUDA/cuDNN version: CUDA 10.0 /cuDNN 7.6.3.30
- GPU model and memory: nvidia GTX 1080 8GB RAM



**Problem Description**
when building using clang/llvm compiler over nvcc, the build fails  with the error message:

ERROR: /usr/local/tensorflow/tensorflow/tools/pip_package/BUILD:35:1: Illegal ambiguous match on configurable attribute ""deps"" in //tensorflow/tools/pip_package:included_headers_gather:
@local_config_cuda//cuda:using_nvcc
@local_config_cuda//cuda:using_clang
Multiple matches are not allowed unless one is unambiguously more specialized.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

step1:  configuring with these options:
Do you wish to build TensorFlow with XLA JIT support? [Y/n]: y
XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: n
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: y
TensorRT support will be enabled for TensorFlow.

Found CUDA 10.0 in:
    /usr/local/cuda/lib64
    /usr/local/cuda/include
Found cuDNN 7 in:
    /usr/lib/x86_64-linux-gnu
    /usr/include
Found TensorRT 6 in:
    /usr/lib/x86_64-linux-gnu
    /usr/include/x86_64-linux-gnu

Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 6.1]: 

Do you want to use clang as CUDA compiler? [y/N]: y
Clang will be used as CUDA compiler.

Do you wish to download a fresh release of clang? (Experimental) [y/N]: n
Clang will not be downloaded.

Please specify which clang should be used as device and host compiler. [Default is /usr/bin/clang]: 

Do you wish to build TensorFlow with MPI support? [y/N]: y
MPI support will be enabled for TensorFlow.

Please specify the MPI toolkit folder. [Default is /usr/local/pgi/linux86-64/19.4/mpi/openmpi-3.1.3]: 

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 

Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=gdr         	# Build with GDR support.
	--config=verbs       	# Build with libverbs support.
	--config=ngraph      	# Build with Intel nGraph support.
	--config=numa        	# Build with NUMA support.
	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
	--config=v2          	# Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
	--config=noaws       	# Disable AWS S3 filesystem support.
	--config=nogcp       	# Disable GCP support.
	--config=nohdfs      	# Disable HDFS support.
	--config=noignite    	# Disable Apache Ignite support.
	--config=nokafka     	# Disable Apache Kafka support.
	--config=nonccl      	# Disable NVIDIA NCCL support.
Configuration finished

step 2: build with this command:

bazel build  --config=cuda --linkopt='-lrt'  --verbose_failures -c opt  //tensorflow/tools/pip_package:build_pip_packag




**Any other info / logs**
none"
33472,Allowing to provide pre-built flatbuffers when building tflite C++,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android/Ubuntu
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.15.0
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: ip
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): NDK r17b clang
- CUDA/cuDNN version: -
- GPU model and memory: -


**Describe the problem**
Currently tensorflow build always pulls flatbuffers on its own, resulting in duplication of flatbuffers, if user already has dependency on flatbuffers.
Due to how tensorflow headers work, it leaks dependency to generated schema (and therefore flatbuffers.h) 
But as we used flatbuffers 1.10.0 in our project, we had no compilation errors due to missing header.
Since tf 1.15 schema uses some specific feature of flatbuffers 1.11.0 which results in failed build when including model.h for example

Ideally it would be great if flatbuffers schema wouldn't be leaked, but I doubt it is feasible.
So my plan is currently upgrading our own flatbuffers to 1.11.0.

But this brings me to a question, if we could somehow tell bazel to use our own flatbuffers instead of pulling its own?

P.s. I tried to find some options in configuration script, but there seem to be none. So I assume most common use case is always build own copy of flatbuffers as part of build process.

**Any other info / logs**

Having proper instructions to how build and install self-contained C++ tflite would be nice too :)
"
33471,TF 2.0 Keras add_loss() function seems to make trainable weight not in model but added in add_loss() also being updated during training,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04.2 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
pip
- TensorFlow version (use command below):
v2.0.0-rc2-26-g64c3d38 2.0.0
v1.14.0-rc1-22-gaf24dc9 1.14.0
- Python version: 
3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

In TF 2.0, if output of another model with trainable weight is included in add_loss() function, all weight from that model will be updated during training.

I also couldn't find any documentation regarding this change. So I assume it is unintended.

**Describe the expected behavior**

It should be like in TF 1.14. The gradient of additional model in add_loss() should be back propagated because the model to be trained may be used as input for additional model. But additional model should not be updated.

**Code to reproduce the issue**
```
import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow_probability as tfp
import sys
import time

from tensorflow.keras.layers import Dense, Input, Add, Lambda
from tensorflow.keras import Model
from tensorflow.keras.models import load_model, clone_model
from tensorflow.keras import optimizers

from scipy.io import loadmat
from scipy.spatial.distance import cdist
tf.compat.v1.disable_eager_execution()

x = np.random.rand(100).reshape(100, 1).astype(float)
y = np.array(x>0.5).reshape(100, 1).astype(float)

input1 = Input(shape=(1, ), name='input1')
d1 = Dense(12, name='d11')(input1)
d1 = Dense(12, name='d12')(d1)
d1 = Dense(1, name='output1')(d1)

input2 = Input(shape=(1, ), name='input2')
d2 = Dense(12, name = 'd21')(input2)
d2 = Dense(12, name = 'd22')(d2)
d2 = Dense(1, name = 'output2')(d2)

label = Input(shape = (1, ), name = 'label')

model1 = Model(inputs = [input1, label], outputs = d1)
model2 = Model(inputs = input2, outputs = d2)
model2_cl = clone_model(model2)
model1_cl = clone_model(model1)

pre_result1 = model1.predict({'input1': x, 'label': y})
pre_result1_cl = model1_cl.predict({'input1': x, 'label': y})
pre_result2 = model2.predict(x)

def cust_loss(xi, yi, yp):
    loss = tf.reduce_mean((yi - yp)**2) + tf.reduce_mean((model2(xi) - yi)**2)
    
    return loss

model1.add_loss(cust_loss(input1, label, d1))
#optimizer = optimizers.Adam(lr = 3e-4)
optimizer = tf.compat.v1.train.AdamOptimizer(3e-4)
model1.compile(optimizer, loss = None)

model1.fit({'input1': x, 'label': y}, None, epochs=100)
post_result1 = model1.predict({'input1': x, 'label': y})
post_result1_cl = model1_cl.predict({'input1': x, 'label': y})
post_result2 = model2.predict(x)

print(sum(pre_result2 != post_result2))
```

**Other info / logs**
If you run the code above in TF 1.14, it will show 0 because model2 remains and should remain the same after training of model1.

But if you run it in TF 2.0, it will show 100 as model2 is updated as well for some reason during model1 training.
"
33470,TFLite-micro: unable to build bluepill tests,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian 9
- TensorFlow version: current master (17c4db8)
- GCC version: gcc (Debian 9.2.1-8) 9.2.1 20190909

**Describe the problem**

Trying to follow the instructions from [TFLite Micro README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/README.md#building-for-the-blue-pill-stm32f103-using-make) fails, being unable to build the code properly.

I traced down the problem to e98d181 - the commit before this one passes properly.

The fail log is below, but the first line is important, namely the `cannot find entry symbol _main`.
Further lines are because Renode is unable to run it properly.

```
...
.../tensorflow/tensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/bin/ld: warning: cannot find entry symbol _main; defaulting to 0000000008000000
tensorflow/lite/experimental/micro/testing/test_bluepill_binary.sh tensorflow/lite/experimental/micro/tools/make/gen/bluepill_cortex-m3/bin/micro_features_fft_test '~~~ALL TESTS PASSED~~~'
Sending build context to Docker daemon  37.38kB
Step 1/2 : FROM antmicro/renode:latest
 ---> d8aae99c4341
Step 2/2 : LABEL maintainer=""Pete Warden <petewarden@google.com>""
 ---> Using cache
 ---> 659756518d3d
Successfully built 659756518d3d
Successfully tagged renode_bluepill:latest
LOGS:
Preparing suites
Starting suites
Running /workspace/tensorflow/lite/experimental/micro/testing/bluepill.robot
==============================================================================
bluepill                                                                      
==============================================================================
Should Run Bluepill Test :: Runs a Bluepill test and waits for a s... | FAIL |
TargetInvocationException: Exception has been thrown by the target of an invocation.
InvalidOperationException: Time for operation to finish has exceeded 00:00:30.000000. Events so far:
[14:42:22.501]   ------------------------------------------------------------------------------------
[14:42:52.633]   >>> 'WaitUntilLine': timeout occurred
[14:42:52.634]   >>> Characters waiting in buffer: 

[14:42:52.635]   ------------------------------------------------------------------------------------
------------------------------------------------------------------------------
bluepill                                                              | FAIL |
1 critical test, 0 passed, 1 failed
1 test total, 0 passed, 1 failed
==============================================================================
Output:  /home/developer/bluepill.xml
Cleaning up suites
Aggregating all robot results
Output:  /home/developer/robot_output.xml
Log:     /home/developer/log.html
Report:  /home/developer/report.html
Some tests failed :( See logs for details!
tensorflow/lite/experimental/micro/tools/make/gen/bluepill_cortex-m3/bin/micro_features_fft_test: FAIL - '~~~ALL TESTS PASSED~~~' not found in logs.
make: *** [tensorflow/lite/experimental/micro/examples/micro_speech/Makefile.inc:314: test_micro_features_fft_test] Error 1
```

The said symbol is provided by stm32_bare_lib which is downloaded correctly. The problem is that it is **not compiled** at all. I believe that `MICROLITE_CC_SRCS` in [bluepill_makefile.inc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/tools/make/targets/bluepill_makefile.inc) is evaluated before the lib is actually downloaded.

This is easy to verify: just add the following in `bluepill_makefile.inc:54`
```
$(error MICROLITE_CC_SRCS is $(MICROLITE_CC_SRCS))
```
It will stop the build process before downloading the lib (and will print out the variable **not** containing the relevant source files).

**Provide the exact sequence of commands / steps that you executed before running into the problem**

1. Clone the repo
2. Run `make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=bluepill test`
3. Fail with the above.

CC @petewarden 

**Note**
I assume there are two actual problems: one is that the compilation is not correct, the other is that it does not prevent the test from running, but let's it work on a ""crippled"" output binary."
33469,"Simultaneous fetching of collective_ops and global_step triggers ""Skipping rendezvous re-initialization""","**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Linux CentOS 7.6.1810
- Mobile device if the issue happens on mobile device: No
- TensorFlow installed from: Binary
- TensorFlow version: v1.13.1-0-g6612da8951
- Python version: 3.6.8
- Bazel version: None
- GCC/Compiler version: None
- CUDA/cuDNN version: None
- GPU model and memory: None

**Describe the current behavior**

`collective_ops.all_reduce` and `global_step` can be fetched successfully when the operations are carried out _separately_ by a session. Nevertheless, the calling will trigger an info or occasionally fail when the two tensors are fetched _simultaneously_ in a session run.

regularly raise info:
```console
2019-10-17 17:33:58.119365: I tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc:159] Skipping rendezvous re-initialization.
```
occasionally raise failure:
```console
2019-10-17 17:35:07.980957: I tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc:159] Skipping rendezvous re-initialization.
2019-10-17 17:35:07.982111: W tensorflow/core/common_runtime/base_collective_executor.cc:203] BaseCollectiveExecutor::StartAbort Aborted: Cleanup 34190423657599268
         [[{{node _send_worker0/CollectiveReduce_0}}]]
task 1: sync_op and global_step [0.5, 0]
INFO:tensorflow:An error was raised. This may be due to a preemption in a connected worker or parameter server. The current session will be closed and a new session will be created. This error may also occur due to a gRPC failure caused by high memory or network bandwidth usage in the parameter servers. If this error occurs repeatedly, try increasing the number of parameter servers assigned to the job. Error: Cleanup 34190423657599268
         [[{{node _send_worker0/CollectiveReduce_0}}]]
```
Full logs are attached below.

**Describe the expected behavior**

Value is fetched without warnings.

**Code to reproduce the issue**
```python
""""""Illustrate AllReduce""""""

import os
import multiprocessing as mp
import time
import tensorflow as tf
from tensorflow.python.ops import collective_ops

MP_METHOD = 'fork'
NUM_PROCESSES = 2
CHIEF_INDEX = 0
JOB = 'worker'
DELAY = 0.01

def process_fn(hosts, task_index):
    """"""allreduce process""""""
    tf.logging.set_verbosity(tf.logging.INFO)

    cluster_spec = tf.train.ClusterSpec({JOB: hosts})
    workers = list()
    for task, _ in enumerate(hosts):
        workers.append(tf.DeviceSpec(
            job=JOB, replica=0, task=task, device_type='cpu', device_index=0))

    collective_group_leader, _, _ = \
        workers[0].to_string().partition('/device')
    config = tf.ConfigProto()
    config.experimental.collective_group_leader = collective_group_leader
    server = tf.train.Server(cluster_spec, config=config,
                             job_name='worker', task_index=task_index)
    with tf.Graph().as_default():
        creator_fn = tf.train.ChiefSessionCreator
        if task_index != CHIEF_INDEX:
            creator_fn = tf.train.WorkerSessionCreator
        session_creator = creator_fn(master=server.target, config=config)

        with tf.device(workers[task_index]), \
                tf.variable_scope('worker{}'.format(task_index)):
            token = tf.constant(task_index, dtype=tf.float32)
            sync_op = collective_ops.all_reduce(
                token, NUM_PROCESSES, 0, 0, 'Add', 'Div')

        with tf.device(workers[0]), tf.variable_scope('worker0'):
            global_step = tf.train.get_or_create_global_step()

        with tf.train.MonitoredSession(
                session_creator=session_creator, hooks=[]) \
                as mon_sess:
            time.sleep((task_index + 1) * DELAY)
            ret = mon_sess.run(sync_op)  # successful
            print('task {}: sync_op {}.'.format(task_index, ret))

            ret = mon_sess.run(global_step)  # successful
            print('task {}: global_step {}'.format(task_index, ret))

            ret = mon_sess.run([sync_op, global_step])  # failed
            print('task {}: sync_op and global_step {}'.format(task_index, ret))

            mon_sess.run(sync_op)
            print('task {}: finalized.'.format(task_index))
            time.sleep(DELAY)

def start_process():
    """"""start process""""""

    port = 60000
    host_fmt = 'localhost:{}'
    hosts = list()
    for process_index in range(NUM_PROCESSES):
        hosts.append(host_fmt.format(port + process_index))
    mp_ctx = mp.get_context(MP_METHOD)
    processes = list()
    for process_index in range(NUM_PROCESSES):
        process = mp_ctx.Process(target=process_fn,
                                 args=(hosts, process_index,))
        processes.append(process)
        process.start()
        time.sleep(DELAY)
    for process in processes:
        process.join()

if __name__ == '__main__':
    start_process()
```

**Other info / logs**

Full log with regular info of `Skipping rendezvous re-initialization`, processes exit successfully:
```console
tf-1.13) [huwh1@huwh1-centos worksync]$ python ./tf_distribute_re-initialization.py
2019-10-17 17:33:57.919229: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-17 17:33:57.931531: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-17 17:33:57.935766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz
2019-10-17 17:33:57.936208: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x378c150 executing computations on platform Host. Devices:
2019-10-17 17:33:57.936241: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-17 17:33:57.938117: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> localhost:60000, 1 -> localhost:60001}
2019-10-17 17:33:57.939150: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:60000
2019-10-17 17:33:57.949331: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz
2019-10-17 17:33:57.949702: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x378c2a0 executing computations on platform Host. Devices:
2019-10-17 17:33:57.949723: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-17 17:33:57.951578: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> localhost:60000, 1 -> localhost:60001}
2019-10-17 17:33:57.952724: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:60001
WARNING:tensorflow:From /home/huwh1/virtualenv/tf-1.13/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/huwh1/virtualenv/tf-1.13/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
INFO:tensorflow:Graph was finalized.
2019-10-17 17:33:58.053372: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session 96a54c0a4de96215 with config: experimental { collective_group_leader: ""/job:worker/replica:0/task:0"" }
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Graph was finalized.
2019-10-17 17:33:58.072731: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session 543a2da8fd7ecd53 with config: experimental { collective_group_leader: ""/job:worker/replica:0/task:0"" }
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
task 1: sync_op 0.5.
task 0: sync_op 0.5.
task 0: global_step 0
task 1: global_step 0
2019-10-17 17:33:58.119365: I tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc:159] Skipping rendezvous re-initialization.
task 1: sync_op and global_step [0.5, 0]
task 0: sync_op and global_step [0.5, 0]
task 1: finalized.
task 0: finalized.
```
Full log with occasionally warning `BaseCollectiveExecutor::StartAbort Aborted`, processes hang:
```console
(tf-1.13) [huwh1@huwh1-centos worksync]$ python ./tf_distribute_re-initialization.py
2019-10-17 17:35:07.780731: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-17 17:35:07.793013: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-17 17:35:07.795259: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz
2019-10-17 17:35:07.795603: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x30ea150 executing computations on platform Host. Devices:
2019-10-17 17:35:07.795627: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-17 17:35:07.797198: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> localhost:60000, 1 -> localhost:60001}
2019-10-17 17:35:07.798176: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:60000
2019-10-17 17:35:07.810391: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz
2019-10-17 17:35:07.810780: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x30ea2a0 executing computations on platform Host. Devices:
2019-10-17 17:35:07.810805: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-17 17:35:07.812369: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> localhost:60000, 1 -> localhost:60001}
2019-10-17 17:35:07.813640: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:60001
WARNING:tensorflow:From /home/huwh1/virtualenv/tf-1.13/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/huwh1/virtualenv/tf-1.13/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
INFO:tensorflow:Graph was finalized.
2019-10-17 17:35:07.902323: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session b8c8018638e2809a with config: experimental { collective_group_leader: ""/job:worker/replica:0/task:0"" }
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Graph was finalized.
2019-10-17 17:35:07.921347: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session 41eee7eda589977d with config: experimental { collective_group_leader: ""/job:worker/replica:0/task:0"" }
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
task 1: sync_op 0.5.
task 0: sync_op 0.5.
task 0: global_step 0
task 1: global_step 0
2019-10-17 17:35:07.980957: I tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc:159] Skipping rendezvous re-initialization.
2019-10-17 17:35:07.982111: W tensorflow/core/common_runtime/base_collective_executor.cc:203] BaseCollectiveExecutor::StartAbort Aborted: Cleanup 34190423657599268
         [[{{node _send_worker0/CollectiveReduce_0}}]]
task 1: sync_op and global_step [0.5, 0]
INFO:tensorflow:An error was raised. This may be due to a preemption in a connected worker or parameter server. The current session will be closed and a new session will be created. This error may also occur due to a gRPC failure caused by high memory or network bandwidth usage in the parameter servers. If this error occurs repeatedly, try increasing the number of parameter servers assigned to the job. Error: Cleanup 34190423657599268
         [[{{node _send_worker0/CollectiveReduce_0}}]]
INFO:tensorflow:Graph was finalized.
2019-10-17 17:35:07.986279: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session 82ea6dbd6778bbf4 with config: experimental { collective_group_leader: ""/job:worker/replica:0/task:0"" }
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
```
A related issue can be found #33321."
33468,Current thread 0x00004514 (most recent call first):,"(tensorflow1) C:\Users\Юрий\Desktop\models-master\research\object_detection>python generate_tfrecord.py --csv_input=images\train_labels.csv --image_dir=images\train --output_path=train.record
2019-10-17 20:28:23.110602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
C:\Python 3.7\anaconda\envs\tensorflow1\lib\site-packages\h5py\__init__.py:75: UserWarning: h5py is running against HDF5 1.10.5 when it was built against 1.10.4, this may cause problems
  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)
WARNING:tensorflow:From generate_tfrecord.py:116: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From generate_tfrecord.py:102: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.

W1017 20:28:25.492974 17684 module_wrapper.py:137] From generate_tfrecord.py:102: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.

WARNING:tensorflow:From generate_tfrecord.py:61: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W1017 20:28:25.515945 17684 module_wrapper.py:137] From generate_tfrecord.py:61: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

Windows fatal exception: access violation

Current thread 0x00004514 (most recent call first):
  File ""C:\Python 3.7\anaconda\envs\tensorflow1\lib\site-packages\tensorflow_core\python\lib\io\file_io.py"", line 84 in _preread_check
  File ""C:\Python 3.7\anaconda\envs\tensorflow1\lib\site-packages\tensorflow_core\python\lib\io\file_io.py"", line 122 in read
  File ""generate_tfrecord.py"", line 62 in create_tf_example
  File ""generate_tfrecord.py"", line 107 in main
  File ""C:\Python 3.7\anaconda\envs\tensorflow1\lib\site-packages\absl\app.py"", line 250 in _run_main
  File ""C:\Python 3.7\anaconda\envs\tensorflow1\lib\site-packages\absl\app.py"", line 299 in run
  File ""C:\Python 3.7\anaconda\envs\tensorflow1\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40 in run
  File ""generate_tfrecord.py"", line 116 in <module>


**********************************
Tensorflow gives such an error, how can I fix it ???"
33467,tf.range is not equivalent to np.arange,"`tensorflow-gpu==1.12.3`

[The docs](https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/range#numpy_compatibility) state about `tf.range`:

> Equivalent to np.arange

But:

```python
import tensorflow as tf
import numpy as np
tf.enable_eager_execution()

def main():

    s = tf.constant(np.random.rand(20))
    rate = 2.5
    s1 = np.arange(0, tf.shape(s)[0], rate)
    s2 = tf.range(0, tf.shape(s)[0], rate).numpy()

    print(s1)
    print(s2)

if __name__ == '__main__':
    main()
```

Outputs:

```
[ 0.   2.5  5.   7.5 10.  12.5 15.  17.5 20.  22.5]
[ 0.   2.5  5.   7.5 10.  12.5 15.  17.5]
```"
33465,Padded_batch with pre- or post-padding option,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.12.2
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
I have a dataset of variable-length sequences to feed an LSTM network and I want to try and compare pre- and post-padding in the batches, but current padded_batch function only pads at the sequences end.

**Who will benefit with this feature?**
I heard that pre-padding may be better for LSTM than post-padding, because post-padding may 'wash' the cell states before final decision making. Is it true?

**Any Other info.**
"
33464,TFLite-micro: AllocateTensors produces HardFault even for small models,"I am deploying a model consisting of a GRU with 128 input units and 64 Hidden units (total 37,056 parameters) on the following platform:
NRF52832 Arm cortex M4, with 64 KB ram and 512 KB FLASH.

To build the tflite model I follow the steps below:
```python 
converter=tf.lite.TFLiteConverter.from_keras_model(new_gru)
converter.optimizations= [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
gruQ=converter.convert()
f=open('gruQ.tflite',""wb"").write(gruQ)
```
and I convert it to a c++ array with
`xxd -i gruQ.tflite > gruQ.h`

On the embedded platform:
```cpp
static tflite::MicroErrorReporter micro_error_reporter;
      error_reporter = &micro_error_reporter;

   //extern unsigned char* quantQ5_tflite;
   const tflite::Model* model = ::tflite::GetModel(gruQ_tflite);
	
   if (model->version() != TFLITE_SCHEMA_VERSION) {
     error_reporter->Report(
         ""Model provided is schema version %d not equal ""
         ""to supported version %d.\n"",
         model->version(), TFLITE_SCHEMA_VERSION);
   }

   // This pulls in all the operation implementations we need
   tflite::ops::micro::AllOpsResolver resolver;

   static tflite::MicroInterpreter static_interpreter(
         model, resolver, tensor_arena, kTensorArenaSize, error_reporter);
     interpreter = &static_interpreter;

     TfLiteStatus allocate_status = interpreter->AllocateTensors();
```

The last line of code generates a HardFault regardless the size of the TensorArena, which I also tried to set to the maximum allowed by my system (45*1024). More into the details, the function call that produces it is:
`if (auto* array = buffer->data()) {`
in
`tensorflow/lite/experimental/micro/micro_allocator.cc    Line 259`
The size of the converted model (flatbuffer) is 43304

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0
- Python version: 3.7.3
"
33463,"Undefined symbols for architecture arm64:   ""NewGpuDelegate(GpuDelegateOptions const*)","System information

    Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
    OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6
    Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone X.s, 13.1.3
    TensorFlow installed from (source or binary): source
    TensorFlow version (use command below): master branch cloned on 2019-10-8
    Python version: 3.7.4
    Bazel version (if compiling from source):  0.26.1
    GCC/Compiler version (if compiling from source): NA
    CUDA/cuDNN version: NA
    GPU model and memory: NA

Describe the current behavior:
It fails to build the library in Xcode.
Undefined symbols for architecture arm64:   ""NewGpuDelegate(GpuDelegateOptions const*)

Describe the expected behavior:
I want to build my C++ library with the ability to run it with GPU in an iOS app

Code to reproduce the issue

Other info / logs
I changed the extension of the file having this line of code: 
_delegate = NewGpuDelegate(&options);_
from cpp to mm, as otherwise I couldn't include header files for metal(which are written in obj-c).
I tested the tensorflow ios/camera example and it builds and runs fine. But using the same .framework lib gives me the same undefined symbol error.

Bazel Command for building the tensorflow lib:
**bazel build -c opt --cpu ios_arm64 --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt -fvisibility=hidden --linkopt -s --strip always --cxxopt=-std=c++14 :tensorflow_lite_gpu_framework --apple_platform_type=ios**

Any help would be appreciated!"
33462,A question on ctc implementation,"I have a question on ctc implementation here:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_loss_calculator.h#L500
why the gradient is set to y instead of zero when no valid path is found? "
33459,resnet50 imagenet weights are differents in tf.keras vs keras,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10, pycharm (same issue from colab)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pycharm
- TensorFlow version (use command below): 2.0 and keras 2.3.0 (same issue with tf 1.15 and keras 2.2.5 in google colab)
- Python version: 3.7


**Describe the current behavior**
The weights of the kernel in layers 13 & 14 are different in tf.keras and keras: the weights of the layer 13 in tf.keras are the ones of the layers 14 in keras and the weights of the layer 14 in tf.keras are the ones of the layer 13 in keras:
with tf.keras:
layer 13: conv2_block1_0_conv
[[[[ 0.00460704  0.0613995   0.04595907 ... -0.12616335 -0.00781816
     0.03271283]
   ...
   [-0.00736084  0.00832207 -0.00591875 ... -0.16227128  0.00581011
     0.01718325]]]]
layer 14: conv2_block1_3_conv
[[[[ 0.00412396 -0.01779881 -0.01002417 ... -0.0397268  -0.01897338
    -0.00012411]
   ...
   [ 0.01601992  0.00197976 -0.01605847 ...  0.06464136  0.0353195
     0.02405972]]]]


with keras:
layer 13: res2a_branch2c
[[[[ 0.00412396 -0.01779881 -0.01002417 ... -0.0397268  -0.01897338
    -0.00012411]
   ...
   [ 0.01601992  0.00197976 -0.01605847 ...  0.06464136  0.0353195
     0.02405972]]]]
layer 14: res2a_branch1
[[[[ 0.00460704  0.0613995   0.04595907 ... -0.12616335 -0.00781816
     0.03271283]
   ...
   [-0.00736084  0.00832207 -0.00591875 ... -0.16227128  0.00581011
     0.01718325]]]]

this is with include_top=True but include_top=False gives the same thing

**Describe the expected behavior**
I would expect the same weights, not sure which weights are the right ones

**Code to reproduce the issue**
from tensorflow.python.keras.applications import ResNet50
#from keras.applications import ResNet50
image_size = 224
model = ResNet50(input_shape=(image_size, image_size, 3), include_top=True, weights='imagenet')
print(model.layers[13].name)
weights = model.layers[13].get_weights()[0]
print(weights)
print(model.layers[14].name)
weights = model.layers[14].get_weights()[0]
print(weights)

**Other info / logs**
The difference is coming from the different path used to load the h5 file:
in tf.keras:
'https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5'
in keras: 
'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'
"
33456,happen error：ERROR: Config value opt is not defined in any .rc file,"# Environment
Ubuntu 16.05
tensorflow r1.14
bazel 0.24.1

# Problem
I transform the model using the following command, [documentation](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md)
```
bazel run --config=opt tensorflow/lite/toco:toco -- \
--input_file=$OUTPUT_DIR/tflite_graph.pb \
--output_file=$OUTPUT_DIR/detect.tflite \
--input_shapes=1,300,300,3 \
--input_arrays=normalized_input_image_tensor \
--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \
--inference_type=FLOAT \
--allow_custom_ops
```

error logs:
```
test@test:~/tensorflow$ bazel run --config=opt tensorflow/lite/toco:toco -- \
> --input_file=/home/test/lite/model/tflite_graph.pb \
> --output_file=/home/test/lite/model/ssd_mobilenet_v2.tflite \
> --input_shapes=1,300,300,3 \
> --input_arrays=normalized_input_image_tensor \
> --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \
> --inference_type=FLOAT \
> --allow_custom_ops
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=258
INFO: Reading rc options for 'run' from /home/test/tensorflow/.bazelrc:
  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
ERROR: Config value opt is not defined in any .rc file
```

How do I transform the model to tensorflow lite.

"
33455,Can't create Tensor from java buffer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from: binary
- TensorFlow version: 1.13.1 (maybe 1.14 and 2.0)

**Describe the current behavior**
when you create a `java.nio.buffer` and fill it with data you can't use it to create `Tensor` with shape

**Describe the expected behavior**
We should be able to create a Tensor with buffer

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```scala
import java.nio.FloatBuffer
import org.tensorflow.Tensor
val buf: FloatBuffer = FloatBuffer.allocate(4)
buf.put(1f)
buf.put(2f)
buf.put(3f)
buf.put(4f)
val t = Tensor.create(Array(1L,4L), buf)
```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
java.lang.IllegalArgumentException: buffer with 0 elements is not compatible with a Tensor with shape [1, 4]
  at org.tensorflow.Tensor.incompatibleBuffer(Tensor.java:583)
  at org.tensorflow.Tensor.allocateForBuffer(Tensor.java:308)
  at org.tensorflow.Tensor.create(Tensor.java:186)
```

source of Tensor
```java
public static Tensor<Float> create(long[] shape, FloatBuffer data) {
    Tensor<Float> t = allocateForBuffer(DataType.FLOAT, shape, data.remaining());
    t.buffer().asFloatBuffer().put(data);
    return t;
  }

private static <T> Tensor<T> allocateForBuffer(DataType dataType, long[] shape, int nBuffered) {
    final int nflattened = numElements(shape);
    int nbytes = 0;
    if (dataType != DataType.STRING) {
      if (nBuffered != nflattened) {
        throw incompatibleBuffer(nBuffered, shape);
      }
      nbytes = nflattened * elemByteSize(dataType);
    } else {
      // DT_STRING tensor encoded in a ByteBuffer.
      nbytes = nBuffered;
    }
    Tensor<T> t = new Tensor<T>(dataType);
    t.shapeCopy = Arrays.copyOf(shape, shape.length);
    t.nativeHandle = allocate(t.dtype.c(), t.shapeCopy, nbytes);
    return t;
  }
```
"
33454,[1.15]Discrepancy between documentation & behaviour in tf.keras.Model.Save,"## URL(s) with the issue:

In the 1.15 changelog:

https://github.com/tensorflow/tensorflow/releases/tag/v1.15.0
> tf.keras.model.save_model and model.save now defaults to saving a TensorFlow SavedModel.


In the 1.15 docstring:
https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/Model#save
> filepath: String, path to SavedModel or H5 file to save the model. overwrite: Whether to silently 
overwrite any existing file at the target location, or provide the user with a manual prompt. include_optimizer: If True, save optimizer's state together. save_format: Either 'tf' or 'h5', indicating whether to save the model to Tensorflow SavedModel or HDF5. The default is currently 'h5', but will switch to 'tf' in TensorFlow 2.0. The 'tf' option is currently disabled (use tf.keras.experimental.export_saved_model instead).

## Description of issue (what needs changing):

- The changelogs states that tf.keras.Model are saved using tf format by default
- The docstring states that the default save format in tf1.x is hdf5 and that tf is disabled
- ""tf"" save format is NOT disabled but can be passed as parameters
https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/python/keras/saving/save.py#L92
We can still save using tf format using tf.keras.Model.save(). HOWEVER you cannot load tf model

## Usage example

This is not a critical issue but this can be confusing to users reading the changelog and reading the docstring, and seeing that tf behaviour is enabled by default.

This will lead users to:
- Being confused between behaviours...
- Thinking they need to update their codebases to switch to 1.15
- Seeing that tf format doesn't work in tf1.15

Saving works but not reloading, which confirms the fact that tf save format doesn't work

```python
i = tf.keras.layers.Input(shape=(10,))
x = tf.keras.layers.Dense(2)(i)
o = tf.keras.layers.Activation(""softmax"")(x)
m = tf.keras.Model(inputs=i, outputs=o)
m.save('test_model_tf', save_format=""tf"")
m2 = tf.keras.models.load_model(""test_model_tf"")
m2.summary()
```

```text
Layer (type)                 Output Shape              Param #   
=================================================================
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-48-d0af62cb113d> in <module>
----> 1 m2.summary()

~/opt/miniconda3/envs/py36-tf1.15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in summary(self, line_length, positions, print_fn)
   1459                               line_length=line_length,
   1460                               positions=positions,
-> 1461                               print_fn=print_fn)
   1462 
   1463   def _validate_graph_inputs_and_outputs(self):

~/opt/miniconda3/envs/py36-tf1.15/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/layer_utils.py in print_summary(model, line_length, positions, print_fn)
    224   for i in range(len(layers)):
    225     if sequential_like:
--> 226       print_layer_summary(layers[i])
    227     else:
    228       print_layer_summary_with_connections(layers[i])

~/opt/miniconda3/envs/py36-tf1.15/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/layer_utils.py in print_layer_summary(layer)
    182     name = layer.name
    183     cls_name = layer.__class__.__name__
--> 184     fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params()]
    185     print_row(fields, positions)
    186 

~/opt/miniconda3/envs/py36-tf1.15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in count_params(self)
   1632                          ', but the layer isn\'t built. '
   1633                          'You can build it manually via: `' + self.name +
-> 1634                          '.build(batch_input_shape)`.')
   1635     return int(sum(np.prod(w.shape.as_list()) for w in self.weights))
   1636 

ValueError: You tried to call `count_params` on input_1, but the layer isn't built. You can build it manually via: `input_1.build(batch_input_shape)`.

```
This works,

```python
i = tf.keras.layers.Input(shape=(10,))
x = tf.keras.layers.Dense(2)(i)
o = tf.keras.layers.Activation(""softmax"")(x)
m = tf.keras.Model(inputs=i, outputs=o)
m.save('test_model_hdf5.hdf5`)
m2 = tf.keras.models.load_model(""test_model_hdf5.hdf5"")
m2.summary()
```
```txt
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         [(None, 10)]              0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 22        
_________________________________________________________________
activation_3 (Activation)    (None, 2)                 0         
=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
```"
33453,tf.print operations inside tf.function do not print in order,"**System information**
Tensorflow-gpu 2.0.0 installed via `pip install tensorflow-gpu` in a Colaboratory notebook.

**Describe the current and expected behavior**
In https://www.tensorflow.org/guide/function#side_effects one can read that `tf.print` operations inside `tf.function` will execute in order. This seem, indeed , to be the case. However, while operations are executed in order, the printed statements are not always shown in the expected order.

The code
```
v = tf.Variable(5)

@tf.function
def find_next_odd():
  tf.print('1:',v)
  v.assign(v + 1)
  tf.print('2:', v)
  if v % 2 == 0:
    v.assign(v + 1)
    tf.print('3:', v)

find_next_odd()
```
prints
```
1: 5
3: 7
2: 6
```

Note, however, that if a (dummy) conditional statement is inserted before the second `tf.print`, the output is the expected one.

The code
```
v = tf.Variable(5)

@tf.function
def find_next_odd():
  tf.print('1:',v)
  v.assign(v + 1)
  if v==v: #dummy condition
    tf.print('2:', v)
  if v % 2 == 0:
    v.assign(v + 1)
    tf.print('3:', v)

find_next_odd()
```
prints
```
1: 5
2: 6
3: 7
```
"
33452,gpu-jupyter Dockerfile not compatible with docker-compose?,"I am taking the official TF image `tensorflow/tensorflow:1.15.0rc2-gpu-py3-jupyter` and trying to get it to work in a `docker-compose.yml` file.

I have the following `docker-compose.yml` file:

```
version: '3'

services:
  tf:
    image: tensorflow/tensorflow:1.15.0rc2-gpu-py3-jupyter

    # mount host system volume to save updates from container
    volumes:
      - jupyter:/tf/notebooks
    
    ports:
      - '8888:8888'
   
    # build:
    #   context: .
    #   dockerfile: Dockerfile


volumes:
  jupyter:

```

where `jupyter` is the directory of notebooks. 

The result of `docker-compose build & docker-compose up` is:

```
ERROR: for 186e1443ba94_docker-tf-jn_tf_1  Cannot start service tf: OCI runtime create failed: container_linux.go:346: starting container process caused ""exec: \""jupyter notebook --notebook-dir=/tf/notebooks --ip 0.0.0.0 --no-browser --allow-root\"": stat jupyter notebook --notebook-dir=/tf/notebooks --ip 0.0.0.0 --no-browser --allow-root: no such file or directory"": unknown

ERROR: for tf  Cannot start service tf: OCI runtime create failed: container_linux.go:346: starting container process caused ""exec: \""jupyter notebook --notebook-dir=/tf/notebooks --ip 0.0.0.0 --no-browser --allow-root\"": stat jupyter notebook --notebook-dir=/tf/notebooks --ip 0.0.0.0 --no-browser --allow-root: no such file or directory"": unknown
```

"
33450,What is the Const node in batch_normalization?,"use **tensorflow.layer.batch_normalization** then define the batch_normalization/Const node,
<br>
## what is this const node and how act this node in batch normal operation?"
33449,"WARNING:tensorflow:Entity <function layers at 0x7fdeb05e6d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7fde56634b38>","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos7
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 1.15.0
- Python version: 3.7.4
- Bazel version (if compiling from source): 1.0.0
- GCC/Compiler version (if compiling from source):4.8.5 
- CUDA/cuDNN version: 10.0/7.60
- GPU model and memory: 2080ti/11GB

**Describe the current behavior**
tensor2tensor 1.14.1 
t2t-trainer 

PROBLEM=translate_ende_wmt32k
MODEL=transformer
HPARAMS=transformer_base_single_gpu
t2t-trainer \
  --data_dir=$DATA_DIR \
  --problem=$PROBLEM \
  --model=$MODEL \
  --hparams_set=$HPARAMS \
  --output_dir=$TRAIN_DIR

**Other info / logs / WARNING logs**

WARNING:tensorflow:Entity <function layers at 0x7fe5fa758d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7fe60c8ffc50>
W1017 12:48:28.307721 140626233849664 ag_logging.py:146] Entity <function layers at 0x7fe5fa758d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7fe60c8ffc50>
WARNING:tensorflow:From /opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensor2tensor/layers/common_layers.py:3077: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.


WARNING:tensorflow:From /opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensor2tensor/utils/bleu_hook.py:151: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.

W1017 12:52:31.947059 140626233849664 deprecation.py:323] From /opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensor2tensor/utils/bleu_hook.py:151: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.





"
33447,Could not satisfy explicit device specification '' because the node placed on device Device assignments active during op was colocated with a group of nodes that required incompatible device,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- I didn't write custom code
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): pip install tensorflow-gpu==1.14.0
- Python version: 3.6.9
- CUDA/cuDNN version: 8.0, cuDNN 6.0
- GPU model and memory: 2 x 1080 TI
**Describe the current behavior**
I try to train a simple convolutional neural network defined by tf.keras.layers.Conv2D with random normal initialization, the network should be trained on GPU:

I use the following code to initialize the code:

config = tf.compat.v1.ConfigProto()
config.log_device_placement=False
sess = tf.compat.v1.InteractiveSession(config=config)
with tf.device('/gpu:0'):
     setup the network and train
**Describe the expected behavior**
It should train without bugs

I tried to use config.allow_soft_placement=True and it didn't throw out the bug anymore but the network can only be trained on cpu instead of GPU. Please help to figure out this issue as I've seen multiple issue reported in many places but the problem is never solved with a clean solution.

**Other info / logs**
Could not satisfy explicit device specification '' because the node placed on device Device assignments active during op was colocated with a group of nodes that required incompatible device"
33446,GraphKeys.BIASES variables present in losses.get_regularization_losses(),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14 GPU
- Python version: 3.6
- CUDA/cuDNN version: 10.2
- GPU model and memory: 1060 ti

**Describe the current behavior**

All variables, including biases are added to regularization losses (not only weights) within a tf.variable_scope with a regularizer.

**Describe the expected behavior**

I find this behavior very strange. As far as I know only weights should be added to the l1/l2 losses list. Even if some of the losses resolve to zero later (doesn't seem the case). I asume this is by design, however this has caused me tons of confusion in the past and forces me to manually pass the regularizer everywhere. Please point me in the right direction if I'm missing something here, because I find this quite odd.

**Code to reproduce the issue**


```
import tensorflow.compat.v1 as tf
import tensorflow.contrib.layers as tf_c_l

with tf.Session() as sess:
    t0 = tf.placeholder(dtype=tf.float32, shape=(20, 10,))

    reg = tf_c_l.l1_l2_regularizer()
    with tf.variable_scope('test', regularizer=reg):
        v2 = tf.get_variable('test', shape=(20, 10), collections=[tf.GraphKeys.BIASES])
        layer = tf_c_l.fully_connected(t0, num_outputs=10)

    print('Bias Variables:')
    for i in tf.get_collection(tf.GraphKeys.BIASES):
        print('{} {}'.format(i.shape.as_list(), i.name))

    print()

    print('Regularization losses:')
    for i in tf.losses.get_regularization_losses():
        print('{} {}'.format(i.shape.as_list(), i.name))
```


**Other info / logs**

```
Bias Variables:
[20, 10] test/test:0

Regularization losses:
[] test/test/Regularizer/l1_l2_regularizer:0
[] test/fully_connected/weights/Regularizer/l1_l2_regularizer:0
[] test/fully_connected/biases/Regularizer/l1_l2_regularizer:0
```
"
33445,"Delete temporary variables from memory, but maintain them on graph for back propagation. ","

**System information**
- TensorFlow version: 1.15



**Describe the feature and the current behavior/state.**
I'm wondering if there is any feature that allows deleting a temporary variable from memory but still keep it on the graph. For example, I'm writing a custom layer:
```bash
from tensorflow.keras import layers


class custom_layer(layers.Layer):

  def __init__(self, units=32, input_dim=32):
    super(custom_layer, self).__init__()
    self.units = units
    self.input_dim = input_dim
    w_init = tf.random_normal_initializer()
    self.w = tf.Variable(initial_value=w_init(shape=(self.input_dim, self.units),
                                              dtype='float32'),
                         trainable=True)
    b_init = tf.zeros_initializer()
    self.b = tf.Variable(initial_value=b_init(shape=(self.units,),
                                              dtype='float32'),
                         trainable=True)

  def call(self, inputs1, inputs2):
    batch_size = tf.shape(inputs1)[0]
    G = tf.matrix_diag(tf.matmul(inputs1, self.w) + self.b)
    map = tf.matrix_inverse(tf.eye(self.units, batch_shape=[batch_size]) + tf.matmul(G, tf.transpose(G, perm = [0,2,1])))
    res = tf.matmul(inputs2, map)
    
    return res

```    

The tensor ```G``` and ```map``` will take large memory space here, so I want to delete these variables to free the memory they took but still keep them on graph. When going through back propagation, if any of these variable is needed, it still can be recomputed according to the forward graph. I know this will definitely cost longer computation time but I'm willing to trade time for space. Just curious whether there is any feature like this.
 Or any suggestion about trade time for space will be appreciated.

**Who will benefit with this feature?**
People who doing research on representation learning, meta learning.

"
33442,Unable to run train.py / model_main.py,"**System information**
- Windows 10
- TensorFlow installed via pip - I've tried 1.5, 1.8, 1.9, and 2.0 - all yield different error messages
- Python 3.7.4 installed, 3.5 in virtual environment
- Using conda too
- CUDA/cuDNN: N/A
- GPU model and memory: N/A, CPU only

Consistently getting error message when trying to execute train.py or model_main.py.  The latter always returns ""no module named pycocotools.""

The train.py error depends on the version of Tensorflow I try, but it's always ""module tensorflow has no attribute '[something]'""  For example, 'contrib,' or 'experimental'.

I'm using this command: `python` model_main.py --logtostderr --train_dir=training/ `--pipeline_config_path=training/faster_rcnn_inception_v2_pets.config`

I also tried porting the train.py to v2, with no change.

Full traceback: 
`Traceback (most recent call last):
  File ""train.py"", line 49, in <module>
    from object_detection.builders import dataset_builder
  File ""C:\tensorflow1\models\research\object_detection\builders\dataset_builder.py"", line 27, in <module>
    from object_detection.data_decoders import tf_example_decoder
  File ""C:\tensorflow1\models\research\object_detection\data_decoders\tf_example_decoder.py"", line 32, in <module>
    slim_example_decoder = tf.contrib.slim.tfexample_decoder
AttributeError: module 'tensorflow' has no attribute `'contrib'``



HUGE thanks for looking at this - I'm not a professional programmer, just a hobbyist trying to get better.  I appreciate the help in solving it, and I'm very open to education to help me understand the 'why' behind these problems!"
33439,Cannot import tensorflow after installing via pip3,"**System information**
- OS Platform and Distribution: Linux Ubuntu 19.04
- TensorFlow installed from: binary
- TensorFlow version: 2.0.0
- Python version: 3.7.3
- Installed using: pip


**Describe the problem**

Installed `tensorflow` via `pip3` using `pip3 install tensorflow --user`. Any python script using `import tensorflow` or `import tensorflow as tf` fails.


**Any other info / logs**
```none
Traceback (most recent call last):
  File ""/home/[redacted]/Documents/VSC Projects/POSNN/main.py"", line 5, in <module>
    import tensorflow as tf
ImportError: No module named tensorflow
```"
33438,UpSample2D INT8 quantization not supported,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source): 2.0


**Provide the text output from ~tflite_convert~ TFLiteConverter**

```
2019-10-16 13:10:02.543859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-10-16 13:10:02.551468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.551740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:01:00.0
2019-10-16 13:10:02.551828: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-16 13:10:02.552513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-16 13:10:02.553132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-16 13:10:02.553261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-16 13:10:02.554087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-16 13:10:02.554716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-16 13:10:02.556627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-16 13:10:02.556687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.556988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.557237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-16 13:10:02.557401: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-16 13:10:02.580750: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 4008000000 Hz
2019-10-16 13:10:02.581738: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e194a15110 executing computations on platform Host. Devices:
2019-10-16 13:10:02.581748: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-10-16 13:10:02.624356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.624717: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e194aa7ab0 executing computations on platform CUDA. Devices:
2019-10-16 13:10:02.624728: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-10-16 13:10:02.624836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.625102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:01:00.0
2019-10-16 13:10:02.625122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-16 13:10:02.625130: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-16 13:10:02.625137: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-16 13:10:02.625143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-16 13:10:02.625149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-16 13:10:02.625155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-16 13:10:02.625162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-16 13:10:02.625189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.625459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.625708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-16 13:10:02.625725: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-16 13:10:02.626255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-16 13:10:02.626262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-10-16 13:10:02.626265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-10-16 13:10:02.626314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.626592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.626856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9051 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-10-16 13:10:02.739500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.739771: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2019-10-16 13:10:02.739810: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-10-16 13:10:02.740219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.740510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:01:00.0
2019-10-16 13:10:02.740538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-16 13:10:02.740545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-16 13:10:02.740551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-16 13:10:02.740557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-16 13:10:02.740563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-16 13:10:02.740568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-16 13:10:02.740574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-16 13:10:02.740601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.740873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.741124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-16 13:10:02.741138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-16 13:10:02.741142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-10-16 13:10:02.741145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-10-16 13:10:02.741185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.741460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.741715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9051 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-10-16 13:10:02.742758: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-10-16 13:10:02.742766: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2019-10-16 13:10:02.742770: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-10-16 13:10:02.749704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.749989: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2019-10-16 13:10:02.750037: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-10-16 13:10:02.750314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.750591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:01:00.0
2019-10-16 13:10:02.750609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-16 13:10:02.750615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-16 13:10:02.750621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-16 13:10:02.750627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-16 13:10:02.750633: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-16 13:10:02.750639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-16 13:10:02.750645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-16 13:10:02.750670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.750974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.751224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-16 13:10:02.751237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-16 13:10:02.751241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-10-16 13:10:02.751244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-10-16 13:10:02.751285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.751587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-16 13:10:02.751843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9051 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-10-16 13:10:02.757033: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-10-16 13:10:02.757044: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 10 nodes (0), 10 edges (0), time = 0.65ms.
2019-10-16 13:10:02.757047: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 10 nodes (0), 10 edges (0), time = 0.14ms.
INFO: Initialized TensorFlow Lite runtime.
Traceback (most recent call last):
  File ""/home/wd_ai/git-pkgs/yolov3-tf2/test_upsample2d_tflite.py"", line 35, in <module>
    tflite_model = convert2tflite_int8(model)
  File ""/home/wd_ai/git-pkgs/yolov3-tf2/test_upsample2d_tflite.py"", line 28, in convert2tflite_int8
    tflite_model = converter.convert()
  File ""/home/wd_ai/miniconda3/envs/tf2-n-pytorch/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py"", line 450, in convert
    constants.FLOAT)
  File ""/home/wd_ai/miniconda3/envs/tf2-n-pytorch/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py"", line 239, in _calibrate_quantize_model
    inference_output_type, allow_float)
  File ""/home/wd_ai/miniconda3/envs/tf2-n-pytorch/lib/python3.7/site-packages/tensorflow_core/lite/python/optimize/calibrator.py"", line 78, in calibrate_and_quantize
    np.dtype(output_type.as_numpy_dtype()).num, allow_float)
  File ""/home/wd_ai/miniconda3/envs/tf2-n-pytorch/lib/python3.7/site-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py"", line 115, in QuantizeModel
    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, input_py_type, output_py_type, allow_float)
RuntimeError: Quantization not yet supported for op: RESIZE_NEAREST_NEIGHBOR

Process finished with exit code 1
```

Also, please include a link to a GraphDef or the model if possible. (source code)

```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np


def build_upsample_model():
    inputs = keras.Input(shape=(28, 28, 32), name='input')
    outputs = layers.UpSampling2D()(inputs)
    model = keras.models.Model(inputs=inputs, outputs=outputs, name='upsample_model')
    return model


def convert2tflite_int8(model):
    def repr_data_gen(shape):

        def gen_random_data():
            for _ in range(10):
                yield [np.array(np.random.random_sample(shape), dtype=np.float32)]

        return gen_random_data

    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.representative_dataset = repr_data_gen((1, 28, 28, 32))

    tflite_model = converter.convert()

    return tflite_model


if __name__ == '__main__':
    model = build_upsample_model()
    tflite_model = convert2tflite_int8(model)
```

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33437,IPython Tab Completion causes logged warnings,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below):  `.1.15.0` (git version `v1.15.0-rc3-22-g590d6ee`, `1.15.0`)
- Python version: 3.6.6

**Describe the current behavior**
Tab-completions in IPython spam the console with `The name ___ is deprecated` logging warnings.

**Code to reproduce the issue**
I am using Python 3.6.6 with IPython 7.8.0. If you do:

```
$ ipython
imporPython 3.6.6 | packaged by conda-forge | (default, Oct 12 2018, 14:43:46) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.8.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import tensorflow as tf                                                                                                                                                                                                        

In [2]: tf.
```

and press `tab` after the `.`, you get dozens of warnings like:

```
WARNING:tensorflow:From /opt/anaconda/envs/ctrldev/lib/python3.6/site-packages/jedi/evaluate/compiled/access.py:347: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.

WARNING:tensorflow:From /opt/anaconda/envs/ctrldev/lib/python3.6/site-packages/jedi/evaluate/compiled/access.py:347: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /opt/anaconda/envs/ctrldev/lib/python3.6/site-packages/jedi/evaluate/compiled/access.py:347: The name tf.parse_single_sequence_example is deprecated. Please use tf.io.parse_single_sequence_example instead.

WARNING:tensorflow:From /opt/anaconda/envs/ctrldev/lib/python3.6/site-packages/jedi/evaluate/compiled/access.py:347: The name tf.parse_tensor is deprecated. Please use tf.io.parse_tensor instead.
```

You can actually reproduce this with the docker images, although that produces fewer deprecation warnings than the released package does:

```
$ docker run -it tensorflow/tensorflow:1.15.0rc1-py3-jupyter ipython
Python 3.6.8 (default, Aug 20 2019, 17:12:48) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.8.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import tensorflow as tf                                                                                                                                                                                                        
tf.
In [2]: tf.WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/jedi/evaluate/compiled/access.py:347: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.  
```

(Unfortunately, I wasn't able to find a more up-to-date official docker image)."
33435,mixed_precision_graph_rewrite behaviours,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0
- Python version: 3.7
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: V10.0.130
- GPU model and memory: GeForce RTX 2080ti, 10G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
See the results below. Basically, there no clear evidence mix precision speeds up the training in this case. 
**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import os
os.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""
os.environ[""CUDA_VISIBLE_DEVICES""]= '3'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import tensorflow
import tensorflow.keras as keras
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, Flatten, Input
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras import backend as K
import time


optimizer1 = keras.optimizers.Adadelta()
optimizer2 = tensorflow.train.experimental.enable_mixed_precision_graph_rewrite(optimizer1)
opts_dict = {'fp32': optimizer1, 'mix': optimizer2}
batch_sizes = [256, 512, 1024, 2048, 4096, 8192]
num_classes = 10
epochs = 30

dataset = 'mnist'

for batch_size in batch_sizes:
    for precision in opts_dict:

        optimizer = opts_dict[precision]
        start_time = time.time()

        # the data, split between train and test sets
        if dataset == 'mnist':
            (x_train, y_train), (x_test, y_test) = mnist.load_data()
            if K.image_data_format() == 'channels_first':
                x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)
                x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)
                input_shape = (1, 28, 28)
            else:
                x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
                x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)
                input_shape = (28, 28, 1)

        if dataset == 'cifar10':
            (x_train, y_train), (x_test, y_test) = cifar10.load_data()
            input_shape = x_train.shape[1:]


        x_train = x_train.astype('float32')
        x_test = x_test.astype('float32')
        x_train /= 255
        x_test /= 255

        y_train = keras.utils.to_categorical(y_train, num_classes)
        y_test = keras.utils.to_categorical(y_test, num_classes)

        input = Input(shape=input_shape)
        x = Conv2D(32, kernel_size=(3, 3),
                         activation='relu',
                         input_shape=input_shape)(input)
        x = Conv2D(64, (3, 3), activation='relu')(x)
        x = MaxPooling2D(pool_size=(2, 2))(x)
        x = Dropout(0.25)(x)
        x = Flatten()(x)
        x = Dense(128, activation='relu')(x)
        x = Dropout(0.5)(x)
        x = Dense(num_classes, activation='softmax')(x)
        model = Model(inputs=input, outputs=x)
        model.compile(loss=keras.losses.categorical_crossentropy,
                      optimizer=optimizer,
                      metrics=['accuracy'])

        model.fit(x_train, y_train,
                  batch_size=batch_size,
                  epochs=epochs,
                  verbose=0,
                  validation_data=(x_test, y_test))
        score = model.evaluate(x_test, y_test, verbose=0)
        print('Batch size = %s' % batch_size)
        print('Precision = %s' % precision)
        print('Test loss:', score[0])
        print('Test accuracy:', score[1])
        dur = time.time() - start_time
        print('Run time = %s s' % dur)
        print('================================')


```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Results on mnist:
![Screenshot from 2019-10-17 13-58-01](https://user-images.githubusercontent.com/32969920/67010775-33941d80-f0e6-11e9-944a-fccb1ec7b933.png)

I also tried running on cifar10:
![Screenshot from 2019-10-17 13-56-01](https://user-images.githubusercontent.com/32969920/67010652-f6c82680-f0e5-11e9-930c-e5f58bf7e0b7.png)
"
33434,tf.function tracing when input tensor varies,"Dear experts,
  In tf 2.0, when using the tf.function decorator, if the shape of the input tensors varies, it seems TF will create a new graph every single time. Is there a way to get around this?

```
import tensorflow as tf

@tf.function
def add(a, b):
    print('Addition')
    return a + b
add(tf.constant(1), tf.constant(2))
add(tf.constant([1, 2]), tf.constant([2, 4]))
add(tf.constant([333, 2]), tf.constant([2, 4444]))
```

Output:
```
Addition
Addition
```
"
33431,"internal compiler error: in assign_temp, at function.c:968","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: 
- Bazel version (if compiling from source): Build label: 0.26.1
- GCC/Compiler version (if compiling from source): 
```gcc (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010```
and
```gcc (Ubuntu 7.4.0-1ubuntu1~16.04~ppa1) 7.4.0```

- CUDA/cuDNN version: off
- GPU model and memory: off



**Describe the problem**
```
ERROR: /home/ubuntu/tensorflow/tensorflow/compiler/mlir/xla/BUILD:226:1: C++ compilation of rule '//tensorflow/compiler/mlir/xla:hlo' failed (Exit 1)
tensorflow/compiler/mlir/xla/ir/hlo_ops.cc: In function 'mlir::Type {anonymous}::GetBroadcastType(mlir::Builder*, mlir::Type, mlir::Type, mlir::Type, mlir::DenseIntElementsAttr)':
tensorflow/compiler/mlir/xla/ir/hlo_ops.cc:622:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     for (int i = 0; i < shape_x.size(); i++) {
                     ~~^~~~~~~~~~~~~~~~
In file included from ./tensorflow/compiler/mlir/xla/ir/hlo_ops.h:22:0,
                 from tensorflow/compiler/mlir/xla/ir/hlo_ops.cc:18:
external/local_config_mlir/include/mlir/IR/Attributes.h: In member function 'T mlir::DenseElementsAttr::getValue(llvm::ArrayRef<long unsigned int>) const [with T = mlir::IntegerAttr]':
external/local_config_mlir/include/mlir/IR/Attributes.h:783:20: internal compiler error: in assign_temp, at function.c:968
     auto castFn = [](Attribute attr) { return attr.template cast<T>(); };
                    ^
Please submit a full bug report,
```
**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
$ bazel build --config=opt  //tensorflow/tools/pip_package:build_pip_package
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33430,estimator for tf serving error '_lower_using_switch_merge',"
**System information**
- OS Platform and Distribution :
win10 subsystem Ubuntu 18.04 LTS
- TensorFlow version: 2.0
- Python version: 3.6


**Describe the current behavior**
when I use tensorflow_model_server, I get a error:
```python
failed: Internal: Node {{node dnn/zero_fraction/cond}} of type StatelessIf has '_lower_using_switch_merge' attr set but it does not support lowering.
```


**Code to reproduce the issue**
```python
import pandas as pd
from sklearn import datasets
import tensorflow as tf
import itertools

COLUMNS = [""crim"", ""zn"", ""indus"", ""nox"", ""rm"", ""age"",
           ""dis"", ""tax"", ""ptratio"", ""medv""]

training_set = pd.read_csv(r'./data/boston/boston_train.csv', skipinitialspace=True, skiprows=1, names=COLUMNS)
test_set = pd.read_csv(r'./data/boston/boston_test.csv', skipinitialspace=True, skiprows=1, names=COLUMNS)
predict_set = pd.read_csv(r'./data/boston/boston_predict.csv', skipinitialspace=True, skiprows=1, names=COLUMNS)

FEATURES = [""crim"", ""zn"", ""indus"", ""nox"", ""rm"",
                 ""age"", ""dis"", ""tax"", ""ptratio""]
LABEL = ""medv""

feature_cols = [tf.feature_column.numeric_column(k) for k in FEATURES]

estimator = tf.estimator.LinearRegressor(    
        feature_columns=feature_cols
)

def get_input_fn(data_set, num_epoch=None, n_batch=128, shuffle=True):
    return tf.compat.v1.estimator.inputs.pandas_input_fn(
        x=pd.DataFrame({k: data_set[k].values for k in FEATURES}),
        y=pd.Series(data_set[LABEL].values),
        batch_size=n_batch,
        num_epochs=num_epoch,
        shuffle=shuffle
    )


estimator.train(input_fn=get_input_fn(training_set, num_epoch=None, n_batch=128, shuffle=False), steps=1000)

feature_spec = tf.feature_column.make_parse_example_spec(feature_cols)
erving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)
estimator.export_saved_model(r'./saved/boston', erving_input_receiver_fn)
```
after that, when I try tf serving:
```bash
tensorflow_model_server --rest_api_port=8501 --model_name=saved_model --model_base_path='/mnt/c/Study/tensorflow/saved/boston'
```
I get this error:
```bash
 SavedModel load for tags { serve }; Status: fail. Took 59577 microseconds.
Loading servable: {name: saved_model version: 1571232515} failed: Internal: Node {{node zero_fraction/total_zero/zero_count/else/_1/zero_fraction/cond}} of type StatelessIf has '_lower_using_switch_merge' attr set but it does not support lowering.
```
"
33429,Tensorflow lite conversion problem,"

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, RESHAPE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: EmptyTensorList, TensorListFromTensor, TensorListReserve, TensorListStack, While.

```
Graph code:
self.inputs = tf.placeholder(tf.float32, [None, None, num_features], name='inputs')

        # # Here we use sparse_placeholder that will generate a
        # # SparseTensor required by ctc_loss op.
        # # https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor
        # # https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss
        self.targets = tf.sparse_placeholder(tf.int32, name='targets')

        # # 1d array of size [batch_size]
        self.seq_len = tf.placeholder(tf.int32, [None], name='seq_len')
        self.lstm_cell = tf.lite.experimental.nn.TFLiteLSTMCell(num_hidden)
        self.outputs, _ =tf.lite.experimental.nn.dynamic_rnn(self.lstm_cell,self.inputs,dtype='float32')

        self.shape = tf.shape(self.inputs)
        self.batch_s, self.max_time_steps = self.shape[0], self.shape[1]

        # Reshaping to apply the same weights over the timesteps
        self.outputs = tf.reshape(self.outputs, [-1, num_hidden])

        # Truncated normal with mean 0 and stdev=0.1
        # Tip: Try another initialization
        # see https://www.tensorflow.org/versions/r0.9/api_docs/python/contrib.layers.html#initializers
        self.W = tf.Variable(tf.truncated_normal([num_hidden,
                                             num_classes],
                                            stddev=0.1))
        # Zero initialization
        # Tip: Is tf.zeros_initializer the same?
        self.b = tf.Variable(tf.constant(0., shape=[num_classes]))

        # Doing the affine projection
        self.logits = tf.matmul(self.outputs, self.W) + self.b

        # Reshaping back to the original shape
        self.logits = tf.reshape(self.logits, [self.batch_s, -1, num_classes])

        # Time major
        self.logits = tf.transpose(self.logits, (1, 0, 2))

        self.logits = tf.identity(self.logits,name=""output"")

        self.loss = tf.nn.ctc_loss(self.targets, self.logits, self.seq_len)
        self.cost = tf.reduce_mean(self.loss)

        with tf.variable_scope(""gs""):
            self.global_step = tf.Variable(0, name='global_step', trainable=False)

        # optimizer = tf.train.AdamOptimizer().minimize(cost)
        # optimizer = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.9).minimize(cost)
        self.optimizer = tf.train.AdamOptimizer(learning_rate=5e-4)
        self.gvs = self.optimizer.compute_gradients(self.cost)
        self.clipped = []
        for grad, var in self.gvs:
            grad = tf.clip_by_value(grad, -1., 1.)
            self.clipped.append((grad, var))
            self.train_op = self.optimizer.apply_gradients(self.clipped, global_step=self.global_step)


**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33428,TF2 Keras functional API error,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.6 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0 (most recent from pip)
- Python version: Python 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CPU version
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Show OperatorNotAllowedInGraphError error. 

**Describe the expected behavior**

Show model summary.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
import tensorflow as tf

tf.keras.backend.clear_session()

class Manager(tf.keras.Model):
    def __init__(self):
        super(Manager, self).__init__()

        self.inputs = tf.keras.Input(shape=(None,))

model = Manager()
model.build(input_shape=(16,16)).summary()
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py"", line 630, in build
    if input_shape and not self.inputs:
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 765, in __bool__
    self._disallow_bool_casting()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 534, in _disallow_bool_casting
    self._disallow_in_graph_mode(""using a `tf.Tensor` as a Python `bool`"")
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 523, in _disallow_in_graph_mode
    "" this function with @tf.function."".format(task))
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.
```
"
33427,Colab TPU cannot use dataset from GCS,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS (Colab)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Colab
- TensorFlow version (use command below): 1.15
- Python version: 3.6
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: - 

**Describe the current behavior**
upload credential to TPU is failed. Therefore, cannot train on TPU using dataset from google cloud service. I also tried to downgrade to tf 1.14 but still not working.

**Describe the expected behavior**
Same code was working few days ago, also the example codes in seedbank are using same code and they were working fine. Now all are not working.

**Code to reproduce the issue**
```python
import os
import tensorflow as tf

import json
bucket = 'kurnianggoro ' #@param {type:""string""}

assert bucket, 'Must specify an existing GCS bucket name'
print('Using bucket: {}'.format(bucket))


from google.colab import auth
auth.authenticate_user()

TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])

# Upload credentials to TPU.
with tf.Session(TF_MASTER) as sess:    
    with open('/content/adc.json', 'r') as f:
        auth_info = json.load(f)
    tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)
```

similar code in the official examples of google colab also not working
https://colab.research.google.com/github/GoogleCloudPlatform/cloudml-samples/blob/master/tpu/templates/tpu_estimator/trainer.ipynb

**Other info / logs**
```

InternalError                             Traceback (most recent call last)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)
   1364     try:
-> 1365       return fn(*args)
   1366     except errors.OpError as e:

9 frames

InternalError: From /job:tpu_worker/replica:0/task:0:
The filesystem registered under the 'gs://' scheme was not a tensorflow::RetryingGcsFileSystem*.
	 [[{{node GcsConfigureCredentials}}]]


During handling of the above exception, another exception occurred:

InternalError                             Traceback (most recent call last)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)
   1382                     '\nsession_config.graph_options.rewrite_options.'
   1383                     'disable_meta_optimizer = True')
-> 1384       raise type(e)(node_def, op, message)
   1385 
   1386   def _extend_graph(self):

InternalError: From /job:tpu_worker/replica:0/task:0:
The filesystem registered under the 'gs://' scheme was not a tensorflow::RetryingGcsFileSystem*.
	 [[node GcsConfigureCredentials (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]
```"
33426,TPU/Colab auth to google cloud bucket failing,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15rc
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: TPU

**Describe the current behavior**
Calling this code on a TPU notebook on colab generate this issue :
```
from google.colab import auth
auth.authenticate_user()
```

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)
   1364     try:
-> 1365       return fn(*args)
   1366     except errors.OpError as e:

9 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1349       return self._call_tf_sessionrun(options, feed_dict, fetch_list,
-> 1350                                       target_list, run_metadata)
   1351 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)
   1442                                             fetch_list, target_list,
-> 1443                                             run_metadata)
   1444 

InternalError: From /job:tpu_worker/replica:0/task:0:
The filesystem registered under the 'gs://' scheme was not a tensorflow::RetryingGcsFileSystem*.
	 [[{{node GcsConfigureCredentials}}]]

During handling of the above exception, another exception occurred:

InternalError                             Traceback (most recent call last)
<ipython-input-3-1f759c1655bd> in <module>()
      1 from google.colab import auth
----> 2 auth.authenticate_user()

/usr/local/lib/python3.6/dist-packages/google/colab/auth.py in authenticate_user(clear_output)
    155         with open(_get_adc_path()) as auth_info:
    156           tf.contrib.cloud.configure_gcs(
--> 157               sess, credentials=_json.load(auth_info))
    158   if _check_adc():
    159     return

/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cloud/python/ops/gcs_config_ops.py in configure_gcs(session, credentials, block_cache, device)
    180     with ops.device(device):
    181       return configure(credentials, block_cache)
--> 182   return configure(credentials, block_cache)
    183 
    184 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cloud/python/ops/gcs_config_ops.py in configure(credentials, block_cache)
    169       placeholder = array_ops.placeholder(dtypes.string)
    170       op = gen_gcs_config_ops.gcs_configure_credentials(placeholder)
--> 171       session.run(op, feed_dict={placeholder: credentials})
    172     if block_cache:
    173       op = gen_gcs_config_ops.gcs_configure_block_cache(

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    954     try:
    955       result = self._run(None, fetches, feed_dict, options_ptr,
--> 956                          run_metadata_ptr)
    957       if run_metadata:
    958         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1178     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1179       results = self._do_run(handle, final_targets, final_fetches,
-> 1180                              feed_dict_tensor, options, run_metadata)
   1181     else:
   1182       results = []

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1357     if handle is None:
   1358       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1359                            run_metadata)
   1360     else:
   1361       return self._do_call(_prun_fn, handle, feeds, fetches)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)
   1382                     '\nsession_config.graph_options.rewrite_options.'
   1383                     'disable_meta_optimizer = True')
-> 1384       raise type(e)(node_def, op, message)
   1385 
   1386   def _extend_graph(self):

InternalError: From /job:tpu_worker/replica:0/task:0:
The filesystem registered under the 'gs://' scheme was not a tensorflow::RetryingGcsFileSystem*.
	 [[node GcsConfigureCredentials (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]


**Describe the expected behavior**
Auth must work

**Code to reproduce the issue**
```
from google.colab import auth
auth.authenticate_user()
```
"
33425,"Tensorflow eager execution not working with tf.math.unsorted_segment_max, Gradient output is null","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, Professional Edition
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary, installed using conda
- TensorFlow version (use command below): unknown, 1.14.0
- Python version: 3.7.3
- CUDA/cuDNN version: 10.0, 7.6
- GPU model and memory: T1000, 4GB VRAM

**Describe the current behavior**
When using tf.math.unsorted_segment_max with Tensorflow eager execution and Gradient Tape, the source code (see below) produces following error:
```
Traceback (most recent call last):
  File ""C:/Projects/iotmap/py/segmented_max_error.py"", line 80, in <module>
    grads = tape.gradient(loss_value, model.trainable_weights)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\backprop.py"", line 980, in gradient
    unconnected_gradients=unconnected_gradients)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\imperative_grad.py"", line 76, in imperative_grad
    compat.as_str(unconnected_gradients.value))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\backprop.py"", line 137, in _gradient_function
    return grad_fn(mock_op, *out_grads)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\math_grad.py"", line 349, in _UnsortedSegmentMaxGrad
    return _UnsortedSegmentMinOrMaxGrad(op, grad)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\math_grad.py"", line 326, in _UnsortedSegmentMinOrMaxGrad
    _GatherDropNegatives(op.outputs[0], op.inputs[1])
TypeError: 'NoneType' object is not subscriptable
```
Operations tf.math.segment_max, tf.math.segment_mean and tf.math.unsorted_segment_mean are working ok, though. 
I need the unsorted version because in more complex code bases, I a using several segmented aggregations and concatenating them, so I need to have fixed sizes.

**Describe the expected behavior**
It should work without throwing error.

**Code to reproduce the issue**
The code is here:
https://gist.github.com/racinmat/9a95cac7db36d5f0b6b33e9c35678ca2

**Other info / logs**
Exception thrown is mentioned above."
33424,Loading optimizer variables from checkpoint not working in tf.keras,"**System information**
- Custom code
- Ubuntu 18
- TensorFlow version 2.0.0
- Python version 3.7

**Describe the current behavior**

Restoring a checkpoint with saved optimizer variables is not working. 

**Describe the expected behavior**

When saving a checkpoint using `tf.keras.callbacks.ModelCheckpoint(..., save_weights_only=False)`, restoring the checkpoint should also recover the optimizer variables.

**Code to reproduce the issue**

```python
model = get_model()
model.fit(
    train_images,
    train_labels,
    epochs=1,
    callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath=model_path, save_weights_only=False)]
)
w0 = model.trainable_weights[0].numpy()
opt_w0 = model.optimizer.weights[1].numpy()

tf.keras.backend.clear_session()

# this throws an error when `save_weights_only=True`. If `save_weights_only=False` it doesn't restore optimizer variables
model = tf.keras.models.load_model(model_path)

# this throws an error when `save_weights_only=False`.
model = get_model()
model.load_weights(model_path)

w1 = model.trainable_weights[0].numpy()
try:
    opt_w1 = model.optimizer.weights[1].numpy()
except:
    opt_w1 = None
    
print(f'Weights correctly loaded: {np.all(w0 == w1)}') 
print(f'Optimizer weights correctly loaded: {np.all(opt_w0 == opt_w1) if opt_w1 is not None else False}') 
```

**Outputs**

`save_weights_only=True` with `tf.keras.load_model()`:

```
OSError: SavedModel file does not exist at: /tmp/m79804149/model/{saved_model.pbtxt|saved_model.pb}
```

`save_weights_only=False` with `tf.keras.load_model()`:

```
Train on 60000 samples
59136/60000 [============================>.] - ETA: 0s - loss: 0.4933 - accuracy: 0.8269INFO:tensorflow:Assets written to: /tmp/m41299667/model/assets
60000/60000 [==============================] - 3s 55us/sample - loss: 0.4923 - accuracy: 0.8273
Weights correctly loaded: True
Optimizer weights correctly loaded: False
```

`save_weights_only=True` with `model.load_weights()` (expected behaviour):

```
Train on 60000 samples
60000/60000 [==============================] - 3s 50us/sample - loss: 0.4945 - accuracy: 0.8266
Weights correctly loaded: True
Optimizer weights correctly loaded: False
```


`save_weights_only=False` with `model.load_weights()`:

```
OSError: Unable to open file (file read failed: time = Wed Oct 16 13:16:20 2019
, filename = '/tmp/m88520022/model', file descriptor = 79, errno = 21, error message = 'Is a directory', buf = 0x7ffd683b9c80, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)
```"
33423,"""Tensor.op is meaningless when eager execution is enabled"",  when using tf.compat.v1 RNN cells","
**System information**
- Have I written custom code : Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): openSUSE Leap 15.0
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from : binary
- TensorFlow version: v2.0.0-rc2-26-g64c3d38( 2.0.0)
- Python version: Python 3.6
- Bazel version (if compiling from source): - 
- GCC/Compiler version (if compiling from source): - 
- CUDA/cuDNN version: CUDA Version 10.2
- GPU model and memory: GeForce RTX 2080

**Describe the current behavior**
[The final goal is convert the saved_model to .tflite to port to an Android device. My model must use LSTM layers. My references are from : [Tensorflow Lite Experimental Examples](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/examples/lstm/g3doc/README.md) and [Supported functions to convert RNNs](https://www.tensorflow.org/lite/convert/rnn) ]

I have used a single BasicLSTMCell with Static RNN with compat.v1.*.
MNIST dataset is used to provide a stand-alone code example.

**Describe the expected behavior**
operations in compat.V1 for RNNs for TF2.0 should be supported for eager execution.

**Code to reproduce the issue**
```
import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras import Sequential
from tensorflow.keras import layers
from tensorflow.keras.layers import LSTM, Dense, Input, Layer


(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))

n_hidden = 8
time_steps = x_train.shape[1]
n_input = x_train.shape[2]
n_classes = 10
batch_size  = 20

loss_object = tf.keras.losses.CategoricalCrossentropy()
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)

train_loss = tf.keras.metrics.Mean(name='train_loss')
train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')

val_loss = tf.keras.metrics.Mean(name='val_loss')
val_accuracy = tf.keras.metrics.CategoricalAccuracy(name='val_accuracy')


@tf.function
def train_step(model, features, labels):
    with tf.GradientTape() as tape:
        predictions = model(features)
        loss = loss_object(labels, predictions)

    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    train_loss(loss)
    train_accuracy(labels, predictions)


weights = {
    'out': tf.Variable(tf.random.normal([n_hidden, n_classes]), trainable = True, dtype='float32')
}
biases = {
    'out': tf.Variable(tf.random.normal([n_classes]), trainable = True, dtype='float32')
}


class CompatV1LSTM(tf.keras.layers.Layer):
    def __init__(self, n_hidden = 8):
        super(CompatV1LSTM, self).__init__()
        print('Layer Init')

    def call(self, x):
        x = tf.dtypes.cast(x, tf.dtypes.float32, name='Converted_floats')
        _X = tf.unstack(x, time_steps, 1)

        print('Shape of x', x.shape)
        print('Shape of input after unstack',len(_X))
        print('Shape of first element', _X[0].shape)

        lstm_cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)
        output, state = tf.compat.v1.nn.static_rnn(cell=lstm_cell, inputs=_X, dtype=tf.float32)

        return tf.matmul(output[-1], weights['out']) + biases['out']

batch_dataset = train_dataset.batch(20)
x, y = next(iter(batch_dataset))
labels = tf.one_hot(y, depth = 10)

model = CompatV1LSTM()
print(model)
train_step(model, x, labels)
print(train_accuracy.result())
print(train_loss.result())
```

**Other info / logs** : Error log :
```
Traceback (most recent call last):
  File ""<input>"", line 1, in <module>
  File ""/opt/pycharm-community-2019.1.3/helpers/pydev/_pydev_bundle/pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""/opt/pycharm-community-2019.1.3/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/localdata/d1300/HAR_RW_Linse10/Models/DeployModels/tflite2.py"", line 123, in <module>
    train_step(model, x, labels)
  File ""/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1822, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 905, in wrapper
    raise e.ag_error_metadata.to_exception(e)
AttributeError: in converted code:
    /localdata/d1300/HAR_RW_Linse10/Models/DeployModels/tflite2.py:31 train_step  *
        predictions = model(features)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:847 __call__
        outputs = call_fn(cast_inputs, *args, **kwargs)
    /localdata/d1300/HAR_RW_Linse10/Models/DeployModels/tflite2.py:118 call  *
        x = self.block_1(inputs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:847 __call__
        outputs = call_fn(cast_inputs, *args, **kwargs)
    /localdata/d1300/HAR_RW_Linse10/Models/DeployModels/tflite2.py:87 call  *
        output, state = tf.compat.v1.nn.static_rnn(cell=lstm_cell, inputs=_X, dtype=tf.float32)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py:324 new_func
        return func(*args, **kwargs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn.py:1438 static_rnn
        (output, state) = call_cell()
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn.py:1425 <lambda>
        call_cell = lambda: cell(input_, state)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:386 __call__
        self, inputs, state, scope=scope, *args, **kwargs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/layers/base.py:548 __call__
        outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:817 __call__
        self._maybe_build(inputs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:2141 _maybe_build
        self.build(input_shapes)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py:306 wrapper
        output_shape = fn(instance, input_shape)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735 build
        shape=[input_depth + h_depth, 4 * self._num_units])
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py:324 new_func
        return func(*args, **kwargs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:1702 add_variable
        return self.add_weight(*args, **kwargs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/layers/base.py:461 add_weight
        **kwargs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:522 add_weight
        aggregation=aggregation)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py:744 _add_variable_with_custom_getter
        **kwargs_for_getter)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:1504 get_variable
        aggregation=aggregation)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:1247 get_variable
        aggregation=aggregation)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:567 get_variable
        aggregation=aggregation)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:519 _true_getter
        aggregation=aggregation)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:861 _get_single_variable
        tb = var.op.traceback[::-1]
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:555 op
        return self._handle.op
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1080 op
        ""Tensor.op is meaningless when eager execution is enabled."")
    AttributeError: Tensor.op is meaningless when eager execution is enabled.
```
"
33422,Specifying output_shape is not working in tf.keras Lambda Layer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.3
- CUDA/cuDNN version: 10.0/7

**Describe the current behavior**
When creating a keras Model using a lambda function with specified output shape, the shape is not assigned to the resulting tensor: 
dense_net from the example below:
`<tf.Tensor 'lambda_6/Identity:0' shape=(None, None, None) dtype=float32>`
If used before another layer like Dense the error appears:
`ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.`

**Describe the expected behavior**
dense_net should have shape information:
`<tf.Tensor 'lambda_6/Identity:0' shape=(None, 10, 5) dtype=float32>`

**Code to reproduce the issue**
```
from tensorflow.keras.layers import Input, Dense, Lambda
from tensorflow.keras.models import Model
from tensorflow.keras.backend import to_dense

test_input = Input((10, 5), sparse=True)
dense_net = Lambda(to_dense, output_shape=(10, 5))(test_input)
test_net = Dense(50)(dense_net)
```
"
33419,save_weights does not work for scalars in keras subclass when using h5 format,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

I tried three cases and they all result in the same problem:

```
import os
import tensorflow as tf
import tempfile
import glob

class A(tf.keras.models.Model):
    def __init__(self):
        self.something = tf.keras.backend.variable(name='something', value=1.0)
        super().__init__()

        
for fmt in ['tf', 'h5']:
    print(f'fmt={fmt}')
    filename_a = os.path.join(tempfile.mkdtemp(), 'data_{fmt}')
    filename_b = os.path.join(tempfile.mkdtemp(), 'data_{fmt}')

    a = A()
    a.save_weights(filename_a, save_format=fmt)
    a.something.assign(1.2)
    a.save_weights(filename_b, save_format=fmt)
    print('trainable_variables', a.trainable_variables)

    b = A()
    b.load_weights(filename_b)
    value = float(b.something.numpy())
    check = np.abs(value - 1.2) < 1e-4
    print(value, f'fmt={fmt}. class var PASS={check}. The value should be 1.2')
    
    value = float(b.trainable_variables[0].numpy())
    check = np.abs(value - 1.2) < 1e-4
    print(value, f'fmt={fmt}. trainable_variables PASS={check}. The value should be 1.2')


```

```
import os
import tensorflow as tf
import tempfile
import glob

class A(tf.keras.models.Model):
    def __init__(self):
        self.something = tf.Variable(1.0, dtype='float32', trainable=True)
        super().__init__()

        
for fmt in ['tf', 'h5']:
    print(f'fmt={fmt}')
    filename_a = os.path.join(tempfile.mkdtemp(), 'data_{fmt}')
    filename_b = os.path.join(tempfile.mkdtemp(), 'data_{fmt}')

    a = A()
    a.save_weights(filename_a, save_format=fmt)
    a.something.assign(1.2)
    a.save_weights(filename_b, save_format=fmt)
    print('trainable_variables', a.trainable_variables)

    b = A()
    b.load_weights(filename_b)
    value = float(b.something.numpy())
    check = np.abs(value - 1.2) < 1e-4
    print(value, f'fmt={fmt}. class var PASS={check}. The value should be 1.2')
    
    value = float(b.trainable_variables[0].numpy())
    check = np.abs(value - 1.2) < 1e-4
    print(value, f'fmt={fmt}. trainable_variables PASS={check}. The value should be 1.2')
```

```
import os
import tensorflow as tf
import tempfile
import glob

class A(tf.keras.models.Model):
    def __init__(self):
        super().__init__()

    def build(self, input_shape):
        self.something = self.add_weight(initializer=tf.keras.initializers.Ones(), dtype=tf.float32, shape=(1,), name='something')

    def call(self, x):
        return x


for fmt in ['tf', 'h5']:
    print(f'fmt={fmt}')
    filename_a = os.path.join(tempfile.mkdtemp(), 'data_{fmt}')
    filename_b = os.path.join(tempfile.mkdtemp(), 'data_{fmt}')

    a = A()
    a(np.random.randn(3, 4).astype(np.float32))
    a.save_weights(filename_a, save_format=fmt)
    a.something.assign([1.2])
    a.save_weights(filename_b, save_format=fmt)
    print('trainable_variables', a.trainable_variables)

    b = A()
    b(np.random.randn(3, 4).astype(np.float32))
    b.load_weights(filename_b)
    value = float(b.something.numpy())
    check = np.abs(value - 1.2) < 1e-4
    print(value, f'fmt={fmt}. class var PASS={check}. The value should be 1.2')
    
    value = float(b.trainable_variables[0].numpy())
    check = np.abs(value - 1.2) < 1e-4
    print(value, f'fmt={fmt}. trainable_variables PASS={check}. The value should be 1.2')
```


Output is:

```
fmt=tf
trainable_variables [<tf.Variable 'something:0' shape=() dtype=float32, numpy=1.2>]
1.2000000476837158 fmt=tf. class var PASS=True. The value should be 1.2
1.2000000476837158 fmt=tf. trainable_variables PASS=True. The value should be 1.2
fmt=h5
trainable_variables [<tf.Variable 'something:0' shape=() dtype=float32, numpy=1.2>]
1.0 fmt=h5. class var PASS=False. The value should be 1.2
1.0 fmt=h5. trainable_variables PASS=False. The value should be 1.2
```


The value of 1.2 is not coming back in the h5 case


"
33418,(TF 2.0)My custom loss doesn't works.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0 / 7.6.0
- GPU model and memory: 8G



I have made my custom loss like below:
```
def inner_loss(model, penalty=0.001):
    for i in range(model.layers[3].trainable_variables[1].shape[3]):
         for j in range(i + 1, model.layers[3].trainable_variables[1].shape[3]):
            pw_kernel_i = tf.squeeze(model.layers[3].trainable_variables[1][:, :, :, i])
            pw_kernel_j = tf.squeeze(model.layers[3].trainable_variables[1][:, :, :, j])
            model.add_loss(lambda: penalty * tf.tensordot(pw_kernel_i, pw_kernel_j, 1))
    return

@tf.function
def train_one_step(model, x, y, optimizer):
    with tf.GradientTape() as tape:
        logits = model(x, training=True)
        loss = _criterion(y_true=y, y_pred=logits)

        inner_loss(model, 0.001)
        loss += sum(model.losses)

    grads = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))
    return loss, logits
```

And I have this error code:

**TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: Squeeze_4030:0**


Why does this error occur? 

"
33416,"TensorFlow Lite: TensorListFromTensor, TensorListReserve, TensorListStack, While","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- TensorFlow installed from (source or binary): Binaries from pacman
- TensorFlow version (or github SHA if from source): 2.0.0


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, EXPAND_DIMS, FILL, LOGISTIC, MAXIMUM, MAX_POOL_2D, MINIMUM, MUL, PACK, PAD, RELU, RESHAPE, RESIZE_NEAREST_NEIGHBOR, SHAPE, STRIDED_SLICE, SUB, TILE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.

```

The model is very similar to https://github.com/fizyr/keras-retinanet.

I am converting with target specs `[tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]`, so my problem could be solved by adding TensorListFromTensor, TensorListReserve, TensorListStack, While to the whitelist [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/flex/whitelisted_flex_ops.cc) and use the standard tensorflow implementation.

"
33414,Allow to specify the type of the tf.data.Dataset.range function,"**System information**
- TensorFlow version (you are using): *v2.0.0*
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

[`tf.data.Dataset.range`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#range) return a dataset of `tf.dtypes.int64` tensors.

It could be nice if the `range` method accept a `dtype` argument (as many other TF methods) to choose the type of the dataset elements.

**Will this change the current api? How?**

This will change the API, adding an accepted `dtype` parameter to the `range` method.

**Who will benefit with this feature?**

Any person that uses the `Dataset.range` method to generate some index to use with `TensorArray.write` which only accept a `tf.dtypes.int32` tensor as its first argument.

**Any Other info.**

It could be possible to update `TensorArray.write` to let it accept `int32` or `int64` (or even `int8`) as its `index` argument."
33413,tflite 2.0 gpu delegate error when inputs resized,"Hi,

For gpu delegate if resizeInput is called and then runForMultipleInputsOutputs, there is an exception.

- Mobile Samsung S9
- Mali G72 GPU
- Tensorflow lite installed from binary version 2.0
- Development env, android studio on fedora 29

Example code:
```
fun resizeInput() {
            val options: Interpreter.Options = Interpreter.Options()
            val del = GpuDelegate()
            //options.addDelegate(del)
            val inter = Interpreter(AssetLoader.loadMappedBytes(""best_model_shape_4x416x224_float32.tflite""), options)
            val sh = inter.getInputTensor(0).shape()
            inter.resizeInput(0, intArrayOf(1, 224, 416, 4))
            var inNumBytes = inter.getInputTensor(0).numBytes()
            var inputs = Array<ByteBuffer>(1) {
                ByteBuffer.allocateDirect(inNumBytes).order(ByteOrder.nativeOrder())
            }
            val outputs1 = Array<ByteBuffer>(inter.outputTensorCount) {
                val tensor = inter.getOutputTensor(it)
                ByteBuffer.allocateDirect(tensor.numBytes()).order(ByteOrder.nativeOrder())
            }
            val outputBuffers = outputs1.mapIndexed { index, byteBuffer -> index to byteBuffer }.toMap()

            inter.modifyGraphWithDelegate(del)
            inter.runForMultipleInputsOutputs(inputs, outputBuffers)
            DefaultLogger.verbose { ""TfLite inference: ${inter.lastNativeInferenceDurationNanoseconds} ns"" }

            inter.resetVariableTensors()
            inter.resizeInput(0, intArrayOf(1, 416, 224, 4))
            inNumBytes = inter.getInputTensor(0).numBytes()
            inputs = Array<ByteBuffer>(1) {
                ByteBuffer.allocateDirect(inNumBytes).order(ByteOrder.nativeOrder())
            }
            inter.runForMultipleInputsOutputs(inputs, outputBuffers)
            DefaultLogger.verbose { ""After resize TfLite inference: ${inter.lastNativeInferenceDurationNanoseconds} ns"" }
    }
```
```java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: TfLiteGpuDelegate Init: Index is out of range
TfLiteGpuDelegate Prepare: delegate is not initialized
Node number 70 (TfLiteGpuDelegateV2) failed to prepare.

Restored previous execution plan after delegate application failure.
at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native Method)
```

Is this a bug or this sequence of operations is not supported for gpu delegate? I am using the Java API.

Regards,

Naveen"
33412,tf2.0 takes more than twice memory than 1.14,"I have 2 environments. tf 1.14 installed for python 3.5 and tf 2 for python 3.7.

I run the same code and load the same keras model in both environments. in py3.5, after model loaded, the process takes 560MB memory. while in py3.7, it takes 1.2GB.

is there any way to reduce the memory for tf 2 ?"
33411,Saving model containing sequence_numeric_column fails,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v1.12.1-15925-g2e1e8ecea2 2.1.0-dev20191015
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
Saving a keras model containing a `sequence_numeric_column` feature_column results in the error:

`TypeError: Input must be a SparseTensor.`

However, saving a model using a `sequence_categorical_column_with_*` together with `indicator_column` or `embedding_column` works as expected. For example, the following works as expected:

```
import tensorflow as tf

cols = [
    tf.feature_column.indicator_column(
        tf.feature_column.sequence_categorical_column_with_vocabulary_list(
            ""a"", vocabulary_list=[""one"", ""two""]
        )
    ),
    tf.feature_column.embedding_column(
        tf.feature_column.sequence_categorical_column_with_hash_bucket(
            ""b"", hash_bucket_size=10
        ),
        dimension=2,
    ),
]
input_layers = {
    ""a"": tf.keras.layers.Input(
        shape=(None, 1), sparse=True, name=""a"", dtype=""string""
    ),
    ""b"": tf.keras.layers.Input(
        shape=(None, 1), sparse=True, name=""b"", dtype=""string""
    ),
}

fc_layer, _ = tf.keras.experimental.SequenceFeatures(cols)(input_layers)
x = tf.keras.layers.GRU(32)(fc_layer)
output = tf.keras.layers.Dense(10)(x)

model = tf.keras.models.Model(input_layers, output)

model.compile(
    loss=tf.keras.losses.MSE,
    optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),
    metrics=[tf.keras.metrics.categorical_accuracy],
)

tf.saved_model.save(model, ""model"")
```

**Describe the expected behavior**
It should be possible to save a model containing all types of sequence_feature_columns.

**Code to reproduce the issue**

```
import tensorflow as tf

cols = [
    tf.feature_column.sequence_numeric_column('a'),
]
input_layers = {
    'a':
        tf.keras.layers.Input(shape=(None, 1), sparse=True, name='a'),
}

fc_layer, _ = tf.keras.experimental.SequenceFeatures(cols)(input_layers)
x = tf.keras.layers.GRU(32)(fc_layer)
output = tf.keras.layers.Dense(10)(x)

model = tf.keras.models.Model(input_layers, output)

model.compile(
    loss=tf.keras.losses.MSE,
    optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),
    metrics=[tf.keras.metrics.categorical_accuracy])

tf.saved_model.save(model, ""model"")
```
**Other info / logs**
Full traceback:
```
Traceback (most recent call last):
  File ""test2.py"", line 22, in <module>
    tf.saved_model.save(model, ""model"")
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py"", line 894, in save
    checkpoint_graph_view)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_serialization.py"", line 64, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py"", line 142, in list_functions
    self._serialization_cache)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 2414, in _list_functions_for_serialization
    .list_functions_for_serialization(serialization_cache))
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py"", line 91, in list_functions_for_serialization
    fns = self.functions_to_serialize(serialization_cache)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 80, in functions_to_serialize
    serialization_cache).functions_to_serialize)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 95, in _get_serialized_attributes
    serialization_cache)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/model_serialization.py"", line 47, in _get_serialized_attributes_internal
    default_signature = save_impl.default_save_signature(self.obj)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 212, in default_save_signature
    fn.get_concrete_function()
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 891, in get_concrete_function
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2365, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2673, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2563, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 958, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saving_utils.py"", line 143, in _wrapped_model
    outputs_list = nest.flatten(model(inputs=inputs, training=False))
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 771, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py"", line 713, in call
    convert_kwargs_to_constants=base_layer_utils.call_context().saving)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py"", line 869, in _run_internal_graph
    output_tensors = layer(computed_tensors, **kwargs)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 771, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 292, in wrapper
    return func(*args, **kwargs)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/feature_column/sequence_feature_column.py"", line 144, in call
    transformation_cache, self._state_manager)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/feature_column/sequence_feature_column.py"", line 559, in get_sequence_dense_tensor
    sp_tensor, default_value=self.default_value)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/ops/sparse_ops.py"", line 1488, in sparse_tensor_to_dense
    sp_input = _convert_to_sparse_tensor(sp_input)
  File ""/Users/emla2805/.pyenv/versions/bug/lib/python3.6/site-packages/tensorflow_core/python/ops/sparse_ops.py"", line 69, in _convert_to_sparse_tensor
    raise TypeError(""Input must be a SparseTensor."")
TypeError: Input must be a SparseTensor.
```
"
33410,tfliteGpuDelegate Invoke write to buffer failed source data is larger than buffer,"

I followed the steps in https://www.tensorflow.org/lite/performance/gpu and added gpu to tflite interpreter. The mobilenet model given by an android project called tensorflow/lite/jave/demo can work using this project on Pixel 2. However, when it was put into another project with the follwing code. Here comes the errors: 
```
TfLiteGpuDelegate Invoke: Write to buffer failed. Source data is larger than buffer
Node number 31 (TfLiteGpuDelegateV2) failed to invoke.
```
imgData, outputClasses are already checked and have the same size with those in tensorflow/lite/jave/demo project.

Versions of TfLite and TfLiteGpu are also kept the same with that in tensorflow/lite/jave/demo project.

```
import  org.tensorflow.lite.TensorFlowLite;
import org.tensorflow.lite.gpu.GpuDelegate;

/**
 * Wrapper for frozen detection models trained using the Tensorflow Object Detection API:
 * github.com/tensorflow/models/tree/master/research/object_detection
 */
public class TFLiteObjectDetectionAPIModel implements Classifier {
  private static final Logger LOGGER = new Logger();

  // Only return this many results.
  private static final int NUM_DETECTIONS = 1001; // hand landmark ,21, mobilenet, 1001
  // Float model
  private static final float IMAGE_MEAN = 128.0f;
  private static final float IMAGE_STD = 128.0f;
  private boolean isModelQuantized;
  private int inputSize;
  private Vector<String> labels = new Vector<String>();
  private int[] intValues;
  private float[][][] outputLocations;
  private float[][] outputClasses;
  private float[][] outputScores;
  private float[] numDetections;

  private GpuDelegate gpuDelegate = new GpuDelegate();
  private final Interpreter.Options options = (new Interpreter.Options()).addDelegate(gpuDelegate);
  private ByteBuffer imgData;

  private Interpreter tfLite;
  private ArrayList<Recognition> recognitions = new ArrayList<Recognition>();

  private TFLiteObjectDetectionAPIModel() {}

  /** Memory-map the model file in Assets. */
  private static MappedByteBuffer loadModelFile(AssetManager assets, String modelFilename)
      throws IOException {
    FileInputStream inputStream = new FileInputStream(new File(""/sdcard/sunny/data/""+modelFilename+"".tflite""));

    FileChannel fileChannel = inputStream.getChannel();
    long startOffset = fileChannel.position();
    long declaredLength = fileChannel.size();
    return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);
  }

  /**
   * Initializes a native TensorFlow session for classifying images.
   *
   * @param assetManager The asset manager to be used to load assets.
   * @param modelFilename The filepath of the model GraphDef protocol buffer.
   * @param labelFilename The filepath of label file for classes.
   * @param inputSize The size of image input
   * @param isQuantized Boolean representing model is quantized or not
   */
  public static Classifier create(
      final AssetManager assetManager,
      final String modelFilename,
      final String labelFilename,
      final int inputSize,
      final boolean isQuantized)
      throws IOException {
    final TFLiteObjectDetectionAPIModel d = new TFLiteObjectDetectionAPIModel();

    InputStream labelsInput = null;
    String actualFilename = labelFilename.split(""file:///android_asset/"")[1];
    labelsInput = assetManager.open(actualFilename);
    BufferedReader br = null;
    br = new BufferedReader(new InputStreamReader(labelsInput));
    String line;
    while ((line = br.readLine()) != null) {
      LOGGER.w(line);
      d.labels.add(line);
    }
    br.close();

    d.inputSize = inputSize;
    try {
      d.tfLite = new Interpreter(loadModelFile(assetManager, modelFilename),d.options);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }

    d.isModelQuantized = isQuantized;
    // Pre-allocate buffers.
    int numBytesPerChannel;
    if (isQuantized) {
      numBytesPerChannel = 1; // Quantized
    } else {
      numBytesPerChannel = 4; // Floating point
    }
    d.imgData = ByteBuffer.allocateDirect(1 * d.inputSize * d.inputSize * 3 * 4);
    d.imgData.order(ByteOrder.nativeOrder());
    d.intValues = new int[d.inputSize * d.inputSize];

    d.outputClasses = new float[1][NUM_DETECTIONS];

    return d;
  }

  @Override
  public List<Recognition> processImage(final AssetManager assetManager, Classifier.Recognition.inputFormat imageFormat, int[] intValues){
    Trace.beginSection(""preprocessBitmap"");

    imgData.rewind();
    for (int i = 0; i < inputSize; ++i) {
      for (int j = 0; j < inputSize; ++j) {
        int pixelValue = intValues[i * inputSize + j];
        if (isModelQuantized) {
          // Quantized model
          imgData.put((byte) ((pixelValue >> 16) & 0xFF));
          imgData.put((byte) ((pixelValue >> 8) & 0xFF));
          imgData.put((byte) (pixelValue & 0xFF));
        } else { // Float model
          imgData.putFloat((((pixelValue >> 16) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);
          imgData.putFloat((((pixelValue >> 8) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);
          imgData.putFloat(((pixelValue & 0xFF) - IMAGE_MEAN) / IMAGE_STD);
        }
      }
    }
    Trace.endSection(); // preprocessBitmap

    // Copy the input data into TensorFlow.
    Trace.beginSection(""feed"");
    outputClasses = new float[1][NUM_DETECTIONS];
    Trace.endSection();

    // Run the inference call.
    Trace.beginSection(""run"");
    tfLite.run(imgData, outputClasses);
    Trace.endSection();

    return recognitions;
  }


  @Override
  public void enableStatLogging(final boolean logStats) {}

  @Override
  public String getStatString() {
    return """";
  }

  @Override
  public void close() {
    tfLite.close();
    tfLite = null;
    recognitions.clear();
    recognitions=null;
    gpuDelegate.close();
    gpuDelegate = null;
}
```"
33408,Time Series Forecasting with LSTM and different/mixed frequencies,"I could not find anything in the docs about how to handle different frequencies of time series. I have a Dataset A with monthly data that i want to use to predict the values from Dataset B that contains quarterly based data. So the target value e.g. quarter 1 is based on the values from month 1-3.

Dataset A (Features):

| Month  | Value1 | Value2 | Value3 |
| ------------- | ------------- | ------------- | ------------- |
| 1  | 91  | 72 | 23 |
| 2  | 93  | 68 | 33 |
| 3  | 92  | 57 | 27 |
| 4  | 91  | 72 | 23 |
| 5  | 93  | 68 | 33 |
| 6  | 92  | 57 | 27 |

Dataset B (Target):

| Quarter   | Target_Value |
| ------------- | ------------- |
| 1  | 51  |
| 2  | 57  |"
33407,Eager mode not being disabled tf 1.14.0,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Trying out example from Tensorflow Probability with the following code:

```
import tensorflow as tf
import tensorflow_probability as tfp
import numpy as np

tfd = tfp.distributions
dtype = np.float32

with tf.Session(graph=tf.Graph()) as sess:
  # Set up random seed for the optimizer
  tf.set_random_seed(42)
  true_mean = dtype([0, 0, 0])
  true_cov = dtype([[1, 0.25, 0.25], [0.25, 1, 0.25], [0.25, 0.25, 1]])
  # Loss is defined through the Cholesky decomposition
  chol = tf.linalg.cholesky(true_cov)

  var_1 = tf.Variable(name='var_1', initial_value=[1., 1.])
  var_2 = tf.Variable(name='var_2', initial_value=[1.])

  def loss_fn():
    var = tf.concat([var_1, var_2], axis=-1)
    loss_part = tf.linalg.cholesky_solve(chol, tf.expand_dims(var, -1))
    return tf.linalg.matvec(loss_part, var, transpose_a=True)

  # Set up the learning rate with a polynomial decay
  step = tf.Variable(0, dtype=tf.int64)
  starter_learning_rate = .3
  end_learning_rate = 1e-4
  decay_steps = 1e4
  learning_rate = tf.compat.v1.train.polynomial_decay(
      starter_learning_rate,
      step,
      decay_steps,
      end_learning_rate,
      power=1.)

  # Set up the optimizer
  optimizer_kernel = tfp.optimizer.StochasticGradientLangevinDynamics(
      learning_rate=learning_rate, preconditioner_decay_rate=0.99)
  optimizer_kernel.iterations = step
  optimizer = optimizer_kernel.minimize(loss_fn, var_list=[var_1, var_2])

  # Number of training steps
  training_steps = 5000
  # Record the steps as and treat them as samples
  samples = [np.zeros([training_steps, 2]), np.zeros([training_steps, 1])]
  sess.run(tf.compat.v1.global_variables_initializer())
  for step in range(training_steps):
    sess.run(optimizer)
    sample = [sess.run(var_1), sess.run(var_2)]
    samples[0][step, :] = sample[0]
    samples[1][step, :] = sample[1]

  samples_ = np.concatenate(samples, axis=-1)
  sample_mean = np.mean(samples_, 0)
  print('sample mean', sample_mean)

```
Getting following error:

```
File ""/Users/shashank.gupta/miniconda2/lib/python2.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 318, in minimize
    loss, var_list=var_list, grad_loss=grad_loss)
  File ""/Users/shashank.gupta/miniconda2/lib/python2.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 351, in _compute_gradients
    tape.watch(var_list)
  File ""/Users/shashank.gupta/miniconda2/lib/python2.7/site-packages/tensorflow/python/eager/backprop.py"", line 816, in watch
    for t in nest.flatten(tensor):
AttributeError: 'RefVariable' object has no attribute '_id'

```
Looks like eager mode is enabled. Have added a command to disable it still it's getting activated."
33403,max_pool_with_argmax can gives different results on GPU than on CPU,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: GPU 1080-Ti

**Describe the current behavior**

When running the test in the code below, one of the tests fail. Somehow, the argmax result of max_pool_with_argmax is different when running with self.session(use_gpu=True).
Interestingly, the failing test behaves as if it was ignoring the batch index in the argmax.


**Describe the expected behavior**

All 3 tests should pass.

**Code to reproduce the issue**

    import tensorflow as tf
    import numpy as np
    
    
    class TestMaxPool(tf.test.TestCase):

        def setUp(self):
            tf.reset_default_graph()

        def _test(self, sess):
             # Image with 2 channels, H = 4, W = 4
             image_t = tf.constant([[[1.0, 12.0], [3.0, 14.0], [5.0, 16.0], [7.0, 18.0]],
                               [[11.0, 2.0], [13.0, 4.0], [15.0, 6.0], [17.0, 8.0]],
                               [[38.0, 37.0], [36.0, 35.0], [34.0, 33.0], [32.0, 31.0]],
                               [[28.0, 27.0], [26.0, 25.0], [24.0, 23.0], [22.0, 21.0]]])
             input_t = tf.stack([image_t, image_t])
             _, pool_indices = tf.nn.max_pool_with_argmax(input_t, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
             pool_indices_out = sess.run(pool_indices)

            expected_image_indices = np.array([[[10, 3], [14, 7]], [[16, 17], [20, 21]]])
            self.assertAllEqual(pool_indices_out, np.stack([expected_image_indices, expected_image_indices + 32]))

        def test_with_normal_session(self):
            with tf.Session() as sess:
                self._test(sess)

        def test_with_self_session_and_gpu(self):
            with self.session(use_gpu=True) as sess:
                self._test(sess)

        def test_with_self_session_and_cpu(self):
            with self.session(use_gpu=False) as sess:
                self._test(sess)


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33402,Please add TPU kernels for tf.linalg.[[s]log]det,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.15
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
Adding determinant kernels (along with gradients) will allow us to train Normalizing Flow models on TPUs.

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
33401,Uniform APIs for Tensor etc regardless of graph mode or runtime mode,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.14+
- Are you willing to contribute it (Yes/No): N/A


**Describe the feature and the current behavior/state.**
This feature request is related to the issue ""Tensor object has no attribute numpy"" (maybe other issues as well) due to the fact Tensorflow implementation distinguishes graph mode (using evel()) and runtime mode (using numpy()) at public API level. However, such API difference is not desirable. From developer's perspective, a good design would be uniform APIs (e.g. value()) that hides away internal different treatment between graph time and runtime. So, what a developer wants is to have a UNIFORM mechanism/APIs for setting up business logic regardless of the modes even though actual data may not be known yet during building model (graph mode). This has been the case at macro level for example tf.keras modelling. It needs to extend to micro level APIs/classes like Tensor. (Particularly, since eager execution is default from v2.0.0+)


**Will this change the current api? How?**
Ideally expect a uniform API like value/data. A compromise is just to implement numpy for graph mode as well to avoid break existing code.


**Who will benefit with this feature?**
Developers who use Tensorflow.

 
**Any Other info.**
N/A"
33400,tensor object has no attribute numpy ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
33399,"keras.metrics.MeanSquaredError update_state, sample_weight not working as expected","**System information**
- Have I written custom code: **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.04**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**
- TensorFlow installed from (source or binary): **pip**
- TensorFlow version (use command below): **Version: 2.0.0**
- Python version: **Python 3.6.8**
- Bazel version (if compiling from source):**N/A**
- GCC/Compiler version (if compiling from source): **N/A**
- CUDA/cuDNN version: **CUDA Version: 10.2**
- GPU model and memory: **GeForce GTX 1660 Ti, 6GB**

**Describe the current behavior**
Running `update_state` on `tf.keras.metrics.MeanSquaredError` ,raises exception when passing in `sample_weight` even if sample_weight and y_true shape are the same.

Weighting in other metrics works fine so not sure if this is a user error, in which case the docs could be updated, or an acutal bug. 
I haven't had time to look into this deeper but would be open too applying fixes if someone could point me in the right direction, thanks.

```python

m = tf.keras.metrics.MeanSquaredError()
m.update_state([0., 0., 1., 1.], [1., 1., 1., 0.], sample_weight=[1, 1, 1, 0])

```
Error:
`tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[0], expected a dimension of 1, got 4 [Op:Squeeze]`

**Describe the expected behavior**
Should work the same as all other weighted metrics.

eg:
```python
m = tf.keras.metrics.Mean()
m.update_state([1, 3, 5, 7], sample_weight=[1,1,1,0])

# output: <tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=3.0>

```

**Code to reproduce the issue**
See above

**Other info / logs**
```
m = tf.keras.metrics.MeanSquaredError()
m.update_state([0., 0., 1., 1.], [1., 1., 1., 0.], sample_weight=[1, 1, 1, 0])

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/shaun/src/tf2_env/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py"", line 128, in __call__
    losses, sample_weight, reduction=self._get_reduction())
  File ""/home/shaun/src/tf2_env/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/losses_utils.py"", line 107, in compute_weighted_loss
    losses, sample_weight)
  File ""/home/shaun/src/tf2_env/lib/python3.6/site-packages/tensorflow_core/python/ops/losses/util.py"", line 145, in scale_losses_by_sample_weight
    losses = math_ops.cast(losses, dtypes.float32)
  File ""/home/shaun/src/tf2_env/lib/python3.6/site-packages/tensorflow_core/python/ops/losses/util.py"", line 97, in squeeze_or_expand_dimensions
    # Use static rank.
  File ""/home/shaun/src/tf2_env/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/shaun/src/tf2_env/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/shaun/src/tf2_env/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py"", line 3649, in squeeze
    return gen_array_ops.squeeze(input, axis, name)
  File ""/home/shaun/src/tf2_env/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py"", line 10061, in squeeze
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[0], expected a dimension of 1, got 4 [Op:Squeeze]

```
"
33397,LEAKY_RELU not supported in INT8 quantization,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.0


**Provide the text output from tflite_convert**

```
<ipython-input-54-6f97bfc97449> in <module>
----> 1 workflow(False, 10, 'int8', True, True)

<ipython-input-53-3889d2128b41> in workflow(dw, n_conv, dtype, v1, leaky)
     11     model.save(keras_file_name)
     12     if v1:
---> 13         tflite_model = convert2tflitev1(keras_file_name, qmode=dtype)
     14     else:
     15         tflite_model = convert2tflite(model, qmode=dtype)

<ipython-input-27-637084f295d5> in convert2tflitev1(model_file, qmode)
     19     elif qmode == 'float32':
     20         pass
---> 21     tflite_model = converter.convert()
     22 
     23     return tflite_model

~/miniconda3/envs/tf2-n-pytorch/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py in convert(self)
    991     if self._is_calibration_quantize():
    992       result = self._calibrate_quantize_model(result, inference_input_type,
--> 993                                               inference_output_type)
    994 
    995     return result

~/miniconda3/envs/tf2-n-pytorch/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py in _calibrate_quantize_model(self, result, inference_input_type, inference_output_type)
    237     return calibrate_quantize.calibrate_and_quantize(
    238         self.representative_dataset.input_gen, inference_input_type,
--> 239         inference_output_type, allow_float)
    240 
    241   def _get_base_converter_args(self):

~/miniconda3/envs/tf2-n-pytorch/lib/python3.7/site-packages/tensorflow_core/lite/python/optimize/calibrator.py in calibrate_and_quantize(self, dataset_gen, input_type, output_type, allow_float)
     76     return self._calibrator.QuantizeModel(
     77         np.dtype(input_type.as_numpy_dtype()).num,
---> 78         np.dtype(output_type.as_numpy_dtype()).num, allow_float)

~/miniconda3/envs/tf2-n-pytorch/lib/python3.7/site-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py in QuantizeModel(self, input_py_type, output_py_type, allow_float)
    113 
    114     def QuantizeModel(self, input_py_type, output_py_type, allow_float):
--> 115         return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, input_py_type, output_py_type, allow_float)
    116 CalibrationWrapper_swigregister = _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_swigregister
    117 CalibrationWrapper_swigregister(CalibrationWrapper)

RuntimeError: Quantization not yet supported for op: LEAKY_RELU
```

Also, please include a link to a GraphDef or the model if possible.

Model definition
```
def build_lrelu_model(n_layers):
    layer_list = []
    for idx in range(n_layers):
        conv_name = f'conv{idx}'
        if idx == 0:
            conv = layers.Conv2D(filters=32, 
                                 kernel_size=3, 
                                 padding='same', 
                                 name=conv_name, 
                                 input_shape=(28, 28, 3))
        else:
            conv = layers.Conv2D(filters=32, 
                                 kernel_size=3, 
                                 padding='same', 
                                 name=conv_name)
        bn = layers.BatchNormalization(name=f'bn{idx}')
        activation = layers.LeakyReLU(alpha=0.1, name=f'lrelu{idx}')
        layer_list.extend([conv, bn, activation])
    model = tf.keras.models.Sequential(layer_list)
    model.summary()
    return model
```

Conversion options:

```
        converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(model_file)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
        converter.inference_input_type = tf.uint8
        converter.inference_output_type = tf.uint8
```

**Any other info / logs**

I saw there were some PR about the implementation of Leaky_ReLU in tflite and quantization. But I still cannot get it to work. 

Ref PR: https://github.com/tensorflow/tensorflow/pull/27061

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33396,"python -c ""import tensorflow as tf; print(tf.contrib.eager.num_gpus())"" from docs doesn't work with ","python -c ""import tensorflow as tf; print(tf.contrib.eager.num_gpus())"" Doesn't work from https://www.tensorflow.org/install/source
with tf2
"
33395,test,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33394,AttributeError: 'list' object has no attribute 'op' when calling SparseCategoricalCrossentropy,"**Describe the current behavior**
When running the following code in the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) of `SparseCategoricalCrossentropy`:

```
cce = tf.keras.losses.SparseCategoricalCrossentropy()
loss = cce(
  [0, 1, 2],
  [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])
print('Loss: ', loss.numpy())  # Loss: 0.3239
```

I obtained the following error:

> ---------------------------------------------------------------------------
> AttributeError                            Traceback (most recent call last)
> <ipython-input-2-e7331c659215> in <module>()
>       3 loss = cce(
>       4   [0, 1, 2],
> ----> 5   [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])
>       6 print('Loss: ', loss.numpy())  # Loss: 0.3239
> 
> 3 frames
> /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py in sparse_categorical_crossentropy(target, output, from_logits, axis)
>    4397   if not from_logits:
>    4398     if (isinstance(output, (ops.EagerTensor, variables_module.Variable)) or
> -> 4399         output.op.type != 'Softmax'):
>    4400       epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)
>    4401       output = clip_ops.clip_by_value(output, epsilon_, 1 - epsilon_)
> 
> AttributeError: 'list' object has no attribute 'op'

"
33393,"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: AVERAGE_POOL_2D, CONCATENATION, CONV_2D, FULLY_CONNECTED, MAX_POOL_2D, MEAN, RELU, SOFTMAX, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: AddV2.","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33392,SEGBUS on tf.data.Dataset when generating large numpy arrays,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33391,TensorFlow documentation should be associated with the applicable specific versions of TensorFlow,"## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/guide/gpu

## Description of issue (what needs changing):

I was reading this documentation page https://www.tensorflow.org/guide/gpu, but it is **unclear** which TensorFlow version the documentation applies to. Especially now that a stable version of TF 2 has been released, it is important to clarify which TF version the documentation refers to. 

On the top bar of the linked webpage, there is a menu called API, where you can select the API you are interested in. Right now, the sub-menu corresponding to the specific version of TF I am reading is not even highlighted, so I don't know if I am reading the documentation for TF 1 or 2. To confuse people even further, even though I think I am reading the documentation for TF 2, in another top bar, it is written `TF 1`. 

Given that I am confused, another person can also be confused, so the documentation needs to be clarified. So, I suggest that every documentation page is associated (**in a very clear way**) with all applicable TF versions."
33390,Docker Image with a pre-built Tensorflow-gpu with a compute capability 3.0 GPUs,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0

**Describe the feature and the current behavior/state.**
Currently if someone has an older GPU - they have to build from source. However this is time-consuming and error-prone. I tried building it as per instructions with no luck.

**Will this change the current api? How?**

**Who will benefit with this feature?**
 If there was a docker image for legacy GPU CUDA support - it would help many people who still have a legacy GPU cards to make use of them to train their models without having to dash out hundreds of dollars on a new GPU card right away. Building from source is very time consuming and error prone.

**Any Other info.**
"
33389,[TF2.0] tf.make_ndarray() not functional,"* environment: colab
* python3
* TF 2.0

Running ```tf.make_ndarray()``` throws an attribute error ```AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'tensor_shape' ```

As per the documentation [here](https://www.tensorflow.org/api_docs/python/tf/make_ndarray)
it's supposed to create a numpy array with the same shape and content as the input tensor.
I've also tried with lazy eval mode but the same attribute error is thrown. could it be a bug??

```python
a=tf.constant([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])
x = tf.make_ndarray(a)
print(x)
```
Full error log:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-4-039c2e207451> in <module>()
      1 a=tf.constant([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])
----> 2 tf.make_ndarray(a)
      3 #print(x)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_util.py in MakeNdarray(tensor)
    576 
    577   """"""
--> 578   shape = [d.size for d in tensor.tensor_shape.dim]
    579   num_elements = np.prod(shape, dtype=np.int64)
    580   tensor_dtype = dtypes.as_dtype(tensor.dtype)

AttributeError: 'Tensor' object has no attribute 'tensor_shape'
```"
33388,TypeError: reduce() missing 1 required positional argument: 'per_replica_value',"```
> with mirrored_strategy.scope():
>     model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
>     optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
> 
> global_batch_size = 10 * mirrored_strategy.num_replicas_in_sync
> 
> def input_fn():
>     dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(1000).batch(
>     global_batch_size)
>     dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)
>     return dist_dataset
>     
> dataset = input_fn()
> 
> @tf.function
> def train_step(dist_inputs):
>     def step_fn(inputs):
>         features, labels = inputs
>         with tf.GradientTape() as tape:
>             logits = model(features)
>             cross_entropy = tf.nn.softmax_cross_entropy_with_logits(
>                 logits=logits, labels=labels
>             )
>             loss = tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)
>         grads = tape.gradient(loss, model.trainable_variables)
>         optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))
>         return cross_entropy
> 
>     per_example_losses = mirrored_strategy.experimental_run_v2(
>         step_fn, args=(dist_inputs,)
>     )
>     mean_loss = mirrored_strategy.reduce(
>         tf.distribute.ReduceOp.MEAN, per_example_losses, axis=0
>     )    
>     return mean_loss
> 
> with mirrored_strategy.scope():
>     for input in dataset:
>         train_step(inputs)
```

Its one of the code snippets from the distributed strategy guide for custom training loops.
Im getting this, 

TypeError:TypeError: reduce() missing 1 required positional argument: 'per_replica_value' 

but then when I ran the same code today morning it was working perfectly. "
33387,[TF 2.0] Custom objects,"Hello all,

I have a keras file (.hdf5) that I've saved using TF 1.14 with custom operations (eg loss function). 
I recently upgraded to Tensorflow 2.0 and I was trying to convert this model to .tflite but I've seen that there is no 'custom_objects' argument. 
Is this an unnecessary argument had I saved the .hdf5 using the latest TF 2.0? Or is there any other new way to include this custom object when converting to .tflite?

Thank you in advance"
33385,"hub.Module(""https://tfhub.dev/google/elmo/2"")` doesn't work.","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow-hub version: 0.6.0
- TensorFlow version: 1.14.0
- Python version: 3.7.4


**Describe the current behavior**
The module load has not been completed and is waiting indefinitely.

**Code to reproduce the issue**
`elmo = hub.Module(""https://tfhub.dev/google/elmo/2"")`
"
33383,Desynchronized zipped datasets when using tf.data.experimental.ignore_errors,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
na
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
v2.0.0-rc2-26-g64c3d38 2.0.0
- Python version:
Python 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
cuda 10.0
- GPU model and memory:
P100 / 16GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

When an error is caught using the `tf.data.experimental.ignore_errors` on a zipped dataset, only the faulty dataset drops an element. The datasets are therefore desynchronized.

**Describe the expected behavior**

Datasets should stay synchronized by dropping an element from both datasets.

**Code to reproduce the issue**

```
good_dataset = tf.data.Dataset.from_tensor_slices([1., 2., 0., 4.])
bad_dataset = good_dataset.map(lambda x: tf.debugging.check_numerics(1. / x, ""error""))

dataset = tf.data.Dataset.zip((bad_dataset, good_dataset))
dataset = dataset.apply(tf.data.experimental.ignore_errors())

for bad, good in dataset:
    print(float(good), float(bad))

1.0 1.0
2.0 0.5
0.0 0.25
```


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33382,Bugs about dequantize operator calculation formula in SCALED mode,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.0
- Python version: Python 2.7.12
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Using numpy to simulate the calculation formula in SCALED mode of the dequantize operator in tensorflow, you can't get the correct result.
```
# This is the method of dequantize operator in tensorflow kernel code written by me.
if mode == ""SCALED"":
    num_bits = size * 8
    if dtype == ""uint8"":
        limit_min = 0
        limit_max = 1 << num_bits - 1
        scalar_factor = max_range / limit_max
    if dtype in (""int8"", ""int32""):
        limit_min = -(1 << (num_bits - 1))
        limit_max = -1 * limit_min - 1
        scalar_factor = max(min_range / limit_min, max_range / limit_max)
    res = input_tensor * scalar_factor
```
```
# This is the code of dequantize operator in tensorflow kernel code written by c++.
else if (mode_ == QUANTIZE_MODE_SCALED) {
    const float scale_factor =
        std::numeric_limits<T>::min() == 0
            ? (max_range / std::numeric_limits<T>::max())
            : std::max(min_range / std::numeric_limits<T>::min(),
                       max_range / std::numeric_limits<T>::max());
    const auto& input_tensor = input.flat<T>();
    output->flat<float>() =
    input_tensor.template cast<int>().template cast<float>() * scale_factor;
}
```
**Describe the expected behavior**
the code written by me should get the same result as the tensorflow c++ code.
However, I got much different result.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
# Then, I write the code that can get the same result as the actual result of the tensorflow
if mode == ""SCALED"":
    m = max_range  # float32
    if dtype == ""int8"" or dtype == ""int16"" or dtype == ""int32"":
        # min&max fixed is float32
        [min_fixed, max_fixed] = [-((1 << (num_bits - 1)) - 1), (1 << (num_bits - 1))-1]
        s = 2.0 * m / (max_fixed - min_fixed)
    if dtype == ""uint8"" or dtype == ""uint16"":
        [min_fixed, max_fixed] = [0, (1 << num_bits) - 1]
        s = m / (max_fixed - min_fixed)
    z = input_tensor * s
```
In my code, the _input_min_range_ param is redundant.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
33381,"[TFLite, Converter] Converting error on unusual dense layer","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): GIT_VERSION: 'v1.12.1-15611-g025365a736', VERSION: '2.0.0''
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): GCC 8.3.0
- CUDA/cuDNN version: No
- GPU model and memory: No

**Describe the current behavior**
When run the code below, conversion errors appear that are in the logs below.

**Code to reproduce the issue**
```
import tensorflow as tf

class MyDense(tf.keras.layers.Layer):
  def __init__(self, num_units, **kwargs):
    super(MyDense, self).__init__(**kwargs)
    self.num_units = num_units

  def build(self, input_shape):
    kernel_shape = [input_shape[-1], self.num_units * 2, self.num_units]
    bias_shape = [self.num_units]

    self.kernel = self.add_weight(""kernel"", shape=kernel_shape, trainable=True)
    self.bias = self.add_weight(""bias"", shape=bias_shape, trainable=True)
    super(MyDense, self).build(input_shape)

  def call(self, inputs):
    return tf.einsum(""ac,cde->ade"", inputs, self.kernel) + self.bias

inputs = tf.keras.Input(shape=(10,), dtype=tf.float32)
outputs = MyDense(15)(inputs)
model = tf.keras.Model(inputs=inputs, outputs=outputs)
model.summary()

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
print(""SUCCESS!"")
```

**Logs**
```
2019-10-15 14:43:59.548878: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-10-15 14:43:59.566412: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3100000000 Hz
2019-10-15 14:43:59.567598: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3502840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-10-15 14:43:59.567616: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 10)]              0
_________________________________________________________________
my_dense (MyDense)           (None, 30, 15)            4515
=================================================================
Total params: 4,515
Trainable params: 4,515
Non-trainable params: 0
_________________________________________________________________
2019-10-15 14:43:59.640959: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-10-15 14:43:59.641037: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-10-15 14:43:59.642744: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:829] Optimization results for grappler item: graph_to_optimize
2019-10-15 14:43:59.642759: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:831]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2019-10-15 14:43:59.642763: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:831]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-10-15 14:43:59.657830: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-10-15 14:43:59.657896: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-10-15 14:43:59.660184: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:829] Optimization results for grappler item: graph_to_optimize
2019-10-15 14:43:59.660198: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:831]   constant_folding: Graph size after: 21 nodes (-3), 23 edges (-4), time = 0.76ms.
2019-10-15 14:43:59.660203: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:831]   constant_folding: Graph size after: 21 nodes (0), 23 edges (0), time = 0.248ms.
Traceback (most recent call last):
 File ""convert_error.py"", line 25, in <module>
   tflite_model = converter.convert()
 File ""/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 447, in convert
   **converter_kwargs)
 File ""/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 449, in toco_convert_impl
   enable_mlir_converter=enable_mlir_converter)
 File ""/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 200, in toco_convert_protos
   raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2019-10-15 14:44:00.554744: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 10 operators, 19 arrays (0 quantized)
2019-10-15 14:44:00.554825: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 10 operators, 19 arrays (0 quantized)
2019-10-15 14:44:00.554930: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 3 operators, 8 arrays (0 quantized)
2019-10-15 14:44:00.554945: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:118] Check failed: dim_x == dim_y (450 vs. 15)Dimensions must match
Fatal Python error: Aborted
Current thread 0x00007f4cae2e4740 (most recent call first):
 File ""/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52 in execute
 File ""/workspace/.local/lib/python3.6/site-packages/absl/app.py"", line 250 in _run_main
 File ""/workspace/.local/lib/python3.6/site-packages/absl/app.py"", line 299 in run
 File ""/workspace/.local/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40 in run
 File ""/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89 in main
 File ""/workspace/.local/bin//toco_from_protos"", line 10 in <module>
Aborted (core dumped)
```
"
