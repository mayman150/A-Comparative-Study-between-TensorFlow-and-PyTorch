Issue Number,Issue Title,Issue Body
3377,Moving data from CPU to GPU is slow ,"I have noticed that when moving MNIST data from the CPU to the GPU, there is a significant time lag when using TensorFlow in comparison to Theano. Specifically, we have noticed this problem in the context of feed_dict, which moves information from the CPU to the GPU when running minibatches. I am using python 2.7. Our current solution to this problem is to move all of the data directly to the GPU at the beginning of the program, which is of course not sustainable unless one has a significant amount of space on their GPU. 

When we time 25000 minibatches of size 100 each, TensorFlow is approximately four times as slow as Theano. I have attached both files, and the time difference is evident in the final output. 
### Environment info

Operating System: Ubuntu 14.04

CPU Information:

Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                12
On-line CPU(s) list:   0-11
Thread(s) per core:    2
Core(s) per socket:    6
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 63
Stepping:              2
CPU MHz:               1246.328
BogoMIPS:              6995.89
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              15360K
NUMA node0 CPU(s):     0-11

GPU: NVidia GeForce GTX TITAN X Graphics Card (12GB) 

Installed version of CUDA and cuDNN: 7.5.17
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

Relevant files (I apologize for the poor naming conventions):

1.[mnist_softmax.txt](https://github.com/tensorflow/tensorflow/files/370296/mnist_softmax.txt)
This file contains the relevant program that uses TensorFlow. 
1. [mnist.pkl.gz](https://github.com/tensorflow/tensorflow/files/370306/mnist.pkl.gz)
   This file contains the dataset for the TensorFlow file. 
2.  [mnist_softmax_theano.txt(https://github.com/tensorflow/tensorflow/files/370314/mnist_softmax_theano.txt)
   This file contains the relevant program that uses Theano.
3. [tf_data.pkl.gz](https://github.com/tensorflow/tensorflow/files/370310/tf_data.pkl.gz)
   This file contains the dataset necessary for the _Theano_ file.
"
3376,Element-wise tf.cond (like theano switch),"When I try the following code:

```
import tensorflow as tf
x = tf.placeholder('float32', shape=(None, None))
tf.cond(x >= 0.9, lambda: 1., lambda: x)
```

I get this error:

```
/Users/stas/.pyenv/versions/anaconda-2.4.0/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc in cond(pred, fn1, fn2, name)
   1314     if isinstance(pred, bool):
   1315       raise TypeError(""pred must not be a Python bool"")
-> 1316     p_2, p_1 = switch(pred, pred)
   1317     pivot_1 = array_ops.identity(p_1, name=""switch_t"")
   1318     pivot_2 = array_ops.identity(p_2, name=""switch_f"")

/Users/stas/.pyenv/versions/anaconda-2.4.0/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc in switch(data, pred, dtype, name)
    258     pred = ops.convert_to_tensor(pred, name=""pred"")
    259     if isinstance(data, ops.Tensor):
--> 260       return gen_control_flow_ops._switch(data, pred, name=name)
    261     else:
    262       if not isinstance(data, (ops.IndexedSlices, ops.SparseTensor)):

/Users/stas/.pyenv/versions/anaconda-2.4.0/lib/python2.7/site-packages/tensorflow/python/ops/gen_control_flow_ops.pyc in _switch(data, pred, name)
    368     output_true: A `Tensor`. Has the same type as `data`. If `pred` is true, data will be forwarded to this output.
    369   """"""
--> 370   result = _op_def_lib.apply_op(""Switch"", data=data, pred=pred, name=name)
    371   return _SwitchOutput._make(result)
    372

/Users/stas/.pyenv/versions/anaconda-2.4.0/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)
    702           op = g.create_op(op_type_name, inputs, output_types, name=scope,
    703                            input_types=input_types, attrs=attr_protos,
--> 704                            op_def=op_def)
    705           outputs = op.outputs
    706           return _Restructure(ops.convert_n_to_tensor(outputs),

/Users/stas/.pyenv/versions/anaconda-2.4.0/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)
   2260                     original_op=self._default_original_op, op_def=op_def)
   2261     if compute_shapes:
-> 2262       set_shapes_for_outputs(ret)
   2263     self._add_op(ret)
   2264     self._record_op_seen_by_control_dependencies(ret)

/Users/stas/.pyenv/versions/anaconda-2.4.0/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in set_shapes_for_outputs(op)
   1700       raise RuntimeError(""No shape function registered for standard op: %s""
   1701                          % op.type)
-> 1702   shapes = shape_func(op)
   1703   if shapes is None:
   1704     raise RuntimeError(

/Users/stas/.pyenv/versions/anaconda-2.4.0/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc in _SwitchShape(op)
   2345 def _SwitchShape(op):
   2346   input_shape = op.inputs[0].get_shape()
-> 2347   unused_pred_shape = op.inputs[1].get_shape().merge_with(tensor_shape.scalar())
   2348   return [input_shape] * 2

/Users/stas/.pyenv/versions/anaconda-2.4.0/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc in merge_with(self, other)
    568       except ValueError:
    569         raise ValueError(""Shapes %s and %s are not compatible"" %
--> 570                          (self, other))
    571
    572   def concatenate(self, other):

ValueError: Shapes (?, ?) and () are not compatible
```

As I understand _pred_ argument should be scalar, but what I need is element-wise condition.

Though theano switch is working as expected:

```
import theano.tensor as T
x = T.matrix()
T.switch(x >= 0.9, 1, x).eval({x: np.zeros((2,2), 'float32')})
```
"
3375,wrong use of sequence_loss_by_example in ptb_word_lm.py?,"Hi, I noticed ""sequence_loss_by_example"" with default of ""average_across_timesteps"":

def sequence_loss_by_example(logits, targets, weights,
                             average_across_timesteps=True,
                             softmax_loss_function=None, name=None):

but in pub_word_lm.py:

loss = tf.nn.seq2seq.sequence_loss_by_example(
        [logits],
        [tf.reshape(self._targets, [-1])],
        [tf.ones([batch_size \* num_steps])])
    self._cost = cost = tf.reduce_sum(loss) / batch_size

weights sum of batch_size*num_steps was used in ""sequence_loss_by_example"" to normalize the score, so there is no need to divide loss by batch_size again, right? cost was used for gradient later.
"
3374,Android app compilation fails: fatal error: gif_lib_private.h: No such file or directory,"Hi.

I'm unable to compile the Android app. Here is the error message:

```
ERROR: /home/arnaud/.cache/bazel/_bazel_arnaud/5d461d587a2aa81b3eca305842d75a99/external/gif_archive/BUILD:14:1: C++ compilation of rule '@gif_archive//:gif' failed: namespace-sandbox failed: error executing command /home/arnaud/.cache/bazel/_bazel_arnaud/5d461d587a2aa81b3eca305842d75a99/execroot/tensorflow/_bin/namespace-sandbox ... (remaining 46 argument(s) skipped).
external/gif_archive/giflib-5.1.4/lib/quantize.c:17:29: fatal error: gif_lib_private.h: No such file or directory
compilation terminated.
Target //tensorflow/examples/android:tensorflow_demo failed to build
Use --verbose_failures to see the command lines of failed build steps.
```
### Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: N/A
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from sources, provide the commit hash: https://github.com/tensorflow/tensorflow/commit/a3f61c1d5c76339e6c9655dac426bb3822659772
### Steps to reproduce
1. bazel build //tensorflow/examples/android:tensorflow_demo
   2.
   3.
### What have you tried?
1. install the giflib from Ubuntu, but I understand that bazel downloads during the build process
### Logs or other output that would be helpful

With max verbosity:

```
ERROR: /home/arnaud/.cache/bazel/_bazel_arnaud/5d461d587a2aa81b3eca305842d75a99/external/gif_archive/BUILD:14:1: C++ compilation of rule '@gif_archive//:gif' failed: namespace-sandbox failed: error executing command 
  (cd /home/arnaud/.cache/bazel/_bazel_arnaud/5d461d587a2aa81b3eca305842d75a99/execroot/tensorflow && \
  exec env - \
    PATH=/home/arnaud/Documents/Python/anaconda2/bin:/home/arnaud/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/arnaud/.rvm/bin:/home/arnaud/.rvm/bin:/home/arnaud/Documents/Android/android-studio/bin \
  /home/arnaud/.cache/bazel/_bazel_arnaud/5d461d587a2aa81b3eca305842d75a99/execroot/tensorflow/_bin/namespace-sandbox @/home/arnaud/.cache/bazel/_bazel_arnaud/5d461d587a2aa81b3eca305842d75a99/execroot/tensorflow/bazel-sandbox/aeac231e-239e-4110-a556-7f20a424a56a-197.params -- /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 -DHAVE_CONFIG_H -iquote external/gif_archive -iquote bazel-out/host/genfiles/external/gif_archive -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/gif_archive/giflib-5.1.4/lib -isystem bazel-out/host/genfiles/external/gif_archive/giflib-5.1.4/lib -isystem external/bazel_tools/tools/cpp/gcc3 -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -MD -MF bazel-out/host/bin/external/gif_archive/_objs/gif/external/gif_archive/giflib-5.1.4/lib/gif_err.d -c external/gif_archive/giflib-5.1.4/lib/gif_err.c -o bazel-out/host/bin/external/gif_archive/_objs/gif/external/gif_archive/giflib-5.1.4/lib/gif_err.o).
external/gif_archive/giflib-5.1.4/lib/gif_err.c:10:29: fatal error: gif_lib_private.h: No such file or directory
compilation terminated.
Target //tensorflow/examples/android:tensorflow_demo failed to build
```
"
3373,Cannot use more than 50% of available memory for a single variable,"I'm running Tensorflow 0.9.0 on a K40m (with 12GB of memory) with CUDA 7.5.0.

I'm attempting to preload data as described here: https://www.tensorflow.org/versions/r0.9/how_tos/reading_data/index.html#preloaded-data

Treating the data as a constant doesn't work because constants are limited to 2GB, and a minibatch approach does not make sense for my application.

Perhaps Tensorflow wants to allocate space for the placeholder on GPU, allocate space for the variable, copy from host to placeholder (on GPU), and then copy from placeholder to variable?

Here's a minimal failing test case. 

The following program:

``` python
import numpy as np
import tensorflow as tf

# allocate 6GB of zeros                                                                                                                                                                                                                                                                   
_data = np.zeros(1536 * (1 << 20), dtype=np.float32)

data_init = tf.placeholder(tf.float32, shape=_data.shape)
data = tf.Variable(data_init, trainable=False, collections=[])

with tf.Session() as sess:
    sess.run(data.initializer, feed_dict={data_init: _data})
```

produces the following output:

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: Tesla K40m
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:04:00.0
Total memory: 11.25GiB
Free memory: 11.12GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x16034f0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: Tesla K40m
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:42:00.0
Total memory: 11.25GiB
Free memory: 11.12GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40m, pci bus id: 0000:42:00.0)
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (256):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (512):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (1024):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (2048):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (4096):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (8192):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (16384):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (32768):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (65536):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (131072):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (262144):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (524288):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (1048576):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (2097152):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (4194304):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (8388608):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (16777216):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (33554432):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (67108864):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (134217728):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (268435456):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:656] Bin for 6.00GiB was 256.00MiB, Chunk State: 
I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0x4208f40000 of size 11344840448
I tensorflow/core/common_runtime/bfc_allocator.cc:689]      Summary of in-use Chunks by size: 
I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 11344840448 totalling 10.57GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 10.57GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats: 
Limit:                 11344840295
InUse:                 11344840448
MaxInUse:              11344840448
NumAllocs:                       1
MaxAllocSize:          11344840448

W tensorflow/core/common_runtime/bfc_allocator.cc:270] *********************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
W tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 6.00GiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:909] Resource exhausted: OOM when allocating tensor with shape[1610612736]
Traceback (most recent call last):
  File ""tf_fail.py"", line 11, in <module>
    sess.run(data.initializer, feed_dict={data_init: _data})
  File ""/software/rhel7/tensorflow-0.9.0/lib/tensorflow/python/client/session.py"", line 372, in run
    run_metadata_ptr)
  File ""/software/rhel7/tensorflow-0.9.0/lib/tensorflow/python/client/session.py"", line 636, in _run
    feed_dict_string, options, run_metadata)
  File ""/software/rhel7/tensorflow-0.9.0/lib/tensorflow/python/client/session.py"", line 708, in _do_run
    target_list, options, run_metadata)
  File ""/software/rhel7/tensorflow-0.9.0/lib/tensorflow/python/client/session.py"", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[1610612736]
         [[Node: Variable/Assign = Assign[T=DT_FLOAT, _class=[""loc:@Variable""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Variable, _recv_Placeholder_0/_2)]]
Caused by op u'Variable/Assign', defined at:
  File ""tf_fail.py"", line 8, in <module>
    data = tf.Variable(data_init, trainable=False, collections=[])
  File ""/software/rhel7/tensorflow-0.9.0/lib/tensorflow/python/ops/variables.py"", line 211, in __init__
    dtype=dtype)
  File ""/software/rhel7/tensorflow-0.9.0/lib/tensorflow/python/ops/variables.py"", line 309, in _init_from_args
    validate_shape=validate_shape).op
  File ""/software/rhel7/tensorflow-0.9.0/lib/tensorflow/python/ops/gen_state_ops.py"", line 45, in assign
    use_locking=use_locking, name=name)
  File ""/software/rhel7/tensorflow-0.9.0/lib/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/software/rhel7/tensorflow-0.9.0/lib/tensorflow/python/framework/ops.py"", line 2260, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/software/rhel7/tensorflow-0.9.0/lib/tensorflow/python/framework/ops.py"", line 1230, in __init__
    self._traceback = _extract_stack()
```
"
3372,Multi-GPU for LSTM,"I am experimenting with multi-gpu feedforwarding for LSTM models, by feeding two batches of sequences through a LSTM model. Here are two cases I am testing:

**Single-GPU**: simply pass the two batches sequentially on 1 GPU
**Two-GPU**: 2 parallel GPUs where each GPU takes care of one batch. **My code is in the attached file** (.txt --> .py).

However, instead of being 2X faster, the two-GPU case runs even slightly slower than the single-GPU case. It seems that even if I am initiating 2 GPU threads, the 2 batches are processed still sequentially, rather than in a parallel manner. 

Does anyone see anything wrong with my code, or give any insight on how to do debugging? Your help would be highly appreciated.

[lstm_multi_gpu.txt](https://github.com/tensorflow/tensorflow/files/370021/lstm_multi_gpu.txt)
"
3371,GridRNNCell -> RNN TypeError: unsupported operand type(s) for +: 'int',"I am unsure whether this is an issue in my code, or a bug in the contrib -> GridRNNCell.

Please see this SO post: http://stackoverflow.com/questions/38442025/tensorflow-grid-lstm-rnn-typeerror
"
3370,Tests for examples/learn,"A little while ago I caught a bug with the [resnet example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/skflow/resnet.py) that could have been caught by an automated test.

What do people think about bringing in some kind of automated tests to examples/skflow? What sort of tests should these be? I think the first step would be to simply run the code regularly. That would have caught the bug with the resnet example.
"
3369,AttributeError: 'module' object has no attribute 'constant',"Hi everyone, I tried to run Tensorflow 0.9.0 with Python 3.4 but I've received this error:

Python 3.4.5 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:47:57)
[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
Traceback (most recent call last):
 File ""<stdin>"", line 1, in <module>
AttributeError: 'module' object has no attribute 'constant'
### Steps to reproduce
1. Installed Anaconda 64-bit Python 3.5
2. Installed Tensorflow following these [instructions](https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#anaconda-installation)
### What have you tried?

Tried with Python 3.5 but no luck as well. Version 2.7 works fine but I need to use version 3.x as part of my coursework requirement.
### Environment info

Operating System: OSX 10.11.1
"
3368,download tensorboard vis export to image files,"Has there been discussion of exporting tensorboard visualizations as images (e.g. `.png`)? This would be helpful for rough drafts and work-in-progress type presentations.
"
3367,"model with batchnorm runs overfit in multigpu training,but is ok in single gpu. mutilgpu model is based on cifar10_multi_gpu_train.py","1. mutil gpu code based on cifar10_multi_gpu_train.py(https://github.com/tensorflow/tensorflow/blob/d42facc3cc9611f0c9722c81551a7404a0bd3f6b/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py)
2. two implementation of batch norm  is overfit in multigpu ,but is ok in sigle gpu.<br>
   one implementation based on inception batch_norm function: (https://github.com/tensorflow/models/blob/master/inception/inception/slim/ops.py)
   <br>
   the other implementation base on :
   https://codegists.com/snippet/python/batchnormpy_thouis_python
"
3366,"bus error (core dumped), when build with GPU support","I followed the installing from source tutorial, however in step

```
bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu
```

I encountered the following message:

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
[1]    5462 bus error (core dumped)  bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu
```

Any helps would be great
### Environment info

Operating System:  Ubuntu 16.04

Installed version of CUDA and cuDNN: CUDA 8.0, cuDNN 5

(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
/usr/local/cuda/lib64/libcudadevrt.a
/usr/local/cuda/lib64/libcudart.so
/usr/local/cuda/lib64/libcudart.so.8.0
/usr/local/cuda/lib64/libcudart.so.8.0.27
/usr/local/cuda/lib64/libcudart_static.a
/usr/local/cuda/lib64/libcudnn.so
/usr/local/cuda/lib64/libcudnn.so.5
/usr/local/cuda/lib64/libcudnn.so.5.0.5
```

If installed from sources, provide the commit hash:
e95f4e760c6b6713b6b686ebeff9a1586a5831dd
### Steps to reproduce
1. flowed the tutorial of installing Tensorflow from source 
### What have you tried?
1. goolged around, but with no help
"
3364,dnn_autoencoder_iris.py example error,"The example in skflow folder gives this error:

```
Traceback (most recent call last):
  File ""/home/rmasad/test/dnn_autoencoder_iris.py"", line 33, in <module>
    transformed = autoencoder.fit_transform(iris.data)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 403, in fit_transform
    return self.fit(x, y, monitor=None, logdir=None).transform(x)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 394, in transform
    x, axis=1, batch_size=None))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 237, in predict
    return self._predict(x, axis=axis, batch_size=batch_size)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 211, in _predict
    feed_fn=predict_data_feeder.get_feed_dict_fn())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 566, in _infer_model
    predictions = self._get_predict_ops(features)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 720, in _get_predict_ops
    self._targets_info)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/tensor_signature.py"", line 133, in create_placeholders_from_signatures
    return signatures.get_placeholder()
AttributeError: 'NoneType' object has no attribute 'get_placeholder'
```
"
3363,embeddings tutorial has dead link to googlecode svn,"The page:

https://www.tensorflow.org/versions/r0.9/tutorials/word2vec/index.html#evaluating-embeddings-analogical-reasoning

Has a dead (404) link to https://word2vec.googlecode.com/svn/trunk/questions-words.txt

I'd submit a PR if I knew where it _should_ point, but I don't :)
"
3362,Using a batchsize greater than 1 when using C++ API,"I have a Tensorflow model trained in Python and frozen with the freeze_graph script. I've succesfully loaded the model in C++ and made inference for a single image. However, whenever I attempt to feed the model a batch of images in C++ I get the error:

`tensorflow/core/framework/tensor.cc:433] Check failed: 1 == NumElements() (1 vs. 16)Must have a one element tensor`

If I print the frozen graph def, the input placeholder seems to have the correct shape for batch inference:

```
node {
  name: ""inputs""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 16
        }
        dim {
          size: 50
        }
        dim {
          size: 50
        }
        dim {
          size: 3
        }
      }
    }
  }
}
```

I'm using the `LoadGraph` function from the Tensorflow `label_image` C++ example, and I can't see anything in that function that should limit me to one image at a time.

Is this a limitation of the C++ API or am I doing something wrong?
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 7.5, 5.0.5

(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): 

```
-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 59909104 Jul 14 11:54 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 59909104 Jul 14 11:54 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 59909104 Jul 14 11:54 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 58775484 Jul 14 11:54 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from sources, provide the commit hash: 115f5185e56c3fc4c8ada87c56651434f6be585c (r0.9)
### Steps to reproduce
1. Create and train model in python.
2. Save model and checkpoint, and use `freeze_graph` to prepare for C++.
3. Load model in C++ and feed it an input tensor with a batch size larger than 1.
### What have you tried?
1. Not using a variable batch size.
2. Sanity checking the input placeholder shape of the frozen graph.
"
3361,Support streaming from hdf5,"It would be nice if streaming HDF5 (which is required in out-of-core situations) would be implemented in Tensorflow. 
"
3360,5:1: C++ compilation of rule '//tensorflow/stream_executor:stream_executor' failed:,"I am using the latest branch of tensorflow 
Error:/home/xxxxx/bazel/output/bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --verbose_failures
/home/xxxxx/bazel/output/bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --verbose_failures
/home/newSpace/projects2/tensorflow/tensorflow/stream_executor/BUILD:5:1: C++ compilation of rule '//tensorflow/stream_executor:stream_executor' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 117 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionFwdAlgo_t perftools::gputools::cuda::{anonymous}::ToConvForwardAlgo(perftools::gputools::dnn::AlgorithmType)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:266:10: error: 'CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING' was not declared in this scope
     case CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING:
          ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionBwdDataAlgo_t perftools::gputools::cuda::{anonymous}::ToConvBackwardDataAlgo(perftools::gputools::dnn::AlgorithmType)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:284:10: error: 'CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING' was not declared in this scope
     case CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING:
          ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::GetConvolveAlgorithms(std::vector<long long int>*)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:942:7: error: 'CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING' was not declared in this scope
       CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING,
       ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:947:4: error: no matching function for call to 'std::vector<long long int>::assign(<brace-enclosed initializer list>)'
   });
    ^
"
3359,Gradient computation fails concatenation in while_loop() body,"### Description

When I was trying to implement RNN with while_loop(), I tried to concatenate output to a matrix.
This worked in forward passes but not in applying gradients.

Also, I saw that there are discussions (#2237) about supporting Recursive NN. There's a workaround by transforming tree structures to a matrix. For example, if we have a binary tree with its node values and structure be like

```
10------20------40
 |       |------50
 | 
 |------30------60
         |------70
```

Then we could transform it to a value vector V

```
[70 60 50 40 30 20 10]
```

and a (strictly bottom-up) structure matrix M

```
[[0 1 4]  # V[0] and V[1] are V[4]'s children
 [2 3 5]
 [4 5 6]]
```

Then we could build our graph with while_loop() by iteratively index into previous output. Note that this is without any specific inputs; only knowing they'll be a vector and a matrix instead.
For more details, see
https://github.com/jacobvsdanniel/tf_rnn
inspired by
https://github.com/ofirnachum/tree_rnn
I also ran into problems of computing gradients for nested gather inside while_loop(), but managed to worked around before fixes come up to #418 and #206 .
### Tensorflow version

0.9.0
### Reproduction steps

``` python
def test_concat_loop():
    x = tf.constant([[1.,2.]])
    X = tf.get_variable(""X"", initializer=x)

    i = tf.constant(0)
    H = tf.zeros([0, 2])

    def condition(i, H):
        return i < 2

    def body(i, H):
        return i+1, tf.concat(0, [H, X])

    _, H = tf.while_loop(condition, body, [i, H])
    s = tf.reduce_sum(H)

    sess = tf.Session()
    sess.run(tf.initialize_all_variables())
    print sess.run(X)
    print sess.run(H)
    print sess.run(s)

    optimizer = tf.train.GradientDescentOptimizer(0.01)
    op = optimizer.minimize(s) #Raise
    print sess.run(op)
    print sess.run(X)
    return
```
### Workaround

``` python
def test_concat_loop_workaround():
    x = tf.constant([[1.,2.]])
    X = tf.get_variable(""X"", initializer=x)

    i = tf.constant(0)
    H = tf.zeros([5, 2])

    def condition(i, H):
        return i < 5

    def body(i, H):
        past = tf.zeros([i, 2])
        future = tf.zeros([4-i, 2])
        return i+1, H + tf.concat(0, [past, X, future])

    _, H = tf.while_loop(condition, body, [i, H])
    s = tf.reduce_sum(H)

    sess = tf.Session()
    sess.run(tf.initialize_all_variables())
    print sess.run(X)
    print sess.run(H)
    print sess.run(s)

    optimizer = tf.train.GradientDescentOptimizer(0.01)
    op = optimizer.minimize(s)
    print sess.run(op)
    print sess.run(X)
    return
```
### Error Logs

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 980
major: 5 minor: 2 memoryClockRate (GHz) 1.329
pciBusID 0000:01:00.0
Total memory: 4.00GiB
Free memory: 3.86GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
[[ 1.  2.]]
[[ 1.  2.]
 [ 1.  2.]]
6.0
Traceback (most recent call last):
  File ""issue-418.py"", line 244, in <module>
    main()
  File ""issue-418.py"", line 233, in main
    test_concat_loop()
  File ""issue-418.py"", line 53, in test_concat_loop
    op = optimizer.minimize(s)
  File ""/home/danniel/.local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 193, in minimize
    grad_loss=grad_loss)
  File ""/home/danniel/.local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 250, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/home/danniel/.local/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 494, in gradients
    in_grad.set_shape(t_in.get_shape())
  File ""/home/danniel/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 404, in set_shape
    self._shape = self._shape.merge_with(shape)
  File ""/home/danniel/.local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 570, in merge_with
    (self, other))
ValueError: Shapes (0, 2) and (1, 2) are not compatible
```
"
3358,IOS - No OpKernel was registered to support Op 'Add' with these attrs,"Hi everyone,

We are trying to load a very simple graph inside IOS 
Right now, we have this following error:

```
Running model failed: Invalid argument: No OpKernel was registered to support Op 'Add' with these attrs
     [[Node: deconv2d_1_1/add_3 = Add[T=DT_INT32](deconv2d_1_1/Squeeze_2, deconv2d_1_1/add_3/y)]]
```
"
3357,./tensorflow/core/platform/jpeg.h:31:2: error: #error Define the appropriate PLATFORM_<foo> macro for this platform,"I got a problem when building tensorflow from source in Raspberrypi platform. Anyone knows how to solve it ? Thanks 
pi@raspberrypi:~/tensorflow/tensorflow $ bazel build -c opt --local_resources 1024,1.0,1.0 --verbose_failures tensorflow/tools/pip_package:build_pip_package
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
INFO: Found 1 target...
ERROR: /home/pi/tensorflow/tensorflow/tensorflow/core/BUILD:807:1: C++ compilation of rule '//tensorflow/core:lib_internal' failed: gcc failed: error executing command 
  (cd /home/pi/.cache/bazel/_bazel_pi/72651946b65f096261d7acfbb49ff852/tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/games:/usr/games \
  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++0x' -DHAVE_CONFIG_H -iquote . -iquote bazel-out/host/genfiles -iquote external/protobuf -iquote bazel-out/host/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -iquote external/farmhash_archive -iquote bazel-out/host/genfiles/external/farmhash_archive -iquote external/jpeg_archive -iquote bazel-out/host/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/host/genfiles/external/png_archive -iquote external/gif_archive -iquote bazel-out/host/genfiles/external/gif_archive -iquote external/highwayhash -iquote bazel-out/host/genfiles/external/highwayhash -iquote external/re2 -iquote bazel-out/host/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/host/genfiles/external/eigen_archive -iquote external/zlib_archive -iquote bazel-out/host/genfiles/external/zlib_archive -isystem external/protobuf/src -isystem bazel-out/host/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem bazel-out/host/genfiles/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/host/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/host/genfiles/external/png_archive/libpng-1.2.53 -isystem external/gif_archive/giflib-5.1.4/lib -isystem bazel-out/host/genfiles/external/gif_archive/giflib-5.1.4/lib -isystem external/highwayhash -isystem bazel-out/host/genfiles/external/highwayhash -isystem external/re2 -isystem bazel-out/host/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/host/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-b4fa9622b809 -isystem bazel-out/host/genfiles/external/eigen_archive/eigen-eigen-b4fa9622b809 -isystem external/zlib_archive/zlib-1.2.8 -isystem bazel-out/host/genfiles/external/zlib_archive/zlib-1.2.8 -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -pthread -no-canonical-prefixes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/host/bin/tensorflow/core/_objs/lib_internal/tensorflow/core/lib/jpeg/jpeg_handle.o' -MD -MF bazel-out/host/bin/tensorflow/core/_objs/lib_internal/tensorflow/core/lib/jpeg/jpeg_handle.d -c tensorflow/core/lib/jpeg/jpeg_handle.cc -o bazel-out/host/bin/tensorflow/core/_objs/lib_internal/tensorflow/core/lib/jpeg/jpeg_handle.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from ./tensorflow/core/lib/jpeg/jpeg_handle.h:22:0,
                 from tensorflow/core/lib/jpeg/jpeg_handle.cc:22:
./tensorflow/core/platform/jpeg.h:31:2: error: #error Define the appropriate PLATFORM_<foo> macro for this platform
 #error Define the appropriate PLATFORM_<foo> macro for this platform
  ^
In file included from tensorflow/core/lib/jpeg/jpeg_handle.cc:22:0:
./tensorflow/core/lib/jpeg/jpeg_handle.h:29:17: error: variable or field 'CatchError' declared void
 void CatchError(j_common_ptr cinfo);
                 ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:29:17: error: 'j_common_ptr' was not declared in this scope
./tensorflow/core/lib/jpeg/jpeg_handle.h:32:31: error: field 'pub' has incomplete type 'tensorflow::jpeg::jpeg_destination_mgr'
   struct jpeg_destination_mgr pub;
                               ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:33:3: error: 'JOCTET' does not name a type
   JOCTET _buffer;
   ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:40:26: error: field 'pub' has incomplete type 'tensorflow::jpeg::jpeg_source_mgr'
   struct jpeg_source_mgr pub;
                          ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:46:13: error: variable or field 'SetSrc' declared void
 void SetSrc(j_decompress_ptr cinfo, const void *data,
             ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:46:13: error: 'j_decompress_ptr' was not declared in this scope
./tensorflow/core/lib/jpeg/jpeg_handle.h:46:37: error: expected primary-expression before 'const'
 void SetSrc(j_decompress_ptr cinfo, const void *data,
                                     ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:47:13: error: expected primary-expression before 'unsigned'
             unsigned long int datasize, bool try_recover_truncated_jpeg);
             ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:47:41: error: expected primary-expression before 'bool'
             unsigned long int datasize, bool try_recover_truncated_jpeg);
                                         ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:51:14: error: variable or field 'SetDest' declared void
 void SetDest(j_compress_ptr cinfo, void *buffer, int bufsize);
              ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:51:14: error: 'j_compress_ptr' was not declared in this scope
./tensorflow/core/lib/jpeg/jpeg_handle.h:51:36: error: expected primary-expression before 'void'
 void SetDest(j_compress_ptr cinfo, void *buffer, int bufsize);
                                    ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:51:50: error: expected primary-expression before 'int'
 void SetDest(j_compress_ptr cinfo, void *buffer, int bufsize);
                                                  ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:54:14: error: variable or field 'SetDest' declared void
 void SetDest(j_compress_ptr cinfo, void *buffer, int bufsize,
              ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:54:14: error: 'j_compress_ptr' was not declared in this scope
./tensorflow/core/lib/jpeg/jpeg_handle.h:54:36: error: expected primary-expression before 'void'
 void SetDest(j_compress_ptr cinfo, void *buffer, int bufsize,
                                    ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:54:50: error: expected primary-expression before 'int'
 void SetDest(j_compress_ptr cinfo, void *buffer, int bufsize,
                                                  ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:55:21: error: expected primary-expression before '_' token
              string *destination);
                     ^
./tensorflow/core/lib/jpeg/jpeg_handle.h:55:22: error: 'destination' was not declared in this scope
              string *destination);
                      ^
tensorflow/core/lib/jpeg/jpeg_handle.cc:32:17: error: variable or field 'CatchError' declared void
 void CatchError(j_common_ptr cinfo) {
                 ^
tensorflow/core/lib/jpeg/jpeg_handle.cc:32:17: error: 'j_common_ptr' was not declared in this scope
tensorflow/core/lib/jpeg/jpeg_handle.cc:45:25: error: variable or field 'MemInitDestination' declared void
 void MemInitDestination(j_compress_ptr cinfo) {
                         ^
tensorflow/core/lib/jpeg/jpeg_handle.cc:45:25: error: 'j_compress_ptr' was not declared in this scope
tensorflow/core/lib/jpeg/jpeg_handle.cc:177:1: error: expected '}' at end of input
 }  // namespace tensorflow
 ^
tensorflow/core/lib/jpeg/jpeg_handle.cc:177:1: error: expected '}' at end of input
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 10.892s, Critical Path: 7.94s
"
3356,can't construct gradient of gradient,"In general, I've had no trouble constructing the gradient of a gradient in Tensorflow, but I hit on a weird edge case involving complex numbers where I couldn't.  Below, I show a case where the double gradient works, and one that is minimally different where it doesn't.

Here's where double gradient works:

``` python
x = tf.Variable(tf.zeros([10]))
xx = x * x
g = tf.gradients(tf.reduce_sum(xx), x)
h = tf.gradients(tf.reduce_sum(g), x)
```

As expected, evaluating `h` produces:

```
>>> sess.run(h, feed_dict={x:10*[1.]})
[array([ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.], dtype=float32)]
```

Here's where double gradient doesn't work:

``` python
x = tf.Variable(tf.zeros([10]))
xx = tf.real(tf.complex(x*x, tf.zeros([10])))
g = tf.gradients(tf.reduce_sum(xx), x)
h = tf.gradients(tf.reduce_sum(g), x)
```

Running the last line gives:

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 494, in gradients
    in_grad.set_shape(t_in.get_shape())
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 404, in set_shape
    self._shape = self._shape.merge_with(shape)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 570, in merge_with
    (self, other))
ValueError: Shapes (10,) and () are not compatible
```

I'm running version 0.9.0, CPU only, in OS X.
"
3355,feature request - tf.stack,"Given a tensor `x[i,j,k]` in a graph, I often want to construct tensors like `X[i,j,k,p,q] = x[i,j,k]`. 

You can get this done using `tf.pack`, but it can get kind of messy if you are adding a bunch of dimensions.

It would be nice if there was a function `tf.stack(x,list)` which added dimensions to a tensor as above. The name is motivated by the following situation. If x is a matrix, then tf.stack(x,[n]) would create a 3-tensor by stacking the matrix up n times. I imagine that tf.stack would fit nicely under tf.tile in the documentation

It is possible that there is already a better way to do this than using tf.pack, but if so, it is not in the docs. 
"
3354,Problem trying to install iOS example,"I get this problem when running `compile_ios_tensorflow.sh`

I tried cloning TensorFlow again, download dependencies and `compile_ios_protobuf.sh` but the problem persists.

```
Undefined symbols for architecture armv7:
  ""tensorflow::OptimizationPassRegistry::Global()"", referenced from:
      tensorflow::SimpleGraphExecutionState::InitBaseGraph(tensorflow::BuildGraphOptions const&) in libtensorflow-core-armv7.a(simple_graph_execution_state.o)
      tensorflow::SimpleGraphExecutionState::BuildGraph(tensorflow::BuildGraphOptions const&, std::__1::unique_ptr<tensorflow::SimpleClientGraph, std::__1::default_delete<tensorflow::SimpleClientGraph> >*) in libtensorflow-core-armv7.a(simple_graph_execution_state.o)
  ""tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)"", referenced from:
      tensorflow::SimpleGraphExecutionState::InitBaseGraph(tensorflow::BuildGraphOptions const&) in libtensorflow-core-armv7.a(simple_graph_execution_state.o)
      tensorflow::SimpleGraphExecutionState::BuildGraph(tensorflow::BuildGraphOptions const&, std::__1::unique_ptr<tensorflow::SimpleClientGraph, std::__1::default_delete<tensorflow::SimpleClientGraph> >*) in libtensorflow-core-armv7.a(simple_graph_execution_state.o)
ld: symbol(s) not found for architecture armv7
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *** [/Users/Kevin/Developer/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark] Error 1
+ '[' 2 -ne 0 ']'
+ echo 'armv7 compilation failed.'
armv7 compilation failed.
+ exit 1

```
"
3352,iOS Example with fine-tuned inception network memory error & quantization attempt,"For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: iOS
### Steps to reproduce
1. Follow the contrib/makefile/README to install the tensorflow iOS core lib
2. Create my own model using flower's example and shards (https://github.com/tensorflow/models/tree/master/inception)
3. Create inference graph by removing shard preprocessing ops and replacing them with:
   input_ = tf.placeholder(tf.float32, shape=(1, FLAGS.image_size, FLAGS.image_size, 3),
            name='input')
   logits, _ = inception_model.inference(input_, FLAGS.num_classes + 1)
   softmax = tf.nn.softmax(logits, name='softmax')
   
   And loading a saved checkpoint, restoring it, then writing out a graph def.
4. Apply tensorflow/python/tools/freeze_graph on  graph def
5. Apply tensorflow/python/tools/strip_unused on graph def
6. Copy graph def and labels file into camera example
7. Change objective-C image preprocessing to 299x299, with std & image_mean of 128.
### What have you tried?
1. Running the 'simple' example on the grace hopper image. This works fine
2. Running the 'camera' example. This crashes after 3 seconds of the app being open with the output below:
### Logs or other output that would be helpful

/tensorflow/tensorflow/contrib/ios_examples/skinscan/tensorflow_utils.mm:130] Session created.
/tensorflow/tensorflow/contrib/ios_examples/skinscan/tensorflow_utils.mm:133] Graph created.
tensorflow/tensorflow/contrib/ios_examples/skinscan/CameraExampleViewController.mm:306] Running model failed:Invalid argument: Session was not created with a graph before Run()!
2016-07-17 15:47:44.317 CameraExample[1109:39568] Received memory warning.

It appears that this issue is similar to #2927 . I tried quantizing the graph (tensorflow/contrib/quantization/tools/quantize_graph with --mode=weights), but then ran into a 'quantize ops dont exist' type of error on iOS. It seems those ops need to be built by modifying tensorflow/contrib/makefile/tf_cc_files.txt and tensorflow/contrib/makefile/proto_text_pb_h_files.txt. I have attempting including into both every non-test file and header located in tensorflow/contrib/quantization/kernels, but am running into build-rule errors from the makefile. Unfortunately, I have little knowledge of adjusting makefiles for this type of application.
"
3350,No GPU implementation of determinant and no gradient of determinant?,"We do not have GPU implementation of determinant calculation and its gradient is not available? It is really nice to have them.

Thanks!
"
3349,-mavx2 or -mavx prevents eigen from compiling,"I'm compiling the master branch of TensorFlow as follows:

> bazel build -c opt --copt=-mavx2 --config=cuda //tensorflow/tools/pip_package:build_pip_package

and receive the error:

> ERROR: /tmp/tensorflow/tensorflow/contrib/ffmpeg/BUILD:22:1: C++ compilation of rule '//tensorflow/contrib/ffmpeg:decode_audio_op_cc' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 57 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
> In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:36:0,
>                  from ./tensorflow/core/framework/types.h:27,
>                  from ./tensorflow/core/framework/type_traits.h:22,
>                  from ./tensorflow/core/framework/allocator.h:25,
>                  from ./tensorflow/core/framework/op_kernel.h:22,
>                  from tensorflow/contrib/ffmpeg/decode_audio_op.cc:23:
> ./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:347:8: error: 'scalar_multiple2_op' is not a class template
>  struct scalar_multiple2_op<QInt32, double> {
>         ^
> ./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:347:44: error: explicit specialization of non-template 'Eigen::internal::scalar_multiple2_op'
>  struct scalar_multiple2_op<QInt32, double> {
>                                             ^
> ./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:369:23: error: 'Eigen::internal::scalar_multiple2_op' is not a template
>  struct functor_traits<scalar_multiple2_op<QInt32, double>> {
>                        ^
> In file included from ./tensorflow/core/framework/op_kernel.h:22:0,
>                  from tensorflow/contrib/ffmpeg/decode_audio_op.cc:23:
> ./tensorflow/core/framework/allocator.h: In member function 'virtual std::size_t tensorflow::Allocator::RequestedSize(void_)':
> ./tensorflow/core/framework/allocator.h:155:3: warning: control reaches end of non-void function [-Wreturn-type]
>    }
>    ^
> In file included from ./tensorflow/core/framework/op_kernel.h:25:0,
>                  from tensorflow/contrib/ffmpeg/decode_audio_op.cc:23:
> ./tensorflow/core/framework/device_base.h: In member function 'virtual tensorflow::Allocator_ tensorflow::DeviceBase::GetAllocator(tensorflow::AllocatorAttributes)':
> ./tensorflow/core/framework/device_base.h:151:3: warning: control reaches end of non-void function [-Wreturn-type]
>    }
>    ^
> ./tensorflow/core/framework/device_base.h: In member function 'virtual const tensorflow::DeviceAttributes& tensorflow::DeviceBase::attributes() const':
> ./tensorflow/core/framework/device_base.h:182:3: warning: control reaches end of non-void function [-Wreturn-type]
>    }
>    ^

/proc/cpuinfo shows my CPU has avx2 support:

> processor       : 31
> model name      : Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz
> flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm ida arat epb pln pts dtherm tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 **avx2** smep bmi2 erms invpcid cqm xsaveopt cqm_llc 
"
3348,tf.gradients() gives the conjugate of what is expected,"`tf.gradients()`, when used on complex numbers, erroneously flips the sign of the imaginary part:

```
>>> x = tf.Variable(0. + 0.j)
>>> sess.run(tf.gradients(x*x, x), feed_dict={x:0.1j})
[-0.20000000000000001j]
>>> sess.run(tf.gradients(tf.exp(x), x), feed_dict={x:0.1j})
[(0.99500416527802571-0.099833416646828155j)]
```

I expect `0.2j` and `0.99500416527802571+0.099833416646828155j`.

I'm running version 0.9.0, CPU only, on OS X.
"
3347,Cuda/Cudnn file name change break ./configure & Bazel build,"- Ubuntu 16.04
- Gtx 1080
- Building master (614d4c19fb22df501ba16a3f580f4e3ac1a9df1a)
- Cudnn 5 (Nvidia site download)
- Cuda 8

I've got the above mostly installed, except for Tensorflow itself.

But anyways, Nvidia seems to have changed the file names on this stuff, and it is not what Tensorflow's configure and Bazel are expecting.

Actual error message below:

 `bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer`

```
ERROR: /home/john/.cache/bazel/_bazel_john/79381a0230f40e8d23e37c3a71bb0cd2/execroot/tensorflow/third_party/gpus/cuda/lib64/libcublas.so.8 cannot be found
##############################################################################
Cuda 8 toolkit is missing.
1. Download and install the CUDA 8 toolkit and CUDNN 5 library;
```

But `ls /usr/llocal/cuda-8.0` looks like: 

`
libcublas.so
libcublas.so.8.0
libcublas.so.8.0.27
`

This is the fourth time there has been a file name change using this Tensorflow commit or perhaps Cuda/Cudnn.

I wouldn't mention this if it was one file change but it's at least 4.  May throw a bunch of beginners off.  Or perhaps I'm the beginner doing something wrong.

Just something I ran into and seems like a Nvidia file naming change.
"
3346,Casting from real to complex lacks gradient,"The operation of casting from `float32` to `complex64` lacks a gradient:

```
>>> x = tf.Variable(tf.zeros([10]))
>>> tf.gradients(tf.cast(x, dtype=tf.complex64), x)
[None]
```

Surely this is not intentional?

(FWIW, I'm on Tensorflow 0.9.0, running on the CPU on OS X.)
"
3345,GPU implementation for RangeSampler and related samplers,"The implementation for `RangeSampler` currently works only for the CPU, even though the sampling is done using `SimplePhilox` in most cases (which has GPU support). This issue is for tracking all changes to enable GPU support for the samplers.

This issue came into picture while digging for #1140, and affects it directly. Once GPU implementations are written for the samplers related to `RangeSampler`, float64 can easily be enabled for the `*Sampler` ops mentioned [here](https://github.com/tensorflow/tensorflow/issues/1140#issuecomment-227012645).  Some more context can be found in [this comment](https://github.com/tensorflow/tensorflow/issues/1140#issuecomment-232891827).
"
3344,Tensorboard is failing to parse tfevents,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
Ubuntu 16.04
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
No Cuda
If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

'0.9.0'
If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.I've followed the instructions on README and verified that tensorboard is pointing to the right directory and the log files are there
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
As requested, the log file is supplied below
[log.zip](https://github.com/tensorflow/tensorflow/files/367328/log.zip)
"
3343,Can I export a gpu-trained model to a cpu-only machine for serving/evaluation?,"I trained a model on a GPU machine.
When l load such model on a cpu-only machine, I get the error below.
![](https://raw.githubusercontent.com/3rduncle/DeepNLP/master/error.png)

Thank you for any suggestions!
"
3342,"segfault after building from source with cuda 8, cudnn 4.0.7","### Environment info

Operating System: Ubuntu 16.04 LTS (Linux thinkpad 4.4.0-31-generic #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux)

Installed version of CUDA and cuDNN: CUDA 8.0, cuDNN 4.0.7

``` bash
$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   560184 Jul 16 08:43 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Jul 16 08:43 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Jul 16 08:43 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 Jul 16 08:43 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 Jul 16 08:43 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 root root       17 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxr-xr-x 1 root root 61453024 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from sources, provide the commit hash: e8aa19bd4fbcbbaeacb1f4f753e6c4f15dee1d9c

``` bash
~/GitHub/tensorflow $ git rev-parse HEAD
e8aa19bd4fbcbbaeacb1f4f753e6c4f15dee1d9c
```

Graphics card: GeForce 940MX

Driver version:  361.42
### Steps to reproduce
1. Install from sources with GPU support
2. `import tensorflow`

``` python
>>> import tensorflow
[1]    17461 segmentation fault (core dumped)  python
```

I'm not sure if it is the same / related to #2034. So I tried:

``` python
>>> import numpy
>>> import tensorflow
*** Error in `python': malloc(): memory corruption: 0x000000000202a2d0 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x77725)[0x7f1cb4ae4725]
/lib/x86_64-linux-gnu/libc.so.6(+0x819be)[0x7f1cb4aee9be]
/lib/x86_64-linux-gnu/libc.so.6(__libc_malloc+0x54)[0x7f1cb4af05a4]
/usr/lib/x86_64-linux-gnu/libstdc++.so.6(_Znwm+0x18)[0x7f1c962b5e78]
/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1cd777a)[0x7f1c984e277a]
/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1cd78dc)[0x7f1c984e28dc]
/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1cd7a45)[0x7f1c984e2a45]
/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1cd997c)[0x7f1c984e497c]
/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1ceca98)[0x7f1c984f7a98]
/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1ced92f)[0x7f1c984f892f]
/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x77bee9)[0x7f1c96f86ee9]
/lib64/ld-linux-x86-64.so.2(+0x104ea)[0x7f1cb50634ea]
/lib64/ld-linux-x86-64.so.2(+0x105fb)[0x7f1cb50635fb]
/lib64/ld-linux-x86-64.so.2(+0x15712)[0x7f1cb5068712]
/lib64/ld-linux-x86-64.so.2(+0x10394)[0x7f1cb5063394]
/lib64/ld-linux-x86-64.so.2(+0x14bd9)[0x7f1cb5067bd9]
/lib/x86_64-linux-gnu/libdl.so.2(+0xf09)[0x7f1cb4869f09]
/lib64/ld-linux-x86-64.so.2(+0x10394)[0x7f1cb5063394]
/lib/x86_64-linux-gnu/libdl.so.2(+0x1571)[0x7f1cb486a571]
/lib/x86_64-linux-gnu/libdl.so.2(dlopen+0x31)[0x7f1cb4869fa1]
python(_PyImport_GetDynLoadFunc+0xf3)[0x522aa3]
python(_PyImport_LoadDynamicModule+0x4f)[0x52264f]
python[0x5c6815]
python(PyEval_EvalFrameEx+0x68a)[0x4c41da]
python(PyEval_EvalFrameEx+0x5dff)[0x4c994f]
python(PyEval_EvalCodeEx+0x255)[0x4c22e5]
python(PyEval_EvalCode+0x19)[0x4c2089]
python(PyImport_ExecCodeModuleEx+0xcb)[0x4c019b]
python[0x4bd24e]
python[0x4afd2d]
python(PyImport_ImportModuleLevel+0xd59)[0x4af969]
python[0x4b10a8]
python(PyObject_Call+0x43)[0x4b0de3]
python(PyEval_CallObjectWithKeywords+0x30)[0x4ce140]
python(PyEval_EvalFrameEx+0x31b1)[0x4c6d01]
python(PyEval_EvalCodeEx+0x255)[0x4c22e5]
python(PyEval_EvalCode+0x19)[0x4c2089]
python(PyImport_ExecCodeModuleEx+0xcb)[0x4c019b]
python[0x4bd24e]
python[0x4be547]
python[0x4afd2d]
python(PyImport_ImportModuleLevel+0x8bd)[0x4af4cd]
python[0x4b10a8]
python(PyObject_Call+0x43)[0x4b0de3]
python(PyEval_CallObjectWithKeywords+0x30)[0x4ce140]
python(PyEval_EvalFrameEx+0x31b1)[0x4c6d01]
python(PyEval_EvalCodeEx+0x255)[0x4c22e5]
python(PyEval_EvalCode+0x19)[0x4c2089]
python(PyImport_ExecCodeModuleEx+0xcb)[0x4c019b]
python[0x4bd24e]
python[0x4be547]
python(PyImport_ImportModuleLevel+0x785)[0x4af395]
python[0x4b10a8]
python(PyObject_Call+0x43)[0x4b0de3]
python(PyEval_CallObjectWithKeywords+0x30)[0x4ce140]
python(PyEval_EvalFrameEx+0x31b1)[0x4c6d01]
python(PyEval_EvalCodeEx+0x255)[0x4c22e5]
python(PyEval_EvalCode+0x19)[0x4c2089]
python[0x4f1e6f]
python(PyRun_InteractiveOneFlags+0x199)[0x44c7b0]
python(PyRun_InteractiveLoopFlags+0xc6)[0x44c575]
python[0x42e91d]
python(Py_Main+0x68a)[0x49e36a]
======= Memory map: ========
00400000-006e9000 r-xp 00000000 08:01 21502507                           /usr/bin/python2.7
008e9000-008eb000 r--p 002e9000 08:01 21502507                           /usr/bin/python2.7
008eb000-00962000 rw-p 002eb000 08:01 21502507                           /usr/bin/python2.7
00962000-00985000 rw-p 00000000 00:00 0 
017a3000-02035000 rw-p 00000000 00:00 0                                  [heap]
7f1c90000000-7f1c90021000 rw-p 00000000 00:00 0 
7f1c90021000-7f1c94000000 ---p 00000000 00:00 0 
7f1c96020000-7f1c96027000 r-xp 00000000 08:01 1708545                    /lib/x86_64-linux-gnu/librt-2.23.so
7f1c96027000-7f1c96226000 ---p 00007000 08:01 1708545                    /lib/x86_64-linux-gnu/librt-2.23.so
7f1c96226000-7f1c96227000 r--p 00006000 08:01 1708545                    /lib/x86_64-linux-gnu/librt-2.23.so
7f1c96227000-7f1c96228000 rw-p 00007000 08:01 1708545                    /lib/x86_64-linux-gnu/librt-2.23.so
7f1c96228000-7f1c9639a000 r-xp 00000000 08:01 21503122                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f1c9639a000-7f1c9659a000 ---p 00172000 08:01 21503122                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f1c9659a000-7f1c965a4000 r--p 00172000 08:01 21503122                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f1c965a4000-7f1c965a6000 rw-p 0017c000 08:01 21503122                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f1c965a6000-7f1c965aa000 rw-p 00000000 00:00 0 
7f1c965aa000-7f1c96607000 r-xp 00000000 08:01 26751834                   /usr/local/cuda-8.0/lib64/libcudart.so.8.0.27
7f1c96607000-7f1c96807000 ---p 0005d000 08:01 26751834                   /usr/local/cuda-8.0/lib64/libcudart.so.8.0.27
7f1c96807000-7f1c9680a000 rw-p 0005d000 08:01 26751834                   /usr/local/cuda-8.0/lib64/libcudart.so.8.0.27
7f1c9680a000-7f1c9680b000 rw-p 00000000 00:00 0 
7f1c9680b000-7f1c9bba5000 r-xp 00000000 08:01 23869804                   /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so
7f1c9bba5000-7f1c9bda5000 ---p 0539a000 08:01 23869804                   /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so
7f1c9bda5000-7f1c9be4b000 r--p 0539a000 08:01 23869804                   /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so
7f1c9be4b000-7f1c9be4f000 rw-p 05440000 08:01 23869804                   /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so
7f1c9be4f000-7f1c9c714000 rw-p 00000000 00:00 0 
7f1c9c74c000-7f1c9c78c000 rw-p 00000000 00:00 0 
7f1c9c78c000-7f1c9c802000 r-xp 00000000 08:01 21760526                   /usr/lib/python2.7/dist-packages/numpy/random/mtrand.x86_64-linux-gnu.so
7f1c9c802000-7f1c9ca02000 ---p 00076000 08:01 21760526                   /usr/lib/python2.7/dist-packages/numpy/random/mtrand.x86_64-linux-gnu.so
7f1c9ca02000-7f1c9ca03000 r--p 00076000 08:01 21760526                   /usr/lib/python2.7/dist-packages/numpy/random/mtrand.x86_64-linux-gnu.so
7f1c9ca03000-7f1c9ca3e000 rw-p 00077000 08:01 21760526                   /usr/lib/python2.7/dist-packages/numpy/random/mtrand.x86_64-linux-gnu.so
7f1c9ca3e000-7f1c9ca7f000 rw-p 00000000 00:00 0 
7f1c9ca7f000-7f1c9ca88000 r-xp 00000000 08:01 21760740                   /usr/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.x86_64-linux-gnu.so
7f1c9ca88000-7f1c9cc87000 ---p 00009000 08:01 21760740                   /usr/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.x86_64-linux-gnu.so
7f1c9cc87000-7f1c9cc88000 r--p 00008000 08:01 21760740                   /usr/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.x86_64-linux-gnu.so
7f1c9cc88000-7f1c9cc89000 rw-p 00009000 08:01 21760740                   /usr/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.x86_64-linux-gnu.so
7f1c9cc89000-7f1c9ccc9000 rw-p 00000000 00:00 0 
7f1c9ccc9000-7f1c9ccca000 r-xp 00000000 08:01 21637140                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f1c9ccca000-7f1c9cec9000 ---p 00001000 08:01 21637140                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f1c9cec9000-7f1c9ceca000 r--p 00000000 08:01 21637140                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f1c9ceca000-7f1c9cecb000 rw-p 00001000 08:01 21637140                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f1c9cecb000-7f1c9ceeb000 r-xp 00000000 08:01 21634770                   /usr/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.x86_64-linux-gnu.so
7f1c9ceeb000-7f1c9d0ea000 ---p 00020000 08:01 21634770                   /usr/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.x86_64-linux-gnu.so
7f1c9d0ea000-7f1c9d0eb000 r--p 0001f000 08:01 21634770                   /usr/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.x86_64-linux-gnu.so
7f1c9d0eb000-7f1c9d0ec000 rw-p 00020000 08:01 21634770                   /usr/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.x86_64-linux-gnu.so
7f1c9d0ec000-7f1c9d6cc000 r-xp 00000000 08:01 21508094                   /usr/lib/openblas-base/liblapack.so.3
7f1c9d6cc000-7f1c9d8cc000 ---p 005e0000 08:01 21508094                   /usr/lib/openblas-base/liblapack.so.3
7f1c9d8cc000-7f1c9d8cd000 r--p 005e0000 08:01 21508094                   /usr/lib/openblas-base/liblapack.so.3
7f1c9d8cd000-7f1c9d8cf000 rw-p 005e1000 08:01 21508094                   /usr/lib/openblas-base/liblapack.so.3
7f1c9d8cf000-7f1c9d8d2000 r-xp 00000000 08:01 21634771                   /usr/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.x86_64-linux-gnu.so
7f1c9d8d2000-7f1c9dad1000 ---p 00003000 08:01 21634771                   /usr/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.x86_64-linux-gnu.so
7f1c9dad1000-7f1c9dad2000 r--p 00002000 08:01 21634771                   /usr/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.x86_64-linux-gnu.so
7f1c9dad2000-7f1c9dad3000 rw-p 00003000 08:01 21634771                   /usr/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.x86_64-linux-gnu.so
7f1c9dad3000-7f1c9db53000 rw-p 00000000 00:00 0 
7f1c9db53000-7f1c9dd82000 r-xp 00000000 08:01 1708703                    /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f1c9dd82000-7f1c9df81000 ---p 0022f000 08:01 1708703                    /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f1c9df81000-7f1c9df9d000 r--p 0022e000 08:01 1708703                    /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f1c9df9d000-7f1c9dfaa000 rw-p 0024a000 08:01 1708703                    /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f1c9dfaa000-7f1c9dfae000 rw-p 00000000 00:00 0 
7f1c9dfae000-7f1c9dfb4000 r-xp 00000000 08:01 21636955                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f1c9dfb4000-7f1c9e1b3000 ---p 00006000 08:01 21636955                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f1c9e1b3000-7f1c9e1b4000 r--p 00005000 08:01 21636955                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f1c9e1b4000-7f1c9e1b5000 rw-p 00006000 08:01 21636955                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f1c9e1b5000-7f1c9e3b6000 rw-p 00000000 00:00 0 
7f1c9e3b6000-7f1c9e3bd000 r-xp 00000000 08:01 21503706                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f1c9e3bd000-7f1c9e5bc000 ---p 00007000 08:01 21503706                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f1c9e5bc000-7f1c9e5bd000 r--p 00006000 08:01 21503706                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f1c9e5bd000-7f1c9e5be000 rw-p 00007000 08:01 21503706                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f1c9e5be000-7f1c9e5dc000 r-xp 00000000 08:01 21637148                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f1c9e5dc000-7f1c9e7db000 ---p 0001e000 08:01 21637148                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f1c9e7db000-7f1c9e7dc000 r--p 0001d000 08:01 21637148                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f1c9e7dc000-7f1c9e7e0000 rw-p 0001e000 08:01 21637148                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f1c9e7e0000-7f1c9e820000 rw-p 00000000 00:00 0 
7f1c9e820000-7f1c9e8d4000 r-xp 00000000 08:01 21760674                   /usr/lib/python2.7/dist-packages/numpy/core/umath.x86_64-linux-gnu.so
7f1c9e8d4000-7f1c9ead4000 ---p 000b4000 08:01 21760674                   /usr/lib/python2.7/dist-packages/numpy/core/umath.x86_64-linux-gnu.so
7f1c9ead4000-7f1c9ead5000 r--p 000b4000 08:01 21760674                   /usr/lib/python2.7/dist-packages/numpy/core/umath.x86_64-linux-gnu.so
7f1c9ead5000-7f1c9eadb000 rw-p 000b5000 08:01 21760674                   /usr/lib/python2.7/dist-packages/numpy/core/umath.x86_64-linux-gnu.so
7f1c9eadb000-7f1c9eadd000 rw-p 00000000 00:00 0 
7f1c9eadd000-7f1caaadd000 rw-p 00000000 00:00 0 
7f1caaadd000-7f1caaade000 ---p 00000000 00:00 0 
7f1caaade000-7f1cab2de000 rw-p 00000000 00:00 0 
7f1cab2de000-7f1cad2de000 rw-p 00000000 00:00 0 
7f1cad2de000-7f1cad2df000 ---p 00000000 00:00 0 
7f1cad2df000-7f1cadadf000 rw-p 00000000 00:00 0 
7f1cadadf000-7f1cadae0000 ---p 00000000 00:00 0 
7f1cadae0000-7f1cae2e0000 rw-p 00000000 00:00 0 
7f1cae2e0000-7f1cae2e1000 ---p 00000000 00:00 0 
7f1cae2e1000-7f1caeae1000 rw-p 00000000 00:00 0 
7f1caeae1000-7f1caeae2000 ---p 00000000 00:00 0 
7f1caeae2000-7f1caf2e2000 rw-p 00000000 00:00 0 
7f1caf2e2000-7f1caf2e3000 ---p 00000000 00:00 0 
7f1caf2e3000-7f1cafae3000 rw-p 00000000 00:00 0 
7f1cafae3000-7f1cafae4000 ---p 00000000 00:00 0 
7f1cafae4000-7f1cb02e4000 rw-p 00000000 00:00 0 
7f1cb02e4000-7f1cb02fa000 r-xp 00000000 08:01 1708431                    /lib/x86_64-linux-gnu/libgcc_s.so.1
7f1cb02fa000-7f1cb04f9000 ---p 00016000 08:01 1708431                    /lib/x86_64-linux-gnu/libgcc_s.so.1
7f1cb04f9000-7f1cb04fa000 rw-p 00015000 08:01 1708431                    /lib/x86_64-linux-gnu/libgcc_s.so.1
7f1cb04fa000-7f1cb0538000 r-xp 00000000 08:01 21503118                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f1cb0538000-7f1cb0737000 ---p 0003e000 08:01 21503118                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f1cb0737000-7f1cb0738000 r--p 0003d000 08:01 21503118                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f1cb0738000-7f1cb0739000 rw-p 0003e000 08:01 21503118                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f1cb0739000-7f1cb0862000 r-xp 00000000 08:01 21503124                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f1cb0862000-7f1cb0a61000 ---p 00129000 08:01 21503124                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f1cb0a61000-7f1cb0a62000 r--p 00128000 08:01 21503124                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f1cb0a62000-7f1cb0a64000 rw-p 00129000 08:01 21503124                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f1cb0a64000-7f1cb28c8000 r-xp 00000000 08:01 21508096                   /usr/lib/libopenblasp-r0.2.18.so
7f1cb28c8000-7f1cb2ac7000 ---p 01e64000 08:01 21508096                   /usr/lib/libopenblasp-r0.2.18.so
7f1cb2ac7000-7f1cb2acd000 r--p 01e63000 08:01 21508096                   /usr/lib/libopenblasp-r0.2.18.so
7f1cb2acd000-7f1cb2adf000 rw-p 01e69000 08:01 21508096                   /usr/lib/libopenblasp-r0.2.18.so
7f1cb2adf000-7f1cb2af8000 rw-p 00000000 00:00 0 
7f1cb2af8000-7f1cb2b53000 r-xp 00000000 08:01 21508092                   /usr/lib/openblas-base/libblas.so.3
7f1cb2b53000-7f1cb2d53000 ---p 0005b000 08:01 21508092                   /usr/lib/openblas-base/libblas.so.3
7f1cb2d53000-7f1cb2d58000 r--p 0005b000 08:01 21508092                   /usr/lib/openblas-base/libblas.so.3
7f1cb2d58000-7f1cb2d59000 rw-p 00060000 08:01 21508092                   /usr/lib/openblas-base/libblas.so.3
7f1cb2d85000-7f1cb2eed000 r-xp 00000000 08:01 21760683                   /usr/lib/python2.7/dist-packages/numpy/core/multiarray.x86_64-linux-gnu.so
7f1cb2eed000-7f1cb30ec000 ---p 00168000 08:01 21760683                   /usr/lib/python2.7/dist-packages/numpy/core/multiarray.x86_64-linux-gnu.so
7f1cb30ec000-7f1cb30ee000 r--p 00167000 08:01 21760683                   /usr/lib/python2.7/dist-packages/numpy/core/multiarray.x86_64-linux-gnu.so
7f1cb30ee000-7f1cb30fb000 rw-p 00169000 08:01 21760683                   /usr/lib/python2.7/dist-packages/numpy/core/multiarray.x86_64-linux-gnu.so
7f1cb30fb000-7f1cb310d000 rw-p 00000000 00:00 0 
7f1cb310d000-7f1cb3132000 r-xp 00000000 08:01 1708563                    /lib/x86_64-linux-gnu/libtinfo.so.5.9
7f1cb3132000-7f1cb3331000 ---p 00025000 08:01 1708563                    /lib/x86_64-linux-gnu/libtinfo.so.5.9
7f1cb3331000-7f1cb3335000 r--p 00024000 08:01 1708563                    /lib/x86_64-linux-gnu/libtinfo.so.5.9
7f1cb3335000-7f1cb3336000 rw-p 00028000 08:01 1708563                    /lib/x86_64-linux-gnu/libtinfo.so.5.9
7f1cb3336000-7f1cb3373000 r-xp 00000000 08:01 1708542                    /lib/x86_64-linux-gnu/libreadline.so.6.3
7f1cb3373000-7f1cb3573000 ---p 0003d000 08:01 1708542                    /lib/x86_64-linux-gnu/libreadline.so.6.3
7f1cb3573000-7f1cb3575000 r--p 0003d000 08:01 1708542                    /lib/x86_64-linux-gnu/libreadline.so.6.3
7f1cb3575000-7f1cb357b000 rw-p 0003f000 08:01 1708542                    /lib/x86_64-linux-gnu/libreadline.so.6.3
7f1cb357b000-7f1cb357c000 rw-p 00000000 00:00 0 
7f1cb357c000-7f1cb3581000 r-xp 00000000 08:01 21637152                   /usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so
7f1cb3581000-7f1cb3781000 ---p 00005000 08:01 21637152                   /usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so
7f1cb3781000-7f1cb3782000 r--p 00005000 08:01 21637152                   /usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so
7f1cb3782000-7f1cb3784000 rw-p 00006000 08:01 21637152                   /usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so
7f1cb3784000-7f1cb4143000 r--p 00000000 08:01 21502372                   /usr/lib/locale/locale-archive
7f1cb4143000-7f1cb424b000 r-xp 00000000 08:01 1708463                    /lib/x86_64-linux-gnu/libm-2.23.so
7f1cb424b000-7f1cb444a000 ---p 00108000 08:01 1708463                    /lib/x86_64-linux-gnu/libm-2.23.so
7f1cb444a000-7f1cb444b000 r--p 00107000 08:01 1708463                    /lib/x86_64-linux-gnu/libm-2.23.so
7f1cb444b000-7f1cb444c000 rw-p 00108000 08:01 1708463                    /lib/x86_64-linux-gnu/libm-2.23.so
7f1cb444c000-7f1cb4465000 r-xp 00000000 08:01 1708582                    /lib/x86_64-linux-gnu/libz.so.1.2.8
7f1cb4465000-7f1cb4664000 ---p 00019000 08:01 1708582                    /lib/x86_64-linux-gnu/libz.so.1.2.8
7f1cb4664000-7f1cb4665000 r--p 00018000 08:01 1708582                    /lib/x86_64-linux-gnu/libz.so.1.2.8
7f1cb4665000-7f1cb4666000 rw-p 00019000 08:01 1708582                    /lib/x86_64-linux-gnu/libz.so.1.2.8
7f1cb4666000-7f1cb4668000 r-xp 00000000 08:01 1708572                    /lib/x86_64-linux-gnu/libutil-2.23.so
7f1cb4668000-7f1cb4867000 ---p 00002000 08:01 1708572                    /lib/x86_64-linux-gnu/libutil-2.23.so
7f1cb4867000-7f1cb4868000 r--p 00001000 08:01 1708572                    /lib/x86_64-linux-gnu/libutil-2.23.so
7f1cb4868000-7f1cb4869000 rw-p 00002000 08:01 1708572                    /lib/x86_64-linux-gnu/libutil-2.23.so
7f1cb4869000-7f1cb486c000 r-xp 00000000 08:01 1708417                    /lib/x86_64-linux-gnu/libdl-2.23.so
7f1cb486c000-7f1cb4a6b000 ---p 00003000 08:01 1708417                    /lib/x86_64-linux-gnu/libdl-2.23.so
7f1cb4a6b000-7f1cb4a6c000 r--p 00002000 08:01 1708417                    /lib/x86_64-linux-gnu/libdl-2.23.so
7f1cb4a6c000-7f1cb4a6d000 rw-p 00003000 08:01 1708417                    /lib/x86_64-linux-gnu/libdl-2.23.so
7f1cb4a6d000-7f1cb4c2d000 r-xp 00000000 08:01 1708395                    /lib/x86_64-linux-gnu/libc-2.23.so
7f1cb4c2d000-7f1cb4e2c000 ---p 001c0000 08:01 1708395                    /lib/x86_64-linux-gnu/libc-2.23.so
7f1cb4e2c000-7f1cb4e30000 r--p 001bf000 08:01 1708395                    /lib/x86_64-linux-gnu/libc-2.23.so
7f1cb4e30000-7f1cb4e32000 rw-p 001c3000 08:01 1708395                    /lib/x86_64-linux-gnu/libc-2.23.so
7f1cb4e32000-7f1cb4e36000 rw-p 00000000 00:00 0 
7f1cb4e36000-7f1cb4e4e000 r-xp 00000000 08:01 1708537                    /lib/x86_64-linux-gnu/libpthread-2.23.so
7f1cb4e4e000-7f1cb504d000 ---p 00018000 08:01 1708537                    /lib/x86_64-linux-gnu/libpthread-2.23.so
7f1cb504d000-7f1cb504e000 r--p 00017000 08:01 1708537                    /lib/x86_64-linux-gnu/libpthread-2.23.so
7f1cb504e000-7f1cb504f000 rw-p 00018000 08:01 1708537                    /lib/x86_64-linux-gnu/libpthread-2.23.so
7f1cb504f000-7f1cb5053000 rw-p 00000000 00:00 0 
7f1cb5053000-7f1cb5079000 r-xp 00000000 08:01 1708367                    /lib/x86_64-linux-gnu/ld-2.23.so
7f1cb5094000-7f1cb5154000 rw-p 00000000 00:00 0 
7f1cb5185000-7f1cb524a000 rw-p 00000000 00:00 0 
7f1cb526d000-7f1cb526e000 rw-p 00000000 00:00 0 
7f1cb526e000-7f1cb526f000 rwxp 00000000 00:00 0 
7f1cb526f000-7f1cb5276000 r--s 00000000 08:01 21890355                   /usr/lib/x86_64-linux-gnu/gconv/gconv-modules.cache
7f1cb5276000-7f1cb5278000 rw-p 00000000 00:00 0 
7f1cb5278000-7f1cb5279000 r--p 00025000 08:01 1708367                    /lib/x86_64-linux-gnu/ld-2.23.so
7f1cb5279000-7f1cb527a000 rw-p 00026000 08:01 1708367                    /lib/x86_64-linux-gnu/ld-2.23.so
7f1cb527a000-7f1cb527b000 rw-p 00000000 00:00 0 
7fffb822d000-7fffb824e000 rw-p 00000000 00:00 0                          [stack]
7fffb82ba000-7fffb82bc000 r--p 00000000 00:00 0                          [vvar]
7fffb82bc000-7fffb82be000 r-xp 00000000 00:00 0                          [vdso]
ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]
[1]    17517 abort (core dumped)  python
```

```
$ gdb python
run tf.py
```

with `tf.py`:

```
import tensorflow as tf
```

gives

```
(gdb) run tf.py
Starting program: /usr/bin/python tf.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7ffff3234700 (LWP 17850)]
[New Thread 0x7ffff2a33700 (LWP 17851)]
[New Thread 0x7ffff0232700 (LWP 17852)]
[New Thread 0x7fffeda31700 (LWP 17853)]
[New Thread 0x7fffe9230700 (LWP 17854)]
[New Thread 0x7fffe6a2f700 (LWP 17855)]
[New Thread 0x7fffe422e700 (LWP 17856)]

Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.
0x00007ffff786f5a1 in ?? () from /lib/x86_64-linux-gnu/libc.so.6
```
"
3341,undefined reference to `tensorflow::strings::StrAppend,"### Environment info

Operating System: Ubuntu 16.04 LTS (Linux thinkpad 4.4.0-31-generic #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux)

Installed version of CUDA and cuDNN: CUDA 8.0, cuDNN 4.0.7

``` bash
$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   560184 Jul 16 08:43 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Jul 16 08:43 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Jul 16 08:43 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 Jul 16 08:43 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 Jul 16 08:43 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 root root       17 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxr-xr-x 1 root root 61453024 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from sources, provide the commit hash: d2c913aa9b7cb63e466392f76d46ac5fbc1e9825

``` bash
~/GitHub/tensorflow $ git rev-parse HEAD
d2c913aa9b7cb63e466392f76d46ac5fbc1e9825
```
### Steps to reproduce
1. Clone the tensorflow repository
2. `./configure` (with GPU)
3. `bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer`
### What I tried

When I tried to build it, I got:

``` bash
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(log_memory.o): In function `tensorflow::LogMemory::RecordTensorAllocation(std::string const&, long long, tensorflow::Tensor const&)':
log_memory.cc:(.text._ZN10tensorflow9LogMemory22RecordTensorAllocationERKSsxRKNS_6TensorE+0x4a): undefined reference to `google::protobuf::internal::empty_string_'
log_memory.cc:(.text._ZN10tensorflow9LogMemory22RecordTensorAllocationERKSsxRKNS_6TensorE+0x8c): undefined reference to `google::protobuf::Message::GetTypeName() const'
log_memory.cc:(.text._ZN10tensorflow9LogMemory22RecordTensorAllocationERKSsxRKNS_6TensorE+0x11b): undefined reference to `tensorflow::ProtoShortDebugString(tensorflow::MemoryLogTensorAllocation const&)'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_kernel.o): In function `tensorflow::ValidateKernelRegistrations(tensorflow::OpRegistryInterface const&)':
op_kernel.cc:(.text._ZN10tensorflow27ValidateKernelRegistrationsERKNS_19OpRegistryInterfaceE+0x92): undefined reference to `tensorflow::ProtoShortDebugString(tensorflow::KernelDef const&)'
op_kernel.cc:(.text._ZN10tensorflow27ValidateKernelRegistrationsERKNS_19OpRegistryInterfaceE+0x2d8): undefined reference to `tensorflow::strings::StrCat(tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(types.o): In function `tensorflow::DataTypeString(tensorflow::DataType)':
types.cc:(.text._ZN10tensorflow14DataTypeStringENS_8DataTypeE+0x81): undefined reference to `tensorflow::strings::StrCat(tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_gen_lib.o): In function `tensorflow::WordWrap(tensorflow::StringPiece, tensorflow::StringPiece, int)':
op_gen_lib.cc:(.text._ZN10tensorflow8WordWrapENS_11StringPieceES0_i+0xde): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&)'
op_gen_lib.cc:(.text._ZN10tensorflow8WordWrapENS_11StringPieceES0_i+0x1bf): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&)'
op_gen_lib.cc:(.text._ZN10tensorflow8WordWrapENS_11StringPieceES0_i+0x242): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&)'
op_gen_lib.cc:(.text._ZN10tensorflow8WordWrapENS_11StringPieceES0_i+0x27f): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&)'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(tensor_shape.o): In function `tensorflow::TensorShape::DebugString() const':
tensor_shape.cc:(.text._ZNK10tensorflow11TensorShape11DebugStringEv+0x124): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'
tensor_shape.cc:(.text._ZNK10tensorflow11TensorShape11DebugStringEv+0x178): undefined reference to `tensorflow::strings::StrCat(tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(tensor_shape.o): In function `tensorflow::TensorShape::DebugString(tensorflow::TensorShapeProto const&)':
tensor_shape.cc:(.text._ZN10tensorflow11TensorShape11DebugStringERKNS_16TensorShapeProtoE+0xf6): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'
tensor_shape.cc:(.text._ZN10tensorflow11TensorShape11DebugStringERKNS_16TensorShapeProtoE+0x11d): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&)'
collect2: error: ld returned 1 exit status
Target //tensorflow/cc:tutorials_example_trainer failed to build
```

Any ideas what the problem could be / why I get this?
"
3340,cannot save/restore contrib.learn.DNNClassifier,"Hi , i been struggling some days trying to save a contrib.learn.DNNClassifier and im getting desperate can you help me? I tried everything it says in official documentation, but it sees as if the documentation isnt coherent with the API, things i have tried are:
- rain.Saver() ,but got a ""No variables to save"" error 
- tried https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn this examples, created my DNNClassifier but when trying to call function save() on my classifier , it says 'DNNClassifier' object has no attribute 'save'
- Tried the deprecated class TensorflowDNNClassifier and it can be saved right ,but when you try to restore it ,it says that theres no model to restore.
- Tried to restore the saved TensorflowDNNClassifier with Estimator.restore() but it says that Estimator has no attribute restore.

Is there a way to save and restore a DNNClassifier? This question is asked multiple times in stackoverflow and in https://gitter.im/tensorflow/skflow

I would be very thankfull if you can help me.
"
3338,Tensorflow build error on the Macbook docker ,"In my MacBook(using docker) has a built in Tensorflow source.
The error occurred during the build.
### Environment info

Operating System: OSX, El Capitan
Using Docker & tensor flow docker image :  tensorflow/tensorflow:latest-devel
### Steps to reproduce
1. checking bazel & update
2. download a new tensorflow source
3. ./configure   --> No GPU...
4. build bazel to pip
   --> bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
### Build error

> ERROR: /tensorflow/tensorflow/core/kernels/BUILD:1694:1: C++ compilation of rule '//tensorflow/core/kernels:training_ops' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections ... (remaining 107 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
> gcc: internal compiler error: Killed (program cc1plus)
> Please submit a full bug report,
> with preprocessed source if appropriate.
> <img width=""990"" alt=""2016-07-16 12 07 46"" src=""https://cloud.githubusercontent.com/assets/547925/16892518/445d0698-4b50-11e6-946e-36b90c2d8ea6.png"">
> 
> See file:///usr/share/doc/gcc-4.8/README.Bugs for instructions.
> Target //tensorflow/tools/pip_package:build_pip_package failed to build
#### Include option(--verbose_failures) build err:

  bazel build -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures

> ERROR: /tensorflow/tensorflow/core/kernels/BUILD:1078:1: C++ compilation of rule '//tensorflow/core/kernels:argmax_op' failed: gcc failed: error executing command
>   (cd /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/tensorflow && \
>   exec env - \
>     PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
>   /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -DHAVE_CONFIG_H -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/protobuf -iquote bazel-out/local_linux-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/farmhash_archive -iquote bazel-out/local_linux-opt/genfiles/external/farmhash_archive -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/gif_archive -iquote bazel-out/local_linux-opt/genfiles/external/gif_archive -iquote external/highwayhash -iquote bazel-out/local_linux-opt/genfiles/external/highwayhash -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -iquote external/zlib_archive -iquote bazel-out/local_linux-opt/genfiles/external/zlib_archive -isystem external/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem bazel-out/local_linux-opt/genfiles/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/gif_archive/giflib-5.1.4/lib -isystem bazel-out/local_linux-opt/genfiles/external/gif_archive/giflib-5.1.4/lib -isystem external/highwayhash -isystem bazel-out/local_linux-opt/genfiles/external/highwayhash -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-b4fa9622b809 -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-b4fa9622b809 -isystem external/zlib_archive/zlib-1.2.8 -isystem bazel-out/local_linux-opt/genfiles/external/zlib_archive/zlib-1.2.8 -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -pthread -no-canonical-prefixes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/argmax_op/tensorflow/core/kernels/argmax_op.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/argmax_op/tensorflow/core/kernels/argmax_op.pic.d -fPIC -c tensorflow/core/kernels/argmax_op.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/argmax_op/tensorflow/core/kernels/argmax_op.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
> gcc: internal compiler error: Killed (program cc1plus)
> Please submit a full bug report,
> with preprocessed source if appropriate.
> See file:///usr/share/doc/gcc-4.8/README.Bugs for instructions.
> Target //tensorflow/tools/pip_package:build_pip_package failed to build
> INFO: Elapsed time: 3619.233s, Critical Path: 3589.94s

<img width=""1246"" alt=""2016-07-16 2 48 52"" src=""https://cloud.githubusercontent.com/assets/547925/16893041/8d3c4fb8-4b64-11e6-8d8f-0557e9128b1f.png"">
"
3334,tf.case doesn't preserve shape information,"tf.case is a python implementation of a case statement using tf.cond, but unlike cond it doesn't preserve shape information when executing. This is because of this little snippet:

``` python
...
    # preds = [p1, p2, p3]
    # fns = [f1, f2, f3]
    # not_preds = [~p1, ~p2, ~p3]
    # and_not_preds = [True, ~p1, ~p1 & ~p2, ~p1 & ~p2 & ~p3]
    # case_preds = [p1,
    #               p2 & ~p1,
    #               p3 & ~p2 & ~p1,
    #              ~p3 & ~p2 & ~p1]

    case_preds = []
    for i, (p, and_not_p_prev) in enumerate(zip(preds, and_not_preds[:-1])):
      with ops.name_scope(""case_%d"" % i):
        case_preds.append(math_ops.logical_and(p, and_not_p_prev))
    with ops.name_scope(""case_none_are_true""):
      case_preds.append(and_not_preds[-1])

    # Create an empty tensor, or list, with the right type and shape
    with ops.name_scope(""case_create_empty""):
      dummy_value = default()
      def _correct_empty(v):
        if isinstance(v, ops.Operation):
          return no_op()
        elif v.dtype == dtypes.string:
          return array_ops.constant("""")
        else:
          return array_ops.constant(v.dtype.as_numpy_dtype())

      if isinstance(dummy_value, collections.Sequence):
        dummy_type = type(dummy_value)
        empty = lambda: dummy_type(_correct_empty(v) for v in dummy_value)
      else:
        empty = lambda: _correct_empty(dummy_value)

    # case_sequence = [
    #   cond(~p3 & ~p2 & ~p1, default, empty),
    #   cond(p3 & ~p2 & ~p1, f3, lambda: case_sequence[0]),
    #   cond(p2 & ~p1, f2, lambda: case_sequence[1]),
    #   cond(p1, f1, lambda: case_sequence[2])
    # ]
    #
    # And the return value will be case_sequence[-1]
    def _build_case():
      all_fns = [fn for fn in fns]
      all_fns.append(default)
      prev_case = None
      for i, (cp, fn) in enumerate(list(zip(case_preds, all_fns))[::-1]):
        prev_case = cond(
            cp, fn,
            empty if i == 0 else lambda: prev_case,
            name=""If_%d"" % i)
      return prev_case
...
```

The op works by evaluating a series of predicates (including a predicate for the default value) but it starts off with an empty object. The empty object seems to be designed to pass on correct shape and type information but it fails to do so in my use case. I recommend changing this code to read:

``` python
...
    # preds = [p1, p2, p3]
    # fns = [f1, f2, f3]
    # not_preds = [~p1, ~p2, ~p3]
    # and_not_preds = [True, ~p1, ~p1 & ~p2, ~p1 & ~p2 & ~p3]
    # case_preds = [p1,
    #               p2 & ~p1,
    #               p3 & ~p2 & ~p1]

    case_preds = []
    for i, (p, and_not_p_prev) in enumerate(zip(preds, and_not_preds[:-1])):
      with ops.name_scope(""case_%d"" % i):
        case_preds.append(math_ops.logical_and(p, and_not_p_prev))

    # case_sequence = [
    #   cond(p3 & ~p2 & ~p1, f3, default),
    #   cond(p2 & ~p1, f2, lambda: case_sequence[0]),
    #   cond(p1, f1, lambda: case_sequence[1])
    # ]
    #
    # And the return value will be case_sequence[-1]
    def _build_case():
      all_fns = [fn for fn in fns]
      prev_case = None
      for i, (cp, fn) in enumerate(list(zip(case_preds, all_fns))[::-1]):
        prev_case = cond(
            cp, fn,
            default if prev_case is None else lambda: prev_case,
            name=""If_%d"" % i)
      return prev_case
...
```

This removes the need not only for creating a dummy empty op, but also removes the need to create a separate predicate for the default op, simplifying the whole op by about 18 lines of code.
"
3332,Feature Request: Support for depthwise convolution by groups,"As much as I have managed to follow the API section of tensorflow the depthwise_conv2d doesn't fulfill my thoughts on what I would like to do with the input/filters.

```
shape = (2,5,5,48,128)
initializer = tf.truncated_normal_initializer(stddev=1e-2)
kernel = tf.get_variable(name='weights', shape=shape, initializer=initializer)
```

Considering the input is of shape (batch_size, 55, 55, 96),
the function definition would be:

```
def depthwise_group_conv2d(input, filter, groups, strides, padding, name)
```

which would be able to do

```
conv = tf.nn.depthwise_group_conv2d(input, kernel, [48,48], strides, padding, name)
```

that would split the input depthwise into depths from given 'groups' parameter and perform the convolution with shared parameters (i.e. depths [:48] take weights[0] and depths[48:] take weights[1]) inside a group. Then the outputs of convolutions by groups would be concatenated depthwise.

This would make it easier to define groups such as one used in AlexNet/CaffeNet architectures.

Hopefully I have missed a certain feature already existing for making this easier.

Best regards,
Filip
"
3331,Retrofitting: idgi make me smarter :),"can someone point me to some info on retrofitting?  I don't get it really.  

I'm specifically trying to combine some of my writing with ConceptNet (which I can download in matrix form) in order to generate output that sounds something like me or at least talks about the things i talk about.  Guess I'm not understanding how to align and combine the matrices for the most part but any literature is greatly appreciated.

Cheers,
di-synthetic-logic
p.s. bless you
"
3330,tensorflow based shared library can't link to other project,"Problem:
I create a project in tensorflow/tensorflow/my_project. Then create a library by cc_library of bazel. I can compile it and create the library. For example, test.a, test.so in tensorflow/bazel-bin/my_project. But if I use the library in another project by linking it. It would raise a problem of finding the header file.

```
fatal error: tensorflow/core/framework/graph.pb.h: No such file or directory
```

test.h:

```
#include ""tensorflow/core/framework/graph.pb.h""
#include ""tensorflow/core/framework/tensor.h""
#include ""tensorflow/core/public/session.h""
#include ""tensorflow/core/platform/env.h""

blabla...
```
"
3329,issue running build_all_ios.sh ?,"On running build_all_ios.sh script, getting folllowing error?

m -lz
    Undefined symbols for architecture x86_64:
      ""google::protobuf::io::CodedInputStream::ReadVarintSizeAsIntFallback()"", referenced from:
      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in test_log.pb.o
      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in saved_tensor_slice.pb.o
      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in event.pb.o
      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in tensorflow_server.pb.o
      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in named_tensor.pb.o
      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in meta_graph.pb.o
      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in config.pb.o
      ...
      ""google::protobuf::MessageLite::InternalSerializeWithCachedSizesToArray(bool, unsigned char_) const"", referenced from:
      vtable for google::protobuf::internal::MapEntryBase in test_log.pb.o
      vtable for google::protobuf::internal::MapEntryBase in tensorflow_server.pb.o
      vtable for google::protobuf::internal::MapEntryBase in meta_graph.pb.o
      vtable for google::protobuf::internal::MapEntryBase in config.pb.o
      vtable for google::protobuf::internal::MapEntryBase in graph.pb.o
      vtable for google::protobuf::internal::MapEntryBase in function.pb.o
      vtable for google::protobuf::internal::MapEntryBase in attr_value.pb.o
      ...
    ld: symbol(s) not found for architecture x86_64
    clang: error: linker command failed with exit code 1 (use -v to see invocation)
    make: **\* [/Users/jsahil/projects/tensorflow/tensorflow
master/tensorflow/contrib/makefile/gen/host_bin/proto_text] Error 1
    + '[' 2 -ne 0 ']'
    + echo 'armv7 compilation failed.'
    armv7 compilation failed. 
    + exit 1

Let me know if I am missing something. Thanks
"
3327,Issue running compile_ios_tensorflow.sh?,"On running compile_ios_tensorflow.sh, I am facing the below issue.

**sh compile_ios_tensorflow.sh** 

```
sed: tensorflow/contrib/makefile/downloads/eigen-latest/eigen/src/Core/arch/NEON/Complex.h: No such file or directory
sed: tensorflow/contrib/makefile/downloads/eigen-latest/eigen/src/Core/arch/NEON/Complex.h: No such file or directory
sed: tensorflow/contrib/makefile/downloads/eigen-latest/eigen/src/Core/arch/NEON/Complex.h: No such file or directory
make: tensorflow/contrib/makefile/Makefile: No such file or directory
make: *** No rule to make target `tensorflow/contrib/makefile/Makefile'.  Stop.
make: tensorflow/contrib/makefile/Makefile: No such file or directory
make: *** No rule to make target `tensorflow/contrib/makefile/Makefile'.  Stop.
```

armv7 compilation failed.

because of this I am unable to proceed with iOS example, cos of missing libtensorflow.a 

```
ld: file not found: /Users/jsahil/projects/tensorflow/tensorflow-master/tensorflow/contrib/ios_examples/camera/../../makefile/gen/lib/libtensorflow-core.a
```

Please let me know, if I am missing something or this is an issue with the script. Thanks
"
3326,classification using tensorflow : word2vec_basic,"Hi,

In tensorflow, using word2vec_basic, can we have a few fixed buckets and others as custom buckets based on valid_examples ? 

I have also raised a similar doubt on[ stack overflow ](http://stackoverflow.com/questions/38295791/classification-using-tensorflow-word2vec-basic) . It will be great to have your feedback on the same !! 
"
3325,build_pip_package failed,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
Redhat 6.7
module environment
gcc 6.1.0

`printenv
MKLROOT=/software/intel/xe2015/composer_xe_2015.1.133/mkl
FLIBDIR=/software/intel/xe2015/composer_xe_2015.1.133/compiler/lib/intel64
MANPATH=/software/python/3.4.5/login/man:/software/intel/xe2015/composer_xe_2015.1.133/man/en_US:/usr/share/man:/usr/man:/usr/local/share/man:/usr/X11R6/man
MKLLIBDIR=/software/intel/xe2015/composer_xe_2015.1.133/mkl/lib/intel64
FDIR=/software/intel/xe2015/composer_xe_2015.1.133
IPPROOT=/software/intel/xe2015/composer_xe_2015.1.133/ipp
INTEL_LICENSE_FILE=/software/intel/licenses/server.lic
TERM=xterm
SHELL=/bin/bash
MLIBDIR=/software/intel/xe2015/composer_xe_2015.1.133/mkl/lib/intel64
HISTSIZE=1000
SSH_CLIENT=134.99.4.11 52640 22
LIBRARY_PATH=/software/intel/xe2015/composer_xe_2015.1.133/compiler/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/ipp/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/mkl/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/tbb/lib/intel64
FPATH=
OLDPWD=/root
SSH_TTY=/dev/pts/3
USER=root
LD_LIBRARY_PATH=/software/gcc/6.1.0/login/lib:/software/gcc/6.1.0/login/lib64:/software/python/install/Python-3.4.5/Include/:/software/python/3.4.5/login/lib:/software/intel/xe2015/composer_xe_2015.1.133/compiler/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/ipp/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/mkl/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/tbb/lib/intel64:/lib64:/usr/lib64:/usr/local/lib64:/usr/X11R6/lib64
CPATH=/software/intel/xe2015/composer_xe_2015.1.133/mkl/include:/software/intel/xe2015/composer_xe_2015.1.133/tbb/include
LIBPATH=/software/python/install/Python-3.4.5/Lib/:/software/python/3.4.5/login/lib
CDIR=/software/intel/xe2015/composer_xe_2015.1.133
CLIBDIR=/software/intel/xe2015/composer_xe_2015.1.133/compiler/lib/intel64
MAIL=/var/spool/mail/root
PATH=/software/gcc/6.1.0/login/bin:/software/python/3.4.5/login/bin:/software/intel/xe2015/composer_xe_2015.1.133/bin/intel64:/software/intel/xe2015/composer_xe_2015.1.133/bin/intel64_mic:/software/intel/xe2015/composer_xe_2015.1.133/debugger/gui/intel64:/usr/pbs/bin:.:/bin:/usr/bin:/usr/local/bin:/usr/X11R6/bin
TBBROOT=/software/intel/xe2015/composer_xe_2015.1.133/tbb
F90=gfortran
PWD=/software/tensorflow/install/tensorflow
_LMFILES_=/software/modules/tools/hpc_basis:/software/modules/compiler/intel/xe2015:/software/modules/tools/Python/3.4.5:/software/modules/compiler/gcc/6.1.0
F95=gfortran
LANG=en_US.UTF-8
MODULEPATH=/software/modules/compiler:/software/modules/software:/software/modules/tools
LOADEDMODULES=hpc_basis:intel/xe2015:Python/3.4.5:gcc/6.1.0
PYTHONHOME=/software/python/3.4.5/login
F77=gfortran
CXX=g++
HISTCONTROL=ignoredups
SHLVL=1
HOME=/root
FC=gfortran
DYLD_LIBRARY_PATH=/software/gcc/6.1.0/login/lib:/software/gcc/6.1.0/login/lib64:/software/intel/xe2015/composer_xe_2015.1.133/compiler/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/ipp/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/mkl/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/tbb/lib/intel64
LOGNAME=root
CVS_RSH=ssh
MODULESHOME=/usr/share/Modules
LESSOPEN=||/usr/bin/lesspipe.sh %s
ARCH=login
FRTLIB=-lifcore
CC=gcc
INCLUDE=/software/intel/xe2015/composer_xe_2015.1.133/mkl/include:/software/intel/xe2015/composer_xe_2015.1.133/tbb/include:/usr/X11R6/include/X11:/usr/include:/usr/local/include
G_BROKEN_FILENAMES=1
BASH_FUNC_module()=() {  eval`/usr/bin/modulecmd bash $*`
}
_=/usr/bin/printenv
`

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
ls -l /software/CUDA/7.5.18/lib/libcud*
-rw-r--r-- 1 root users 189170 Sep 10  2015 /software/CUDA/7.5.18/lib/libcudadevrt.a
lrwxrwxrwx 1 root users     16 Sep 10  2015 /software/CUDA/7.5.18/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root users     19 Sep 10  2015 /software/CUDA/7.5.18/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root users 311596 Sep 10  2015 /software/CUDA/7.5.18/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root users 558020 Sep 10  2015 /software/CUDA/7.5.18/lib/libcudart_static.a

If installed from sources, provide the commit hash:
d2c913aa9b7cb63e466392f76d46ac5fbc1e9825
### Steps to reproduce
1. install gcc in different path and set PATH, LD_LIBRARY_PATH, INCLDUE_PATH
2. git clone https://github.com/tensorflow/tensorflow.git
3. ./configure
4. bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures
### Logs or other output that would be helpful

`[root@hpc-login1 tensorflow]# bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures
WARNING: /software/tensorflow/install/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
INFO: Found 1 target...
ERROR: /root/.cache/bazel/_bazel_root/60e5a3f81176660f3aa05e1fb0a50126/external/zlib_archive/BUILD:7:1: undeclared inclusion(s) in rule '@zlib_archive//:zlib':
this rule is missing dependency declarations for the following files included by 'external/zlib_archive/zlib-1.2.8/uncompr.c':
  '/software/gcc/6.1.0/login/lib/gcc/x86_64-pc-linux-gnu/6.1.0/include-fixed/limits.h'
  '/software/gcc/6.1.0/login/lib/gcc/x86_64-pc-linux-gnu/6.1.0/include-fixed/syslimits.h'
  '/software/gcc/6.1.0/login/lib/gcc/x86_64-pc-linux-gnu/6.1.0/include/stddef.h'
  '/software/gcc/6.1.0/login/lib/gcc/x86_64-pc-linux-gnu/6.1.0/include/stdarg.h'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 3.201s, Critical Path: 1.01s`

I also tried to use the intel compiler but bazel brakes the environment
"
3324,tensorflow anaconda : pip install fails in newly created python 2.7 environment,"### Environment info

Operating System:
(tf) :~/anaconda3/bin$ cat /proc/version
Linux version 4.4.0-31-generic (buildd@lgw01-16) (gcc version 5.3.1 20160413 (Ubuntu 5.3.1-14ubuntu2.1) ) #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016
### Steps to reproduce
1. Follow https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#anaconda-installation
2. :~/anaconda3/bin$ ./conda create --name tf python=2
   Fetching package metadata .......
   Solving package specifications: ..........

Package plan for installation in environment /home/paddlescoot/anaconda3/envs/tf:

The following packages will be downloaded:

| package | build |
| --- | --- |
| python-2.7.12 | 1        12.1 MB |
| setuptools-23.0.0 | py27_0         455 KB |
| wheel-0.29.0 | py27_0          81 KB |
| pip-8.1.2 | py27_0         1.5 MB |

```
------------------------------------------------------------
                                       Total:        14.1 MB
```

The following NEW packages will be INSTALLED:

```
openssl:    1.0.2h-1     
pip:        8.1.2-py27_0 
python:     2.7.12-1     
readline:   6.2-2        
setuptools: 23.0.0-py27_0
sqlite:     3.13.0-0     
tk:         8.5.18-0     
wheel:      0.29.0-py27_0
zlib:       1.2.8-3      
```

Proceed ([y]/n)? y

Fetching packages ...
python-2.7.12- 100% 
setuptools-23. 100% 
wheel-0.29.0-p 100% 
pip-8.1.2-py27 100% 

Extracting packages ...
Linking packages ...

:~/anaconda3/bin$ source activate tf
(tf) :~/anaconda3/bin$ ./conda info --envs
# conda environments:
# 

tf                    \*  /home/paddlescoot/anaconda3/envs/tf
root                     /home/paddlescoot/anaconda3

(tf) :~/anaconda3/bin$ python --version
Python 2.7.12 :: Continuum Analytics, Inc.

(tf) :~/anaconda3/bin$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl

(tf) :~/anaconda3/bin$ pip install --upgrade $TF_BINARY_URL
Collecting tensorflow==0.9.0 from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl
  Downloading https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl (27.6MB)
    100% || 27.6MB 52kB/s 
Collecting numpy>=1.8.2 (from tensorflow==0.9.0)
  Downloading numpy-1.11.1-cp27-cp27mu-manylinux1_x86_64.whl (15.3MB)
    100% || 15.3MB 90kB/s 
Collecting six>=1.10.0 (from tensorflow==0.9.0)
  Using cached six-1.10.0-py2.py3-none-any.whl
Collecting protobuf==3.0.0b2 (from tensorflow==0.9.0)
  Using cached protobuf-3.0.0b2-py2.py3-none-any.whl
Requirement already up-to-date: wheel in /home/paddlescoot/anaconda3/envs/tf/lib/python2.7/site-packages (from tensorflow==0.9.0)
Collecting setuptools (from protobuf==3.0.0b2->tensorflow==0.9.0)
  Downloading setuptools-24.0.3-py2.py3-none-any.whl (441kB)
    100% || 450kB 1.3MB/s 
Installing collected packages: numpy, six, setuptools, protobuf, tensorflow
  Found existing installation: setuptools 23.0.0
Cannot remove entries from nonexistent file /home/paddlescoot/anaconda3/envs/tf/lib/python2.7/site-packages/easy-install.pth

(tf) :~/anaconda3/bin$ python
Python 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:42:40) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
Anaconda is brought to you by Continuum Analytics.
Please check out: http://continuum.io/thanks and https://anaconda.org

> > > import tensorflow as tf
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > > ImportError: No module named tensorflow
> > > quit()

(tf) :~/anaconda3/bin$ ls -ali /home/paddlescoot/anaconda3/envs/tf/lib/python2.7/site-packages/
numpy/                       pip/                         README                       setuptools.pth               six.py                       wheel/
numpy-1.11.1.dist-info/      pip-8.1.2-py2.7.egg-info/    setuptools-23.0.0-py2.7.egg  six-1.10.0.dist-info/        six.pyc                      wheel-0.29.0-py2.7.egg-info/

(tf) :~/anaconda3/bin$ ls -ali /home/paddlescoot/anaconda3/envs/tf/lib/python2.7/site-packages/
numpy/                       pip/                         README                       setuptools.pth               six.py                       wheel/
numpy-1.11.1.dist-info/      pip-8.1.2-py2.7.egg-info/    setuptools-23.0.0-py2.7.egg  six-1.10.0.dist-info/        six.pyc                      wheel-0.29.0-py2.7.egg-info/
### What have you tried?
1. Searching for similar issues.
"
3322,Wrong type in rnn function,"I think the type of `zero_output` in line 135 in [(rnn.py)](https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/python/ops/rnn.py#L135) should be `dtype` and not `inputs[0].dtype` as it is right now. If the cell output is a float, this will trigger an exception in the select statement in `_rnn_step` function in line [(298)](https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/python/ops/rnn.py#L298) of the type 

`TypeError: Input 'e' of 'Select' Op has type float32 that does not match type int32 of argument 't'.`

when the inputs of the cells are int. I don't have a short piece of code to reproduce this, but if needed I can produce one.
"
3321,Tensorflow with GPU on Mac OSX: Works in Python but NOT IPython,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Mac OSX 10.11.5

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): 7.5

lrwxr-xr-x  1 root  admin    13 Jul 14 13:25 /usr/local/cuda/lib/libcuda.1.dylib -> libcuda.dylib
-rwxr-xr-x  1 root  wheel  8280 Apr 12 23:02 /usr/local/cuda/lib/libcuda.dylib
lrwxr-xr-x  1 root  wheel    45 Apr 12 23:03 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
lrwxr-xr-x  1 root  wheel    50 Apr 12 23:03 /usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
lrwxr-xr-x  1 root  wheel    46 Apr 12 23:03 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
lrwxr-xr-x  1 root  wheel    49 Apr 12 23:03 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a
lrwxr-xr-x  1 root  admin    47 Jul 14 12:37 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.5.dylib
lrwxr-xr-x  1 root  admin    45 Jul 14 12:37 /usr/local/cuda/lib/libcudnn.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.dylib
lrwxr-xr-x  1 root  admin    48 Jul 14 12:37 /usr/local/cuda/lib/libcudnn_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.  tensorflow
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.1.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.7.5.dylib locally
0.9.0

If installed from sources, provide the commit hash:
### Steps to reproduce
1. Install Anaconda 64-bit Python 2.7
2. Install Tensorflow for Mac with GPU support according to [these instructions](https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installation-for-mac-os-x). Make sure to fix the [segmentation fault bug](https://github.com/tensorflow/tensorflow/issues/3263) as well.
3. Open up ipython (not python) and import tensorflow

It works in Python:

```
Xiaojians-MacBook-Pro:lib xjdeng$ python
Python 2.7.11 |Anaconda 4.0.0 (x86_64)| (default, Dec  6 2015, 18:57:58) 
[GCC 4.2.1 (Apple Inc. build 5577)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
Anaconda is brought to you by Continuum Analytics.
Please check out: http://continuum.io/thanks and https://anaconda.org
>>> import tensorflow
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.1.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.7.5.dylib locally
>>> 
```

But not iPython:

```
Xiaojians-MacBook-Pro:lib xjdeng$ ipython
Python 2.7.11 |Anaconda 4.0.0 (x86_64)| (default, Dec  6 2015, 18:57:58) 
Type ""copyright"", ""credits"" or ""license"" for more information.

IPython 4.1.2 -- An enhanced Interactive Python.
?         -> Introduction and overview of IPython's features.
%quickref -> Quick reference.
help      -> Python's own help system.
object?   -> Details about 'object', use 'object??' for extra details.

In [1]: import tensorflow
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-1-a649b509054f> in <module>()
----> 1 import tensorflow

/Users/xjdeng/anaconda/lib/python2.7/site-packages/tensorflow/__init__.py in <module>()
     21 from __future__ import print_function
     22 
---> 23 from tensorflow.python import *

/Users/xjdeng/anaconda/lib/python2.7/site-packages/tensorflow/python/__init__.py in <module>()
     46 _default_dlopen_flags = sys.getdlopenflags()
     47 sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)
---> 48 from tensorflow.python import pywrap_tensorflow
     49 sys.setdlopenflags(_default_dlopen_flags)
     50 

/Users/xjdeng/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()
     19         except ImportError:
     20             return importlib.import_module('_pywrap_tensorflow')
---> 21     _pywrap_tensorflow = swig_import_helper()
     22     del swig_import_helper
     23 elif _swig_python_version_info >= (2, 6, 0):

/Users/xjdeng/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in swig_import_helper()
     18             return importlib.import_module(mname)
     19         except ImportError:
---> 20             return importlib.import_module('_pywrap_tensorflow')
     21     _pywrap_tensorflow = swig_import_helper()
     22     del swig_import_helper

/Users/xjdeng/anaconda/lib/python2.7/importlib/__init__.pyc in import_module(name, package)
     35             level += 1
     36         name = _resolve_name(name[level:], package, level)
---> 37     __import__(name)
     38     return sys.modules[name]

ImportError: No module named _pywrap_tensorflow

In [2]: import pywrap_tensorflow
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-2-6e414ae7ae75> in <module>()
----> 1 import pywrap_tensorflow

ImportError: No module named pywrap_tensorflow


```
### What have you tried?
1. I've googled for the error message `No module named _pywrap_tensorflow` but haven't gotten any useful results.  What's really puzzling is that tensorflow loads in python but not [ipython.]
2. This error doesn't happen if I import tensorflow in a Jupyter notebook either.  Only iPython from the command line.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3320,CPU vs GPU Performance,"I am working on a reinforcement learning model problem.  I have been working to get the model creation running faster and bumped into a strange issue I cannot explain.  It runs much faster ~50% or so on the CPU vs the GPU.  This was unexpected and I have disabled the GPU using **""export CUDA_VISIBLE_DEVICES=-1""** so the learning runs faster.  I have been looking at upgrading my GTX 950, but not sure it makes sense if I don't get a speed improvement.

I ran a profile based upon #1824 and got the following trace files for a single "".run()"" iteration. I am not sure how to read this, but the GPU iteration took over 10ms where the CPU alone is <10ms. I am running the HEAD of TensorFlow (reports 0.9.0) on Ubuntu 15.10 with CUDA 7.5 and cuDNN 4 & 5 (tried both). The CPU is a dual XEON 6 core, 2.66 GHz  processors (24 threads total) with 72 GB or RAM (DDR3).

I have a GTX 950 GPU.  I can't tell if this performance difference is related to the structure of the graph or simply the data set isn't big enough to get a benefit from the GPU given the IO overhead?  I have tested the GPU with TF on a basic ""matmut()"" of a 7000x7000 matrix and it beats the CPU hands down by orders of magnitude.  So I known it is installed correctly.

Then networks runs in this case a Batch of 200 x 189 into 5 layers with Dropout() between each layer. The layers are 140, 120, 100, 80, and 3 as the output.  Any advice or things to try would be much appreciated.

**CPU Timeline:**
![cpu timeline](https://cloud.githubusercontent.com/assets/18412448/16854147/ad4c8760-49dd-11e6-8919-2c0940322b53.png)

**GPU Timeline:**
![gpu timeline](https://cloud.githubusercontent.com/assets/18412448/16854181/cfa25844-49dd-11e6-9f20-e2268bdd4299.png)

NOTE: This issue was posted to #2444 but may have got lost.  It might be related to RL performance but feel it is a separate issue.

I have enclosed the TIMELINE trace files for more detail.  If it is of value, I can create a ""tensorboard"" log file so you can review the model in detail.
[GPU Slowdown.zip](https://github.com/tensorflow/tensorflow/files/364706/GPU.Slowdown.zip)
"
3319,TensorFlow Android demo crashes on start,"I installed the TensorFlow on my mac and tried the Android demo. It is confusing that it's all fine with compiling to .apk, but the application crashes as soon as it starts on my Nexus5 cellphone.
### Environment info

Operating System: Mac OS X
Android SDK: 24.0.0
Android NDK: r10e (will encounter problems when building with bazel if using latest v12)
Bazel: 0.1.4
Cellphone OS: Android 6

I tried using adb to install the application, and everything seems perfectly fine until I launched the application. Before that, I have already checked that the camera permission is fine. As soon as I open the application, it will immediately crash. I grabbed the log from my device. Besides, I also compared the log with those generated by a successfully running demo. The main difference starts from:
 **07-14 14:00:46.044  2754  2754 E tensorflow: CameraConnectionFragment: Couldn't find any suitable preview size**
Could anyone help me on finding out what cause this problem? The complete log is attached below.
### Logs or other output that would be helpful

07-14 14:00:45.722   773  1502 I ActivityManager: START u0 {act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] flg=0x10200000 cmp=org.tensorflow.demo/.CameraActivity (has extras)} from uid 10022 on display 0
07-14 14:00:45.735   202   811 D audio_hw_primary: out_set_parameters: enter: usecase(1: low-latency-playback) kvpairs: routing=2
07-14 14:00:45.767   202   811 D AudioFlinger: mixer(0xb4100000) throttle end: throttle time(9)
07-14 14:00:45.767  2754  2754 I art     : Late-enabling -Xcheck:jni
07-14 14:00:45.768   773   947 I ActivityManager: Start proc 2754:org.tensorflow.demo/u0a84 for activity org.tensorflow.demo/.CameraActivity
07-14 14:00:45.800  2734  2734 W System  : ClassLoader referenced unknown path: /system/priv-app/MediaProvider/lib/arm
07-14 14:00:45.815  2734  2734 W System  : ClassLoader referenced unknown path: /system/priv-app/DownloadProvider/lib/arm
07-14 14:00:45.858  2754  2754 W linker  : /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so: unused DT entry: type 0x1d arg 0x10ff60a
07-14 14:00:45.871  1146  1929 D GCM     : GcmService start Intent { act=com.google.android.checkin.CHECKIN_COMPLETE flg=0x10 cmp=com.google.android.gms/.gcm.GcmService (has extras) } com.google.android.checkin.CHECKIN_COMPLETE
07-14 14:00:45.875  1566  1566 D ChimeraCfgMgr: Loading module com.google.android.gms.kids from APK com.google.android.gms
07-14 14:00:45.876  1566  1566 I Kids    : [GCoreUtils] Current gmscore version, 8186438 is smaller than the required version 8400000
07-14 14:00:45.907  1385  1385 V UserPresentBroadcastReceiver: Received Intent { act=android.intent.action.USER_PRESENT flg=0x24000010 cmp=com.google.android.gms/.auth.trustagent.UserPresentBroadcastReceiver }.
07-14 14:00:45.937  2754  2788 D OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true
07-14 14:00:45.979  1408  1408 W LocationOracleImpl: Not started: ignore location
07-14 14:00:45.981  1408  1408 E LocationReceiver: Received bad location: null
07-14 14:00:45.984  1408  1408 E LocationReceiver: Received bad location: null
07-14 14:00:45.990  2754  2788 I Adreno-EGL: <qeglDrvAPI_eglInitialize:379>: QUALCOMM Build: 10/21/15, 369a2ea, I96aee987eb
07-14 14:00:45.994  2754  2788 I OpenGLRenderer: Initialized EGL, version 1.4
07-14 14:00:46.025  1258  1258 I Keyboard.Facilitator: onFinishInput()
07-14 14:00:46.026  2754  2754 I CameraManagerGlobal: Connecting to camera service
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 3264x2448
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 3200x2400
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 2592x1944
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 2048x1536
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 1920x1080
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 1600x1200
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 1280x960
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 1280x768
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 1280x720
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 1024x768
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 800x600
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 800x480
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 720x480
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 640x480
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 352x288
07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 320x240
07-14 14:00:46.044  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 176x144
07-14 14:00:46.044  2754  2754 E tensorflow: CameraConnectionFragment: Couldn't find any suitable preview size
07-14 14:00:46.049   202   887 I CameraService: CameraService::connect call (PID 2754 ""org.tensorflow.demo"", camera ID 0) for HAL version default and Camera API version 2
07-14 14:00:46.052   202   887 I CameraService: onTorchStatusChangedLocked: Torch status changed for cameraId=0, newStatus=0
07-14 14:00:46.052   202   887 I Camera2ClientBase: Camera 0: Opened. Client: org.tensorflow.demo (PID 2754, UID 10084)
07-14 14:00:46.052   202   887 I CameraDeviceClient: CameraDeviceClient 0: Opened
07-14 14:00:46.057   202   887 D mm-camera-intf: mm_camera_open: dev name = /dev/video1, cam_idx = 1
07-14 14:00:46.061   217   217 I mm-camera-sensor: module_sensor_start_session:584 session 1
07-14 14:00:46.074  2696  2732 I MediaStoreImporter: Update: incremental Added music: 0 Updated music: 0 Deleted music: 0 Created playlists: 0 Updated playlists: 0 Deleted playlists: 0 Inserted playlist items: 0 Deleted playlist items: 0 Removed orphaned playlist items: 0
07-14 14:00:46.075  2696  2696 D MusicLifecycle: com.google.android.music.store.MediaStoreImportService generated event: Service destroyed
07-14 14:00:46.076   773  1275 I ActivityManager: Killing 2280:com.google.android.configupdater/u0a27 (adj 15): empty #17
07-14 14:00:46.102   217   217 I mm-camera: gyro_module_start_session: Enter
07-14 14:00:46.102   217   217 I mm-camera: gyro_module_start_session: Init DSPS
07-14 14:00:46.103   217   217 E mm-camera: Failed to open sensor1 port
07-14 14:00:46.103   217   217 I mm-camera: gyro_module_start_session: dsps_proc_init() failed
07-14 14:00:46.103   217   217 I mm-camera: gyro_module_get_port: Exit failure
07-14 14:00:46.103   217   217 I mm-camera: cpp_module_start_session:352, info: starting session 1
07-14 14:00:46.113   773  1275 I ActivityManager: Killing 2255:com.google.android.apps.gcs/u0a25 (adj 15): empty #18
07-14 14:00:46.122   217  2793 I mm-camera: cpp_thread_func:55: cpp_thread entering the polling loop...
07-14 14:00:46.122   217   217 I mm-camera: cpp_module_start_session:433, info: cpp_thread created.
07-14 14:00:46.122   217   217 I mm-camera: cpp_module_start_session:436, info: session 1 started.
07-14 14:00:46.122   217   217 I mm-camera: c2d_module_start_session:246, info: starting session 1
07-14 14:00:46.122   217   217 I mm-camera: c2d_module_start_session:284, info: c2d_thread created.
07-14 14:00:46.122   217  2794 I mm-camera: c2d_thread_func:39: c2d_thread entering the polling loop...
07-14 14:00:46.124   217   217 I mm-camera: c2d_module_start_session:306, info: session 1 started.
07-14 14:00:46.125   217   217 I mm-camera-sensor: module_module_set_session_data:2667 max delay 2 report dSelay 1
07-14 14:00:46.125   217   217 D mm-camera: module_faceproc_set_session_data:1987] Per frame control 2 1
07-14 14:00:46.125   202   887 D mm-camera-intf: mm_camera_open:  opened, break out while loop
07-14 14:00:46.125  1872  1878 E ANDR-PERF-LOCK: Failed to apply optimization for resource: 4 level: 0
07-14 14:00:46.131  2754  2786 I tensorflow: CameraConnectionFragment: Opening camera preview: 3264x2448
07-14 14:00:46.139   202   887 W CameraDeviceClient: createStream: Camera 0: Forcing asynchronous mode for stream
07-14 14:00:46.139   202   887 W CameraDeviceClient: createStream: Camera 0: Overriding format 0x1 to IMPLEMENTATION_DEFINED
07-14 14:00:46.140   202  2542 E CameraDeviceClient: createStream: bufferProducer must not be null
--------- beginning of crash
07-14 14:00:46.141  2754  2786 E AndroidRuntime: FATAL EXCEPTION: CameraBackground
07-14 14:00:46.141  2754  2786 E AndroidRuntime: Process: org.tensorflow.demo, PID: 2754
07-14 14:00:46.141  2754  2786 E AndroidRuntime: java.lang.IllegalArgumentException: Bad argument passed to camera service
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.utils.CameraBinderDecorator.throwOnError(CameraBinderDecorator.java:114)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.utils.CameraBinderDecorator$CameraBinderDecoratorListener.onAfterInvocation(CameraBinderDecorator.java:73)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.utils.Decorator.invoke(Decorator.java:81)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at java.lang.reflect.Proxy.invoke(Proxy.java:393)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at $Proxy1.createStream(Unknown Source)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.impl.CameraDeviceImpl.configureStreamsChecked(CameraDeviceImpl.java:429)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.impl.CameraDeviceImpl.createCaptureSessionInternal(CameraDeviceImpl.java:561)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.impl.CameraDeviceImpl.createCaptureSession(CameraDeviceImpl.java:476)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at org.tensorflow.demo.CameraConnectionFragment.createCameraPreviewSession(CameraConnectionFragment.java:471)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at org.tensorflow.demo.CameraConnectionFragment.access$400(CameraConnectionFragment.java:63)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at org.tensorflow.demo.CameraConnectionFragment$2.onOpened(CameraConnectionFragment.java:144)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.impl.CameraDeviceImpl$1.run(CameraDeviceImpl.java:134)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.os.Handler.handleCallback(Handler.java:739)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.os.Handler.dispatchMessage(Handler.java:95)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.os.Looper.loop(Looper.java:148)
07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.os.HandlerThread.run(HandlerThread.java:61)
07-14 14:00:46.159   773   792 I ActivityManager: Displayed org.tensorflow.demo/.CameraActivity: +404ms
07-14 14:00:46.162   773  1503 W ActivityManager:   Force finishing activity org.tensorflow.demo/.CameraActivity
"
3317,handling multiple graphs,"In numerous locations in the documentation, it has been mentioned that it is possible to handle multiple `Graph`s, but I couldn't find any example. 

Since `Session` only support a single `Graph`, it seems the only way of doing it is to create multiple `Session` instances. 

Is it **safe** to have multiple instances `Session` at the same time? 
if not, what is the proper way of handling multiple `Graph`s? 

Thanks
"
3313,iOS tensforflow example ? ,"Hi,

I observed that in the latest version of tensorflow example folder, there is no iOS example, though it was available in the previous version. Could you please direct me on where do I find the iOS example for tensorflow.

Thanks  
"
3312,drawing random numbers in a loop,"Hey tf-community,

Please consider the following example:
`import tensorflow as tf`
`x = tf.random_normal(shape=(1,), mean=0.0, stddev=1.0)`
`sess = tf.Session()`
`sess.run([x for _ in xrange(4)])`

This results in a list of four identical numbers. What I would expect, however, is a list of 4 independently drawn numbers. Is this behaviour by design? And if so, is there a way to specify that I would like to have four different numbers? 

Drawing a vector of numbers is not applicable to my situation...

Thx,
Mat
"
3311,Bug with tensorflow.random_normal() when using placeholders and last dimension is 1 ,"tensorflow.shape(x) gives ? for the last dimension when the last dimension is 1.
This is a problem if you have layers or inputs which are only one dimensional. 
### Environment info

Operating System: OSX
Tensorflow 0.9.0

Installed version of CUDA and cuDNN: 
problem not related to CUDA or cuDNN

**Edit:** thanks to @cwhipkey I noticed I mischaracterized the problem, edited version below.
### Steps to reproduce

`import tensorflow as tf`
`n=1`
`x = tf.placeholder(tf.float32, shape=(None, None, n), name='x')`
`shp = tf.shape(x)`

shp is (?,?,n)  as it should be.

But then if I use shp to create a random_normal tensor of the same shape, it will fail if n==1.

`noise = tf.random_normal(shp,mean=0,stddev=1)`

`print(noise.get_shape(noise))`
has output (?,?,n) if n>1 but output (?,?,?) if n==1.

This is a problem, because if I then do 
`xtilde= x+noise`

this will give me an error if n==1.
Specifically in my case:

>   File ""/anaconda/envs/hrnn/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 630, in _dynamic_rnn_loop
>     ""Input size (depth of inputs) must be accessible via shape inference, ""
> ValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.

when I feed this xtilde to dynamic_rnn
`rnn.dynamic_rnn(rnn, xtilde,
                                                       initial_state=self.hhat_combined_init,
                                                       scope='RNN')`
I get no such error if n>1.
"
3310,warning when running commands with bazel,"Hello, I'm installing tensorflow following instructions of
https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html
especially in ""Installing from sources""

I almost encountered the below warnings when running commands with bazel
Among the warnings, I'd like to resolve the warning which says 'in includes attribute of cc_library rule //***_' resolves to '**_*' not in 'third_party'. This will be an error in the future.'

btw, what does the above warnings mean and why was the warnings occurred?
As I saw other person's console outputs through googling, many people also went through the warnings. However, many of them seem to ignore them.
I'm a little concerned because of the final sentence saying 'This will be an error in the future'
I'd appreciate any reply, thank you very much
### Environment info

Operating System: Ubuntu 14.04
Linux seslab86 3.16.0-76-generic #98~14.04.1-Ubuntu SMP Fri Jun 24 17:04:54 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

Installed version of CUDA and cuDNN: 7.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
  316 -rw-r--r-- 1 root root   322936  8 16  2015 /usr/local/cuda/lib64/libcudadevrt.a
    0 lrwxrwxrwx 1 root root       16  8 16  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
    0 lrwxrwxrwx 1 root root       19  8 16  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
  376 -rwxr-xr-x 1 root root   383336  8 16  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
  704 -rw-r--r-- 1 root root   720192  8 16  2015 /usr/local/cuda/lib64/libcudart_static.a
    0 lrwxrwxrwx 1 root root       13  4 11 01:10 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
60020 -rwxr-xr-x 1 root root 61453024  6  1 22:42 /usr/local/cuda/lib64/libcudnn.so.4
60020 -rwxr-xr-x 1 root root 61453024  6  1 22:42 /usr/local/cuda/lib64/libcudnn.so.4.0.7
    0 lrwxrwxrwx 1 root root       17  4 11 01:10 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.0.4
60016 -rwxr-xr-x 1 root root 61453024  6  1 22:42 /usr/local/cuda/lib64/libcudnn.so.5.0.4
60576 -rw-r--r-- 1 root root 62025862  6  1 22:42 /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?
1. bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

WARNING: /home/sujin/.cache/bazel/_bazel_sujin/a8907e64af45524f9c5b5e83198958ce/external/grpc/WORKSPACE:1: Workspace name in /home/sujin/.cache/bazel/_bazel_sujin/a8907e64af45524f9c5b5e83198958ce/external/grpc/WORKSPACE (@__main__) does not match the name given in the repository's definition (@grpc); this will cause a build error in future versions.
WARNING: /home/sujin/.cache/bazel/_bazel_sujin/a8907e64af45524f9c5b5e83198958ce/external/re2/WORKSPACE:1: Workspace name in /home/sujin/.cache/bazel/_bazel_sujin/a8907e64af45524f9c5b5e83198958ce/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.

WARNING: /home/sujin/Desktop/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
WARNING: /home/sujin/Desktop/tensorflow/google/protobuf/BUILD:59:16: in includes attribute of cc_library rule //google/protobuf:protobuf_lite: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.
WARNING: /home/sujin/Desktop/tensorflow/google/protobuf/BUILD:124:16: in includes attribute of cc_library rule //google/protobuf:protobuf: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.
WARNING: /home/sujin/Desktop/tensorflow/google/protobuf/BUILD:546:16: in includes attribute of cc_binary rule //google/protobuf:pyext/_message.so: 'python/' resolves to 'google/protobuf/python' not in 'third_party'. This will be an error in the future.
WARNING: /home/sujin/Desktop/tensorflow/google/protobuf/BUILD:546:16: in includes attribute of cc_binary rule //google/protobuf:pyext/_message.so: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.
WARNING: /home/sujin/Desktop/tensorflow/google/protobuf/BUILD:266:16: in includes attribute of cc_library rule //google/protobuf:protoc_lib: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.
"
3309,contrib/makefile: device_attributes.pb_text.h: No such file or directory,"### Environment info

Operating System: Arch Linux 64-bit
GCC: 6.1.1
no CUDA or cdDNN used

Tensorflow installed from Git repo sources (v0.9.0).
### Steps to reproduce

**1.** Get a clean copy tensorflow repository
**2.** Run `tensorflow/contrib/makefile/download_dependencies.sh`
**3.** Run `make -f tensorflow/contrib/makefile/Makefile`
**4.** The build sometimes fails with:

```
In file included from tensorflow/core/kernels/stack_ops.cc:21:0:
./tensorflow/core/common_runtime/device.h:38:65: fatal error: tensorflow/core/framework/device_attributes.pb_text.h: No such file or directory
 #include ""tensorflow/core/framework/device_attributes.pb_text.h""
                                                                 ^
compilation terminated.
make: *** [tensorflow/contrib/makefile/Makefile:322: tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/core/kernels/stack_ops.o] Error 1
make: *** Waiting for unfinished jobs....
```

**5.** Run `make` again and the problem disappears.
"
3308,contrib/makefile: No session factory registered for the given session options,"### Environment info

Operating System: Arch Linux 64-bit
GCC: 6.1.1
no CUDA or cuDNN used

Tensorflow installed from Git repo sources. I tried v0.9.0 and current master (`c129591`).
### Steps to reproduce

**1.** Build `contrib/makefile` (`download_dependencies.sh` + `make`)
**2.** Link produced `tensorflow-core` to a C++ project
**3.** Try to create a new TensorFlow session:

``` c++
Session* session;
Status status = NewSession(SessionOptions(), &session);
```

**4.** Compile succeeds, but running the code gives:

```
E tensorflow/core/common_runtime/session.cc:69] Not found: No session factory registered for the given session options: {target: """" config: } Registered factories are {}.
```

`tensorflow/contrib/makefile/gen/bin/benchmark` seems to be working.
"
3307,"NaN values in the learnable parameters with custom initialization, along with lasso regularization","From what I read online, getting NaN cost values can happen if someone uses a custom cross entropy calculation while doing classification. However, I use the built-in cross entropy calculation provided.

My problem is different. I have a network that consists of an RNN and a convolutional layer before that. When I initialize the convolutional layer with random values(e.g., normal random or uniform random), I do not experience any problem. However, I use a custom initialization, and start getting NaN gradients right away(i.e., starting from the first batch).

My filter initialization is as follows: All values in the filter are zero, except a single value is 1. When I initialize the filters in this manner, I start to get NaN gradients starting from the first batch, hence NaN weights and NaN cost in the following batches. 
### Environment info

Operating System: Mac v10.11.3 (El Capitan)

The output of `ls -l /path/to/cuda/lib/libcud*`:

-rw-r--r-- 1 root root 189170 Mar 24 16:02 libcudadevrt.a
lrwxrwxrwx 1 root root     16 Mar 24 16:02 libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Mar 24 16:02 libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Mar 24 16:02 libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Mar 24 16:02 libcudart_static.a
- The tensorflow version is: 0.9.0rc0

The whole code is quite messy and complex, . But reproducing the code should not be hard: I initialize convolutional filters with all zeros but one ""1"" value, and I get nan values as gradients in the locations where 0's appear. 

One thing to note is that I apply group lasso regularization to the convolutional filter weights. I realized when regularization lambda is set to a small value, (like 10e-3), the problem did not occur. However, when I chose values that have larger order of magnitude (like 10e-2 or 1), I observed this problem. Values other than the group initialized as ""1"" becomes all Nan.

To exemplify, suppose I initialize the weights as the matrix on the top, and each column is a group (in group lasso objective). After the first batch of data, the matrix on the bottom is what I get: 

0 0 0 0 0
0 0 0 0 0
0 0 1 0 0
0 0 0 0 0
0 0 0 0 0

becomes:        

NaN NaN 0.3 NaN NaN 
NaN NaN 0.7 NaN NaN
NaN NaN  0.1  NaN NaN
NaN NaN 0.5 NaN NaN
NaN NaN 0.2 NaN NaN 

Long story short; I know how to avoid this problem (using smaller lambda values), but I just wanted to know if there is an explanation for why this problem occur. Is it because of a numerical error, or it is because I am doing something wrong?
"
3306,".Save, .Restore for contrib.learn.DNNClassifier","The older functions like skflow.TensorFlowDNNClassifier had methods .save and .restore.  These were supposedly migrated over to the contrib.learn functions, but there are no longer save and restore methods that I can find.  Is there a new protocol for saving the graph and variables with the new contrib.learn package?   
"
3305, .,
3304,Ran out of GPU memory,"I have a network similar to A3C network described [here](http://arxiv.org/abs/1602.01783), with lots of syncing and copying tensor values between different duplicates of the model. The code crashes with a `Ran out of memory` exception (see below). This might be a little bit hard to reproduce somewhere other than my machine (since the code is not open source ... yet) but I would be more than happy to provide any logs or help to track down the issue.

What happens is that I receiving a lot of `pool_allocator` messages like below:

> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 40664481 get requests, put_count=40664484 evicted_count=39000 eviction_rate=0.000959068 and unsatisfied allocation rate=0.000959265

and then finally it crashes like this:

> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (256):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (512):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (1024):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (2048):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (4096):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (8192):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (16384):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (32768):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (65536):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (131072):    Total Chunks: 1, Chunks in use: 0 204.5KiB allocated for chunks. 1.0KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (262144):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (524288):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (1048576):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (2097152):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (4194304):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (8388608):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (16777216):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (33554432):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (67108864):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (134217728):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:656] Bin for 220.5KiB was 128.0KiB, Chunk State: 
> I tensorflow/core/common_runtime/bfc_allocator.cc:662]   Size: 204.5KiB | Requested Size: 1.0KiB | in_use: 0, prev:   Size: 16.0KiB | Requested Size: 16.0KiB | in_use: 1, next:   Size: 16.0KiB | Requested Size: 16.0KiB | in_use: 1
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060000 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060100 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060200 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060300 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060400 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060500 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060600 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060700 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060800 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060900 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060a00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a064a00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a068a00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a070a00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a078a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a440a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a808a00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a808e00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a809200 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a809e00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a80aa00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a80ea00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a812a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a813600 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a81b600 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a823600 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0abeb600 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afb3600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afb3a00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afb3e00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afb4a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afb5600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afb5a00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afbda00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afc1a00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afc1e00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afc9e00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afcde00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afcea00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afcee00 of size 58624
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afdd300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afddf00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afe1f00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afe5f00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afe6b00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afe6f00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0afeef00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0aff2f00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0aff3b00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0aff3f00 of size 39168
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0affd800 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0affdc00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b005c00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b009c00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b00a800 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b00ac00 of size 58624
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b019100 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b019d00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b01dd00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b01e900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b01ed00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b022d00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b023900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b023d00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b02bd00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b02fd00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b030900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b030d00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b038d00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b03cd00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b03d900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b03dd00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b045d00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b049d00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b04a900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b04ad00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b052d00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b056d00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b057900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b057d00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b05fd00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b063d00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b064900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b064d00 of size 51968
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b071800 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b079800 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b07d800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b07e400 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b07e800 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b082800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b083400 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b083800 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b08b800 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b08f800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b090400 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b090800 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b094800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b095400 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b095800 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b09d800 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0a1800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0a2400 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0a2800 of size 39168
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0ac100 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0b4100 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0b8100 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0b8d00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0b9100 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0c1100 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0c5100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0c5500 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0cd500 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0d1500 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0d2100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0d2500 of size 58624
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0e0a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0e1600 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0e5600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0e5a00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0e9a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0ea600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0eaa00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0f2a00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0f6a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0f7600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b0f7a00 of size 39168
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b101300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b109300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b10d300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b10df00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b10e300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b116300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b11a300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b11af00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b11b300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b123300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b127300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b127f00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b128300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b130300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b134300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b134f00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b135300 of size 41984
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b13f700 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b147700 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b148300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b14c300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b14cf00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b14d300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b155300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b159300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b159f00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b15a300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b162300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b166300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b166f00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b167300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b16f300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b173300 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b173700 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b17b700 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b17f700 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b180300 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b180700 of size 58624
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b18ec00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b18f800 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b193800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b194400 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b194800 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b19c800 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1a0800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1a1400 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1a1800 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1a9800 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1ad800 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1adc00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1b5c00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1b9c00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1ba800 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1bac00 of size 58624
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1c9100 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1c9d00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1cdd00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1ce900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1ced00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1d2d00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1d6d00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1d7900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1d7d00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1dfd00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1e3d00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1e4900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1e4d00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1ecd00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1f0d00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1f1900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1f1d00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1f9d00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1fdd00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1fe900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b1fed00 of size 29184
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b205f00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b20df00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b20e300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b216300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b21a300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b21af00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b21b300 of size 58624
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b229800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b22a400 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b22a800 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b232800 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b236800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b237400 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b237800 of size 58624
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b245d00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b246900 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b247500 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b247900 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b24f900 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b253900 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b254500 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b254900 of size 55552
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b262200 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b26a200 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b26e200 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b26ee00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b276e00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b27ae00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b27ba00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b27be00 of size 59648
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b28a700 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b28ab00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b28eb00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b28f700 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b28fb00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b297b00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b29bb00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b29c700 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b29cb00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2a4b00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2a8b00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2a9700 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2a9b00 of size 45568
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2b4d00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2b8d00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2bcd00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2bd900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2bdd00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2c5d00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2c9d00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2ca100 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2d2100 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2d6100 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2d6d00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2d7100 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2df100 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2e3100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2e3500 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2eb500 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2ef500 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2f0100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2f0500 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2f8500 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2fc500 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2fd100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b2fd500 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b305500 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b309500 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b30a100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b30a500 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b312500 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b316500 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b317100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b317500 of size 21248
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b31c800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b31d400 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b31e000 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b326000 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b326c00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b327000 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b32b000 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b32bc00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b32c000 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b334000 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b338000 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b338c00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b339000 of size 39168
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b342900 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b34a900 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b34e900 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b34f500 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b34f900 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b357900 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b35b900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b35bd00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b363d00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b367d00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b368900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b368d00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b370d00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b374d00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b375900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b375d00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b37dd00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b381d00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b382900 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b382d00 of size 26880
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b389600 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b38a200 of size 33792
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b392600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b392a00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b396a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0b75ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0bb26a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0beeea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0c2b6a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0c67ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0ca46a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0ce0ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0d1d6a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0d59ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0d966a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0dd2ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0e0f6a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0e4bea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0e886a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0ec4ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0f016a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0f3dea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0f7a6a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0fb6ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0ff36a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb102fea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb106c6a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb10a8ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb10e56a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1121ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb115e6a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb119aea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb11d76a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1213ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb12506a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb128cea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb12c96a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1305ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb13426a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb137eea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb13bb6a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb13f7ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb14346a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1470ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb14ad6a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb14e9ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb15266a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1562ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb159f6a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb15dbea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb16186a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1654ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb16916a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb16cdea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb170a6a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1746ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb17836a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb17bfea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb17fc6a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1838ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb18756a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb18b1ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb18ee6a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb192aea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb19676a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb19a3ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb19e06a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1a1cea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1a596a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1a95ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ad26a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1b0eea00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1b0ef600 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1b4b7600 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1b87f600 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1bc47600 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1bc4f600 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c017600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c017a00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c01fa00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c023a00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c023e00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c02be00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c02fe00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c033e00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c034a00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c034e00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c03ce00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c040e00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c041a00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c041e00 of size 51712
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c04e800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c04f400 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c417400 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c418000 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7e0000 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7e0400 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7e8400 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7ec400 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7ed000 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7ed400 of size 58624
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7fb900 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1c7fc500 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1cbc4500 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1cf8c500 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d354500 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d358500 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d359100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d359500 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d361500 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d365500 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d366100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d366500 of size 56320
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d374100 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1d73c100 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1db04100 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1db08100 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ded0100 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ded0d00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ded1100 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ded9100 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1dedd100 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e2a5100 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e2a5d00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e2a6100 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e2ae100 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e2b2100 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e67a100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e67a500 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e682500 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e686500 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e687100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e687500 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e68f500 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e693500 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e694100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e694500 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e69c500 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e6a0500 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e6a1100 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e6a1500 of size 65024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e6b1300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1e6b1f00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ea79f00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1ee41f00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f209f00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f20df00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f5d5f00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f5d6b00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f5d6f00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f5def00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f5e2f00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9aaf00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9abb00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9abf00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9aff00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9b0b00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9b0f00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9b4f00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9b5b00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9b5f00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9bdf00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9c1f00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9c2b00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9c2f00 of size 39168
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9cc800 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9d4800 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9d8800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9d9400 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9d9800 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9e1800 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9e5800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9e6400 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9e6800 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9ee800 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9f2800 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9f3400 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9f3800 of size 45568
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1f9fea00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1fa06a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb1fdcea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb20196a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2055ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb20926a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb20ceea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb210b6a00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb210baa00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21482a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21483600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21483a00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2148ba00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2148fa00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21857a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21858600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21858a00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21860a00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21864a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21c2ca00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21c2d600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21c2da00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21c35a00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb21c39a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22001a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22002600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22002a00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2200aa00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2200ea00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb223d6a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb223d7600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb223d7a00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb223dfa00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb223e3a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb227aba00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb227ac600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb227aca00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb227b4a00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb227b8a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b80a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b81600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b81a00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b85a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b86600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b86a00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b8ea00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b92a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b93600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b93a00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b9ba00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22b9fa00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22ba0600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22ba0a00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22ba8a00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22baca00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22bad600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22bada00 of size 45568
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22bb8c00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22bc0c00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb22f88c00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23350c00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23718c00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23ae0c00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23ae4c00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23eacc00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23ead800 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23eadc00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23eb5c00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb23eb9c00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24281c00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24282800 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24282c00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2428ac00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2428ec00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24656c00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24657800 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24657c00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2465fc00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24663c00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a2bc00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a2c000 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a34000 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a38000 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a38c00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a39000 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a41000 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a45000 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a45c00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a46000 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a4e000 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a52000 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a52c00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a53000 of size 65024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a62e00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24a63a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb24e2ba00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb251f3a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb255bba00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb255bfa00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25987a00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25988600 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25988a00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25990a00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25994a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d5ca00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d5ce00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d60e00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d61200 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d69200 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d6d200 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d6de00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d6e200 of size 58624
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d7c700 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d7d300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d81300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d81f00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d82300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d8a300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d8e300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d8ef00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d8f300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d97300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d9b300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d9bf00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25d9c300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25da4300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25da4f00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25da5300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dad300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25db1300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25db1f00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25db2300 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dba300 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dbe300 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dbef00 of size 1024
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dbf300 of size 47872
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dcae00 of size 3072
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dcba00 of size 32768
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb25dd3a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2619ba00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb26563a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb2692ba00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb26cf3a00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb270bba00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb270f2c00 of size 16384
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb270f6c00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb274bec00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb27886c00 of size 3964928
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb27c4ec00 of size 4219136
> I tensorflow/core/common_runtime/bfc_allocator.cc:683] Free at 0xb270bfa00 of size 209408
> I tensorflow/core/common_runtime/bfc_allocator.cc:689]      Summary of in-use Chunks by size: 
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 10 Chunks of size 256 totalling 2.5KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 125 Chunks of size 1024 totalling 125.0KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 125 Chunks of size 3072 totalling 375.0KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 122 Chunks of size 16384 totalling 1.91MiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 21248 totalling 20.8KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 26880 totalling 26.2KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 29184 totalling 28.5KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 98 Chunks of size 32768 totalling 3.06MiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 33792 totalling 33.0KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 5 Chunks of size 39168 totalling 191.2KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 41984 totalling 41.0KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 3 Chunks of size 45568 totalling 133.5KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 47872 totalling 46.8KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 51712 totalling 50.5KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 51968 totalling 50.8KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 55552 totalling 54.2KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 56320 totalling 55.0KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 9 Chunks of size 58624 totalling 515.2KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 59648 totalling 58.2KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 2 Chunks of size 65024 totalling 127.0KiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 124 Chunks of size 3964928 totalling 468.88MiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 4219136 totalling 4.02MiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 479.76MiB
> I tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats: 
> Limit:                   503270604
> InUse:                   503061248
> MaxInUse:                503061248
> NumAllocs:                20717987
> MaxAllocSize:              4219136
> 
> W tensorflow/core/common_runtime/bfc_allocator.cc:270] ****************************************************************************************************
> W tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 220.5KiB.  See logs for memory state.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (256):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (512):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (1024):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (2048):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (4096):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (8192):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (16384):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (32768):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (65536):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (131072):    Total Chunks: 1, Chunks in use: 0 204.5KiB allocated for chunks. 1.0KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (262144):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (524288):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (1048576):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (2097152):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (4194304):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (8388608):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (16777216):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (33554432):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (67108864):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (134217728):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
> I tensorflow/core/common_runtime/bfc_allocator.cc:656] Bin for 330.8KiB was 256.0KiB, Chunk State: 
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060000 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060100 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060200 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060300 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060400 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060500 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060600 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060700 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060800 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060900 of size 256
> I tensorflow/core/common_runtime/bfc_allocator.cc:674] Chunk at 0xb0a060a00 of size 16384
> Exception in thread Predictor3:
> Traceback (most recent call last):
>   File ""/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 715, in _do_call
>     return fn(*args)
>   File ""/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 697, in _run_fn
>     status, run_metadata)
>   File ""/home/mbz/anaconda3/lib/python3.5/contextlib.py"", line 66, in __exit__
>     next(self.gen)
>   File ""/home/mbz/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors.py"", line 450, in raise_exception_on_not_ok_status
>     pywrap_tensorflow.TF_GetCode(status))
> tensorflow.python.framework.errors.InternalError: Dst tensor is not initialized.
>      [[Node: _recv_network1/X_0/_28 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:1"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_9__recv_network1/X_0"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:1""]()]]
>      [[Node: network1/Squeeze/_30 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:1"", send_device_incarnation=1, tensor_name=""edge_10_network1/Squeeze"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64//libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64//libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64//libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64//libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64//libcudart_static.a
-rwxr-xr-x 1 root root 61453024 May 19 18:24 /usr/local/cuda/lib64//libcudnn.so
-rwxr-xr-x 1 root root 61453024 May 19 18:24 /usr/local/cuda/lib64//libcudnn.so.4
-rwxr-xr-x 1 root root 61453024 May 19 18:24 /usr/local/cuda/lib64//libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 May 19 18:24 /usr/local/cuda/lib64//libcudnn_static.a

If installed from binary pip package, provide:
Anaconda3 (python3)
TF v0.9 
"
3302,"[Tensorboard] Make long column names in ""Images"" tab more readable","Currently it's difficult to read long experiment names in ""Images"" tab due to the lack of word-break and adaptive cell height: 
![image](https://cloud.githubusercontent.com/assets/1441616/16820454/e5bbb9c8-4905-11e6-908f-25caa0ba9027.png)

Adding `word-break: break-all;` to and removing `height: 30px;` from the css class `.run-name-cell.tf-image-grid` will make it easier to read: 
![image](https://cloud.githubusercontent.com/assets/1441616/16820551/852360ba-4906-11e6-9a93-af92ae1060e1.png)
"
3300,Error trying to predict using skflow example dnn_autoencoder_iris,"I am trying to generate new data using trained construction layer using dnn autoencoder on iris data. I run into a couple issues detailed after the system and installation information. 
### Environment info

Operating System:

Mac OSx 10.11.5

I installed from the source code and the commit hash is- 
bef942ca38d03bda48e3f39d3473973f0219933a

**Error 1:** 
### Steps to reproduce
- Add the following line to the file `tensorflow/tensorflow/examples/skflow/dnn_autoencoder_iris.py`

```
new_data = autoencoder.generate()
print new_data
```
- Run the above file.
  Error: `get_tensor_value()` is not a class method. 

I tried changing  the function name to `get_tensor()` which actually exists in the parent class. 

I get the following error trace 

```
WARNING:tensorflow:learn.ops.dnn is deprecated,     please use contrib.layers.dnn.
Traceback (most recent call last):
  File ""/Users/nbajaj/tensorflow_git/tensorflow/tensorflow/examples/skflow/dnn_autoencoder_rfk.py"", line 56, in <module>
    new_data = autoencoder.generate()
  File ""/Users/nbajaj/tensorflow_git/tvenv/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/autoencoder.py"", line 97, in generate
    ""encoder/dnn/layer%d/Linear/Bias:0"" % last_layer)
  File ""/Users/nbajaj/tensorflow_git/tvenv/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 270, in get_tensor
    return self._graph.get_tensor_by_name(name)
  File ""/Users/nbajaj/tensorflow_git/tvenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2519, in get_tensor_by_name
    return self.as_graph_element(name, allow_tensor=True, allow_operation=False)
  File ""/Users/nbajaj/tensorflow_git/tvenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2373, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""/Users/nbajaj/tensorflow_git/tvenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2415, in _as_graph_element_locked
    ""graph."" % (repr(name), repr(op_name)))
KeyError: ""The name 'encoder/dnn/layer1/Linear/Bias:0' refers to a Tensor which does not exist. The operation, 'encoder/dnn/layer1/Linear/Bias', does not exist in the graph.""
```

Then I changed the line 
`new_data = autoencoder.generate()` -> `new_data = autoencoder.generate(hideen=transformed)` so that the above code path doesn't get executed in the first place. 

Then I get the following error trace- 

```
Traceback (most recent call last):
  File ""dnn_autoencoder_rfk.py"", line 56, in <module>
    new_data = autoencoder.generate(hidden=[10, 20])
  File ""/Users/nbajaj/tensorflow_git/tvenv/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/autoencoder.py"", line 101, in generate
    return self._session.run(self.decoder, feed_dict={self.encoder: hidden})
AttributeError: 'TensorFlowDNNAutoencoder' object has no attribute '_session'
```

Please let me know if I could try something else or there is anyway I can help to fix this. 
"
3299,Frequent dynamic memory allocation in tensorflow/core/kernels/conv_ops.cc?,"I am looking at the code in tensorflow/core/kernels/conv_ops.cc, Compute(OpKernelContext\* context)  function:
`
  // Output tensor is of the following dimensions:                          
  // [ in_batch, out_rows, out_cols, out_depth ]                            
  Tensor* output = nullptr;                                                 
  OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output)); 
`
Does it mean each CONV OP will always dynamic allocate output tensor (including the buffer as the size of in_batch x out_rows x out_cols x out_depth) even if I load the graph once but iterate multiple times to inference multiple images? Where the memory was freed? 

Thanks.
"
3295,"tf.train.Server.create_local_server  has two problems :1)performance drop 2 times compare to without it,2) gpu memory fraction limitations fails. ","tf.train.Server.create_local_server has two problems :1)performance drop 2 times compare to without it,2) gpu memory fraction limitations fails

my model is a dnn network with 12 layers, same as the alphago policy network!
## code1: whitout server = tf.train.Server.create_local_server(start = True)

```
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)

sess =  tf.Session(config=tf.ConfigProto(log_device_placement=True,allow_soft_placement=True,gpu_options=gpu_options))
```
## \- code2:  using server = tf.train.Server.create_local_server(start = True)

```
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)

    server = tf.train.Server.create_local_server(start = True)

    sess= tf.Session(target=server.target,config=tf.ConfigProto(log_device_placement=True,allow_soft_placement=True,gpu_options=gpu_options))
```
# Questions:

**1. code2 performance drop 3 times compare to code1( 3 steps/seconds vs 11 steps/seconds), why?**
**2. code2 will broke the  limitations of gpu memory. while code1 is ok**

ps: Is this relevant to this issue than the training data is read from queue?
"
3293,Slicing of rank>=6 tensor?,"Currently it throws a not implemented error ""inputs rank not in [0,5]"".
"
3291,How to create an op like conv_ops in tensorflow?,"Notice that I'm not looking for a tutorial like [this](https://github.com/jikexueyuanwiki/tensorflow-zh/blob/master/SOURCE/how_tos/adding_an_op/index.md).
**What I'm trying to do**

I'm new to C++ and bazel and I want to make some change on the convolution operation in tensorflow, so I decide that my first step is to create an ops just like it.

**What I have done**

I copied conv_ops.cc from //tensorflow/core/kernels and change the name of the ops registrated in my new_conv_ops.cc. I also changed some name of the functions in the file to avoid duplication. And here is my BUILD file. 
![qq 20160713201655](https://cloud.githubusercontent.com/assets/9963412/16803076/c495f610-4936-11e6-9e28-9aa27dd55e4d.png)

As you can see, I copy the deps attributes of conv_ops from //tensorflow/core/kernels/BUILD. Then I use ""bazel build -c opt //tensorflow/core/user_ops:new_conv_ops.so"" to build the new op.

**What my problem is**

Then I got this error.
![](https://cloud.githubusercontent.com/assets/9963412/16803048/9b960250-4936-11e6-90ab-7e7cd3b81b96.png)

I tried to delete bounds_check and got same error for the next deps. Then I realize that there is some problem for including h files in //tensorflow/core/kernels from //tensorflow/core/user_ops. So how can I perfectely create a new op excatcly like conv_ops?

---
"
3290,I think tf.nn.moments() produces negative variance.," tf.nn.normalize_moments() calculates variance like this.

```
variance = math_ops.sub(
        math_ops.mul(variance_ss, divisor),
        math_ops.square(shifted_mean),
        name=""variance"")
```

This code can cause negative variance due to floating point precision problem.

Thanks.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

tf.Print output for variance from tf.nn.moments().

```
I tensorflow/core/kernels/logging_ops.cc:79] variance[-0.0021057129 0.00061035156 -0.00024414062...]
I tensorflow/core/kernels/logging_ops.cc:79] variance[14.041901 5.8100648 60.691284...]
I tensorflow/core/kernels/logging_ops.cc:79] variance[0.46612549 0.017944336 0.87060547...]
```
"
3289,tensorflow mobile : makefile raspberry pi - protobuf build error,"### Environment info

Operating System:
pi@raspberrypi:~ $ cat /proc/version
Linux version 4.4.13-v7+ (dc4@dc4-XPS13-9333) (gcc version 4.9.3 (crosstool-NG crosstool-ng-1.22.0-88-g8460611) ) #894 SMP Mon Jun 13 13:13:27 BST 2016
### Steps to reproduce
1. Follow instructions under Raspberry Pi section - https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile
2. pi@raspberrypi:~/tensorflow/tensorflow/contrib/makefile/downloads/protobuf $ sudo ./autogen.sh
   Google Mock not present.  Fetching gmock-1.7.0 from the web...
   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                  Dload  Upload   Total   Spent    Left  Speed
   100 2116k  100 2116k    0     0  1169k      0  0:00:01  0:00:01 --:--:-- 1170k
3. autoreconf -f -i -Wall,no-obsolete
   ./autogen.sh: 43: ./autogen.sh: autoreconf: not found
### What have you tried?
1. Searched for similar issues.
"
3287,tf.cond and tf.case execute all branches,"When I run:

``` python
import tensorflow as tf


X1 = tf.Variable(1.)
X2 = tf.Variable(1.)

cond_value = tf.Variable(True)

assign_1 = tf.assign(X1, 2.)
assign_2 = tf.assign(X2, 2.)

with tf.control_dependencies([assign_1]):
    result_1 = tf.identity(X1)
with tf.control_dependencies([assign_2]):
    result_2 = tf.identity(X2)

cond_result = tf.cond(cond_value, lambda: result_1, lambda: result_2)

with tf.Session() as sesh:
    sesh.run(tf.initialize_all_variables())
    sesh.run(cond_result)
    print(sesh.run(X1), sesh.run(X2))
```

my expected output is: 2.0 1.0 but my actual output is 2.0 2.0. I need control flow in my graph that actually controls which nodes get executed, not just selects from a list of tensors. Am I missing some sort of operation here?
"
3285,How to install with GLIBC_2.12?,"I install it directly with conda

And get ""version `GLIBC_2.17' not found,required by _pywrap_tensorflow.so""

I use LD_PRELOAD to load GLIBC_2.17

And get ""__vdso_time: invalid mode for dlopen(): Invalid argument""

I try to install from the source, but bazel require GLIBC_2.14

What should I do?

---

```
uname -a
Linux mu01 2.6.32-358.el6.x86_64 #1 SMP Tue Jan 29 11:47:41 EST 2013 x86_64 x86_64 x86_64 GNU/Linux
```

and the version of glibc is 2.12
"
3280,Default env python maybe different from python selected in config step,"Python that is default in the environment maybe different from the one selected in the  configure step. [File](https://github.com/tensorflow/tensorflow/blob/master/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc)
calls `#!/usr/bin/env python`, it should instead be the one defined in the configuration step.
"
3278,Implement 3D data for LSTM RNN -- request,"I'm new to this, and I'm not sure where is the appropriate place to make a dev requests. If I am in the wrong place, can someone please redirect me?

I am not an experienced Tensorflow dev or I would try to build this myself, but I think it is a really interesting idea and I would love for another dev to build it. 

The idea is for an LSTM RNN to accept 3D data -- such as video frames. I'm interested in papers such as [this](http://cvgl.stanford.edu/papers/CVPR16_Social_LSTM.pdf), where LSTM RNN's are used for object tracking. Also [this](http://mediatum.ub.tum.de/doc/1138498/100891.pdf) paper.

Is there a way to do this already in Tensorflow?

I know I can flatten data, but that kind of defeats the point. I want a 3D network. In other words, please look at the attached picture for what I am envisioning. 

![file_000](https://cloud.githubusercontent.com/assets/3602993/16751849/9e9e25fa-47aa-11e6-89b3-ed4fe4b6b174.jpeg)

Each frame is a full layer (in a horizontal direction). The second layer has inputs from both the second frame and the outputs from the first frame.
"
3277,Broadcast 0-rank tensors when computing gradients for tf.nn.relu,"### Environment info

Operating System: OSX (macOS....?), CPU only, version 0.9.0

Perhaps this is desired behavior, but I would have much appreciated a more descriptive warning at least, which would have saved much debugging.  

I haven't found a small reproducible case for this: but in the code I originally found this bug, no error is raised as the other variables are trained, leaving me scratching my head as to why the linear rectified variable was not being trained. 

The same issue also occurs for tf.nn.softplus, and perhaps other methods as well. 
### Steps to reproduce

```
import tensorflow as tf
sess = tf.Session()

x = tf.Variable(100.)
y = tf.nn.relu(x)
loss = y ** 2
optimizer = tf.train.AdamOptimizer(learning_rate=0.1)
train_op = optimizer.minimize(loss)
sess.run(tf.initialize_all_variables())

sess.run(train_op)

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
    729     try:
--> 730       return fn(*args)
    731     except errors.OpError as e:

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
    711                                  feed_dict, fetch_list, target_list,
--> 712                                  status, run_metadata)
    713 

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/contextlib.py in __exit__(self, type, value, traceback)
     65             try:
---> 66                 next(self.gen)
     67             except StopIteration:

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()
    449           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 450           pywrap_tensorflow.TF_GetCode(status))
    451   finally:

InvalidArgumentError: We only handle up to Tensor::dims() up to 8, not 0
     [[Node: gradients_29/Relu_5_grad/ReluGrad = ReluGrad[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](gradients_29/pow_9_grad/tuple/control_dependency, Relu_5)]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-51-ea082b2869a4> in <module>()
----> 1 sess.run(train_op)

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    380     try:
    381       result = self._run(None, fetches, feed_dict, options_ptr,
--> 382                          run_metadata_ptr)
    383       if run_metadata:
    384         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
    653     movers = self._update_with_movers(feed_dict_string, feed_map)
    654     results = self._do_run(handle, target_list, unique_fetches,
--> 655                            feed_dict_string, options, run_metadata)
    656 
    657     # User may have fetched the same tensor multiple times, but we

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
    721     if handle is None:
    722       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
--> 723                            target_list, options, run_metadata)
    724     else:
    725       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
    741         except KeyError:
    742           pass
--> 743       raise type(e)(node_def, op, message)
    744 
    745   def _extend_graph(self):

InvalidArgumentError: We only handle up to Tensor::dims() up to 8, not 0
     [[Node: gradients_29/Relu_5_grad/ReluGrad = ReluGrad[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](gradients_29/pow_9_grad/tuple/control_dependency, Relu_5)]]
Caused by op 'gradients_29/Relu_5_grad/ReluGrad', defined at:
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/runpy.py"", line 170, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/traitlets/config/application.py"", line 596, in launch_instance
    app.start()
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/kernelapp.py"", line 442, in start
    ioloop.IOLoop.instance().start()
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/zmq/eventloop/ioloop.py"", line 162, in start
    super(ZMQIOLoop, self).start()
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tornado/ioloop.py"", line 883, in start
    handler_func(fd_obj, events)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/kernelbase.py"", line 391, in execute_request
    user_expressions, allow_stdin)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/ipkernel.py"", line 199, in do_execute
    shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/IPython/core/interactiveshell.py"", line 2723, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/IPython/core/interactiveshell.py"", line 2825, in run_ast_nodes
    if self.run_code(code, result):
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/IPython/core/interactiveshell.py"", line 2885, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-49-21a2f038fac9>"", line 5, in <module>
    train_op = optimizer.minimize(loss)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py"", line 193, in minimize
    grad_loss=grad_loss)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py"", line 250, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/ops/gradients.py"", line 482, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/ops/nn_grad.py"", line 233, in _ReluGrad
    return gen_nn_ops._relu_grad(grad, op.outputs[0])
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1374, in _relu_grad
    features=features, name=name)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2297, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1231, in __init__
    self._traceback = _extract_stack()

...which was originally created as op 'Relu_5', defined at:
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/runpy.py"", line 170, in _run_module_as_main
    ""__main__"", mod_spec)
[elided 17 identical lines from previous traceback]
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/IPython/core/interactiveshell.py"", line 2885, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-49-21a2f038fac9>"", line 2, in <module>
    y = tf.nn.relu(x)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1312, in relu
    result = _op_def_lib.apply_op(""Relu"", features=features, name=name)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2297, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1231, in __init__
    self._traceback = _extract_stack()
```
### What have you tried?

The problem is resolved by expanding the dimensions of `x`:

```
import tensorflow as tf
sess = tf.Session()

x = tf.Variable(100.)
y = tf.nn.relu(tf.expand_dims(x, 0))
loss = y ** 2
optimizer = tf.train.AdamOptimizer(learning_rate=0.1)
train_op = optimizer.minimize(loss)
sess.run(tf.initialize_all_variables())

sess.run(train_op)
# runs fine
```

I wonder if it would be possible to do this automatically? 
"
3276,Trouble building from source: import tensorflow fails (from any directory),"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 7.5/5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root 189170 Oct  8  2015 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Oct  8  2015 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Oct  8  2015 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Oct  8  2015 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Oct  8  2015 /usr/local/cuda/lib/libcudart_static.a
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   Traceback (most recent call last):
   File ""<string>"", line 1, in <module>
   ImportError: No module named tensorflow
   If installed from sources, provide the commit hash: (most recent: b62f19cdc7672ff31b90b4f2b7aad870849be3e0)
### Steps to reproduce
1.  Created an empty conda environment only seeded w/ python 2.7.5 + anaconda
2. Installed numpy scipy
3. Correctly configured w/ ./configure
4. Ran the exact bazel build command provided on the site from root of tensorflow cloned directory
5. import tensorflow fails (from any directory) AND conda list or pip list do not show tensorflow after installation.  (Yes, I checked to make sure that the ./configure had the right address matching the output of which python)
### What have you tried?
1. Creating new conda env, to see if it would help. Don't have access to virtualenv on my machine nor do I have sudo access.
"
3273,Cannot build from source,"Cannot build from source
### Environment info

Operating System: Arch Linux

Installed version of CUDA and cuDNN: 
7.5

(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rwxr-xr-x 1 root root 311596 May  1 07:04 /opt/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 May  1 07:04 /opt/cuda/lib/libcudart_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.9.0rc0

If installed from sources, provide the commit hash:
ecdb06c03db58daef5a8271bdef9f85c3bf28d08
### Steps to reproduce
1. bazel build -c opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package
### What have you tried?
1. bazel build -c opt --genrule_strategy=standalone --spawn_strategy=standalone --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

```
ERROR: /home/bernardo/.cache/bazel/_bazel_bernardo/6e092ee851f20b3b3e86c2bd0d1d1759/external/protobuf/BUILD:331:1: C++ compilation of rule '@protobuf//:protoc' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/bernardo/.cache/bazel/_bazel_bernardo/6e092ee851f20b3b3e86c2bd0d1d1759/tensorflow && \
  exec env - \
    PATH=/opt/cuda/bin/:/usr/local/sbin:/usr/local/bin:/usr/bin:/snap/bin:/opt/cuda/bin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' -iquote external/protobuf -iquote bazel-out/host/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/host/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers '-frandom-seed=bazel-out/host/bin/external/protobuf/_objs/protoc/external/protobuf/src/google/protobuf/compiler/main.o' -MD -MF bazel-out/host/bin/external/protobuf/_objs/protoc/external/protobuf/src/google/protobuf/compiler/main.d -c external/protobuf/src/google/protobuf/compiler/main.cc -o bazel-out/host/bin/external/protobuf/_objs/protoc/external/protobuf/src/google/protobuf/compiler/main.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
gcc: error trying to exec 'cc1plus': execvp: No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1.540s, Critical Path: 0.24s
```
"
3271,Reverse for complex numbers,"tf.reverse does not seem to be implemented for complex numbers

```
w_real = tf.Variable(tf.truncated_normal([10], stddev=0.1, dtype=tf.float32))
w_imag = tf.Variable(tf.truncated_normal([10], stddev=0.1, dtype=tf.float32))
w = tf.complex(w_real, w_imag)
w_rev = tf.reverse(w, [True])
```

I came across this needing to construct a matrix that is conjugate symmetric, but this was also referenced on StackOverflow : [http://stackoverflow.com/questions/38145235/why-cant-i-reverse-a-sequence-of-complex-numbers-in-tensorflow](http://stackoverflow.com/questions/38145235/why-cant-i-reverse-a-sequence-of-complex-numbers-in-tensorflow)
"
3270,Loading Multiple models into the same session of tensorflow,"I have trained two models. en-fr and fr-en models. The fr-en model has different vocab size compared to the en-fr model. The first model is being loaded properly. It crashes while loading the second one. I have trained both the models separately. Please check the log file attached to see the error logs. kindly tell me the right way to go ahead.

I want to create a webservice for en-rf and fr-en translation. I ahve to load the models in a session for this, which is causing the problem. below is the piece of code. I am using the translate.py provided by tensorflow and the methods available in it.

```
`global en_fr_sess

 if en_fr_sess==None:
 en_fr_sess = tf.Session()

 global en_fr_model
 global en_fr_en_vocab_path
 global en_fr_fr_vocab_path

 en_fr_model = create_model(en_fr_sess, True)
 en_fr_model.batch_size = 1  
 fr_en_model = fr_en_create_model(en_fr_sess, True)
 fr_en_model.batch_size = 1`
```

I am able to run both the models separately and generate the translations. However, when I try to load both the models in the same session or even a different session one after the other, I get the following error

```
`ValueError: Variable embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:`
`File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/translate/seq2seq_model.py"", line 113, in seq2seq_f
feed_previous=do_decode)`
`File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/translate/seq2seq_model.py"", line 136, in <lambda>
self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),`
`File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/translate/seq2seq_model.py"", line 137, in __init__
softmax_loss_function=softmax_loss_function)`
```

Please find the detailed log file attached too. Kindly give me the inputs on how to proceed further. 
[out.txt](https://github.com/tensorflow/tensorflow/files/357036/out.txt)
"
3268,Timeline's reported memory usage not properly displayed in Chrome,"I am attempting to debug out-of-memory issues using the recently introduced support for timeline:

```
run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
run_metadata = tf.RunMetadata()
sess.run(..., options=run_options, run_metadata=run_metadata)
train_writer.add_run_metadata(run_metadata, 'step' + repr(i))
tl = timeline.Timeline(run_metadata.step_stats)
trace_file = tf.gfile.Open(name='timeline', mode='w')
trace_file.write(tl.generate_chrome_trace_format(show_memory=True))
```

The file is generated, but when opened via `chrome://tracing/` the memory usage events are not displayed at all, only the names. Moreover, opening such memory section results in the CPU-usage events disappearing as well:

<img width=""665"" alt=""screen shot 2016-07-11 at 7 23 59 pm"" src=""https://cloud.githubusercontent.com/assets/6617696/16727681/2fcce290-479d-11e6-8ce4-8563e16f3212.png"">

<img width=""699"" alt=""screen shot 2016-07-11 at 7 24 09 pm"" src=""https://cloud.githubusercontent.com/assets/6617696/16727688/35cf0cf4-479d-11e6-9fc2-1bdc8706e227.png"">

Possibly too many datapoints results in failure to display them?
"
3267,TensorBoard: gracefully handle deleted event files,"Hi!

At the moment, TensorBoard at firstignores the deletion of folders and event files inside the log directory, and displays them as though they were there. Then at some later time (i can't tell what triggers it), it starts throwing exceptions, like

```
  File ""bla/lib/python3.5/site-packages/tensorflow/python/platform/gfile.py"", line 379, in ListDirectory
    files = os.listdir(directory)
FileNotFoundError: [Errno 2] No such file or directory: 'bla/dataset-test/logs/watch/dbg/test'
```

However, sometimes a cleanup is required, and unused runs have to be deleted. This is not possible under the current version.

The workaround of restarting TensorBoard every time that a run is deleted is **very** unsatisfying, because loading a log directory with several (long) runs takes forever.

Would it be possible to implement the handling of deleted session files and directories in TensorBoard?
"
3266,ERROR: Cannot find './util/python/python_lib,"### Environment info

Operating System:
OSX El Capitan 10.11.5

Installed version of CUDA and cuDNN: 
N/A

If installed from sources, provide the commit hash:
a4b7bb9
### Steps to reproduce
1. `git clone --recursive https://github.com/tensorflow/models.git`
2. `cd models/syntaxnet/tensorflow`
3. `./configure`
4. `cd ..`
5. `bazel build syntaxnet/...`
### What have you tried?
1. Confirmed that bazel version is 0.2.2
2. Confirmed that configure has been run
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
`INFO: Found 74 targets...
ERROR: /private/var/tmp/_bazel_pberkman/64f225994fec6ff696f44dfe0caf6bfc/external/org_tensorflow/util/python/BUILD:14:1: Executing genrule @org_tensorflow//util/python:python_check failed: bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
ERROR: Cannot find 'external/org_tensorflow/util/python/python_lib'.  Did you run configure?`

Seems that this issue is consistent with error https://github.com/tensorflow/tensorflow/issues/2703
"
3265,Change is_training of tf.contrib.layers.batch_norm to conditional function,"`tf.contrib.layers.batch_norm` is using `is_training` as a python boolean variable so I may have to define two different ops which share its variables by using `reuse=True` to the second op.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L209

However, I think it is better to use `tf.placeholder` or other tensor variables as `is_training` and use `tf.cond` to dynamically change training and testing phase without defining two different ops. Or is there any better usage of using `tf.contrib.layers.batch_norm` that I couldn't think of? Also, is `tf.contrib.layers.fully_connected` ready to use `batch_norm` as a `normalizer_fn` (because I guess this is still in contrib for several months)?
"
3263,"Segmentation fault, import tensorflow, tensorflow 0.9, mac osx","I have followed the installation steps for GPU enabled tensorflow 0.9 on OSX, (https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installation-for-mac-os-x), within a conda environment.  The installation seems to go smoothly, but I get a seg fault error when importing tensorflow.  I have tried the fixes from related threads without success. 

See below for the segmentation fault error.
### Environment info

Operating System: Mac OSX 10.10.5

Installed version of CUDA and cuDNN:  CUDA 7.5 and cuDNN 5.1
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
$ ls -l /usr/local/cuda/lib/libcud*
-rwxr-xr-x  1 root     wheel      8280 Apr 13 02:02 /usr/local/cuda/lib/libcuda.dylib
lrwxr-xr-x  1 root     wheel        45 Apr 13 02:03 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
lrwxr-xr-x  1 root     wheel        50 Apr 13 02:03 /usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
lrwxr-xr-x  1 root     wheel        46 Apr 13 02:03 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
lrwxr-xr-x  1 root     wheel        49 Apr 13 02:03 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a
-rwxr-xr-x@ 1 lw17567  staff  58975112 Jun 10 04:30 /usr/local/cuda/lib/libcudnn.5.dylib
lrwxr-xr-x@ 1 lw17567  staff        16 Jun 10 04:31 /usr/local/cuda/lib/libcudnn.dylib -> libcudnn.5.dylib
-rw-r--r--@ 1 lw17567  staff  56392320 Jun 10 04:30 /usr/local/cuda/lib/libcudnn_static.a

Installed tensorflow 0.9 within anaconda 2 env,

pip version: pip 8.1.2
Python 2.7.12

The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

$ python -c ""import tensorflow; print(tensorflow.**version**)""
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally
Segmentation fault: 11
### Steps to reproduce

1.) Create a conda environment
2.) Followed https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installation-for-mac-os-x
3.) Launch python and import  tensorflow 
### What have you tried?
1. importing numpy before importing tensorflow
2. ensuring that I'm outside the tensorflow source directory (well outside)
3. adding /Developer/NVIDIA/CUDA-7.5/lib to the DYLD_LIBRARY_PATH, per #2773 
   4.) uninstalling and reinstalling everything and trying again.
### Logs or other output that would be helpful

Output from bt, after using gdb to run test script with only line, 'import tensorflow'
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally

Program received signal SIGSEGV, Segmentation fault.
0x00007fff8d2b8f92 in strlen () from /usr/lib/system/libsystem_c.dylib

(gdb) bt
#0 0x00007fff8d2b8f92 in strlen () from /usr/lib/system/libsystem_c.dylib
#1 0x0000000104a0b4f0 in perftools::gputools::internal::DsoLoader::GetDsoHandle(tensorflow::StringPiece, void, perftools::gputools::internal::DsoLoader::LoadKind) ()

from /Users/lw17567/anaconda2/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#2 0x0000000104a0c06c in perftools::gputools::internal::DsoLoader::GetLibcudaDsoHandle(void) ()

from /Users/lw17567/anaconda2/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#3 0x0000000104a0d0d2 in std::__1::__function::__func, tensorflow::Status (void)>::operator()(void&&) ()

from /Users/lw17567/anaconda2/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#4 0x0000000104a0c86f in perftools::gputools::internal::CachedDsoLoader::FetchHandleResult(std::__1::function) ()

from /Users/lw17567/anaconda2/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#5 0x0000000104a0cdcf in perftools::gputools::internal::CachedDsoLoader::GetLibcudaDsoHandle() ()

from /Users/lw17567/anaconda2/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
---Type to continue, or q to quit---
#6 0x0000000104a8ebe5 in perftools::gputools::initialize_cuda_gpu_executor()

()
from /Users/lw17567/anaconda2/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#7 0x00007fff5fc12d4b in ?? ()
#8 0x000000155fbfc830 in ?? ()
#9 0x0000000000000001 in ?? ()
#10 0x00000001034c02e8 in ?? ()
#11 0x00000001034c0740 in ?? ()
#12 0x00000001034c0420 in ?? ()
#13 0x00007fff5fc38660 in ?? ()
#14 0x00000000000001b8 in ?? ()
#15 0x00000001004613d0 in ?? ()
#16 0x00007fff5fbfc8a0 in ?? ()
#17 0x0000000000000713 in ?? ()
#18 0x00007fff5fc38598 in ?? ()
#19 0x00007fff5fc41a38 in ?? ()
#20 0x00007fff5fbfc830 in ?? ()
#21 0x00007fff5fc12ed8 in ?? ()
#22 0x00000001004613d0 in ?? ()
#23 0x0000b481cbaa22ee in ?? ()
#24 0x00007fff5fbfc890 in ?? ()
#25 0x00007fff5fc0f8d1 in ?? ()

---Type to continue, or q to quit---
#26 0x0000000000000000 in ?? ()

If necessary, please see the full gdb output, and deviceQuery (CUDA sample) output in my related comments in #2773 .  
"
3262,IOS Makefile Problem,"I followed the steps given in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile but ran into problems when running the command  make -f tensorflow/contrib/makefile/Makefile  TARGET=IOS  IOS_ARCH=ARM64. 
### Environment info

Operating System:
MacBook Pro (Retina, 13-inch, Mid 2014), 10.11.5 El Capitan
Xcode 7.3.1 

[make_file_errors.txt](https://github.com/tensorflow/tensorflow/files/356308/make_file_errors.txt)
### Steps to reproduce
1.  make -f tensorflow/contrib/makefile/Makefile  TARGET=IOS  IOS_ARCH=ARM64 (in the root tensorflow directory)
### What have you tried?
1. Recloning and following steps in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile  again  
2. Trying to resolve using Stackoverflow  
### Logs or other output that would be helpful

Attaced below 
Thank You!
"
3261,Environment variables PATH and LD_LIBRARY_PATH not being passed to Protobuf compiler,"With protobuf neither the PATH nor LD_LIBRARY_PATH are being passed and building tensorflow fails with:

```
(cd /home/gbkedar/.cache/bazel/_bazel_gbkedar/2cce0d25c048758b29b453d7b4e29b85/execroot/tensorflow && \
  exec env - \
  bazel-out/host/bin/external/protobuf/protoc '--cpp_out=bazel-out/local_linux-opt/genfiles/' -I. -Iexternal/protobuf/src -Ibazel-out/local_linux-opt/genfiles/external/protobuf/src tensorflow/core/example/example.proto tensorflow/core/example/example_parser_configuration.proto tensorflow/core/example/feature.proto tensorflow/core/framework/allocation_description.proto tensorflow/core/framework/attr_value.proto tensorflow/core/framework/cost_graph.proto tensorflow/core/framework/device_attributes.proto tensorflow/core/framework/function.proto tensorflow/core/framework/graph.proto tensorflow/core/framework/kernel_def.proto tensorflow/core/framework/log_memory.proto tensorflow/core/framework/op_def.proto tensorflow/core/framework/step_stats.proto tensorflow/core/framework/summary.proto tensorflow/core/framework/tensor.proto tensorflow/core/framework/tensor_description.proto tensorflow/core/framework/tensor_shape.proto tensorflow/core/framework/tensor_slice.proto tensorflow/core/framework/types.proto tensorflow/core/framework/variable.proto tensorflow/core/framework/versions.proto tensorflow/core/lib/core/error_codes.proto tensorflow/core/protobuf/config.proto tensorflow/core/protobuf/meta_graph.proto tensorflow/core/protobuf/named_tensor.proto tensorflow/core/protobuf/queue_runner.proto tensorflow/core/protobuf/saver.proto tensorflow/core/protobuf/tensorflow_server.proto tensorflow/core/util/event.proto tensorflow/core/util/memmapped_file_system.proto tensorflow/core/util/saved_tensor_slice.proto tensorflow/core/util/test_log.proto)
ERROR: /project/roysam/compiledLibs/tensorflow/tensorflow/core/BUILD:91:1: null failed: protoc failed: error executing command
  (cd /home/gbkedar/.cache/bazel/_bazel_gbkedar/2cce0d25c048758b29b453d7b4e29b85/execroot/tensorflow && \
  exec env - \
  bazel-out/host/bin/external/protobuf/protoc '--cpp_out=bazel-out/host/genfiles/' -I. -Iexternal/protobuf/src -Ibazel-out/host/genfiles/external/protobuf/src tensorflow/core/example/example.proto tensorflow/core/example/example_parser_configuration.proto tensorflow/core/example/feature.proto tensorflow/core/framework/allocation_description.proto tensorflow/core/framework/attr_value.proto tensorflow/core/framework/cost_graph.proto tensorflow/core/framework/device_attributes.proto tensorflow/core/framework/function.proto tensorflow/core/framework/graph.proto tensorflow/core/framework/kernel_def.proto tensorflow/core/framework/log_memory.proto tensorflow/core/framework/op_def.proto tensorflow/core/framework/step_stats.proto tensorflow/core/framework/summary.proto tensorflow/core/framework/tensor.proto tensorflow/core/framework/tensor_description.proto tensorflow/core/framework/tensor_shape.proto tensorflow/core/framework/tensor_slice.proto tensorflow/core/framework/types.proto tensorflow/core/framework/variable.proto tensorflow/core/framework/versions.proto tensorflow/core/lib/core/error_codes.proto tensorflow/core/protobuf/config.proto tensorflow/core/protobuf/meta_graph.proto tensorflow/core/protobuf/named_tensor.proto tensorflow/core/protobuf/queue_runner.proto tensorflow/core/protobuf/saver.proto tensorflow/core/protobuf/tensorflow_server.proto tensorflow/core/util/event.proto tensorflow/core/util/memmapped_file_system.proto tensorflow/core/util/saved_tensor_slice.proto tensorflow/core/util/test_log.proto): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
bazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by bazel-out/host/bin/external/protobuf/protoc)
bazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by bazel-out/host/bin/external/protobuf/protoc)
bazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.18' not found (required by bazel-out/host/bin/external/protobuf/protoc)
Target //tensorflow/cc:tutorials_example_trainer failed to build
```

Further, checking the dependencies of protoc shows that they are set correctly when it is compiled

```
ldd bazel-out/host/bin/external/protobuf/protoc
        linux-vdso.so.1 =>  (0x00007ffffadff000)
        libpthread.so.0 => /lib64/libpthread.so.0 (0x00002b5195f33000)
        libstdc++.so.6 => /share/apps/gcc-4.9.2/lib64/libstdc++.so.6 (0x00002b5196150000)
        libgcc_s.so.1 => /share/apps/gcc-4.9.2/lib64/libgcc_s.so.1 (0x00002b5196463000)
        libc.so.6 => /lib64/libc.so.6 (0x00002b5196679000)
        /lib64/ld-linux-x86-64.so.2 (0x0000003e37c00000)
        libm.so.6 => /lib64/libm.so.6 (0x00002b5196a0d000)
```

I have checked out and built the master of bazel. Previous to https://github.com/bazelbuild/bazel/commit/c9bc051f32b0d153110863e983749420200d000c other parts were being passed the PATH and not LD_LIBRARY_PATH. For example:

```
//third_party/gpus/cuda:cuda_check [action 'Executing genrule //third_party/gpus/cuda:cuda_check']
(cd /home/gbkedar/.cache/bazel/_bazel_gbkedar/2cce0d25c048758b29b453d7b4e29b85/execroot/tensorflow && \
  exec env - \
    PATH= ...... \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; OUTPUTDIR=`readlink -f bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/../../..`; cd `dirname third_party/gpus/cuda/cuda_config.sh`; OUTPUTDIR=$OUTPUTDIR ./cuda_config.sh --check;')
```

The commit adds LD_LIBRARY_PATH:

```
//third_party/gpus/cuda:cuda_check [action 'Executing genrule //third_party/gpus/cuda:cuda_check']
(cd /home/gbkedar/.cache/bazel/_bazel_gbkedar/2cce0d25c048758b29b453d7b4e29b85/execroot/tensorflow && \
  exec env - \
    LD_LIBRARY_PATH= ...... \
    PATH= ...... \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; OUTPUTDIR=`readlink -f bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/../../..`; cd `dirname third_party/gpus/cuda/cuda_config.sh`; OUTPUTDIR=$OUTPUTDIR ./cuda_config.sh --check;')
```

which solves some issues when gcc or python are not in the default path but not this one.
"
3260,Deep Dream Tutorial with UnsupportedOperation: fileno,"When running Deep Dream Tutorial on Jupyter Notebook, for the section of Naive feature visualization, it shows following

`UnsupportedOperation: fileno`

backtracked up from 

`PIL.Image.fromarray(a).save(f, fmt)`

upto  `PIL/ImageFile.pyc in _save(im, fp, tile)`

```
    475     try:
--> 476         fh = fp.fileno()
    477         fp.flush()
    478     except AttributeError:
```

The TensorFlow is installed under Anaconda and created an environment with internal installation of PIL package. 

```
source activate tensorflow
conda install PIL
```
"
3256,[feature request]copy lstm parameters,"I'm using tensorflow to implement DQN network and use LSTM at the bottom layer. 

But in DQN, a target network is used(coping the main network and keep it for a while, and at the mean time update the original network), when use the `tf.Variable` as parameter A, I can use `tf.Variable.assign` to copy A to A', but when I use LSTM, it seems like there is no way to do this copy operation.

Or maybe there is a way to copy the whole graph include its variable weights?
"
3254,"Cannot see summaries after running ""mnist_with_summaries"" exmaple","Hi, I'm learning something about tensorboard and summaries. After I run the code from /tensorflow/examples/tutorials/mnist/mnist_with_summaries.py, open the tensorboard, I can't see any histograms or scalar summaries. All are blank. It's wired.
![](http://ww3.sinaimg.cn/large/901f9a6fjw1f5on9oq9tnj20a90m5wft.jpg)
![](http://ww1.sinaimg.cn/large/901f9a6fjw1f5on9xq4npj20iy0gt0uw.jpg)

operation system: ubuntu14.04
gpu: gtx1080
cuda 7.5
cudnn 4.0.7
install tensorflow from sources

Another thing I should mention is that I cannot run the mnist_with_summaries.py directly in Pycharm. Its log like that

```
/usr/bin/python2.7 /home/lan/Packages/tensorflow/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py
Traceback (most recent call last):
  File ""/home/lan/Packages/tensorflow/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py"", line 27, in <module>
    import tensorflow as tf
  File ""/home/lan/Packages/tensorflow/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/home/lan/Packages/tensorflow/tensorflow/python/__init__.py"", line 48, in <module>
    from tensorflow.python import pywrap_tensorflow
ImportError: cannot import name pywrap_tensorflow

Process finished with exit code 1
```

So I run the code in terminal by `python mnist_with_summaries.py`. It do run successfully, but there are warnings (or sth?): Unhandled API Callback
![](http://ww3.sinaimg.cn/large/901f9a6fjw1f5onjmkjoaj20lx07y77z.jpg)
I'm not sure if this warning influences summaries.
"
3251,tensorflow mobile : pi_examples - unable to locate graph.pb.h,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
pi@raspberrypi:~ $ cat /proc/version
Linux version 4.4.13-v7+ (dc4@dc4-XPS13-9333) (gcc version 4.9.3 (crosstool-NG crosstool-ng-1.22.0-88-g8460611) ) #894 SMP Mon Jun 13 13:13:27 BST 2016

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from sources, provide the commit hash:
### Steps to reproduce
1. Follow https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/pi_examples/
2. When you get to the final step in ""Building the Examples"", the following error occurs.
   pi@raspberrypi:~/tf/tensorflow $ make -f tensorflow/contrib/pi_examples/label_image/Makefile 
   gcc --std=c++11 -O0 -I/usr/local/include -I. -I/home/pi/tf/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/downloads -I/home/pi/tf/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/downloads/eigen-latest/ -I/home/pi/tf/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/proto/ -I/home/pi/tf/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/proto_text/ -c tensorflow/contrib/pi_examples/label_image/label_image.cc -o /home/pi/tf/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o
   tensorflow/contrib/pi_examples/label_image/label_image.cc:30:48: fatal error: tensorflow/core/framework/graph.pb.h: No such file or directory
   #include ""tensorflow/core/framework/graph.pb.h""
                                                 ^
   compilation terminated.
   tensorflow/contrib/pi_examples/label_image/Makefile:78: recipe for target '/home/pi/tf/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o' failed
   make: **\* [/home/pi/tf/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o] Error 1
### What have you tried?
1. Searching for similar issues.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3247,Different padding boundaries for different directions. ,"Hello, 

I recently started to use TensorFlow to implement and idea using 3D convolutions. It requires me to use different padding boundary conditions along spatial and temporal directions (dimensions) of the tensor (I need `padding='SAME'` for spatial and `padding='VALID'` for temporal directions).  `tf.nn.conv3d` and `tf.nn.max_pool3d` specify padding for the operation as a whole. 

Is there any way to specify padding type for each dimension individually, like how the stride is specified? I don't mind contributing for this if necessary, if someone could direct me on how to add this feature or create a new op for it. 
"
3246,"tf.matmul() fails when matrices are sparse, even if a_is_sparse is set.  Cryptic error.","tf.matmul(A, B, a_is_sparse=True) fails on a = ops.convert_to_tensor(a, name=""a"") with cryptic error.

Example code:

```
import tensorflow as tf
import numpy as np

x = tf.sparse_placeholder(tf.float32)
y = tf.Variable(tf.random_uniform([9, 9], minval=0.0, maxval=1.0, dtype=tf.float32))

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    indices = np.array([[3, 2], [4, 5]], dtype=np.int64)
    values = np.array([1.0, 2.0], dtype=np.float32)
    shape = np.array([9, 9], dtype=np.int64)
    _ = sess.run(tf.matmul(x, y), feed_dict={
        x: tf.SparseTensorValue(indices, values, shape)})
```

Error:
 line 12, in <module>
    _ = sess.run(tf.matmul(x, y, a_is_sparse=True), feed_dict={
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py"", line 1189, in matmul
    a = ops.convert_to_tensor(a, name=""a"")
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 620, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py"", line 179, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py"", line 162, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 421, in make_tensor_proto
    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/util/compat.py"", line 44, in as_bytes
    raise TypeError('Expected binary or unicode string, got %r' % bytes_or_text)
TypeError: Expected binary or unicode string, got <tensorflow.python.framework.ops.SparseTensor object at 0x11d952d90>

Is fixed by explicitly converting from sparse to dense tensor before multiplication:

```

import tensorflow as tf
import numpy as np

x = tf.sparse_placeholder(tf.float32)
z = tf.sparse_tensor_to_dense(x)
y = tf.Variable(tf.random_uniform([9, 9], minval=0.0, maxval=1.0, dtype=tf.float32))

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    indices = np.array([[3, 2], [4, 5]], dtype=np.int64)
    values = np.array([1.0, 2.0], dtype=np.float32)
    shape = np.array([9, 9], dtype=np.int64)
    _ = sess.run(tf.matmul(z, y), feed_dict={
        x: tf.SparseTensorValue(indices, values, shape)})
```
"
3245,Training learn.DNNClassifier iteratively does not yield similar result,"### Environment info

Operating System: OS X 10.11.5

If installed from binary pip package, provide:
1. Which pip package you installed.

```
https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0-py3-none-any.whl
```
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
0.9.0
```
### Steps to reproduce
1. I used the code in [tf.contrib.learn.QuickStart](https://www.tensorflow.org/versions/r0.9/tutorials/tflearn/index.html#tf-contrib-learn-quickstart)
2. change
   
   ```
   # Fit model.
   classifier.fit(x=x_train, y=y_train, steps=200)
   ```
   
   to
   
   ```
   # Fit model.
   for i in range(40):
     classifier.fit(x=x_train, y=y_train, steps=5)
   ```
3. The result accuracy is around 0.33, which is similar to call `fit` with `steps=5` only once.
"
3239,FFT gradient over variables fails,"The following code fails with an error `ValueError: Shapes (3, 32, 28, 28) and () are not compatible`

```
import tensorflow as tf

filters = 32
width = 28
height = 28
channels = 3

x = tf.placeholder(tf.float32, shape=[None, height, width, channels])
w = tf.Variable(tf.truncated_normal([channels, filters, height, width], stddev=0.1))
b = tf.Variable(tf.constant(0.1, shape=[32]))

w_ifft = tf.real(tf.batch_ifft2d(tf.complex(w, 0.0)))
w_ifft_transpose = tf.transpose(w_ifft, [2, 3, 0, 1])

conv = tf.nn.conv2d(x, w_ifft_transpose, strides=[1, 1, 1, 1], padding='SAME')
output = tf.nn.bias_add(conv, b)

print tf.gradients(output, w)
```

Performing backprop of an FFT over a variable is important for reproducing the work found [https://hips.seas.harvard.edu/files/rippel-spectral-nips-2015.pdf](https://hips.seas.harvard.edu/files/rippel-spectral-nips-2015.pdf)
"
3238,Android example fails to build with AndroidResourceProcessingAction: No such file or directory,"### Environment info

Operating System:
Ubuntu 16.04 LTS

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rw-r--r-- 1 root root 189170 May 18 19:42 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 May 18 19:42 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 May 18 19:42 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 May 18 19:42 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 May 18 19:42 /usr/local/cuda/lib/libcudart_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed.:
   Compiled python wheel from source and installed it. But I don't think that is relevant for building the Android demo. I maybe wrong.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.8.0

If installed from sources, provide the commit hash:
Don't have it
### Steps to reproduce

```
$ git clone https://github.com/tensorflow/tensorflow.git
$ cd tensorflow
$ # Edit WORKSPACE file
$ head -n 20 WORKSPACE 
workspace(name = ""org_tensorflow"")


android_sdk_repository(
    name = ""androidsdk"",
    api_level = 23,
    build_tools_version = ""23.0.1"",
    # Replace with path to Android SDK on your system
    path = ""/home/username/Android/Sdk"",
)

android_ndk_repository(
    name=""androidndk"",
    path=""/home/username/software/android-ndk-r10e"",
    api_level=21)

# Please add all new TensorFlow dependencies in workspace.bzl.
load(""//tensorflow:workspace.bzl"", ""tf_workspace"")
tf_workspace()

$ ls ~/Android/Sdk/
add-ons  build-tools  extras  licenses  ndk-bundle  platforms  platform-tools  SDK Readme.txt  sources  system-images  temp  tools
$ ls ~/software/android-ndk-r10e/
build  find-win-host.cmd  ndk-build      ndk-depends  ndk-gdb-py  ndk-gdb-py.cmd  ndk-which  prebuilt    RELEASE.TXT                samples  tests
docs   GNUmakefile        ndk-build.cmd  ndk-gdb      ndk-gdb.py  ndk-stack       platforms  README.TXT  remove-windows-symlink.sh  sources  toolchains

$ bazel build //tensorflow/examples/android:tensorflow_demo
```
### What have you tried?

Nothing yet.
### Logs or other output that would be helpful

```
ERROR: /home/username/tmp/tensorflow/tensorflow/examples/android/BUILD:47:1: Processing resources failed: namespace-sandbox failed: error executing command /home/username/.cache/bazel/_bazel_username/2b0ff57a0352a92ef031f8d7910813fd/tensorflow/_bin/namespace-sandbox ... (remaining 26 argument(s) skipped).
bazel-out/host/bin/external/bazel_tools/tools/android/resources_processor: line 21: /home/username/.cache/bazel/_bazel_username/2b0ff57a0352a92ef031f8d7910813fd/tensorflow/bazel-out/host/bin/external/bazel_tools/tools/android/resources_processor.runfiles/external/bazel_tools/src/tools/android/java/com/google/devtools/build/android/AndroidResourceProcessingAction: No such file or directory
```

I notice that although the file bazel is looking for does not exist, this file seems to be there

```
~/.cache/bazel/_bazel_username/2b0ff57a0352a92ef031f8d7910813fd/tensorflow/bazel-out/host/bin/external/bazel_tools/tools/android/resources_processor.runfiles/org_tensorflow/external/bazel_tools/src/tools/android/java/com/google/devtools/build/android/AndroidResourceProcessingAction
```

It looks to me that some component is not attaching ""org_tensorflow"" to some path

I did a fresh clone and tried compiling the Android example without compiling the rest of tensorflow. My assumption is that bazel would build whatever was necessary. I will attach the full log if it's required. 
"
3234,"distributed tensorflow does not use GPU 1,2,3 on server B ","### Environment info

Operating System: Ubuntu 14.04 desktop
Installed version of CUDA and cuDNN: 7.5,  5.0.5
 tensorflow 0.9.0.rc0 is installed from source.

---

I'm using distributed tensorflow with 8 Titan-x GPUs in two servers.
4 GPUs are in one server.

GU=gpu utilization

These are what I tested, changing ps and workers.
Cifar-10, ResNet. batchsize=32.

1) serverA (1 ps, 1 worker),  serverB (None) ==> Mem allocated on (serverA: GPU 0: GU>30%)

2) serverA (1 ps, 4 workers),  serverB (None)  ==> Mem allocated on (serverA: GPU 0,1,2,3: GU>30%)

3) serverA (1 ps, 1 workers),  serverB (1 ps, 1 worker)  ==> Mem allocated on (serverA: GPU 0,1: GU>30%), (serverB: GPU 0: GU ~8%). 

4) serverA (1 ps, 1 workers),  serverB (1 ps, 2 workers)  ==> Mem allocated on (serverA: GPU 0,1,2: GU>30%), (serverB: GPU 0: GU ~8%).

5) serverA (1 ps, 1 workers),  serverB (1 ps, 3 workers)  ==> Mem allocated on (serverA: GPU 0,1,2,3: GU>30%), (serverB: GPU 0: GU ~8%).

6) serverA (1 ps, 4 workers),  serverB (1 ps, 4 workers)  ==> Mem allocated on (serverA: GPU 0,1,2,3: GU>50%), (serverB: GPU 0: GU ~8%).

It looks dist tensorflow does not use GPU on serverB.

next is ""nvidia-smi"" in case of 6)

((serverA)) Mem allocated on GPU 0,1,2,3
![image](https://cloud.githubusercontent.com/assets/9377459/16659014/75379c00-44a3-11e6-957c-845bed33f492.png)

((serverB)) Mem allocated on GPU 0 (last one is 0)
![image](https://cloud.githubusercontent.com/assets/9377459/16658977/5748e794-44a3-11e6-94d1-f2eac24639cf.png)

I use replica_device_setter to allocate workers to GPU.

```
if FLAGS.job == ""ps"":
    server.join()
elif FLAGS.job == ""worker"":
    # Assigns ops to the local worker by default.
    with tf.device(tf.train.replica_device_setter(worker_device=""/gpu:%d"" % (FLAGS.task_id%4), cluster=cluster)):
```

please help me.
"
3233,partial_run can't do incremental feeds in InteractiveSession,"Here is a section of code copied from the docstring of `partial_run`, with required import statements added. However, note that this constructs an `InteractiveSession` instead of a `Session`.

``` python
import tensorflow as tf
import numpy as np
from tensorflow.python.ops import array_ops, math_ops
from tensorflow.python import dtypes
sess = tf.InteractiveSession()

a = array_ops.placeholder(dtypes.float32, shape=[])
b = array_ops.placeholder(dtypes.float32, shape=[])
c = array_ops.placeholder(dtypes.float32, shape=[])
r1 = math_ops.add(a, b)
r2 = math_ops.mul(r1, c)

h = sess.partial_run_setup([r1, r2], [a, b, c])
res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})
res = sess.partial_run(h, r2, feed_dict={c: res})
```

The code fails with a `NotFoundError`. When the `InteractiveSession` is replaced by a normal `Session`, the code runs correctly. The difference between the two is that the interactive session sets the `place_pruned_graph` option to True (starting a plain `Session` with `place_pruned_graph=True` reproduces the issue.)

I do all of my work in an interactive terminal, and I would find it useful to have `partial_run` work correctly in this setting.

**System info**: Ubuntu 14.04, tensorflow 11834fb02bfa9296f4aa48ee1eaa2a002fecbf1f; python3; cudnn 4.0.4, cuda 7.0.28
"
3232,ImportError: cannot import name pywrap_tensorflow,"Operating System: MAC ISO 10.11
"
3228,Dockerhub image tags naming inconsistency,"Hi,

I see on dockerhub that the image for version `r0.8` is the tag `0.8.0` but for version `r0.9` is `r0.9`. It would be nice if they were consistent so you don't have to look up every time you want to update.
"
3226,Failure to build from source,"Hello,
I'm trying to build tensorflow with GPU enabled from source using the instructions given here. https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installation-for-linux.

The build for the tutorial_example_trainer fails for me, with no error messages that I can discern. Please advise

```
215 ____Building complete.
216 Target //tensorflow/cc:tutorials_example_trainer failed to build
217 ____Elapsed time: 25.909s, Critical Path: 25.58s

```
### Environment info

Operating System:
Debian 3.16.7

Installed version of CUDA and cuDNN: 
CUDA: 7.5
cuDNN: 4.0
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
>ls -l ~/local/cuda-7.5/lib/libcud*
-rw-r--r-- 1 firdaus firdaus 185K Jul  6 15:33 /home/firdaus/local/cuda-7.5/lib/libcudadevrt.a
lrwxrwxrwx 1 firdaus firdaus   16 Jul  6 15:33 /home/firdaus/local/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5*
lrwxrwxrwx 1 firdaus firdaus   19 Jul  6 15:33 /home/firdaus/local/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18*
-rwxr-xr-x 1 firdaus firdaus 305K Jul  6 15:33 /home/firdaus/local/cuda-7.5/lib/libcudart.so.7.5.18*
-rw-r--r-- 1 firdaus firdaus 545K Jul  6 15:33 /home/firdaus/local/cuda-7.5/lib/libcudart_static.a
```

If installed from sources, provide the commit hash:
`commit 70de76e696c21da617fd2e6435cf7fedab220db8`
### Steps to reproduce
1.  bazel build  --verbose_failures -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer 
### What have you tried
1. I had to patch the build file in third_party/gpus/crosstool/CROSSTOOL to point it to a non-standard gcc path.
   ![image](https://cloud.githubusercontent.com/assets/923438/16667600/5c4a98fc-445b-11e6-9ff7-ef84f6df971c.png)
### Logs or other output that would be helpful

Attached.
[buildlog.txt](https://github.com/tensorflow/tensorflow/files/352935/build.txt)
"
3225,Make cuDNN compile-time vs. load-time validation use major version only,"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 

```
 ~ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   322936 Feb 27 11:34 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Feb 27 11:34 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Feb 27 11:34 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Feb 27 11:34 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Feb 27 11:34 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Jul  7 01:57 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 root root       17 Jul  7 01:57 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxr-xr-x 1 root root 61453024 Jul  7 01:57 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Jul  7 01:57 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. Pip package: `https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl`
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
 ~ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.9.0
```
### Steps to reproduce
1. `git clone https://github.com/soumith/convnet-benchmarks`
2. Go to `tensorflow` and run `python benchmark_googlenet.py`
### Logs

```
 tensorflow git:(master) python benchmark_googlenet.py
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:8a:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:8a:00.0)
E tensorflow/stream_executor/cuda/cuda_dnn.cc:346] Loaded cudnn library: 4004 but source was compiled against 4007.  If using a binary install, upgrade your cudnn library to match.  If building from sources, make sure the library loaded matches the version you specified during compile configuration.
F tensorflow/core/kernels/conv_ops.cc:459] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms)
[1]    18918 abort (core dumped)  python benchmark_googlenet.py
```

Notice the line: **Loaded cudnn library: 4004 but source was compiled against 4007**.  If using a binary install, upgrade your cudnn library to match.  If building from sources, make sure the library loaded matches the version you specified during compile configuration.
"
3224,Error polling for event status: failed to query event: CUDA_ERROR_MISALIGNED_ADDRESS,"### Summary:

Trying inceptionv3, was working fine all the way until I downgraded gcc 5+ to gcc4.9 to use Theano with keras: following this example http://deeplearning.net/software/theano/install_ubuntu.html

Now hitting this error before training starts (bottlenecks generate fine) whenever i run 

bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir <image dir>

```
E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_MISALIGNED_ADDRESS
F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1
```

Cant figure out the problem. Sidenote that might help: bottlenecks generated alot faster when i used gcc 4.9 instead, but now the training crashes and i cant even run.
### Environment info

Operating System:
Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
`ls: cannot access '/path/to/cuda/lib/libcud*': No such file or directory
`
It's installed in /usr/local/cuda and /usr/local/cuda-7.5 instead.

CUDA 7.5, CuDNN v4.

Install steps:
CUDA: 
`bash cuda_7.5.18_linux.run --override
`
CUDNN:
Tried both:

```

tar xvzf cudnn-7.0-linux-x64-v4.0-prod.tgz
sudo cp cuda/include/cudnn.h /usr/local/cuda-7.5/include
sudo cp -r cuda/lib64/. /usr/local/cuda-7.5/lib64

```

and from here:
http://askubuntu.com/questions/767269/how-can-i-install-cudnn-on-ubuntu-16-04

If installed from binary pip package, provide:
1. Which pip package you installed.

```
$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp35-cp35m-linux_x86_64.whl
pip install --upgrade $TF_BINARY_URL
```
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.9.0
```

If installed from sources, provide the commit hash:
### Steps to reproduce
1. bazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain
2. bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir <direc>
3. scratch head
### What have you tried?

1.literally every other stack overflow / github question. eg, https://github.com/tensorflow/tensorflow/issues/2810

2.reinstalling cuda 7.5 and cudnn v4, running ./configure. no luck.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3221,Distributed tensorflow does not allocate well 'worker' to GPUs,"### Environment info

Operating System: Ubuntu 14.04 desktop
Installed version of CUDA and cuDNN: 7.5,  5.0.5
tensorflow 0.9.0.rc0 is installed from source.

(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   322936  8 16  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16  8 16  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19  8 16  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336  8 16  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192  8 16  2015 /usr/local/cuda/lib64/libcudart_static.a
-rwxr--r-- 1 root root 59909104  6 21 15:39 /usr/local/cuda/lib64/libcudnn.so
-rwxr--r-- 1 root root 59909104  6 21 15:39 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr--r-- 1 root root 59909104  6 21 15:39 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rwxr--r-- 1 root root 58775484  6 21 15:39 /usr/local/cuda/lib64/libcudnn_static.a

I'm trying to use distributed tensorflow with 8 Titan-x GPUs in two servers.
4 GPUs are in one server.

I separate workers to each GPUs as follows.

 with tf.device(tf.train.replica_device_setter(
      worker_device=""/gpu:%d"" % (FLAGS.task_id%4), cluster=cluster_spec)):

When I execute two 'ps' and eight 'worker', nvidia-smi shows next.

((server1)) workers are allocated on GPU 0,1,2,3
![image](https://cloud.githubusercontent.com/assets/9377459/16659014/75379c00-44a3-11e6-957c-845bed33f492.png)

((server2)) workers are allocated on GPU 0
![image](https://cloud.githubusercontent.com/assets/9377459/16658977/5748e794-44a3-11e6-94d1-f2eac24639cf.png)

Why the workers are not allocated to GPU 1,2,3 in server1 ?

please help me.
"
3220,AggregationMethod.EXPERIMENTAL_ACCUMULATE_N gives Already exists error.,"I have used EXPERIMENTAL_ACCUMULATE_N in all my past tensorflow projects since it lets me use larger batch sizes.  I have never had any issues with it until now.  Now I get the following error when I run the train step.

```
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_4/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_2/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_3/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
     [[Node: gradients/AccumulateN_5/TemporaryVariable = TemporaryVariable[dtype=DT_FLOAT, shape=[2,1024], var_name="""", _device=""/job:localhost/replica:0/task:0/gpu:0""](^gradients/Sub_1)]]
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
     [[Node: gradients/AccumulateN_5/TemporaryVariable = TemporaryVariable[dtype=DT_FLOAT, shape=[2,1024], var_name="""", _device=""/job:localhost/replica:0/task:0/gpu:0""](^gradients/Sub_1)]]
W tensorflow/core/framework/op_kernel.cc:936] Already exists: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
     [[Node: gradients/AccumulateN_5/TemporaryVariable = TemporaryVariable[dtype=DT_FLOAT, shape=[2,1024], var_name="""", _device=""/job:localhost/replica:0/task:0/gpu:0""](^gradients/Sub_1)]]
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 14880 get requests, put_count=3563 evicted_count=1000 eviction_rate=0.280662 and unsatisfied allocation rate=0.834476
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=10010 evicted_count=10000 eviction_rate=0.999001 and unsatisfied allocation rate=0
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 730, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 712, in _run_fn
    status, run_metadata)
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors.py"", line 450, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors.AlreadyExistsError: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
     [[Node: gradients/AccumulateN_5/TemporaryVariable = TemporaryVariable[dtype=DT_FLOAT, shape=[2,1024], var_name="""", _device=""/job:localhost/replica:0/task:0/gpu:0""](^gradients/Sub_1)]]
     [[Node: Mean/_21 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_3391_Mean"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/chase/workspace/Translator/translator.py"", line 106, in <module>
    c, _ = sess.run([cost, train_step], feed_dict = {input_tensor: x, expected_output: y})
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 382, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 655, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 723, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 743, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.AlreadyExistsError: Resource tmp_var/gradients/AccumulateN_5/TemporaryVariable/N10tensorflow19TemporaryVariableOp6TmpVarE
     [[Node: gradients/AccumulateN_5/TemporaryVariable = TemporaryVariable[dtype=DT_FLOAT, shape=[2,1024], var_name="""", _device=""/job:localhost/replica:0/task:0/gpu:0""](^gradients/Sub_1)]]
     [[Node: Mean/_21 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_3391_Mean"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op 'gradients/AccumulateN_5/TemporaryVariable', defined at:
  File ""/home/chase/workspace/Translator/translator.py"", line 79, in <module>
    train_step = tf.train.AdamOptimizer(1e-4).minimize(cost, aggregation_method = tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py"", line 193, in minimize
    grad_loss=grad_loss)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py"", line 250, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients.py"", line 432, in gradients
    out_grads = _AggregatedGrads(grads, op, loop_state, aggregation_method)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients.py"", line 692, in _AggregatedGrads
    out_grads[i] = math_ops.accumulate_n(out_grad)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py"", line 1497, in accumulate_n
    var = gen_state_ops._temporary_variable(shape=shape, dtype=tensor_dtype)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 365, in _temporary_variable
    var_name=var_name, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2297, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 1231, in __init__
    self._traceback = _extract_stack()

```

This error goes away if I change the aggregation method of ADD_N.  Here is my code.  I am trying to implement a sequence to sequence model to translate english to german.

```
import unidecode
import tensorflow as tf
rnn = tf.nn.rnn_cell
import numpy as np
import string
import sys
import random
import multiprocessing

TIME_STEPS = 128
BATCH_SIZE = 2

def ctov(c):
    v = np.zeros(128)
    v[ord(c)] = 1
    return v

def vtoc(v):
    return chr(np.argmax(v))

def stov(s, vlen):
    null_vec = ctov('\0')
    v = np.tile(null_vec, (vlen, 1))
    if len(s) > vlen: s = s[:vlen]
    for i, c in enumerate(s):
        v[i] = ctov(c)
    return v

def vtos(v):
    s = ''
    for cv in v:
        c = vtoc(cv)
        if c == '\0':
            break
        s += c
    return s

def clean_text(txt):
    txt = unidecode.unidecode(txt)
    txt = ''.join([c for c in txt if c in CHARS])
    return txt

def load_training_data():
    print('Loading English...')
    en = [e.strip() for e in open('/home/chase/Desktop/de-en/english.txt')]
    print('Loading German...')
    de = [d.strip() for d in open('/home/chase/Desktop/de-en/german.txt')]
    print('Processing...')
    translations = [(unidecode.unidecode(e), unidecode.unidecode(d)) for e, d in zip(en, de) if len(e) and len(d) and len(e) <= TIME_STEPS and len(d) <= TIME_STEPS]
    return translations


input_tensor = tf.placeholder(tf.float32, (BATCH_SIZE, TIME_STEPS, 128), 'input_tensor')
expected_output = tf.placeholder(tf.float32, (BATCH_SIZE, TIME_STEPS, 128), 'expected_output')

y = input_tensor
with tf.variable_scope('encoder'):
    rnn_cell = rnn.MultiRNNCell([rnn.GRUCell(1024) for _ in range(3)])
    y = tf.nn.dynamic_rnn(rnn_cell, y, dtype = tf.float32)[0]

with tf.variable_scope('attn'):
    W = tf.get_variable('W_attn', shape = (1, TIME_STEPS, TIME_STEPS), initializer = tf.truncated_normal_initializer(0.0, 1 / np.sqrt(TIME_STEPS)))
    W = tf.tile(W, (BATCH_SIZE, 1, 1))
    y = tf.batch_matmul(W, y)

with tf.variable_scope('decoder'):
    rnn_cell = rnn.MultiRNNCell([rnn.GRUCell(1024) for _ in range(3)])
    y = tf.nn.dynamic_rnn(rnn_cell, y, dtype = tf.float32)[0]

with tf.variable_scope('output'):
    y = tf.split(1, TIME_STEPS, y)
    y = [tf.reshape(x, (BATCH_SIZE, 1024)) for x in y]
    W = tf.get_variable('W', shape = (1024, 128), initializer = tf.truncated_normal_initializer(0.0, 1 / np.sqrt(1024)))
    b = tf.get_variable('b', shape = (128,), initializer = tf.truncated_normal_initializer(0.0, 0.01))
    y = [tf.nn.softmax(tf.matmul(x, W) + b) for x in y]
    output = tf.pack(y, 1)

cost = tf.reduce_mean(-tf.reduce_sum(expected_output * tf.log(output), reduction_indices = 2))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cost, aggregation_method = tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N)

config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.8
sess = tf.Session(config = config)
sess.run(tf.initialize_all_variables())

if 'train' in sys.argv or True:
    translations = load_training_data()
    validation = translations[:10000]
    translations = translations[10000:]

    def training_data_generator(data):
        x = np.zeros((BATCH_SIZE, TIME_STEPS, 128))
        y = np.zeros_like(x)
        random.shuffle(data)
        for i in range(0, len(data) - BATCH_SIZE, BATCH_SIZE):        
            for b in range(BATCH_SIZE):
                e, d = data[i + b]
                x[b] = stov(e, TIME_STEPS)
                y[b] = stov(d, TIME_STEPS)

            yield (x, y)

    for e in range(50):
        for b, v in enumerate(training_data_generator(translations)):
            x, y = v
            c, _ = sess.run([cost, train_step], feed_dict = {input_tensor: x, expected_output: y})
            print('Epoch %-6d  Batch %-6d  Cost %-6e' % (e, b, c), end = '\r')
```

I am using Python 3.5 on Ubuntu 16.04.  I have the latest tensorflow version 0.9.
"
3218,Can not build tf from source - no such package '@grpc//': Error c loning repository,"# description

Try to build&install tf from source. But it does not work with the guide.
I think it is because I am working in China and it has Great Fire Wall.

Built with commit id: 71f6bb336e5e11d6da2cedac6ba1c992ad9992bd
And OS: Mac OSX EI

```
$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

WARNING: /private/var/tmp/_bazel_hain/13b9e8642207ccdb0c7f56a5c17d327c/external/protobuf/WORKSPACE:1: Workspace name in /priv
ate/var/tmp/_bazel_hain/13b9e8642207ccdb0c7f56a5c17d327c/external/protobuf/WORKSPACE (@__main__) does not match the name give
n in the repository's definition (@protobuf); this will cause a build error in future versions.
ERROR: /Users/hain/glory/ai/tensorflow/tensorflow/core/distributed_runtime/rpc/BUILD:87:1: no such package '@grpc//': Error c
loning repository: Unexpected end of file from server caused by Unexpected end of file from server caused by Unexpected end o
f file from server and referenced by '//tensorflow/core/distributed_runtime/rpc:grpc_channel'.
ERROR: Loading failed; build aborted.
INFO: Elapsed time: 639.082s
```

Other related issues -
https://github.com/tensorflow/tensorflow/issues/1387
https://github.com/tensorflow/tensorflow/issues/1413

@fayeshine 
@melody-rain 
"
3217,ImportError: cannot import name pywrap_tensorflow," I followed the TensorFlow installation instructions for Mac OS X.(Mac OS X, CPU only, Python 2.7):
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0rc0-py2-none-any.whl
sudo pip install --upgrade $TF_BINARY_URL

Got this error:
## In [2]: import tensorflow

ImportError                               Traceback (most recent call last)
<ipython-input-2-a649b509054f> in <module>()
----> 1 import tensorflow

/usr/local/lib/python2.7/site-packages/tensorflow/**init**.py in <module>()
     21 from **future** import print_function
     22 
---> 23 from tensorflow.python import *

/usr/local/lib/python2.7/site-packages/tensorflow/python/**init**.py in <module>()
     46 _default_dlopen_flags = sys.getdlopenflags()
     47 sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)
---> 48 from tensorflow.python import pywrap_tensorflow
     49 sys.setdlopenflags(_default_dlopen_flags)
     50 

ImportError: cannot import name pywrap_tensorflow

Any help would be appreciated.
"
3216,after freezing a graph the inference time is slower than when restoring variables from checkpoint ,"I'm using the  freeze_graph.py script that takes a graph definition and the corresponding checkpoint to combine them them into a single file (variables are replaced by constants). On my system (Linux, titanx tensorflow R0.9) I'm measuring aprox 50% slower inference time compared to the same graph running with  variables restored from the checkpoint file. 
Is it normal?
Thanks
Laurent
"
3215,build_pip_package => no such package '@iron_range_behavior//',"bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
works (and runs)
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
fails:

ERROR: ~/git_clone/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_range_behavior//': Error cloning repository: https://github.com/polymerelements/iron-range-behavior.git: cannot open git-upload-pack caused by https://github.com/polymerelements/iron-range-behavior.git: cannot open git-upload-pack caused by https://github.com/polymerelements/iron-range-behavior.git: cannot open git-upload-pack and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: Loading failed; build aborted.
### Environment info

Operating System: ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
/usr/local/cuda/lib64/libcudart.so.8.0.2

If installed from sources, provide the commit hash:
71f6bb336e5e11d6da2cedac6ba1c992ad9992bd
"
3213,Accompany TF_LoadLibrary with TF_DeleteLibrary,"The C API provides the [following function](https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/core/public/tensor_c_api.h#L357) for loading libraries:

``` c
extern TF_Library* TF_LoadLibrary(const char* library_filename, TF_Status* status);
```

The documentation says that the caller owns the library handle returned by the function. Unlike other functions allocating memory and returning pointers, `TF_LoadLibrary` doesnt have a counterpart for properly freeing the memory. Note that its not about unloading the library but about deallocating the `TF_Library` struct; although, a function for unloading the library would also be nice. Thanks!

Regards,
Ivan
"
3212,Nan causes writing summary failed,"I find when I try to write some weights or biases into summaries, they cannot be Nan, or it causes the program crashed. When I turn off writing summaries, everything runs normally, unless sometimes the loss could be Nan. 

Is it normal that some variables (e.g. weights, biases) be Nans at sometime and the whole training process runs ok? If it is, please modify the writing summary functions to avoid crash at this situation. 

Thanks!
Ben
"
3211,"ValueError: Shape (?, ?) must have rank 1","r9.0

code:

```
tensor_shape = tf.reshape(tf.shape(tensor), shape=[2])
indexes = tf.reshape(sparse_tensor.indices, shape=tensor_shape)

tf.slice(indexes, one, two)
// Where one and two are tensor constants
OR
tf.slice(sparse_tensor.indices, one, two)
```

Stack trace:

```
minus_1_index = tf.slice(indexes, minus_1, one)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 251, in slice
    return gen_array_ops._slice(input_, begin, size, name=name)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1634, in _slice
    name=name)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py"", line 2262, in create_op
    set_shapes_for_outputs(ret)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py"", line 1702, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1054, in _SliceShape
    input_shape.assert_has_rank(ndims)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 621, in assert_has_rank
    raise ValueError(""Shape %s must have rank %d"" % (self, rank))
ValueError: Shape (?, ?) must have rank 1
```

Obviously it does have a rank of 1 but the dim itself is unknown
"
3210,Using foldl inside while_loop doesn't seem to work,"### Environment info

Operating System: OSX

If installed from binary pip package, provide:
1. Which pip package you installed.

tensorflow (0.1.0)       - UNKNOWN
  INSTALLED: 0.9.0rc0
  LATEST:    0.1.0
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

0.9.0rc0
### What have you tried?

I'm trying to use foldl inside while_loop and wrote reduced test case to find what I'm doing wrong. However looks like this might be bug in foldl implementation.

``` python
import tensorflow as tf
from tensorflow.python.ops import functional_ops as fops

s = tf.InteractiveSession()

print(""Evaluating foldl part"",
  fops.foldl(
    lambda x,y: x+y,
    tf.constant([1,2])
  ).eval()
)

print(""Evaluating while without fold"",
  tf.while_loop(
    lambda i: tf.less(i, 10), 
    lambda i: tf.add(i, 3), 
    [tf.constant(0)]
  ).eval()
)

# This one fails for some reason... 
print(""Evaluating while with fold inside"",
  tf.while_loop(
    lambda i: tf.less(i, 10), 
    lambda i: tf.add(i, 
      fops.foldl(
        lambda x,y: x+y,
        tf.constant([1,2])
      )
    ), 
    [tf.constant(0)]
  ).eval()
)
```

output:

```
Evaluating foldl part 3
Evaluating while without fold 12

W tensorflow/core/framework/op_kernel.cc:909] Already exists: Resource _tensor_arrays/while_1/foldl/TensorArray/N10tensorflow11TensorArrayE
Traceback (most recent call last):
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 715, in _do_call
    return fn(*args)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 697, in _run_fn
    status, run_metadata)
  File ""/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/framework/errors.py"", line 450, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors.AlreadyExistsError: Resource _tensor_arrays/while_1/foldl/TensorArray/N10tensorflow11TensorArrayE
     [[Node: while_1/foldl/TensorArray = TensorArray[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, tensor_array_name="""", _device=""/job:localhost/replica:0/task:0/cpu:0""](while_1/foldl/Squeeze)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""fops_test.py"", line 58, in <module>
    [tf.constant(0)]
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 555, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 3498, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 372, in run
    run_metadata_ptr)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 636, in _run
    feed_dict_string, options, run_metadata)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 708, in _do_run
    target_list, options, run_metadata)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.AlreadyExistsError: Resource _tensor_arrays/while_1/foldl/TensorArray/N10tensorflow11TensorArrayE
     [[Node: while_1/foldl/TensorArray = TensorArray[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, tensor_array_name="""", _device=""/job:localhost/replica:0/task:0/cpu:0""](while_1/foldl/Squeeze)]]
Caused by op 'while_1/foldl/TensorArray', defined at:
  File ""fops_test.py"", line 58, in <module>
    [tf.constant(0)]
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1873, in while_loop
    result = context.BuildLoop(cond, body, loop_vars)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1749, in BuildLoop
    body_result = body(*vars_for_body_with_tensor_arrays)
  File ""fops_test.py"", line 55, in <lambda>
    tf.constant([1,2])
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/ops/functional_ops.py"", line 102, in foldl
    infer_shape=True)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/ops/tensor_array_ops.py"", line 132, in __init__
    tensor_array_name=tensor_array_name, name=scope)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 759, in _tensor_array
    name=name)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2260, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/mikaelle/Projects/Omat/tensorflow-grouping/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1230, in __init__
    self._traceback = _extract_stack()
```
"
3209,Problems with Tensorboard on Ubuntu 16.04,"I'm running code from https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tf15_tensorboard/full_code.py on my own computer, which is a sample of how to use Tensorboard, however, I see nothing from the Tensor board from my computer: every tab of the Tensorflow is empty, saying no XX data is found.

I tried the '--inspect option':

> zhao@zhao-ubuntu:~/Desktop/samples$ tensorboard --logdir = 'logs' --inspect ====================================================================== Processing event files... (this can take a few minutes) ======================================================================
> 
> No event files found within logdir =

and the '--debug' option:

> zhao@zhao-ubuntu:~/Desktop/samples$ tensorboard --logdir = 'logs' --debug INFO:tensorflow:TensorBoard is in debug mode. INFO:tensorflow:Starting TensorBoard in directory /home/zhao/Desktop/samples
> INFO:tensorflow:TensorBoard path_to_run is: {'/home/zhao/Desktop/samples/=': None} 
> INFO:tensorflow:Multiplexer done loading. Load took 0.0 secs INFO:tensorflow:TensorBoard is tag:b'22' 
> Starting TensorBoard b'22' on port 6006 (You can navigate to http://0.0.0.0:6006)

BTW, I'm using python3.5.1 on my ubuntu machine.
"
3208,"minimize raises ""ValueError: None values not supported."" error when tf.while_loop used inside fn() of tf.cond()","On TF 0.9.0, The following code with tf.while_loop inside tf.cond raises ValueError when minimized. 

```
import tensorflow as tf
from tensorflow.python.ops import tensor_array_ops

with tf.Session() as sess:
    a = tf.constant([[1., 2.], [3.,4.]])
    w = tf.get_variable('w', [2, 1], tf.float32)
    c = tf.Variable(1)

    def loss_a(a, w):
        a_ta = tensor_array_ops.TensorArray(dtype=tf.float32, size=2,
                                            tensor_array_name=""a_ta"")
        a_ta = a_ta.unpack(a)

        b_ta = tensor_array_ops.TensorArray(dtype=tf.float32, size=2,
                                            tensor_array_name=""b_ta"")


        time = tf.constant(0, dtype=tf.int32, name=""time"")

        def _time_step(time, a_ta_t, b_ta_t):
          a = a_ta_t.read(time)
          b_ta_t = b_ta_t.write(time, a * w)
          return (time+1, a_ta_t, b_ta_t)

        (_, _, final_b) = tf.while_loop(
            cond=lambda time, _1, _2: time < 2,
            body=_time_step,
            loop_vars=(time, a_ta, b_ta),
            parallel_iterations=32,
            swap_memory=True)
        b = tf.reduce_sum(final_b.pack(), 0)
        return b

    def loss_b(a, w):
        return 2 * a * w

    loss = tf.cond(tf.equal(c, 0), lambda: loss_a(a, w), lambda: loss_b(a,w))
    train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)

    sess.run(tf.initialize_all_variables())

    sess.run(train_op)
```

> Traceback (most recent call last):
>   File ""test.py"", line 39, in <module>
>     train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)
>   File ""/.../tensorflow/python/training/optimizer.py"", line 193, in minimize
>     grad_loss=grad_loss)
>   File ""/.../tensorflow/python/training/optimizer.py"", line 250, in compute_gradients
>     colocate_gradients_with_ops=colocate_gradients_with_ops)
>   File ""/.../tensorflow/python/ops/gradients.py"", line 481, in gradients
>     in_grads = _AsList(grad_fn(op, *out_grads))
>   File ""/.../tensorflow/python/ops/tensor_array_grad.py"", line 115, in _TensorArrayWriteGrad
>     grad = g.read(index)
>   File ""/.../tensorflow/python/ops/tensor_array_ops.py"", line 191, in read
>     dtype=self._dtype, name=name)
>   File ""/.../tensorflow/python/ops/gen_data_flow_ops.py"", line 905, in _tensor_array_read
>     flow_in=flow_in, dtype=dtype, name=name)
>   File ""/.../tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
>     op_def=op_def)
>   File ""/.../tensorflow/python/framework/ops.py"", line 2260, in create_op
>     original_op=self._default_original_op, op_def=op_def)
>   File ""/.../tensorflow/python/framework/ops.py"", line 1234, in __init__
>     self._control_flow_context.AddOp(self)
>   File ""/.../tensorflow/python/ops/control_flow_ops.py"", line 1479, in AddOp
>     self._AddOpInternal(op)
>   File ""/.../tensorflow/python/ops/control_flow_ops.py"", line 1499, in _AddOpInternal
>     self.AddValue(x)
>   File ""/.../tensorflow/python/ops/control_flow_ops.py"", line 1438, in AddValue
>     real_val = grad_ctxt.grad_state.GetRealValue(val)
>   File ""/.../tensorflow/python/ops/control_flow_ops.py"", line 781, in GetRealValue
>     real_value = self.AddBackPropAccumulatedValue(h_value, value)
>   File ""/.../tensorflow/python/ops/control_flow_ops.py"", line 731, in AddBackPropAccumulatedValue
>     history_value = _SwitchRefOrTensor(history_value, pred)[branch]
>   File ""/.../tensorflow/python/ops/control_flow_ops.py"", line 324, in _SwitchRefOrTensor
>     return ref_switch(data, pred, name=name)
>   File ""/.../tensorflow/python/ops/gen_control_flow_ops.py"", line 341, in ref_switch
>     result = _op_def_lib.apply_op(""RefSwitch"", data=data, pred=pred, name=name)
>   File ""/.../tensorflow/python/ops/op_def_library.py"", line 459, in apply_op
>     as_ref=input_arg.is_ref).dtype.name
>   File ""/.../tensorflow/python/framework/ops.py"", line 620, in convert_to_tensor
>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
>   File ""/.../tensorflow/python/ops/constant_op.py"", line 179, in _constant_tensor_conversion_function
>     return constant(v, dtype=dtype, name=name)
>   File ""/.../tensorflow/python/ops/constant_op.py"", line 162, in constant
>     tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))
>   File ""/.../tensorflow/python/framework/tensor_util.py"", line 346, in make_tensor_proto
>     raise ValueError(""None values not supported."")
> ValueError: None values not supported.

It works fine if I add la, lb as follows, although this would force execution of loss_a and loss_b regardless of the pred in tf.cond(). 

```
    la = loss_a(a, w)
    lb = loss_b(a, w)

    loss = tf.cond(tf.equal(c, 0), lambda: la, lambda: lb)
    train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)

    sess.run(tf.initialize_all_variables())

    sess.run(train_op)
```

Is this a known issue or did I miss something in how to use tf.while_loop within tf.cond? 
"
3205,Failed to build tensorflow using custom Python/3.5.1-CrayGNU-2016.03,"I am trying to build tensorflow 0.9.0 (bdc43730c9e6037c608adb91fe55d6c1a82879a8) on a cray cluster using bazel 0.3.0. 

I was able to build tensorflow using a fresh installation of python3.5.1 but [this paper from the cluster admins](https://cug.org/proceedings/cug2016_proceedings/includes/files/pap145.pdf) suggests that I loose quite some performance by not using an optimized python installation. 

Therefore I want to install tensorflow using the provided python installation. 
I create a virtualenv (inheriting the locally installed packages) and activate it. Then I run configure and select the proposed python binary from virtualenv.
But unfortunately building fails:

```
bazel build --linkopt '-lrt' --config=cuda --verbose_failures -c opt //tensorflow/tools/pip_package:build_pip_package
INFO: $TEST_TMPDIR defined: output root default is '/scratch/daint/user_name/bazelout'.
.....
INFO: Waiting for response from Bazel server (pid 4431)...
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
WARNING: /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/protobuf/WORKSPACE:1: Workspace name in /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
WARNING: /users/user_name/tensorflow-cray/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
WARNING: /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/re2/WORKSPACE:1: Workspace name in /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
WARNING: /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/highwayhash/WORKSPACE:1: Workspace name in /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.
INFO: Found 1 target...
[removed code]
ERROR: /users/user_name/tensorflow-cray/tensorflow/contrib/session_bundle/example/BUILD:38:1: Executing genrule //tensorflow/contrib/session_bundle/example:half_plus_two failed: bash failed: error executing command 
  (cd /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/execroot/tensorflow-cray && \
  exec env - \
    PATH=/users/user_name/tf_cray_env/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/Python/3.5.1-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/Tk/8.6.4-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/SQLite/3.9.2-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/Tcl/8.6.4-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/freetype/2.5.5-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/libpng/1.6.16-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/libreadline/6.3-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/ncurses/6.0-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/bzip2/1.0.6-CrayGNU-2016.03/bin:/opt/cray/rca/1.0.0-2.0502.60530.1.62.ari/bin:/opt/cray/alps/5.2.4-2.0502.9822.32.1.ari/sbin:/opt/cray/dvs/2.5_0.9.0-1.0502.2188.1.116.ari/bin:/opt/cray/xpmem/0.1-2.0502.64982.5.3.ari/bin:/opt/cra
 y/pmi/5.0.10-1.0000.11050.0.0.ari/bin:/opt/cray/ugni/6.0-1.0502.10863.8.29.ari/bin:/opt/cray/udreg/2.3.2-1.0502.10518.2.17.ari/bin:/opt/toolworks/totalview.8.11.0-0/bin:/opt/totalview-support/1.1.4/bin:/opt/gcc/4.9.3/bin:/opt/nvidia/cudatoolkit7.0/7.0.28-1.0502.10742.5.1/bin:/opt/nvidia/cudatoolkit7.0/7.0.28-1.0502.10742.5.1/libnvvp:/opt/java/jdk1.8.0_51/bin:/apps/common/UES/SLES11/ddt/6.0.6/libexec:/apps/common/UES/SLES11/ddt/6.0.6/bin:/opt/cray/mpt/7.3.2/gni/bin:/apps/daint/munge/default/bin:/apps/daint/slurm/default/bin:/opt/slurm/default/bin:/opt/cray/craype/2.4.0/bin:/opt/cray/switch/1.0-1.0502.60522.1.61.ari/bin:/opt/cray/eslogin/eswrap/1.1.0-1.020200.1231.0/bin:/opt/modules/3.2.10.3/bin:/users/user_name/bin:/usr/local/bin:/usr/bin:/bin:/usr/bin/X11:/usr/X11R6/bin:/usr/games:/usr/lib/mit/bin:/usr/lib/mit/sbin:/sbin:/usr/sbin:.:/usr/lib/qt3/bin:/opt/cray/bin:/apps/ela/system/bin:/apps/common/system/bin:/apps/daint/system/bin:/apps/ela/system/bin:/apps/common/system/bin:/apps/dain
 t/system/bin \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; rm -rf /tmp/half_plus_two; /users/user_name/tf_cray_env/bin/python bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two; cp -r /tmp/half_plus_two/* bazel-out/local_linux-py3-opt/genfiles/tensorflow/contrib/session_bundle/example/half_plus_two'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127.
/users/user_name/tf_cray_env/bin/python: error while loading shared libraries: libpython3.5m.so.1.0: cannot open shared object file: No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 2664.471s, Critical Path: 1412.20s
```
"
3204,Knights Landing feature request,"It would be nice to see a tensorflow binary compatible with Knights Landing for AWS.
"
3203,ImportError for graph_util from tensorflow.python.framework,"Importing `graph_util` from `tensorflow.python.framework` fails with an `ImportError`.

I discovered this while I was trying to go through the [TensorFlow for Poets Codelab](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html), an the the [re-training](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html?index=..%2F..%2Findex#4) failed.

I can reproduce the same error in my Python shell. I am able to verify that TensorFlow is installed correctly by importing `tensorflow`, `tensor_shape` from `tensorflow.python.framework`, and `gfile` from `tensorflow.python.platform` (as in the [retraining script](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py)); but trying to import `graph_util` results in the same `ImportError`:

```
>>> import tensorflow
# Success
>>> from tensorflow.python.framework import tensor_shape
# Success
>>> from tensorflow.python.platform import gfile
# Success
>>> from tensorflow.python.framework import graph_util
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: cannot import name graph_util
```

I have also posted this as a [question on Stack Overflow](http://stackoverflow.com/questions/38218274/tensorflow-importerror-for-graph-util-from-tensorflow-python-framework), and haven't received any answers so far. I am not sure if this is a bug or a configuration problem etc. Feels like a bug, since I can import `tensor_shape` from `tensorflow.python.framework` no problem.
### Environment info

Operating System: OS X El Capitan (v10.11.5)
Python: v2.7.11 via Homebrew 

TensorFlow 0.9.0 installed from binary pip package for Mac OS X, CPU only, Python 2.7 (TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0-py2-none-any.whl).
### Steps to reproduce

In Python shell:

```
>>> from tensorflow.python.framework import graph_util
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: cannot import name graph_util
```
### What have I tried?
- Looked to see if the file `graph_util` is there inside `tensorflow/python/framework`. It is.
- Looked to see if the current source code I am examining has undergone any [changes since v0.9.0](https://github.com/tensorflow/tensorflow/compare/v0.9.0...r0.9) that would fix this issue that appears in the release that I am using. It doesn't appear so to me.
"
3202,genrule //tensorflow/contrib/session_bundle/example:half_plus_two ignores bazels TEST_TMPDIR and uses uses /tmp/,"I am trying to build tensorflow 0.9.0 on a cray cluster using bazel 0.3. Becuase I have limited space in my home directory I set TEST_TMPDIR to some scratch space.

Somehow the /tmp directory already contains a folder half_plus_two created by another user of the system. Therefore I don't have write access and the build fails: 

```
bazel  build  --linkopt '-lrt' --config=cuda --verbose_failures -c opt //tensorflow/tools/pip_package:build_pip_package
INFO: $TEST_TMPDIR defined: output root default is '/scratch/daint/user_name/bazelout'.
Extracting Bazel installation...
.
INFO: Waiting for response from Bazel server (pid 9772)...
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
WARNING: /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/protobuf/WORKSPACE:1: Workspace name in /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
WARNING: /users/user_name/tensorflow-cray/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
WARNING: /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/highwayhash/WORKSPACE:1: Workspace name in /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.
WARNING: /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/re2/WORKSPACE:1: Workspace name in /scratch/daint/user_name/bazelout/_bazel_user_name/e48b2676a5a6481d625353bc3f790885/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
INFO: Found 1 target...
[removed output...]
ERROR: /users/user_name/tensorflow-cray/tensorflow/contrib/session_bundle/example/BUILD:38:1: Executing genrule //tensorflow/contrib/session_bundle/example:half_plus_two failed: bash failed: error executing command 
  (cd /scratch/daint/user_name/bazelout/e48b2676a5a6481d625353bc3f790885/execroot/tensorflow-cray && \
  exec env - \
    PATH=/users/user_name/tf_cray_env/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/Python/3.5.1-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/Tk/8.6.4-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/SQLite/3.9.2-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/Tcl/8.6.4-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/freetype/2.5.5-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/libpng/1.6.16-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/libreadline/6.3-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/ncurses/6.0-CrayGNU-2016.03/bin:/apps/daint/UES/jenkins/5.2.UP04/easybuild/software/bzip2/1.0.6-CrayGNU-2016.03/bin:/opt/cray/rca/1.0.0-2.0502.60530.1.62.ari/bin:/opt/cray/alps/5.2.4-2.0502.9822.32.1.ari/sbin:/opt/cray/dvs/2.5_0.9.0-1.0502.2188.1.116.ari/bin:/opt/cray/xpmem/0.1-2.0502.64982.5.3.ari/bin:/opt/cray/pmi/5.0.10-1.0000.11050.0.0.ari/bin:/opt/cray/ugni/6.0-1.0502.10863.8.29.ari/bin:/opt/cray/udreg/2.3.2-1.0502.10518.2.17.ari/bin:/opt/toolworks/totalview.8.11.0-0/bin:/opt/totalview-support/1.1.4/bin:/opt/gcc/4.9.3/bin:/opt/nvidia/cudatoolkit7.0/7.0.28-1.0502.10742.5.1/bin:/opt/nvidia/cudatoolkit7.0/7.0.28-1.0502.10742.5.1/libnvvp:/opt/java/jdk1.8.0_51/bin:/apps/common/UES/SLES11/ddt/6.0.6/libexec:/apps/common/UES/SLES11/ddt/6.0.6/bin:/opt/cray/mpt/7.3.2/gni/bin:/apps/daint/munge/default/bin:/apps/daint/slurm/default/bin:/opt/slurm/default/bin:/opt/cray/craype/2.4.0/bin:/opt/cray/switch/1.0-1.0502.60522.1.61.ari/bin:/opt/cray/eslogin/eswrap/1.1.0-1.020200.1231.0/bin:/opt/modules/3.2.10.3/bin:/users/user_name/bin:/usr/local/bin:/usr/bin:/bin:/usr/bin/X11:/usr/X11R6/bin:/usr/games:/usr/lib/mit/bin:/usr/lib/mit/sbin:/sbin:/usr/sbin:.:/usr/lib/qt3/bin:/opt/cray/bin:/apps/ela/system/bin:/apps/common/system/bin:/apps/daint/system/bin:/apps/ela/system/bin:/apps/common/system/bin:/apps/daint/system/bin \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; rm -rf /tmp/half_plus_two; /users/user_name/tf_cray_env/bin/python bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two; cp -r /tmp/half_plus_two/* bazel-out/local_linux-py3-opt/genfiles/tensorflow/contrib/session_bundle/example/half_plus_two'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
rm: cannot remove `/tmp/half_plus_two/00000123/assets': Permission denied
rm: cannot remove `/tmp/half_plus_two/00000123/export-00000-of-00001': Permission denied
rm: cannot remove `/tmp/half_plus_two/00000123/export.meta': Permission denied
rm: cannot remove `/tmp/half_plus_two/00000123/checkpoint': Permission denied
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1912.489s, Critical Path: 975.47s
```

Wouldn't it make sense if the genrule half_plus_two would also use TEST_TMPDIR or is there some reason that it does not. 

Where do I have to make changes to hardcode the directory used by the genrule?

Thanks for whatever support you are able to provide.
"
3201,Calculate a vector l1 norm of a tensor creates unnecessary copy of tensor,"I am using tensorflow 0.9.
when I am trying to calculate a simple l1-norm of vector, like 

``` python
    matrix = vs.get_variable(""Matrix"", [total_arg_size, output_size])                      
    l1norm = tf.reduce_mean(tf.abs(matrix))                                                 
```

Tensorflow allocates memory for the results of tf.abs(matrix). when matrix size are large, this could cause out of memory issue.
Is there a way I can avoid this additional allocation? 
"
3200,dnn_linear_combined.py is not compatible with Python 3,"in Python 3.x, line 215 of dnn_linear_combined.py (master version) results in an error.

**line 215 is:**
return sorted(set(self._dnn_feature_columns)) if self._dnn_feature_columns else None

**the error is:**
builtins.TypeError: unorderable types: _SparseColumnHashed() < str()

**to reproduce this error:**
in wide_n_deep_tutorial.py, change the following line:
feature_cols = dict(continuous_cols.items() + categorical_cols.items())
to
feature_cols = {_**continuous_cols , *_*categorical_cols}
this change makes wide_n_deep_tutorial.py compatible with Python 3.x.
Now simply run it like:
python3.5 wide_n_deep_tutorial.py --model_type=wide_n_deep
"
3199,All weights become nan after training more than about 20000+10000 times,"Operating System: CentOS 7
Installed version of CUDA and cuDNN: cuda 7.5.18, cudnn4

When I run my own project, I found that all weights would become nan after training more than 20000+10000 times (That means I first trained the model for 20000 times, and then I continued training the model for 10000 times). The accuracy would suddenly change from 0.8 to 0.5. I thought that might be my own problem of setting weights and they become divergent after a certain point.

But we I rerun the Tensorflow tutorial: ""Deep MNIST for Experts"", I got the same problem.
Follow the instruction, I run the following script:

for i in range(20000):
  batch = mnist.train.next_batch(50)
  if i%100 == 0:
    train_accuracy = accuracy.eval(feed_dict={
        x:batch[0], y_: batch[1], keep_prob: 1.0})
    print(""step %d, training accuracy %g""%(i, train_accuracy))
  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})

Everything is perfect until now, and the training accuracy is as high as 0.99.

However, when I rerun the above script, something strange happened. The training accuracy suddenly become around 0.1 and all weights become nan. Like following: 
<img width=""372"" alt=""screen shot 2016-07-06 at 02 19 17"" src=""https://cloud.githubusercontent.com/assets/19503832/16603033/79ca3a3a-4321-11e6-92b7-19750de858c9.png"">
<img width=""775"" alt=""screen shot 2016-07-06 at 02 20 15"" src=""https://cloud.githubusercontent.com/assets/19503832/16603036/8074b87e-4321-11e6-9736-6ff2a98f5a4c.png"">

To reproduce the problem, first train the model for 20000 times, and then continue training the module for 20000 times, using another for loop.
"
3198,Error: Nodes were connected by a reference connection,"I am running distributed TF 0.8 for Py 3.5. I have followed the initialization of tf.train.Server() as in the imagenet_distributed_train.py. I am getting the following error while executing sv.prepare_or_wait_for_session(). I am passing remote ps server and local workers as the arguments. I do have blocks of code using tf.device('/cpu:0') at some places.

sv = tf.train.Supervisor(is_chief=is_chief,
                                       init_op=init_op,
                                        summary_op=None,
                                        global_step=global_step)
sess_config = tf.ConfigProto(
                 allow_soft_placement=True,
               log_device_placement=True)
 # Get a session.
sess = sv.prepare_or_wait_for_session(target, config=sess_config)

Error while executing last line:
tensorflow.python.pywrap_tensorflow.StatusNotOK: Invalid argument: Nodes were connected by a reference connection (requiring them to be on the same device), but the two nodes were assigned two different devices: Cannot colocate nodes 'Variable' and 'Assign: Cannot merge devices with incompatible jobs: '/job:ps/task:0' and '/job:worker/task:0'
         [[Node: Assign = Assign[T=DT_FLOAT, use_locking=false, validate_shape=true, _device=""/job:worker/task:0""](Variable, mul)]]

Any idea what is happening?
"
3197,add l2 regularization and dropout,"Hi,

Is it posible to add l2 regularization and dropout in the text_classification_cnn.py ?

Thanks
"
3196,Nightly builds 404 Not Found,"I'm getting a 404 error on trying to download all nightly builds: https://github.com/tensorflow/tensorflow#installation
"
3195,Documentation of Session arguments seems outdated,"In [README.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/public/README.md) a session is created as `tf.Session(""local"")`. At the same time, the [docstring](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session.py#L888) says ""no value other than an empty string is supported"". This is clearly an inconsistency.
"
3194,[install error] install failed on RedHat ,"In large scale cluster,  Entherprise RedHat system is mainstream distribution branch, and its always encounter a low version of kernel and libc problem.  There  several similar issue in this project.  I'm wondering that
1  is there any method to build tensorflow offline? 
2  how can I build tensorflow cc part as static library instead of shared library. 
3  is there any way to pay a cheap price to replace the bazel build tool?  Here we encounter a build tool bug.
https://github.com/bazelbuild/bazel/issues/1474, which had been labeled as a bug in bazel, is there any alternative method?

Thanks
System info:

```
(gcc version 4.4.4 20100726 (Red Hat 4.4.4-13) (GCC) )
ldd --version
ldd  2.18
```
"
3193,AttributeError: 'LinearClassifier' object has no attribute 'save',"### Environment info

Operating System:
OS X 10.11.5

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
NA

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

Tensor Flow verison: `0.9`

If installed from sources, provide the commit hash:
Commit Hash:`70de76e696c21da617fd2e6435cf7fedab220db8`
### Steps to reproduce
1. Run the example commands give at [sklearn doc](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn#linear-classifier)
2. Try to save the model with .save() function [sklearn doc](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn#saving--restoring-models)
### What have you tried?
1. I tried using `tf.train.Saver()` but I guess it can save the session but not the classifier.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

``` python
Python 2.7.10 (default, Oct 23 2015, 19:19:21) 
[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow.contrib.learn as learn
>>> from sklearn import datasets, metrics
>>> iris = datasets.load_iris()
>>> classifier = learn.LinearClassifier(n_classes=3)
>>> classifier.fit(iris.data, iris.target, steps=200, batch_size=32)
LinearClassifier()
>>> classifier.save('/tmp/tf_examples/my_model_1/')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: 'LinearClassifier' object has no attribute 'save'
>>> import tensorflow as tf
>>> saver = tf.train.Saver()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/Vijay/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/saver.py"", line 837, in __init__
    raise ValueError(""No variables to save"")
ValueError: No variables to save
>>> 
```
"
3191,iOS build breaks,"git rev-parse HEAD
70de76e696c21da617fd2e6435cf7fedab220db8

ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: **\* [/Users/Shared/Develop/google/tensorflow/tensorflow/contrib/makefile/gen/host_bin/proto_text] Error 1
- '[' 2 -ne 0 ']'
- echo 'armv7 compilation failed.'
  armv7 compilation failed.
- exit 1

The rest of the output is here:

https://gist.github.com/john-difool/67126c4ccf5d8201cd1842ca18acc78b
"
3190,How does wide_n_deep model support install app columns?,"wide_n_deep model in paper [1] support embedding for users' installed app features. 
But in wide_n_deep.py and feature_column.py, I haven't find something about supporting embedding for users' installed app features, which trains embedding jointly for multi-columns.
Do I miss anything? or misunderstanding  

[1] Wide & Deep Learning for Recommender Systems @moonboots 
"
3188,BasicLSTMCell __call__ fails. ,"### Environment info

Operating System: 
OSX Yosemite 10.10.5

If installed from binary pip package, provide:
1. Which pip package you installed: CPU only mac-version
2. The output from `python -c ""import tensorflow; print(tensorflow.**version**)"": 0.9.0rc0

I've been getting a strange error when trying to use the BasicLSTM cell. Running the below code:

```
import tensorflow as tf

sess =  tf.Session()
init_state = tf.zeros([32, 6])
init_state2 = tf.zeros([32, 6])
input = tf.placeholder(tf.float32, [32, 10])
input2 = tf.placeholder(tf.float32, [32, 10])
print init_state.get_shape()
output, state = tf.nn.rnn_cell.BasicLSTMCell(3)(input, init_state)
output2, state2 = tf.nn.rnn_cell.BasicLSTMCell(3)(input2, init_state2)
```

results in a ValueError:

```
ValueError: Variable BasicLSTMCell/Linear/Matrix already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:
output, state = tf.nn.rnn_cell.BasicLSTMCell(3)(input, init_state)
```

the error doesn't occur if the line generating `(output2, state2)` is omitted. 
"
3186,Insufficient alignment in u_ union in tensorflow/core/lib/gtl/inlined_vector.h,"### Environment info

Operating System: Linux

Installed version of CUDA and cuDNN: None

If installed from sources, provide the commit hash: aa2cacd6627ffb296bedc910c957a0fd4a2f957f
### Steps to reproduce
1. Find an architecture with 32 bit pointers but strict alignment requirements for 64 bit
2. Compile and run ""benchmark"" from tensorflow/contrib/makefile
3. Get bus error from misaligned pointer
### What have you tried?
1. Fixing the issue by increasing the u_ alignment.  This works.

In tensorflow/core/lib/gtl/inlined_vector.h, the data buf is aligned by adding a pointer.  However, it is cast to other types, including uint64_t.  On architectures where pointers are 32 bits, this cast causes errors.

The fix is to add another component to the union that will force alignment to the largest size, such as uint64_t.

For example:

diff --git a/tensorflow/core/lib/gtl/inlined_vector.h b/tensorflow/core/lib/gtl/inlined_vector.h
index e8fe66c..518b421 100644
--- a/tensorflow/core/lib/gtl/inlined_vector.h
+++ b/tensorflow/core/lib/gtl/inlined_vector.h
@@ -276,6 +276,8 @@ class InlinedVector {
     unsigned char data[kSize];
     // Force data to be aligned enough for a pointer.
     T\* unused_aligner;
-    // EJP: force 8 byte alignment, as pointers could be 4-byte but data elements 8-byte?
-    uint64_t unused_64;
  } u_;

You won't see this issue on architectures where pointers are the size of the largest type (aarch64, x86-64) or where a 32-bit architecture loads 64-bit things but can do so at arbitrary 32-bit boundaries (x86, armv7 with misaligned pointers enabled).  

But it might improve performance to have 64-bit values on 64-bit boundaries.
"
3185,"Udacity Notebook with ""None"" kernel","I use Jupyter notebook to open the .ipynb files, but it shows a red ""None"" kernel on top right corner and all lines of code cannot run. 

Method I use:
1. Build a new directory and extract .ipynb files from `examples/udacity` to the directory
2. In terminal, run `jupyter notebook`
"
3184,Configure script attemps to seek for libcudart.so in wrong path,"Hi! I'm trying to configure build for cuda utilization. When I answer the question 

> Please specify the location where CUDA  toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/lib/x86_64-linux-gnu/libcudart.so

i get the following error:

> Invalid path to CUDA  toolkit. /usr/lib/x86_64-linux-gnu/**lib64**/libcudart.so cannot be found

but i have cuda installed in:

> $ ll /usr/lib/x86_64-linux-gnu/libcudart.so
> lrwxrwxrwx 1 root root 16  30 15:25 /usr/lib/x86_64-linux-gnu/libcudart.so -> libcudart.so.7.5

This happens because of the following code in `configure` file:

```
  if [ ""$OSNAME"" == ""Linux"" ]; then
    CUDA_RT_LIB_PATH=""lib64/libcudart.so${TF_CUDA_EXT}""

```

Why it tries to look for cuda installation in `lib64` subdirectory? I think make me to symlink /usr/lib/**lib64**/ -> /usr/lib/**x86_64-linux-gnu**/ is cruel.

Forgot. My system is Ubuntu 16.04:

> $ uname -a
> Linux user-desktop 4.4.0-28-generic #47-Ubuntu SMP Fri Jun 24 10:09:13 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
"
3183,Implement tf-slim from tensorflow/models.,"Feature request: Implement tf-slim from `tensorflow/models` into `tensorflow/tensorflow`.
See requests from models: https://github.com/tensorflow/models/issues/186, https://github.com/tensorflow/models/issues/203. Maybe mark for 0.9 as suggested by @sguada?
"
3181,tf.initialize_variables fails on missing Tensor initializer attribute,"### Environment info

Operating System: `Ubuntu 14.04.4`

Installed version of CUDA and cuDNN:  CUDA 7.5 and cuDNN 4.0.7
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

``` bash
ls -l /usr/local/cuda-7.5/lib64/libcud*
-rw-r--r-- 1 root root    322936 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root        19 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root    383336 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root    720192 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
lrwxrwxrwx 1 3319 users       13 Feb  9 19:48 /usr/local/cuda-7.5/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 3319 users       17 Feb  9 19:48 /usr/local/cuda-7.5/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxrwxr-x 1 3319 users 61453024 Feb  9 00:12 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7
-rw-rw-r-- 1 3319 users 62025862 Feb  9 00:12 /usr/local/cuda-7.5/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed. Nightly build, Ubuntu/Linux 64-bit, GPU enabled, Python 2.7 
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

``` bash
$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.9.0
```

If installed from sources, provide the commit hash:
### Steps to reproduce
1. Running the following python script

``` python
import tensorflow as tf

with tf.Session() as S:
    V = tf.linspace(0., 100., 10)
    S.run(tf.initialize_variables([V]))
```

produces the following output:

``` python
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 850M
major: 5 minor: 0 memoryClockRate (GHz) 0.9015
pciBusID 0000:01:00.0
Total memory: 4.00GiB
Free memory: 3.56GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 850M, pci bus id: 0000:01:00.0)
Traceback (most recent call last):
  File ""test_init_fail.py"", line 5, in <module>
    S.run(tf.initialize_variables([V]))
  File ""/home/foobar/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 907, in initialize_variables
    *[v.initializer for v in var_list], name=name)
AttributeError: 'Tensor' object has no attribute 'initializer'

```
### What have you tried?
1. See above
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3180,Execution order of ReLU and Max-Pooling,"Hello Everyone,

I'm new to Deep Learning and TensorFlow. From studying tutorials / research papers / online lectures it appears that people always have the execution order: ReLU -> Pooling. But in case of e.g. 2x2 max-pooling it seems that we can save 75% of the ReLU operations by simply reversing the execution order to: Max-Pooling -> ReLU. This should calculate the exact same thing using only a quarter of the ReLU operations. This reversal of operations can be done in general for max-pooling and all non-decreasing activation functions (which I guess they all are?), but it won't work for average-pooling.

This is an optimization that TensorFlow could perform automatically when compiling the computation graph. I haven't quite figured out how to use TensorBoard yet, so I can't tell if this automatic reversal of ReLU and max-pooling is already being done in TensorFlow.

So I've done a few experiments instead, timing the optimization of a convolutional net on MNIST, but the results are inconclusive for the two execution orders. Perhaps this means that TensorFlow already does the reversal automatically, or it means that there's no consistent advantage because the saved ReLU operations are such a tiny fraction of the overall computational cost, or perhaps it takes much larger images than MNIST and much deeper convolutional networks for the performance difference to become apparent.

Any thoughts?
"
3179,ImportError: cannot import name pywrap_tensorflow,"### Environment info

Operating System: Mac OS X 10.10
### Steps to reproduce

1.
%matplotlib inline
%load_ext autoreload
%autoreload 2
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from matplotlib import gridspec
2.
import sys
sys.path.append('..')
3.
from tasks import *

input_dim=10
output_dim=10

sess = tf.InteractiveSession()

cell = NTMCell(input_dim=input_dim, output_dim=output_dim)
ntm = NTM(cell, sess, 1, 10, 100, forward_only=True)
ntm.load('../checkpoint', 'copy')

---

ImportError                               Traceback (most recent call last)
<ipython-input-18-0a6f382608e4> in <module>()
----> 1 from tasks import *
      2 
      3 input_dim=10
      4 output_dim=10
      5 

/Users/William_Chuang/Documents/NTM/NTM-tensorflow-master/tasks/**init**.py in <module>()
----> 1 from copy import *
      2 from recall import *

/Users/William_Chuang/Documents/NTM/NTM-tensorflow-master/tasks/copy.py in <module>()
      2 import time
      3 import numpy as np
----> 4 import tensorflow as tf
      5 from random import randint
      6 

/Users/William_Chuang/cuting_edge/anaconda/lib/python2.7/site-packages/tensorflow/**init**.py in <module>()
     21 from **future** import print_function
     22 
---> 23 from tensorflow.python import *

/Users/William_Chuang/cuting_edge/anaconda/lib/python2.7/site-packages/tensorflow/python/**init**.py in <module>()
     46 _default_dlopen_flags = sys.getdlopenflags()
     47 sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)
---> 48 from tensorflow.python import pywrap_tensorflow
     49 sys.setdlopenflags(_default_dlopen_flags)
     50 

ImportError: cannot import name pywrap_tensorflow
"
3178,How to check/enlarge computer memory in Mac OS when running .py code? ,"Hi everyone,

I'm new to python, and learning tensorflow recently on my mac OS X Yosemite system with 8g memory. I'm using anaconda with tensorflow installed within it. When trying some demo codes, I found they run very slowly.

 I've saw somewhere previously that python only use 2g (or 1g? sorry I cannot remember clearly) memory in Mac OS since it was installed in virtual environment, so one can enlarge the memory to 8g to speed up the programme by using just several command lines. 

Unfortunately I  cannot find out that webpage now. Does anyone have idea how to do this? Thanks a lot!
"
3177,Is wide_n_deep compatible with python3.5?,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Ubuntu 14/04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from sources, provide the commit hash:
### Steps to reproduce
1. run wide_n_deep.py on python 3.5
   2.
   3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
TypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items'

This is because python3.5 does not support + between dict_items. I worked around using dict.copy(), but still get error and could proceed. Do you have plan to release python 3.5 version in near future?
"
3176,Mutability of TF_NewTensors arguments,"The C API provides the [following function](https://github.com/tensorflow/tensorflow/blob/v0.9.0/tensorflow/core/public/tensor_c_api.h#L195) for creating tensors:

``` c
extern TF_Tensor* TF_NewTensor(TF_DataType, long long* dims, int num_dims,
                               void* data, size_t len,
                               void (*deallocator)(void* data, size_t len,
                                                   void* arg),
                               void* deallocator_arg);
```

Based on what the function does conceptually and on how it is [implemented](https://github.com/tensorflow/tensorflow/blob/v0.9.0/tensorflow/core/client/tensor_c_api.cc#L122), it doesnt seem to be reasonable that `dims` is required to be a pointer to mutable data. This makes the usage of the function a bit inconvenient, especially when developing bindings for other languages. If its OK to change the signature of the function, I can submit a pull request. Thanks!

Regards,
Ivan
"
3175,"Android demo: unable to build with Bazel, could not read RELEASE.TXT","### Environment info

Operating System: Ubuntu 14.04 LTS 64-bit

Installed version of CUDA and cuDNN: none (not using GPU)
### Steps to reproduce

Note: TensorFlow was installed previously.
1. Install Bazel as instructed here: http://www.bazel.io/docs/install.html#install-on-ubuntu
2. Install Android Studio (which includes the SDK).
3. Install Android NDK through the Android Studio SDK Manager.
4. Download and unzip the TensorFlow graph as instructed here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md
5. Uncomment the Android entries in the WORKSPACE file and add in paths to the SDK and NDK (in my case, these were `/home/me/Android/Sdk` and `/home/me/android-studio/android-studio/plugins/android-ndk`)
6. Run `$ bazel build //tensorflow/examples/android:tensorflow_demo`
### What have you tried?
1. I've looked around, and my understanding is that the RELEASE.TXT file is not included in the most recent version of the Android NDK. Since the NDK installed via Android Studio is a .jar file, I wasn't sure what to do with that, so I went to the path indicated by the terminal log and created a blank RELEASE.TXT file. This made no difference.
2. According to #1468, it can be resolved by downgrading to an earlier version of the NDK which contains RELEASE.TXT. I downloaded the version of Bazel (for Linux) from the links given, but the downloaded file is a .bin, which is unusable to me. As such, I found this solution to be a dead end.
3. Commenting out the NDK entry is said to resolve the issue, but I haven't tried this yet, since I don't know if it'll cause more complications down the road.
### Logs or other output that would be helpful

```
ERROR: no such package '@androidndk//': Could not read RELEASE.TXT in Android NDK: /home/me/.cache/bazel/_bazel_me/f3471be34d1e62bf21975aa777cedaa3/external/androidndk/ndk/RELEASE.TXT (No such file or directory).
ERROR: no such package '@androidndk//': Could not read RELEASE.TXT in Android NDK: /home/me/.cache/bazel/_bazel_me/f3471be34d1e62bf21975aa777cedaa3/external/androidndk/ndk/RELEASE.TXT (No such file or directory).
```

Is there another way to resolve this issue without downgrading or commenting out the NDK entry? If not, how can I install a previous version of Android NDK? Thanks in advance.
"
3174,C Stack smashing from inside python when using tensorflow,"I am trying to implement Fully Connected Convolutional Network in python using tensorflow and I am getting a Stack Smashing error in one of the Convolution operators. I have checked and all the filter sizes match up and are perfectly in sync with the layer shapes. I did my research on the error and found that this error is caused when you overflow the alloted buffer but I cant see any place where I exceed this buffer and the most weird part is that it's running for 10 layers (7 convolutions and 3 max pool ones of the VGG network) and crashing on the next convolution.
(Posted this on Stack Overflow and was told that this error is due to a bug in tensorflow and hence should be posted here. The reason I was told was that the stack smashing is happening in the C++ code and not the python code and I havent written any C++ code myself so the most likely place for the error to have happened is inside tensorflow)

The error I get is:
`-> _, loss_value = sess.run([train_op, loss],feed_dict=feed_dict)
(Pdb) c
I tensorflow/core/kernels/logging_ops.cc:79] Shape of input image: [1 375 1242 3]
I tensorflow/core/kernels/logging_ops.cc:79] Shape of conv1_1[1 375 1242 64]
I tensorflow/core/kernels/logging_ops.cc:79] Shape of conv1_2[1 375 1242 64]
I tensorflow/core/kernels/logging_ops.cc:79] Shape of pool1[1 188 621 64]
I tensorflow/core/kernels/logging_ops.cc:79] Shape of conv2_1[1 188 621 128]
I tensorflow/core/kernels/logging_ops.cc:79] Shape of conv2_2[1 188 621 128]
I tensorflow/core/kernels/logging_ops.cc:79] Shape of pool2[1 94 311 128]
I tensorflow/core/kernels/logging_ops.cc:79] Shape of conv3_1[1 94 311 256]
I tensorflow/core/kernels/logging_ops.cc:79] Shape of conv3_2[1 94 311 256]
I tensorflow/core/kernels/logging_ops.cc:79] Shape of conv3_3[1 94 311 256]
I tensorflow/core/kernels/logging_ops.cc:79] Shape of pool3[1 47 156 256]
*** stack smashing detected ***: python terminated
Aborted (core dumped)`

Here is the relevant part of my code:

```
`class FCN8VGG:
def __init__(self, vgg16_npy_path=None):
    if vgg16_npy_path is None:
        path = sys.modules[self.__class__.__module__].__file__
        # print path
        path = os.path.abspath(os.path.join(path, os.pardir))
        # print path
        path = os.path.join(path, ""vgg16.npy"")
        print(path)
        vgg16_npy_path = path

    self.data_dict = np.load(vgg16_npy_path).item()
    self.wd = 5e-4
    print(""npy file loaded"")
def build(self, rgb, train=True, num_classes=14, random_init_fc8=True,
          debug=True):
    """"""
    Build the VGG model using loaded weights
    Parameters
    ----------
    rgb: image batch tensor
        Image in rgb shap. Scaled to Intervall [0, 255]
    train: bool
        Whether to build train or inference graph
    num_classes: int
        How many classes should be predicted (by fc8)
    random_init_fc8 : bool
        Whether to initialize fc8 layer randomly.
        Finetuning is required in this case.
    debug: bool
        Whether to print additional Debug Information.
    """"""
    # Convert RGB to BGR

    with tf.name_scope('Processing'):
        #import pdb;pdb.set_trace()
        red, green, blue = tf.split(3, 3, rgb)
        # assert red.get_shape().as_list()[1:] == [224, 224, 1]
        # assert green.get_shape().as_list()[1:] == [224, 224, 1]
        # assert blue.get_shape().as_list()[1:] == [224, 224, 1]
        bgr = tf.concat(3, [
            blue - VGG_MEAN[0],
            green - VGG_MEAN[1],
            red - VGG_MEAN[2],
        ])

        if debug:
            bgr = tf.Print(bgr, [tf.shape(bgr)],
                           message='Shape of input image: ',
                           summarize=4, first_n=1)

    self.conv1_1 = self._conv_layer(bgr, ""conv1_1"")
    self.conv1_2 = self._conv_layer(self.conv1_1, ""conv1_2"")
    self.pool1 = self._max_pool(self.conv1_2, 'pool1', debug)

    print(""Pool1 layer ready"")

    self.conv2_1 = self._conv_layer(self.pool1, ""conv2_1"")
    self.conv2_2 = self._conv_layer(self.conv2_1, ""conv2_2"")
    self.pool2 = self._max_pool(self.conv2_2, 'pool2', debug)
    self.conv3_1 = self._conv_layer(self.pool2, ""conv3_1"")
    self.conv3_2 = self._conv_layer(self.conv3_1, ""conv3_2"")
    self.conv3_3 = self._conv_layer(self.conv3_2, ""conv3_3"")
    self.pool3 = self._max_pool(self.conv3_3, 'pool3', debug)

    print(""Pool 3 layer ready"")
    #pdb.set_trace()
    self.conv4_1 = self._conv_layer(self.pool3, ""conv4_1"")
    self.conv4_2 = self._conv_layer(self.conv4_1, ""conv4_2"")
    self.conv4_3 = self._conv_layer(self.conv4_2, ""conv4_3"")
    self.pool4 = self._max_pool(self.conv4_3, 'pool4', debug)

    print(""Pool 4 layer ready"")
    #pdb.set_trace()
    self.conv5_1 = self._conv_layer(self.pool4, ""conv5_1"")
    self.conv5_2 = self._conv_layer(self.conv5_1, ""conv5_2"")
    self.conv5_3 = self._conv_layer(self.conv5_2, ""conv5_3"")
    self.pool5 = self._max_pool(self.conv5_3, 'pool5', debug)

    print(""Pool 5 layer ready"")
    #pdb.set_trace()
    self.fc6 = self._fc_layer(self.pool5, ""fc6"")

    if train:
        self.fc6 = tf.nn.dropout(self.fc6, 0.5)

    self.fc7 = self._fc_layer(self.fc6, ""fc7"")
    if train:
        self.fc7 = tf.nn.dropout(self.fc7, 0.5)

    if random_init_fc8:
        self.score_fr = self._score_layer(self.fc7, ""score_fr"",
                                          num_classes)
    else:
        self.score_fr = self._fc_layer(self.fc7, ""score_fr"",
                                       num_classes=num_classes,
                                       relu=False)

    self.pred = tf.argmax(self.score_fr, dimension=3)

    self.upscore2 = self._upscore_layer(self.score_fr,
                                        shape=tf.shape(self.pool4),
                                        num_classes=num_classes,
                                        debug=debug, name='upscore2',
                                        ksize=4, stride=2)
    self.score_pool4 = self._score_layer(self.pool4, ""score_pool4"",
                                         num_classes=num_classes)
    self.fuse_pool4 = tf.add(self.upscore2, self.score_pool4)
    self.upscore4 = self._upscore_layer(self.fuse_pool4,
                                        shape=tf.shape(self.pool3),
                                        num_classes=num_classes,
                                        debug=debug, name='upscore4',
                                        ksize=4, stride=2)
    self.score_pool3 = self._score_layer(self.pool3, ""score_pool3"",
                                         num_classes=num_classes)
    self.fuse_pool3 = tf.add(self.upscore4, self.score_pool3)

    self.upscore32 = self._upscore_layer(self.fuse_pool3,
                                         shape=tf.shape(bgr),
                                         num_classes=num_classes,
                                         debug=debug, name='upscore32',
                                         ksize=16, stride=8)

    self.pred_up = tf.argmax(self.upscore32, dimension=3)

def _max_pool(self, bottom, name, debug):
    pool = tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],
                          padding='SAME', name=name)

    if debug:
        pool = tf.Print(pool, [tf.shape(pool)],
                        message='Shape of %s' % name,
                        summarize=4, first_n=1)
    return pool

def _conv_layer(self, bottom, name):
    with tf.variable_scope(name) as scope:
        filt = self.get_conv_filter(name)
        conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')

        conv = tf.Print(conv, [tf.shape(conv)], message='Shape of %s' % name, summarize=4, first_n=1)

        conv_biases = self.get_bias(name)
        bias = tf.nn.bias_add(conv, conv_biases)
        if relu:
            bias = tf.nn.relu(bias)
        _activation_summary(bias)

        if debug:
            bias = tf.Print(bias, [tf.shape(bias)],
                            message='Shape of %s' % name,
                            summarize=4, first_n=1)
        return bias`

The driver tensorflow code has this command which produces the error:

` _, loss_value = sess.run([train_op, loss],feed_dict=feed_dict)`

Where loss is the tensorflow op for:

`def loss(logits, labels):
""""""Calculate the loss from the logits and the labels.

Args:
  logits: Logits tensor, float - [batch_size, height, width, NUM_CLASSES].  Must be unsclaed and unsoftmaxed.
  labels: Labels tensor, int32 - [batch_size, height, width].

Returns:
  loss: Loss tensor of type float.
""""""
with tf.name_scope('loss'):
    reshaped_logits = tf.reshape(logits, [-1, 14])  # shape [batch_size*height*width, 14]
    reshaped_labels = tf.reshape(labels, [-1])  # shape [batch_size*height*width]   #Need fix size images for this
    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(reshaped_logits, reshaped_labels)
return loss   `

And training is the driver training function:

`def training(loss, learning_rate):
  """"""Sets up the training Ops.

  Creates a summarizer to track the loss over time in TensorBoard.

  Creates an optimizer and applies the gradients to all trainable variables.

  The Op returned by this function is what must be passed to the
  `sess.run()` call to cause the model to train.

  Args:
    loss: Loss tensor, from loss().
    learning_rate: The learning rate to use for gradient descent.

  Returns:
    train_op: The Op for training.
  """"""
  # Add a scalar summary for the snapshot loss.
  tf.scalar_summary(loss.op.name, loss)
  # Create the gradient descent optimizer with the given learning rate.
  #optimizer = tf.train.GradientDescentOptimizer(learning_rate)
  optimizer = tf.train.AdamOptimizer(1e-6)
  # Create a variable to track the global step.
  print(""Setting step size to 1e-6 for Adam Optimizer"")
  global_step = tf.Variable(0, name='global_step', trainable=False)
  # Use the optimizer to apply the gradients that minimize the loss
  # (and also increment the global step counter) as a single training step.
  print(""Running optimizer"")
  train_op = optimizer.minimize(loss, global_step=global_step)
  return train_op `
```

The debug log from the building of the network is: This contains details of filter and layer shapes etc.

```
`Layer name: conv1_1
Layer shape: (3, 3, 3, 64)
INFO:tensorflow:Created variable conv1_1/filter:0 with shape (3, 3, 3, 64) and init <function _initializer at 0x7fcc27c85ed8>
2016-06-30 14:15:53,939 INFO Created variable conv1_1/filter:0 with shape (3, 3, 3, 64) and init <function _initializer at 0x7fcc27c85ed8>

INFO:tensorflow:Created variable conv1_1/biases:0 with shape (64,) and init <function _initializer at 0x7fcc27c85ed8>
2016-06-30 14:15:53,944 INFO Created variable conv1_1/biases:0 with shape (64,) and init <function _initializer at 0x7fcc27c85ed8>
Layer name: conv1_2
Layer shape: (3, 3, 64, 64)

INFO:tensorflow:Created variable conv1_2/filter:0 with shape (3, 3, 64, 64) and init <function _initializer at 0x7fcc27c96488>
2016-06-30 14:15:53,952 INFO Created variable conv1_2/filter:0 with shape (3, 3, 64, 64) and init <function _initializer at 0x7fcc27c96488>

INFO:tensorflow:Created variable conv1_2/biases:0 with shape (64,) and init <function _initializer at 0x7fcc27c96488>
2016-06-30 14:15:53,956 INFO Created variable conv1_2/biases:0 with shape (64,) and init <function _initializer at 0x7fcc27c96488>
Pool1 layer ready
Layer name: conv2_1
Layer shape: (3, 3, 64, 128)

INFO:tensorflow:Created variable conv2_1/filter:0 with shape (3, 3, 64, 128) and init <function _initializer at 0x7fcc27c9dc08>
2016-06-30 14:15:53,967 INFO Created variable conv2_1/filter:0 with shape (3, 3, 64, 128) and init <function _initializer at 0x7fcc27c9dc08>

INFO:tensorflow:Created variable conv2_1/biases:0 with shape (128,) and init <function _initializer at 0x7fcc27c9dc08>
2016-06-30 14:15:53,972 INFO Created variable conv2_1/biases:0 with shape (128,) and init <function _initializer at 0x7fcc27c9dc08>
Layer name: conv2_2
Layer shape: (3, 3, 128, 128)

INFO:tensorflow:Created variable conv2_2/filter:0 with shape (3, 3, 128, 128) and init <function _initializer at 0x7fcbb3012488>
2016-06-30 14:15:53,980 INFO Created variable conv2_2/filter:0 with shape (3, 3, 128, 128) and init <function _initializer at 0x7fcbb3012488>

INFO:tensorflow:Created variable conv2_2/biases:0 with shape (128,) and init <function _initializer at 0x7fcbb2f8af50>
2016-06-30 14:15:53,985 INFO Created variable conv2_2/biases:0 with shape (128,) and init <function _initializer at 0x7fcbb2f8af50>
Pool 2 layer ready
Layer name: conv3_1
Layer shape: (3, 3, 128, 256)

INFO:tensorflow:Created variable conv3_1/filter:0 with shape (3, 3, 128, 256) and init <function _initializer at 0x7fcbb3012488>
2016-06-30 14:15:53,995 INFO Created variable conv3_1/filter:0 with shape (3, 3, 128, 256) and init <function _initializer at 0x7fcbb3012488>

INFO:tensorflow:Created variable conv3_1/biases:0 with shape (256,) and init <function _initializer at 0x7fcbb1a7cb90>
2016-06-30 14:15:54,000 INFO Created variable conv3_1/biases:0 with shape (256,) and init <function _initializer at 0x7fcbb1a7cb90>
Layer name: conv3_2
Layer shape: (3, 3, 256, 256)

INFO:tensorflow:Created variable conv3_2/filter:0 with shape (3, 3, 256, 256) and init <function _initializer at 0x7fcbb3012488>
2016-06-30 14:15:54,010 INFO Created variable conv3_2/filter:0 with shape (3, 3, 256, 256) and init <function _initializer at 0x7fcbb3012488>

INFO:tensorflow:Created variable conv3_2/biases:0 with shape (256,) and init <function _initializer at 0x7fcbb3012488>
2016-06-30 14:15:54,015 INFO Created variable conv3_2/biases:0 with shape (256,) and init <function _initializer at 0x7fcbb3012488>
Layer name: conv3_3
Layer shape: (3, 3, 256, 256)

INFO:tensorflow:Created variable conv3_3/filter:0 with shape (3, 3, 256, 256) and init <function _initializer at 0x7fcbb1a8aaa0>
2016-06-30 14:15:54,024 INFO Created variable conv3_3/filter:0 with shape (3, 3, 256, 256) and init <function _initializer at 0x7fcbb1a8aaa0>

INFO:tensorflow:Created variable conv3_3/biases:0 with shape (256,) and init <function _initializer at 0x7fcbb1a8aaa0>
2016-06-30 14:15:54,029 INFO Created variable conv3_3/biases:0 with shape (256,) and init <function _initializer at 0x7fcbb1a8aaa0>
Pool 3 layer ready
Layer name: conv4_1
Layer shape: (3, 3, 256, 512)

INFO:tensorflow:Created variable conv4_1/filter:0 with shape (3, 3, 256, 512) and init <function _initializer at 0x7fcbb1a4c7d0>
2016-06-30 14:15:54,043 INFO Created variable conv4_1/filter:0 with shape (3, 3, 256, 512) and init <function _initializer at 0x7fcbb1a4c7d0>

INFO:tensorflow:Created variable conv4_1/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb1a4c7d0>
2016-06-30 14:15:54,048 INFO Created variable conv4_1/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb1a4c7d0>
Layer name: conv4_2
Layer shape: (3, 3, 512, 512)

INFO:tensorflow:Created variable conv4_2/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb1a12500>
2016-06-30 14:15:54,063 INFO Created variable conv4_2/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb1a12500>

INFO:tensorflow:Created variable conv4_2/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb1a12500>
2016-06-30 14:15:54,068 INFO Created variable conv4_2/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb1a12500>
Layer name: conv4_3
Layer shape: (3, 3, 512, 512)

INFO:tensorflow:Created variable conv4_3/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb19d89b0>
2016-06-30 14:15:54,083 INFO Created variable conv4_3/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb19d89b0>

INFO:tensorflow:Created variable conv4_3/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb19d89b0>
2016-06-30 14:15:54,088 INFO Created variable conv4_3/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb19d89b0>
Pool 4 layer ready
Layer name: conv5_1
Layer shape: (3, 3, 512, 512)

INFO:tensorflow:Created variable conv5_1/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb199f6e0>
2016-06-30 14:15:54,103 INFO Created variable conv5_1/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb199f6e0>

INFO:tensorflow:Created variable conv5_1/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb199f6e0>
2016-06-30 14:15:54,108 INFO Created variable conv5_1/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb199f6e0>
Layer name: conv5_2
Layer shape: (3, 3, 512, 512)

INFO:tensorflow:Created variable conv5_2/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb1961488>
2016-06-30 14:15:54,122 INFO Created variable conv5_2/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb1961488>

INFO:tensorflow:Created variable conv5_2/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb18daf50>
2016-06-30 14:15:54,127 INFO Created variable conv5_2/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb18daf50>
Layer name: conv5_3
Layer shape: (3, 3, 512, 512)

INFO:tensorflow:Created variable conv5_3/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb1961488>
2016-06-30 14:15:54,141 INFO Created variable conv5_3/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb1961488>

INFO:tensorflow:Created variable conv5_3/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb1961488>
2016-06-30 14:15:54,146 INFO Created variable conv5_3/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb1961488>
Pool 5 layer ready
Layer name: fc6
Layer shape: [7, 7, 512, 4096]

INFO:tensorflow:Created variable fc6/weights:0 with shape (7, 7, 512, 4096) and init <function _initializer at 0x7fcbb186b5f0>
2016-06-30 14:15:54,435 INFO Created variable fc6/weights:0 with shape (7, 7, 512, 4096) and init <function _initializer at 0x7fcbb186b5f0>

INFO:tensorflow:Created variable fc6/biases:0 with shape (4096,) and init <function _initializer at 0x7fcbb186b5f0>
2016-06-30 14:15:54,438 INFO Created variable fc6/biases:0 with shape (4096,) and init <function _initializer at 0x7fcbb186b5f0>
Layer name: fc7
Layer shape: [1, 1, 4096, 4096]

INFO:tensorflow:Created variable fc7/weights:0 with shape (1, 1, 4096, 4096) and init <function _initializer at 0x7fcbb189fed8>
2016-06-30 14:15:54,492 INFO Created variable fc7/weights:0 with shape (1, 1, 4096, 4096) and init <function _initializer at 0x7fcbb189fed8>

INFO:tensorflow:Created variable fc7/biases:0 with shape (4096,) and init <function _initializer at 0x7fcbb189fed8>
2016-06-30 14:15:54,495 INFO Created variable fc7/biases:0 with shape (4096,) and init <function _initializer at 0x7fcbb189fed8>

INFO:tensorflow:Created variable score_fr/weights:0 with shape (1, 1, 4096, 14) and init <function _initializer at 0x7fcbb186b5f0>
2016-06-30 14:15:54,506 INFO Created variable score_fr/weights:0 with shape (1, 1, 4096, 14) and init <function _initializer at 0x7fcbb186b5f0>

INFO:tensorflow:Created variable score_fr/biases:0 with shape (14,) and init <function _initializer at 0x7fcbb186b5f0>
2016-06-30 14:15:54,510 INFO Created variable score_fr/biases:0 with shape (14,) and init <function _initializer at 0x7fcbb186b5f0>

INFO:tensorflow:Created variable upscore2/up_filter:0 with shape (4, 4, 14, 14) and init <function _initializer at 0x7fcbb17a48c0>
2016-06-30 14:15:54,525 INFO Created variable upscore2/up_filter:0 with shape (4, 4, 14, 14) and init <function _initializer at 0x7fcbb17a48c0>

INFO:tensorflow:Created variable score_pool4/weights:0 with shape (1, 1, 512, 14) and init <function _initializer at 0x7fcbb17a48c0>
2016-06-30 14:15:54,536 INFO Created variable score_pool4/weights:0 with shape (1, 1, 512, 14) and init <function _initializer at 0x7fcbb17a48c0>

INFO:tensorflow:Created variable score_pool4/biases:0 with shape (14,) and init <function _initializer at 0x7fcbb17a48c0>
2016-06-30 14:15:54,540 INFO Created variable score_pool4/biases:0 with shape (14,) and init <function _initializer at 0x7fcbb17a48c0>

INFO:tensorflow:Created variable upscore4/up_filter:0 with shape (4, 4, 14, 14) and init <function _initializer at 0x7fcbb16c0aa0>
2016-06-30 14:15:54,555 INFO Created variable upscore4/up_filter:0 with shape (4, 4, 14, 14) and init <function _initializer at 0x7fcbb16c0aa0>

INFO:tensorflow:Created variable score_pool3/weights:0 with shape (1, 1, 256, 14) and init <function _initializer at 0x7fcbb16c0aa0>
2016-06-30 14:15:54,566 INFO Created variable score_pool3/weights:0 with shape (1, 1, 256, 14) and init <function _initializer at 0x7fcbb16c0aa0>

INFO:tensorflow:Created variable score_pool3/biases:0 with shape (14,) and init <function _initializer at 0x7fcbb16c0aa0>
2016-06-30 14:15:54,570 INFO Created variable score_pool3/biases:0 with shape (14,) and init <function _initializer at 0x7fcbb16c0aa0>

INFO:tensorflow:Created variable upscore32/up_filter:0 with shape (16, 16, 14, 14) and init <function _initializer at 0x7fcbb15eb758>
2016-06-30 14:15:54,585 INFO Created variable upscore32/up_filter:0 with shape (16, 16, 14, 14) and init <function _initializer at 0x7fcbb15eb758>`
```

Been stuck on this for quite some time and cant figure out whats wrong... Any help will be appreciated :)
"
3173,Pip should not install as super user in the install tutorial (sudo pip install ),"Is there a particular reason it is installed as root in this case? It is usually deprecated to do it this way. 
"
3172,float division by zero,"It seems that if you only run 1 training step at a time then you can come to a point where it is too fast

```
Traceback (most recent call last):
  File ""main.py"", line 6, in <module>
    connection.start_socket(8089, callback=handler.message_processor)
  File ""/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/connection/python_socket_server.py"", line 13, in start_socket
    process_message(connection, callback=callback)
  File ""/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/connection/python_socket_server.py"", line 38, in process_message
    result = callback(general_proto)
  File ""/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/recognition/proto_handler.py"", line 39, in message_processor
    return train_shape(general_proto.template)
  File ""/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/recognition/proto_handler.py"", line 23, in train_shape
    rec.add_training_data(recognition_template.interpretation.label, recognition_template.shape)
  File ""/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/recognition/recognition_manager.py"", line 98, in add_training_data
    self.recognizers[label].train(label, points)
  File ""/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/recognition/simple/recognizer.py"", line 82, in train
    self.classifier.fit(x=reshaped_points, y=target, steps=1)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 182, in fit
    monitors=monitors)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 484, in _train_model
    monitors=monitors)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 296, in train
    supervisor.Stop(close_summary_writer=False)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 768, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py"", line 322, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py"", line 267, in stop_on_exception
    yield
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py"", line 411, in run
    self.run_loop()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 1012, in run_loop
    steps_per_sec = added_steps / elapsed_time
ZeroDivisionError: float division by zero
```

This happens because the time between the start of the step and the end is exactly the same because it is a single step.

Here is the code snippet

```
current_time = time.time()
    elapsed_time = current_time - self._last_time
    self._last_time = current_time
    # Reports the number of steps done per second
    steps_per_sec = added_steps / elapsed_time
    summary = Summary(value=[Summary.Value(tag=self._summary_tag,
                                           simple_value=steps_per_sec)])
```

Maybe add an if statement to just say zero if elapsed_time is zero?
"
3170,Gradients are always zero during training,"I have implemented [YOLO](http://pjreddie.com/media/files/papers/yolo.pdf) algorithm in tensorflow and face with an issue during training: all my gradients are equal to zero from the very beginning of training. I also noticed that with some weights initialization gradients become non-zero at first several iterations and then stick to zero. Thanks in advance for any help!
### Environment info

Operating System: Ubuntu 16.04 lts
Tensorflow version: 0.8.0
"
3169,AttributeError: 'module' object has no attribute 'linear',"I'm trying to run this tutorial : https://medium.com/@ilblackdragon/tensorflow-tutorial-part-1-c559c63c0cb1#.1a7hit535

I have got some errors on this bug report : https://github.com/tensorflow/tensorflow/issues/3167

Then I have tried to fix it by modifying the TF Learn code. 
### Environment info

Operating System: Linux Mint 17.3 Rosa
$uname -a

Linux Pabeda 3.19.0-32-generic #37~14.04.1-Ubuntu SMP Thu Oct 22 09:41:40 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux

$python -c ""import tensorflow; print(tensorflow.version)""
0.9.0
### Steps to reproduce
1. $ git clone https://github.com/ilblackdragon/tf_examples.git
2. edit /usr/local/lib/python2.7/dist-packages/skflow/trainer.py

Line 146 

replace
`if summaries`
with
`if summaries is not None:`

Line 167

replace
`if summaries  and summary_writer and summ is not None`
with
`if summaries is not None and summary_writer is not None and summ is not None:`

3.$python titanic.py
### Errors

Traceback (most recent call last):
  File ""titanic.py"", line 41, in <module>
    classifier.fit(X_train, y_train)
  File ""/usr/local/lib/python2.7/dist-packages/skflow/estimators/base.py"", line 200, in fit
    self._setup_training()
  File ""/usr/local/lib/python2.7/dist-packages/skflow/estimators/base.py"", line 139, in _setup_training
    self._inp, self._out)
  File ""/usr/local/lib/python2.7/dist-packages/skflow/estimators/dnn.py"", line 82, in _model_fn
    models.logistic_regression)(X, y)
  File ""/usr/local/lib/python2.7/dist-packages/skflow/models.py"", line 99, in dnn_estimator
    layers = dnn(X, hidden_units)
  File ""/usr/local/lib/python2.7/dist-packages/skflow/ops/dnn_ops.py"", line 39, in dnn
    tensor_in = tf.nn.rnn_cell.linear(tensor_in, n_units, True)
AttributeError: 'module' object has no attribute 'linear'
"
3168,fully_connected_preloaded example: Attempting to use uninitialized value input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs,"I have the error `Attempting to use uninitialized value input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs` when I load data in my code. I have found the same issue on the fully_connected_preloaded example, so I think it may be a regression.
### Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: Cuda 8.0 and CuDnn 8.0

``` bash
$ ls -l /path/to/cuda/lib*/libcud*
-rw-r--r-- 1 root root   560184 juin  30 00:45 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 juin  30 00:45 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 juin  30 00:45 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 juin  30 00:45 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 juin  30 00:45 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 78065952 juin  30 01:08 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 78065952 juin  30 01:08 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 78065952 juin  30 01:08 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 68709594 juin  30 01:08 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from sources, provide the commit hash: db90885e9f27b1e069dd689ddd2dd3b743ed1cb7
### Steps to reproduce
1. cd tensorflow/examples/how_tos/reading_data
2. python fully_connected_preloaded.py
### What have you tried?
1. `bazel run -c opt tensorflow/examples/how_tos/reading_data:fully_connected_preloaded``
2. `python fully_connected_preloaded.py`
3. My code, which is similar
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

``` python
python fully_connected_preloaded.py
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
Extracting /tmp/data/train-images-idx3-ubyte.gz
Extracting /tmp/data/train-labels-idx1-ubyte.gz
Extracting /tmp/data/t10k-images-idx3-ubyte.gz
Extracting /tmp/data/t10k-labels-idx1-ubyte.gz
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:02:00.0
Total memory: 7.92GiB
Free memory: 7.52GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)
Saving
W tensorflow/core/framework/op_kernel.cc:936] Out of range: FIFOQueue '_1_input/input_producer/input_producer/fraction_of_32_full/fraction_of_32_full' is closed and has insufficient elements (requested 1, current size 0)
     [[Node: input/input_producer/fraction_of_32_full_Dequeue = QueueDequeue[_class=[""loc:@input/input_producer/input_producer/fraction_of_32_full/fraction_of_32_full""], component_types=[DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](input/input_producer/input_producer/fraction_of_32_full/fraction_of_32_full)]]
Done training for 2 epochs, 0 steps.
Traceback (most recent call last):
  File ""fully_connected_preloaded.py"", line 157, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""fully_connected_preloaded.py"", line 153, in main
    run_training()
  File ""fully_connected_preloaded.py"", line 148, in run_training
    coord.join(threads)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py"", line 333, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner.py"", line 185, in _run
    sess.run(enqueue_op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 382, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 655, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 723, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 743, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs
     [[Node: input/input_producer/input_producer/fraction_of_32_full/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, _class=[""loc:@input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs""], limit=2, _device=""/job:localhost/replica:0/task:0/cpu:0""](input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs)]]
Caused by op u'input/input_producer/input_producer/fraction_of_32_full/limit_epochs/CountUpTo', defined at:
  File ""fully_connected_preloaded.py"", line 157, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""fully_connected_preloaded.py"", line 153, in main
    run_training()
  File ""fully_connected_preloaded.py"", line 73, in run_training
    [input_images, input_labels], num_epochs=FLAGS.num_epochs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py"", line 266, in slice_input_producer
    shared_name=shared_name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py"", line 223, in range_input_producer
    shared_name, name, ""fraction_of_%d_full"" % capacity)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py"", line 133, in input_producer
    input_tensor = limit_epochs(input_tensor, num_epochs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py"", line 84, in limit_epochs
    counter = epochs.count_up_to(num_epochs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 573, in count_up_to
    return state_ops.count_up_to(self._variable, limit=limit)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 127, in count_up_to
    result = _op_def_lib.apply_op(""CountUpTo"", ref=ref, limit=limit, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 703, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2297, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1231, in __init__
    self._traceback = _extract_stack()
```
"
3167,Using a `tf.Tensor` as a Python `bool` is not allowed.,"### Environment info

Operating System: Linux Mint 17.3 Rosa
$uname -a

Linux Pabeda 3.19.0-32-generic #37~14.04.1-Ubuntu SMP Thu Oct 22 09:41:40 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux

$python -c ""import tensorflow; print(tensorflow.**version**)""
0.9.0
### Steps to reproduce

$ git clone https://github.com/ilblackdragon/tf_examples.git
$ python titanic.py
### What have you tried?
1. I'm trying to run the tutorial on : https://medium.com/@ilblackdragon/tensorflow-tutorial-part-1-c559c63c0cb1#.1a7hit535
### Errors

/usr/local/lib/python2.7/dist-packages/skflow/io/data_feeder.py:217: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  out.itemset((i, self.y[sample]), 1.0)
Traceback (most recent call last):
  File ""titanic.py"", line 30, in <module>
    tflr.fit(X_train, y_train)
  File ""/usr/local/lib/python2.7/dist-packages/skflow/estimators/base.py"", line 227, in fit
    feed_params_fn=self._data_feeder.get_feed_params)
  File ""/usr/local/lib/python2.7/dist-packages/skflow/trainer.py"", line 146, in train
    if summaries:
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 528, in __nonzero__
    raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""
TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use the logical TensorFlow ops to test the value of a tensor.
"
3165,AttributeError: 'Tensor' object has no attribute 'shape',"### Environment info

Operating System:  BashOn Windows

Installed version of CUDA and cuDNN: 
(doesnt matter CPU version only)

If installed from binary pip package, provide:
0.9.0

If installed from sources, provide the commit hash:
### Steps to reproduce

```
    def create_classifier(self):
        hiddenLayers = [self.num_points, self.num_points * 2, 10]
        self.classifier = tf.contrib.learn.DNNClassifier(hidden_units=hiddenLayers)
```

label is a string
point list is a list of an array of x, y values
ex:

```
[[1,2],[2,3],[3,4],...]
```

```
    def train(self, label, point_list):
        points = self.resample(point_list, self.num_points)
        utils.strip_ids_from_points(points)
        value_class = 1 if label == self.label else 0
        target = tf.reshape(tf.constant(value_class), [1])
        print 'training classifier to recognize value as: [' + str(value_class) + '] label is ' + label + ' class is ' + self.label
        point_tensor = tf.convert_to_tensor(points, dtype=tf.float32)
        reshaped_tensor = tf.reshape(point_tensor, [1, self.num_points * 2])
        print reshaped_tensor
        print target
        self.classifier.fit(x=reshaped_tensor, y=target, steps=1)
```
### What have you tried?

googling why a tensor would not have a shape attribute
### Logs or other output that would be helpful

```
Tensor(""Reshape_1:0"", shape=(1, 64), dtype=float32)
Tensor(""Reshape:0"", shape=(1,), dtype=int32)
Traceback (most recent call last):
  File ""main.py"", line 6, in <module>
    connection.start_socket(8089, callback=handler.message_processor)
  File ""/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/connection/python_socket_server.py"", line 13, in start_socket
    process_message(connection, callback=callback)
  File ""/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/connection/python_socket_server.py"", line 38, in process_message
    result = callback(general_proto)
  File ""/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/recognition/proto_handler.py"", line 39, in message_processor
    return train_shape(general_proto.template)
  File ""/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/recognition/proto_handler.py"", line 23, in train_shape
    rec.add_training_data(recognition_template.interpretation.label, recognition_template.shape)
  File ""/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/recognition/recognition_manager.py"", line 98, in add_training_data
    self.recognizers[label].train(label, points)
  File ""/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/recognition/simple/recognizer.py"", line 78, in train
    self.classifier.fit(x=reshaped_tensor, y=target, steps=1)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 173, in fit
    input_fn, feed_fn = _get_input_fn(x, y, batch_size)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 67, in _get_input_fn
    x, y, n_classes=None, batch_size=batch_size)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py"", line 117, in setup_train_data_feeder
    X, y, n_classes, batch_size, shuffle=shuffle, epochs=epochs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py"", line 239, in __init__
    self.X.shape, None if self.y is None else self.y.shape, n_classes,
AttributeError: 'Tensor' object has no attribute 'shape'
```
"
3163,the results is not reproducible,"the results is not reproducible due to some random factors, is there a way to reproduce the exactly same result in NN training
"
3161,Sequence_Length for RNN Bug,"I'm using the current up-to-date version of Tensorflow for Apple. For Long-Short Term Memory, there is an error which prevents me from specifying the sequence length [batch_size] Tensor. Code used to work until I updated Tensorflow:

`seq_len = tf.placeholder(""int64"", [batch_size])`

...
...
...

`lstm_fw1_cell = rnn_cell.BasicLSTMCell(n_LSTM_input, forget_bias=1.0)`

`state_fw1 = tf.fill([batch_size,2*n_LSTM_input], constant(0, dtype=tf.float32))`

`outputs, states = rnn.rnn(lstm_fw1_cell, _X, initial_state=state_fw1, scope=""LSTM1"", sequence_length=_seq_len)`

Error:
File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 112, in rnn
    lambda: zero_output_state, output_state)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 642, in cond
    res_f = context_f.BuildCondBranch(fn2)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 568, in BuildCondBranch
    r = fn()
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 107, in output_state
    return cell(input_, state)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py"", line 190, in **call**
    concat = linear([inputs, h], 4 \* self._num_units, True)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py"", line 667, in linear
    shapes = [a.get_shape().as_list() for a in args]
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 722, in as_list
    return [dim.value for dim in self._dims]
TypeError: 'NoneType' object is not iterable
"
3160,iOS: No OpKernel was registered to support Op 'Assign',"`Running model failed: Invalid argument: No OpKernel was registered to support Op 'Assign' with these attrs
     [[Node: save/Assign_18 = Assign[T=DT_INT64, _class=[""loc:@input_producer/limit_epochs/epochs""], use_locking=true, validate_shape=true, _device=""/device:CPU:0""](input_producer/limit_epochs/epochs, save/restore_slice_18)]]`

Tensorflow 0.9 iOS build.
Model+graph: https://cloud.mail.ru/public/EhFP/eN1dwHhQR

I have added
./ops/state_ops.cc
./kernels/dense_update_ops.cc

to the tensorflow/contrib/makefile/tf_cc_files.txt

But with no result.
"
3159,How to remember the unit position of Dropout,"I am using dropout in my neural network:

```
W   = tf.get_variable(""W"", [hidden_unit, 50]) 

def RNN_L1(x,  initial_state,  real_length):
                x = tf.transpose(x, [1, 0, 2]) 
                x = tf.reshape(x, [-1, word_dim]) 

                lstm_cell = rnn_cell.LSTMCell(num_units = hidden_unit, input_size = word_dim)

                x = tf.split(0, sequence_length, x)
                outputs, _ = rnn.rnn(lstm_cell, x, initial_state=initial_state, sequence_length=real_length)

                return outputs



outputs_L1  =  RNN_L1(x_vec,      self.initial_stateL1,     self.real_length)
outputs_L1  =  tf.pack(outputs_L1)


tensor_shape = outputs_L1.get_shape()

for step_index in range(tensor_shape[0]):
                output_relu= tf.matmul(outputs_L1[step_index,  :,  :], W) + B
                output_relu= tf.nn.relu(output_relu)
                output_relu = tf.nn.dropout(output_relu, self.dropout_keep_prob)
```

**outputs_L1** is the output of LSTM which has 3D-Tensor[sentence length, batchsize, hidden unit]. So, you can see the ""for loop"" code, I use ""for loop"" to do dropout for each **outputs_L1[step_index,  :,  :]**. But in this way, each outputs_L1[step_index,  :,  :] has it's own position of dropout. 

For example:
**outputs_L1[1,  :,  :]** and **outputs_L1[2,  :,  :]** have different position of dropout at 
`output_relu = tf.nn.dropout(output_relu, self.dropout_keep_prob)`.

What I want is that they have same dropout position in ""for loop"". Can you help me?
"
3155,More clear error message required,"Tensorflow 0.9.0

Trying to load and execute that graph+checkpoint from C++ API: https://cloud.mail.ru/public/5yk3/No887jqS8

Model was prepared using 'freeze_graph.py'

Code based on Tensorflow examples(graph contains no input layer):
`std::string output_layer = ""output_node"";
    std::vector<tensorflow::Tensor> outputs;
    tensorflow::Status run_status = session->Run({{}},{output_layer}, {}, &outputs);
    if (!run_status.ok()) {
        LOG(ERROR) << ""Running model failed: "" << run_status;
        return;
    }
    tensorflow::string status_string = run_status.ToString();
    NSLog(@""%s"",status_string.c_str());
`

Error:

> Running model failed: Invalid argument: No OpKernel was registered to support Op 'PaddingFIFOQueue' with these attrs
>      [[Node: batch/padding_fifo_queue = PaddingFIFOQueue[capacity=32, component_types=[DT_FLOAT], container="""", shapes=[[-1,-1,3]], shared_name=""""]()]]

And that's all. Nothing that can help me to understand what to do with the error. The only information I was able to find is that the error might be due to GPU only operation, but same model runs fine from python in CPU only mode.

Clearly don't know what to do with this error message. Created stackoverflow question http://stackoverflow.com/questions/38155086/no-opkernel-was-registered-to-support-op-paddingfifoqueue-with-these-attrs And hope for some insights.

I think that it would be very useful to elaborate on this kind of errors in run_status.
"
3154,can't enable --config=cuda,"I successfully built tensorflow 0.9.0 with bazel 0.3.0 on Redhat Enterprices 6.6 without cuda support. 
### but when I enable --config=cuda, the build process stopped at linking '@protobuf//:protoc'

I suspected some settings associate with both cuda and python are incorrect (from the highlighted error logs) but have no idea how to reconfigure. Can you please help to find the problem?  I am using python2.7.11 from anaconda2

Thanks,
-Wei

$ bazel build --config=cuda @protobuf//:protoc --verbose_failures --keep_going
WARNING: /root/.cache/bazel/_bazel_root/33ff58ac202e7ac02dc3ff3533effc70/external/protobuf/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/33ff58ac202e7ac02dc3ff3533effc70/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
INFO: Found 1 target...
ERROR: /root/.cache/bazel/_bazel_root/33ff58ac202e7ac02dc3ff3533effc70/external/protobuf/BUILD:331:1: Couldn't build file external/protobuf/protoc: Linking of rule '@protobuf//:protoc' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /root/.cache/bazel/_bazel_root/33ff58ac202e7ac02dc3ff3533effc70/execroot/tensorflow.gpu && \
  exec env - \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/local_linux-fastbuild/bin/external/protobuf/protoc bazel-out/local_linux-fastbuild/bin/external/protobuf/_objs/protoc/external/protobuf/src/google/protobuf/compiler/main.pic.o bazel-out/local_linux-fastbuild/bin/external/protobuf/libprotoc_lib.a bazel-out/local_linux-fastbuild/bin/external/protobuf/libprotobuf.a bazel-out/local_linux-fastbuild/bin/external/protobuf/libprotobuf_lite.a -lpthread -lstdc++ -B/usr/local/bin/ -pie -fPIC -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,-S): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
### Could not find platform independent libraries <prefix>
### Could not find platform dependent libraries <exec_prefix>
### Consider setting $PYTHONHOME to <prefix>[:<exec_prefix>]
### ImportError: No module named site

Target @protobuf//:protoc failed to build
INFO: Elapsed time: 0.354s, Critical Path: 0.01s
"
3152,num_epochs does not work in modified cifar10,"I am running cifar10 examples and have made some changes. I would like to evaluate every example only once, while the original example can only do mass evaluation. My question are described [here](http://stackoverflow.com/questions/38125436/tensorflow-how-to-evaluate-all-test-set-with-every-example-once-and-only-once). And was suggested by changing function 'tf.train.string_input_producer'.

But it failed and I also found a similar [question](http://stackoverflow.com/questions/35674073/compute-status-not-found-tensor-name-input-producer-limit-epochs-epochs-not) but with no final solution given, @mrry .

And this problem can also solve other problems including this [one](http://stackoverflow.com/questions/36960457/tensorflow-evaluate-with-confusion-matrix) here.

Thank you in advance.
"
3148,nan error: linear regression demo at tensorflow.org,"There is a linear regression demo on [Here](https://www.tensorflow.org/versions/r0.9/get_started/index.html).
The x_data is generate by

``` python
x_data = np.random.rand(100).astype(np.float32)
```

but when I change it to

``` python
x_data = np.arange(100).astype(np.float32)
```

the ""w"" and ""b"" will become ""nan"".
"
3147,Better way to count number of zero elements across a dimension?,"I was wondering whether there is a nicer way to count the number of zero elements across a given dimension? Looking through the API the closest result is `tf.unique_with_counts` ([link](https://www.tensorflow.org/versions/r0.9/api_docs/python/array_ops.html#unique_with_counts)) but this operation returns the values in order of occurrence so I first would need to find the index of the zero-element. The solution that I am currently using is not very elegant:

``` python
x = np.asarray([[0, 0, 1], [1, 0, 3], [1, 2, 3]])

a = tf.Variable(x)
zero_elements = tf.equal(a, tf.zeros_like(a))
count_zeros_per_row = tf.reduce_sum(tf.to_int32(zero_elements), reduction_indices=1)

# result => [2, 1, 0]
```

Would be nice to have operations to count the (non-)zero elements across a given dimension.
"
3146,eigen-eigen issue,"Hi,

I am trying to compile an example with C++ api, and I'm running into this issue:

```
In file included from /Users/danieleghisi/max-sdk-7.0.3/source/fool/mains/dg/fool.rnn.c:53:
In file included from /Users/danieleghisi/LibrariesAndStuff/tensorflow/tensorflow/cc/ops/standard_ops.h:22:
In file included from /Users/danieleghisi/LibrariesAndStuff/tensorflow/tensorflow/cc/ops/array_ops.h:6:
In file included from /Users/danieleghisi/LibrariesAndStuff/tensorflow/tensorflow/core/framework/tensor.h:21:
In file included from /Users/danieleghisi/LibrariesAndStuff/tensorflow/tensorflow/core/framework/allocator.h:25:
In file included from /Users/danieleghisi/LibrariesAndStuff/tensorflow/tensorflow/core/framework/type_traits.h:22:
In file included from /Users/danieleghisi/LibrariesAndStuff/tensorflow/tensorflow/core/framework/types.h:23:
/Users/danieleghisi/LibrariesAndStuff/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:10: fatal error: 'eigen-eigen-334b1d428283/unsupported/Eigen/CXX11/Tensor' file not found
```

I do not seem to have an ""eigen-eigen-334b1d428283"" folder anywhere. 
There's an eigen.BUILD file at the root level, but I am unable to bazel it with 
`bazel build eigen`
nor
`bazel build tensorflow/eigen`
(but it should be the first one, isn't it? eigen.BUILD being at the root level... Or how does bazel work in this respect?)

Should I build that file via bazel? I guess I should. (but how do I build in general a xxxx.BUILD file, given that bazel build xxxx doesn't work?)

Thanks a lot,
daniele
### Environment info

Operating System: Mac OS X 10.10
Installed version of CUDA: 7.5
"
3144,Weird behavior with no skflow installation.,"Environment info: Pycharm-Community Editon
Operating System: Ubuntu-14.04-x64
Pip package: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl
Tensorflow version 0.9.0 (from python -c import tensorflow)

When I was trying the text_classification examples from skflow repository (which are now moved to tensorflow), at line: `word_list = tf.unpack(word_vectors, axis=1)` it threw an error that says:
`TypeError: unpack() got an unexpected keyword argument 'axis'`

When I browsed the commit history on git, It says 

> 2 days ago: Switch from split_squeeze to tf.unpack where it makes sense.

earlier it was working fine. Also it works fine when I run it on machine with skflow installed on it.
I have used `tensorflow.contrib.learn as skflow` as directed on the tensorflow home page.But somehow it doesn't work.

I have explored the `tf.unpack()` to check if it takes `axis` as an argument, but it doesn't. When I pass some other number that 1 to the `tf.unpack()` it says `num can not infer from shape (?,50,10)`
"
3139,Building tensorflow (makefile method) on arhmf Olimex A20,"Building tensorflow using the makefile method, i get the below error, 

`PROTOC = ""protoc""
CC_PREFIX = """"
gcc --std=c++11 -DIS_SLIM_BUILD -O0 -I/usr/local/include -I. -I/home/olimex/tf/tensorflow/tensorflow/contrib/makefile/downloads/ -I/home/olimex/tf/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-334b1d428283 -I/home/olimex/tf/tensorflow/tensorflow/contrib/makefile/gen/proto/ -I/home/olimex/tf/tensorflow/tensorflow/contrib/makefile/gen/proto_text/ \
        -o /home/olimex/tf/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark /home/olimex/tf/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/core/util/reporter.o /home/olimex/tf/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/tools/benchmark/benchmark_model.o /home/olimex/tf/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/tools/benchmark/benchmark_model_main.o \
         -Wl,--allow-multiple-definition -Wl,--whole-archive /home/olimex/tf/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a -L/usr/local/lib -lstdc++ -lprotobuf -lz -lm -ldl -lpthread
/usr/lib/gcc/arm-linux-gnueabihf/4.8/libgcc.a(fp16.o): In function`__gnu_h2f_ieee':
(.text+0x12a): relocation truncated to fit: R_ARM_THM_JUMP11 against symbol `__gnu_h2f_internal' defined in .text section in /usr/lib/gcc/arm-linux-gnueabihf/4.8/libgcc.a(fp16.o)
/usr/lib/gcc/arm-linux-gnueabihf/4.8/libgcc.a(fp16.o): In function`__gnu_h2f_alternative':
(.text+0x132): relocation truncated to fit: R_ARM_THM_JUMP11 against symbol `__gnu_h2f_internal' defined in .text section in /usr/lib/gcc/arm-linux-gnueabihf/4.8/libgcc.a(fp16.o)
/usr/lib/gcc/arm-linux-gnueabihf/4.8/libgcc.a(fp16.o): In function`__gnu_h2f_ieee':
(.text+0x12a): relocation truncated to fit: R_ARM_THM_JUMP11 against symbol `__gnu_h2f_internal' defined in .text section in /usr/lib/gcc/arm-linux-gnueabihf/4.8/libgcc.a(fp16.o)
/usr/lib/gcc/arm-linux-gnueabihf/4.8/libgcc.a(fp16.o): In function`__gnu_h2f_alternative':
(.text+0x132): relocation truncated to fit: R_ARM_THM_JUMP11 against symbol `__gnu_h2f_internal' defined in .text section in /usr/lib/gcc/arm-linux-gnueabihf/4.8/libgcc.a(fp16.o)
/usr/lib/gcc/arm-linux-gnueabihf/4.8/libgcc.a(fp16.o): In function`__gnu_h2f_ieee':
(.text+0x12a): relocation truncated to fit: R_ARM_THM_JUMP11 against symbol `__gnu_h2f_internal' defined in .text section in /usr/lib/gcc/arm-linux-gnueabihf/4.8/libgcc.a(fp16.o)
/usr/lib/gcc/arm-linux-gnueabihf/4.8/libgcc.a(fp16.o): In function`__gnu_h2f_alternative':
(.text+0x132): relocation truncated to fit: R_ARM_THM_JUMP11 against symbol `__gnu_h2f_internal' defined in .text section in /usr/lib/gcc/arm-linux-gnueabihf/4.8/libgcc.a(fp16.o)
collect2: error: ld returned 1 exit status`

From what i understand this appears to be an issue with the linker trying to branch on a long address, 
https://lists.gnu.org/archive/html/bug-binutils/2007-06/msg00065.html
But this issue is back from 2007, any workaround i can do on the source to avoid this?

System:
gcc version 4.8.4 (Debian 4.8.4-1)
GNU ld (GNU Binutils for Debian) 2.25
"
3138,weird behavior on GPU ec2 - zero tensor instead of random one on local machine,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Ubuntu 14.04 
Linux ip-172-31-7-130 3.13.0-88-generic #135-Ubuntu SMP Wed Jun 8 21:10:42 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

Installed version of CUDA and cuDNN: cuda 7.5, cudnn 5.0.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root 189170 Jun 12 02:51 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Jun 12 02:51 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Jun 12 02:51 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Jun 12 02:51 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Jun 12 02:51 /usr/local/cuda/lib/libcudart_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so.7.5 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so.5.0.5 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so.7.5 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so.7.5 locally
   0.8.0

If installed from sources, provide the commit hash:
9b69ec3960cf9225df557fdc1ab673bd36bde4fb
### Steps to reproduce

1.
import tensorflow as tf
a=tf.Variable(tf.random_uniform([5], 0, 10, dtype=tf.int32, seed=10))
init = tf.initialize_all_variables()
with tf.Session() as sess:
    sess.run(init)
    result=sess.run(a)
    print(result)
    sess.close()

the result is: [0 0 0 0 0] 
2. If i run it locally (on my mac laptop where tensorflow was installed via pip - i dont have a gpu), i get: [ 33689671 570442370 201367012 671088640 671145444]
3. I have python 3.5.1 , miniconda --version = ""conda 4.1.5"", run on EC2 , GPU K520
### What have you tried?
1. inside miniconda, outside it..
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3135,Raspberry Pi build error,"I am trying to build tensorflow on a Raspberry Pi 3 (Raspbian OS, gcc 4.9.2, no USB stick for swap) according to the steps provided [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile).  When I execute the following make command,

make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI \
 OPTFLAGS=""-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize""

I am getting the error reproduced below.  Is this an eigen issue?  Any suggestions on how to overcome this error?

---

In file included from /usr/include/c++/4.9/atomic:41:0,
                 from /home/pi/Desktop/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-334b1d428283/unsupported/Eigen/CXX11/ThreadPool:40,
                 from /home/pi/Desktop/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-334b1d428283/unsupported/Eigen/CXX11/Tensor:57,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from tensorflow/core/lib/core/threadpool.cc:19:
/usr/include/c++/4.9/bits/atomic_base.h: In member function void Eigen::EventCount::CancelWait(Eigen::EventCount::Waiter_):
/usr/include/c++/4.9/bits/atomic_base.h:538:70: error: failure memory model cannot be stronger than success memory model for __atomic_compare_exchange
  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 1, __m1, __m2);
                                                                      ^
/usr/include/c++/4.9/bits/atomic_base.h: In member function void Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter_):
/usr/include/c++/4.9/bits/atomic_base.h:538:70: error: failure memory model cannot be stronger than success memory model for __atomic_compare_exchange
  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 1, __m1, __m2);
                                                                      ^
/usr/include/c++/4.9/bits/atomic_base.h: In member function void Eigen::EventCount::Notify(bool):
/usr/include/c++/4.9/bits/atomic_base.h:538:70: error: failure memory model cannot be stronger than success memory model for __atomic_compare_exchange
  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 1, __m1, __m2);
                                                                      ^
/usr/include/c++/4.9/bits/atomic_base.h: In member function Work Eigen::RunQueue<Work, kSize>::PushBack(Work) [with Work = tensorflow::thread::EigenEnvironment::Task; unsigned int kSize = 1024u]:
/usr/include/c++/4.9/bits/atomic_base.h:581:70: error: failure memory model cannot be stronger than success memory model for __atomic_compare_exchange
  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0, __m1, __m2);
                                                                      ^
/usr/include/c++/4.9/bits/atomic_base.h: In member function void Eigen::NonBlockingThreadPoolTempl<Environment>::Schedule(std::function<void()>) [with Environment = tensorflow::thread::EigenEnvironment]:
/usr/include/c++/4.9/bits/atomic_base.h:581:70: error: failure memory model cannot be stronger than success memory model for __atomic_compare_exchange
  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0, __m1, __m2);
                                                                      ^
/usr/include/c++/4.9/bits/atomic_base.h: In member function Work Eigen::RunQueue<Work, kSize>::PopFront() [with Work = tensorflow::thread::EigenEnvironment::Task; unsigned int kSize = 1024u]:
/usr/include/c++/4.9/bits/atomic_base.h:581:70: error: failure memory model cannot be stronger than success memory model for __atomic_compare_exchange
  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0, __m1, __m2);
                                                                      ^
/usr/include/c++/4.9/bits/atomic_base.h: In member function Work Eigen::RunQueue<Work, kSize>::PopBack() [with Work = tensorflow::thread::EigenEnvironment::Task; unsigned int kSize = 1024u]:
/usr/include/c++/4.9/bits/atomic_base.h:581:70: error: failure memory model cannot be stronger than success memory model for __atomic_compare_exchange
  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0, __m1, __m2);
                                                                      ^
tensorflow/contrib/makefile/Makefile:404: recipe for target '/home/pi/Desktop/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/core/lib/core/threadpool.o' failed
make: **\* [/home/pi/Desktop/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/core/lib/core/threadpool.o] Error 1
"
3131,string_input_producer misbehave when num_epochs is set,"string_input_producer doesn't seem to enqueue string when the **num_epochs** is set.

With the following code, the program print [0], which is not right.

``` python
import tensorflow as tf
sess = tf.InteractiveSession()
filenames = [""1"", ""2"", ""3""]
filename_queue = tf.train.string_input_producer(filenames, num_epochs=10)
test_value = tf.convert_to_tensor(filename_queue.size())

coord = tf.train.Coordinator()
threads = tf.train.start_queue_runners(sess=sess, coord=coord)

print(sess.run([test_value]))
```

But if I take out num_epochs,

``` python
import tensorflow as tf
sess = tf.InteractiveSession()
filenames = [""1"", ""2"", ""3""]
filename_queue = tf.train.string_input_producer(filenames)
test_value = tf.convert_to_tensor(filename_queue.size())

coord = tf.train.Coordinator()
threads = tf.train.start_queue_runners(sess=sess, coord=coord)

print(sess.run([test_value]))
```

It prints [3] as expected.

Is there anyone else encounter the same issue?
"
3128,conv3d_transpose -- Error in 'python': free(): invalid pointer,"I'm running into an issue with the recently added `conv3d_transpose` -- error statement in the title. The network builds, but upon first training session it outputs the above error, runs for a second, and then `Aborted (core dumped)`.  I have verified all dimensions and data. 

I wrote a simple convolutional-deconvolutional network to reproduce the bug. This small program actually outputs a different error than the network I am trying to build, but I believe it is pointing to the same issue.

The error it is outputting is: `Error in 'python': double free or corruption (out):`

I have tried running the program on two different linux (Ubuntu 14) machines. I had to install Tensorflow from the nightly builds in order to include the `conv3d_transpose` source code. I want to try and run the program on my Mac, but there isn't a build out yet that includes the function.

```
#this is a small program to reproduce the bug
    # Error in 'python': free(): invalid pointer:
    # and
    # Error in `python': double free or corruption (out):

    #the network is designed for image segmentation
        #input and outputs have the same dimensions

import tensorflow as tf
import numpy as np
import pdb

learning_rate = 0.001

n_depth = 5
n_input_x = 200
n_input_y = 200
n_classes = 2
n_examples = 3

x = tf.placeholder(tf.float32, [n_examples, n_depth, n_input_x, n_input_y])
y = tf.placeholder(tf.float32, [n_examples, n_depth, n_input_x, n_input_y, n_classes], name=""ground_truth"")

#generate random data
input_data = np.random.rand(n_examples, n_depth, n_input_x, n_input_y)
label_data = np.random.rand(n_examples * n_depth * n_input_x * n_input_y, n_classes)

weights = {
    'l1': tf.Variable(tf.random_normal([5, 5, 5, 1, 32])),
    'l2': tf.Variable(tf.random_normal([3, 2, 2, 2, 32]))
}

biases = {
    'l1': tf.Variable(tf.random_normal([32])),
    'l2': tf.Variable(tf.random_normal([2]))
}

#build network
def conv(x, w, b):
    #one convolutional layer followed by one deconvolutional layer
    x = tf.reshape(x, shape=[-1, n_depth, n_input_x, n_input_y, 1])

    conv1 = tf.nn.conv3d(x, weights['l1'], strides=[1,1,1,1,1], padding=""SAME"")
    conv1 = tf.nn.bias_add(conv1, biases['l1'])
    conv1 = tf.nn.relu(conv1)
    conv1 = tf.nn.max_pool3d(conv1, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding=""SAME"")

    output_shape = [n_examples, n_depth, n_input_x, n_input_y, n_classes]
    deconv1 = tf.nn.conv3d_transpose(conv1, weights['l2'], output_shape=output_shape, strides=[1,1,2,2,1], padding=""VALID"")
    deconv1 = tf.nn.bias_add(deconv1, biases['l2'])

    return deconv1

pred = conv(x, weights, biases)

#reshape for classification
temp_pred = tf.reshape(pred, [-1,n_classes])
temp_y = tf.reshape(y, [-1,n_classes])

#define loss & optimizer
cost = tf.nn.softmax_cross_entropy_with_logits(temp_pred, temp_y)
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)
init = tf.initialize_all_variables()

#train
with tf.Session() as sess:
    sess.run(init)
    sess.run(optimizer, feed_dict={x: input_data, temp_y: label_data})

```
"
3127,installation problem (version `GLIBC_2.14' not found),"Hello,
I tried to install tensorflow using pip.
It has been installed without any error.
When I am trying to use it:
import tensorflow as tf
it gives me the following error, but the requested library exists at the /lib64/.
What should I do?!
Thanks

> Traceback (most recent call last):
>   File ""<string>"", line 1, in <module>
>   File ""/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/**init**.py"", line 23, in <module>
>     from tensorflow.python import *
>   File ""/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/**init**.py"", line 48, in <module>
>     from tensorflow.python import pywrap_tensorflow
>   File ""/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
>     _pywrap_tensorflow = swig_import_helper()
>   File ""/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
>     _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
> ImportError: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so)
### Environment info

Operating System:
Linux mmmlog2 2.6.32-573.26.1.el6.x86_64 #1 SMP Tue Apr 12 01:47:01 EDT 2016 x86_64 x86_64 x86_64 GNU/Linux Red Hat

Installed version of CUDA and cuDNN: 7.5 & 5

> -rw-rw-r-- 1 jbaker2 jbaker2 189170 May 31 08:11 /apps/CUDA/cuda-7.5/lib/libcudadevrt.a
> lrwxrwxrwx 1 jbaker2 jbaker2     16 May 31 08:11 /apps/CUDA/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5
> lrwxrwxrwx 1 jbaker2 jbaker2     19 May 31 08:11 /apps/CUDA/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
> -rwxrwxr-x 1 jbaker2 jbaker2 311596 May 31 08:11 /apps/CUDA/cuda-7.5/lib/libcudart.so.7.5.18
> -rw-rw-r-- 1 jbaker2 jbaker2 558020 May 31 08:11 /apps/CUDA/cuda-7.5/lib/libcudart_static.a

If installed from binary pip package, provide:

I am using conda, https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl

The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`:

> Traceback (most recent call last):
>   File ""<string>"", line 1, in <module>
>   File ""/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/**init**.py"", line 23, in <module>
>     from tensorflow.python import *
>   File ""/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/**init**.py"", line 48, in <module>
>     from tensorflow.python import pywrap_tensorflow
>   File ""/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
>     _pywrap_tensorflow = swig_import_helper()
>   File ""/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
>     _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
> ImportError: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so)
"
3126,GPU not working on C++,"I'm on working on load trained model in c++ like [this](http://stackoverflow.com/questions/34343259/is-there-an-example-on-how-to-generate-protobuf-files-holding-trained-tensorflow/34343517#34343517).
After many tries, I've manage to load trained model with its weights. But it looks like c++ version doesn't use GPU for inference. While running my code in c++, I check GPU usage using nvidia-smi and there is no change in GPU usage. After close looking at the example code in /tensorflow/cc/tutorials/example_trainer.cc and [this,](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/graph/default_device.h) I've tried assigning device to each node like below. But still, no GPU usage in nvidia-smi and actual running time is horribly slow. BTW, there is no problem using GPU if it is running on python.
`  const std::string device = ""/gpu:0"";

  std::vector<string> vNames;

  int node_count = graph_def.node_size();
  for (int i = 0; i < node_count; i++) {
      auto n = graph_def.node(i);
       if (n.name().find(""nWeights"") != std::string::npos) {
          vNames.push_back(n.name());
          std::cout << n.name() << std::endl;
      }
      auto node = graph_def.mutable_node(i);
      node->set_device(device);
  }`

My Environment:
OS: ubuntu 14.04
Graphics: GeForce GTX 980 Ti
CUDA Driver Version / Runtime Version          7.5 / 7.5
CUDA Capability Major/Minor version number:    5.2
"
3125,TypeError: load_dataset() got an unexpected keyword argument 'test_with_fake_data',"### Environment info

Operating System: ubuntu 14.04 and Mac OSX
Pip install: 0.9.0

In 'tensorflow/tensorflow/examples/skflow/' folder, when run 'text_classification*.py',
the code
'''
dbpedia = learn.datasets.load_dataset(
    'dbpedia', test_with_fake_data=FLAGS.test_with_fake_data)
'''
cause a bug
'''
TypeError: load_dataset() got an unexpected keyword argument 'test_with_fake_data'
'''

It is because that if user install tensorflow by pip, the definition of 'load_dataset()' in 'tensorflow/tensorflow/contrib/learn/python/learn/datasets/**init**.py' is
'def load_dataset(name):',
but in current git version, the definition of 'load_dataset()' is
'def load_dataset(name, size='small', test_with_fake_data=False):'.
"
3123,Documentation link broken ,"### Environment info

Operating System: osX
Browser: Firefox
Looks like the below link in the documentation page is broken

https://www.tensorflow.org/versions/r0.9/tutorials/linear/index.html
"
3119,can not load custom op," I just do as the document'adding a new op', when i used the Op in Python, i got the error as below:
 I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
Traceback (most recent call last):
  File ""test.py"", line 2, in <module>
    zero_out_module = tf.load_op_library('zero_out.so')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py"", line 57, in load_op_library
    raise RuntimeError(compat.as_text(py_tf.TF_Message(status)))
RuntimeError: zero_out.so: undefined symbol: _ZN10tensorflow10DEVICE_CPUE

where am i wrong?
"
3117,Android Tensorflow Crashes w/ Custom Graph ,"Solved: Followed steps at the bottom of [#1269](https://github.com/tensorflow/tensorflow/issues/1269)

And the app works fine!
### Environment info

Ubuntu 14.04
Android LG G4

Installed version of CUDA and cuDNN: 
Cuda 7.5
cuDNN 5

-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Jun 29 09:46 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Jun 29 09:46 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.0.5
-rwxrwxr-x 1 root root 59909104 Apr 22 17:15 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rw-rw-r-- 1 root root 58775484 Apr 22 17:15 /usr/local/cuda/lib64/libcudnn_static.a

If installed from sources, provide the commit hash:

Installed from source June 29th, 2016
### Steps to reproduce
1. Followed Tensorflow for Poets tutorial (OK!) used --config=cuda and --use_gpu to speed up process
2. Create new graph and labels and test to see if it can classify new image (OK!)
3. Try to build tensorflow_demo.apk using new graph and labels with modifications to:

[TensorflowImageListener.java](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorflowImageListener.java#L45)

```
  // These are the settings for the original v1 Inception model. If you want to
  // use a model that's been produced from the TensorFlow for Poets codelab,
  // you'll need to set IMAGE_SIZE = 299 **_# do they mean INPUT_SIZE?_**, IMAGE_MEAN = 128, IMAGE_STD = 128,
  // INPUT_NAME = ""Mul:0"", and OUTPUT_NAME = ""final_result:0"".
  // You'll also need to update the MODEL_FILE and LABEL_FILE paths to point to
  // the ones you produced.
  private static final int NUM_CLASSES = 5;
  private static final int INPUT_SIZE = 299;
  private static final int IMAGE_SIZE = 299; **_# i added this line in / confused about instructions_**
  private static final int IMAGE_MEAN = 128;
  private static final float IMAGE_STD = 128;
  private static final String INPUT_NAME = ""Mul:0"";
  private static final String OUTPUT_NAME = ""final_result:0"";

  private static final String MODEL_FILE = ""file:///android_asset/retrained_graph.pb"";
  private static final String LABEL_FILE =
""file:///android_asset/retrained_labels.txt"";

// I moved files into /tensorflow/examples/android/assets
```

4) Do bazel build and adb devices install

5) Launch app and it crashes everytime
### What have you tried?
1.  I restored TensorflowImageListener.java to it's original state and the app works fine.
"
3116,Getting an 0.8 .whl when installing from source from master branch,"I'm getting an `0.8` `.whl` when installing from source right now (current master [6-27]; Ubuntu 15.1; Python3.5). Am trying it from scratch again.
- Checked the repo: `README.md`: `# Release 0.9.0`
- cudnn 7.5, is that correct?
- bazel version: `0.2.3`

Output from `ls -l /usr/local/cuda/lib64/cudn*`:

`
 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
61453024 Jun 25 17:23 /usr/local/cuda/lib64/libcudnn.so
61453024 Jun 25 17:23 /usr/local/cuda/lib64/libcudnn.so.4
61453024 Jun 25 17:23 /usr/local/cuda/lib64/libcudnn.so.4.0.7
62025862 Jun 25 17:23 /usr/local/cuda/lib64/libcudnn_static.a
`

**And my primary question: what does the following mean:**

`Cudnn libraries, use '6.5' for R2, '7.0' for R3, and '4.0.4' for R4-RC.`

That's about the only thing I can think of that could be causing me problems.
"
3115,initializer option for all RNNCell's,"RNN's are very sensitive to the initial weight settings, but only the LSTMCell allows the user to specify an initializer. Could we add similar initializer options for all cells?

More control would be particularly helpful for implementing ReLU RNN's (http://arxiv.org/abs/1504.00941), where the hidden-to-hidden weight matrix should be initialized to the identity matrix.
"
3114,Backpropagation through the while-loop doesn't work if external tensors are used inside,"In the simple example below I copy `inputs` to `outputs` in a while loop. When I try to take gradient of the `outputs` w.r. to `inputs`, I get an error. It's worth noting that 1) the forward pass works 2) the gradient computation works if I made `inputs` a `TensorArray`, like it is done in the [scan implementation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/functional_ops.py#L289)

The code:

``` python
with tf.Graph().as_default(), tf.Session() as sess:
  num_steps = 9

  inputs = tf.placeholder(dtype='float32', shape=(num_steps))
  initial_outputs = tf.TensorArray(dtype=tf.float32, size=num_steps)
  initial_i = tf.constant(0, dtype='int32')

  def should_continue(i, *args):
    return i < num_steps

  def iteration(i, outputs_):
    outputs_ = outputs_.write(i, tf.gather(inputs, i))
    return i + 1, outputs_

  i, outputs = tf.while_loop(
    should_continue, iteration,
    [initial_i, initial_outputs])

  outputs = outputs.pack()
  grad_wr_inputs = tf.convert_to_tensor(tf.gradients([tf.reduce_sum(outputs)], [inputs])[0])
  print sess.run([outputs, grad_wr_inputs],
                 feed_dict={inputs: [4, 6, 0, 7, 0, 0, 1, 2, 0]})
```

The stack trace:

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-354-e1d117e742f9> in <module>()
     20   grad_wr_inputs = tf.convert_to_tensor(tf.gradients([tf.reduce_sum(outputs)], [inputs])[0])
     21   print sess.run([outputs, grad_wr_inputs],
---> 22                  feed_dict={inputs: [4, 6, 0, 7, 0, 0, 1, 2, 0]})

/google/data/ro/teams/colab/tensorflow/google3/third_party/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    366     try:
    367       result = self._run(None, fetches, feed_dict, options_ptr,
--> 368                          run_metadata_ptr)
    369       if run_metadata:
    370         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/google/data/ro/teams/colab/tensorflow/google3/third_party/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
    639     movers = self._update_with_movers(feed_dict_string, feed_map)
    640     results = self._do_run(handle, target_list, unique_fetches,
--> 641                            feed_dict_string, options, run_metadata)
    642 
    643     # User may have fetched the same tensor multiple times, but we

/google/data/ro/teams/colab/tensorflow/google3/third_party/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
    707     if handle is None:
    708       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
--> 709                            target_list, options, run_metadata)
    710     else:
    711       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/google/data/ro/teams/colab/tensorflow/google3/third_party/tensorflow/python/client/session.py in _do_call(self, fn, *args)
    727         except KeyError:
    728           pass
--> 729       raise type(e)(node_def, op, message)
    730 
    731   def _extend_graph(self):

InvalidArgumentError: All inputs to node Slice must be from the same frame.
```
"
3111,word2vec_basic : Unique nodes clustering,"Hi !

I am getting the output of word2vec_basic.py in the following format

```
Nearest to key1  : node1, node2, node3 ..
Nearest to key2 : node2, node4, node5 ..

```

This implies that node2 is comparatively closer to key2 over key1 (Please correct me if I am wrong, as I am newbie here)

It would be great if I get the output in the following format

```
Nearest to key1  : node1, node3 , node6..
Nearest to key2 : node2, node4, node5 ..

```

That is, consider only the closest neighbor for clustering. Suggestions are welcome!

Appreciate the hardwork behind tensorflow :+1:

Thanks! 
"
3107,[Docs Request] InceptionV3 Classify multiple images in same run.,"Dearest github community,

Thank you for your wonderful contributions to Tensorflow! I greatly appreciate Tensorflow being open-source, for anyone to use :)

I was browsing the docs. and was attempting to retrain the last layer of the inceptionV3 model on new categories.(From https://www.tensorflow.org/versions/r0.9/how_tos/image_retraining/index.html)

It was successful, and i can predict a single image by running:

```

bazel build tensorflow/examples/label_image:label_image && \
bazel-bin/tensorflow/examples/label_image/label_image \
--graph=/tmp/output_graph.pb --labels=/tmp/output_labels.txt \
--output_layer=final_result \
--image=PATH_TO_IMG
```

However, after much searching, I still could not find a way to use this retrained model to classify multiple images. The link provided here: https://github.com/eldor4do/Tensorflow-Examples/blob/master/retraining-example.py also discusses using the model on a per-image basis.

I've attempted to modify that file to accept multiple images, but I was unsuccessful. (Playing around with feed_dict threw errors.)

It would be really helpful if there was a documentation of some sort to provide guidelines / show how to accomplish this task :) 

Tldr: requesting documentation to show how to classify multiple images using InceptionV3 (tensorflow) in python instead of one by one.

Thank you, and have a great day!
"
3106,system memory leak,"Running tutorial_example_trainer (similar leak for my own tensorflow scripts) results in ~70MB of memory being lost. `free` shows the memory is used, but `ps` shows that no process is using the memory. Nothing short of a reboot seems to free up the memory.

Reproduce with the following (After the ~10 minute run, you should be down ~7GB of memory)
`for i in `seq 1 100`; do ./bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu; done`

os: 14.04
gpu: Titan X (361.28)
commit: 0927e5eaf3f5f031dbb1d3a13ac6529d8263ad9e (from yesterday)
cuda: 7.5
cudnn: 4.0.7
This leak is also present on an EC2 12.04 with an older version of tensorflow, cuda 7.0, cudnn 6.5.

Here is the output from a fresh reboot:

```
woodward@dev-box:~/install_files/tensorflow$ free -g
             total       used       free     shared    buffers     cached
Mem:           125          0        125          0          0          0
-/+ buffers/cache:          0        125
Swap:          127          0        127
woodward@dev-box:~/install_files/tensorflow$ for i in `seq 1 100`; do ./bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu &>/dev/null; done
woodward@dev-box:~/install_files/tensorflow$ free -g
             total       used       free     shared    buffers     cached
Mem:           125          7        118          0          0          0
-/+ buffers/cache:          7        118
Swap:          127          0        127
woodward@dev-box:~/install_files/tensorflow$ ps -Ao user,pid,%mem,vsz,rss,command --sort -rss | head -n 10
USER       PID %MEM    VSZ   RSS COMMAND
root      1263  0.0 105648  6532 sshd: woodward [priv]
root      1317  0.0 105648  6512 sshd: woodward [priv]
woodward  1387  0.0  22756  5560 /bin/bash
woodward  1388  0.0  22668  5504 /bin/bash
woodward  1390  0.0  22668  5488 /bin/bash
woodward  1389  0.0  22668  5464 /bin/bash
root      1097  0.0  61384  5376 /usr/sbin/sshd -D
woodward  1366  0.0  22552  5144 -bash
woodward  1365  0.0 106776  5000 sshd: woodward@pts/0
```
"
3103,Non-deterministic mean and sum reduction,"I'm running Tensorflow 0.9.0 installed from wheel on Python 2.7 on a K40 with CUDA 7.0.

The following test case attempts to minimize the mean of a vector through gradient descent. The script finds that the vectors are equal at all steps, but the means are not. I believe the vectors being equal at all steps is pure numerical luck, since non-deterministic loss likely means non-deterministic gradient which means non-deterministic/reproducible iterative optimization. I've observed cases where training results in different final losses where the only source of non-determinism is from reduce_mean.

``` python
import numpy as np
import tensorflow as tf

n_dims = 1000
n_steps = 50

np.random.seed(2016)

vec = tf.Variable(np.random.randn(n_dims).astype(np.float32))
mean = tf.reduce_mean(vec)

optimizer = tf.train.GradientDescentOptimizer(0.01)
train_step = optimizer.minimize(mean)

def generate():
    data = []
    with tf.Session() as sess:
        sess.run(tf.initialize_all_variables())

        for _ in xrange(n_steps):
            _vec, _mean, _ = sess.run([vec, mean, train_step])
            data.append((_vec, _mean))

    return [np.array([f[i] for f in data]) for i in xrange(2)]

first_vec, first_mean = generate()
second_vec, second_mean = generate()
print 'vecs equal:', np.all(first_vec == second_vec)

print 'mean equal:', np.all(first_mean == second_mean)
print 'means not equal at idxs:', np.nonzero(first_mean != second_mean)[0]
```

Example output:

```
vecs equal: True
mean equal: False
means not equal at idxs: [ 4  5 11 18 34 38 44 49]
```

From looking through the code, it appears the GPU mean reduction is implemented with GPU sum reduction: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/reduction_ops_gpu.cu.cc#L43
I've confirmed my test case still triggers when I replace ""reduce_mean"" with ""reduce_sum"".

The GPU sum reduction appears to be implemented using CUDA's atomicAdd: https://bitbucket.org/eigen/eigen/src/241472d2a52142e23b0b2ba5c301c6c146298fa9/unsupported/Eigen/CXX11/src/Tensor/TensorReductionCuda.h?at=default&fileviewer=file-view-default#TensorReductionCuda.h-97

Atomic floating point adds on GPU are the problem. Having floating point adds to the same address in an undefined order is inherently non-deterministic due to non-associativity of floating point arithmetic.

This issue could be solved (and reduction performance improved) by using some sort of reduction tree to reduce within blocks, and then launching a second kernel (or doing some manual block synchronization tricks) to reduce across blocks.
"
3102,"Constant operation ""forgets"" about incoming shape","## Feature request

Following this question in StackOverflow: [Why can't tensorflow determine the shape of this expression](http://stackoverflow.com/questions/37881917/why-cant-tensorflow-determine-the-shape-of-this-expression/37882501#37882501).

When using a constant tensor (`tf.zeros`, `tf.ones`, `tf.constant`...), if one of the input dimension is unknown, the operation will forget every dimension of the input.  
The code will be clearer:

``` python
input_tensor = tf.placeholder(tf.float32, [None, 32])
batch_size = tf.shape(input_tensor)[0]

res = tf.zeros((batch_size, 128))
print res.get_shape()  # prints (?, ?) WHEREAS one could expect (?, 128)
```

The easy fix is to set the output shape by hand:

``` python
res.set_shape([None, 128])
print res.get_shape()  # prints (?, 128)
```

However, this could be done directly in the TensorFlow code. Otherwise, it may confuse users that think their shape is fully defined.
"
3101,Softmax for multiple dimensions,"Attention models get more popular. In many of my experiments with attention, I end up using Softmax over multiple dimensions. 

tf.nn.softmax() supports only one dimension. It would be nice to expand the API with another argument, softmax_dim, for softmax over multiple dimension, say over 2 (images) or 3 (CT-scans, videos)

I;d like to here what you think? DO more people end up writing softmax code themselves?
"
3100,tensorflow best practice model exploration record keeping,"I understand that we're trying to keep questions to StackOverflow. But, since subjective questions are off-topic for SO, I wasn't sure were to put questions about best practices.

to the point: As a matter of record keeping during model exploration, what are best (I'll settle for sustainable) practices for record keeping of tf graph and parameters of previously tried models?

I'm doing a fair bit of model exploration, but this has resulted in an unsustainable number of model#.py files... Every time I tweak the model involving a graph or parameter change, I feel like I have to keep that .py file for eternity. I have a great workflow for checkpoint saving and loading, but I can't just load up my model from the checkpoint file; I need to have some documentation of what the graph structure and parameters are that actually generated this checkpoint file.

Thanks,
Chris Snyder
"
3099,Building Tensorflow in armhf (olimex a20),"I'm trying to build Tensorflow on an olimex A20 for an embedded NN application. 
I just need to build the C++ or C session API because i'm building the graph in a different box. 

So far I've managed to build protobuf and bazel following this guide. 
https://github.com/samjabrahams/tensorflow-on-raspberry-pi/blob/master/GUIDE.md

But compiling Tensorflow with bazel i get the following error,

`ERROR: /root/.cache/bazel/_bazel_root/8bbee47417ac55737a4a72fb4017df9b/external/highwayhash/BUILD:17:1: C++ compilation of rule '@highwayhash//:sip_hash' failed: gcc failed: error executing command
  (cd /root/.cache/bazel/_bazel_root/8bbee47417ac55737a4a72fb4017df9b/tensorflow && \
  exec env - \
    PATH=/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++0x' -iquote external/highwayhash -iquote bazel-out/host/genfiles/external/highwayhash -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/highwayhash -isystem bazel-out/host/genfiles/external/highwayhash -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/host/bin/external/highwayhash/_objs/sip_hash/external/highwayhash/highwayhash/sip_hash.o' -MD -MF bazel-out/host/bin/external/highwayhash/_objs/sip_hash/external/highwayhash/highwayhash/sip_hash.d -c external/highwayhash/highwayhash/sip_hash.cc -o bazel-out/host/bin/external/highwayhash/_objs/sip_hash/external/highwayhash/highwayhash/sip_hash.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from external/highwayhash/highwayhash/sip_hash.cc:15:0:
external/highwayhash/highwayhash/sip_hash.h:31:9: error: expected nested-name-specifier before 'Key'
external/highwayhash/highwayhash/sip_hash.h:31:9: error: using-declaration for non-member at class scope
external/highwayhash/highwayhash/sip_hash.h:31:13: error: expected ';' before '=' token
external/highwayhash/highwayhash/sip_hash.h:31:13: error: expected unqualified-id before '=' token
external/highwayhash/highwayhash/sip_hash.h:34:38: error: 'Key' does not name a type
external/highwayhash/highwayhash/sip_hash.h: In constructor 'highwayhash::SipHashState::SipHashState(const int&)':
external/highwayhash/highwayhash/sip_hash.h:35:39: error: invalid types 'const int[int]' for array subscript
external/highwayhash/highwayhash/sip_hash.h:36:39: error: invalid types 'const int[int]' for array subscript
external/highwayhash/highwayhash/sip_hash.h:37:39: error: invalid types 'const int[int]' for array subscript
external/highwayhash/highwayhash/sip_hash.h:38:39: error: invalid types 'const int[int]' for array subscript
external/highwayhash/highwayhash/sip_hash.h: At global scope:
external/highwayhash/highwayhash/sip_hash.h:114:36: error: 'Key' in 'class highwayhash::SipHashState' does not name a type
external/highwayhash/highwayhash/sip_hash.h: In function 'highwayhash::uint64 highwayhash::SipHash(const int&, const char*, highwayhash::uint64)':
external/highwayhash/highwayhash/sip_hash.h:116:52: error: no matching function for call to 'ComputeHash(const int&, const char*&, const uint64&)'
external/highwayhash/highwayhash/sip_hash.h:116:52: note: candidate is:
external/highwayhash/highwayhash/state_helpers.h:63:8: note: template<class State> highwayhash::uint64 highwayhash::ComputeHash(const typename State::Key&, const char*, highwayhash::uint64)
external/highwayhash/highwayhash/sip_hash.h: At global scope:
external/highwayhash/highwayhash/sip_hash.h:120:46: error: 'Key' in 'class highwayhash::SipHashState' does not name a type
cc1plus: warning: unrecognized command line option ""-Wno-free-nonheap-object"" [enabled by default]
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1577.488s, Critical Path: 22.08s`

System:
Linux version 3.4.90+ (root@debian) (gcc version 4.7.1 (Debian 4.7.1-7) )

Bazel:
Build label: 0.2.1-2016-06-28 (@447f7f3)
Build target: bazel-out/local_linux-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Jun 28 17:09:27 2016 (1467133767)
Build timestamp: 1467133767
Build timestamp as int: 1467133767
"
3092,Compile fails with 'DSO missing from command line',"```
ERROR: /sw/tensorflow/tensorflow/tools/proto_text/BUILD:31:1: Linking of rule '//tensorflow/tools/proto_text:gen_proto_text_functions' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/tools/proto_text/gen_proto_text_functions ... (remaining 26 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/usr/bin/ld: bazel-out/host/bin/tensorflow/core/liblib_internal.a(numbers.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'
//lib/x86_64-linux-gnu/libm.so.6: error adding symbols: DSO missing from command line
collect2: error: ld returned 1 exit status
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 123.174s, Critical Path: 86.34s

```
### Environment info

Operating System:
Linux ghost 4.4.0-24-generic #43-Ubuntu SMP Wed Jun 8 19:27:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

Installed version of CUDA and cuDNN: 

Using 8.0
(output of `ls -l /path/to/cuda/lib/libcud*`):
https://gist.github.com/delip/6a85c0750a216a8e5340dd29606860f2

If installed from sources, provide the commit hash:
commit 214ba59755791a4c4631e2bc0325d77451483740
### Steps to reproduce

Follow usual compile steps
1. ./configure
2. bazel build -c opt --verbose_failures --config=cuda //tensorflow/cc:tutorials_example_trainer
### What have you tried?
1. bazel clean, rebuild
2. Fresh clone + build
### Logs or other output that would be helpful

logs with --verbose_failures

```
ERROR: /sw/tensorflow/tensorflow/tools/proto_text/BUILD:31:1: Linking of rule '//tensorflow/tools/proto_text:gen_proto_text_functions' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/delip/.cache/bazel/_bazel_delip/197c8f9456af837dca196cbcaf2ed97a/tensorflow && \
  exec env - \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/tools/proto_text/gen_proto_text_functions bazel-out/host/bin/tensorflow/tools/proto_text/_objs/gen_proto_text_functions/tensorflow/tools/proto_text/gen_proto_text_functions.o bazel-out/host/bin/tensorflow/tools/proto_text/libgen_proto_text_functions_lib.a bazel-out/host/bin/tensorflow/core/liblib_internal.a bazel-out/host/bin/external/farmhash_archive/libfarmhash.a bazel-out/host/bin/external/jpeg_archive/libjpeg.a bazel-out/host/bin/external/png_archive/libpng.a bazel-out/host/bin/external/highwayhash/libsip_hash.a bazel-out/host/bin/external/re2/libre2.a bazel-out/host/bin/tensorflow/core/libprotos_all_cc.a bazel-out/host/bin/external/protobuf/libprotobuf.a bazel-out/host/bin/external/protobuf/libprotobuf_lite.a bazel-out/host/bin/external/zlib_archive/libzlib.a -ldl -lz -pthread -lpthread -lstdc++ -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,-S -Wl,--gc-sections): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/usr/bin/ld: bazel-out/host/bin/tensorflow/core/liblib_internal.a(numbers.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'
//lib/x86_64-linux-gnu/libm.so.6: error adding symbols: DSO missing from command line
collect2: error: ld returned 1 exit status
Target //tensorflow/cc:tutorials_example_trainer failed to build
INFO: Elapsed time: 0.856s, Critical Path: 0.13s

```
"
3089,400 bad request when creating pip package,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
CentOS 6
Installed version of CUDA and cuDNN: 7.5, 4.0

(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA and cuDNN files are both present

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   NA

If installed from sources, provide the commit hash:
`25023dffcf88f46777b5ddab457ac84a5bed5d2f`
### Steps to reproduce
1. Build package from source
2. Run `bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`
### What have you tried?
1. Have tried looking at #1817 which had same error. It is not intermittent as described in that issue, it fails every single time but works if you just try to clone the repo directly.
2. However, running `git clone https://github.com/google/boringssl.git` results in:

```
git clone https://github.com/google/boringssl.git
Cloning into 'boringssl'...
remote: Counting objects: 26620, done.
remote: Compressing objects: 100% (310/310), done.
remote: Total 26620 (delta 164), reused 0 (delta 0), pack-reused 26299
Receiving objects: 100% (26620/26620), 18.72 MiB | 5.79 MiB/s, done.
Resolving deltas: 100% (18032/18032), done.
Checking connectivity... done.
```
### Logs or other output that would be helpful

(If logs are large, please upload as attachment)

```
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
WARNING: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/protobuf/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
WARNING: /tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
WARNING: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/highwayhash/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.
WARNING: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/re2/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
ERROR: /tensorflow/tensorflow/core/distributed_runtime/rpc/BUILD:48:1: no such package '@grpc//': Error cloning repository: https://github.com/google/boringssl.git: 400 Bad Request caused by https://github.com/google/boringssl.git: 400 Bad Request and referenced by '//tensorflow/core/distributed_runtime/rpc:grpc_util'.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
INFO: Elapsed time: 49.467s
```
"
3088,nvidia/cuda:7.5-cudnn4-devel + 0.9.0 fails after second epoch,"### Environment info

Operating System:

```
 Ubuntu 14.04
```

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
nvidia/cuda:7.5-cudnn4-devel
nvidia/cuda:7.5-cudnn5-devel

Driver version: 361.42 (AWS)
```

If installed from binary pip package, provide:
1. Which pip package you installed.
   
   ```
   export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl
   ```
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   
   ```
   0.9.0
   ```

If installed from sources, provide the commit hash:

```
N/A
```
### Steps to reproduce
1. Train simple convnet for one epoch
2. Fails on second epoch? (no new operations or changes between epochs)
### What have you tried?
1. Tried various CUDA/cuDNN nvidia-docker versions.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

```
F tensorflow/stream_executor/cuda/cuda_dnn.cc:422] could not set cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM
Failed to run user code: signal: aborted (core dumped)
```

The docker container reports the expected CUDA/CUDNN version (7.5 and 4 respectively).
"
3087,tensorbaord graph broken for multi-gpu (cifar10 example),"![graph-run 1](https://cloud.githubusercontent.com/assets/15835199/16431922/c084e280-3d50-11e6-9b9d-5169d84ae865.png)
GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

CentOS 6 (64 bit) + NVidia K80

Installed version of CUDA and cuDNN: 
CUDA 7.5, cuDNN v4

If installed from binary pip package, provide:
1. Which pip package you installed.
   The lateset (0.9 with GPU)
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.9.0
### Steps to reproduce
1. Locate the cifar10 example https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/image/cifar10
2. run ""python cifar10_multi_gpu_train.py --num_gpus=2""
3. Check the tensorboard results from events. The ""GRAPHS"" doesn't look right
### What have you tried?
1. I tried to run the single GPU version of cifar10 example ""python cifar10_train.py"", Tensorboard graph looks normal
2. I tried ""python cifar10_multi_gpu_train.py --num_gpus=1"", Tensorboard graph broken
3. I didn't try a early version of tensorflow this time, but I remember the Tensorboard used to work with the cifar10 multi-gpu example
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
3086,from google.protobuf import descriptor as _descriptor ImportError: No module named google.protobuf,"Hey guys I'm working on a project using tensorflow on the Amazon Web Services microservices platform and I've run into a few problems. I installed tensorflow using pip into a virtualenv. Then I took the contents of /env/lib/python2.7/site-packages/ and zipped it along with my source code into a development package for AWS Lambda (env is the name of my virtualenv). This is the process for using python libraries for an AWS Lambda process and I haven't run into any problems with other libraries. I've done this for numpy,scipy,Pillow, and a bunch of other far less supported libraries and they have all worked fine with Lambda.

However when I attempt to use tensorflow it returns this:

Unable to import module 'classify': Traceback (most recent call last): File `""/var/task/tensorflow/python/__init__.py"",` line 52, in <module> from tensorflow.core.framework.graph_pb2 import \* File ""/var/task/tensorflow/core/framework/graph_pb2.py"", line 6, in <module> from google.protobuf import descriptor as _descriptor ImportError: No module named google.protobuf   Error importing tensorflow. Unless you are using bazel, you should not try to import tensorflow from its source directory; please exit the tensorflow source tree, and relaunch your python interpreter from there.

classify is the source script AWS Lambda calls when it is invoked and was zipped along with the contents of  /env/lib/python2.7/site-packages/  as I described.

These errors have been addressed a couple of other places but none of the solutions I found on those pages have worked for me, probably because none of them were using lambda. Is it possible that tensorflow just will not work with lambda because of the way lambda imports libraries? If so is there anyway import the tensorflow package from just a source folder that I upload as a zip?

Specific Steps to Reproduce:
- virtualenv env 
- env/bin/pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl
- zip contents of /env/lib/python2.7/site-packages with .py file classify
- upload to aws lambda function
- invoke aws lambda function which calls classify and runs into an issue with ""import tensorflow as tf""

It's occurred to me that this probably isn't something tensorflow is probably supporting given that most people aren't using tensorflow inside AWS containers but hopefully someone can help or at least give it their best shot even if they don't specifically have experience with AWS.

Thanks!!
"
3085,TensorFlow r0.9 warning warns about Deprecation and recommends itself.,"TensorFlow r0.9:

```
In [3]: tf.logging.warning('asdf')
/home/hholst/anaconda3/envs/tf-r0.9/bin/ipython:1: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  #!/home/hholst/anaconda3/envs/tf-r0.9/bin/python
WARNING:tensorflow:asdf
```
"
3084,ImportError: No module named tensorflow,"**I followed the steps for Anaconda installation for the CPU install of Tensorflow. (r0.9)**

**Despite installation completing successfully in my conda environment on CentOS, I am unable to import tensorflow**
### Environment info

Operating System:  **CentOS 7.2.1511**
                                **Python 2.7.11 Anaconda 4.0.0 (64-bit)**

If installed from binary pip package, provide:
1. Which pip package you installed.

```
# Ubuntu/Linux 64-bit, CPU only, Python 2.7
$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl
```
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
(tensorflow)[hmanjunatha@curran ~]$ python -c ""import tensorflow; print(tensorflow.__version__)""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ImportError: No module named tensorflow
```
### What have you tried?
1. Searched on Google, Stackoverflow, but to no avail
2. **OS X installation of tensorflow worked perfectly**
"
3083,ValueError in tensorflow/examples/skflow/mnist_weights.py,"### Environment info

OS: OS X 10.11.5

Cuda version: 7.5.30

cuDNN version: v5.1rc (or 5103)

Tensorflow version: 0.9.0rc0

Installed with cuda support using these [instructions](https://medium.com/@fabmilo/how-to-compile-tensorflow-with-cuda-support-on-osx-fd27108e27e1#.mf4zcsmu3).
### Steps to reproduce:
1. cd tensorflow/examples/skflow/
2. $ python mnist_weights.py
### Output:

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.7.5.dylib locally
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:TensorFlowLinearClassifier class is deprecated. Please consider using LinearClassifier as an alternative.
Traceback (most recent call last):
  File ""mnist_weights.py"", line 37, in <module>
    classifier.fit(mnist.train.images, mnist.train.labels)
  File ""/Users/tcf/.virtualenvs/dnn/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 458, in fit
    batch_size=batch_size or self.batch_size, monitors=monitors)
  File ""/Users/tcf/.virtualenvs/dnn/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 182, in fit
    monitors=monitors)
  File ""/Users/tcf/.virtualenvs/dnn/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 449, in _train_model
    train_op, loss_op = self._get_train_ops(features, targets)
  File ""/Users/tcf/.virtualenvs/dnn/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py"", line 97, in _get_train_ops
    return super(LinearClassifier, self)._get_train_ops(features, targets)
  File ""/Users/tcf/.virtualenvs/dnn/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 158, in _get_train_ops
    targets, self._get_weight_tensor(features))]):
  File ""/Users/tcf/.virtualenvs/dnn/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 282, in _centered_bias_step
    loss = self._loss(logits, targets, weight_tensor)
  File ""/Users/tcf/.virtualenvs/dnn/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 316, in _loss
    loss_vec = self._loss_vec(logits, target)
  File ""/Users/tcf/.virtualenvs/dnn/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 510, in _loss_vec
    ""Instead got %s."" % target.dtype)
ValueError: Target's dtype should be int32, int64 or compatible. Instead got <dtype: 'uint8'>.
```
### What have I tried?

I used the ndarray method `.astype` to change the type appropriately. That is, I replaced `mnist.train.images` with `mnist.train.images.astype(np.float32)` and `mnist.train.labels` with `mnist.train.images.astype(int)`.
##### I can make a PR for this if you want.
"
3081,Check for Xcode 7.3 fails in compile_ios_tensorflow.sh,"```
++ xcodebuild -version
++ head -n 1
++ sed 's/Xcode //'
+ ACTUAL_XCODE_VERSION=7.3
+ REQUIRED_XCODE_VERSION=7.3.0
+ '[' 73 -lt 730 ']'
+ echo 'error: Xcode 7.3.0 or later is required.'
error: Xcode 7.3.0 or later is required.
```

This should be easy to fix :)
"
3080,Problem with meta file size when saving model initialized with pre-trained weights,"### Context/Problem

I have pretrained models (from elsewhere) with weights saved as numpy arrays. I want to create a tensorflow model where the weights and biases are initialized with numpy arrays rather than random tensors. I am able to do this (code snippet below), but run into problems when I try saving/loading my model.

Specifically, the problem involves using the `Saver` class to save `model` and `model.meta`. I expect `model.meta` to be much smaller in size than `model`, but this is not the case. In fact, using the code snippet below, you can see that the meta file is the same size as the model file.

This results in problems when importing the meta file with much larger models.
### Environment info

Operating System: Ubunutu 14.04
Tensorflow version: '0.9.0rc0'
### Steps to reproduce

```
import tensorflow as tf
import numpy as np

# normally pretrained weights, but random arrays used for brevity
weights = np.random.rand(1000, 500).astype(np.float32)
biases = np.random.rand(500).astype(np.float32)

x = tf.placeholder(tf.float32, [None, 1000], name='input')

W = tf.Variable(weights)
b = tf.Variable(biases)

fc = tf.matmul(x, W, name='fc1')
fc = tf.nn.bias_add(fc, b)
y_pred = tf.nn.softmax(fc, name='output')

# saving model
sess = tf.Session()
init_op = tf.initialize_all_variables()
sess.run(init_op)
saver = tf.train.Saver()
saver.save(sess, ""model"")
```
"
3079,Wheel not supported installation problem: GPU Ubuntu 64 bit,"My installation attempt failed on the last step:

```
drake@sparky:~$ sudo pip3 install --upgrade $TF_BINARY_URL
[sudo] password for drake: 
The directory '/home/drake/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
The directory '/home/drake/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
tensorflow-0.9.0-cp35-cp35m-linux_x86_64.whl is not a supported wheel on this platform.
drake@sparky:~$ whoami
drake
drake@sparky:~$ sudo -H pip3 install --upgrade $TF_BINARY_URL
tensorflow-0.9.0-cp35-cp35m-linux_x86_64.whl is not a supported wheel on this platform.
```

What to do?
### Environment info

Operating System:

```
drake@sparky:/usr/local/bin/cuda/include$ uname -a
Linux sparky 3.13.0-88-generic #135-Ubuntu SMP Wed Jun 8 21:10:42 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
```

Installed version of CUDA and cuDNN: 

I've installed cuda-repo-ubuntu1404_7.5-18_amd64.deb.

I _think_ I've installed cuDNN 5.0, but the instructions there are vague offer no way to test it.

(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
drake@sparky:/usr/local/bin/cuda$ ls -l lib64/libcud*
lrwxrwxrwx 1 root root       13 Jun 28 09:21 lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Jun 28 09:21 lib64/libcudnn.so.5 -> libcudnn.so.5.0.5
-rwxr-xr-x 1 root root 59909104 Jun 28 09:21 lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 58775484 Jun 28 09:21 lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed.

See above
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
drake@sparky:/usr/local/bin/cuda$ python3 -c ""import tensorflow; print(tensorflow.__version__)""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ImportError: No module named 'tensorflow'
```
"
3078,Allow use of gitter.im for tensorflow/tensorflow repo,"As far as I could tell, there is no place for the community to discuss tensorflow in realtime; the recommendations all seem to be about asking specific questions in a detailed async fashion.

It would be nice if there was a gitter.im or IRC channel for tensorflow so that the community could interact more easily. not even as a dedicated support channel.

There is already a gitter.im for skflow, but since fewer people know about skflow, let alone the gitter.im for it, it's pretty small: https://gitter.im/tensorflow/skflow

It would be even nicer if the channel was linked from the repo, but gitter.im is nice since it has some automatic discoverability if you're already familiar with gitter
"
3076,Problem compiling version 0.9 for iOS,"### Environment info

Operating System: macOS 10.11.5
xcode 7.3.1
I tried installing on 2 different computers and got the exact same error. One system was very clean as it was freshly initialized out of the box and had not been polluted.
### Steps to reproduce

I follow the steps indicated here first for the Makefile and than the steps specific to install for iOS
- clone the repository
- install the dependencies
- run build_all_ios.sh

Everything run fine for a little while and I get the following error:

configure: creating ./config.status
config.status: creating Makefile
config.status: creating scripts/gtest-config
config.status: creating build-aux/config.h
config.status: executing depfiles commands
config.status: executing libtool commands
- make
  /Applications/Xcode.app/Contents/Developer/usr/bin/make  all-recursive
  Making all in .
  make[2]: Nothing to be done for `all-am'.
  Making all in src
  /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc -I. --cpp_out=. google/protobuf/any_test.proto google/protobuf/compiler/cpp/cpp_test_bad_identifiers.proto google/protobuf/map_lite_unittest.proto google/protobuf/map_proto2_unittest.proto google/protobuf/map_unittest.proto google/protobuf/unittest_arena.proto google/protobuf/unittest_custom_options.proto google/protobuf/unittest_drop_unknown_fields.proto google/protobuf/unittest_embed_optimize_for.proto google/protobuf/unittest_empty.proto google/protobuf/unittest_enormous_descriptor.proto google/protobuf/unittest_import_lite.proto google/protobuf/unittest_import.proto google/protobuf/unittest_import_public_lite.proto google/protobuf/unittest_import_public.proto google/protobuf/unittest_lite_imports_nonlite.proto google/protobuf/unittest_lite.proto google/protobuf/unittest_mset.proto google/protobuf/unittest_mset_wire_format.proto google/protobuf/unittest_no_arena_lite.proto google/protobuf/unittest_no_arena_import.proto google/protobuf/unittest_no_arena.proto google/protobuf/unittest_no_field_presence.proto google/protobuf/unittest_no_generic_services.proto google/protobuf/unittest_optimize_for.proto google/protobuf/unittest_preserve_unknown_enum2.proto google/protobuf/unittest_preserve_unknown_enum.proto google/protobuf/unittest.proto google/protobuf/unittest_proto3_arena.proto google/protobuf/unittest_proto3_arena_lite.proto google/protobuf/unittest_proto3_lite.proto google/protobuf/unittest_well_known_types.proto google/protobuf/util/internal/testdata/anys.proto google/protobuf/util/internal/testdata/books.proto google/protobuf/util/internal/testdata/default_value.proto google/protobuf/util/internal/testdata/default_value_test.proto google/protobuf/util/internal/testdata/field_mask.proto google/protobuf/util/internal/testdata/maps.proto google/protobuf/util/internal/testdata/oneofs.proto google/protobuf/util/internal/testdata/struct.proto google/protobuf/util/internal/testdata/timestamp_duration.proto google/protobuf/util/json_format_proto3.proto google/protobuf/util/message_differencer_unittest.proto google/protobuf/compiler/cpp/cpp_test_large_enum_value.proto
  make[2]: /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc: No such file or directory
  make[2]: **\* [unittest_proto_middleman] Error 1
  make[1]: **\* [all-recursive] Error 1
  make: **\* [all] Error 2
- make install
  Making install in .
  make[2]: Nothing to be done for `install-exec-am'.
  ./install-sh -c -d '/Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/ios_arm64/lib/pkgconfig'
  /usr/bin/install -c -m 644 protobuf.pc protobuf-lite.pc '/Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/ios_arm64/lib/pkgconfig'
  Making install in src
  /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc -I. --cpp_out=. google/protobuf/any_test.proto google/protobuf/compiler/cpp/cpp_test_bad_identifiers.proto google/protobuf/map_lite_unittest.proto google/protobuf/map_proto2_unittest.proto google/protobuf/map_unittest.proto google/protobuf/unittest_arena.proto google/protobuf/unittest_custom_options.proto google/protobuf/unittest_drop_unknown_fields.proto google/protobuf/unittest_embed_optimize_for.proto google/protobuf/unittest_empty.proto google/protobuf/unittest_enormous_descriptor.proto google/protobuf/unittest_import_lite.proto google/protobuf/unittest_import.proto google/protobuf/unittest_import_public_lite.proto google/protobuf/unittest_import_public.proto google/protobuf/unittest_lite_imports_nonlite.proto google/protobuf/unittest_lite.proto google/protobuf/unittest_mset.proto google/protobuf/unittest_mset_wire_format.proto google/protobuf/unittest_no_arena_lite.proto google/protobuf/unittest_no_arena_import.proto google/protobuf/unittest_no_arena.proto google/protobuf/unittest_no_field_presence.proto google/protobuf/unittest_no_generic_services.proto google/protobuf/unittest_optimize_for.proto google/protobuf/unittest_preserve_unknown_enum2.proto google/protobuf/unittest_preserve_unknown_enum.proto google/protobuf/unittest.proto google/protobuf/unittest_proto3_arena.proto google/protobuf/unittest_proto3_arena_lite.proto google/protobuf/unittest_proto3_lite.proto google/protobuf/unittest_well_known_types.proto google/protobuf/util/internal/testdata/anys.proto google/protobuf/util/internal/testdata/books.proto google/protobuf/util/internal/testdata/default_value.proto google/protobuf/util/internal/testdata/default_value_test.proto google/protobuf/util/internal/testdata/field_mask.proto google/protobuf/util/internal/testdata/maps.proto google/protobuf/util/internal/testdata/oneofs.proto google/protobuf/util/internal/testdata/struct.proto google/protobuf/util/internal/testdata/timestamp_duration.proto google/protobuf/util/json_format_proto3.proto google/protobuf/util/message_differencer_unittest.proto google/protobuf/compiler/cpp/cpp_test_large_enum_value.proto
  make[1]: /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc: No such file or directory
  make[1]: **\* [unittest_proto_middleman] Error 1
  make: **\* [install-recursive] Error 1
- lipo /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/iossim_386/lib/libprotobuf.a /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/iossim_x86_64/lib/libprotobuf.a /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/ios_arm7/lib/libprotobuf.a /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/ios_arm7s/lib/libprotobuf.a /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/ios_arm64/lib/libprotobuf.a -create -output /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/libprotobuf.a
  fatal error: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/lipo: can't open input file: /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/iossim_386/lib/libprotobuf.a (No such file or directory)
- lipo /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/iossim_386/lib/libprotobuf-lite.a /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/iossim_x86_64/lib/libprotobuf-lite.a /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/ios_arm7/lib/libprotobuf-lite.a /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/ios_arm7s/lib/libprotobuf-lite.a /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/ios_arm64/lib/libprotobuf-lite.a -create -output /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/libprotobuf-lite.a
  fatal error: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/lipo: can't open input file: /Users/lcavalie/iOSdev/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/iossim_386/lib/libprotobuf-lite.a (No such file or directory)
### What have you tried?

I looked into tensorflow/contrib/makefile/gen/ it contains only a protobuf-host folder that is empty and a protobuf_ios folder with the various architectures and on each case only 2 files /lib/ios_arm7/lib/pkgconfig/protobuf-lite.pc and  /lib/ios_arm7/lib/pkgconfig/protobuf.pc 

Assuming that there is a problem with the building of everything related to protobuf I tried to run compile_ios_protobuf.sh it resulted in the exact same error.
### Logs or other output that would be helpful

I can upload the full log if needed
"
3074,Tensorflow compile failed,"bazel's version :0.30
tensorflow's version: git clone lastest source code
cuda: 7.0
i've tried compiling tensorflow and get the following error:
@damienmg @vrv 

---

ERROR: /home/scw4350/yxc/tensorflow/tensorflow/stream_executor/BUILD:5:1: C++ compilation of rule '//tensorflow/stream_executor:stream_executor' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/scw4350/.cache/bazel/_bazel_scw4350/e4878b1a7f151dbce57ddd078b0591b0/execroot/tensorflow && \
  exec env - \
    PATH=/home/scw4350/bin:/usr/local/cuda-7.0/bin:/usr/local/cuda-7.5/bin:/home/scw4350/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.pic.o' -fPIC -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/protobuf -iquote bazel-out/local_linux-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/farmhash_archive -iquote bazel-out/local_linux-opt/genfiles/external/farmhash_archive -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/highwayhash -iquote bazel-out/local_linux-opt/genfiles/external/highwayhash -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -iquote external/zlib_archive -iquote bazel-out/local_linux-opt/genfiles/external/zlib_archive -isystem external/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem bazel-out/local_linux-opt/genfiles/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/highwayhash -isystem bazel-out/local_linux-opt/genfiles/external/highwayhash -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-802d984ade26 -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-802d984ade26 -isystem external/zlib_archive/zlib-1.2.8 -isystem bazel-out/local_linux-opt/genfiles/external/zlib_archive/zlib-1.2.8 -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -MD -MF bazel-out/local_linux-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.pic.d -c tensorflow/stream_executor/cuda/cuda_dnn.cc -o bazel-out/local_linux-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionFwdAlgo_t perftools::gputools::cuda::{anonymous}::ToConvForwardAlgo(perftools::gputools::dnn::AlgorithmType)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:271:10: error: 'CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING' was not declared in this scope
     case CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING:
          ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionBwdDataAlgo_t perftools::gputools::cuda::{anonymous}::ToConvBackwardDataAlgo(perftools::gputools::dnn::AlgorithmType)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:289:10: error: 'CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING' was not declared in this scope
     case CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING:
"
3073,tf.reset_default_graph() doesn't work on kubernetes?,"In my understanding reset_default_graph() will reset the whole graph. However, it seems that this will only reset the value of variables when running parameter servers on kubernetes.

First, I tried to get variable values before and after reset_default_graph(). The value is reset (value is 0) after running reset_default_graph().

Then I tried to run a totally different algorithm using the same parameter server, it reported the error below:

**Assign requires shapes of both tensors to match. lhs shape= [5,5,32,64] rhs shape= [50000]**

Only chief run the reset_default_graph()  cmd. The code is:

```
is_chief = (FLAGS.worker_index == 0)
if is_chief: tf.reset_default_graph()
```

The whole error message is:

```
Traceback (most recent call last):                                                                                                 
  File ""word2vector.py"", line 160, in <module>                                                                                     
    with sv.prepare_or_wait_for_session(FLAGS.worker_grpc_url, config=sess_config) as sess:                                        
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 685, in prepare_or_wait_for_session 
    config=config, init_feed_dict=self._init_feed_dict)                                                                            
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 163, in prepare_session        
    sess.run(init_op, feed_dict=init_feed_dict)                                                                                    
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 340, in run                              
    run_metadata_ptr)                                                                                                              
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 564, in _run                             
    feed_dict_string, options, run_metadata)                                                                                       
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 637, in _do_run                          
    target_list, options, run_metadata)                                                                                            
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 659, in _do_call                         
    e.code)                    

tensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [5,5,32,64] rhs shape= [50000]                                                                                                                   

         [[Node: Variable_3/Assign = Assign[T=DT_FLOAT, _class=[""loc:@Variable_3""], use_locking=true, validate_shape=true, _device=
""/job:ps/replica:0/task:3/cpu:0""](Variable_3, zeros_S1)]]                                                                          
Caused by op u'Variable_3/Assign', defined at:                                                                                     
  File ""word2vector.py"", line 127, in <module>                                                                                     
    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))                                                                          
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 209, in __init__                          
    dtype=dtype)                                                                                                                   
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 308, in _init_from_args                   
    validate_shape=validate_shape).op                                                                                              
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 40, in assign                         
    use_locking=use_locking, name=name)                                                                                            
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op                     
    op_def=op_def)                                                                                                                 
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op                        
    original_op=self._default_original_op, op_def=op_def)                                                                          
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1154, in __init__                         
    self._traceback = _extract_stack()                   
```
"
3071,0.9.0 installation issue ,"I have a system that have no access to the internet. usually I download the wheel file of tensorflow and install it via file. I'm trying to upgrade tensorflow version with my method but it seem it cant be done. I'm trying to upgrade my tensorflow version from 0.8.0 to 0.9.0.
### Environment info

Operating System: Ubuntu 14.04  (CPU version)
### Logs or other output that would be helpful

``` Exception:
Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/usr/local/lib/python2.7/dist-packages/pip/commands/install.py"", line 317, in run
    prefix=options.prefix_path,
  File ""/usr/local/lib/python2.7/dist-packages/pip/req/req_set.py"", line 742, in install
    **kwargs
  File ""/usr/local/lib/python2.7/dist-packages/pip/req/req_install.py"", line 831, in install
    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)
  File ""/usr/local/lib/python2.7/dist-packages/pip/req/req_install.py"", line 1032, in move_wheel_files
    isolated=self.isolated,
  File ""/usr/local/lib/python2.7/dist-packages/pip/wheel.py"", line 348, in move_wheel_files
    assert info_dir, ""%s .dist-info directory not found"" % req
AssertionError: cpu-tensorflow==0.9.0 .dist-info directory not found
```
"
3070,GLIBC bug,"I use ubuntu16.04, at before it is OK to build, after I updated GLIBC, this bug happened.

```
ERROR: /home/wenjian/pkgs/tensorflow/tensorflow/tools/proto_text/BUILD:31:1: Linking of rule '//tensorflow/tools/proto_text:gen_proto_text_functions' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/tools/proto_text/gen_proto_text_functions ... (remaining 26 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/usr/bin/ld: bazel-out/host/bin/tensorflow/core/liblib_internal.a(numbers.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'
//lib/x86_64-linux-gnu/libm.so.6: error adding symbols: DSO missing from command line
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
```
"
3069,Installation issue with CUDA 8,"Hi,

I've attempted to install Tensorflow with CUDA 8 on Ubuntu 14.04 by installing from source since it doesn't seem like there are binaries available (following https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#installing-from-sources)

Everything installed well, but once I tried importing, I received this while trying to import tensorflow in python:
ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory.

I'm not sure where this is coming from, since I'm using CUDA 8.  I did have a previous installation of CUDA 7.5, but all those files got replaced, and there is no libcudart.so.7.5 (or anything 7.5) in the cuda lib64 folder.

Any thoughts? Many Thanks!
### Environment info

Operating System: Ubuntu 14.04
Graphics Card: NVIDIA GTX 1080 Founders Edition

Installed version of CUDA and cuDNN: CUDA 8.0, cuDNN 5.0
-rw-r--r-- 1 root     root       560184 Jun 27 16:13 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root     root           16 Jun 27 16:13 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root     root           19 Jun 27 16:13 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root     root       394472 Jun 27 16:13 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root     root       737516 Jun 27 16:13 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 lfibrain lfibrain       13 Jun 27 17:02 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 lfibrain lfibrain       17 Jun 27 17:02 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.0.5
lrwxrwxrwx 1 lfibrain lfibrain       17 Jun 27 17:46 /usr/local/cuda/lib64/libcudnn.so.5.0 -> libcudnn.so.5.0.5
-rwxr-xr-x 1 lfibrain lfibrain 78065952 Apr 22 15:17 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 lfibrain lfibrain 68709594 Apr 22 15:17 /usr/local/cuda/lib64/libcudnn_static.a

If installed from sources, provide the commit hash:
861644c
### Steps to reproduce
1. Install NVIDIA 367 driver
2. Install CUDA 8.0
3. Install cuDNN 5.0
4. Reboot
5. Install tensorflow from source with bazel using the above configuration
### What have you tried?
1. reconfiguring/reinstalling tensorflow with inputting the exact directory locations (instead of pressing ENTER for default), even if the default locations were already correct.
"
3068,GTX 1080 with CIFAR 10 example,"I ran the tensorflow CIFAR10 example and got the following error: (sometimes shows loss such as loss = 523454323, I reinstall the CPU only version and that works fine.)
### Environment info

Operating System: Ubuntu 14.04
GPU: GTX 1080
Installed version of CUDA and cuDNN: CUDA7.5, CUDNN V4

name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:02:00.0
Total memory: 7.92GiB
Free memory: 7.81GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x1e22300
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.05GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
2016-06-28 12:03:35.740025: step 0, loss = 4.68 (4.7 examples/sec; 27.498 sec/batch)
W tensorflow/core/kernels/queue_base.cc:292] _0_input_producer: Skipping cancelled enqueue attempt with queue not closed
Traceback (most recent call last):
  File ""cifar10_train.py"", line 136, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""cifar10_train.py"", line 132, in main
    train()
  File ""cifar10_train.py"", line 105, in train
    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'
AssertionError: Model diverged with loss = NaN
"
3067,"reshape on bad data: ""segment_ids[0] = -1 is out of range""","This piece of code fails in `unsorted_segment_sum` inside `Reshape` op. It works just fine for a few batches and then fails on one specific batch of data: it just so happened (bug in my code) that the length of one line of the input of rnn turned out to be zero (and `length` param in `dynamic_rnn` was also zero), and I was passing the resulting tensor to a reshape, so it gave me this error:

```
InvalidArgumentError: segment_ids[0] = -1 is out of range [0, 100100)
     [[Node: gradients/Reshape_grad/Reshape/tensor = UnsortedSegmentSum[T=DT_FLOAT, Tindices=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](gradients/Gather_grad/Reshape/_137, gradients/Gather_grad/Reshape_1/_139, gradients/Reshape_grad/Reshape/Squeeze/_141)]]
     [[Node: gradients/Reshape_grad/Reshape/tensor/_143 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:2"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_31_gradients/Reshape_grad/Reshape/tensor"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:2""]()]]
...
  File ""/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1383, in reshape
    name=name)
  File ""/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py"", line 455, in apply_op
    as_ref=input_arg.is_ref)
  File ""/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 620, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/ops/gradients.py"", line 94, in _IndexedSlicesToTensor
    name=name)
  File ""/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 2215, in unsorted_segment_sum
    num_segments=num_segments, name=name)
  File ""/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2260, in create_op
    original_op=self._default_original_op, op_def=op_def)
```

here's the piece of code on which it fails:

```
def last_relevant(output, length):
    batch_size = tf.shape(output)[0]
    max_length = int(output.get_shape()[1])
    output_size = int(output.get_shape()[2])
    index = tf.range(0, batch_size) * max_length + (length - 1)
    flat = tf.reshape(output, [-1, output_size])
    relevant = tf.gather(flat, index)
    return relevant
```

just wondering if error message could be less obscure.
"
3066,Tensorboard webpage breaking on current build,"**Tensorboard** GUI is breaking on the latest build after commit https://github.com/tensorflow/tensorflow/commit/861644c0bcae5d56f7b3f439696eefa6df8580ec.

On Chrome, only a blue header with buttons appears.
On Firefox, large button icons appear (unclickable).

The nightly build from about a week ago works fine with the orange header and using same event files.
Operating System: Ubuntu 14.04 x64
"
3065,Problem running build_all_ios.sh ,"Mac OS X: El Capitan (10.11.4)

I am trying to build Tensorflow for iOS and am following the ""Building all at once"" instructions found [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/makefile/README.md).  When running the build_all_ios.sh file, I am getting the following errors:

In file included from /Users/mw/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-802d984ade26/unsupported/Eigen/CXX11/../../../Eigen/Core:355:
/Users/mw/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-802d984ade26/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/NEON/Complex.h:18:35: error: 
      statement expression not allowed at file scope
static uint32x4_t p4ui_CONJ_XOR = vld1q_u32( conj_XOR_DATA );

/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../lib/clang/7.3.0/include/arm_neon.h:7609:39: note: 
      expanded from macro 'vld1q_u32'
# define vld1q_u32(**p0) __extension** ({ \

In file included from tensorflow/core/kernels/xent_op.cc:20:
In file included from ./tensorflow/core/kernels/xent_op.h:20:
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:
In file included from /Users/mw/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-802d984ade26/unsupported/Eigen/CXX11/Tensor:14:
In file included from /Users/mw/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-802d984ade26/unsupported/Eigen/CXX11/../../../Eigen/Core:355:
/Users/mw/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-802d984ade26/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/NEON/Complex.h:19:35: error: 
      statement expression not allowed at file scope
static uint32x2_t p2ui_CONJ_XOR = vld1_u32( conj_XOR_DATA );

/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../lib/clang/7.3.0/include/arm_neon.h:7759:38: note: 
      expanded from macro 'vld1_u32'
# define vld1_u32(**p0) __extension** ({ \

2 errors generated.
make: **\* [/Users/mw/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/core/kernels/xent_op.o] Error 1
- '[' 2 -ne 0 ']'
- echo 'armv7 compilation failed.'
  armv7 compilation failed.
- exit 1
  MW:makefile mw$ ./build_all_ios.sh

I have been able to overcome many issues up to this one but am now stuck.  Any suggestions?
"
3061,Supervisor should start queue runners before initializing the model,"For some use cases, the models use a random batch of inputs when initializing the weights. Currently (as of version 0.9) this is not supported with Supervisor that uses queues. It attempts to initialize the model before starting queue runners (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/supervisor.py#L650 method prepare_or_wait_for_session).

Do you think changing the order of operations in this method is reasonable? 
1. recover_session() 
2. start_queue_runners() (currently done at the end)
3. initialize_model()

Thanks!
"
3059,tf_version_script giving syntaxerror,"Hi everyone,
I ran the command `ld tf_version_script.lds` and it gave this error-
`ld:/home/me/tensorflow/tensorflow/tf_version_script.lds:1: syntax error`
I had the directory mounted. Why is this happening?
Thanks!
"
3057,Use gpu_memory_fraction in while using distributed tensorflow,"While I'm implementing models in A3C, I tried to allocate a fraction of gpu to a process and processes that use multiple fractions of gpus update a parameters of a parameter server (in a single machine). For example, I want to create 12 workers with 3 gpus to update a master model.

I referenced https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html and used `tf.GPUOptions(per_process_gpu_memory_fraction=0.1)` but it doesn't work when we pass it to `sv.managed_session` (just take all of the memory of the first visible gpu).

Also, I can't find how to give `GPUOptions` to parameter server that does not have session creation (I always pass `GPUoptions` to `tf.Session` which similar to `sv.managed_session`). **How can I allocate a specific fraction of a gpu to each tasks including parameter server and workers?**

Code can be found https://github.com/devsisters/DQN-tensorflow/blob/distributed/main.py#L78.
"
3056,LSTMStateTuple without get_shape() method,"I have a problem when building seq2seq model with attention based on the LSTM cell, using TensorFlow r0.9 on OS X.

I find that the LSTMCell generates a LSTMStateTuple state if the state_is_tuple parameter is set to True (the rnn_cell.py code seems to encourage this setting). But when I feed the output to an attention_decoder as the initial_state, the attention() function in seq2seq.py calls the _linear() function in rnn_cell.py, and _linear() calls the get_shape() function of the initial_state variable, and the program reports ""AttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'"". 

Could you please help me find if I am missing some important steps in building seq2seq with attention based on the LSTM cell, or should LSTMStateTuple support the get_shape() function?

(The error does not appear when I set state_is_tuple=False.)

Thank you!
"
3055,wide_n_deep_tutorial.py,"I want to output the data's result: such as: age: 18,  percent, gender: female, percent.
What should I do?
"
3054,Multivariate normal distribution crashes on broadcast,"### Environment info

Operating System: Mac OS X 10.11.5

If installed from binary pip package, provide:
1. Which pip package you installed. 
   https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0-py3-none-any.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.9.0
### Issue

The Multivariate Normal distribution in `contrib.distributions` [claims to support broadcasting](https://github.com/tensorflow/tensorflow/blob/d42facc3cc9611f0c9722c81551a7404a0bd3f6b/tensorflow/contrib/distributions/python/ops/mvn.py#L378) but it does not appear to work. This script will illustrate the issue:

``` python
import numpy as np
import tensorflow as tf

# dimensions
a = 2
b = 3
c = 4

mu = tf.reshape(tf.constant(
    np.arange(a * b * c * 1.0)),
    [a, b, c])

sigma = tf.batch_matrix_diag(tf.reshape(tf.constant(
    np.arange(a * b * c * 1.0) + 1),
    [a, b, c]))

mvn = tf.contrib.distributions.MultivariateNormal(mu, sigma)

with tf.Session() as sess:
    # works because shape(input) == shape(mu)
    sess.run(mvn.pdf(np.ones((a, b, c))))

    # fails even though input and mu are broadcastable
    sess.run(mvn.pdf(np.ones((1, a, b, c))))
```
"
3052,No nightly wheel with CUDA 8.0,"Current nightly Linux wheel seems to be built with CUDA 7.5

Going from 7.5 to CUDA 8.0 gives me about 50% speed in TensorFlow up on 2048x2048 matmul on GTX 980 (2 T ops/sec -> 3 T ops/sec)

```

export url=http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/143/artifact/pip_test/whl/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
pip install --upgrade $url

# check that it has GPU support
# note, I see performance gain of 50% on matmul going from 7.5 to 8.0
ldd ~/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so | grep libcudart
    libcudart.so.7.5 => /usr/local/cuda-7.5/lib64/libcudart.so.7.5 (0x00007f4290bec000)

```
"
3051,wide_n_deep_tutorial.py,"helloI am woking on wide_n_deep_tutorial.py and I change the download part like this:

```
def maybe_download():
  """"""May be downloads training data and returns train and test file names.""""""
  train_file_name = ""./adult.data""
  print(""Training data is %s"" % train_file_name)

  test_file_name = ""./adult.test""
  print(""Test data is %s"" % test_file_name)

  return train_file_name, test_file_name
```

and I got this error! :TypeError: argument of type 'float' is not iterable! 
at this line:`df_train[LABEL_COLUMN] = (df_train[""income_bracket""].apply(lambda x: "">50K"" in x)).astype(int)`
I don't known how to make it right! please help!
"
3050,tf_version_script giving syntaxerror,"Hi everyone,
I ran the command `ld tf_version_script.lds` and it gave this error-
`ld:/home/me/tensorflow/tensorflow/tf_version_script.lds:1: syntax error`
I had the directory mounted. Why is this happening? 
Thanks!
"
3048,android demo protobuf-related build error,"### Environment info

Operating System:
Ubuntu 14.04

Installed version of CUDA and cuDNN: 
None

If installed from binary pip package, provide:
Git cloned. Tried several versions of TF. Same result.
### Steps to reproduce
1. Clone repo here : https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android
2. I installed SDK 24 (part of Android Studio) and NKD 10e.
3. Also installed build tools 23.0.1. Seemed to be required.
4. Followed steps on page
### What have you tried?
1. I tried several versions of bazel and tensorflow. The error persists.
### Logs or other output that would be helpful

This is my error:

C++ compilation of rule '@protobuf//:protobuf' failed: namespace-sandbox failed: error executing command /home/sander/.cache/bazel/_bazel_sander/577a8dcd97360f56540bc1f3f08ac240/tf-cat-face/_bin/namespace-sandbox ... (remaining 51 argument(s) skipped).
src/main/tools/namespace-sandbox.c:697: execvp(argv[0], argv): No such file or directory
Target //tensorflow/examples/android:tensorflow_demo failed to build
Use --verbose_failures to see the command lines of failed build steps.
### Also, here's how I edited the WORKSPACE file.

workspace(name = ""org_tensorflow"")

android_sdk_repository(
    name = ""androidsdk"",
    api_level = 24,
    build_tools_version = ""23.0.1"",
    # Replace with path to Android SDK on your system
    path = ""/home/sander/Android/Sdk/"",
)

android_ndk_repository(
    name=""androidndk"",
    path=""/home/sander/Android/android-ndk-r10e/"",
    api_level=21)

This error is quite persistent as I've already tried many installations of both TF and Bazel. I also have a little side question: if the build succeeds, what should the output be when there is no camera attached to my PC? Should I build with my android phone plugged in via USB? Thanks!
"
3047,Logging doesn't produce any output in console or in Jupyter,"Currently running examples leads to a void of empty output.
Both in console and in Jupyter notebooks. Which for example of LinearClassifier leads to a ""stuck"" model because steps by default is None.
"
3046,Please add Cuda compute capability 6.1 for GTX 1080,"I am building tensorflow from source, and after running below from the root

`bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer`

I get

> ERROR: /home/shuaiwang/Downloads/tensorflow/tensorflow/cc/BUILD:61:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error cloning repository: https://github.com/google/protobuf: cannot open git-upload-pack caused by https://github.com/google/protobuf: cannot open git-upload-pack caused by github.com and referenced by '//tensorflow/cc:tutorials_example_trainer'.
> ERROR: /home/shuaiwang/Downloads/tensorflow/tensorflow/cc/BUILD:61:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error cloning repository: https://github.com/google/protobuf: cannot open git-upload-pack caused by https://github.com/google/protobuf: cannot open git-upload-pack caused by github.com and referenced by '//tensorflow/cc:tutorials_example_trainer'.
> ERROR: Analysis of target '//tensorflow/cc:tutorials_example_trainer' failed; build aborted.
> INFO: Elapsed time: 11.805s

I guess this is because tensorflow doesn't support compute capability for 6.1, which is the only option for GTX 1080, according to [this](https://developer.nvidia.com/cuda-gpus)?
"
3044,Deep MNIST Tutorial would benefit from some diagrams of the neural network architecture ,"The basic version of this tutorial has a [nice diagram](https://www.tensorflow.org/versions/r0.9/images/softmax-regression-scalargraph.png) that makes it really clear what model the code is attempting to reproduce.

The _Deep MNIST for Experts_ tutorial however doesn't have such an image, especially for the Multilayer Convolutional Network that is the heart of the article. I had a hard time (and still do, a bit) visualising what exactly the model code is attempting to do. I think the tutorial would benefit from some diagrams.

I am willing to contribute this if someone could handhold me a bit as to how the graphic above was generated and what the bar is for contributing to the docs.
"
3043,NameError: Name MNIST is not defined,"I am following the [Deep MNIST](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/pros/index.html#start-tensorflow-interactivesession) tutorial. After copy-pasting code till [here](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/pros/index.html#evaluate-the-model), I get a NameError. The exact output is

```
Traceback (most recent call last):
  File ""Deep_MNIST.py"", line 29, in <module>
    batch = mnist.train.next_batch(50)
NameError: name 'mnist' is not defined
```

This is my file-

```
x = tf.placeholder(tf.float32, shape=[None, 784])
y_ = tf.placeholder(tf.float32, shape=[None, 10])

W = tf.Variable(tf.zeros([784,10]))
b = tf.Variable(tf.zeros([10]))

sess.run(tf.initialize_all_variables())

y = tf.nn.softmax(tf.matmul(x,W) + b)

cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))

train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

for i in range(1000):
  batch = mnist.train.next_batch(50)
  train_step.run(feed_dict={x: batch[0], y_: batch[1]})

correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
```

Thanks!
"
3042,Inconsistent naming of the getter functions in the C API,"The naming scheme of the getter functions in the [C API](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/public/tensor_c_api.h) seems to be a bit inconsistent. For instance, there are the following declarations:

``` c
// With Get and without the type name.
extern TF_Code TF_GetCode(const TF_Status*);

// Without Get and without the type name.
extern const char* TF_Message(const TF_Status*);

// Without Get and with the type name (Tensor).
extern TF_DataType TF_TensorType(const TF_Tensor*);
```

The first two are even concerned with the same type, `TF_Status`. Im curious if theres any particular reason behind this naming. Thanks!

Regards,
Ivan
"
3039,convert_to_records.py has maybe_download and other functions that are not found.,"When I ran convert_to_records.py without changing the file, it would complain maybe_download and other functions that are not found. If you look at the input_data that was imported, it doesn't include the maybe_download as well even with recursive imports. 

When I fixed that by copying and pasting from the mnist/convolution.py the download and extraction of the images and label, I ran the fully_connected_reader.py, then it would complain:
W tensorflow/core/framework/op_kernel.cc:909] Invalid argument: Shape mismatch in tuple component 0. Expected [784], got [3136]
Traceback (most recent call last):
  File ""fully_connected_reader.py"", line 203, in <module>
    tf.app.run()
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""fully_connected_reader.py"", line 199, in main
    run_training()
  File ""fully_connected_reader.py"", line 194, in run_training
    coord.join(threads)
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 322, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/queue_runner.py"", line 185, in _run
    sess.run(enqueue_op)
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 372, in run
    run_metadata_ptr)
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 636, in _run
    feed_dict_string, options, run_metadata)
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 708, in _do_run
    target_list, options, run_metadata)
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 728, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Shape mismatch in tuple component 0. Expected [784], got [3136]
     [[Node: input/shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], _class=[""loc:@input/shuffle_batch/random_shuffle_queue""], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](input/shuffle_batch/random_shuffle_queue, input/sub, input/Cast_1)]]
Caused by op u'input/shuffle_batch/random_shuffle_queue_enqueue', defined at:
  File ""fully_connected_reader.py"", line 203, in <module>
    tf.app.run()
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""fully_connected_reader.py"", line 199, in main
    run_training()
  File ""fully_connected_reader.py"", line 140, in run_training
    num_epochs=FLAGS.num_epochs)
  File ""fully_connected_reader.py"", line 126, in inputs
    min_after_dequeue=1000)
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py"", line 768, in shuffle_batch
    _enqueue(queue, tensor_list, num_threads, enqueue_many)
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py"", line 490, in _enqueue
    enqueue_ops = [queue.enqueue(tensor_list)] \* threads
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/data_flow_ops.py"", line 296, in enqueue
    return gen_data_flow_ops._queue_enqueue(self._queue_ref, vals, name=scope)
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 542, in _queue_enqueue
    name=name)
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 711, in apply_op
    op_def=op_def)
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2260, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/user/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1230, in __init__
    self._traceback = _extract_stack()

Not sure if my fix to convert_to_records.py was wrong or the fully_connected_reader.py was off for some other reason.
"
3038,Incorrect tf.truncated_normal results on gpu,"I've narrowed the behavior I'm seeing to this small example

```
with tf.Session() as s : 
    with tf.device(DEVICE):
      v = tf.Variable(tf.truncated_normal([2, 2], stddev=1.0, dtype=tf.float32))
    with tf.device('/gpu:0'):
      p = tf.placeholder( tf.float32, shape=(2,2))
      product = tf.matmul(p,v)
      s.run(tf.initialize_all_variables())
      feed = {p: np.eye(2,2)}
      product_res,v_res = s.run([product,v], feed_dict=feed)
      print(v_res)
      print(product_res)
```

When DEVICE is '/cpu:0' all is as expected.  With DEVICE as '/gpu:0', the output will be as expected for one execution, but output two identity matrices for all subsequent executions.  Running again with DEVICE='/cpu:0' resets the gpu behavior.
### Environment info

Operating System: Fedora 23

Installed version of CUDA and cuDNN: 
I'm using CUDA 7.5 and cuDNN v5 with Driver Version: 367.27 on a gtx780
-rw-r--r--. 1 root    root      322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx. 1 root    root          16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx. 1 root    root          19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x. 1 root    root      383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r--. 1 root    root      720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx. 1 jlovitt jlovitt       13 Apr 22 20:52 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx. 1 jlovitt jlovitt       17 Apr 22 20:52 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.0.5
-rwxrwxr-x. 1 jlovitt jlovitt 59909104 Apr 22 18:15 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rw-rw-r--. 1 jlovitt jlovitt 58775484 Apr 22 18:15 /usr/local/cuda/lib64/libcudnn_static.a

If installed from sources, provide the commit hash: 84225a2b612fe748c9c923f0c1cb8471911c3b77
I've added the following lines to third_party/gpus/crosstool/CROSSTOOL to compile with gcc 4.9.3

```
cxx_builtin_include_directory: ""/home/jlovitt/opt/gcc-4.9.3/include""
cxx_builtin_include_directory: ""/home/jlovitt/opt/gcc-4.9.3/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include""
cxx_builtin_include_directory: ""/home/jlovitt/opt/gcc-4.9.3/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include-fixed""
```
### Output from execution producing incorrect results

```
$ipython3 util/tensorflowtest.py 
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 780
major: 3 minor: 5 memoryClockRate (GHz) 1.0195
pciBusID 0000:01:00.0
Total memory: 2.95GiB
Free memory: 2.60GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:844] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 780, pci bus id: 0000:01:00.0)
[[ 1.  0.]
 [ 0.  1.]]
[[ 1.  0.]
 [ 0.  1.]]
```
## Update:

Recompiling with CUDA 7.0 and cuDNN v4 fixes the problem.
"
3037,Stuck at prepare_or_wait_for_session for workers when running on kubernetes,"### Environment info

Operating System: Kubernetes/Ubuntu 14.04
### Steps to reproduce
1. start tensorflow server on kubernetes using yaml generated by [the python code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/scripts/k8s_tensorflow.py)
2. Start tensorflow code:

```
python mnist_dnn.py --worker_grpc_url=grpc://180.101.191.78:30001 --worker_index=0 --workers=180.101.191.78:30001,180.101.191.78:30002,180.101.191.78:30003 --parameter_servers=tf-ps0:2222,tf-ps1:2222
```

```
python mnist_dnn.py --worker_grpc_url=grpc://180.101.191.78:30002 --worker_index=1 --workers=180.101.191.78:30001,180.101.191.78:30002,180.101.191.78:30003 --parameter_servers=tf-ps0:2222,tf-ps1:2222
```
### What have you tried?
1. The worker with index 0 (chief) can execute normally.
2. It was able to execute well (using the same yaml and code)
3. I tried to restart the servers, but it didn't work.
4. All other workers stuck at `prepare_or_wait_for_session`. However, it seems that logs suggest other workers are actually executing. 

Log is [here](https://github.com/tensorflow/tensorflow/files/332895/log.txt) and the code is here:

```
import sys
import time

import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import datetime

flags = tf.app.flags
flags.DEFINE_string(""data_dir"", ""/tmp/data"",
                    ""Directory for storing mnist data"")

flags.DEFINE_boolean(""download_only"", False,
                     ""Only perform downloading of data; Do not proceed to ""
                     ""session preparation, model definition or training"")

flags.DEFINE_integer(""worker_index"", 0,
                     ""Worker task index, should be >= 0. worker_index=0 is ""
                     ""the master worker task the performs the variable ""
                     ""initialization "")

flags.DEFINE_string(""workers"", None,
                    ""The worker url list, separated by comma (e.g. tf-worker1:2222,1.2.3.4:2222)"")

flags.DEFINE_string(""parameter_servers"", None,
                    ""The ps url list, separated by comma (e.g. tf-ps2:2222,1.2.3.5:2222)"")

flags.DEFINE_integer(""grpc_port"", 2222,
                     ""TensorFlow GRPC port"")

flags.DEFINE_integer(""train_steps"", 200000,
                     ""Number of (global) training steps to perform"")

flags.DEFINE_string(""worker_grpc_url"", None,
                    ""Worker GRPC URL (e.g., grpc://1.2.3.4:2222, or ""
                    ""grpc://tf-worker0:2222)"")
FLAGS = flags.FLAGS

cur_time = datetime.datetime.now().strftime('%Y%m%d%H%M%S')

def nn_layer(input_tensor, input_dim, output_dim, act=tf.nn.relu):
    with tf.name_scope(cur_time):
        weights = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1))
        biases = tf.Variable(tf.constant(0.1, shape=[output_dim]))
    activations = act(tf.matmul(input_tensor, weights) + biases)
    return activations

def model(x, y_, global_step):
    hidden_nodes = 500
    hidden1 = nn_layer(x, 784, hidden_nodes)
    y = nn_layer(hidden1, hidden_nodes, 10, act=tf.nn.softmax)

    cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))
    train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy, global_step=global_step)

    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

    return train_step, accuracy

print(""Loading data from worker index = %d"" % FLAGS.worker_index)

mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)
print(""Testing set size: %d"" % len(mnist.test.images))
print(""Training set size: %d"" % len(mnist.train.images))
if FLAGS.download_only: sys.exit(0)

print(""Worker GRPC URL: %s"" % FLAGS.worker_grpc_url)
print(""Workers = %s"" % FLAGS.workers)
print(""Using time = %s"" % cur_time)

is_chief = (FLAGS.worker_index == 0)
cluster = tf.train.ClusterSpec({""ps"": FLAGS.parameter_servers.split("",""), ""worker"": FLAGS.workers.split("","")})
# Construct device setter object
device_setter = tf.train.replica_device_setter(cluster=cluster)

# The device setter will automatically place Variables ops on separate
# parameter servers (ps). The non-Variable ops will be placed on the workers.
with tf.device(device_setter):
    with tf.name_scope(cur_time):
        global_step = tf.Variable(0, trainable=False)

    x = tf.placeholder(tf.float32, [None, 784])
    y_ = tf.placeholder(tf.float32, [None, 10])
    val_feed = {x: mnist.test.images, y_: mnist.test.labels}

    train_step, accuracy = model(x, y_, global_step)

    sv = tf.train.Supervisor(is_chief=is_chief,
                             logdir=""/tmp/dist-mnist-log/train"",
                             saver=tf.train.Saver(),
                             init_op=tf.initialize_all_variables(),
                             recovery_wait_secs=1,
                             global_step=global_step)
    sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True,
                                 device_filters=[""/job:ps"", ""/job:worker/task:%d"" % FLAGS.worker_index])

    # The chief worker (worker_index==0) session will prepare the session,
    # while the remaining workers will wait for the preparation to complete.
    if is_chief:
        print(""Worker %d: Initializing session..."" % FLAGS.worker_index)
    else:
        print(""Worker %d: Waiting for session to be initialized..."" % FLAGS.worker_index)

    with sv.prepare_or_wait_for_session(FLAGS.worker_grpc_url, config=sess_config) as sess:
        print(""Worker %d: Session initialization complete."" % FLAGS.worker_index)

        # Perform training
        time_begin = time.time()
        print(""Training begins @ %f"" % time_begin)

        local_step = 0
        while True:
            # Training feed
            batch_xs, batch_ys = mnist.train.next_batch(100)
            train_feed = {x: batch_xs, y_: batch_ys}

            _, step = sess.run([train_step, global_step], feed_dict=train_feed)
            local_step += 1
            if local_step % 100 == 0:
                print(""Worker %d: training step %d done (global step: %d); Accuracy: %g"" % 
                      (FLAGS.worker_index, local_step, step, sess.run(accuracy, feed_dict=val_feed)))
            if step >= FLAGS.train_steps: break

        time_end = time.time()
        print(""Training ends @ %f"" % time_end)
        training_time = time_end - time_begin
        print(""Training elapsed time: %f s"" % training_time)

        # Accuracy on test data
        print(""Final test accuracy = %g"" % (sess.run(accuracy, feed_dict=val_feed)))
```
"
3036,rnn language model example https://www.tensorflow.org/versions/r0.8/tutorials/recurrent/index.html isnt working,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
Ubuntu 14.04
Installed version of CUDA and cuDNN: cuda 7.5, cudnn 5.0.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root 189170 Jun 12 02:51 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Jun 12 02:51 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Jun 12 02:51 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Jun 12 02:51 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Jun 12 02:51 /usr/local/cuda/lib/libcudart_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so.7.5 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so.5.0.5 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so.7.5 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so.7.5 locally
   0.8.0
   If installed from sources, provide the commit hash:
### Steps to reproduce
1. example from https://www.tensorflow.org/versions/r0.8/tutorials/recurrent/index.html github in: tensorflow/tensorflow/models/rnn/ptb/ 
2. wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz and extract it
3. python ptb_word_lm.py --data_path=simple-examples/data/ after you get 
### What have you tried?
1. Running it - i'm new to TF, however the cost is nan and doesn't make sense that iters is nan as well. Tried both TF 0.9 and 0.8 , same output 
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
0.004 perplexity: 1.000 speed: 9537 wps
0.104 perplexity: nan speed: 11236 wps
0.204 perplexity: nan speed: 11232 wps
0.304 perplexity: nan speed: 11206 wps
0.404 perplexity: nan speed: 11231 wps

0.504 perplexity: nan speed: 11220 wps
0.604 perplexity: nan speed: 11239 wps
0.703 perplexity: nan speed: 11250 wps
0.803 perplexity: nan speed: 11259 wps
0.903 perplexity: nan speed: 11261 wps
Epoch: 4 Train Perplexity: nan
Epoch: 4 Valid Perplexity: nan
Epoch: 5 Learning rate: 1.000
0.004 perplexity: 1.000 speed: 9563 wps
0.104 perplexity: nan speed: 11171 wps
0.204 perplexity: nan speed: 11219 wps
0.304 perplexity: nan speed: 11245 wps
0.404 perplexity: nan speed: 11264 wps
0.504 perplexity: nan speed: 11269 wps
0.604 perplexity: nan speed: 11265 wps
0.703 perplexity: nan speed: 11269 wps
"
3035,UnboundLocalError when TF_NewSessionOptions fails in session.py,"The following fails with UnboundLocalError after https://github.com/tensorflow/tensorflow/commit/b80a4a8732dfcbbeb348b9f8470aa420bab3931b

```
session = tf.Session(tf.ConfigProto(log_device_placement=True))

Traceback (most recent call last):
  File ""opts_error.py"", line 3, in <module>
    session = tf.Session(tf.ConfigProto(log_device_placement=True))
  File ""/Users/yaroslavvb/tfimmediate_hood/tensorflow/_python_build/tensorflow/python/client/session.py"", line 880, in __init__
    super(Session, self).__init__(target, graph, config=config)
  File ""/Users/yaroslavvb/tfimmediate_hood/tensorflow/_python_build/tensorflow/python/client/session.py"", line 147, in __init__
    tf_session.TF_DeleteSessionOptions(opts)

UnboundLocalError: local variable 'opts' referenced before assignment

```

It's an incorrect usage of `Session`  I think it used to fail with a more informative message like ``*** TypeError: Expected binary or unicode string, got log_device_placement: true` before https://github.com/tensorflow/tensorflow/commit/b80a4a8732dfcbbeb348b9f8470aa420bab3931b

This commit moved creation inside the ""try/finally"" block, so real exception is swallowed, and this exception happens because ""opts"" right hand side doesn't get evaluated
"
3034,Tensorflow import error on OS X 10.8.5,"I have installed tensorflow using acadonda virtual envoronment. When I import it is giving following error.

```
ImportError: dlopen(/Users/SummerREU/anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 2): Symbol not found: ___sincos_stret
  Referenced from: /Users/SummerREU/anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
  Expected in: /usr/lib/libSystem.B.dylib
 in /Users/SummerREU/anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
```
"
3032,Optimizer classes do not support complex variables,"Using TF 0.8.0.

`````` ---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-4-871aef3761c0> in <module>()
----> 1 train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)
      2 init = tf.initialize_all_variables()

/usr/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc in minimize(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name)
    188         loss, var_list=var_list, gate_gradients=gate_gradients,
    189         aggregation_method=aggregation_method,
--> 190         colocate_gradients_with_ops=colocate_gradients_with_ops)
    191     return self.apply_gradients(grads_and_vars, global_step=global_step,
    192                                 name=name)

/usr/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc in compute_gradients(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops)
    243       grads = control_flow_ops.tuple(grads)
    244     grads_and_vars = list(zip(grads, var_list))
--> 245     self._assert_valid_dtypes([v for g, v in grads_and_vars if g is not None])
    246     return grads_and_vars
    247 

/usr/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc in _assert_valid_dtypes(self, tensors)
    354         raise ValueError(
    355             ""Invalid type %r for %s, expected: %s."" % (
--> 356                 dtype, t.name, [v for v in valid_dtypes]))
    357 
    358   # --------------

ValueError: Invalid type tf.complex64 for complex_weight_variable:0, expected: [tf.float32].```
``````
"
3029,Linking Error building master from sources on 16.04,"Hey all I am getting the following error building tensorflow from sources:

```
ERROR: /home/william/tensorflow/tensorflow/tools/proto_text/BUILD:31:1: Linking of rule '//tensorflow/tools/proto_text:gen_proto_text_functions' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/william/.cache/bazel/_bazel_william/1c01fb06292961944db1914ac48e6a52/execroot/tensorflow && \
  exec env - \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/tools/proto_text/gen_proto_text_functions bazel-out/host/bin/tensorflow/tools/proto_text/_objs/gen_proto_text_functions/tensorflow/tools/proto_text/gen_proto_text_functions.o bazel-out/host/bin/tensorflow/tools/proto_text/libgen_proto_text_functions_lib.a bazel-out/host/bin/tensorflow/core/liblib_internal.a bazel-out/host/bin/external/farmhash_archive/libfarmhash.a bazel-out/host/bin/external/jpeg_archive/libjpeg.a bazel-out/host/bin/external/png_archive/libpng.a bazel-out/host/bin/external/highwayhash/libsip_hash.a bazel-out/host/bin/external/re2/libre2.a bazel-out/host/bin/tensorflow/core/libprotos_all_cc.a bazel-out/host/bin/external/protobuf/libprotobuf.a bazel-out/host/bin/external/protobuf/libprotobuf_lite.a bazel-out/host/bin/external/zlib_archive/libzlib.a -ldl -lz -pthread -lpthread -lstdc++ -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,-S -Wl,--gc-sections): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/usr/bin/ld: bazel-out/host/bin/tensorflow/core/liblib_internal.a(numbers.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'
//lib/x86_64-linux-gnu/libm.so.6: error adding symbols: DSO missing from command line
collect2: error: ld returned 1 exit status
Target //tensorflow/cc:tutorials_example_trainer failed to build
```

This occurs when I run `bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --verbose_failures`
### Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 8.0, 5

```
ls -l /usr/local/cuda-8.0/lib64/libcud*
-rw-r--r-- 1 root root   560184 May 18 17:44 /usr/local/cuda-8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 May 18 17:47 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 May 18 17:47 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rw-r--r-- 1 root root   394472 May 18 17:44 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 May 18 17:44 /usr/local/cuda-8.0/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 78065952 Jun 23 18:54 /usr/local/cuda-8.0/lib64/libcudnn.so
-rwxr-xr-x 1 root root 78065952 Jun 23 18:54 /usr/local/cuda-8.0/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 78065952 Jun 23 18:54 /usr/local/cuda-8.0/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 68709594 Jun 23 18:54 /usr/local/cuda-8.0/lib64/libcudnn_static.a
```

If installed from sources, provide the commit hash: `84225a2b612fe748c9c923f0c1cb8471911c3b77`
### Reproduce It

Follow the documnentation exactly for building from sources:
1. Install Cuda and Cudnn from nvidia
2. Install python/build dependencies
3. Install bazel from apt-get:
- `sudo apt-get install openjdk-8-jdk`
- `sudo apt-get install pkg-config zip g++ zlib1g-dev unzip`
  -  `echo ""deb http://storage.googleapis.com/bazel-apt stable jdk1.8"" | sudo tee /etc/apt/sources.list.d/bazel.list`
- `curl https://storage.googleapis.com/bazel-apt/doc/apt-key.pub.gpg | sudo apt-key add -`
-  `sudo apt-get update && sudo apt-get install bazel`
- Then run the first install command using bazel as mentioned before.
"
3028,iterative pruning,"It would be very advantageous to have support (tools) for iterative pruning in TF as in 
Deep Compression paper
https://arxiv.org/abs/1510.00149
Since in many cases it can give up to 2x speedup and 80% weight reduction practically for free. 
PS: thanks for the excellent support of the framework !
"
3027,cp: cannot stat 'bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/tensorflow': No such file or directory,"### Steps to reproduce
1. `docker build ./tensorflow/tools/docker/Dockerfile.devel-gpu`
### Logs or other output that would be helpful

```
cp: cannot stat 'bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/tensorflow': No such file or directory
cp: cannot stat 'bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/external': No such file or directory
The command '/bin/sh -c ./configure &&     bazel build --local_resources 3072,3.0,1.0 -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package &&     bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip &&     pip install --upgrade /tmp/pip/tensorflow-*.whl' returned a non-zero code: 1
```
"
3026,Accessing ALL the states in rnn.py,"Dear all,

Would it be possible to return all the states when we call the `rnn` function in `tensorflow/tensorflow/python/ops/rnn.py` (and not only the final state):

```
def rnn(cell, inputs, initial_state=None, dtype=None,
        sequence_length=None, scope=None):
```

I posted the code of the latest version as an illustration:

```
   for time, input_ in enumerate(inputs):
      if time > 0: varscope.reuse_variables()
      # pylint: disable=cell-var-from-loop
      call_cell = lambda: cell(input_, state)
      # pylint: enable=cell-var-from-loop
      if sequence_length is not None:
        (output, state) = _rnn_step(
            time=time,
            sequence_length=sequence_length,
            min_sequence_length=min_sequence_length,
            max_sequence_length=max_sequence_length,
            zero_output=zero_output,
            state=state,
            call_cell=call_cell,
            state_size=cell.state_size)
      else:
        (output, state) = call_cell()

      outputs.append(output)

    return (outputs, state)
```

Thanks!
"
3025,python 3.5 mnist implementation error,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: ubuntu 16.04 / 14.04

Installed version of CUDA and cuDNN: NA
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide: NA
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. 0.8.0
   If installed from sources, provide the commit hash:
### Steps to reproduce
1. Just implemented the mnist code provided by tensorflow. 
   2.
   3.
### What have you tried?
1. While starting training, I have got an error as below. I have tried with ubuntu 14.04 and ubuntu 16.04, tensorflow 0.8 and tensorflow 0.9, both had the same error. However, when I tried it with python 2.7, it worked. Now with python 3.5, not working.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

TypeError                                 Traceback (most recent call last)
<ipython-input-9-80fac15278ee> in <module>()
----> 1 training()

<ipython-input-8-d1198db7bf1d> in training()
     11         loss = mnist.loss(logits, labels_placeholder)
     12         train_op = mnist.training(loss, FLAGS.learning_rate)
---> 13         eval_correct = mnist.evaluation(logits, labels_placeholder)
     14         # Build the summary operation based on the TF collections of Summaries.
     15         summary_op = tf.merge_all_summaries()

/opt/conda/lib/python3.5/site-packages/tensorflow/examples/tutorials/mnist/mnist.py in evaluation(logits, labels)
    146   # the examples where the label is in the top k (here k=1)
    147   # of all logits for that example.
--> 148   correct = tf.nn.in_top_k(logits, labels, 1)
    149   # Return the number of true entries.
    150   return tf.reduce_sum(tf.cast(correct, tf.int32))

/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py in in_top_k(predictions, targets, k, name)
    547   """"""
    548   return _op_def_lib.apply_op(""InTopK"", predictions=predictions,
--> 549                               targets=targets, k=k, name=name)
    550 
    551 

/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py in apply_op(self, op_type_name, name, **keywords)
    484             for base_type in base_types:
    485               _SatisfiesTypeConstraint(base_type,
--> 486                                        _Attr(op_def, input_arg.type_attr))
    487             attrs[input_arg.type_attr] = attr_value
    488             inferred_from[input_arg.type_attr] = input_name

/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py in _SatisfiesTypeConstraint(dtype, attr_def)
     57           ""DataType %s for attr '%s' not in list of allowed values: %s"" %
     58           (dtypes.as_dtype(dtype).name, attr_def.name,
---> 59            "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))
     60 
     61 

TypeError: DataType float32 for attr 'T' not in list of allowed values: int32, int64
"
3024,The speed of reading images is unstable.,"The speed of reading image is very unstable. This problem troubled me for a long time. Can anyone help me to check the problem. 

The function of the following code is just reading images from several files with tf_recored pattern in the batch method.

```
def test_tf_decode_jpeg():
  with tf.device('/cpu:0'): 
    tf_record_pattern = os.path.join('../anno/train_data_with_history', '*')
    data_files = tf.gfile.Glob(tf_record_pattern)
    filename_queue = tf.train.string_input_producer(data_files, shuffle=False, capacity=10)
    images = []
    num_preprocess_threads = 4
    for thread_id in range(num_preprocess_threads):
      reader = tf.TFRecordReader()
      _, image = reader.read(filename_queue)
      image = parse_example_proto(image)
      image = tf.image.decode_jpeg(image, channels=3)
      image.set_shape([256,256,3])
      images.append([image])
    batch_size = 256
    image_batch = tf.train.batch_join(images, batch_size=batch_size,capacity=2 * num_preprocess_threads * batch_size)
  sess = tf.Session()
  coord = tf.train.Coordinator()
  threads = tf.train.start_queue_runners(coord=coord, sess=sess)
  for i in xrange(1000000):
    if coord.should_stop():
      break
    start = time.time()
    output_images = sess.run(image_batch) 
    print time.time() - start, output_images.shape
  coord.request_stop()
  coord.join(threads)
```

The speed of reading images is very unstable. Here is the running log.
0.876242160797 (256, 256, 256, 3)
0.165473937988 (256, 256, 256, 3)
0.458849906921 (256, 256, 256, 3)
0.172335863113 (256, 256, 256, 3)
0.483803033829 (256, 256, 256, 3)
0.517580032349 (256, 256, 256, 3)
0.174633979797 (256, 256, 256, 3)
0.944914102554 (256, 256, 256, 3)
0.169141054153 (256, 256, 256, 3)
0.447196006775 (256, 256, 256, 3)
0.512051820755 (256, 256, 256, 3)
0.179712057114 (256, 256, 256, 3)
0.53243303299 (256, 256, 256, 3)
0.646076917648 (256, 256, 256, 3)
0.175096988678 (256, 256, 256, 3)
0.656931877136 (256, 256, 256, 3)
0.500935077667 (256, 256, 256, 3)
0.456654071808 (256, 256, 256, 3)
0.41271686554 (256, 256, 256, 3)
0.169769048691 (256, 256, 256, 3)
0.632494926453 (256, 256, 256, 3)
0.369579076767 (256, 256, 256, 3)
0.160307168961 (256, 256, 256, 3)
0.47083902359 (256, 256, 256, 3)
0.440319061279 (256, 256, 256, 3)
0.534809827805 (256, 256, 256, 3)
0.464602947235 (256, 256, 256, 3)
0.183679103851 (256, 256, 256, 3)
0.605715990067 (256, 256, 256, 3)
0.463223934174 (256, 256, 256, 3)
0.329600095749 (256, 256, 256, 3)
0.181442975998 (256, 256, 256, 3)
0.551628112793 (256, 256, 256, 3)
0.52916097641 (256, 256, 256, 3)
0.172710180283 (256, 256, 256, 3)
0.577185153961 (256, 256, 256, 3)

The utilization of cpu and io is quite low.  

""cat /proc/cpu"" outputs:
processor       : 39
vendor_id       : GenuineIntel
cpu family      : 6
model           : 63
model name      : Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
"
3021,"""Could not find platform independent libraries""  && ""Missing input file""","I am installing Tensorflow on a server without internet access.  I can now build tutorials_example_trainer without GPU support and successfully execute it, but can't move forward to complete the installation. Can you please help me to diagnosis ? Thanks!  
### Environment info

Operating System:
   Red Hat Enterprise Linux Server release 6.6 (Santiago)

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root  28585480 Aug 15  2015 libcublas_device.a
lrwxrwxrwx 1 root root        16 Jun 15 19:52 libcublas.so -> libcublas.so.7.5
lrwxrwxrwx 1 root root        19 Jun 15 19:52 libcublas.so.7.5 -> libcublas.so.7.5.18
-rwxr-xr-x 1 root root  23938736 Aug 15  2015 libcublas.so.7.5.18
-rw-r--r-- 1 root root  28220076 Aug 15  2015 libcublas_static.a
-rw-r--r-- 1 root root    322936 Aug 15  2015 libcudadevrt.a
lrwxrwxrwx 1 root root        16 Jun 15 19:52 libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root        19 Jun 22 03:12 libcudart.so.7.0 -> libcudart.so.7.5.18
lrwxrwxrwx 1 root root        19 Jun 15 19:52 libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root    383336 Aug 15  2015 libcudart.so.7.5.18
-rw-r--r-- 1 root root    720192 Aug 15  2015 libcudart_static.a
-rwxr-xr-x 1 root root  59909104 Jun 15 20:09 libcudnn.so
-rwxr-xr-x 1 root root  59909104 Jun 15 20:09 libcudnn.so.5
-rwxr-xr-x 1 root root  59909104 Jun 15 20:09 libcudnn.so.5.0.5
lrwxrwxrwx 1 root root        17 Jun 22 03:13 libcudnn.so.6.5 -> libcudnn.so.5.0.5
-rw-r--r-- 1 root root  58775484 Jun 15 20:09 libcudnn_static.a
lrwxrwxrwx 1 root root        15 Jun 15 19:52 libcufft.so -> libcufft.so.7.5
lrwxrwxrwx 1 root root        18 Jun 15 19:52 libcufft.so.7.5 -> libcufft.so.7.5.18
-rwxr-xr-x 1 root root 111231960 Aug 15  2015 libcufft.so.7.5.18
-rw-r--r-- 1 root root 115104400 Aug 15  2015 libcufft_static.a
lrwxrwxrwx 1 root root        16 Jun 15 19:52 libcufftw.so -> libcufftw.so.7.5
lrwxrwxrwx 1 root root        19 Jun 15 19:52 libcufftw.so.7.5 -> libcufftw.so.7.5.18
-rwxr-xr-x 1 root root    447664 Aug 15  2015 libcufftw.so.7.5.18
-rw-r--r-- 1 root root     42206 Aug 15  2015 libcufftw_static.a
lrwxrwxrwx 1 root root        17 Jun 15 19:52 libcuinj64.so -> libcuinj64.so.7.5
lrwxrwxrwx 1 root root        20 Jun 15 19:52 libcuinj64.so.7.5 -> libcuinj64.so.7.5.18
-rwxr-xr-x 1 root root   5751400 Aug 15  2015 libcuinj64.so.7.5.18
-rw-r--r-- 1 root root   1649726 Aug 15  2015 libculibos.a
lrwxrwxrwx 1 root root        16 Jun 15 19:52 libcurand.so -> libcurand.so.7.5
lrwxrwxrwx 1 root root        19 Jun 15 19:52 libcurand.so.7.5 -> libcurand.so.7.5.18
-rwxr-xr-x 1 root root  51765952 Aug 15  2015 libcurand.so.7.5.18
-rw-r--r-- 1 root root  51992564 Aug 15  2015 libcurand_static.a
lrwxrwxrwx 1 root root        18 Jun 15 19:52 libcusolver.so -> libcusolver.so.7.5
lrwxrwxrwx 1 root root        21 Jun 15 19:52 libcusolver.so.7.5 -> libcusolver.so.7.5.18
-rwxr-xr-x 1 root root  37034328 Aug 15  2015 libcusolver.so.7.5.18
-rw-r--r-- 1 root root  16613348 Aug 15  2015 libcusolver_static.a
lrwxrwxrwx 1 root root        18 Jun 15 19:52 libcusparse.so -> libcusparse.so.7.5
lrwxrwxrwx 1 root root        21 Jun 15 19:52 libcusparse.so.7.5 -> libcusparse.so.7.5.18
-rwxr-xr-x 1 root root  36816424 Aug 15  2015 libcusparse.so.7.5.18
-rw-r--r-- 1 root root  44445334 Aug 15  2015 libcusparse_static.a
lrwxrwxrwx 1 root root        14 Jun 15 19:52 libnppc.so -> libnppc.so.7.5
lrwxrwxrwx 1 root root        17 Jun 15 19:52 libnppc.so.7.5 -> libnppc.so.7.5.18
-rwxr-xr-x 1 root root    427168 Aug 15  2015 libnppc.so.7.5.18
-rw-r--r-- 1 root root     20664 Aug 15  2015 libnppc_static.a
lrwxrwxrwx 1 root root        14 Jun 15 19:52 libnppi.so -> libnppi.so.7.5
lrwxrwxrwx 1 root root        17 Jun 15 19:52 libnppi.so.7.5 -> libnppi.so.7.5.18
-rwxr-xr-x 1 root root  63516808 Aug 15  2015 libnppi.so.7.5.18
-rw-r--r-- 1 root root  90106200 Aug 15  2015 libnppi_static.a
lrwxrwxrwx 1 root root        14 Jun 15 19:52 libnpps.so -> libnpps.so.7.5
lrwxrwxrwx 1 root root        17 Jun 15 19:52 libnpps.so.7.5 -> libnpps.so.7.5.18
-rwxr-xr-x 1 root root   6047400 Aug 15  2015 libnpps.so.7.5.18
-rw-r--r-- 1 root root   8647292 Aug 15  2015 libnpps_static.a
lrwxrwxrwx 1 root root        16 Jun 15 19:52 libnvblas.so -> libnvblas.so.7.5
lrwxrwxrwx 1 root root        19 Jun 15 19:52 libnvblas.so.7.5 -> libnvblas.so.7.5.18
-rwxr-xr-x 1 root root    456112 Aug 15  2015 libnvblas.so.7.5.18
lrwxrwxrwx 1 root root        24 Jun 15 19:52 libnvrtc-builtins.so -> libnvrtc-builtins.so.7.5
lrwxrwxrwx 1 root root        27 Jun 15 19:52 libnvrtc-builtins.so.7.5 -> libnvrtc-builtins.so.7.5.18
-rwxr-xr-x 1 root root  22408512 Aug 15  2015 libnvrtc-builtins.so.7.5.18
lrwxrwxrwx 1 root root        15 Jun 15 19:52 libnvrtc.so -> libnvrtc.so.7.5
lrwxrwxrwx 1 root root        18 Jun 15 19:52 libnvrtc.so.7.5 -> libnvrtc.so.7.5.17
-rwxr-xr-x 1 root root  18199288 Aug 15  2015 libnvrtc.so.7.5.17
lrwxrwxrwx 1 root root        18 Jun 15 19:52 libnvToolsExt.so -> libnvToolsExt.so.1
lrwxrwxrwx 1 root root        22 Jun 15 19:52 libnvToolsExt.so.1 -> libnvToolsExt.so.1.0.0
-rwxr-xr-x 1 root root     37936 Aug 15  2015 libnvToolsExt.so.1.0.0
-rw-r--r-- 1 root root     25840 Aug 15  2015 libOpenCL.so
drwxr-xr-x 2 root root      4096 Jun 15 19:52 stubs

If installed from sources, provide the commit hash:
  r0.9 master
### What have you tried?
1. Transferred the tensorflow repo and the dependency repos to server, modified WORKSPACE and tensorflow/workspace.bzl
2. Built bazel-real from source code and gcc-4.9.0 from source because version of the gcc library with the server isn't compatible. 
3. Manually copied anaconda3 (with python 3.5), 
4. set customized PATH and LD_LIBRARY_PATH to use the new bazel, gcc, python etc.
5. eventually successfully build tutorials_example_trainer without GPU support
        bazel build -c opt //tensorflow/cc:tutorials_example_trainer
   and can run it without use_gpu
        bazel-bin/tensorflow/cc/tutorials_example_trainer 
6. But failed on building tutorials_example_trainer with cuda. Seems need to set PYTHONHOME. but after I didn't that, no change at all.
   
   ```
   bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
   ```

ERROR: /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/external/protobuf/BUILD:331:1: Linking of rule '@protobuf//:protoc' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/execroot/tensorflow && \
  exec env - \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/external/protobuf/protoc bazel-out/host/bin/external/protobuf/_objs/protoc/external/protobuf/src/google/protobuf/compiler/main.o bazel-out/host/bin/external/protobuf/libprotoc_lib.a bazel-out/host/bin/external/protobuf/libprotobuf.a bazel-out/host/bin/external/protobuf/libprotobuf_lite.a -lpthread -lstdc++ -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,-S -Wl,--gc-sections): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Could not find platform independent libraries <prefix>
Could not find platform dependent libraries <exec_prefix>
Consider setting $PYTHONHOME to <prefix>[:<exec_prefix>]
ImportError: No module named site
Target //tensorflow/cc:tutorials_example_trainer failed to build
INFO: Elapsed time: 22.901s, Critical Path: 17.57s
1. Failed to build :build_pip_package (without gpu support). It reported different file missed each time 

$ bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
/home/wzhan/.bazel/bin/bazel-real
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
WARNING: /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/external/protobuf/WORKSPACE:1: Workspace name in /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
WARNING: /usr/local/tf/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
WARNING: /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/external/re2/WORKSPACE:1: Workspace name in /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
INFO: Found 1 target...
ERROR: missing input file ## ### **'**@webcomponentsjs//:ShadowDOM.min.js**'.**
ERROR: /usr/local/tf/tensorflow/tensorflow/tools/pip_package/BUILD:23:1: Creating runfiles tree bazel-out/local-py3-opt/bin/tensorflow/tools/pip_package/build_pip_package.runfiles failed: build-runfiles failed: error executing command /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/execroot/tensorflow/_bin/build-runfiles ... (remaining 2 argument(s) skipped): com.google.devtools.build.lib.shell.AbnormalTerminationException: Process terminated by signal 15.
ERROR: /usr/local/tf/tensorflow/tensorflow/tools/pip_package/BUILD:23:1: //tensorflow/tools/pip_package:build_pip_package: missing input file '@webcomponentsjs//:ShadowDOM.min.js'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /usr/local/tf/tensorflow/tensorflow/tools/pip_package/BUILD:23:1 1 input file(s) do not exist.
INFO: Elapsed time: 3.593s, Critical Path: 0.08s

8 build :build_pip_package with GPU support also reports ""missing file""

$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
/home/wzhan/.bazel/bin/bazel-real
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
WARNING: /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/external/protobuf/WORKSPACE:1: Workspace name in /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
WARNING: /usr/local/tf/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
WARNING: /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/external/re2/WORKSPACE:1: Workspace name in /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
INFO: Found 1 target...
ERROR: missing input file '@grpc//:src/core/lib/support/tmpfile_win32.c'.
ERROR: /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/external/protobuf/BUILD:71:1: C++ compilation of rule '@protobuf//:protobuf_lite' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 43 argument(s) skipped): com.google.devtools.build.lib.shell.AbnormalTerminationException: Process terminated by signal 15.
ERROR: /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/external/grpc/BUILD:38:1: @grpc//:gpr: missing input file '@grpc//:src/core/lib/support/tmpfile_win32.c'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/wzhan/.cache/bazel/_bazel_wzhan/c2f4a381d5d3be272ee3353b5d3cb1aa/external/grpc/BUILD:38:1 1 input file(s) do not exist.
INFO: Elapsed time: 4.185s, Critical Path: 2.34s
"
3018,no such package '@webcomponentsjs//': Error cloning repository,"I am trying to build the r0.8 `Dockerfile.devel-gpu` image:

```
ERROR: /tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@webcomponentsjs//': Error cloning repository: https://github.com/polymer/webcomponentsjs.git: cannot open git-upload-pack caused by https://github.com/polymer/webcomponentsjs.git: cannot open git-upload-pack caused by Remote host closed connection during handshake caused by SSL peer shut down incorrectly and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
```
"
3017,how to generate image_ops.h with makefile?,"As TensorFlow v0.9.0 RC0 add makefile for better cross-platform build support (C API only), i try to compile [Image Recognition](https://www.tensorflow.org/versions/r0.9/tutorials/image_recognition/index.html) with makefile (which is compiled with bazel originally). However, it raise error that 

```
image_ops.h: No such file...
```

And I cannot find `image_ops.h` in `tensorflow/cc/ops/`. But when I compile it with Bazel, the error is gone.
### what you have tried?
1. I analysed `tensorflow/tensorflow.bzl` and `BUILD` files related and found that image_ops.h(or many others) was generated by `tensorflow/cc/ops/cc_op_gen.cc` automatically.
2. I found files which generated by`tensorflow/contrib/makefile/gen_file_lists.sh` didn't contain cc_ops_gen.cc etc. Is it not supported yet with makefile?
### My Questions:
1. how to generate image_ops.h with makefile so as to compile [Image Recongnition](https://www.tensorflow.org/versions/r0.9/tutorials/image_recognition/index.html) successfully.
2. Has image_ops any other lib dependencies?
"
3012,Conv3d_transpose in TensorFlow,"Feature request: Would it be possible to provide a conv3d_transpose, analogous to conv2d_transpose?
"
3009,FIFOQueue: dequeue many operation very slow?,"When training a relatively simple model (1-layer LSTM, 256 units) my Titan X GPU keeps spiking from 0% to 30% GPU utilization. Conclusion: somewhere in the pipeline there is a bottleneck which limits the GPU to be processing the training batches continuously. I use a FIFOQueue to which examples are being fed in one or more separate threads:

``` python
queue = tf.FIFOQueue(
     capacity=self.config.queue_capacity,
     dtypes=[tf.float32, tf.float32],
     shapes=[[30, 49, 512], [30]],
     name=""FIFOQueue""
)
```

For the training operation I use `queue.dequeue_many` to get examples from the queue. As you can see the batch size is 64 examples. So in the end the input tensor is `64x30x49x512` of type `tf.float32`:

``` python
# Model inputs, either use the queue (training) or feed_dict (evaluation)
inputs, targets = queue.dequeue_many(64)
```

To find out why my code is running ""slow"" (i.e. spiking GPU allocation and no temperature increase) I use the `Timeline` object ([see here](http://stackoverflow.com/questions/34293714/tensorflow-can-i-measure-the-execution-time-of-individual-operations)) to measure execution times of individual operations. The results displayed below show the measurements for one training iteration at which point the queue was filled with more than 1000 examples. I have included screenshots for both GPU and CPU-only runs (forced with `export CUDA_VISIBLE_DEVICES=-1`. 

What strikes me from these results is that it takes a really long time to dequeue examples from the FIFOQueue. What is happening here...something wrong or is the dequeuing operation just very slow? Overall the dequeuing operation and sending the data to the GPU takes up half of the time of a training iteration. No wonder that the GPU utilization is spiking. Any help is welcome optimizing my training pipeline! As I understand correctly the examples are all queued in RAM, is there also a way to queue them ahead on GPU memory so when they are needed they do not have to be moved CPU => GPU?

This is tested on TensorFlow v9.0 build from sources about 1.5 week ago.

**GPU running on Titan X**
![gpu](http://i.imgur.com/eTZNPDM.png?1) 

**CPU running on Xeon CPU E5-2640**
![cpu](http://i.imgur.com/mQkLH8h.png?1)
"
3008,NotImplementedError for learn.TensorFlowEstimator.restore,"I had saved a model using tensorflow.contrib.learn and am currently trying to restore it. However, I am getting a `NotImplementedError`.

```
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
<ipython-input-9-2a884c20d327> in <module>()
----> 1 gender_classifier = learn.TensorFlowEstimator.restore('gender_classifier_model/')

/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.pyc in restore(cls, path, config)
    336       custom_estimator = TensorFlowEstimator(model_fn=None, **model_def)
    337       # pylint: disable=protected-access
--> 338       custom_estimator._restore(path)
    339       return custom_estimator
    340 

/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.pyc in _restore(self, path)
    295       path: Path to checkpoints and other information.
    296     """"""
--> 297     raise NotImplementedError
    298 
    299   @classmethod
```

I realized that this is indeed not implemented in the [latest commit](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/base.py).

Until this is implemented, are there any workarounds? I tried pickling the model but was not able to do so, as it is a Module object.
"
3007,Tensorflow with ubuntu 16.04 doesn't work,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: None
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide: NA
1. Which pip package you installed. NA
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. 

If installed from sources, provide the commit hash:
### Steps to reproduce
1. I change the Dockerfile that you have provided to get ubuntu 16.04. i.e. FROM ubuntu:14.04 -> ubuntu:16.04
2. Also changed to git checkout to 0.9
3. It was for CPU only, so nothing else has changed regarding GPU setting.
### What have you tried?
1. I change the version back to 14.04, which worked flawlessly.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

Would you let me know if you provide tensorflow Dockerfile for ubuntu 16.04? Soon, I will connect this to Nvidia-docker as well and NVIDIA already provides the ubuntu 16.04 support.
"
3006,TensorBoard doesn't display Events under Safari,"I've been attempting to view events in TensorBoard, using both the mnist_with_summaries.py tutorial, and a much simpler example from the ""Hello, TensorFlow!"" article (example code at the bottom of this page: https://www.oreilly.com/learning/hello-tensorflow). In both cases, I can see the Graph, but nothing under Events.
### Environment info

Operating System: OSX 10.11.5
Running Python 3.5.1 (installed from the DMG installer on python.org)
Installed tensorflow 0.9.0rc0 via pip3
### Steps to reproduce
1. Paste the following code into a file:

``` python
import tensorflow as tf

x = tf.constant(1.0, name='input')
w = tf.Variable(0.8, name='weight')
y = tf.mul(w, x, name='output')
y_ = tf.constant(0.0, name='correct_value')
loss = tf.pow(y - y_, 2, name='loss')
train_step = tf.train.GradientDescentOptimizer(0.025).minimize(loss)

for value in [x, w, y, y_, loss]:
    tf.scalar_summary(value.op.name, value)

summaries = tf.merge_all_summaries()

sess = tf.Session()
summary_writer = tf.train.SummaryWriter('log_simple_stats', sess.graph)

sess.run(tf.initialize_all_variables())
for i in range(100):
    summary_writer.add_summary(sess.run(summaries), i)
    sess.run(train_step)
```
1. Run the code, then after it is complete, run ""tensorboard --logdir=log_simple_stats/""
2. Go to localhost:6006, under Events, there are no Runs listed.
   ### What have you tried?
3. Adding a flush() call to the summary writer
4. Copying the css and js directories under tensorboard/lib, from source (this had no effect, so I reverted the change)
### Logs or other output that would be helpful

The log output looks like:
Looking in log_simple_stats reveals:

``` bash
-rw-r--r--  1 jason  staff  19030 Jun 23 01:11 events.out.tfevents.1466669497.hostname.local
MD5 (events.out.tfevents.1466669497.hostname.local) = f7032e6e643bbac6b0009411a02cb8db
```

And the logs from tensorboard:

``` bash
~ tensorboard --logdir=log_simple_stats/
WARNING:tensorflow:Found more than one graph event per run. Overwriting the graph with the newest event.
WARNING:tensorflow:IOError [Errno 2] No such file or directory: '/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/tensorboard/TAG' on path /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/tensorboard/TAG
WARNING:tensorflow:Unable to read TensorBoard tag
Starting TensorBoard  on port 6006
(You can navigate to http://0.0.0.0:6006)
127.0.0.1 - - [23/Jun/2016 01:11:11] ""GET / HTTP/1.1"" 200 -
127.0.0.1 - - [23/Jun/2016 01:11:11] ""GET /lib/css/global.css HTTP/1.1"" 200 -
127.0.0.1 - - [23/Jun/2016 01:11:11] ""GET /external/d3/d3.min.js HTTP/1.1"" 200 -
127.0.0.1 - - [23/Jun/2016 01:11:11] ""GET /external/lodash/lodash.min.js HTTP/1.1"" 200 -
...
```
"
3005,Tensorflow Variables Copy Issue,"I am using Tensorflow 0.8 to train the Deep Neural Networks. Currently, I encounter an issue that I want to define two exact same Neural Networks N1 and N2, and I train N1, during the training loop, I copy updated weights from N1 to N2 every 4 iterations. In fact, I know there is way using `tf.train.saver.save()` to save all N1 weights into a `.ckpt` file on Disk, and using `tf.train.saver.restore()` to load those weights from `.ckpt` file, which is equivalent to the copy functionality. However, this load/reload will impact the training speed, and I wonder if there are other more efficient ways to do the copy (For example, do in-memory copy, etc.). Thanks!
"
3004,[iOS] Undefined symbols for architecture armv7 Error,"While following the iOS readme installation instructions, the framework didn't compile for iOS. Below are the details.

Operating System: OS X El Capitan 10.11.5
pip package: Mac OS X, CPU only, Python 2.7
TensorFlow version: 0.9.0rc0
### Steps

1.

``` bash
sh tensorflow/contrib/makefile/download_dependencies.sh
```

2.

``` bash
cd tensorflow/contrib/makefile/downloads/protobuf/
./autogen.sh
./configure
make
sudo make install
cd ../../../../..
```
1. `sh tensorflow/contrib/makefile/compile_ios_protobuf.sh`
2. `sh tensorflow/contrib/makefile/compile_ios_tensorflow.sh`
### Log showing error

```
Undefined symbols for architecture armv7:
  ""tensorflow::shape_inference::UnchangedShape(tensorflow::shape_inference::InferenceContext*)"", referenced from:
      ___cxx_global_var_init.17 in libtensorflow-core-armv7.a(math_ops.o)
      ___cxx_global_var_init.24 in libtensorflow-core-armv7.a(math_ops.o)
      ___cxx_global_var_init.27 in libtensorflow-core-armv7.a(math_ops.o)
      ___cxx_global_var_init.31 in libtensorflow-core-armv7.a(math_ops.o)
      ___cxx_global_var_init.37 in libtensorflow-core-armv7.a(math_ops.o)
      ___cxx_global_var_init.41 in libtensorflow-core-armv7.a(math_ops.o)
      ___cxx_global_var_init.44 in libtensorflow-core-armv7.a(math_ops.o)
      ...
ld: symbol(s) not found for architecture armv7
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *** [/Users/Main/Documents/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark] Error 1
armv7 compilation failed.
```
"
3002,google.protobuf.message.DecodeError: Truncated message,"I retrained a Inception model using my data and saved the label txt and pd file. I tried to run @wolffg 
code lab file to load my trained network on my Raspberry Pi and test on another image. But I got this error below:
pi@raspberrypi:~/robotimages $ python retrain_test.py /home/pi/robotimages/Robot1/w/1.jpg
Traceback (most recent call last):
  File ""retrain_test.py"", line 15, in <module>
    graph_def.ParseFromString(f.read())
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/message.py"", line 185, in ParseFromString
    self.MergeFromString(serialized)
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/internal/python_message.py"", line 1091, in MergeFromString
    if self._InternalParse(serialized, 0, length) != length:
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/internal/python_message.py"", line 1127, in InternalParse
    pos = field_decoder(buffer, new_pos, end, self, field_dict)
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/internal/decoder.py"", line 610, in DecodeRepeatedField
    raise _DecodeError('Truncated message.')
google.protobuf.message.DecodeError: Truncated message.
pi@raspberrypi:~/robotimages $ 
"
3001,Use Basic neural network subroutines (BNNS) on iOS,"Take advantage of the [BNNS library that Apple announced for iOS](https://developer.apple.com/reference/accelerate/1912851-bnns).
"
3000,Memory Leak Converting Numpy ndarry to Tensor,"I'm working on a small convolution network to identify faces which takes png images and loads them into numpy arrays through PIL.  Once all the images are loaded, they are passed into the tensorflow model through `train_op.train(feed_dict={input:train_images})`.  The problem is that each iteration of the training loop copies a new batch from the total loaded images before passing the batch into train_op and that memory is never released.

I've looked and looked and found several related issues to memory not being released but nothing that I thought really fit my problem or had a working solution.  I am aware that this process of pre-loading images is not ideal, but I have other obstacles to using a queue structure to read the images directly to tensors and I would like to address this as a memory leak.
### Environment info

Operating System: Ubuntu 14.04
Python: 2.7.6
Tensorflow: 0.8.0
CUDA: 7.5
cuDNN: 4.0.7
### Steps to reproduce

Below is a short python script that replicates the problem by loading an image (pass a filepath as argument) and passing it to `tf.image.random_flip_left_right()` while printing out the memory in use by on the computer.  

```
import tensorflow as tf
import psutil
import numpy as np
import Image
import sys
import gc

def printMemUsed(discript):
    print(""%s:\t%d"" % (discript, psutil.virtual_memory().used))

def main(file):
    sess = tf.InteractiveSession()
    im = Image.open(file)
    arr = np.array(im)
    printMemUsed(""After Array Creation"")
    arr = flipArr(arr)
    printMemUsed(""After Tensor Conversion"")
    del arr
    printMemUsed(""After Array Deletion"")

def flipArr(arr):
    tensor = tf.image.random_flip_left_right(arr)
    arr = tensor.eval()
    return arr  

if __name__ == '__main__':
    main(sys.argv[1])
    printMemUsed(""After Scope Lost"")
    gc.collect()
    printMemUsed(""After gc Collect"")
```

For me this program prints:

> After Array Creation:   1196838912
> After Tensor Conversion:        1273106432
> After Array Deletion:   1273106432
> After Scope Lost:       1273106432
> After gc Collect:       1273106432
### What have you tried?
1. As shown in the example, gc.collect() and del do nothing to free the memory, it is not released when the variables pass out of scope (loop or method), only when the program exits, or in my case when I run out of RAM causing the machine to hang until manually restarted.
2. Again I recognize that there are other (perhaps better) ways to get images into tensorflow, but at least for the start I'd like to address why the memory is not released.
### Other Comments

The plot below shows memory usage over the first 5 training rounds of my full model.  The orange points mark the top of each loop.  The first jump is the creation of the batch, which passes all the images through `tf.image.random_flip_left_right()` as in the example above, the second jump from calling `train_op.train(feed_dict={input:train_images})`, passing in the newly created batch.

![memory_leak_plot](https://cloud.githubusercontent.com/assets/10762452/16284315/75e71fec-3885-11e6-915e-a6d9f6610119.png)
"
2999,Problem in  restore a previously saved model,"I used tensorflow 0.9. I want save my model to be reused with that, I simply add tf.train.save() to save and restore my training variables.

This is my code:

```
`import tensorflow as tf
import input_data
import os

checkpoint_dir='./ckpt_dir/'

mnist = input_data.read_data_sets(""MNIST_data"", one_hot = True)

x = tf.placeholder(tf.float32, shape = [None , 784])
y_ = tf.placeholder(tf.float32, [None, 10])

sess = tf.InteractiveSession()

def load_model(sess, saver, checkpoint_dir ):

ckpt = tf.train.get_checkpoint_state(checkpoint_dir)
if ckpt and ckpt.model_checkpoint_path:
print(ckpt.model_checkpoint_path)

saver.restore(sess, ckpt.model_checkpoint_path)

else:
if not os.path.exists(checkpoint_dir):
os.makedirs(checkpoint_dir)
sess.run(init)
return

def weight_variable(shape):
initial = tf.truncated_normal(shape, stddev = 0.1)
return tf.Variable(initial)

def bias_variable(shape):
initial = tf.constant(0.1, shape= shape)
return tf.Variable(initial)

def conv2d(x, W):
return tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = ""SAME"")

def max_pool_2x2(x):
return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1],
padding = ""SAME"")

W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])

x_image = tf.reshape(x, [-1, 28, 28, 1])

#
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1))
h_pool1 = max_pool_2x2(h_conv1)

#
W_conv2 = weight_variable([5, 5, 32, 64])
b_conv2 = bias_variable([64])

h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2))
h_pool2 = max_pool_2x2(h_conv2)

W_fc1 = weight_variable([7764, 1024])
b_fc1 = bias_variable([1024])

h_pool2_flat = tf.reshape(h_pool2, [-1, 7764])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)

#
keep_prob = tf.placeholder(tf.float32)
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)

#
W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])

y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) +b_fc2)

#
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices = [1]))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)

correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

init = tf.initialize_all_variables()

saver = tf.train.Saver()

load_model(sess, saver, checkpoint_dir)

for i in range(1):
batch = mnist.train.next_batch(50)
if i%10 == 0:
train_accuracy = accuracy.eval(feed_dict = {x : batch[0] , y_ : batch[1], keep_prob : 1.0})
print(""step %d, training accuracy %g""%(i, train_accuracy))

train_step.run(feed_dict = {x : batch[0], y_ : batch[1], keep_prob : 0.5})
print(""test accuracy %g""%accuracy.eval(feed_dict={
x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))

tf.scalar_summary(""accuracy"", accuracy)

saver.save(sess,checkpoint_dir+'model.ckpt')`
```

When I restore the checkpoint:

`saver.restore(sess, ckpt.model_checkpoint_path)`

then arises this error:

```
Traceback (most recent call last):
.
.
.
NotFoundError: Tensor name ""global_step_7"" not found in checkpoint files ./ckpt_dir/model.ckpt-0
[[Node: save_18/restore_slice_438 = RestoreSlicedt=DT_INT32, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""]]
Caused by op 'save_18/restore_slice_438', defined at:
File ""/home/m/anaconda3/lib/python3.5/site-packages/spyderlib/widgets/externalshell/start_ipython_kernel.py"", line 205, in
ipythonkernel.start()
.
.
.
File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1224, in __init
raise TypeError(""Control input must be an Operation, ""
```

How can I solve this problem?
"
2996,tf.reduce_sum(a) is slow,"For large vectors, cost of `tf.reduce_sum(a)` is dominated by cost of `range` that's called to construct list of reduction indices.

Summing up 10k elements 1500 times, I get about 0.8 seconds spent in `_sum` while 2 seconds is spent in `range`. Also, transferring all those indices to sum probably slows things down. This only happens when static graph optimizations don't apply. Will update with reproducible benchmark in a bit
"
2995,Multiple (Bidirectional)LSTM layers leads to nan in loss when time step is large,"I've tried to implement a deep LSTM network and tested it on an autoencoder task in recovering audio magnitude spectrogram. At first I set the number of frames in spectrogram (i.e. time step in LSTM) to be small, and both LSTM and BLSTM worked well. However, when the time step is large, both LSTM and BLSTM began to generate nan loss. To be more specific, when I used a time step of 20 frames, BLSTM worked well with 4 layers and can successfully recover the input; but when I increased it to 100, a 3 layer BLSTM network began to generate nan in two training steps.

I think there might be some problem within the code for `rnn` and `bidirectional_rnn` function (maybe due to unrolling?), but I'm not sure if I did anything wrong.

The codes for (B)LSTM I use are:

``` python
def LSTM(lstm_hidden, batch_size, X, chunk_size, name='LSTM', seq_len=None):
    initializer = tf.random_uniform_initializer(-1, 1)

    cell = tf.nn.rnn_cell.LSTMCell(lstm_hidden, initializer=initializer, 
                                   use_peepholes=True, state_is_tuple=True)

    initial_state = cell.zero_state(batch_size, tf.float32)

    if seq_len is not None:     
        output, _ = tf.nn.rnn(cell, X, initial_state=initial_state,
                                             sequence_length=seq_len, scope=name)
    else:
        output, _ = tf.nn.rnn(cell, X, initial_state=initial_state, scope=name)

    return output
```

``` python
def BLSTM(lstm_hidden, batch_size, X, chunk_size, name='BLSTM', seq_len=None):
    initializer = tf.random_uniform_initializer(-1, 1)

    cell_fw = tf.nn.rnn_cell.LSTMCell(lstm_hidden, initializer=initializer, 
                                      use_peepholes=True, state_is_tuple=True)
    cell_bw = tf.nn.rnn_cell.LSTMCell(lstm_hidden, initializer=initializer, 
                                      use_peepholes=True, state_is_tuple=True)

    # initial states
    initial_state_fw = cell_fw.zero_state(batch_size, tf.float32)
    initial_state_bw = cell_bw.zero_state(batch_size, tf.float32)

    # BLSTM
    if seq_len is not None:     
        output, _, _ = tf.nn.bidirectional_rnn(cell_fw, cell_bw, X, 
                                               initial_state_fw=initial_state_fw,
                                               initial_state_bw=initial_state_bw, 
                                               sequence_length=seq_len, 
                                               scope=name)

    else:
        output, _, _ = tf.nn.bidirectional_rnn(cell_fw, cell_bw, X, 
                                               initial_state_fw=initial_state_fw,
                                               initial_state_bw=initial_state_bw, 
                                               scope=name)
    return output
```

and the loss function is the L2-loss between the recovered magnitude spectrogram and the input, so there might not be a divide-by-zero problem (anyway it works well when time step is small, so I think it's not due to the loss function).
### Environment info

Operating System: Ubuntu 14.04.3
Python version: 2.7.6
Tensorflow version: r0.9
CUDA version: 7.5
"
2994,cifar10_multi_gpu_train.py - unintended loss reporting,"# cifar10_multi_gpu_train.py

At this [line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L180), every loss for each tower in the multi GPU is calculated

However, these losses are not averaged, and it seems like the loss from the last GPU is used to return [loss](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L246).

Is this on purpose (if yes, why?) or is it a bug in the code?
"
2991,Error running tf.nn.atrous_conv2d on TF 0.9.0rc0,"Getting error running tf.nn.atrous_conv2d on TensorFlow 0.9.0rc0. The same code runs successfully on TensorFlow 0.8.0 installed from the source.
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN:  None

If installed from binary pip package, provide:
1. https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0rc0-cp35-cp35m-linux_x86_64.whl
2. 0.9.0rc0
### Steps to reproduce
1. Install TF from the package
2. Call tf.nn.atrous_conv2d from the client code (see code here - https://github.com/nmayorov/ufcnn/blob/master/ufcnn/ufcnn.py)
3. Get TypeError: **int** returned non-int (type NoneType)
### What have you tried?
1. Installation of 0.8.0 from the source helps
### Logs or other output that would be helpful

Traceback (most recent call last):
  File ""UFCNN_functional.py"", line 2050, in <module>
    x, y_hat, *_ = construct_ufcnn(n_inputs=2, n_outputs=y_train.shape[2], n_levels=4, n_filters=150)
  File ""/notebook/UFCNN/ufcnn/ufcnn/ufcnn.py"", line 227, in construct_ufcnn
    x = tf.nn.relu(conv(x, w, b, filter_length, dilation))
  File ""/notebook/UFCNN/ufcnn/ufcnn/ufcnn.py"", line 15, in conv
    x = tf.nn.atrous_conv2d(x, w, dilation, padding='VALID')
  File ""/root/miniconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py"", line 169, in atrous_conv2d
    in_width = int(value_shape[2])
TypeError: **int** returned non-int (type NoneType)
"
2990,inconsistent variable initialization behavior for callables / ops,"When a variable is initialized with a callable, running the initializer of the variable has no effect after it is run once:

``` python
import tensorflow as tf
import scipy

session = tf.InteractiveSession()
retrand = lambda: scipy.random.random(size=[2,2])
var = tf.Variable(retrand, dtype=tf.float32)
session.run(var.initializer)
var.eval()
# prints array([[ 0.73060566,  0.26469722],
#               [ 0.63376802,  0.64898247]], dtype=float32)
session.run(var.initializer)
var.eval()
# prints array([[ 0.73060566,  0.26469722],
#              [ 0.63376802,  0.64898247]], dtype=float32)
# (same as first call)
```

If a variable is initialized with a tensorflow init op, then rerunning the initializer changes the variable state:

``` python
var = tf.Variable(tf.random_normal([2,2]))
session.run(var.initializer)
var.eval()
#prints 
#array([[ 0.61732173,  0.14423341],
#       [ 0.3965871 , -0.98214936]], dtype=float32)
session.run(var.initializer)
var.eval()
# prints 
# array([[ 0.48240849,  0.26547143],
#      [ 1.18776596, -0.12901327]], dtype=float32)
```

Why do variables initialized with a callable only call the callable once, even if they are initialized repeatedly, when variables initialized with an init op rerun the op on each run of the initializer? Is there any way to have a variable initialized with a callable call it each time the variable's initializer is run?
### Environment info

Operating System:  Mac OSX
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): None
If installed from binary pip package, provide: 
1. Which pip package you installed.
https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0rc0-py2-none-any.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.9.0rc0
"
2989,Import pre-trained model to MATLAB?,"Hi,

I am training my own CNN model using tensorflow.

I wonder if there is a way to import a (pre-)trained model (in tensorflow format, .ckpt) into MATLAB/Simulink or Caffe?

Thank you in advance.
"
2987,Random slow downs during training.,"Usually the speed of each training batch is somewhat consistent for me when using tensorflow.  However, I am currently training an RNN.  For the first 3 epochs each batch of 128 samples took about 1 second.  Now on the third epoch my times have become inconsistent.  The batches will randomly become very slow.  I can hear the fan on my GTX Titian spin down indicating that during these slowdowns it is not using the compute resources on the GPU.  

I am timing it like this so I don't think anything else in my code could be affecting it.

```
            begin_time = time.time()
            loss, ts = sess.run([cost, train_step], feed_dict = {input_tensor: x_train, expected_output: y_train, keep_prob: 0.8})
            end_time = time.time()
```

Here is the output with timing information.

```
Epoch 3        Batch 858      Loss 172.072438250   Last Loss 206.985626221   Time 1.432 
Epoch 3        Batch 859      Loss 172.067967827   Last Loss 168.227874756   Time 1.419 
Epoch 3        Batch 860      Loss 172.057925642   Last Loss 163.421646118   Time 1.447 
Epoch 3        Batch 861      Loss 172.056937587   Last Loss 171.206222534   Time 1.339 
Epoch 3        Batch 862      Loss 172.051488565   Last Loss 167.354431152   Time 1.285 
Epoch 3        Batch 863      Loss 172.016926642   Last Loss 142.189987183   Time 1.310 
Epoch 3        Batch 864      Loss 172.011091517   Last Loss 166.969543457   Time 1.291 
Epoch 3        Batch 865      Loss 172.011779468   Last Loss 172.606857300   Time 1.317 
Epoch 3        Batch 866      Loss 172.004100742   Last Loss 165.354324341   Time 1.307 
Epoch 3        Batch 867      Loss 172.008801860   Last Loss 176.084671021   Time 1.372 
Epoch 3        Batch 868      Loss 172.032961320   Last Loss 193.003372192   Time 1.298 
Epoch 3        Batch 869      Loss 172.036121868   Last Loss 174.782638550   Time 1.310 
Epoch 3        Batch 870      Loss 172.044807513   Last Loss 179.601318359   Time 1.429 
Epoch 3        Batch 871      Loss 172.066208551   Last Loss 190.706512451   Time 1.311 
Epoch 3        Batch 872      Loss 172.052568940   Last Loss 160.158828735   Time 2.614 
Epoch 3        Batch 873      Loss 172.032694941   Last Loss 154.682693481   Time 2.208 
Epoch 3        Batch 874      Loss 172.040674805   Last Loss 179.015075684   Time 3.138 
Epoch 3        Batch 875      Loss 172.034015673   Last Loss 166.207275391   Time 1.750 
Epoch 3        Batch 876      Loss 172.029174909   Last Loss 167.788665771   Time 1.955 
Epoch 3        Batch 877      Loss 172.042762183   Last Loss 183.958801270   Time 2.576 
Epoch 3        Batch 878      Loss 172.028727179   Last Loss 159.705993652   Time 3.130 
Epoch 3        Batch 879      Loss 172.035255710   Last Loss 177.773834229   Time 2.622 
Epoch 3        Batch 880      Loss 172.043415273   Last Loss 179.223831177   Time 1.581 
Epoch 3        Batch 881      Loss 172.040243793   Last Loss 169.246170044   Time 3.093 
Epoch 3        Batch 882      Loss 172.017778805   Last Loss 152.203659058   Time 2.470 
Epoch 3        Batch 883      Loss 172.018503957   Last Loss 172.658813477   Time 2.540 
Epoch 3        Batch 884      Loss 172.054275064   Last Loss 203.675933838   Time 2.597 
Epoch 3        Batch 885      Loss 172.029123448   Last Loss 149.769943237   Time 2.915 
Epoch 3        Batch 886      Loss 172.013957027   Last Loss 158.576507568   Time 3.095 
Epoch 3        Batch 887      Loss 171.994215424   Last Loss 154.483413696   Time 2.250 
Epoch 3        Batch 888      Loss 171.998252946   Last Loss 175.583572388   Time 2.997 
Epoch 3        Batch 889      Loss 171.974352959   Last Loss 150.727264404   Time 3.417 
Epoch 3        Batch 890      Loss 171.968166587   Last Loss 166.462295532   Time 2.290 
Epoch 3        Batch 891      Loss 172.011782095   Last Loss 210.873199463   Time 1.358 
Epoch 3        Batch 892      Loss 172.013166695   Last Loss 173.248229980   Time 0.910 
Epoch 3        Batch 893      Loss 172.016952293   Last Loss 175.397491455   Time 0.893 
Epoch 3        Batch 894      Loss 172.015184030   Last Loss 170.434356689   Time 0.986 
Epoch 3        Batch 895      Loss 172.001527531   Last Loss 159.778961182   Time 1.000 
Epoch 3        Batch 896      Loss 172.008338426   Last Loss 178.110900879   Time 0.999 
Epoch 3        Batch 897      Loss 172.015577083   Last Loss 178.508651733   Time 1.699 
Epoch 3        Batch 898      Loss 172.076713689   Last Loss 226.977386475   Time 1.570 
Epoch 3        Batch 899      Loss 172.043461711   Last Loss 142.149932861   Time 1.699 
Epoch 3        Batch 900      Loss 172.069320933   Last Loss 195.342620850   Time 1.678 
Epoch 3        Batch 901      Loss 172.063626562   Last Loss 166.932998657   Time 1.685 
Epoch 3        Batch 902      Loss 172.060249506   Last Loss 169.014144897   Time 1.467 
Epoch 3        Batch 903      Loss 172.068654811   Last Loss 179.658645630   Time 3.737 
Epoch 3        Batch 904      Loss 172.061790508   Last Loss 165.856460571   Time 3.705 
Epoch 3        Batch 905      Loss 172.078748707   Last Loss 187.425918579   Time 3.376 
Epoch 3        Batch 906      Loss 172.065538518   Last Loss 160.097106934   Time 4.606 
Epoch 3        Batch 907      Loss 172.040349112   Last Loss 149.193557739   Time 4.513 
Epoch 3        Batch 908      Loss 172.078197416   Last Loss 206.444458008   Time 2.491 
Epoch 3        Batch 909      Loss 172.081030156   Last Loss 174.655990601   Time 4.244 
```

Here is what the output normally looks like most of the time when this issue is not occurring.

```
Epoch 1        Batch 213      Loss 262.820208541   Last Loss 189.761398315   Time 0.978 
Epoch 1        Batch 214      Loss 262.570083973   Last Loss 209.043426514   Time 0.984 
Epoch 1        Batch 215      Loss 262.265294534   Last Loss 196.735565186   Time 0.985 
Epoch 1        Batch 216      Loss 261.973181588   Last Loss 198.876785278   Time 0.988 
Epoch 1        Batch 217      Loss 261.685996729   Last Loss 199.366882324   Time 0.989 
Epoch 1        Batch 218      Loss 261.385472058   Last Loss 195.871093750   Time 0.981 
Epoch 1        Batch 219      Loss 261.200773135   Last Loss 220.751708984   Time 0.983 
Epoch 1        Batch 220      Loss 260.912834202   Last Loss 197.566268921   Time 0.982 
Epoch 1        Batch 221      Loss 260.757691254   Last Loss 226.471099854   Time 0.981 
Epoch 1        Batch 222      Loss 260.588221186   Last Loss 222.965866089   Time 0.984 
Epoch 1        Batch 223      Loss 260.272108146   Last Loss 189.778900146   Time 0.992 
Epoch 1        Batch 224      Loss 259.962260607   Last Loss 190.556411743   Time 0.981 
Epoch 1        Batch 225      Loss 259.509933337   Last Loss 157.736297607   Time 0.985 
Epoch 1        Batch 226      Loss 259.273305347   Last Loss 205.795379639   Time 0.982 
Epoch 1        Batch 227      Loss 259.062388972   Last Loss 211.184371948   Time 0.991 
Epoch 1        Batch 228      Loss 258.901376783   Last Loss 222.190597534   Time 0.984 
Epoch 1        Batch 229      Loss 258.643836975   Last Loss 199.667221069   Time 0.986 
Epoch 1        Batch 230      Loss 258.344224079   Last Loss 189.433258057   Time 0.979 

```

After a while it will make it through the slow phase and return to being 1s per batch.  I am using Ubuntu 16.04 with CUDNN 5 and Cuda 8.  This problem is intermittent and I have no real way to reproduce it.
"
2986,ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory,"- GPU: GTX 1080
- GPU driver: 367.27
- OS: Ubuntu 16.04
- CUDA: 8.0 rc
- cudnn: 8.0

When I`import tensorflow`I got the error in the header. Looks like tensorflow doesn't support one (or more) or those?
"
2984,Multiple Towers Not Applying Updates,"### Environment info

All 4 machines: 4.1.13-100.fc21.x86_64

Setting 1:
1 machine with 1x 960 GTX (one of the workers from below)

Setting 2:
1 machine with cpu (parameter server)
3 machines with 1x 960 GTX (worker)

tensorflow 0.9.0, cudNN v4
### Problem

I can train a mnist example on both settings while using the same input pipeline as in the following scripts.

The following two scripts are almost identical but one is made to work on Setting 1 while the other one is made for Setting 2 to work in a distributed, parameter sharing, data parallelism manner. The scripts operates on a small set with coin images with 2 classes.

Single Machine Script (Setting 1): https://gist.github.com/ischlag/96b10519a45727bd17fe0cce01c1bd15
Distributed Script (Setting 2): https://gist.github.com/ischlag/d9fc4429971ce7c1957798de30c56372

The Single machine script works as expected and can generalize well:
'''
Session started!
Partial-Epoch Avg Error:  0.692565  AvgMsPerBatch: 0.56 ms
Partial-Epoch Avg Error:  0.686972  AvgMsPerBatch: 0.49 ms
Partial-Epoch Avg Error:  0.671962  AvgMsPerBatch: 0.46 ms
Partial-Epoch Avg Error:  0.645295  AvgMsPerBatch: 0.47 ms
Partial-Epoch Avg Error:  0.59795  AvgMsPerBatch: 0.47 ms
Partial-Epoch Avg Error:  0.607252  AvgMsPerBatch: 0.47 ms
Partial-Epoch Avg Error:  0.548216  AvgMsPerBatch: 0.49 ms
Partial-Epoch Avg Error:  0.5107  AvgMsPerBatch: 0.49 ms
Partial-Epoch Avg Error:  0.492883  AvgMsPerBatch: 0.47 ms
Partial-Epoch Avg Error:  0.466268  AvgMsPerBatch: 0.48 ms
Partial-Epoch Avg Error:  0.431923  AvgMsPerBatch: 0.49 ms
Partial-Epoch Avg Error:  0.407919  AvgMsPerBatch: 0.48 ms
Partial-Epoch Avg Error:  0.387163  AvgMsPerBatch: 0.47 ms
Partial-Epoch Avg Error:  0.340534  AvgMsPerBatch: 0.47 ms
Partial-Epoch Avg Error:  0.349155  AvgMsPerBatch: 0.47 ms
Partial-Epoch Avg Error:  0.327694  AvgMsPerBatch: 0.47 ms
Partial-Epoch Avg Error:  0.244313  AvgMsPerBatch: 0.46 ms
Partial-Epoch Avg Error:  0.256759  AvgMsPerBatch: 0.46 ms
Partial-Epoch Avg Error:  0.206276  AvgMsPerBatch: 0.46 ms
Partial-Epoch Avg Error:  0.184809  AvgMsPerBatch: 0.46 ms
Partial-Epoch Avg Error:  0.187335  AvgMsPerBatch: 0.46 ms
'''
The distributed script is quite slower and fails to update the parameters.
''' 
Session started!
Partial-Epoch Avg Error:  0.69339  AvgMsPerBatch: 3.25 ms
Partial-Epoch Avg Error:  0.692113  AvgMsPerBatch: 3.27 ms
Partial-Epoch Avg Error:  0.693958  AvgMsPerBatch: 3.27 ms
Partial-Epoch Avg Error:  0.688354  AvgMsPerBatch: 3.26 ms
Partial-Epoch Avg Error:  0.692994  AvgMsPerBatch: 3.25 ms
Partial-Epoch Avg Error:  0.692903  AvgMsPerBatch: 3.24 ms
Partial-Epoch Avg Error:  0.691708  AvgMsPerBatch: 3.29 ms
Partial-Epoch Avg Error:  0.691477  AvgMsPerBatch: 3.35 ms
Partial-Epoch Avg Error:  0.69129  AvgMsPerBatch: 3.37 ms
Partial-Epoch Avg Error:  0.691391  AvgMsPerBatch: 3.35 ms
Partial-Epoch Avg Error:  0.691415  AvgMsPerBatch: 3.30 ms
Partial-Epoch Avg Error:  0.69209  AvgMsPerBatch: 3.30 ms
Partial-Epoch Avg Error:  0.691746  AvgMsPerBatch: 3.32 ms
Partial-Epoch Avg Error:  0.690423  AvgMsPerBatch: 3.31 ms
Partial-Epoch Avg Error:  0.692738  AvgMsPerBatch: 3.30 ms
''' 

The same distributed script works well with the mnist dataset in a distributed manner. All the lines necessary to run it with mnist are there but commented out.

Why is my distributed script not working in this case?
"
2983,Multiple CPU usage ineffective: CPU utilization only 200% on a 8 core VM,"This is the same as #583. Opening a new issue since CPU utilization is still low. I built tensorflow with `-mavx2` flag and ran `examples/tutorials/word2vec/word2vec_basic.py`. TensorFlow is recognizing num of cores as 8, yet still only 200% of CPU is used during training.
### Environment info

Operating System:
14.04.1-Ubuntu x86_64 GNU/Linux

Installed version of CUDA and cuDNN: 
No CUDA or cuDNN installed.

If installed from sources, provide the commit hash:
Commit hash:

```
840c4ac
a2d6cf7
5b66275
27b83b7
b77f607
ce330a7
2c33855
451f18c
af794ed
921b709
```
### Steps to reproduce
1. Enable logging of `inter_op_parallelism_threads` and `intra_op_parallelism_threads`.
2. Configure, build tensorflow with AVX2 with this command
   `bazel build -c opt --copt=-mavx2 //tensorflow/tools/pip_package:build_pip_package`
3. Build wheel, install package and run `python examples/tutorials/word2vec/word2vec_basic.py`.
"
2980,"Setting CUDA_VISIBLE_DEVICES="""" crashes TensorFlow on Mac","Something changed in the last 3 days so thatsetting CUDA_VISIBLE_DEVICES to """" makes TensorFlow crash on Mac with SIGSERV

```
Exception Type:        EXC_BAD_ACCESS (SIGSEGV)
Exception Codes:       KERN_INVALID_ADDRESS at 0x0000000000000000
Exception Note:        EXC_CORPSE_NOTIFY

VM Regions Near 0:
--> 
    __TEXT                 0000000107d49000-0000000107d4a000 [    4K] r-x/rwx SM=COW  /System/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python

Thread 0 Crashed:: Dispatch queue: com.apple.main-thread
0   libsystem_c.dylib               0x00007fff97ebc152 strlen + 18
1   _pywrap_tensorflow.so           0x000000010c9e7a2c perftools::gputools::cuda::Diagnostician::FindKernelDriverVersion() + 204
2   _pywrap_tensorflow.so           0x000000010c9e7220 perftools::gputools::cuda::Diagnostician::LogDriverVersionInformation() + 512
3   _pywrap_tensorflow.so           0x000000010c9e6f8f perftools::gputools::cuda::Diagnostician::LogDiagnosticInformation() + 671
4   _pywrap_tensorflow.so           0x000000010c9f7d69 perftools::gputools::cuda::CUDADriver::Init() + 569
5   _pywrap_tensorflow.so           0x000000010ca0e56f perftools::gputools::cuda::CudaPlatform::VisibleDeviceCount() const + 15
6   _pywrap_tensorflow.so           0x000000010c79d1f5 tensorflow::GPUMachineManager() + 261
7   _pywrap_tensorflow.so           0x000000010c79ac4e tensorflow::BaseGPUDeviceFactory::GetValidDeviceIds(std::__1::vector<int, std::__1::allocator<int> >*) + 46
8   _pywrap_tensorflow.so           0x000000010c79aa79 tensorflow::BaseGPUDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<tensorflow::Device*, std::__1::allocator<tensorflow::Device*> >*) + 345
9   _pywrap_tensorflow.so           0x000000010c91d1b5 tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<tensorflow::Device*, std::__1::allocator<tensorflow::Device*> >*) + 245
10  _pywrap_tensorflow.so           0x000000010b5a7175 _wrap_DeviceFactory_AddDevices(_object*, _object*) + 133
11 
```

On main window I see following

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.1.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.dylib locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_NO_DEVICE

```

I used to be able to do this, also, if I run NVidia's `deviceQuery` that comes with CUDA drivers, it fails without a SIGSERV

```
cd /usr/local/cuda/samples
sudo make -C 1_Utilities/deviceQuery
./bin/x86_64/darwin/release/deviceQuery

./bin/x86_64/darwin/release/deviceQuery Starting...
 CUDA Device Query (Runtime API) version (CUDART static linking)

cudaGetDeviceCount returned 38
-> no CUDA-capable device is detected
Result = FAIL
```
"
2977,Complex Number Calculations Not Available On GPU -- No Supported Kernels,"Hey Guys,

Have been trying to implement unitary RNN in tensorflow. Big thanks to @khaotik as he has done much work on implementing unitary RNN's in his repo here:

https://github.com/sherjilozair/char-rnn-tensorflow

When I try to implement this on a GPU I run into several kernel support errors. Here are some operations that do not currently have kernels for the `complex64` dtype:
- `tf.conj`
- `tf.matmul` (which is crucial)

I'm unsure if `batch_fft` has supported GPU kernels. 

Regardless, having these kernels would give tensorflow the ability to explore entirely new architectures as several new RNN papers use complex numbers now. I'm not sure how difficult it would be to write these kernels but much thanks to those who could do it. 
"
2975,"ValueError : Variable proj_w already exists, disallowed. did you mean to set reuse=true in VarScope?","GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 7.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. 0.8

If installed from sources, provide the commit hash:
### Steps to reproduce

I have created a REST webservice to execute machine translation with some modifications in translate.py.  If I run decode function in translate.py alone, on multiple runs I get the right output. But when I try to run the decode function through the webservice that I have created, the first time, I get the translation result. But on the second iteration, I get an error mentioned in the title.
### What have you tried?
1. I tried to close the session at the end of decode function in translate.py.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
[logs-1.txt](https://github.com/tensorflow/tensorflow/files/325737/logs-1.txt)
"
2974,"Could not parse default value '1.0' from Attr(""distortion: float = 1.0"") [locale dependent float parsing]","Hi! I link my library against tensorflow library. When loading I get the following error:

> F tensorflow/core/framework/op.cc:160] Check failed: ::tensorflow::Status::OK() == (RegisterAlreadyLocked(deferred_[i])) (OK vs. Invalid argument: Could not parse default value '1.0' from Attr(""distortion: float = 1.0"") for Op FixedUnigramCandidateSampler)

I tried to figure out what causes this problem and found that tensorflow can't parse OP with float attrs. For example, have a look at [core/ops/candidate_sampling_ops.cc:219](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/candidate_sampling_ops.cc#L219)

> .Attr(""distortion: float = 1.0"")

If I rewrite it as follows:

> .Attr(""distortion: float = 1"")

it works fine until it finds another float attribute. I tried to trace down this problem and stuck here [tensorflow/core/lib/strings/numbers.cc:230](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/strings/numbers.cc#L228):

```
bool safe_strtof(const char* str, float* value) {
  char* endptr;
  *value = strtof(str, &endptr);
  while (isspace(*endptr)) ++endptr;
  // Ignore range errors from strtod/strtof.
  // The values it returns on underflow and
  // overflow are the right fallback in a
  // robust setting.
  return *str != '\0' && *endptr == '\0';
}
```

this function returns false for `str` = ""1.0"" because `endptr` points to "".0"".
Please, fix this problem or suggest me the to fix it and I'll contribute or... tell me how i can work around this... Thank you.

Operating System:
$ uname -a
Linux user-desktop 4.4.0-24-generic #43-Ubuntu SMP Wed Jun 8 19:27:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

$ cat /etc/issue
Ubuntu 16.04 LTS \n \l

$ g++ --version
g++ (Ubuntu 4.9.3-13ubuntu2) 4.9.3
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

commit hash: b77f607ec03ef251c1d28cc00bc743aad26606a4
### UPD. Solution

I found out the reason of this strange behavior. If I run my program as follows:
`$ LC_NUMERIC=C ./my_program_with_tensorflow` 
than it works properly (my previous `LC_NUMERIC` was `ru_RU.UTF-8` where decimal separator is '`,`'). I find it weird when correctness of program depends on current user locale (you always use the same decimal separator in OP descriptions). Fix it please.
"
2973,restore() model with absolute and relative path,"### Comment

restore succeeded with relative path(script directory), but failed with absolute path.
### Environment info

Operating System: 

Ubunto 14.04.1

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
22:16 $ ls -al /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   322936  8 16  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16  8 16  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19  8 16  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336  8 16  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192  8 16  2015 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 61453024  5 26 09:37 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 61453024  5 26 09:37 /usr/local/cuda/lib64/libcudnn.so.4
-rwxr-xr-x 1 root root 61453024  5 26 09:37 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862  5 26 09:37 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed.
   tensorflow-0.8.0    
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.8.0
```
### Steps to reproduce
1. train

```
https://github.com/tensorflow/tensorflow/blob/de1334da2c6e074c427d283898450de6e50a605d/tensorflow/models/embedding/word2vec_optimized.py

$ python word2vec_optimized.py --train_data=text8 --eval_data=questions-words.txt --save_path=tmp
```
1. test

```
https://github.com/dsindex/segm-lstm/blob/master/test_word2vec.py

$ python test_word2vec.py --model_path=tmp
...
checkpoint_dir =  tmp
checkpoint_path =  tmp/model.ckpt-2264698
model restored from tmp/model.ckpt-2264698
analogy = moscow
...

$ python test_word2vec.py --model_path=/path/to/segm-lstm/tensorflow/tensorflow/models/embedding/tmp
...
checkpoint_dir =  /path/to/segm-lstm/tensorflow/tensorflow/models/embedding/tmp
checkpoint_path =  model.ckpt-2264698
Traceback (most recent call last):
  File ""test_word2vec.py"", line 224, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""test_word2vec.py"", line 204, in main
    model.saver.restore(session, ckpt.model_checkpoint_path)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1088, in restore
    raise ValueError(""Restore called with invalid save path %s"" % save_path)
ValueError: Restore called with invalid save path model.ckpt-2264698
```
"
2965,Fail to activate tensorflow,"I installed tensorflow on raspberry pi but fail to activate it:

pi@raspberrypi:~ $ sudo pip install ./tensorflow-0.8.0-cp27-none-linux_armv7l.whl 
Unpacking ./tensorflow-0.8.0-cp27-none-linux_armv7l.whl
Requirement already satisfied (use --upgrade to upgrade): numpy>=1.8.2 in /usr/lib/python2.7/dist-packages (from tensorflow==0.8.0)
Requirement already satisfied (use --upgrade to upgrade): protobuf==3.0.0b2 in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.8.0)
Requirement already satisfied (use --upgrade to upgrade): wheel in /usr/lib/python2.7/dist-packages (from tensorflow==0.8.0)
Requirement already satisfied (use --upgrade to upgrade): six>=1.10.0 in /usr/local/lib/python2.7/dist-packages/six-1.10.0-py2.7.egg (from tensorflow==0.8.0)
Installing collected packages: tensorflow
Successfully installed tensorflow
Cleaning up...
pi@raspberrypi:~ $ source activate tensorflow
-bash: activate: No such file or directory
pi@raspberrypi:~ $ 
"
2962,support for cudnn 5.1,"2.7x faster using 3x3 kernel convolution 
"
2959,Unhandled API callback messages when using GPU tracing,"Using the GPU tracer (e.g. via session.Run with RunOptions FULL_TRACE) results in warnings like the following:

```
W tensorflow/core/common_runtime/gpu/gpu_tracer.cc:513] Unhandled API Callback for 2 41
W tensorflow/core/common_runtime/gpu/gpu_tracer.cc:513] Unhandled API Callback for 2 41
```

These are believed to be harmless, but are obviously annoying.  A fix is in progress.
"
2957,Dequeueing immediately after starting threads fails,"From [a question on Stack Overflow](http://stackoverflow.com/questions/37878696/dequeue-immediately-after-starting-threads-fails), the following code fails:

``` python
import tensorflow as tf
import time
with tf.Graph().as_default():
    filename_list = ['data_batch_{}.mat'.format(i+1) for i in range(5)]
    filename_queue = tf.train.string_input_producer(filename_list)

    with tf.Session() as sess:
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(sess=sess, coord=coord)

        #time.sleep(1) # If I uncomment this it works
        for i in range(5):
            print(sess.run(filename_queue.dequeue()))

        coord.request_stop()
        coord.join(threads)
```

...with the following error:

`NotFoundError: FetchOutputs node input_producer_Dequeue:0: not found`

It turns out that my fix for #2425 was incomplete, and there is still a race between concurrent graph modification and `Session.run()` calls. I'm preparing a fix.
"
2955,Readmea for tensorboard not on website,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Browser issue with readme tensorboard

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. not tensorproblem but website

If installed from sources, provide the commit hash:
### Steps to reproduce
1. Go to https://www.tensorflow.org/versions/r0.9/how_tos/summaries_and_tensorboard/index.html and click on the readme tensorboard. Give you 404 not found error.
### What have you tried?
1. nothing, its on the website
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

![screen shot 2016-06-19 at 10 20 53 pm](https://cloud.githubusercontent.com/assets/1855278/16181716/2cfc7cd4-366c-11e6-92e2-ed67906c95eb.png)
"
2953,Fractional pooling,"Is there or (will there be) a ""Fractional Pooling"" support in tensorflow?
"
2952,learn datasets not found,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

I have tensorflow 0.8.0 installed and when i import learn the datasets are not an option

![screen shot 2016-06-19 at 3 00 22 pm](https://cloud.githubusercontent.com/assets/8854444/16180075/dbe3ff6c-362e-11e6-8f5a-4a7cf575f5cf.png)
![screen shot 2016-06-19 at 3 02 10 pm](https://cloud.githubusercontent.com/assets/8854444/16180076/dbfd3fa4-362e-11e6-836d-d98c68400389.png)
"
2951,Installation of Tensorflow on Mac OS X 10.11.5 wheel not supported?,"Tried installing Tensorflow but wheel not supported on this platform. 
### Environment info

Operating System: Mac OS X 10.11.5

If installed from binary pip package, provide:
1. sudo -H pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl
2. Traceback (most recent call last):
   File ""<string>"", line 1, in <module>
   ImportError: No module named tensorflow

If installed from sources, provide the commit hash:
### Steps to reproduce
1. sudo -H pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl
### Logs or other output that would be helpful

tensorflow-0.8.0-py2-none-any.whl is not a supported wheel on this platform.
"
2950,Error when running resnet.py,"System: Mac OS Yosemite, Python 2.7.

```
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-1-6138fced2cf1> in <module>()
    150   # Train model and save summaries into logdir.
    151   classifier.fit(
--> 152       mnist.train.images, mnist.train.labels, logdir='models/resnet/')
    153 
    154   # Calculate accuracy.

/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.pyc in fit(self, X, y, monitor, logdir)
    225         if not self.continue_training or not self._initialized:
    226             # Sets up model and trainer.
--> 227             self._setup_training()
    228             self._initialized = True
    229         else:

/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.pyc in _setup_training(self)
    146             # Create model's graph.
    147             self._model_predictions, self._model_loss = self.model_fn(
--> 148                 self._inp, self._out)
    149 
    150             # Set up a single operator to merge all the summaries

<ipython-input-1-6138fced2cf1> in res_net(x, y, activation)
    111       # shortcut connections that turn the network into its counterpart
    112       # residual function (identity shortcut)
--> 113       net = conv + net
    114 
    115       try:

/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc in binary_op_wrapper(x, y)
    516       assert isinstance(x, ops.Tensor)
    517       y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=""y"")
--> 518       return func(x, y, name=name)
    519 
    520   ops.Tensor._override_operator(""__%s__"" % op_name, binary_op_wrapper)

/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc in add(x, y, name)
     42     A `Tensor`. Has the same type as `x`.
     43   """"""
---> 44   return _op_def_lib.apply_op(""Add"", x=x, y=y, name=name)
     45 
     46 

/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)
    653         op = g.create_op(op_type_name, inputs, output_types, name=scope,
    654                          input_types=input_types, attrs=attr_protos,
--> 655                          op_def=op_def)
    656         outputs = op.outputs
    657         return _Restructure(ops.convert_n_to_tensor(outputs), output_structure)

/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)
   2154                     original_op=self._default_original_op, op_def=op_def)
   2155     if compute_shapes:
-> 2156       set_shapes_for_outputs(ret)
   2157     self._add_op(ret)
   2158     self._record_op_seen_by_control_dependencies(ret)

/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in set_shapes_for_outputs(op)
   1610       raise RuntimeError(""No shape function registered for standard op: %s""
   1611                          % op.type)
-> 1612   shapes = shape_func(op)
   1613   if len(op.outputs) != len(shapes):
   1614     raise RuntimeError(

/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc in _BroadcastShape(op)
   1388     else:
   1389       raise ValueError(""Incompatible shapes for broadcasting: %s and %s""
-> 1390                        % (shape_x, shape_y))
   1391   return [tensor_shape.TensorShape(return_dims)]
   1392 

ValueError: Incompatible shapes for broadcasting: (?, 14, 14, 128) and (?, 14, 14, 256)
```
"
2948,Automatically merge identical ops,"When an op constructing function is called for multiple times on the same set of inputs, each of these calls adds a new op to the graph, which leads to extra computation. I understand that this could be avoided in most cases by reusing the output tensor. However, this can't be easily done in some situations, e.g. when using different optimizers for different parts of a neural network. Therefore, IMHO, it would be beneficial to have the framework automatically merge identical ops.
"
2944,Errors while running Translate.py sample code with multiple GPUS,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Ubuntu

Installed version of CUDA and cuDNN: 7.5 and 7
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. 0.8

If installed from sources, provide the commit hash:
### Steps to reproduce
1. running the translate.py example
   2.Crashes while creating models after tokenizing the training data.

The sample code seems to run fine with single GPU of 4 GB memory. I am using AWS GPU instances. But it works fine for basic values, ie vocab size of 40000 and size of 512. I want to train on a vocab size of 500000 and size of 1024. This is the reason why I opted to go for 4 GPUs now. 
(In AWS terms, g2.2xlarge to g2.8xlarge). 
![g2-8xlarge-crash](https://cloud.githubusercontent.com/assets/5551707/16170060/c599bef8-3562-11e6-9723-4a38999c6a43.png)
![nvidia-smi-details](https://cloud.githubusercontent.com/assets/5551707/16170062/d7a121fe-3562-11e6-928e-3270ebaa44b9.png)
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2943,Extracting features from mixed layer in inception-v3 ,"Hi,
For my project I need to extract the features from the mixed layer in inception-v3. But, for doing so I need the name of various tensor layer.
as far as I know 
`pool_1:0 correspond to (35X35X192) feature matrix`
`pool_3:0 correspond to (2048,) feature matrix`
`conv_1:0 correspond to ((147X147X32)) feature matrix`
`conv_2:0 correspond to (147X147X64) feature matrix`
`conv_3:0 correspond to (73X73X80) feature matrix`  
`conv_4:0 correspond to (71X71X192) feature matrix`

I am interested in final mixed layer [8X8X2048] `mixed_10` as mentioned in `model.txt` Can you please tell me how to extract this layer 
"
2942,Memory Leak in Queue,"Version: nightly built for Python2+Linux+GPU about a week ago (perhaps earlier). Cannot test on latest binary due to #2939.

The following code:

``` python
import tensorflow as tf
import numpy as np
import os

if __name__ == '__main__':
    input_vars = tf.placeholder(tf.float32, shape=(None, 60, 60, 4))
    queue = tf.FIFOQueue(1000, [tf.float32], name='queue')
    enqueue_op = queue.enqueue([input_vars])
    output = tf.reduce_mean(queue.dequeue())

    sess = tf.Session()
    sess.run(tf.initialize_all_variables())

    with sess.as_default():
        d = np.random.rand(16, 60, 60, 4)
        for k in range(990):
            enqueue_op.run(feed_dict={input_vars: d})
        cmd = ""ps u "" + str(os.getpid()) + "" | tail -n 1 | awk '{print $6}'""
        while True:
            print ""mem in KB: ""
            os.system(cmd)
            for k in range(300):
                enqueue_op.run(feed_dict={input_vars: d})
                output.eval()
```

quickly consumes 10GB main memory.

Tested on ArchLinux as well as CentOS7.
"
2940,Installing Tensorflow with GPU support on os x 10.11,"After configuring and running 
`bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package` 
I am getting this error during the build:

`ERROR: /pathtotensorflow/tensorflow/tensorflow/contrib/session_bundle/example/BUILD:38:1: Executing genrule //tensorflow/contrib/session_bundle/example:half_plus_two failed: bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_xxx/2ba3b3e08313f86d16eb1de7b54bf064/tensorflow/bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two.runfiles/tensorflow/contrib/session_bundle/example/export_half_plus_two.py"", line 33, in <module>
    from tensorflow.contrib.session_bundle import exporter
ImportError: No module named session_bundle
Target //tensorflow/tools/pip_package:build_pip_package failed to build`
### Environment info

Operating System: os x el Capitan

Installed version of CUDA and cuDNN:  
`-rwxr-xr-x  1 root  wheel  8280 Apr 12 23:02 /usr/local/cuda/lib/libcuda.dylib
lrwxr-xr-x  1 root  wheel    45 Apr 12 23:03 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
lrwxr-xr-x  1 root  wheel    50 Apr 12 23:03 /usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
lrwxr-xr-x  1 root  wheel    46 Apr 12 23:03 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
lrwxr-xr-x  1 root  wheel    49 Apr 12 23:03 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a
lrwxr-xr-x  1 root  admin    47 Jun 16 11:25 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.5.dylib
lrwxr-xr-x  1 root  admin    45 Jun 16 11:25 /usr/local/cuda/lib/libcudnn.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.dylib
lrwxr-xr-x  1 root  admin    48 Jun 16 11:25 /usr/local/cuda/lib/libcudnn_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn_static.a`
"
2939,Unable to download nightly binaries,"All the links in README, such as [this one](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.8.0-cp27-none-linux_x86_64.whl)
give me 

```
HTTP ERROR 404

Problem accessing /view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.8.0-cp27-none-linux_x86_64.whl. Reason:

    Not Found
Powered by Jetty://
```
"
2938,dynamic_rnn after reshape seems impossible,"I need to multiply a 3D tensor by a 2D weight matrix, then feed it to dynamic_rnn.
Below is the code.

```
inputSize = 1000
embeddingSize = 100

batchX = tf.placeholder(tf.float32, [None, None, inputSize])
#The maximum length of the sequences and the size of the mini-batch are dynamic
#batchX is a time-major 3D tensor

batchXLenghts = tf.placeholder(tf.int32, [None,])
#A list of integers indicating the length of each sequence in batchX

maxLength = tf.shape(batchX)[0]
batchSize = tf.shape(batchX)[1]

with tf.variable_scope('embedding') as scope:
    W_emb = tf.get_variable('W_emb', [inputDimSize, embDimSize], initializer=tf.truncated_normal_initializer())
    b_emb = tf.get_variable('b_emb', [embDimSize,], initializer=tf.constant_initializer())

emb = tf.reshape(tf.matmul(tf.reshape(batchX, [maxLength*batchSize, inputDimSize]), W_emb) + b_emb, [maxLength, batchSize, embDimSize])
#embedding step. There are two reshape operations because I am doing np.dot(3D, 2D)

cell = GRUCell(embDimSize)
outputs, states = rnn.dynamic_rnn(cell, emb, sequence_length=batchXLengths, time_major=True, parallel_iterations=256, dtype='float32')

# calculating logits, loss, etc.
...
...
```

When I run this code, I get the following error

```
Traceback (most recent call last):
  File ""feedTestDynamicRnn.py"", line 127, in <module>
    train(xFile=xFile, yFile=yFile)
  File ""feedTestDynamicRnn.py"", line 98, in train
    batchX, batchXLengths, batchY, logits, mean_loss = inference(options)
  File ""feedTestDynamicRnn.py"", line 57, in inference
    outputs, states = rnn.dynamic_rnn(cell, emb, sequence_length=batchXLengths, time_major=True, parallel_iterations=256, dtype='float32')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py"", line 580, in dynamic_rnn
    swap_memory=swap_memory, sequence_length=sequence_length)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py"", line 630, in _dynamic_rnn_loop
    ""Input size (depth of inputs) must be accessible via shape inference, ""
ValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.
```

When I comment out the embedding step, and feed `batchX` directly to `dynamic_rnn`, there is no problem. So it seems that `tf.reshape()` loses shape information as told by [this post](http://stackoverflow.com/questions/35374958/reshape-tensor-using-placeholder-value). 

The problem is, I cannot fix `maxLength` and `batchSize` to a static value, because they need to change. Also, I need to do embedding, so directly feeding `batchX` to the RNN is not an option. Is there a work around for this?
"
2937,Tensorflow cudnn integration status,"With this issue I would like to track the efforts in integrating the
cudnn library within tensorflow.

As of June 17th 2016 doing a manual grep on the repository gives these
functions as being mapped from cudnn to the stream executor,

From chapter 4 of the cudnn User Guide version 5.0 (April 2016):
- [x] cudnnGetVersion
- [ ] cudnnGetErrorString
- [x] cudnnCreate
- [x] cudnnDestroy
- [x] cudnnSetStream
- [ ] cudnnGetStream
- [x] cudnnCreateTensorDescriptor
- [ ] cudnnSetTensor4dDescriptor
- [ ] cudnnSetTensor4dDescriptorEx
- [ ] cudnnGetTensor4dDescriptor
- [x] cudnnSetTensorNdDescriptor
- [x] cudnnDestroyTensorDescriptor
- [x] cudnnTransformTensor
- [x] cudnnAddTensor
- [ ] cudnnOpTensor
- [x] cudnnSetTensor
- [ ] cudnnScaleTensor
- [x] cudnnCreateFilterDescriptor
- [ ] cudnnSetFilter4dDescriptor
- [ ] cudnnGetFilter4dDescriptor
- [ ] cudnnSetFilter4dDescriptor_v3 (versioned)
- [ ] cudnnGetFilter4dDescriptor_v3 (versioned)
- [ ] cudnnSetFilter4dDescriptor_v4 (versioned)
- [ ] cudnnGetFilter4dDescriptor_v4 (versioned)
- [x] cudnnSetFilterNdDescriptor
- [ ] cudnnGetFilterNdDescriptor
- [ ] cudnnGetFilterNdDescriptor_v3 (versioned)
- [ ] cudnnGetFilterNdDescriptor_v3 (versioned)
- [ ] cudnnGetFilterNdDescriptor_v4 (versioned)
- [ ] cudnnGetFilterNdDescriptor_v4 (versioned)
- [x] cudnnDestroyFilterDescriptor
- [x] cudnnCreateConvolutionDescriptor
- [ ] cudnnSetConvolution2dDescriptor
- [ ] cudnnGetConvolution2dDescriptor
- [ ] cudnnGetConvolution2dForwardOutputDim
- [x] cudnnSetConvolutionNdDescriptor
- [ ] cudnnGetConvolutionNdDescriptor
- [x] cudnnGetConvolutionNdForwardOutputDim
- [x] cudnnDestroyConvolutionDescriptor
- [ ] cudnnFindConvolutionForwardAlgorithm
- [ ] cudnnFindConvolutionForwardAlgorithmEx
- [x] cudnnGetConvolutionForwardAlgorithm
- [x] cudnnGetConvolutionForwardWorkspaceSize
- [x] cudnnConvolutionForward
- [ ] cudnnConvolutionBackwardBias
- [ ] cudnnFindConvolutionBackwardFilterAlgorithm
- [ ] cudnnFindConvolutionBackwardFilterAlgorithmEx
- [x] cudnnGetConvolutionBackwardFilterAlgorithm
- [x] cudnnGetConvolutionBackwardFilterWorkspaceSize
- [x] cudnnConvolutionBackwardFilter
- [ ] cudnnFindConvolutionBackwardDataAlgorithm
- [ ] cudnnFindConvolutionBackwardDataAlgorithmEx
- [x] cudnnGetConvolutionBackwardDataAlgorithm
- [x] cudnnGetConvolutionBackwardDataWorkspaceSize
- [x] cudnnConvolutionBackwardData
- [ ] cudnnSoftmaxForward
- [ ] cudnnSoftmaxBackward
- [x] cudnnCreatePoolingDescriptor
- [ ] cudnnSetPooling2dDescriptor
- [ ] cudnnGetPooling2dDescriptor
- [x] cudnnSetPoolingNdDescriptor
- [ ] cudnnGetPoolingNdDescriptor
- [ ] cudnnSetPooling2dDescriptor_v3 (versioned)
- [ ] cudnnGetPooling2dDescriptor_v3 (versioned)
- [ ] cudnnSetPoolingNdDescriptor_v3 (versioned)
- [ ] cudnnGetPoolingNdDescriptor_v3 (versioned)
- [ ] cudnnSetPooling2dDescriptor_v4 (versioned)
- [ ] cudnnGetPooling2dDescriptor_v4 (versioned)
- [ ] cudnnSetPoolingNdDescriptor_v4 (versioned)
- [ ] cudnnGetPoolingNdDescriptor_v4 (versioned)
- [x] cudnnDestroyPoolingDescriptor
- [ ] cudnnGetPooling2dForwardOutputDim
- [ ] cudnnGetPoolingNdForwardOutputDim
- [x] cudnnPoolingForward
- [x] cudnnPoolingBackward
- [x] cudnnActivationForward
- [ ] cudnnActivationBackward
- [x] cudnnCreateActivationDescriptor
- [x] cudnnSetActivationDescriptor
- [x] cudnnGetActivationDescriptor
- [x] cudnnDestroyActivationDescriptor
- [ ] cudnnActivationForward_v3  (versioned)
- [ ] cudnnActivationBackward_v3 (versioned)
- [ ] cudnnActivationForward_v4  (versioned)
- [ ] cudnnActivationBackward_v4 (versioned)
- [ ] cudnnCreateLRNDescriptor
- [ ] cudnnSetLRNDescriptor
- [ ] cudnnGetLRNDescriptor
- [ ] cudnnDestroyLRNDescriptor
- [ ] cudnnLRNCrossChannelForward
- [ ] cudnnLRNCrossChannelBackward
- [ ] cudnnDivisiveNormalizationForward
- [ ] cudnnDivisiveNormalizationBackward
- [ ] cudnnBatchNormalizationForwardInference
- [ ] cudnnBatchNormalizationForwardTraining
- [ ] cudnnBatchNormalizationBackward
- [ ] cudnnDeriveBNTensorDescriptor
- [ ] cudnnCreateRNNDescriptor
- [ ] cudnnDestroyRNNDescriptor
- [ ] cudnnSetRNNDescriptor
- [ ] cudnnGetRNNWorkspaceSize
- [ ] cudnnGetRNNTrainingReserveSize
- [ ] cudnnGetRNNParamsSize
- [ ] cudnnGetRNNLinLayerMatrixParams
- [ ] cudnnGetRNNLinLayerBiasParams
- [ ] cudnnRNNForwardInference
- [ ] cudnnRNNForwardTraining
- [ ] cudnnRNNBackwardData
- [ ] cudnnRNNBackwardWeights
- [ ] cudnnCreateDropoutDescriptor
- [ ] cudnnDestroyDropoutDescriptor
- [ ] cudnnDropoutGetStatesSize
- [ ] cudnnDropoutGetReserveSpaceSize
- [ ] cudnnSetDropoutDescriptor
- [ ] cudnnDropoutForward
- [ ] cudnnDropoutBackward
- [ ] cudnnCreateSpatialTransformerDescriptor
- [ ] cudnnDestroySpatialTransformerDescriptor
- [ ] cudnnSetSpatialTransformerNdDescriptor
- [ ] cudnnSpatialTfGridGeneratorForward
- [ ] cudnnSpatialTfGridGeneratorBackward
- [ ] cudnnSpatialTfSamplerForward
- [ ] cudnnSpatialTfSamplerBackward
### Batch Normalization

Seems @lukemetz was working on it but has stalled for a bit https://github.com/tensorflow/tensorflow/pull/1759
### What is the plan for the RNN ?

I know @wchan was working on a [cpu version](https://github.com/tensorflow/tensorflow/pull/2002). I was trying to get a stub at [using the cudnn version](https://github.com/Mistobaan/tensorflow/tree/feature/cudnn-rnn-lstm) but from the comments in that thread seemed like @zheng-xq was working on it internally.
Can anyone comment on the status of these ops?
### Other Questions
1. Any reasons why the Softmax functions are not being used ?
2. Would make sense to split the above list in chunks and create issues with contribution welcome, so external contributors can tackle them without duplicating internal work, or mark what google will be working on internally ?

I hope this helps in organizing the work around the cudnn and inspire the community to contribute. I will try to keep this issue up to date.
"
2935,Exception when trying to use TensorFlowDNNClassifier with Scikit-Learn model_selection.cross_val_score,"I am attempting to use cross_val_score with the TensorFlowDNNClassifier (I know it is deprecated) from Scikit-Learn. I used cross_val_score seamlessly with the original skflow wrapper which allowed me to use evolutionary computing to evolve the parameters of the TensorFlowDNNClassifier. 

It appears that when a clone of the TensorFlowDNNClassifier is initialised for the number of folds specified in cross_val_score, the hidden_units argument is not included as the estimator.get_params() function within clone in sklearn/base.py does not retrieve the value set against _dnn_hidden_units. 

The classifiers/regressors of Scikit-Learn take the approach of assigning the input parameters a default value which allows for a lot of flexibility. Instead of requiring the user to provide the structure of their DNN through the hidden_units parameter perhaps a default value should be provided so that the classifier can be cloned when the classifier is passed to cross_val_score.

Given that the objective of Skflow was to integrate tensorflow into the Scikit-learn pipeline it would be ideal to turn hidden_units into a key word argument.
### Environment info

Operating System:
Linux Mint 17.2 Cinnamon 64 bit

Installed version of CUDA and cuDNN: 
Not relevant

If installed from binary pip package, provide:
1. Which pip package you installed.
   pip3 install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0rc0-cp35-cp35m-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.9.0rc0

python - 3.5.1
scikit-learn - 0.18.dev0
tensorflow - 0.9.0rc0
scipy - 0.17.1
numpy - 1.11.0
### Steps to reproduce
1. Code provided

```
from sklearn import datasets, model_selection
from tensorflow.contrib import learn
import traceback

if __name__ == '__main__':
    try:

        iris = datasets.load_iris()

        X_train, X_test, y_train, y_test = model_selection.train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)

        kwargs = {
            ""n_classes"":3,
            ""optimizer"" : ""Adam"",
            ""hidden_units"" : [10, 20, 10],
            ""steps"": 250
        }

        classifier = learn.TensorFlowDNNClassifier(**kwargs)

        scores = model_selection.cross_val_score(
            classifier,
            X_train,
            y_train,
            scoring=""accuracy""
        )

        print('Accuracy: {0:f}'.format(scores))

    except:
        print(traceback.format_exc())
```
### Logs or other output that would be helpful

```
Traceback (most recent call last):
  File ""/home/thirdoctet/Development/projects/python/scikit-evolution/skevolve/tests/tensorflow_classification.py"", line 47, in <module>
    scoring=""accuracy""
  File ""/usr/local/lib/python3.5/site-packages/sklearn/model_selection/_validation.py"", line 167, in cross_val_score
    for train, test in cv.split(X, y, labels))
  File ""/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py"", line 800, in __call__
    while self.dispatch_one_batch(iterator):
  File ""/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py"", line 653, in dispatch_one_batch
    tasks = BatchedCalls(itertools.islice(iterator, batch_size))
  File ""/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py"", line 68, in __init__
    self.items = list(iterator_slice)
  File ""/usr/local/lib/python3.5/site-packages/sklearn/model_selection/_validation.py"", line 167, in <genexpr>
    for train, test in cv.split(X, y, labels))
  File ""/usr/local/lib/python3.5/site-packages/sklearn/base.py"", line 57, in clone
    new_object = klass(**new_object_params)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 452, in __init__
    super(DeprecatedMixin, self).__init__(*args, **kwargs)
TypeError: __init__() missing 1 required positional argument: 'hidden_units'
```
"
2930,Is contrib/quantization available through Python interface?,"It works in C++ if I build label_image example but if I call through python, I got:
tensorflow.python.framework.errors.NotFoundError: Op type not registered 'QuantizeV2'

Is there any build file I need to update? I tested on RC0.9 release. Thanks. 
"
2929,IOS - No OpKernel was registered to support Op 'Conv2DBackpropInput' with these attrs,"Hi everyone,

We are trying to load a very simple graph inside IOS that we generate and freeze with python.
Right now, we have this following error:

```
E Running model failed: Invalid argument: 
No OpKernel was registered to support Op 'Conv2DBackpropInput' with these attrs
     [[Node: convt = Conv2DBackpropInput[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Shape, W/read, x)]]
```

Here is the python script generating the model:

``` python
from tools import freeze_graph

import tensorflow as tf

print('Init session')
sess = tf.InteractiveSession()

print('Define vars and ops')
x = tf.placeholder(tf.float32, shape=[None, 600, 600, 3], name=""x"")
W = tf.Variable(tf.truncated_normal([3, 3, 3, 3], stddev=0.1), name=""W"")
convt = tf.nn.conv2d_transpose(x, W, tf.shape(x), strides=[1, 1, 1, 1], padding='SAME', name=""convt"")

print('Init vars')
init = tf.initialize_all_variables()
sess.run(init)

input_graph_name = ""input_graph.pb""

saver = tf.train.Saver(var_list=None)
saver.save(sess, 'data/conv', global_step=None)

graph_def = sess.graph.as_graph_def()
tf.train.write_graph(graph_def, ""data"", input_graph_name)

input_graph_path = 'data/' + input_graph_name
input_saver_def_path = """"
input_binary = False
input_checkpoint_path = 'data/conv'
output_node_names = ""convt""
restore_op_name = ""save/restore_all""
filename_tensor_name = ""save/Const:0""
output_graph_path = ""data/frozen_convt.pb""
clear_devices = True

freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,
                          input_binary, input_checkpoint_path,
                          output_node_names, restore_op_name,
                          filename_tensor_name, output_graph_path,
                          clear_devices, """")
```

Here is the Objective-C++ interesting part:

``` C
 //  2. Load the network

  NSString* network_path = FilePathForResourceName(@""frozen_conv"", @""pb"");
  PortableReadFileToProto([network_path UTF8String], &tensorflow_graph);

  LOG(INFO) << ""Creating session."";
  tensorflow::Status s = session->Create(tensorflow_graph);

  if (!s.ok()) {
    LOG(ERROR) << ""Could not create Tensorflow Graph: "" << s;
  }


  //  3. Run the network

    std::string input_layer = ""x:0"";
    std::string output_layer = ""convt:0"";

    std::vector<tensorflow::Tensor> outputs;
    tensorflow::Status run_status = session->Run({{input_layer, image_tensor}},
                                                 {output_layer}, {}, &outputs);


    if (!run_status.ok()) {
      LOG(ERROR) << ""Running model failed: "" << run_status;
    }
```

We are using:
- Python 3.5.1 for the script
- The python tensorflow build is downloaded from `https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0rc0-py3-none-any.whl`
- The compiled tensorflow for IOS is from the master branch 2 hour ago using the script `build_all_ios.sh`
- We have **no** problem running the IOS example
- We have **no** problem running a one standard convolutional graph frozen with custom python script
- We checked that the file `tensorflow/core/ops/nn_ops.cc` is in the generated txt files (and this is the file containing the registering of the op 'Conv2DBackpropInput')

I would be gratefull if anyone has an idea on why IOS seems to not be able to find the `Conv2DBackpropInput` Op ?
"
2928,Zeros function not correctly determining shape.,"I want to have dynamic batch sizes so I defined my input tensors as follows.

`input_tensor = tf.placeholder(tf.float32, (None, TIME_STEPS, 128), 'input_tensor')`

I then calculate the batch size.

`batch_size = tf.shape(input_tensor)[0]`

I can use this to determine the initial state for my RNNs as follows...

```
initial_state = state = tf.zeros((batch_size, encoder_multi_rnn.state_size), tf.float32)
...
forward_outputs[t], state = encoder_multi_rnn(getTimeStep(input_tensor, t), state)
```

This seems to work fine when I evaluate tf.shape(initial_state) in my sess.run() it prints what appears to be the correct value.  However, when do the following it prints (?, ?).  I think the second dimension should not be a ?

```
    state = tf.zeros((batch_size, encoder_multi_rnn.state_size), tf.float32)
    print(state.get_shape())
```

This is not causing an issue and my code compiles fine.  However this is causing an issue when I try to feed the output of the last time step of my sequence generating decoder back into the input of the MultiRNN.  On the first time step I feed it zeros since no output has yet to be produced.

```
    rnn_input = tf.reduce_sum(w * decoder_input, 1)
    last_out = decoder_outputs[t - 1] if t else tf.zeros((batch_size, 128))
    rnn_input = tf.concat(1, (rnn_input, last_out))
```

I get this error when concat is called.  ValueError: Linear expects shape[1] of arguments: [[None, None], [None, 1024]]

When I print last_out.get_shape() I get (?, ?) again.  In this case I think it should be (?, 128) since the last dimension is clearly defined.  
"
2927,iOS example Retrained Stripped model memory usage causes app to crash without warning,"### Environment info

Operating System: iOS
### Steps to reproduce
1. create graph with image_retraining example
2. use strip_unused tool on graph with input_node_names=Mul, output_node_names=final_result
3. run iOS example with the retrained stripped graph
4. 80% of the time the app crashes, apparently because it allocates too much memory
### What have you tried?
1. reducing the size of the image being processed
### Logs or other output that would be helpful

I /Users/matp/Documents/projects/mytrue/third-party/tensorflow3/tensorflow-0.9.0rc0/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:225] Session created.
I /Users/matp/Documents/projects/mytrue/third-party/tensorflow3/tensorflow-0.9.0rc0/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:228] Graph created.
I /Users/matp/Documents/projects/mytrue/third-party/tensorflow3/tensorflow-0.9.0rc0/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:235] Creating session.
W tensorflow/core/framework/op_def_util.cc:332] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().

![image](https://cloud.githubusercontent.com/assets/4634115/16151795/dae3e988-346c-11e6-86ea-8ba085165887.png)
"
2926,"Any plans to support tf.map_fn/tf.fold{l,r} with multiple tensors?","I might be interested in potentially working on this too, but just want to make sure that this doesn't conflict with any planned work :)
"
2925,"Always bind ""localhost"" when starting workers","Now we have tried distributed TensorFlow and run multiple workers. It works but we found that it always bind ""localhost"" when I would like to bind one of my NICs.

Is it the bug? Or do I miss something because I found nothing to configure it in any document.
### Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN:  No

If installed from binary pip package, provide:
1. Which pip package you installed.

```
root@100cd4fb5bca:/notebooks# pip --version
pip 8.1.1 from /usr/local/lib/python2.7/dist-packages (python 2.7)
```
1. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
root@100cd4fb5bca:/notebooks# python -c ""import tensorflow; print(tensorflow.__version__)""
0.8.0
```
### Steps to reproduce
1. docker run -it tensorflow/tensorflow bash
2. Write the server code of `one_worker.py`.
3. `python ./one_worker.py`

```
root@100cd4fb5bca:/notebooks# cat one_worker.py
import tensorflow as tf

worker1 = ""www.a.com:2222""
worker_hosts = [worker1]

cluster_spec = tf.train.ClusterSpec({""worker"": worker_hosts})

server = tf.train.Server(cluster_spec, job_name=""worker"", task_index=0)

server.join()
```
### Logs or other output that would be helpful

```
root@100cd4fb5bca:/notebooks# python ./one_worker.py
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:2222}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2222
```
"
2924,Problems and solutions in installing tf on Redhat,"I encountered several problems in installing tensorflow on Redhat system. I solved them by googling solutions. Hope my experience may be helpful to some users.

OS version: Red Hat Enterprise Linux Server release 6.2 (Santiago)
Linux kernel: 2.6.32-220.el6.x86_64

Problems and solutions:

 **1. glibc version is too low** 

Install higer version glibc, e.g. glibc-2.17.
Please use at least version 2.17. You can configure the installation using --prefix option to specify the path to install, and then modify LD_LIBRARY_PATH to include the new glibc library.

 **2. link problem after install higher version of glibc**

Error info looks like:
""
error while loading shared libraries: __vdso_time: invalid mode for dlopen():Invalid argument
""
You need to use the following method to run a program (eg. python):
/path/to/glibc-2.17/lib/ld-linux-x86-64.so.2 --library-path /path/to/glibc-2.17/lib:$LD_LIBRARY_PATH:/path/to/gcc-5.2.0/lib64:/usr/lib64/ /path/to/anaconda/bin/python2.7

 **3. numpy version problem** 

Install new version of numpy using pip.

 **4. protobuf3 not found, and** 
Error in python after 'import tensorflow': TypeError: **init**() got an unexpected keyword argument 'syntax'

pip install 'protobuf>=3.0.0a3'

 **5.  failed call to cuInit: CUDA_ERROR_NO_DEVICE**
Explicitly specify a cuda device in you environment variable:
export CUDA_VISIBLE_DEVICES=0

 **6. libcuda.so.1 not found**

Explicitly specify the path of this lib in your LD_LIBRARY_PATH environment variable. 
libcuda.so is in usually in /usr/lib64

 **7. ELFCLASS32 error**
elf is incorrect, should use a 64-bits .so file (usually in */lib64)

 **8. glibc 2.15 cannot create regular file `/var/db/Makefile': Permission denied**
Use glibc 2.17 or  even higher version.
"
2923,Error:use tensorflow_cifar-10 model on tensorflow android camera,"I am very new to tensorflow. Now I am trying to use tensorflow_cifar-10 model on tensorflow android camera, the app is running but there is no output.

At first I have tried this example:
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android
This example uses the .pb file at:
https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip
It works well.

Then I tried to replace the .pb file with the tensorflow_cifar-10. I followed some of the instructions here:
https://github.com/tensorflow/tensorflow/issues/616
and add the save__graph() function in /tensorflow/models/image/cifar10/cifar10_train.py

code:

def save_graph():

```
g = tf.Graph()
vars = {}
with g.as_default():
    with tf.Session() as sess:
        d = np.ones([1,24,24,3],dtype=np.float32)
        input_data = tf.placeholder(tf.float32,shape=[1,24,24,3], name=""input_placeholder"")
        images, labels = cifar10.distorted_inputs()
        logits = cifar10.inference(images)
        init = tf.initialize_all_variables()
        sess.run(init)
        saver = tf.train.Saver(tf.trainable_variables(),max_to_keep=0)
        saver.restore(sess,os.path.join(FLAGS.train_dir, 'model.ckpt'))
        print (sess.run(logits,{images:d}))
        for v in tf.trainable_variables():
            vars[v.value().name] = sess.run(v)

g2 = tf.Graph()
consts = {}
with g2.as_default():
    with tf.Session() as sess:
        for k in vars.keys():
            consts[k] = tf.constant(vars[k])
        tf.import_graph_def(g.as_graph_def(),input_map={name:consts[name] for name in consts.keys()})
        tf.train.write_graph(sess.graph_def,'/home/eli/Documents/TensorflowProjetos/ProtobufFiles','graph.pb',False)

return os.path.join('/home/eli/Documents/TensorflowProjetos/ProtobufFiles','graph.pb')
```

I use the save__graph() to get the .pb file after the end of training. Then I replace the tensorflow_inception_graph.pb, whice is from inception5h.zip and used in tensorflow_android_camera, with the new .pb file from the cifar10 model.

Finally I run the tensorflow_android_camera app but there is no output. The error in log is: 
Error during inference: Not found: FeedInputs: unable to find feed output input:0
I do not know why it happened, please help me ,thank you!
"
2922,iris_custom_decay_dnn.py does not work,"The code below is the current version of iris_custom_decay_dnn.py. The custom decay portion of which does not appear to work as whenever I run it I get the Traceback below. Through so light testing I discovered that the code works when the custom decay portion is removed.
# iris_custom_decay_dnn.py

``` python
from sklearn import datasets, metrics
from sklearn.cross_validation import train_test_split

import tensorflow as tf

iris = datasets.load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris.data,
                                                    iris.target,
                                                    test_size=0.2,
                                                    random_state=42)
#setup exponential decay function
def exp_decay(global_step):
    return tf.train.exponential_decay(
        learning_rate=0.1, global_step=global_step,
        decay_steps=100, decay_rate=0.001)

# use customized decay function in learning_rate
optimizer = tf.train.AdagradOptimizer(learning_rate=exp_decay)
classifier = tf.contrib.learn.DNNClassifier(hidden_units=[10, 20, 10],
                                            n_classes=3,
                                            optimizer=optimizer)
classifier.fit(X_train, y_train, steps=800)
score = metrics.accuracy_score(y_test, classifier.predict(X_test))
```
# Traceback

Traceback (most recent call last):
  File ""/home/d3v/Py/SkFlow Iris DNN.py"", line 22, in <module>
    classifier.fit(X_train, y_train, steps=800)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 182, in fit
    monitors=monitors)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 449, in _train_model
    train_op, loss_op = self._get_train_ops(features, targets)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py"", line 113, in _get_train_ops
    return super(DNNClassifier, self)._get_train_ops(features, targets)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 170, in _get_train_ops
    dnn_vars)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 356, in _get_dnn_training_ops
    return [self._dnn_optimizer.apply_gradients(zip(dnn_grads, dnn_vars))]
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py"", line 300, in apply_gradients
    self._prepare()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/adagrad.py"", line 70, in _prepare
    name=""learning_rate"")
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 620, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/constant_op.py"", line 179, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/constant_op.py"", line 162, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py"", line 421, in make_tensor_proto
    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py"", line 421, in <listcomp>
    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/compat.py"", line 44, in as_bytes
    raise TypeError('Expected binary or unicode string, got %r' % bytes_or_text)
TypeError: Expected binary or unicode string, got <function exp_decay at 0x7f84e7161e18>
"
2921,No gradient defined for operation 'ExtractImagePatches',"I tried to  use [tf.extract_image_patches](https://www.tensorflow.org/versions/r0.9/api_docs/python/array_ops.html#extract_image_patches) to implement a locally layer as #2605 said. However an error occurred:
LookupError: No gradient defined for operation 'local/ExtractImagePatches' (op type: ExtractImagePatches)  

I checked that tf.space_to_depth has the gradient definition but tf.extract_image_patches does not. And it seems not easy for me to implement the gradient. Any advice? 
@martinwicke @benoitsteiner @mrry 
"
2920,dso_loader on MacOS opens libcudnn.dylib instead of libcudnn.5.dylib,"I'm getting error below after syncing. Was there something in last 24 hours that affected how libcudnn filename is resolved?

`Couldn't open CUDA library libcudnn.dylib. LD_LIBRARY_PATH: /usr/local/cuda/lib
`
Instead I have these files

```
-rwxr-xr-x@ 1 yaroslavvb  staff  58270280 Apr 22 17:19 libcudnn.5.dylib
-rw-r--r--@ 1 yaroslavvb  staff  55551064 Apr 22 17:19 libcudnn_static.a
```

This worked for me as a work-around:

```
bash-3.2$ cd /usr/local/cuda/lib
bash-3.2$ ln -s libcudnn.5.dylib libcudnn.dylib

```

PS: my configure run is below. 

```
bash-3.2$ ./configure
Please specify the location of python. [Default is /usr/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc nvcc should use as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5
Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 5
Please specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 3.0

```

Note: oneproductivity sink is that `git pull` overwrites files that are written by `./configure` because they are checked in, so at each `pull` you need to run `./configure` or [stash/merge](http://stackoverflow.com/questions/37758333/how-to-prevent-checked-in-files-from-overwriting-local-versions). Also, Bazel is not fully hermetic, so if you `bazel build` with incorrect `configure` once, you will then need to `bazel clean`. This issue can be non obvious -- things run but give numerically incorrect results
"
2919,feed_dict performance,"I have been experimenting with different way of reading data in tensorflow, namely:
- input ops / queues
- feed_dict / placeholders

I am finding that feed_dict is much slower on my alexnet benchmark. I have adapted the alexnet benchmark code from the [convnet-benchmarks](https://github.com/soumith/convnet-benchmarks/blob/master/tensorflow/benchmark_alexnet.py). You can find my benchmarking code [here](https://gist.github.com/nanddalal/a0fdd6798ea52afaaeb6e1a78aaeb6db). The main diff is the addition of a `feed_dict` flag which switches between using tf.Variable and tf.Placeholder for the inputs/labels.

In all my tests, I only run the fprop.
My first test was running the benchmark on a GPU using NCHW:

```
feed_dict=True: 102 ms/minibatch
feed_dict=False 28 ms/minibatch
```

As you can see, with `feed_dict=False`, it matches the benchmark, but with `feed_dict=True`, it is 4-5x slower. You can find the full output for `feed_dict=True` [here](https://github.com/tensorflow/tensorflow/files/319610/benchmark_with_feed_dict.txt)
 and `feed_dict=False` [here](https://github.com/tensorflow/tensorflow/files/319611/benchmark_without_feed_dict.txt). These contain yappi profiling output which shows that the bottleneck does not seem to be in the python code. I have also attached the tf timeline output and would appreciate if you can tell me how to interpret it in chrome://tracing. 
[timeline_with_feed_dict.json.txt](https://github.com/tensorflow/tensorflow/files/319613/timeline_with_feed_dict.json.txt)
[timeline_without_feed_dict.json.txt](https://github.com/tensorflow/tensorflow/files/319614/timeline_without_feed_dict.json.txt)

I also ran the same test on CPU using NHWC:

```
feed_dict=True: 727 ms/minibatch
feed_dict=False: 664 ms/minibatch
```

So using `feed_dict` appears to have a constant/one time cost.

I was able to gain almost 2x speedup by changing this [line](https://github.com/tensorflow/tensorflow/blob/9425f822d8a5dc657022eed5c5142b4bf7b1087a/tensorflow/python/client/session.py#L619) from `np.array` to `np.asarray`, but feed_dict is still quite slow.

Please let me know what your thoughts are about this and whether feed_dict is supposed to be this much slower than a pipeline using tfrecords/queues.
"
2917,tf.fill does not have dtype,"[tf.fill](https://www.tensorflow.org/versions/r0.9/api_docs/python/constant_op.html#fill)

Does not provide a dtype keyword like tf.ones, tf.zeros.  Is there a particular reason or is just missing ? You can force it by casting the number but I don't think is clean `tf.fill([10,10], np.int16(8))`.

EDIT: seems also tf.linspace and tf.range
"
2916,[Feature] RDMA support for distribued Tensorflow,"Tensorflow paper (http://arxiv.org/pdf/1605.08695v1.pdf) states that Tensorflow supports multiple communication protocols such as gRPC over TCP, and RDMA over Converged Ethernet. Current repo, on the other hand, only has gRPC implementations. 

Do you have any plan to introduce RDMA support? It should be beneficial especially for GPU-to-GPU communications across servers. 
"
2915,Error when compiling TensorFlow from source for GPU,"When trying to compile TF from source, I am seeing error
### Environment info

Operating System:
Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
 /usr/local/cuda/lib/libcudadevrt.a
/usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
/usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
/usr/local/cuda/lib/libcudart.so.7.5.18
/usr/local/cuda/lib/libcudart_static.a

If installed from sources, provide the commit hash:
679f95e9d8d538c3c02c0da45606bab22a71420e
### Steps to reproduce
1. Git clone from TF source: `git clone https://github.com/tensorflow/tensorflow.git tf_source``
2. Install Baze and reqs
3. Run ./configure
4. Run 

```
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
pip install `echo /tmp/tensorflow_pkg/tensorflow-*.whl`
```
### Logs or other output that would be helpful

```
____Building...
____[0 / 4] Symlinking //tensorflow/tools/pip_package:build_pip_package
____[3 / 54] Creating source manifest for //tensorflow/tensorboard:tensorboard
____[4 / 59] Creating runfiles tree bazel-out/local_linux-py3-opt/bin/tensorflow/tensorboard/tensorboard.runfiles
____[13 / 288] Creating source manifest for //tensorflow/tools/proto_text:gen_proto_text_functions [for host]
____[20 / 487] Executing genrule //third_party/gpus/cuda:cuda_config_check [for host]
ERROR: /tf_source/third_party/gpus/cuda/BUILD:204:1: declared output 'third_party/gpus/cuda/cuda.config' is a dangling symbolic link.
ERROR: /tf_source/third_party/gpus/cuda/BUILD:204:1: not all outputs were created.
____Building complete.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
____Elapsed time: 243.360s, Critical Path: 0.42s
```
"
2910,"Hard-coding ""1"" for CUDA version breaks existing MacOS GPU build with CUDA 7.5","Commit https://github.com/tensorflow/tensorflow/commit/f45874b4a969a60fa9ced86e6769012e4912b5ca broke existing GPU builds on MacOS with CUDA 7.5

It nows fails
`I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1078] failed to find libcuda.so on this system: Failed precondition: could not dlopen DSO: libcuda.1.dylib; dlerror: dlopen(libcuda.1.dylib, 5): image not found
`
A work-around is to create a symlink

```
cd /usr/local/cuda/lib/
ln -s libcuda.dylib libcuda.1.dylib

```
"
2909,Failure to build from source with GPU support on macOS,"I am trying to follow the installation instructions for Mac with GPU support.  I have CUDA 7.5 and cuDNN installed (and Theano currently works with GPU support on this system).

The contents of my /usr/local/cuda/lib include the following:

```
(py35)Dans-iMac:tensorflow dan$ ls -l /usr/local/cuda/lib/libcud*
-rwxr-xr-x  1 root  wheel  8280 Apr 13 00:02 /usr/local/cuda/lib/libcuda.dylib
lrwxr-xr-x  1 root  wheel    45 Apr 13 00:03 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
lrwxr-xr-x  1 root  wheel    50 Apr 13 00:03 /usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
lrwxr-xr-x  1 root  wheel    46 Apr 13 00:03 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
lrwxr-xr-x  1 root  wheel    49 Apr 13 00:03 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a
```

My configure step doesn't provide any errors, as shown in the following:

```
(py35)Dans-iMac:tensorflow dan$ ./configure
Please specify the location of python. [Default is /Users/dan/anaconda/envs/py35/bin/python]:
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc nvcc should use as the host compiler. [Default is /usr/bin/gcc]:
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5
Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify the Cudnn version you want to use. [Leave empty to use system default]:
Please specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 3.0
Setting up Cuda include
Setting up Cuda lib
Setting up Cuda bin
Setting up Cuda nvvm
Setting up CUPTI include
Setting up CUPTI lib64
Configuration finished
```

However the first bazel build step results in the following error:

```
(py35)Dans-iMac:tensorflow dan$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
ERROR: /Users/dan/tensorflow/tensorflow/contrib/session_bundle/BUILD:160:1: //tensorflow/contrib/session_bundle:manifest_proto_py: no such attribute 'imports' in 'py_library' rule.
ERROR: /Users/dan/tensorflow/tensorflow/tools/pip_package/BUILD:23:1: Target '//tensorflow/contrib/session_bundle:all_files' contains an error and its package is in error and referenced by '//tensorflow/tools/pip_package:build_pip_package'.
ERROR: Loading failed; build aborted.
INFO: Elapsed time: 0.092s
```

I tried looking at build files, but don't know bazel well enough to independently trace this further back.

All of this is using commit `19bda20635c91060996fe44fe201875b3b9ae7a2`
"
2908,cond,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2907,cond,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2906,cond,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2905,Why has the RNN API changed so drastically?,"The new 0.9 version has 3 changes which has broken my existing functionality.
1. Have to use tensorflow.python.ops.rnn_cell instead of tensorflow.models.rnn.rnn_cell
2. Have to use cell(inputs, state..) instead of rnn.rnn(cell, inputs, state ...)
3. Initial_state keyword arg has been removed
4. Worst of all, i can't find any mention of variable sequence length in the new version of rnn_cell code

Can someone at least advice on how to use variable sequence lengths in this version? For now I'm reverting back to 0.8 so my code works again
"
2903,Importing Gtk before tensorflow causes crash,"### Environment info

Ubuntu 16.04
`uname -a
Linux p900 4.4.0-22-generic #40-Ubuntu SMP Thu May 12 22:03:46 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux`

Installed version of CUDA and cuDNN: 
Cuda compilation tools release 7.5, V7.5.17 and CUDNN is v 4

`ls -l /usr/local/cuda-7.5/lib/libcud*
-rw-r--r-- 1 root root 189170 Jun  2 10:18 /usr/local/cuda-7.5/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Jun  2 10:18 /usr/local/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Jun  2 10:18 /usr/local/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Jun  2 10:18 /usr/local/cuda-7.5/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Jun  2 10:18 /usr/local/cuda-7.5/lib/libcudart_static.a`

pip package installed:
`tensorflow-0.9.0rc0-cp35-cp35m-linux_x86_64.whl`

Output of `python3 -c ""import tensorflow; print(tensorflow.__version__)""`:
...
`0.9.0rc0`

Python version:
Python 3.5.1+

Gtk version:
3.0
### Steps to reproduce
1. `import gi`
2. `from gi.repository import Gtk`
3. `import tensorflow`
### What I have tried
1. Removed any Ubuntu protobuf package (Ubuntu package is v 2.6.1):
   `sudo apt purge protobuf*`
2. Upgraded protobuf via pip3:
   `pip3 install --upgrade protobuf`
   ...
   `Requirement already up-to-date: protobuf in /usr/local/lib/python3.5/dist-packages
   Requirement already up-to-date: six>=1.9 in /usr/lib/python3/dist-packages (from protobuf)
   Requirement already up-to-date: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf)`
3. Checked protobuf version installed via pip3:
   `ls /usr/local/lib/python3.5/dist-packages/proto*`
   `/usr/local/lib/python3.5/dist-packages/protobuf-3.0.0b2-py2.7-nspkg.pth`
   
   `/usr/local/lib/python3.5/dist-packages/protobuf-3.0.0b2.dist-info:`
   `DESCRIPTION.rst  INSTALLER  METADATA  metadata.json  namespace_packages.txt  RECORD  top_level.txt  WHEEL`
### Output after importing tensorflow

`[libprotobuf FATAL google/protobuf/stubs/common.cc:61] This program requires version 3.0.0 of the Protocol Buffer runtime library, but the installed version is 2.6.1.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in ""external/protobuf/src/google/protobuf/any.pb.cc"".)
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  This program requires version 3.0.0 of the Protocol Buffer runtime library, but the installed version is 2.6.1.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in ""external/protobuf/src/google/protobuf/any.pb.cc"".)
Aborted (core dumped)`
### Additional comments

As before ( #1373) this ONLY occurs when importing Gtk BEFORE tensorflow. The opposite order causes no crash, nor have I experienced any other crashes associated with tensorflow.

Curiously, when using version 0.8 of tensorflow, a very similar crash was caused by the opposite order of import (ie tensorflow before Gtk), but in that case the output was that: `This program requires version 2.6.1 of the Protocol Buffer runtime library, but the installed version is 3.0.0.` That is, the problem seemed to be caused by the reverse relationship between the protobuf versions. However, when upgrading tensorflow, I did not change the protobuf version. It was kept the same throughout.
"
2902,build_pip_package fails with locally installed python3: script unsets LD_LIBRARY_PATH,"build_pip_package fails here with

`ERROR: /path/to/src/tensorflow/tensorflow/contrib/session_bundle/example/BUILD:38:1: Executing genrule //tensorflow/contrib/session_bundle/example:half_plus_two failed: bash failed: error executing command`

caused by

`error while loading shared libraries: libpython3.5m.so.1.0: cannot open shared object file: No such file or directory`

executing

`(cd path/to/execroot/tensorflow && \
  exec env - \
    PATH=somepath \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; rm -rf /tmp/half_plus_two; path_to/python3 bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two`

it looks like

`exec env -`

unsets LD_LIBRARY_PATH

and therefore python3 cannot find its libraries anymore

Installation of tensorflow 0.8 works
"
2901,problem in checkpoint,"I used tf 0.9. 

When I restore the checkpoint i get the error:

Traceback (most recent call last):

  File ""<ipython-input-42-7082fb551371>"", line 1, in <module>
    runfile('/media/m/E/Deep/proj/1/t.py', wdir='/media/m/E/Deep/proj/1')

  File ""/home/m/anaconda3/lib/python3.5/site-packages/spyderlib/widgets/externalshell/sitecustomize.py"", line 714, in runfile
    execfile(filename, namespace)

  File ""/home/m/anaconda3/lib/python3.5/site-packages/spyderlib/widgets/externalshell/sitecustomize.py"", line 89, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""/media/m/E/Deep/proj/1/t.py"", line 70, in <module>
    saver.restore(sess, ckpt.model_checkpoint_path) # restore all variables

  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1105, in restore
    {self.saver_def.filename_tensor_name: save_path})

  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 333, in run
    The optional `options` argument expects a [`RunOptions`] proto. The options

  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 573, in _run
    elif isinstance(fetches, dict):

  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 648, in _do_run
    for fetch, result in zip(unique_fetches, results):

  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 668, in _do_call
    """"""Runs a step based on the given fetches and feeds.

NotFoundError: Tensor name ""global_step_7"" not found in checkpoint files ./ckpt_dir/model.ckpt-0
     [[Node: save_18/restore_slice_438 = RestoreSlice[dt=DT_INT32, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save_18/Const_0, save_18/restore_slice_438/tensor_name, save_18/restore_slice_438/shape_and_slice)]]
Caused by op 'save_18/restore_slice_438', defined at:
  File ""/home/m/anaconda3/lib/python3.5/site-packages/spyderlib/widgets/externalshell/start_ipython_kernel.py"", line 205, in <module>
    **ipythonkernel**.start()
  File ""/home/m/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py"", line 442, in start
    ioloop.IOLoop.instance().start()
  File ""/home/m/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py"", line 162, in start
    super(ZMQIOLoop, self).start()
  File ""/home/m/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py"", line 883, in start
    handler_func(fd_obj, events)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(_args, *_kwargs)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/home/m/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(_args, *_kwargs)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(_args, *_kwargs)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 391, in execute_request
    user_expressions, allow_stdin)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py"", line 199, in do_execute
    shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2723, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2831, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/m/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2885, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-42-7082fb551371>"", line 1, in <module>
    runfile('/media/m/E/Deep/proj/1/t.py', wdir='/media/m/E/Deep/proj/1')
  File ""/home/m/anaconda3/lib/python3.5/site-packages/spyderlib/widgets/externalshell/sitecustomize.py"", line 714, in runfile
    execfile(filename, namespace)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/spyderlib/widgets/externalshell/sitecustomize.py"", line 89, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)
  File ""/media/m/E/Deep/proj/1/t.py"", line 57, in <module>
    saver = tf.train.Saver()
  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 845, in __init__
    restore_sequentially=restore_sequentially)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 515, in build
    filename_tensor, vars_to_save, restore_sequentially, reshape)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 271, in _AddRestoreOps
    values = self.restore_op(filename_tensor, vs, preferred_shard)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 186, in restore_op
    preferred_shard=preferred_shard)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/io_ops.py"", line 201, in _restore_slice
    file_pattern, tensor_name, shape_and_slice, base_type,
  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 325, in _restore_slice
    def _restore_slice(file_pattern, tensor_name, shape_and_slice, dt,
  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2249, in create_op
    # specified for this op_type.
  File ""/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1224, in __init__
    raise TypeError(""Control input must be an Operation, ""

how can i solve this problem?
"
2900,When will the installation support cuDNN 5 ?,
2899,[make] gen_file_lists.sh output to wrong directory,"The gen_file_lists.sh script in contrib/makefile outputs the generated lists to the incorrect directory:

```
bazel query 'kind(""source file"", deps(//tensorflow/core:android_tensorflow_lib))' | \
grep ""//tensorflow/.*\.cc$"" | \
grep -v ""gen_proto_text"" | \
grep -E -v ""jpeg"" | \
grep -E -v ""png"" | \
sed -E 's#^//##g' | \
sed -E 's#:#/#g' \
> make/tf_cc_files.txt
```

The ""make/"" should be removed as ""make"" expects the lists to be in the same directory as the Makefile.
"
2897,It is too painful to install a gpu-surpport edition on Ubuntu 16.04,
2896,compile_ios_tensorflow.sh failing,"Hi there

I'm following the instructions on your website to build a version of tensor flow for iOS:

https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile

Unfortunately when I get to final step:

tensorflow/contrib/makefile/compile_ios_tensorflow.sh

It errors with:

 /Projects/ML/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core-armv7.a -arch armv7 -miphoneos-version-min=9.2 -Xlinker -S -Xlinker -x -Xlinker -dead_strip -all_load -L/Projects/ML/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib -lz -lstdc++ -lprotobuf -lm
Undefined symbols for architecture armv7:
  ""tensorflow::shape_inference::InferenceContext::Merge(tensorflow::shape_inference::Shape const_, tensorflow::shape_inference::Shape const_, tensorflow::shape_inference::Shape const*_)"", referenced from:
      tensorflow::$_0::operator()(tensorflow::shape_inference::InferenceContext_) const in libtensorflow-core-armv7.a(math_ops.o)
ld: symbol(s) not found for architecture armv7
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: **\* [/Projects/ML/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark] Error 1
- '[' 2 -ne 0 ']'
- echo 'armv7 compilation failed.'
  armv7 compilation failed.
- exit 1
"
2895,fatal issue with _reverse_seq in rnn.py,"I was trying to code bidirectional seq2seq on my own. I made a `cell with a embedding wrapper`, 
following is the code of _reverse_seq which is from tensorflow ver r0.7(r0.9 doesn't work either)

``` javascript
def _reverse_seq(input_seq, lengths):
  """"""Reverse a list of Tensors up to specified lengths.
  Args:
    input_seq: Sequence of seq_len tensors of dimension (batch_size, depth)
    lengths:   A tensor of dimension batch_size, containing lengths for each
               sequence in the batch. If ""None"" is specified, simply reverses
               the list.
  Returns:
    time-reversed sequence
  """"""
  if lengths is None:
    return list(reversed(input_seq))

  for input_ in input_seq:
    input_.set_shape(input_.get_shape().with_rank(2))


  # Join into (time, batch_size, depth)
  s_joined = array_ops.pack(input_seq)

  # Reverse along dimension 0
  s_reversed = array_ops.reverse_sequence(s_joined, lengths, 0, 1)
  # Split again into list
  result = array_ops.unpack(s_reversed)
  return result
```

it requires input_seq which is `sequence of seq_len tensors of dimension (batch_size, depth)`
However, pay attention to a part of `def bidirectional_rnn` : 

``` javascript
with vs.variable_scope(name + ""_FW""):
    output_fw, _ = rnn(cell_fw, inputs, initial_state_fw, dtype,
                       None) # modified
  #print (inputs[0].get_shape())
  #print (sequence_length.get_shape())

  # Backward direction
  with vs.variable_scope(name + ""_BW""):
    tmp, _ = rnn(cell_bw, _reverse_seq(inputs, sequence_length),
                 initial_state_bw, dtype, None) #modified
  output_bw = _reverse_seq(tmp, sequence_length)
```

just because I use a cell with a embedding wrapper, those inputs i feed are not embedded vector but one-hot encodded, and it has confliction with the requirement of _reverse_seq input.
"
2894,how to use multiple parameters server under synchronous gradient update,"recently, I try to train the inceptionV3 mode with multi machine. As described in [https://github.com/tensorflow/models/tree/master/inception](url),  tutorial describes how to train inceptionv3 using tensorflow  distributed version, but only use a parameter server.
I want to know how to use multiple parameters server under synchronous gradient update, anyone can give guidance?
"
2890,Tensorflow Session hangs when tf.Session() is created,"### Environment info

Operating System:
 Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(
CUDA =7.5 cuDNN=4 

ashwin@smile-titan:~$ ls -l /usr/local/cuda-7.5/lib64/libcud*
-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 61453024 Apr 20 17:27 /usr/local/cuda-7.5/lib64/libcudnn.so
-rwxr-xr-x 1 root root 61453024 Apr 20 17:27 /usr/local/cuda-7.5/lib64/libcudnn.so.4
-rwxr-xr-x 1 root root 61453024 Apr 20 17:27 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Apr 20 17:27 /usr/local/cuda-7.5/lib64/libcudnn_static.a

If installed from binary pip package, provide:
1. Installed tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl  (gpu support one)
2. Tensorflow version: 0.9.0rc0
### What have you tried?
1. When i do 

```
 import  tensorflow as tf 
 sess=tf.Session()
```

The program hangs. I am not able to do exit from the program as well. It was working fine 2 weeks before. I don't know whats wrong with this. 
"
2885,Tensorflow import error despite correct installation,"Hi everyone!
### Environment info

Operating System: Ubuntu 16.04 LTS
Graphics card: GTX 1080 Founders Edition
Installed version of CUDA: 8.0 RC
Installed version of cuDNN: v5 (May 27, 2016), for CUDA 8.0 RC

Output of `ls -l /usr/local/cuda/lib64/libcud*`:

```
-rw-r--r-- 1 root root   560184 juin  15 16:06 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 juin  15 16:06 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 juin  15 16:06 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 juin  15 16:06 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 juin  15 16:06 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 78065952 juin  15 16:10 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 78065952 juin  15 16:10 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 78065952 juin  15 16:10 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 68709594 juin  15 16:10 /usr/local/cuda/lib64/libcudnn_static.a
```

Tensorflow installed from source, last commit hash: 7644b3dd001355bf5e3734e541d9955277447601
## Problem

When I open the terminal and type
`$ python`
and then
`>>> import tensorflow`
I get:

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: No module named tensorflow
```
### Steps to reproduce

Perform 'installing from sources' tutorial step by step https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installing-from-sources for a GPU-enabled Tensorflow on Linux 64 bits
### What have you tried?

1- Re-installing step by step: no change
2- Typing in terminal `$ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu` returns the correct output as indicated in the tutorial
3- Typing in terminal `$ bazel test -c opt //tensorflow/python:graph_util_test --test_output=streamed` returns 

```
OK
Converted 1 variables to const ops.
Converted 1 variables to const ops.
Target //tensorflow/python:graph_util_test up-to-date:
  bazel-bin/tensorflow/python/graph_util_test
INFO: Elapsed time: 379.479s, Critical Path: 299.62s
//tensorflow/python:graph_util_test                                      PASSED in 1.1s

Executed 1 out of 1 test: 1 test passes.
```

4- Adding `/home/paul/Downloads/tensorflow` to `PYTHONPATH` and then retry `import tensorflow`. This time I get:

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/paul/Downloads/tensorflow/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/home/paul/Downloads/tensorflow/tensorflow/python/__init__.py"", line 48, in <module>
    from tensorflow.python import pywrap_tensorflow
ImportError: cannot import name pywrap_tensorflow
```

I don't know what else to do to make this work. Would you have an idea?

Thanks a lot in advance,
Paul
"
2883,iOS example DecodeJpeg issue with Image Retraining model,"### Environment info

Operating System: iOS
### Steps to reproduce
1. Follow the contrib/makefile/README to install the tensorflow iOS core lib
2. Create my own model with the Image Retraining tutorial
3. Run the iOS example, error is logged.
### Logs or other output that would be helpful

`Running model failed:Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs
    [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false](DecodeJpeg/contents)]]`
### Related to
#2754 except that I want to use the pd file generated from the Image Retraining tutorial
"
2882,TensorFlow cannot detect my GPU,"I have a Ubuntu 14.04.4 with Titan X, cuda 7.5 and cudnn v4

cuda 7.5 was installed by a run file, just like I used to installed Caffe.
Environment variables have been added to /etc/profile  and ~/.bashrc 
A file named cuda.conf have been added to /etc/ld.so.conf.d/ 

I installed TensorFlow via pip, using the following command:

$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl

I followed the install instruction carefully, but I still met some issues.

'>>> import tensorflow as tf
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally`

`>>> sess = tf.Session()

E tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_UNKNOWN
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: DeepLearning
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: DeepLearning
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: 352.79
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.79  Wed Jan 13 16:17:53 PST 2016
GCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.3) 
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 352.79
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:226] kernel version seems to match DSO: 352.79
I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.`

It seems that TensorFlow cannot find my GPU.
I have no idea why these issues occur.
Please help, thanks 
"
2880,tf.flags.DEFINE_boolean is broken for flags containing dashes,"`tf.flags.DEFINE_boolean` does not replace dashes with underscores when adding the negated flag, which results in a bug for flags containing dashes.
### Environment info

Operating System: Mac OSX 10.11.5
Pip Package: https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0rc0-py3-none-any.whl
TensorFlow Version: 0.9.0rc0
### Steps to reproduce
- `foo.py`:

``` python
import tensorflow as tf

tf.flags.DEFINE_boolean('foo-bar', True, ""Foo Bar"")
tf.flags.FLAGS._parse_flags()
print(tf.flags.FLAGS.__flags)
```
### What have you tried?
- `$ python foo.py`: `{'foo_bar': True, 'foo-bar': True}`
- `$ python foo.py --foo-bar`: `{'foo_bar': True, 'foo-bar': True}`
- `$ python foo.py --nofoo-bar`: `{'foo_bar': True, 'foo-bar': False}`

In the last example it is impossible to get the False value of the flag, `tf.flags.FLAGS.foo-bar` results in an AttributeError, because the dash is interpreted as a minus and `FLAGS.foo` does not exist.

In order to support flags with dashes, Python's argparse replaces dashes with underscores ([docs](https://docs.python.org/dev/library/argparse.html#dest), [code](https://github.com/python/cpython/blob/master/Lib/argparse.py#L1471)).

Fixing this bug should be as simple as substituting `flag_name` with `flag_name.replace('-', '_')` in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/flags.py#L106, but I haven't tested this yet.
"
2877,eigen_spatial_convolutions.h: reading of uninitialized variable 'k',"It appears that `k` is not initialized before being read below. From eigen_spatial_convolutions.h:848:

```
       for (Index k; k < depth; k++) {
          block[0] = dm0.loadCoeffStandard(k);
          block[1] = dm1.loadCoeffStandard(k);
          block[2] = dm2.loadCoeffStandard(k);
          block[3] = dm3.loadCoeffStandard(k);
          block += 4;
        }
      } else {
        for (Index k; k < depth; k++) {
          block[0] = dm0(k);
...
```

Am I missing something here?
"
2874,FixedLenFeature with dimensions of unknown size fails with strange error,"``` python
import tensorflow as tf

example = tf.train.Example(
  features=tf.train.Features(
    feature={'a': tf.train.Feature(int64_list=tf.train.Int64List(value=[1]))}))
serialized = example.SerializeToString()
features = {'a': tf.FixedLenFeature([None], tf.int64)}
parsed = tf.parse_single_example(serialized, features)
```

```
>>> parsed
{'a': <tf.Tensor 'ParseSingleExample_5/Squeeze_a:0' shape=(?,) dtype=int64>}
>>> parsed['a'].eval()
InvalidArgumentError: Shape [-1] has negative dimensions
```

It would be nice to get an informative `ValueError` at graph construction time.
"
2873,Perform CUDA autoconfiguration in Skylark,"Moving the CUDA autoconfiguration to a Skylark repository rule, similar to Bazel's [`cc_configure`](https://github.com/bazelbuild/bazel/blob/master/tools/cpp/cc_configure.bzl), will fix many pain points and build issues that have been reported. This will also eventually allow projects such as Serving and Magenta to include TensorFlow as a Bazel workspace dependency rather than a Git submodule.

Related to this is moving Python detection to a Skylark repository rule (see #1404).

Internal tracking bug: b/29006900
"
2868,"tf.concat(-1, list_of_tensors) should fail at graph build time, not eval time","Instead it gives an erroneous result:

```
>>> tf.concat(-1, [tf.range(3), tf.range(3)])
<tf.Tensor 'concat_2:0' shape=(6, 3) dtype=int32>
```

When you run `.eval()` you get the expected error message:
`InvalidArgumentError: ConcatOp : Expected concatenating dimensions in the range [0, 1), but got -1`

Of course, it would be even better if negative indices counted axes from the end (like in NumPy), but that's a different matter...
"
2867,Support size 0 tensors with parse_example and parse_single_example,"Currently, this fails `InvalidArgumentError: Name: <unknown>, Feature: a is required but could not be found.`:

```
import tensorflow as tf
sess = tf.InteractiveSession()

features = {'a': tf.FixedLenFeature([0], tf.int64, [])}
serialized = tf.placeholder(tf.string, [])
parsed = tf.parse_single_example(serialized, features)

example_str = tf.train.Example().SerializeToString()
sess.run(parsed['a'], feed_dict={serialized: example_str})
```

(The same is true for `tf.parse_example`.)

This sort of thing may seem useless, but can be handy for writing generic code that handles variable sized input (with fixed size for each graph).
"
2865,Docker GPU CUDA failure fails to be caught by CI,"Two issues:
1. It looks like the recent docker images, including `r0.9rc0-devel-gpu` and `nightly-devel-gpu` (as of June 14) are failing to load libcuda. The `latest-devel-gpu` seems to work fine.
2. The CI tests seem to be missing these failures and reporting success.
### Environment info

**Host:**
  Ubuntu 15.10
  GTX 980, driver version 352.63
  docker 1.11.2 build b9f10c9
  using nvidia-docker 1.0.0.rc.2-1_amd64

**Container images** (a la https://hub.docker.com/r/tensorflow/tensorflow/tags/):
  `r0.9rc0-devel-gpu` (bff7093a7715, built ~June 6)
  `nightly-devel-gpu` (d285481a3e65, built ~June 14)
  `latest-devel-gpu` (9e12b89c50bb, built ~two months ago)
### Steps to reproduce

(and installed CUDA versions)

Here's where the fun starts. I'll do this via the docker commands I ran, per container.

For container `r0.9rc0-devel-gpu`:

```
$ nvidia-docker run -it tensorflow/tensorflow:r0.9rc0-devel-gpu bash -c echo LD_LIBRARY_PATH: $LD_LIBRARY_PATH
LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:

$ nvidia-docker run -it tensorflow/tensorflow:r0.9rc0-devel-gpu bash -c ls -l /usr/local/nvidia/lib64/libcuda*
lrwxrwxrwx 1  999  999       41 Jun 13 21:38 /usr/local/nvidia/lib64/libcuda.so.1 -> /usr/local/nvidia/lib64/libcuda.so.352.63
-rw-r--r-- 2 root root 14283432 Nov  8  2015 /usr/local/nvidia/lib64/libcuda.so.352.63

$ nvidia-docker run -it tensorflow/tensorflow:r0.9rc0-devel-gpu bash -c python -c ""import tensorflow; print tensorflow.__version__""
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcuda.so. LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: 03e202e5d433
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.63  Sat Nov  7 21:25:42 PST 2015
GCC version:  gcc version 4.9.3 (Ubuntu 4.9.3-5ubuntu1) 
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 352.63.0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1076] LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1077] failed to find libcuda.so on this system: Failed precondition: could not dlopen DSO: libcuda.so; dlerror: libcuda.so: cannot open shared object file: No such file or directory
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.9.0rc0
```

For container `nightly-devel-gpu`:

```
$ nvidia-docker run -it tensorflow/tensorflow:nightly-devel-gpu bash -c echo LD_LIBRARY_PATH: $LD_LIBRARY_PATH
LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:

$ nvidia-docker run -it tensorflow/tensorflow:nightly-devel-gpu bash -c ls -l /usr/local/nvidia/lib64/libcuda*
lrwxrwxrwx 1  999  999       41 Jun 13 21:38 /usr/local/nvidia/lib64/libcuda.so.1 -> /usr/local/nvidia/lib64/libcuda.so.352.63
-rw-r--r-- 2 root root 14283432 Nov  8  2015 /usr/local/nvidia/lib64/libcuda.so.352.63

$ nvidia-docker run -it tensorflow/tensorflow:nightly-devel-gpu bash -c python -c ""import tensorflow; print tensorflow.__version__""
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcuda.so. LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: 1a40427098ed
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.63  Sat Nov  7 21:25:42 PST 2015
GCC version:  gcc version 4.9.3 (Ubuntu 4.9.3-5ubuntu1) 
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 352.63.0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1077] LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1078] failed to find libcuda.so on this system: Failed precondition: could not dlopen DSO: libcuda.so; dlerror: libcuda.so: cannot open shared object file: No such file or directory
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.8.0
```

For container `latest-devel-gpu`:

```
$ nvidia-docker run -it tensorflow/tensorflow:latest-devel-gpu bash -c echo LD_LIBRARY_PATH: $LD_LIBRARY_PATH
LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:

$ nvidia-docker run -it tensorflow/tensorflow:latest-devel-gpu bash -c ls -l /usr/local/nvidia/lib64/libcuda*
lrwxrwxrwx 1  999  999       41 Jun 13 21:38 /usr/local/nvidia/lib64/libcuda.so.1 -> /usr/local/nvidia/lib64/libcuda.so.352.63
-rw-r--r-- 2 root root 14283432 Nov  8  2015 /usr/local/nvidia/lib64/libcuda.so.352.63

$ nvidia-docker run -it tensorflow/tensorflow:latest-devel-gpu bash -c python -c ""import tensorflow; print tensorflow.__version__""
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.8.0
```

So it looks like the GPU libraries are failing on the first two docker images. What's interesting to note here is also that all three python statements still execute without error. I.E., running `print tensorflow.__version__` completes (and prints the correct version) and python exits with return code 0, even though the GPU failed to load properly. This is not a bug, since the fallback behavior of running on the CPU should still work. However, it also seems this is causing problems for the CI tests, since it isn't detecting a failure:

It seemed odd to me that these docker images weren't working, since you use them for CI. So I checked the CI logs, and _they're the same_. For instance, for the docker CI build for the nightly GPU devel image, this is a snippet from the log showing the output from the seventh test:

(full source is http://ci.tensorflow.org/view/Nightly/job/nightly-docker-gpu/TF_DOCKER_BUILD_IS_DEVEL=YES,TF_DOCKER_BUILD_TYPE=GPU,label=gpu-linux/lastBuild/consoleFull)

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcuda.so. LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: 883e6f728cb9
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.79  Wed Jan 13 16:17:53 PST 2016
GCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.1) 
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 352.79.0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1077] LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1078] failed to find libcuda.so on this system: Failed precondition: could not dlopen DSO: libcuda.so; dlerror: libcuda.so: cannot open shared object file: No such file or directory
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:147] no NVIDIA GPU device is present: /dev/nvidia0 does not exist
I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.
(7 / 7) tutorial test-on-install PASSED: translate_test  (Elapsed time: 8997 ms)
tutorial test-on-install test(s):  7 passed; 0 failed; 0 skipped
```

I'm still learning Docker, so it's entirely possible that I've made some blunder here, but it does seem like there's something going on here between the docker images.
"
2862,Tensorboard: non-square images are overlapped,"### Environment info

Operating System: Ubuntu 14.04

If installed from sources, provide the commit hash:
592675b2b8d1cabbf923638942ea6f200abe353a
### Steps to reproduce
1. Log some non-square (rectangle, 72x105 in my case) images (at least two) with SummaryWriter.
2. Load the log file with tensorboard.
3. Now, you will see the images are overlapped on images tab.
### What have you tried?
1. I tried to fix the CSS with Chrome debugger.<br />
   I changed `height` property in `.tf-image-grid-0 .tag-name-cell.tf-image-grid` and `.tf-image-grid-0 .image-cell.tf-image-grid` to `auto`, and it seems to be good.<br />
   However, I don't know what files need to be patched to apply this change.
### Logs or other output that would be helpful

Here is a screenshot of overlapped images.
`input/image/1`, `input/image/2` is not being shown properly.
Last image isn't overlapped.

<img width=""620"" alt=""2016-06-15 4 20 07"" src=""https://cloud.githubusercontent.com/assets/5977817/16056438/7631b366-32b0-11e6-940e-1dfb7f532990.png"">
"
2860,[Installation problem] ImportError: No module named google.protobuf,"Installation problem
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: None
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
### Which pip package you installed.
- adium-theme-ubuntu (0.3.4)
- apt-xapian-index (0.45)
- argparse (1.2.1)
- auxlib (0.0.39)
- chardet (2.0.1)
- colorama (0.2.5)
- command-not-found (0.3)
- conda (4.0.8)
- configobj (4.7.2)
- Cython (0.20.1post0)
- debtagshw (0.1)
- decorator (3.4.0)
- defer (1.0.6)
- deluge (1.3.6)
- dirspec (13.10)
- dnspython (1.11.1)
- duplicity (0.6.23)
- enum34 (1.1.6)
- gyp (0.1)
- h5py (2.2.1)
- html5lib (0.999)
- httplib2 (0.8)
- ipython (1.2.1)
- Jinja2 (2.7.2)
- Landscape-Client (14.12)
- lockfile (0.8)
- lxml (3.3.3)
- Mako (0.9.1)
- MarkupSafe (0.18)
- matplotlib (1.3.1)
- mercurial (2.8.2)
- nose (1.3.1)
- numexpr (2.2.2)
- numpy (1.11.0)
- oauthlib (0.6.1)
- oneconf (0.3.7.14.04.1)
- PAM (0.4.2)
- pexpect (3.1)
- Pillow (2.3.0)
- pip (1.5.4)
- piston-mini-client (0.7.5)
- pomodoro-indicator (0.1.0)
- powerline-status (2.2.dev9999-git.841c25f6b61e1632d7f2343289c52698bcb9b805)
- protobuf (3.0.0b2)
- psutil (3.2.2)
- pycosat (0.6.1)
- pycrypto (2.6.1)
- pycups (1.9.66)
- pycurl (7.19.3)
- pygame (1.9.1release)
- pygobject (3.12.0)
- pyne (0.5.0-rc1)
- pyOpenSSL (0.13)
- pyparsing (2.0.1)
- pyrtlsdr (0.2.0)
- pyserial (2.6)
- pysmbc (1.0.14.1)
- PyTAPS (1.4)
- python-apt (0.9.3.5ubuntu2)
- python-dateutil (1.5)
- python-debian (0.1.21-nmu2ubuntu2)
- python-libtorrent (0.16.13)
- pytz (2012c)
- pyxdg (0.25)
- PyYAML (3.11)
- reportlab (3.0)
- requests (2.2.1)
- scipy (0.13.3)
- sessioninstaller (0.0.0)
- setuptools (23.0.0)
- simplegeneric (0.8.1)
- six (1.10.0)
- software-center-aptd-plugins (0.0.0)
- sympy (0.7.4.1)
- system-service (0.1.6)
- tables (3.1.1)
- tensorflow (0.9.0rc0)
- Twisted-Core (13.2.0)
- Twisted-Web (13.2.0)
- unity-launcher-folders (14.09.4)
- unity-lens-photos (1.0)
- urllib3 (1.7.1)
- vboxapi (1.0)
- wheel (0.29.0)
- wsgiref (0.1.2)
- xdiagnose (3.6.3build2)
- zope.interface (4.0.5)
### The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/**init**.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/**init**.py"", line 58, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/**init**.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 6, in <module>
    from google.protobuf import descriptor as _descriptor
ImportError: No module named google.protobuf

Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.

If installed from sources, provide the commit hash:
### Steps to reproduce

I followed instructed steps to install tensorflow, however, my python seems to miss the googlebuf package. Weirdly, it does recognize tensorflow package under the same dist-packages folder.
### What have you tried?

I tried to modify the PYTHONPATH and reinstall tensorflow and pip several times.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
 ~  python
Python 2.7.11 |Anaconda 4.0.0 (64-bit)| (default, Dec  6 2015, 18:08:32) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
Anaconda is brought to you by Continuum Analytics.
Please check out: http://continuum.io/thanks and https://anaconda.org

> > > import tensorflow
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/**init**.py"", line 23, in <module>
> > >     from tensorflow.python import *
> > >   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/**init**.py"", line 58, in <module>
> > >     raise ImportError(msg)
> > > ImportError: Traceback (most recent call last):
> > >   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/**init**.py"", line 52, in <module>
> > >     from tensorflow.core.framework.graph_pb2 import *
> > >   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 6, in <module>
> > >     from google.protobuf import descriptor as _descriptor
> > > ImportError: No module named google.protobuf

Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.

"
2859,tf.train.exponential_decay examples use 32 bit number for batch,"As far as I can tell, `tf.train.exponential_decay` examples seem to use a 32-bit signed number for global_step, because the batch number is also a `tf.int32`.  This means that long runs can result in [unpleasant surprises](http://nyus.joshuawise.com/fml-tensorflow.png) with learning rates, which result in a frustrating experience for new users. [1]  Examples should be updated to initialize `batch` as a `dtype=tf.int64`.

I originally believed this to be a `tf.train.exponential_decay` bug, and wrote some code to minimize the issue.  I now understand that this comes from the variable, but you can have the below repro case anyway, because I think it makes it a little more obvious as to the kind of thing that can happen.  When you run it, you'll note a discontinuity between epoch 85 and 86 in learning rate that comes from `batch * batch_size` overflowing (and results in losing an evening's training...).

``` python

import tensorflow as tf

def main(argv=None):
  epoch_size = 25000000
  epoches = 100
  batch_size = 16384

  batch = tf.Variable(0) # <-- this line, in examples, should be changed to have dtype=tf.int64, with explanation of why
  learning_rate = tf.train.exponential_decay(
      0.01,
      batch * batch_size,
      epoch_size,
      0.95,
      staircase = True)
  loss = tf.Variable(0.0)
  eval_frequency = int(epoch_size / batch_size / 2)

  optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9) \
     .minimize(loss, global_step = batch)

  with tf.Session() as sess:
    tf.initialize_all_variables().run()

    for step in xrange(int(epoches * epoch_size) // batch_size):
      _, b, lr = sess.run([optimizer, batch, learning_rate])
      if step % eval_frequency == 0:
        print(""Step %d (epoch %.2f): batch %d, learning rate %.6f"" %
            (step, float(step) * batch_size / epoch_size, b, lr))

if __name__ == '__main__':
  tf.app.run()
```

_[1] No, I did not checkpoint midway through.  Yes, I have learned my lesson._
"
2858,[install problem] Tensorflow with Anaconda on Ubuntu,"On my Ubuntu 14.04, I have installed tensorflow from source, as specified in the Tensorflow Installation instructions and it works well.

Then I install anaconda but it changes the $PATH environment variable, so I cannot import tensorflow.
Following the instruction in http://stackoverflow.com/questions/33646541/tensorflow-and-anaconda-on-ubuntu, I created an environment and installed tensorflow in it, as specified in https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#anaconda-installation. I use this command `sudo pip install --upgrade $TF_BINARY_URL` to install tensorflow. But the tensorflow is not installed in this environment. It seems that it just updates the tensorflow I have installed previously. The terminal window is shown in the image:

I have solved this problem. Use `pip install --upgrade $TF_BINARY_URL` instead. Using sudo will install the package globally. 

![terminal](https://cloud.githubusercontent.com/assets/19935904/16053977/1d0deb32-3239-11e6-9875-f14eb6cc22b3.png)
"
2855,Jenkins test take dependencies from pip package instead of .runfiles directory,"TLDR; Jenkins looks for dependencies in `python2.7/site-packages/tensorflow/..` but it should look for them in `bazel-bin/.../test.runfiles/...`. Possibly related to https://github.com/tensorflow/tensorflow/issues/2844

I'm looking at a test failure in https://github.com/tensorflow/tensorflow/pull/2747, and it can't find a data dependency while running on Jenkins, meanwhile this test passes under `bazel test` in a fresh git clone.

More specifically, `bazel test tensorflow/contrib/immediate/mnist_inference_test` copies all Python files and data dependencies to `bazel-bin/tensorflow/contrib/immediate/mnist_inference_test.runfiles/`

However, from the path of the error, it seems it's looking for dependencies in `python2.7/site-packages/tensorflow/` instead of `.runfiles` directory. The path to convolutional.py should look like this `bazel-bin/tensorflow/contrib/immediate/mnist_inference_test.runfiles/org_tensorflow/tensorflow/models/image/mnist/convolutional.py`, instead of `site-packages`. When dependencies are resolved to `site-packages`,  this case failure is be expected, because while Python files are included in the PIP package, but  data dependencies of tests will not be.

```
Traceback (most recent call last):
  File ""/workspace/pip_test/tests/mnist_inference_test.py"", line 23, in testMnistInference
    test_data = convolutional.extract_data(test_data_filename, 10000)
  File ""/workspace/pip_test/venv/local/lib/python2.7/site-packages/tensorflow/models/image/mnist/convolutional.py"", line 83, in extract_data
    with gzip.open(filename) as bytestream:
  File ""/usr/lib/python2.7/gzip.py"", line 34, in open
    return GzipFile(filename, mode, compresslevel)
  File ""/usr/lib/python2.7/gzip.py"", line 94, in __init__
    fileobj = self.myfileobj = __builtin__.open(filename, mode or 'rb')
IOError: [Errno 2] No such file or directory: 'tensorflow/contrib/immediate/python/immediate/testdata/t10k-images-idx3-ubyte.gz'

```
"
2854,change weights during training,"Hi,
I train a model and save it to ckpt file.
The next think i want do to is to load the model and change some of his weights. I read the TF API and didn't find any way to do that. Am i missing something? Is there a way to change the weights during training?

thank a lot!
"
2852,I think 'class EmbeddingWrapper' has problem,"I found that there are some differences between r0.7 and r0.9 which is that : class EmbeddingWrapper in rnn_cell.py in r0.9 doens't has some @property values, just like `def input_size` , `def output_size` . and when i run rnn.rnn with embeded cell, it causes an NotImplementedError which is from RNNCell 's function

``` javascript
def __call__(self, inputs, state, scope=None):
    """"""Run this RNN cell on inputs, starting from the given state.

    Args:
      inputs: `2-D` tensor with shape `[batch_size x input_size]`.
      state: if `self.state_size` is an integer, this should be a `2-D Tensor`
        with shape `[batch_size x self.state_size]`.  Otherwise, if
        `self.state_size` is a tuple of integers, this should be a tuple
        with shapes `[batch_size x s] for s in self.state_size`.
      scope: VariableScope for the created subgraph; defaults to class name.

    Returns:
      A pair containing:
      - Output: A `2-D` tensor with shape `[batch_size x self.output_size]`.
      - New state: Either a single `2-D` tensor, or a tuple of tensors matching
        the arity and shapes of `state`.
    """"""
    raise NotImplementedError(""Abstract method"")
```

Did i do something wrong?
"
2851,How to reduce_max variable length sentences?,"When I use word-embedding to train model, variable-sentence-length is a problem that could hurt performance.
The task is same as [#2849](https://github.com/tensorflow/tensorflow/issues/2849) . I open this new issue because of variable-sentence-length problem.
The task is to classify each sentence into 10 classes. Each sentence is length of 1~30 words. Firstly I use embedding_lookup to get all 1~30 word-vectors, then I use tf.map_fn(lambda x:tf.reduce_max(x,0), ) to reduce each sentences 1~30 word-vectors into a single sentence vector. Then It put this sentence vector as DNN's input. The code is same as #2849:
[WE_example.py.txt](https://github.com/tensorflow/tensorflow/files/313877/WE_example.py.txt)

In the above code, I have to use 30 as sentence length. Because the tf.map_fn(tf.reduce_max(...))"" could only merge sub-matrixes of the same size, for example, the minibatch is [100, 30, 200], then all sub-matrixes are [30, 200], using ""tf.map_fn(tf.reduce_max(...))"" could merge each sub-matrix into [200]. 

But in the real world, sentences are of variable lengths. If I add padding data to the tail of sub-matrixes, I will not only give accuracy problem, but also bring more data to transfer between CPU&GPU, and also give more unneccesary computation cost.
The ideal solution is providing a powerful_reduce function to support reduce on sub-sections. For example, Five sentences' length are {3, 10, 7, 25, 2}. I gave powerful_reduce a matrix of size [3+10+7+25+2, 200], and a 1D array of content { 3, 10, 7, 25, 2}, it could return the reduce results of the five sub-matrixes, the result shape is [5, 200]. 
Another way is to provide a ""mask"" array as input parameter. The reduce_max operation will only operater on the items with mask 1, and skip the items with mask 0.
Previously I used CUDA Thrust Library, it could handle it by using ""for_each"". 

So, could tensorflow provide a powerful reduce_max function to support variable-size sub matrixes?
Another question is , I found my GPU usage is only about 20%, in order to improve the GPU usage, I prefer to run multiple processes on the same GPU card using distributed tensorflow. But I don't know how much GPU memory my process will occupy(the upper-bound). In another word, how could I safely decide the minimum ""x"" in ""tf.GPUOptions(per_process_gpu_memory_fraction = x)""?

Thanks a lot in advance~
"
2850,Saver() not saving as .ckpt file,"I'm trying to save and restore a model. From all the support I have found [here](https://www.tensorflow.org/versions/r0.9/how_tos/variables/index.html) & [here](http://stackoverflow.com/questions/33759623/tensorflow-how-to-restore-a-previously-saved-model-python) `Saver.save()` is supposed to save a model file of type `.ckpt` & then `Saver.restore()` is supposed to used that file name coupled with the directory it is in. However, my code does not save the files as .ckpt files, it just saves them as binary files. I could be wrong on that. My reasoning is that when I call `Saver.restore()` it returns None.

The files are being saved as `model.ckpt-10` and then `model.ckpt-20` and so on. I have the checkpoint text file. I've tried using that as well, but no luck.

```
saver = tf.train.Saver()
TRAIN_FLAG = 1

# Launch the graph
with tf.Session() as sess:
    sess.run(init)
    # writer = tf.train.SummaryWriter(""/tmp/logs"", sess.graph_def)
    if TRAIN_FLAG:
        from tensorflow.contrib.learn.python.learn.datasets.scroll import scroll_data
        data = scroll_data.read_data('/home/kendall/Desktop/')
        step = 1
        flag = 0
        while flag == 0:
            batch_y, batch_x = data.train.next_batch(batch_size)
            batch_x = batch_x.reshape((batch_size, n_input))
            batch_y = batch_y.reshape((batch_size, n_classes))
            # Run optimization op (backprop)
            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})
            if step % display_step == 0:
                flag = 1
                save_path = ""model.ckpt""
                saver.save(sess, save_path, global_step=step)
                # Calculate batch accuracy
                acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})
                # Calculate batch loss
                loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})
                print ""Iter "" + str(step*batch_size) + "", Minibatch Loss= "" + \
                      ""{:.6f}"".format(loss) + "", Training Accuracy= "" + \
                      ""{:.5f}"".format(acc)
            step += 1
        print ""Optimization Finished!""
else:
    pdb.set_trace()
    ckpt = tf.train.get_checkpoint_state(""/home/kendall/Academic/Summer\ 2016/Programs/"", ""my-model-7001"")
    saver.restore(sess, ckpt.model_checkpoint_path)
    im = Image.open('/home/kendall/Desktop/HA900_frames/frame0635.tif')
    batch_x = np.array(im)
    prediction = sess.run(optimizer, feed_dict={x: batch_x})
    print prediction
```
"
2849,Lack of support for word-embedding on GPU,"Dear experts,

I faced some problems when training model with word-embedding. For simplify the case, I make a helloworld example in this file:
[WE_example.py.txt](https://github.com/tensorflow/tensorflow/files/313712/WE_example.py.txt)

The task is to classify each sentence into 10 classes. Each sentence is length of 30 words. Firstly I use embedding_lookup to get all 30 word-vectors, then I use tf.map_fn(lambda x:tf.reduce_max(x,0), ) to reduce each sentences 30 word-vectors into a single sentence vector. Then It put this sentence vector as DNN's input.

The following are problems & questions:
a.    If I use tf.train.RMSPropOptimizer as optimizer, it reports NotImplementedError, the details is in the following stderr file:
[RMSPropOptimizer_NotImplemented.stderr.txt](https://github.com/tensorflow/tensorflow/files/313717/RMSPropOptimizer_NotImplemented.stderr.txt)
So, is there a plan to implement RMSPropOptimizers support for word-embedding in next release?

b.    Then I replace tf.train.RMSPropOptimizer by tf.train.MomentumOptimizer.  It works! But the GPU usage is only around 22%. I think putting embedding matrix on host memory (/cpu:0) causes data-transfer delay, which may lower down the GPU usage. Then I remove the with tf.device(/cpu:0) in line 21(just before definition of word-embedding variable), to put the word-embedding matrix into GPU memory. And run it again. It shows tensorflow.python.framework.errors.InvalidArgumentError: AttrValue must not have reference type value of float_ref. 
I put the stdout & stderr as follows:
[MomentumOptimizer_on_GPU.stdout.txt](https://github.com/tensorflow/tensorflow/files/313725/MomentumOptimizer_on_GPU.stdout.txt)
[MomentumOptimizer_on_GPU.stderr.txt](https://github.com/tensorflow/tensorflow/files/313727/MomentumOptimizer_on_GPU.stderr.txt)

It seems that putting word-embedding into GPU memory is not supported by all operators. I also found the same issue in [word2vec_basic.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py) , the line 144 # Ops and variables pinned to the CPU because of missing GPU implementation .
And also [word2vec.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/embedding/word2vec.py) Ln508. It also put word-embedding definition onto /cpu:0.

Word-embedding is very popular in NLP domain. It is usually very large(more than 1GB in internet-level data). So putting it from host memory side to GPU global memory side may save a lot of data-transfer time cost. Is there any plan to fully support it in ALL operators in future release?

c.    Then I replace tf.train.MomentumOptimizer by tf.train.GradientDescentOptimizer, still removing /cpu:0. Then it works! The GPU usage is around 25%~30%. If adding /cpu:0, the GPU usage is around 20%~25%.

d.    Because the GPU usage is always below 30%(also in my real code running real data). Is there any way to profiling it to find where is the speed bottleneck?

Sorry for so many questions... But it's really a blocking issue for NLP guys...
"
2848,GPU Host To Device copies don't appear to respect GPU operation dependencies,"I've been trying out the fancy new [tracing](http://stackoverflow.com/a/37774430/1611416) functionality in the Tensorflow nightlies. It's really great, thanks for providing it!

One thing I noticed while [enqueueing](https://github.com/ska-sa/montblanc/blob/29b264ee114a6ef63159808125b1a4505cc5ffa2/montblanc/tensorflow/rime_ops/test_all.py#L66-L127) multiple GPU operations with `tf.control_dependencies` is that Host to Device memory copies for the inputs of consecutive GPU ops can be scheduled in an interleaved pattern, instead of consecutively. In my case I have something like this:
1. op EBeam with inputs: ebeam
2. op SumCoherencies with inputs: gterm, ant2, model_vis, flag, ant1, ant2

but in the [trace](https://github.com/tensorflow/tensorflow/files/313540/timeline.json.zip) I see the memory copies scheduled as:
- ant1, flag, **ebeam**, gterm, ant2, model_vis

when I would expect, due to the the consecutive scheduling of EBeam and SumCoherencies ops, that the memory copies would be scheduled as:
- **ebeam**, ant1, flag,  gterm, ant2, model_vis

I also notice that the EBeam op only starts executing on the GPU after all the SumCoherencies inputs have been copied to the GPU (rather than just the ebeam input) so the GPU is idle. There is no dependency on SumCoherencies by EBeam (Its the other way round).

_There are several other ops and inputs that I haven't mentioned for the sake of brevity_
### Environment info

Operating System: `Ubuntu 14.04.4`

Installed version of CUDA and cuDNN: `CUDA 7.5 and cuDNN 4.0.7`
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

``` bash
~$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root    322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root        19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root    383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root    720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 3319 users       13 Feb  9 19:48 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 3319 users       17 Feb  9 19:48 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxrwxr-x 1 3319 users 61453024 Feb  9 00:12 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-rw-r-- 1 3319 users 62025862 Feb  9 00:12 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed. `python 2 GPU nightly`
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. `0.8.0`

If installed from sources, provide the commit hash: **N/A**
### Steps to reproduce
1. Ran [this](https://github.com/ska-sa/montblanc/blob/29b264ee114a6ef63159808125b1a4505cc5ffa2/montblanc/tensorflow/rime_ops/test_all.py#L66-L127) script. (If necessary, source with Makefile is [here](https://github.com/ska-sa/montblanc/tree/29b264ee114a6ef63159808125b1a4505cc5ffa2/montblanc/tensorflow/rime_ops) and relevent commit is [29b264ee](https://github.com/ska-sa/montblanc/tree/29b264ee114a6ef63159808125b1a4505cc5ffa2))
2. Inspected the timeline ([timeline.json.zip](https://github.com/tensorflow/tensorflow/files/313540/timeline.json.zip)) in `chrome://tracing/`
### What have you tried?
1. Using `tf.control_dependencies` to modify op execution order
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2846,Increase speed of getting pool3 features on CPU machine,"Currently on my CPU setup, Tensorflow is taking almost 0.5 second for one image, to get the pool3 features. I'm using the retrained Inception model, after training it on my own images.

Any way to increase this speed?
"
2844,Setting up TensorFlow for development affects subsequent `bazel test` runs,"After following instructions in [Setting up TensorFlow for development](https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#setting-up-tensorflow-for-development) , `bazel test` will look in `_python_build` before looking in `.runfiles` directory.

The result is that some tests may fail which would otherwise pass in a hermetic requirement. Also it could mean that some tests would pass which would otherwise fail in a hermetic environment. A work-around is to remove `_python_build` directory before running `bazel test`

Breaking into debugger while running test, I see following in `sys.path`, which confirms that `_python_build` is placed before `.runfiles`

```
['/Users/yaroslavvb/tfimmediate_hood/tensorflow/tensorflow/contrib/immediate/python/immediate',
 '/Library/Python/2.7/site-packages/six-1.10.0-py2.7.egg',
 '/Library/Python/2.7/site-packages/numpy-1.11.0-py2.7-macosx-10.10-intel.egg',
 '/Library/Python/2.7/site-packages/wheel-0.29.0-py2.7.egg',
 '/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg',
 '/Library/Python/2.7/site-packages/ipython-4.2.0-py2.7.egg',
 '/Library/Python/2.7/site-packages/gnureadline-6.3.3-py2.7-macosx-10.8-intel.egg',
 '/Library/Python/2.7/site-packages/appnope-0.1.0-py2.7.egg',
 '/Library/Python/2.7/site-packages/pexpect-4.0.1-py2.7.egg',
 '/Library/Python/2.7/site-packages/backports.shutil_get_terminal_size-1.0.0-py2.7.egg',
 '/Library/Python/2.7/site-packages/traitlets-4.2.1-py2.7.egg',
 '/Library/Python/2.7/site-packages/simplegeneric-0.8.1-py2.7.egg',
 '/Library/Python/2.7/site-packages/pickleshare-0.7.2-py2.7.egg',
 '/Library/Python/2.7/site-packages/decorator-4.0.9-py2.7.egg',
 '/Library/Python/2.7/site-packages/ptyprocess-0.5.1-py2.7.egg',
 '/Library/Python/2.7/site-packages/ipython_genutils-0.1.0-py2.7.egg',
 '/Library/Python/2.7/site-packages/pathlib2-2.1.0-py2.7.egg',
 '/Library/Python/2.7/site-packages/protobuf-3.0.0b2-py2.7.egg',
 '/Library/Python/2.7/site-packages/Python_contrib_nbextensions-alpha-py2.7.egg',
 '/Library/Python/2.7/site-packages/PyYAML-3.11-py2.7-macosx-10.11-intel.egg',
 '/Library/Python/2.7/site-packages',
 '/Users/yaroslavvb/tfimmediate_hood/tensorflow/_python_build',
 '/Users/yaroslavvb/tfimmediate_hood/tensorflow/bazel-bin/tensorflow/contrib/immediate/itensor_test.runfiles',
 '/Users/yaroslavvb/tfimmediate_hood/tensorflow/bazel-bin/tensorflow/contrib/immediate/itensor_test.runfiles/protobuf/python',
 '/Users/yaroslavvb/tfimmediate_hood/tensorflow/bazel-bin/tensorflow/contrib/immediate/itensor_test.runfiles/org_tensorflow',
 '/Users/yaroslavvb/tfimmediate_hood/tensorflow/bazel-bin/tensorflow/contrib/immediate/itensor_test.runfiles/protobuf',
 '/Users/yaroslavvb/tfimmediate_hood/tensorflow/bazel-bin/tensorflow/contrib/immediate/itensor_test.runfiles/six_archive',


```
"
2840,segfault in perftools::gputools::StreamExecutor::DeviceMemoryUsage - on a busy gpu,"I'm using tensorflow 0.9.0rc0 with cuda 7.5 on Tesla K40c .

The GPU I'm specifying via `device_id` and

```
    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7, allow_growth=True)
    sess_cfg = tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options)
```

is running under a heavy load now (multiple instances of tf are working with it in parallel, so it has 70-80% gpu voltage), but still has ~20-30% free memory, so I wanted to run a one more tiny script.

If I run the script under `gdb`, I get:

```
Program received signal SIGSEGV, Segmentation fault.
0x00007fffd51237a1 in perftools::gputools::StreamExecutor::DeviceMemoryUsage(long long*, long long*) const ()
   from /data2/users/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so
```

is it indeed ""out of resources"" or there's something wrong with the installation? Shouldn't it somehow signalize about those problems in user code, rather than just segfaulting?
"
2838,Get placeholder for initial state of nested RNN,"For RNN cells, we get the initial state using `cell.zero_state()` and the last state after processing a sequence using `rnn.dynamic_rnn()`. However, to use the last state as the initial state for the next run, one must create a `tf.placeholder()`. As far as I know, currently there is no way to create and fill such  a placeholder (or nested tuple of placeholders) automatically. Such a feature would be very useful so that we don't have to adjust the placeholder manually when changing the RNN cell.
"
2834,Defining shape of 1-D variable-size placeholder with tuple doesn't enforce the actual shape,"I noticed that defining a 1-D batch-sized placeholder with a tuple instead of a list doesn't enforce its shape:

```
ph = tf.placeholder(tf.int32, (None))
op = 2 * ph
x = np.random.randint(0, 9, (5, 5))
sess.run(op, feed_dict={ph: x})
```

This outputs:

```
array([[ 0, 10, 10, 12,  4],
       [12, 12, 16,  2,  2],
       [ 4, 14, 10, 14,  6],
       [ 6,  8,  2, 10, 10],
       [ 4, 14,  6,  6,  4]], dtype=int32)
```

While with `[None]`:

```
ph = tf.placeholder(tf.int32, [None])
op = 2 * ph
sess.run(op, feed_dict={ph: x})
```

results in `ValueError: Cannot feed value of shape (5, 5) for Tensor u'Placeholder_5:0', which has shape '(?,)'`, as I would expect.

Is the behavior with the tuple intended to work like this? I really don't think it's a good idea (I spent a few hours tracking a bug in my code caused by feeding a 2-D array to a supposedly 1-D placeholder). Anyway, the documentation on placeholders says the following about the argument `shape`: _The shape of the tensor to be fed (optional). If the shape is not specified, you can feed a tensor of any shape_.
"
2830,syntaxnet bazel test failed,"I ran `bazel test syntaxnet/... util/utf8/...` and it gave a few errors . It gave me this output:

```
FAIL: //syntaxnet:parser_trainer_test (see /home/me/.cache/bazel/_bazel_rushat/cc4d67663fbe887a603385d628fdf383/syntaxnet/bazel-out/local-opt/testlogs/syntaxnet/parser_trainer_test/test.log).
INFO: Elapsed time: 2179.396s, Critical Path: 1623.00s
//syntaxnet:arc_standard_transitions_test                                PASSED in 0.7s
//syntaxnet:beam_reader_ops_test                                         PASSED in 24.1s
//syntaxnet:graph_builder_test                                           PASSED in 14.6s
//syntaxnet:lexicon_builder_test                                         PASSED in 6.1s
//syntaxnet:parser_features_test                                         PASSED in 5.8s
//syntaxnet:reader_ops_test                                              PASSED in 9.4s
//syntaxnet:sentence_features_test                                       PASSED in 0.2s
//syntaxnet:shared_store_test                                            PASSED in 41.7s
//syntaxnet:tagger_transitions_test                                      PASSED in 5.2s
//syntaxnet:text_formats_test                                            PASSED in 6.1s
//util/utf8:unicodetext_unittest                                         PASSED in 0.4s
//syntaxnet:parser_trainer_test                                          FAILED in 0.5s
  /home/me/.cache/bazel/_bazel_me/cc4d67663fbe887a603385d628fdf383/syntaxnet/bazel-out/local-opt/testlogs/syntaxnet/parser_trainer_test/test.log

Executed 12 out of 12 tests: 11 tests pass and 1 fails locally.
There were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.
```

If you want the output of `--test_verbose_timeout_warnings` then please ask

I have no idea what these mean...please help me :pray:

PS: If this is the wrong place to ask, then please direct me where to post this(but kindly suggest an answer)
"
2829,Can not completely disable GPU & CUDA support. ,"This only applies to `TensorFlow 0.9`.

Even if you disable GPU support when configuring `TensorFlow`, you will still need CUDA to build it. Indeed, `Eigen::half` (half floats) should only be used when running on a GPU, it's not CPU-compatible. 

But they are always used, and this causes exceptions to be thrown if our `Eigen`version does not contains the `Eigen/src/arch/CUDA` folder and headers. (=You don't have CUDA installed).

Thanks for fixing this as fast as possible. If you need some other infos, just ask me.
"
2827,_reverse_seq in rnn.py,"I can't figure out the usage of _reverse_seq in rnn.py

followings are my code

``` javascript

encoder_inputs = []
for i in range(3):
            encoder_inputs.append(tf.placeholder(tf.int32, shape = [None,3], name = 'encoder{}'.format(i)))

train_encoder_batches, train_decoder_batches, train_target_batches, train_target_weight_batches = train_data
input_feed = dict()
encoder_data = np.array([[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]],[[0,0,0],[0,0,0]]])
for i in xrange(3):
    input_feed[encoder_inputs[i].name] = encoder_data[i]

output_feed = [rnn._reverse_seq(encoder_inputs,tf.Variable([2,2]))]
print np.asarray([[1,2,3],[1,2,3]])

sess = tf.InteractiveSession()
print sess.run(output_feed,input_feed)
```

tf.Variable([2,2]) means that (batch size : 2) each length of elements in batch is 2 
data : vector size 3, total length 3, useful length 2

errors are as follows :

``` javascript
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-28-b8ae6f496e18> in <module>()
      1 sess = tf.InteractiveSession()
----> 2 print sess.run(output_feed,input_feed)

/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    338     try:
    339       result = self._run(None, fetches, feed_dict, options_ptr,
--> 340                          run_metadata_ptr)
    341       if run_metadata:
    342         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    521 
    522     # Validate and process fetches.
--> 523     processed_fetches = self._process_fetches(fetches)
    524     unique_fetches = processed_fetches[0]
    525     target_list = processed_fetches[1]

/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _process_fetches(self, fetches)
    491           raise TypeError('Fetch argument %r of %r has invalid type %r, '
    492                           'must be a string or Tensor. (%s)'
--> 493                           % (subfetch, fetch, type(subfetch), str(e)))
    494         except ValueError as e:
    495           raise ValueError('Fetch argument %r of %r cannot be interpreted as a '

TypeError: Fetch argument [<tf.Tensor 'unpack_4:0' shape=(2, 3) dtype=int32>, <tf.Tensor 'unpack_4:1' shape=(2, 3) dtype=int32>, <tf.Tensor 'unpack_4:2' shape=(2, 3) dtype=int32>] of [<tf.Tensor 'unpack_4:0' shape=(2, 3) dtype=int32>, <tf.Tensor 'unpack_4:1' shape=(2, 3) dtype=int32>, <tf.Tensor 'unpack_4:2' shape=(2, 3) dtype=int32>] has invalid type <type 'list'>, must be a string or Tensor. (Can not convert a list into a Tensor or Operation.)
```
"
2826,A 1D and 2D Gaussian implementation in TensorFlow,"Feature request:

Mixture Density networks, attention models and variational inference getting more popular, we are defining more and more Gaussians in our model. My feature request would be to have a native Gaussian implementation in TensorFlow.

Up to now, I re-use [this](https://github.com/hardmaru/write-rnn-tensorflow/blob/master/model.py) code:

```
def tf_2d_normal(x1, x2, mu1, mu2, s1, s2, rho):
  # eq # 24 and 25 of http://arxiv.org/abs/1308.0850
  norm1 = tf.sub(x1, mu1)
  norm2 = tf.sub(x2, mu2)
  s1s2 = tf.mul(s1, s2)
  z = tf.square(tf.div(norm1, s1))+tf.square(tf.div(norm2, s2))-2*tf.div(tf.mul(rho, tf.mul(norm1, norm2)), s1s2)
  negRho = 1-tf.square(rho)
  result = tf.exp(tf.div(-z,2*negRho))
  denom = 2*np.pi*tf.mul(s1s2, tf.sqrt(negRho))
  result = tf.div(result, denom)
  return result
```

However, it might be nice for Tensorflow to implement it in the library. They might be able to apply it more computationally efficient? Also, they might go for N-dimensional Gaussians, not only two.

What do you think? Is this feasible?
"
2825,Initialize moving averages by the first applied value rather than 0,"Currently hidden moving averages are initialized by 0. If the decay is large, it takes a lot of time for the moving average variable to forget about initial zero value. It would be much more reasonable to initialize by the first obtained value of the observed variable, and then start to apply decay. In this case the initial initialization is not required anymore, so the variable can be removed from the ""assert_variables_initialized"" list
"
2823,Implement variable length sequences for seq2seq,"Now, seq2seq uses bucketing to deal with variable length sequences. Which need to define many models and require manually tuning.  While in RNN, some models implement variable length sequences with a param `sequence_length`, which I think is a better method. So how about use the same method in RNN to implement variable length sequences for seq2seq?
"
2821,max_pool_with_argmax index calculation,"max_pool_with_argmax returns an argmax array which doesn't seem to account for the batch dimension. That is, the op returns the flattened index as: (height \* width + x) \* channels + c instead of ((b \* height + y) \* width + x) \* channels + c as indicated in the API
"
2818,tf.gradients casts away imaginary part of result when differentiating by a real value ,"This is continued from #2255:

Differentiating a complex expression by a real value with `tf.gradients` should yield a complex value, but this doesn't seem to be the way that `tf.gradients` works at the moment.
If I run

```
import tensorflow as tf
import numpy as np

s = tf.Session()
x = tf.placeholder(tf.float32)

z = tf.complex(0., x)

print('full', s.run(tf.gradients(z, [x]), feed_dict={x: 1}))
print('real', s.run(tf.gradients(tf.real(z), [x]), feed_dict={x: 1}))
print('imag', s.run(tf.gradients(tf.imag(z), [x]), feed_dict={x: 1}))
```

The output is

```
full [0.0]
real [0.0]
imag [1.0]
```

while I would have expected

```
full [0.0 + 1.0j]
real [0.0]
imag [1.0]
```

I suspect that `tf.gradients` always casts the final result to the type of the variable that we differentiate with respect to, which makes sense in many circumstances, but leads to incorrect behaviour in this case.
"
2816,Executing genrule //tensorflow/contrib/session_bundle/example:half_plus_two failed,"Hi,
Installing TensorFlow from source fails on my system. There seems to be some Python-related error when building 'half_plus_two'.
See (hopefully) all relevant output below.
### Environment info

Operating System:

> lsb_release -a
> No LSB modules are available.
> Distributor ID: Ubuntu
> Description:    Ubuntu 16.04 LTS
> Release:    16.04
> Codename:   xenial
> 
> uname -a
> Linux the-beast 4.4.0-24-generic #43-Ubuntu SMP Wed Jun 8 19:27:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

> ls -l /usr/local/cuda-8.0/lib64/libcud*
> -rw-r--r-- 1 root root   560184 Jun 12 16:53 /usr/local/cuda-8.0/lib64/libcudadevrt.a
> lrwxrwxrwx 1 root root       16 Jun 12 16:53 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
> lrwxrwxrwx 1 root root       19 Jun 12 16:53 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
> -rwxr-xr-x 1 root root   394472 Jun 12 16:53 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.27
> -rw-r--r-- 1 root root   737516 Jun 12 16:53 /usr/local/cuda-8.0/lib64/libcudart_static.a
> -rwxr-xr-x 1 root root 78065952 Jun 12 16:54 /usr/local/cuda-8.0/lib64/libcudnn.so
> -rwxr-xr-x 1 root root 78065952 Jun 12 16:54 /usr/local/cuda-8.0/lib64/libcudnn.so.5
> -rwxr-xr-x 1 root root 78065952 Jun 12 16:54 /usr/local/cuda-8.0/lib64/libcudnn.so.5.0.5
> -rw-r--r-- 1 root root 68709594 Jun 12 16:54 /usr/local/cuda-8.0/lib64/libcudnn_static.a

If installed from sources, provide the commit hash:
bf83048d5f28b7fa0f39df799bd01a8fc581f5cf
### Steps to reproduce
1. Clone TensorFlow and follow instructions to build from source:
   https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installation-for-linux
2. Execute command
   bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
   which ultimately fails.
### Logs or other output that would be helpful

This should be the relevant part:

michael@the-beast:~/devel/tensorflow$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures
WARNING: /home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/external/protobuf/WORKSPACE:1: Workspace name in /home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
WARNING: /home/michael/devel/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
WARNING: /home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/external/highwayhash/WORKSPACE:1: Workspace name in /home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.
WARNING: /home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/external/re2/WORKSPACE:1: Workspace name in /home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
INFO: Found 1 target...
ERROR: /home/michael/devel/tensorflow/tensorflow/contrib/session_bundle/example/BUILD:38:1: Executing genrule //tensorflow/contrib/session_bundle/example:half_plus_two failed: bash failed: error executing command 
  (cd /home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/execroot/tensorflow && \
  exec env - \
    PATH=/home/michael/torch/install/bin:/home/michael/devel/jdk1.8.0_77/bin:/home/michael/devel/bazel/output:/usr/local/cuda-8.0/bin:/home/michael/devel/gocode/bin:/home/michael/torch/install/bin:/home/michael/torch/install/bin:/home/michael/torch/install/bin:/home/michael/torch/install/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; rm -rf /tmp/half_plus_two; /usr/bin/python bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two; cp -r /tmp/half_plus_two/\* bazel-out/local_linux-opt/genfiles/tensorflow/contrib/session_bundle/example/half_plus_two'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally
Traceback (most recent call last):
  File ""/home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/execroot/tensorflow/bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two.runfiles/org_tensorflow/tensorflow/contrib/session_bundle/example/export_half_plus_two.py"", line 32, in <module>
    import tensorflow as tf
  File ""/home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/execroot/tensorflow/bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two.runfiles/org_tensorflow/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/execroot/tensorflow/bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/execroot/tensorflow/bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two.runfiles/org_tensorflow/tensorflow/core/framework/graph_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/execroot/tensorflow/bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two.runfiles/org_tensorflow/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/execroot/tensorflow/bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two.runfiles/org_tensorflow/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
  File ""/home/michael/.cache/bazel/_bazel_michael/09c785d214849e49e64c5959b4c31911/execroot/tensorflow/bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two.runfiles/org_tensorflow/tensorflow/core/framework/tensor_shape_pb2.py"", line 22, in <module>
    serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""z\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x12\x14\n\x0cunknown_rank\x18\x03 \x01(\x08\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tB/\n\x18org.tensorflow.frameworkB\x11TensorShapeProtosP\x01\x62\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'syntax'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 16.639s, Critical Path: 8.93s
"
2815,glibc detected *** python3: invalid fastbin entry (free),"Hello ,I am try to run my code on TensorFlow. When I run it, it works fine. But after 30 minutes, I get this error:

```
*** glibc detected *** python3: invalid fastbin entry (free): 0x00007fae00288af0 ***
======= Backtrace: =========
/lib64/libc.so.6[0x3ba6276166]
/gpfs/home/chaowei/development/python/python3_tf_cpu_vir/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow6Tensor16CopyFromInternalERKS0_RKNS_11TensorShapeE+0x109)[0x7fae8eebecf9]
/gpfs/home/chaowei/development/python/python3_tf_cpu_vir/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1cdb96e)[0x7fae8ee2796e]
/gpfs/home/chaowei/development/python/python3_tf_cpu_vir/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1cd0cf5)[0x7fae8ee1ccf5]
/gpfs/home/chaowei/development/python/python3_tf_cpu_vir/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow6thread10ThreadPool4Impl10WorkerLoopEv+0x17b)[0x7fae8ef4639b]
/gpfs/home/chaowei/software/gcc-6.1.0/lib64/libstdc++.so.6(+0xbe232)[0x7faebd7b4232]
/lib64/libpthread.so.0[0x3ba66079d1]
/lib64/libc.so.6(clone+0x6d)[0x3ba62e8b6d]
======= Memory map: ========
00400000-007f8000 r-xp 00000000 00:15 3515267                            /gpfs/home/chaowei/development/python/python3_tf_cpu_vir/bin/python3.4
009f8000-00a69000 rw-p 003f8000 00:15 3515267                            /gpfs/home/chaowei/development/python/python3_tf_cpu_vir/bin/python3.4
00a69000-00a87000 rw-p 00000000 00:00 0 
010b3000-2970f000 rw-p 00000000 00:00 0                                  [heap]
3ba5a00000-3ba5a20000 r-xp 00000000 08:05 18612623                       /lib64/ld-2.12.so
3ba5c1f000-3ba5c20000 r--p 0001f000 08:05 18612623                       /lib64/ld-2.12.so
3ba5c20000-3ba5c21000 rw-p 00020000 08:05 18612623                       /lib64/ld-2.12.so
3ba5c21000-3ba5c22000 rw-p 00000000 00:00 0 
3ba5e00000-3ba5e02000 r-xp 00000000 08:05 18612630                       /lib64/libdl-2.12.so
3ba5e02000-3ba6002000 ---p 00002000 08:05 18612630                       /lib64/libdl-2.12.so
3ba6002000-3ba6003000 r--p 00002000 08:05 18612630                       /lib64/libdl-2.12.so
3ba6003000-3ba6004000 rw-p 00003000 08:05 18612630                       /lib64/libdl-2.12.so
3ba6200000-3ba638b000 r-xp 00000000 08:05 18612624                       /lib64/libc-2.12.so
3ba638b000-3ba658a000 ---p 0018b000 08:05 18612624                       /lib64/libc-2.12.so
3ba658a000-3ba658e000 r--p 0018a000 08:05 18612624                       /lib64/libc-2.12.so
3ba658e000-3ba658f000 rw-p 0018e000 08:05 18612624                       /lib64/libc-2.12.so
3ba658f000-3ba6594000 rw-p 00000000 00:00 0 
3ba6600000-3ba6617000 r-xp 00000000 08:05 18612626                       /lib64/libpthread-2.12.so
3ba6617000-3ba6817000 ---p 00017000 08:05 18612626                       /lib64/libpthread-2.12.so
3ba6817000-3ba6818000 r--p 00017000 08:05 18612626                       /lib64/libpthread-2.12.so
3ba6818000-3ba6819000 rw-p 00018000 08:05 18612626                       /lib64/libpthread-2.12.so
3ba6819000-3ba681d000 rw-p 00000000 00:00 0 
3ba6a00000-3ba6a83000 r-xp 00000000 08:05 18612635                       /lib64/libm-2.12.so
3ba6a83000-3ba6c82000 ---p 00083000 08:05 18612635                       /lib64/libm-2.12.so
3ba6c82000-3ba6c83000 r--p 00082000 08:05 18612635                       /lib64/libm-2.12.so
3ba6c83000-3ba6c84000 rw-p 00083000 08:05 18612635                       /lib64/libm-2.12.so
3ba6e00000-3ba6e07000 r-xp 00000000 08:05 18612627                       /lib64/librt-2.12.so
3ba6e07000-3ba7006000 ---p 00007000 08:05 18612627                       /lib64/librt-2.12.so
3ba7006000-3ba7007000 r--p 00006000 08:05 18612627                       /lib64/librt-2.12.so
3ba7007000-3ba7008000 rw-p 00007000 08:05 18612627                       /lib64/librt-2.12.so
3ba7200000-3ba7215000 r-xp 00000000 08:05 18612638                       /lib64/libz.so.1.2.3
3ba7215000-3ba7414000 ---p 00015000 08:05 18612638                       /lib64/libz.so.1.2.3
3ba7414000-3ba7415000 r--p 00014000 08:05 18612638                       /lib64/libz.so.1.2.3
3ba7415000-3ba7416000 rw-p 00015000 08:05 18612638                       /lib64/libz.so.1.2.3
3ba7600000-3ba763b000 r-xp 00000000 08:05 5769740                        /usr/lib64/libxslt.so.1.1.26
3ba763b000-3ba783b000 ---p 0003b000 08:05 5769740                        /usr/lib64/libxslt.so.1.1.26
3ba783b000-3ba783d000 rw-p 0003b000 08:05 5769740                        /usr/lib64/libxslt.so.1.1.26
3ba7e00000-3ba7e02000 r-xp 00000000 08:05 18612339                       /lib64/libutil-2.12.so
3ba7e02000-3ba8001000 ---p 00002000 08:05 18612339                       /lib64/libutil-2.12.so
3ba8001000-3ba8002000 r--p 00001000 08:05 18612339                       /lib64/libutil-2.12.so
3ba8002000-3ba8003000 rw-p 00002000 08:05 18612339                       /lib64/libutil-2.12.so
3ba8200000-3ba8203000 r-xp 00000000 08:05 18612558                       /lib64/libgpg-error.so.0.5.0
3ba8203000-3ba8402000 ---p 00003000 08:05 18612558                       /lib64/libgpg-error.so.0.5.0
3ba8402000-3ba8403000 r--p 00002000 08:05 18612558                       /lib64/libgpg-error.so.0.5.0
3ba8403000-3ba8404000 rw-p 00003000 08:05 18612558                       /lib64/libgpg-error.so.0.5.0
3bab600000-3bab610000 r-xp 00000000 08:05 18612329                       /lib64/libbz2.so.1.0.4
3bab610000-3bab80f000 ---p 00010000 08:05 18612329                       /lib64/libbz2.so.1.0.4
3bab80f000-3bab811000 rw-p 0000f000 08:05 18612329                       /lib64/libbz2.so.1.0.4
3bace00000-3bacf48000 r-xp 00000000 08:05 5769052                        /usr/lib64/libxml2.so.2.7.6
3bacf48000-3bad147000 ---p 00148000 08:05 5769052                        /usr/lib64/libxml2.so.2.7.6
3bad147000-3bad151000 rw-p 00147000 08:05 5769052                        /usr/lib64/libxml2.so.2.7.6
3bad151000-3bad152000 rw-p 00000000 00:00 0 
7fadb0000000-7fadb3ff7000 rw-p 00000000 00:00 0 
7fadb3ff7000-7fadb4000000 ---p 00000000 00:00 0 
7fadb4000000-7fadb4ac5000 rw-p 00000000 00:00 0 Aborted (core dumped)

```

I don't see this error before when I use TF. It is the first time to see it on running TF and I am not sure weather it's the problem of TF or not. BTW, I am trying to run my code again in order to see if the error can appear again.

The version of TF is 0.8 and the version of gcc is 6.1
"
2814,Define new ops with pure python,"AFAIK, new ops can't be created with python alone. However, such feature would be quite helpful when dealing with not-so-common IO, e.g. reading an LMDB, or when experimenting with new algorithms.
"
2813,Broken link for tensorboard,"The link [https://www.tensorflow.org/versions/tensorboard/README.html](https://www.tensorflow.org/versions/tensorboard/README.html) for README file in [tensorboard](https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html) page is broken. 
"
2811, ERROR when building pip package: undeclared function related to swig,"I was able to build the cc:tutorials_example_trainer , but failed to build the  pip package. Could anyone suggest how I can fix it? Thanks a lot!
### Environment info

Operating System:
CentOS 6.5
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
cuda-7.5
### Steps to reproduce
1. I used python 3.5.1  installled by pyenv
2. I installed swig from source
### Error Log

ERROR: /csproject/dygroup2/czeng/downloads/tensorflow/tensorflow/python/BUILD:978:1: C++ compilation of rule '//tensorflow/python:_pywrap_tensorflow.so' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /csproject/dygroup2/czeng/.cache/bazel/_bazel_czeng/211970d9a1065a07eafbeb7dcc542b10/execroot/tensorflow && \
  exec env - \
    PATH=/project/dygroup2/czeng//.pyenv/shims:/project/dygroup2/czeng//.pyenv/bin:/project/dygroup2/czeng/venv/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/cuda-7.5/bin:/usr/local/cuda-7.5/nvvm/bin:/csproject/dygroup2/czeng/venv/cudnnv5 \
    TMPDIR=/tmp/2110270.1.all.q \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' -MD -MF bazel-out/host/bin/tensorflow/python/_objs/_pywrap_tensorflow.so/tensorflow/python/pywrap_tensorflow.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/python/_objs/_pywrap_tensorflow.so/tensorflow/python/pywrap_tensorflow.pic.o' -fPIC -DGPR_BACKWARDS_COMPATIBILITY_MODE -iquote . -iquote bazel-out/host/genfiles -iquote external/protobuf -iquote bazel-out/host/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -iquote external/farmhash_archive -iquote bazel-out/host/genfiles/external/farmhash_archive -iquote external/jpeg_archive -iquote bazel-out/host/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/host/genfiles/external/png_archive -iquote external/highwayhash -iquote bazel-out/host/genfiles/external/highwayhash -iquote external/re2 -iquote bazel-out/host/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/host/genfiles/external/eigen_archive -iquote external/grpc -iquote bazel-out/host/genfiles/external/grpc -iquote external/nanopb_git -iquote bazel-out/host/genfiles/external/nanopb_git -isystem external/protobuf/src -isystem bazel-out/host/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem bazel-out/host/genfiles/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/host/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/host/genfiles/external/png_archive/libpng-1.2.53 -isystem external/highwayhash -isystem bazel-out/host/genfiles/external/highwayhash -isystem external/re2 -isystem bazel-out/host/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/host/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-5f86b31739cd -isystem bazel-out/host/genfiles/external/eigen_archive/eigen-eigen-5f86b31739cd -isystem third_party/gpus/cuda/include -isystem bazel-out/host/genfiles/third_party/gpus/cuda/include -isystem third_party/py/numpy/numpy_include -isystem bazel-out/host/genfiles/third_party/py/numpy/numpy_include -isystem util/python/python_include -isystem bazel-out/host/genfiles/util/python/python_include -isystem third_party/gpus/cuda -isystem bazel-out/host/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/extras/CUPTI/include -isystem bazel-out/host/genfiles/third_party/gpus/cuda/extras/CUPTI/include -isystem external/grpc/include -isystem bazel-out/host/genfiles/external/grpc/include -isystem external/grpc -isystem bazel-out/host/genfiles/external/grpc -Wno-self-assign -Wno-write-strings -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -c bazel-out/host/bin/tensorflow/python/pywrap_tensorflow.cc -o bazel-out/host/bin/tensorflow/python/_objs/_pywrap_tensorflow.so/tensorflow/python/pywrap_tensorflow.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
bazel-out/host/bin/tensorflow/python/pywrap_tensorflow.cc: In function 'swig_module_info\* SWIG_Python_GetModule()':
bazel-out/host/bin/tensorflow/python/pywrap_tensorflow.cc:2452:51: error: 'PyCObject_Import' was not declared in this scope
         (char_)""type_pointer"" SWIG_TYPE_TABLE_NAME);
                                                   ^
bazel-out/host/bin/tensorflow/python/pywrap_tensorflow.cc: In function 'void SWIG_Python_SetModule(swig_module_info_)':
bazel-out/host/bin/tensorflow/python/pywrap_tensorflow.cc:2521:92: error: 'PyCObject_FromVoidPtr' was not declared in this scope
   PyObject _pointer = PyCObject_FromVoidPtr((void *) swig_module, SWIG_Python_DestroyModule);
                                                                                            ^
bazel-out/host/bin/tensorflow/python/pywrap_tensorflow.cc:2512:22: warning: unused variable 'swig_empty_runtime_method_table' [-Wunused-variable]
   static PyMethodDef swig_empty_runtime_method_table[] = { {NULL, NULL, 0, NULL} };/_ Sentinel _/
                      ^
bazel-out/host/bin/tensorflow/python/pywrap_tensorflow.cc: In function 'swig_type_info_ SWIG_Python_TypeQuery(const char_)':
bazel-out/host/bin/tensorflow/python/pywrap_tensorflow.cc:2544:60: error: 'PyCObject_AsVoidPtr' was not declared in this scope
     descriptor = (swig_type_info *) PyCObject_AsVoidPtr(obj);
                                                            ^
bazel-out/host/bin/tensorflow/python/pywrap_tensorflow.cc:2549:51: error: 'PyCObject_FromVoidPtr' was not declared in this scope
       obj = PyCObject_FromVoidPtr(descriptor, NULL);
                                                   ^
bazel-out/host/bin/tensorflow/python/pywrap_tensorflow.cc: In function 'PyObject_ _wrap_GetMatchingFiles(PyObject_, PyObject_)':
bazel-out/host/bin/tensorflow/python/pywrap_tensorflow.cc:5392:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     for (int i = 0; i < converted.size(); ++i) {
                       ^
At global scope:
cc1plus: warning: unrecognized command line option ""-Wno-self-assign""
Target //tensorflow/tools/pip_package:build_pip_package failed to build
"
2810,CUDA_ERROR_MISALIGNED_ADDRESS on MNIST example ,"## Summary

What might be causing this error when running **python tensorflow/models/image/mnist/convolutional.py**?

E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_MISALIGNED_ADDRESS
### Environment info

**Operating System:**
Linux Lounge 4.5.6-200.fc23.x86_64 #1 SMP Wed Jun 1 21:28:20 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

**Installed version of CUDA and cuDNN**:
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
ls -l /usr/local/cuda-7.5/lib64/libcud*
-rw-r--r--. 1 root root   322936 Aug 16  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx. 1 root root       16 Aug 16  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx. 1 root root       19 Aug 16  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x. 1 root root   383336 Aug 16  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r--. 1 root root   720192 Aug 16  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
-rwxr-xr-x. 1 root root 61453024 Jun 11 12:35 /usr/local/cuda-7.5/lib64/libcudnn.so
-rwxr-xr-x. 1 root root 61453024 Jun 11 12:35 /usr/local/cuda-7.5/lib64/libcudnn.so.4
-rwxr-xr-x. 1 root root 61453024 Jun 11 12:35 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7
-rwxr-xr-x. 1 root root 59909104 Jun 11 12:35 /usr/local/cuda-7.5/lib64/libcudnn.so.5
-rwxr-xr-x. 1 root root 59909104 Jun 11 12:35 /usr/local/cuda-7.5/lib64/libcudnn.so.5.0.5
-rw-r--r--. 1 root root 62025862 Jun 11 12:35 /usr/local/cuda-7.5/lib64/libcudnn_static.a

If installed from binary pip package, provide:

**1. Which pip package you installed.**

> export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl
> pip install --upgrade $TF_BINARY_URL

**2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.**
python -c ""import tensorflow; print(tensorflow.**version**)""
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally

If installed from sources, provide the commit hash:
### Steps to reproduce

1  python tensorflow/models/image/mnist/convolutional.py.
2. Observe errror CUDA_ERROR_MISALIGNED_ADDRESS
3. Scratch head
### What have you tried?
1. Searching the internet for clues, none found
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
Results of cuda-memcheck and dmesg
[error.txt](https://github.com/tensorflow/tensorflow/files/310536/error.txt)
"
2808,CLOSED Discard PR,"Greetings @tensorflow-jenkins. This is my first contribution to a Google open source project and I'd like to read your Contributor License Agreement (CLA) before I sign it
"
2807,Slow quantized graph,"1. On Ubuntu 15.10 with CUDA 7.5, cuDNN 7.0, tensorflow-0.9.0rc0, ran ""tensorflow/examples/label_image/"" application by taking inception-v3 graph and roughly measure the elapsed time. 
2. Then take ""tensorflow/contrib/quantization/tools:quantize_graph"" to quant inception-v3, rebuilt application by giving 
   
   ```
   ""//tensorflow/contrib/quantization:cc_ops"",
   ""//tensorflow/contrib/quantization/kernels:quantized_ops"",
   ```

into ""tensorflow/examples/label_image/BUILD"" and redo the same classification and measure the time. 

Before/After quantization, elapsed time were 6 seconds vs. 17 seconds, i.e. quantization doubled the inference time? 

The results looks ok as below so I think I was running it correctly. 
Before
- military uniform (866): 0.647299
- suit (794): 0.0477195
- academic gown (896): 0.0232407
- bow tie (817): 0.0157355
- bolo tie (940): 0.0145023

After
- military uniform (866): 0.703474
- suit (794): 0.0248454
- bow tie (817): 0.0171362
- bolo tie (940): 0.0171362
- academic gown (896): 0.0164432

My tensor flow was built as CPU only. Have also tried to enable GPU while the timing didn't change. Do we know what the expected performance would be? 
"
2806,"Building TF with custom GCC requires hardcoded ld,nm and as","Hi! I am using Fedora 23 to build TensorFlow with GPU support.

GPU support requires a specific GCC version, 4.9 for successful compilation. Since this version is not available from the Fedora Package repositories, it has to be compiled from source. Unfortunately, there are a few obstacles using this version with bazel.

One of those is the following:
After configuring TensorFlow with the self-compiled GCC, and running bazel, the compilation stops with the following message:

`gcc: error trying to exec 'as': execvp: No such file or directory`
or
`gcc: error trying to exec 'nm': execvp: No such file or directory`
or
`gcc: error trying to exec 'ld': execvp: No such file or directory`

To work around this, one can compile GCC by hardcoding the paths to those tools, by adding this to the configuration line of GCC:
`--with-ld=/bin/ld --with-nm=/bin/nm --with-as=/usr/bin/as`

This does seem rather strange, however, because those programs are on the path, and the custom GCC without bazel is capable of producing working binaries just fine. I feel that in a well-working build system, this kind of hacks should not be necessary.

This is probably a bazel bug, but since I am compiling TensorFlow with it and I cannot be sure that it's not a TF issue, I am creating this here.
Please ping bazel devs as required.
"
2804,what is the different between tf.mul and * when i used to build a graph,"what is the difference between tf.mul and \* when i used to build a graph?
Can both of them calculate the gradient automatically?
"
2803,Is it possible to truncate BPTT to less than max_time in dynamic_rnn?,"I am wondering whether it is possible to feed, say, sequences of length 10000 while letting the gradients only flow back over a maximum of 100 time steps. This seem to me a pretty common thing to do in sequential learning tasks, so I am wondering whether there is support for that in `dynamic_rnn` and if not, whether it is planned.
"
2802,Compile failed due to undeclared inclusion,"### ERROR message

```
ERROR: /csproject/dygroup2/czeng/downloads/tensorflow/tensorflow/core/kernels/BUILD:1575:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:training_ops_gpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/training_ops_gpu.cu.cc':
```
### Environment info

Operating System:
CentOS 6.5
Installed version of CUDA and cuDNN: 
cuda-7.5
cuDNN v5
### Procedure to reproduce:

I used a custom GCC version (which is in /usr/local/GNU/gcc-4.9.2/) following the guide in #2109 , and executed 

`bazel build --verbose_failures -c opt --config=cuda --genrule_strategy=standalone -j 10 //tensorflow/cc:tutorials_example_trainer
`
### Output of $ echo | gcc4 -E -xc++ - -v

```
Using built-in specs.
COLLECT_GCC=gcc4
Target: x86_64-unknown-linux-gnu
Configured with: ../gcc-4.9.2/configure --prefix=/usr/local/GNU/gcc-4.9.2 --enable-clocale=generic
Thread model: posix
gcc version 4.9.2 (GCC)
COLLECT_GCC_OPTIONS='-E' '-v' '-mtune=generic' '-march=x86-64'
 /export/centos6_usr_local/GNU/gcc-4.9.2/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.2/cc1plus -E -quiet -v -iprefix /export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/ -D_GNU_SOURCE - -mtune=generic -march=x86-64
ignoring nonexistent directory ""/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/../../../../x86_64-unknown-linux-gnu/include""
ignoring duplicate directory ""/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/../../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/../../../../include/c++/4.9.2""
ignoring duplicate directory ""/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/../../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/../../../../include/c++/4.9.2/x86_64-unknown-linux-gnu""
ignoring duplicate directory ""/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/../../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/../../../../include/c++/4.9.2/backward""
ignoring duplicate directory ""/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/../../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/include""
ignoring duplicate directory ""/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/../../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/include-fixed""
ignoring nonexistent directory ""/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/../../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/../../../../x86_64-unknown-linux-gnu/include""
#include ""..."" search starts here:
#include <...> search starts here:
 /csproject/dygroup2/czeng/venv/cudnnv5/include
 /export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/../../../../include/c++/4.9.2
 /export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/../../../../include/c++/4.9.2/x86_64-unknown-linux-gnu
 /export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/../../../../include/c++/4.9.2/backward
 /export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/include
 /export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/include-fixed
 /usr/local/include
 /export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/../../include
 /usr/include
End of search list.
#1 ""<stdin>""
#1 ""<built-in>""
#1 ""<command-line>""
#1 ""<stdin>""
COMPILER_PATH=/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.2/:/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../libexec/gcc/
LIBRARY_PATH=/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/:/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/:/csproject/dygroup2/czeng/venv/cudnnv5/lib64/../lib64/:/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/../../../../lib64/:/lib/../lib64/:/usr/lib/../lib64/:/csproject/dygroup2/czeng/venv/cudnnv5/lib64/:/export/centos6_usr_local/GNU/gcc-4.9.2/bin/../lib/gcc/x86_64-unknown-linux-gnu/4.9.2/../../../:/lib/:/usr/lib/
COLLECT_GCC_OPTIONS='-E' '-v' '-mtune=generic' '-march=x86-64'
```
"
2801,"Error building from source:  ""/usr/bin/env: python2.7: No such file or directory""","I'm building tensorflow from source but I don't know why python2.7 is required. Does anyone know whether I can change the crosstool_wrapper_driver_is_not_gcc file?

ERROR: ~/.cache/bazel/_bazel_czeng/211970d9a1065a07eafbeb7dcc542b10/external/protobuf/BUILD:331:1: Linking of rule '@protobuf//:protoc' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /csproject/dygroup2/czeng/.cache/bazel/_bazel_czeng/211970d9a1065a07eafbeb7dcc542b10/execroot/tensorflow && \
  exec env - \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/external/protobuf/protoc bazel-out/host/bin/external/protobuf/_objs/protoc/external/protobuf/src/google/protobuf/compiler/main.o bazel-out/host/bin/external/protobuf/libprotoc_lib.a bazel-out/host/bin/external/protobuf/libprotobuf.a bazel-out/host/bin/external/protobuf/libprotobuf_lite.a -lpthread -lstdc++ -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,-S -Wl,--gc-sections): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127.
/usr/bin/env: python2.7: No such file or directory
"
2800,Tensorflow on windows using docker,"Hey i am trying to install tensorflow on windows 10 machine using docker. I am getting this message for a very long time. please help me out with this or suggest any alternative.
Thanks
![capture](https://cloud.githubusercontent.com/assets/18229244/15984549/20b37872-2fed-11e6-9f40-4fbbedcc3c88.JPG)
"
2799,Eigen core linking errors (iOS camera example),"when compiling the ios camera example there's a few linking errors where it cant link to:
`#include <Eigen/src/Core/util/DisableStupidWarnings.h>`
a simple hack does the trick. 

Replace with:
`#include ""../../../Eigen/src/Core/util/DisableStupidWarnings.h""`
in Eigen/Core and a couple of other places (Tensor)

similar for
`#include ""../../../Eigen/src/Core/util/ReenableStupidWarnings.h""`
instead of 
`#include <Eigen/src/Core/util/ReenableStupidWarnings.h>
`
"
2797,error when using batch_normalize in tensorflow.contrib,"When I try to use batch_normalize as `bn = batch_normalize(conv, convnet=True)`, the error is as follows:

> File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/ops/batch_norm_ops.py"", line 72, in batch_normalize
>     lambda: (ema_mean, ema_var))
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1316, in cond
>     p_2, p_1 = switch(pred, pred)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 260, in switch
>     return gen_control_flow_ops._switch(data, pred, name=name)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_control_flow_ops.py"", line 370, in _switch
>     result = _op_def_lib.apply_op(""Switch"", data=data, pred=pred, name=name)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 464, in apply_op
>     (prefix, dtypes.as_dtype(input_arg.type).name))
> TypeError: Input 'pred' of 'Switch' Op has type float32 that does not match expected type of bool.

Operating System: Ubuntu 14.04, 64 bits
Pip package: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl
The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`: 0.9.0rc0
"
2793,Clipping gradient w.r.t. inputs at each time step for RNN/LSTM,"New feature request:

While training LSTMs, is it often useful to clip the derivates w.r.t the inputs into the LSTM at each time step ([Alex Graves](http://arxiv.org/pdf/1308.0850v5.pdf), Sec 2.1). This is different from clipping the overall gradient. Theano supports this feature with `theano.gradient.grad_clip(tensor_var)`. Can we have a similar feature in tensorflow? 
"
2791,map_fn: output type error when running the graph,"I am adding batch support to the inception example of tensorflow serving. In order to do that I have tweaked the [exporting script](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/inception_export.py) to support batch with a map function (I have also tweaked the inference server but I think it is not relevant for the bug):

``` python
...
    with tf.Graph().as_default():
        jpegs = tf.placeholder(tf.string, shape=(None))
        images = tf.map_fn(lambda image_buffer : tf.image.decode_jpeg(image_buffer, channels=3), jpegs, dtype=tf.uint8)
        images = tf.map_fn(lambda decode_image : tf.image.convert_image_dtype(decode_image, dtype=tf.float32), images, dtype=tf.float32)
        images = tf.image.resize_bilinear(images, [FLAGS.image_size, FLAGS.image_size], align_corners=False)
        images = tf.sub(images, 0.5)
        images = tf.mul(images, 2.0)
        logits, _ = inception_model.inference(images, len(labels_names))
...
```

The graph is exported without any issues but when testing it in tensorflow serving the client shows this error: 

> grpc.framework.interfaces.face.face.NetworkError: NetworkError(code=StatusCode.INTERNAL, details=""Output 0 of type string does not match declared output type float for node _recv_Mul_0 = _Recv[client_terminated=true, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=3531382951825773879, tensor_name=""Mul:0"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()"")

Somehow when the graph is executed the type of the placeholder is passed through the tensors up to the last operation before the inference graph when it shouldn't. If I comment the lines tf.sub and tf.mul the error is similar but in the tensor of the resize_bilinear function:

> grpc.framework.interfaces.face.face.NetworkError: NetworkError(code=StatusCode.INTERNAL, details=""Output 0 of type string does not match declared output type float for node _recv_ResizeBilinear_0 = _Recv[client_terminated=true, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=-7455415421321039987, tensor_name=""ResizeBilinear:0"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()"")

The error seems related with the map function.

tensorflow-serving commit hash: 1d7a9ceae1b9630377885ae7f38129d22ae0ad93 (June 8, 2016)
tensorflow commit: 592675b2b8d1cabbf923638942ea6f200abe353a (June 7, 2016)
"
2790,Issue re-building with Dockerfile.devel-gpu file,"I tried to build my own version of the `Dockerfile.devel-gpu` with the instructions on [this page](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker) but got the error as seen in the details below. 

After doing some troubleshooting I noticed the `tensorflow/core` folder wasn't getting created by the `git clone` statement that's in the `Dockerfile.devel-gpu` so I updated it to explicitly clone the `-b r0.8` branch and it worked successfully. See below for detailed updates. Is this the proper approach to take to resolve this issue or am I missing something? 

**Executed this command**

`$ docker build --pull -t $USER:tensorflow-suffix -f Dockerfile.devel-gpu .`

**Got this error**

```
...
INFO: Reading 'startup' options from /root/.bazelrc: --batch
Extracting Bazel installation...
____Loading package: tensorflow/tools/pip_package
____Loading...
____Loading package: tensorflow/core
____Loading package: tensorflow/models/image/cifar10
ERROR: /tensorflow/tensorflow/tools/pip_package/BUILD:23:1: error loading package 'tensorflow/core': Extension file not found. Unable to load package for '//google/protobuf:protobuf.bzl': BUILD file not found on package path and referenced by '//tensorflow/tools/pip_package:build_pip_package'.
ERROR: Loading failed; build aborted.
____Elapsed time: 1.802s
The command '/bin/sh -c ./configure &&     bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package &&     bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip &&     pip install --upgrade /tmp/pip/tensorflow-*.whl' returned a non-zero code: 1
```

**Select contents of Dockerfile.devel-gpu BEFORE (results in error)**

`RUN git clone --recursive https://github.com/tensorflow/tensorflow.git && \
    cd tensorflow && \
    git checkout r0.8`

**Select contents of Dockerfile.devel-gpu AFTER (working successfully)**

`RUN git clone -b r0.8 --recursive https://github.com/tensorflow/tensorflow.git && \
    cd tensorflow && \
    git checkout r0.8`
### Environment info

Operating System: Ubuntu 14.04.3 LTS (GNU/Linux 3.13.0-74-generic x86_64)

Installed version of CUDA and cuDNN: Using `nvidia/cuda:7.5-cudnn4-devel` as base image for Docker build

Docker version 1.11.2, build b9f10c9
"
2789,DropoutWrapper has unintended mask behavior when random seed is set,"When using the non-dynamic `rnn`, if the `seed` is set to something other than `None` for `DropoutWrapper`, the dropout masks for the inputs become synchronized across time steps. I.e. the same input dimension is dropped for all time steps for a given entry in a batch. If the maximum number of time steps varies between batches, then the later time steps begin to go out of sync (but all time steps that are earlier than the shortest sequence remain synchronized throughout). This behavior only affects the statically rolled out `rnn`. Dynamically rolled out RNNs using `dynamic_rnn` are always randomized per time step.
"
2788,"Tensorflow hangs without explanation, some threads stay busy.","I've got a machine running a GTX 980 Ti with 32 gb of ram (of which about half is used by the data loading pipeline) and a i7-5930K cpu driving a network. I'm running Ubuntu 14.04, I've got the drivers x86_64-361.45.11 installed, I've installed CUDA 7.5.18_linux with CUDNN linux-x64-v4.0-prod. Every 30 or so iterations the run method hangs and 2 to 5 virtual cores are busy, with the gpu not doing anything more than idling. I thought it hanged indefinitely but when I ran it overnight I saw that it actually completed what it was doing after some time. Pausing and continuing the process using gdb will make it continue immediately. I saw something like this with the initial release of 0.6.0 but it was fixed by 0.6.1 so I just pulled from master and assumed I would never see it again. Inspecting the root process just shows that its waiting on the run method:

```
(gdb) bt full
#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185
No locals.
#1  0x00007f29299964dc in std::condition_variable::wait(std::unique_lock<std::mutex>&) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
No symbol table info available.
#2  0x00007f292b46a883 in tensorflow::DirectSession::WaitForNotification(tensorflow::DirectSession::RunState*, long long) ()
   from /usr/local/lib/python3.4/dist-packages/tensorflow/python/_pywrap_tensorflow.so
No symbol table info available.
#3  0x00007f292b474800 in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) () from /usr/local/lib/python3.4/dist-packages/tensorflow/python/_pywrap_tensorflow.so
No symbol table info available.
#4  0x00007f292b549c81 in TF_Run_Helper(TF_Session*, char const*, TF_Buffer const*, char const**, TF_Tensor**, int, char const**, TF_Tensor**, int, char const**, int, TF_Buffer*, TF_Status*) ()
   from /usr/local/lib/python3.4/dist-packages/tensorflow/python/_pywrap_tensorflow.so
No symbol table info available.
#5  0x00007f292b54a0f1 in TF_Run () from /usr/local/lib/python3.4/dist-packages/tensorflow/python/_pywrap_tensorflow.so
No symbol table info available.
#6  0x00007f292a5787b2 in tensorflow::TF_Run_wrapper_helper(TF_Session*, char const*, TF_Buffer const*, tensorflow::gtl::InlinedVector<std::pair<char const*, tagPyArrayObject*>, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()
   from /usr/local/lib/python3.4/dist-packages/tensorflow/python/_pywrap_tensorflow.so
No symbol table info available.
#7  0x00007f292a578de1 in tensorflow::TF_Run_wrapper(TF_Session*, TF_Buffer const*, tensorflow::gtl::InlinedVector<std::pair<char const*, tagPyArrayObject*>, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()
   from /usr/local/lib/python3.4/dist-packages/tensorflow/python/_pywrap_tensorflow.so
No symbol table info available.
#8  0x00007f292a5666c8 in _wrap_TF_Run () from /usr/local/lib/python3.4/dist-packages/tensorflow/python/_pywrap_tensorflow.so
No symbol table info available.
...
```

Inspection of one of the busy threads is also equally uninteresting:

```
(gdb) bt full
#0  0x00007f293767e3f7 in sched_yield () at ../sysdeps/unix/syscall-template.S:81
No locals.
#1  0x00007f292b76aa60 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(unsigned int) ()
   from /usr/local/lib/python3.4/dist-packages/tensorflow/python/_pywrap_tensorflow.so
No symbol table info available.
#2  0x00007f292b769f52 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()
   from /usr/local/lib/python3.4/dist-packages/tensorflow/python/_pywrap_tensorflow.so
No symbol table info available.
#3  0x00007f2929999a60 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
No symbol table info available.
#4  0x00007f2937980182 in start_thread (arg=0x7f28657fa700) at pthread_create.c:312
        __res = <optimized out>
        pd = 0x7f28657fa700
        now = <optimized out>
        unwind_buf = {cancel_jmp_buf = {{jmp_buf = {139811478284032, -825179003405916230, 1, 0, 139811478284736, 139811478284032, 782688377649571770, 783080021823268794}, mask_was_saved = 0}}, priv = {
            pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}
        not_first_call = <optimized out>
        pagesize_m1 = <optimized out>
        sp = <optimized out>
        freesize = <optimized out>
        __PRETTY_FUNCTION__ = ""start_thread""
#5  0x00007f29376ad47d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111
No locals.
```

Finally the cpu usage revealed by htop doesn't seem to be fully accounted for in the displayed processes, 5 virtual cores might be busy but the processes are only credited with 0-300% cpu usage.
"
2787,0.9rc0 regression when using scan over axes with shape None,"A simple cumulative sum with scan that worked in TF 0.8 fails in 0.9rc0 with an inconsistent shape error. I have attached code to illustrate the error below. Basically, a scan over the 0th axis fails when a different axis has None shape. This occurs, for example, when computing a cumulative sum over an arbitrary axis of a minibatched variable (after first transposing that axis to be in the 0th position).
### Environment info

Operating System: Mac OSX 10.11.5

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): N/A

If installed from binary pip package, provide:
1. Which pip package you installed: 
   
   `https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0rc0-py3-none-any.whl`
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   
   `0.9.0rc0`

If installed from sources, provide the commit hash:
### Steps to reproduce

Run the following code:

``` python
import tensorflow as tf
x = tf.placeholder(dtype=tf.float32, shape=[None, 2])
xT = tf.transpose(x)
# scan over dimension 0 (with shape None)
result = tf.scan(lambda a, x: a + x, x)
# scanned over transposed dimension 0 (with shape 2)
resultT = tf.scan(lambda a, x: a + x, xT)
```

To see the following error:
`ValueError: Inconsistent shapes: saw (?,) but expected (?,) (and infer_shape=True)`
"
2784,Lite runtime is not supported in proto3,"compiling proto3 for ios with `tensorflow/contrib/makefile/compile_ios_protobuf.sh` an error is thrown on the `make` step:

`google/protobuf/unittest_proto3_arena_lite.proto: Lite runtime is not supported in proto3.`

It seems that Lite support has been added to the master branch of protobuf however: https://github.com/google/protobuf/issues/1443

any idea why this error persists? Same for a clean pull and install of tf, as well as a couple of other proto branches.
"
2783,Building TensorFlow on RaspberryPi,"I'm trying to build `TensorFlow` on a Raspberry Pi (OS : Raspbian Jessie), but I get this error :  

http://pastebin.com/zUfP4xsP

I use this command to build TensorFlow : 
`sudo bazel build -c opt --local_resources 1024,1.0,1.0 --verbose_failures --ignore_unsupported_sandboxing --copt=""-mfpu=neon"" tensorflow/tools/pip_package:build_pip_package
`

Any help ?
"
2782,cannot assign,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2781,Deep MNIST for Experts Tutorial accuracy is lower than expected (0.9091),"### Environment info

Operating System:

> $ uname -a
> Linux vvinahradski 4.4.0-23-generic #41-Ubuntu SMP Mon May 16 23:04:25 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
> Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
Not installed

If installed from binary pip package, provide:
1. Which pip package you installed.
   https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0rc0-cp35-cp35m-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.9.0rc0
### Steps to reproduce
1. Copy/past https://www.tensorflow.org/versions/r0.9/tutorials/mnist/pros/index.html#deep-mnist-for-experts tutorial
2. Run code
3. Observe that accuracy is around 90% instead of expected 99%
### What have you tried?
1. Increased test dataset 10x times. Accuracy is around 94%
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
Source code:
[tut.zip](https://github.com/tensorflow/tensorflow/files/308938/tut.zip)
console output:
[log.txt](https://github.com/tensorflow/tensorflow/files/308940/log.txt)
"
2780,Potential Contribution: Ansible roles & playbooks,"I've been running tensorflow on ec2 spot instances rather than buying a GPU, and I've written a few ansible playbooks to make this easier given spot instances go down, etc.

I split the base software out into two separate Ansible roles, one for CUDA/cuDNN: (For those unfamiliar with Ansible, the meat is in blob/master/tasks/main.yml)
https://github.com/kuza55/ansible-cudnn
And one for Bazel/TensorFlow:
https://github.com/kuza55/ansible-tensorflow

I've also got a playbook for baking an ec2 AMI from these, and for setting up more AWS-specific things, which I'll open source after I figure out how they should be structured that isn't super specific to all of my ec2 settings.

One thing I haven't done, but may be of interest, is to put together a playbook for setting up a tensorflow cluster and then doing some distributed training.

Let me know if there is any interest in accepting these and linking to them from somewhere (it takes people a while to realize there's a lot of good stuff in the contrib directory).

I'll probably try and submit these to Ansible Galaxy in the hopes people can find it more easily in either case.
"
2779,dynamic_rnn execution with EmbeddingWrapper,"Hi Guys,

I'm currently working on a sequence to sequence model for sequences with variable length. Instead of using buckets (like in the example of seq2seq) I used the `rnn.dynamic_rnn` function. But when I use an EmbeddingWrapper around my RNNCell I'll get exceptions because of two reasons:
- EmbeddingWrapper doesn't implement the derived property `def output_size(self):` (used in the function `dynamic_rnn`)
- Since I want to use word embeddings and `dynamic_rnn`, my input has the datatype `tf.int32` (like in the seq2seq example) and shape (batch_size, n_steps, 1). But then I get following error: 

> ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(""RNN/while/BasicRNNCell/Tanh:0"", shape=(3, 4), dtype=float32)'

Since I'm new to tensorflow I don't know whats the best way to fix this issue. However, If I change the datatype of the input to `tf.float32` and the modify EmbeddingWrapper class as follows it works.

```
class EmbeddingWrapper(RNNCell):
    if not isinstance(cell, RNNCell):
      raise TypeError(""The parameter cell is not RNNCell."")
    if embedding_classes <= 0 or embedding_size <= 0:
      raise ValueError(""Both embedding_classes and embedding_size must be > 0: ""
                       ""%d, %d."" % (embedding_classes, embedding_size))
    self._cell = cell
    self._embedding_classes = embedding_classes
    self._embedding_size = embedding_size
    self._initializer = initializer

  @property
  def state_size(self):
    return self._cell.state_size

  @property
  def output_size(self):
    return self._cell.output_size

  def __call__(self, inputs, state, scope=None):
    inputs = tf.cast(inputs, tf.int32) # <<<< if I cast the input (tf.float32) to tf.int32 it works

    with vs.variable_scope(scope or type(self).__name__):  # ""EmbeddingWrapper""
      with ops.device(""/cpu:0""):
        if self._initializer:
          initializer = self._initializer
        elif vs.get_variable_scope().initializer:
          initializer = vs.get_variable_scope().initializer
        else:
          # Default initializer for embeddings should have variance=1.
          sqrt3 = math.sqrt(3)  # Uniform(-sqrt(3), sqrt(3)) has variance=1.
          initializer = init_ops.random_uniform_initializer(-sqrt3, sqrt3)
        embedding = vs.get_variable(""embedding"", [self._embedding_classes,
                                                  self._embedding_size],
                                    initializer=initializer)
        embedded = embedding_ops.embedding_lookup(
            embedding, array_ops.reshape(inputs, [-1]))
    return self._cell(embedded, state)
```

I attached a simple working example: [simplernn.txt](https://github.com/tensorflow/tensorflow/files/308766/simplernn.txt)

My Environment:
- Ubuntu 16.04, installed tensorflow 0.9rc0 over pip, python 3.5.1

Thanks in advance!
"
2778,Isn't current tensorflow-git r0.9? ,"### Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
cuda 7.5
cudnn 5.0.5

Build from source, tensorflow-git-master

Just use bazel to build tensorflow, which built out a version 0.8.0, instead of 0.9.0 ....

Shouldn't current git master build out 0.9.0, instead of 0.8.0?

Cheers
Pei
"
2777,tensorflow - KeyError in nearest,"when i am running this code on small corpus i am getting key error because that key is not in dict and corpus vocab is also not that huge.

```
sim = similarity.eval()
for i in xrange(valid_size):
                valid_word = reverse_dictionary[valid_examples[i]]
                print(""--"",valid_word)
                top_k = 5 # number of nearest neighbors

                nearest = (-sim[i, :]).argsort()[1:top_k+1]
                print(nearest)
                log_str = ""Nearest to %s:"" % valid_word
                print(log_str)
                for k in xrange(top_k):

                  close_word = reverse_dictionary[nearest[k]]
```

My output are like this:

```
Average loss at step  0 :  139.830688477
[[ 0.01613899 -0.06088334 -0.043384   ...,  0.02021606 -0.10094199
   0.16063547]
 [ 1.00000012  0.10277888 -0.20193034 ..., -0.04780241  0.07802841
   0.13258868]
 [ 0.09824251 -0.17075592  0.10143445 ...,  0.09903113 -0.08740355
  -0.00371696]
 ..., 
 [-0.01591019  0.02056946  0.09188825 ..., -0.0506176   0.07684846
   0.06354721]
 [-0.06749535  0.0028128  -0.09138335 ...,  0.09473826  0.04847325
  -0.00853895]
 [ 0.01795161  0.01850585  0.04632751 ...,  0.11854959  0.11196665
  -0.00684015]]
16
[-0.01613899  0.06088334  0.043384   ..., -0.02021606  0.10094199
 -0.16063547]
<type 'numpy.ndarray'>
[ 31 113 118 ..., 650 353 233]
-- using
[113 118 555 298 150]
Nearest to using:
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-129-cf006e08ddb8> in <module>()
     87                 for k in xrange(top_k):
     88 
---> 89                   close_word = reverse_dictionary[nearest[k]]
     90                   log_str = ""%s %s,"" % (log_str, close_word)
     91                 print(log_str)

KeyError: 555
```

vocab_length  = 1155
batch_size = 16
embedding_size = 128  
skip_window = 5  
num_skips = 4         

valid_size = 16  
valid_window = 100  
valid_examples = np.random.choice(valid_window, valid_size, replace=False)
num_sampled =64   

Can anybody help please?
"
2776,TensorFlow : Machine Translation example Segmentation fault (Core dumped),"![cuda](https://cloud.githubusercontent.com/assets/5551707/15954993/e761dda4-2efa-11e6-8d70-a36a8ad02239.png)
GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: AWS X2-large GPU instance. Ubuntu

Installed version of CUDA 7.5 and cuDNN: 7.5.18
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. - 0.8.0

If installed from sources, provide the commit hash:
### Steps to reproduce
1. Running the translate.py script from tensorflow/modles/rnn/translate path
2. It downloads the files, unzip's the files
3. prepares the data - > creates the vocabulary for English and French data -> tockenizes the data -> train_set = read_data(en_train, fr_train, FLAGS.max_train_data_size) 
4. In train_set = read_data(en_train, fr_train, FLAGS.max_train_data_size) there is a crash bacause of out of memory.
### What have you tried?
1. Tried to give smaller batch size. varied from 32,64 ...512
### log

segmentation fault(core dumped)
I tried to run gdb and when I back traced I found this
PyObject_Malloc (nbytes=<optimized out) at ../objects/obmalloc.c 934

How can I run Machine Translation example on a smaller dataset.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2775,Bazel fail to resolve submodule tensorflow,"It does not seem possible to build an Android application where TensorFlow r0.9 is a submodule.

The trick should have been to set the correct path prefix and give a repository name, but it does not work:

`tf_workspace(
  path_prefix = tensorflow_path,
  tf_repo_name = ""@caloric_lab""
 )
`
Bazel: 0.2.1-homebrew
OSX El Capitan

WORKSPACE file:

```
tensorflow_path = path/to/tensorflow""

local_repository(
    name = ""org_tensorflow"",
    path = tensorflow_path
)

android_sdk_repository(
    name = ""androidsdk"",
    api_level = 23,
    build_tools_version = ""23.0.3"",
    # Replace with path to Android SDK on your system
    path = ""/Users/<user>/Library/Android/sdk/"",
)

android_ndk_repository(
    name=""androidndk"",
    path=""/Users/<user>/workspace/android/android-ndk-r10e/"",
    api_level=21)

# Please add all new TensorFlow dependencies in workspace.bzl.
load(""@org_tensorflow//tensorflow:workspace.bzl"", ""tf_workspace"")
tf_workspace(
  path_prefix = tensorflow_path,
  tf_repo_name = ""@caloric_lab""
 )

# Specify the minimum required bazel version.
load(""@org_tensorflow//tensorflow:tensorflow.bzl"", ""check_version"")
check_version(""0.2.0"")

bind(
 name   = ""android_tensorflow_lib"",
 actual = ""@org_tensorflow//tensorflow/core:android_tensorflow_lib""
)
```

BUILD file:

``` python
# Description:
#   Tensorflow camera demo app for Android.


#package(default_visibility = [""//visibility:public""])

#licenses([""notice""])  # Apache 2.0

load(""@org_tensorflow//tensorflow:tensorflow.bzl"", ""tf_copts"")

#exports_files([""LICENSE""])

cc_binary(
    name = ""caloric_lab.so"",
    srcs = glob([
        ""jni/**/*.cc"",
        ""jni/**/*.h"",
    ]) + ["":libpthread.so""],
    copts = tf_copts(),
    linkopts = [
        ""-landroid"",
        ""-ljnigraphics"",
        ""-llog"",
        ""-lm"",
        ""-z defs"",
        ""-s"",
        ""-Wl,--icf=all"",           # Identical Code Folding
        ""-Wl,--exclude-libs,ALL"",  # Exclude syms in all libs from auto export
    ],
    linkshared = 1,
    linkstatic = 1,
    tags = [
        ""manual"",
        ""notap"",
    ],
    deps = [
    ]
    #""@org_tensorflow//tensorflow/core:android_tensorflow_lib""
)

# This library only exists as a workaround to satisfy dependencies
# that declare -lpthread in their linkopts. Although Android supports
# pthreads, it does not provide it as a separate library.
cc_binary(
    name = ""libpthread.so"",
    srcs = [],
    linkopts = [""-shared""],
    tags = [
        ""manual"",
        ""notap"",
    ],
)

cc_library(
    name = ""caloric_lab_native_libs"",
    srcs = [
        "":libpthread.so"",
        "":caloric_lab.so""
    ],
    tags = [
        ""manual"",
        ""notap"",
    ],
)

android_binary(
    name = ""caloric_lab"",
    srcs = glob([
        ""src/**/*.java"",
    ]),
    assets = glob([""assets/**""]),
    assets_dir = ""assets"",
    custom_package = ""org.tensorflow.demo"",
    inline_constants = 1,
    manifest = ""AndroidManifest.xml"",
    resource_files = glob([""res/**""]),
    tags = [
        ""manual"",
        ""notap"",
    ],
    deps = [
      "":caloric_lab_native_libs"",
    ],
)
#""@org_tensorflow//tensorflow/core:android_tensorflow_lib""

filegroup(
    name = ""all_files"",
    srcs = glob(
        [""**/*""],
        exclude = [
            ""**/METADATA"",
            ""**/OWNERS"",
            ""bin/**"",
            ""gen/**"",
        ],
    ),
    visibility = [""@org_tensorflow//tensorflow:__subpackages__""],
)

filegroup(
    name = ""java_files"",
    srcs = glob([""src/**/*.java""]),
)

filegroup(
    name = ""jni_files"",
    srcs = glob([
        ""jni/**/*.cc"",
        ""jni/**/*.h"",
    ]),
)

filegroup(
    name = ""resource_files"",
    srcs = glob([""res/**""]),
)

exports_files([""AndroidManifest.xml""])
```

Thanks for your attention
Victor
"
2774,Poor numerics in CPU tf.multinomial,"The CPU implementation of tf.multinomial seems to have numerical underflow/overflow when logits are outside of a certain narrow range. The usable logit range on my system is about -88 to 88, which is unacceptably small for my use case (where the logits come from an automatically-trained hidden layer).

For example:

```
>>> logits = np.array([[1000.]*5])
>>> sess.run(tf.multinomial(logits, 10))
array([[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]])
```

Note that the index 5 is out of range (which is the _undocumented_ behavior used to signal an error condition). Expected behavior is to sample uniformly from [0, 4], such as in this workaround:

```
>>> logits = np.array([[1000.]*5])
>>> sess.run(tf.multinomial(tf.nn.log_softmax(logits), 10))
array([[2, 0, 4, 1, 0, 0, 2, 2, 2, 4]])
```

It's a similar story for negative logits:

```
>>> logits = np.array([[-1000.]*5])
>>> sess.run(tf.multinomial(logits, 10))
array([[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]])
>>> sess.run(tf.multinomial(tf.nn.log_softmax(logits), 10))
array([[2, 4, 3, 3, 3, 2, 2, 2, 3, 0]])
```

I think tf.multinomial should be fixed to accept a wider range of inputs. Or, if that's not possible e.g. due to speed tradeoffs, the workaround above should be noted in the documentation.

**System info**: tensorflow 845fb7ab77fae53b849894925c7d13c1b8918675, Python 3, CPU only on Mac OSX.
"
2773,Segmentation fault on tensorflow 0.9.0,"Hello, 
I installed tensorflow 0.9.0 from source in conda environment, It seems that the last comit didn't solve completely the problem, because I'm getting a segmentation fault while importing tensorflow (even if I import or not numpy and scipy before).

Note: this error occur only in tf 0.9, when trying tf 0.8, everything works well (but no GPU support for iOS in 0.8 version)
### Environment info

OS X 10.11.5
Python 2.7.11
Cuda 7.5
Cudnn 5
numpy 1.11.1rc1

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rwxr-xr-x@ 1 root  wheel   8.1K Apr 13 15:02 /usr/local/cuda/lib/libcuda.dylib*
lrwxr-xr-x@ 1 root  wheel    45B Apr 13 15:03 /usr/local/cuda/lib/libcudadevrt.a@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
lrwxr-xr-x@ 1 root  wheel    50B Apr 13 15:03 /usr/local/cuda/lib/libcudart.7.5.dylib@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
lrwxr-xr-x@ 1 root  wheel    46B Apr 13 15:03 /usr/local/cuda/lib/libcudart.dylib@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
lrwxr-xr-x@ 1 root  wheel    49B Apr 13 15:03 /usr/local/cuda/lib/libcudart_static.a@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a
```

If installed from sources, provide the commit hash:

> 1c618bca14dcd92669a3c1deb8a802f1867a68f7
### Steps to reproduce
1. Create a conda environment
2. Clone tensorflow 0.9.0 repository
3. Build it from souce using the instructions in Readme file
4. Launch python and import numpy and tensorflow (or import just tensorflow)
### What have you tried?
1. import tensorflow
2. import numpy and scipy, then tensorflow
3. uninstall tensorflow 0.8 outside the conda evironment
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

```
>>> import tensorflow
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally
Segmentation fault: 11
```
"
2772,Please consider adding flatten,"Please consider adding [flatten](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.ndarray.flatten.html) to `tensorflow`.
"
2771, output ImportError libcudart.so.7.5. in window 7 pycharm,"### Environment info

Operating System:  

```
 tensorflow in Ubuntu 14.04 
 pycharm in window 7
```

Installed version of CUDA and cuDNN: 

```
 cuda 7.5 and cudnn v4.0
```

If installed from binary pip package, provide:
1. Which pip package you installed.
   
    tensorflow-0.8-GPU-whl 
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   
    0.8
### Steps to reproduce
1. start samba in ubuntu
2. import remote  mnist example by pycharm in window 7
3. change python interpreter to remote ubuntu python
4. run mninst
### What have you tried?
1.  according to above step , output ImportError libcudart.so.7.5.  but ok if run mnist directly 
   by pycharm and command line in ubuntu machine .
### Logs or other output that would be helpful

ImportError libcudart.so.7.5
"
2770,LookupError: No gradient defined for operation 'ScatterUpdate_675' (op type: ScatterUpdate),"### Environment info

Operating System:  Ubuntu 14.04 TLS

Installed version of CUDA and cuDNN: 
-rw-r--r-- 1 root root 189170 May 10 10:51 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 May 10 10:51 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 May 10 10:51 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 May 10 10:51 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 May 10 10:51 /usr/local/cuda/lib/libcudart_static.a

using 0.8.0 and  0.9.0rc0 version cpu only.
I am building a graph involving scatter_update operation. When building optimizer op I am getting following error
**LookupError: No gradient defined for operation 'ScatterUpdate_675' (op type: ScatterUpdate)**

Looks like gradient is not defined for scatter_update. 
"
2769,Bad example in docs for tf.multinomial,"I think this comment in the docstring for tf.multinomial is wrong:

```
samples = tf.multinomial([[1, -1, -1]], 10) # samples is equivalent to tf.zeros([1, 10], dtype=tf.int64)
```

Logits of [1, -1, -1] do not assign zero probability to class 1 and 2.  Additionally, multinomial op has no kernel for `logits` of integer type, which is what's happening here. (Note usage of 1, not 1.0)

Since I can't figure out what purpose this example serves, my suggestion would be to remove it entirely.

I'm using tensorflow 845fb7ab77fae53b849894925c7d13c1b8918675 with Python 3.
"
2768,Checkpoint Restore blocked by changed default bias variable name,"### Environment info

Operating System: Ubuntu 14.04
Built from source (016da8c9b9f171235a528e3361b8068c693c5529)

Has there been a recent change that modified the default name of the bias variable from ""bias"" to ""biases"" (in the nn_ops.conv2d)?

When loading from a checkpoint there is an error:
tensorflow.python.framework.errors.NotFoundError: Tensor name ""model/attention_decoder/Attention_0/fully_connected/biases"" not found in checkpoint files .../model.ckpt

Looking the variables stored in a checkpoint file the closest match is:
model/attention_decoder/Attention_0/fully_connected/bias (DT_FLOAT) [512]

Loading this checkpoint file had been working fine for weeks, so it seems like a TF update that has caused the issue.

Can the model.ckpt[.meta] be edited to work around the change?  If so, is there a guide or any pointers for how to do it.  
"
2766,Dataflow execution model for tensorflow,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2765,Initializing all weight matrices for RNN,"It is currently impossible to initialize the input -> hidden connectivity matrix, and the hidden->hidden connectivity matrix in RNNCells. Indeed, these are generated automatically in tf.python.ops.rnn_cell._linear, which constricts the connectivity architecture. As an example, I would like to have an identity connectivity matrix for input->hidden (H), an all-to-all for H->H and another identity for H->output. This is currently not feasible if you don't want to correct the weights at every iteration. 

I am not sure if this is the right place to post it, since I have never contributed to big projects like tensorflow. Nevertheless, I modified the BasicRNNCell and _linear function in order to allow such initialization.

_High level description_: 
BasicRNNCell can now take 'initializer' and 'trainable' as inputs, which can be both list of two elements.
**Initializer**: Weight matrix combining Input -> H and H -> H connections. Initializer can actually be a list of two matrices, or a matrice and a vector. The first matrix can act as an update index (if trainable of the first matrix is set to False) and the other one (trainable) will either do a dot product (if w2 is a vector) or element wise model (if w2 is a matrix). 
**Trainable**: Whether the specified weight matrice can be trained. If 'initializer' is composed of two matrices, 'trainable' has to be a boolean list of two elements. 

This allows a full control of the weight matrices for the cell, while still leaving all the defaults behaviours. 

**Code changes are wrap between double stars ( *\* ). Do a CTRL+F to highlight them.**
## BasicRNNCell function

```
`class BasicRNNCell(RNNCell):
  """"""The most basic RNN cell.""""""

  def __init__(self, num_units, input_size=None, activation=tanh,
                     **initializer = None, trainable = True**):
    if input_size is not None:
      logging.warn(""%s: The input_size parameter is deprecated."" % self)
   self._num_units   = num_units
    self._activation  = activation
   **self._initializer = initializer**
    **self._trainable   = trainable**
  @property
  def state_size(self):
    return self._num_units

  @property
  def output_size(self):
    return self._num_units

  def __call__(self, inputs, state, scope=None):
    """"""Most basic RNN: output = new_state = activation(W * input + U * state + B).""""""
    with vs.variable_scope(scope or type(self).__name__):  # ""BasicRNNCell""
      output = self._activation(_linear([inputs, state], 
                                        self._num_units, 
                                        True,
                                        **initializer = self._initializer**,
                                        **trainable   = self._trainable**))
    return output, output`
```
## _linear function

```
def _linear(args, output_size, bias, bias_start=0.0, scope=None,
            **initializer=None, trainable=True**):
  """"""Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.

  Args:
    args: a 2D Tensor or a list of 2D, batch x n, Tensors.
    output_size: int, second dimension of W[i].
    bias: boolean, whether to add a bias term or not.
    bias_start: starting value to initialize the bias; 0 by default.
    scope: VariableScope for the created subgraph; defaults to ""Linear"".
    **initializer: Initial weight tensor. Can be a list with up to 2 tensors. 
                 If both tensors are 2D, an element wise multiplication 
                 will be applied. If the first tensor is 2D and the second 1D, 
                 innder product will be applied. Ws have to have inner dimension
                 equal to total_arg_size.
    trainable: True if the variable is trainable. Can be a list with 
               same dimension as initializer.**

  Returns:
    A 2D Tensor with shape [batch x output_size] equal to
    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.

  Raises:
    ValueError: if some of the arguments has unspecified or wrong shape.
  """"""
  if args is None or (_is_sequence(args) and not args):
    raise ValueError(""`args` must be specified"")
  if not _is_sequence(args):
    args = [args]

  # Calculate the total size of arguments on dimension 1.
  total_arg_size = 0
  shapes = [a.get_shape().as_list() for a in args]
  for shape in shapes:
    if len(shape) != 2:
      raise ValueError(""Linear is expecting 2D arguments: %s"" % str(shapes))
    if not shape[1]:
      raise ValueError(""Linear expects shape[1] of arguments: %s"" % str(shapes))
    else:
      total_arg_size += shape[1]   

  **if not np.shape(initializer) and not np.shape(trainable):
    trainLen = initLen = 0
  elif not np.shape(trainable):
    initLen  = np.shape(initializer)[0]
    trainLen = 1
  else:
    initLen = len(initializer)
    trainLen = len(trainable)
  if initLen != trainLen:
    raise ValueError(""`initializer`(len: %s) and `trainable`(len: %s) must be the same len.""
                      % (str(initLen), str(trainLen)))**

  # Now the computation.
  with vs.variable_scope(scope or ""Linear""):
    **if not initializer:**
      matrix = vs.get_variable(""Matrix"", [total_arg_size, output_size], 
                                 **trainable = trainable)
    else:
      if initLen == 1: 
        matrix = vs.get_variable(""Matrix"",initializer = initializer,
                                          trainable   = trainable)
      elif initLen == 2:
        init0Shape = initializer[0].get_shape().as_list()
        init1Shape = initializer[1].get_shape().as_list() 

        if init0Shape[0] !=total_arg_size:
          raise ValueError(
    ""`initializer` first dimension (%s,) should be equal to the `input` inner dimension (%s,).""
                            % (str(init0Shape[0]),str(total_arg_size)))

        matrix0 = vs.get_variable(""Matrix0"",initializer = initializer[0],
                                            trainable   = trainable[0]  )
        matrix1 = vs.get_variable(""Matrix1"",initializer = initializer[1],
                                            trainable   = trainable[1]  )            
        if init0Shape[1] > init1Shape[1]:
          matrix = math_ops.matmul(matrix0,matrix1)
        elif init0Shape[1] == init1Shape[1]:
          matrix = math_ops.mul(matrix0,matrix1)
        else:
          raise ValueError(""First matrix in `initializer` should be equal or bigger \
                            than the second matrix"")
      else:
        raise ValueError(""`initializer`and `trainable` must be lists of 2 elements \
                               maximum"") 
    if len(args) == 1:
      res = math_ops.matmul(args[0], matrix)
    else:
      res = math_ops.matmul(array_ops.concat(1, args), matrix)**
    if not bias:
      return res
    bias_term = vs.get_variable(
        ""Bias"", [output_size],
        initializer = init_ops.constant_initializer(bias_start))
  return res + bias_term`
```

Would this be an interesting feature for a future release? I added error raises that cover pretty much all errors I could think of. This is a simple change and could be implemented in the other RNNCells type.

Thank you for your feedback.
"
2764,Run train op multiple times,"I have some fairly large batch sizes on which I'd like to take multiple gradient steps. While I could easily do this with a python for loop, I imagine that there might be a more efficient method that doesn't involve transferring the data to gpu on each iteration.

@yaroslavvb has confirmed that putting the train op in the fetch list multiple times doesn't work, and suggested that I could save my input tensors as variables with `tf.assign`. Unfortunately, this doesn't work for me because my input tensors have variable sizes, and tensorflow variables must have a fixed size.
"
2760,Provide variable scoping documentation,"This is to track a documentation request from an external user:

The section on variable scopes is pretty helpful and we have been using it to make more complicated nets more manageable. I think some information (could be informal, like a blog post) on best practices that perhaps Googlers are encouraged to follow in structuring their tensorflow code (e.g. for the purposes of speed, variable re-use, minimizing memory consumption, code reusability) would be of high interest to a lot of people. I get the feeling that most of that information might already be available but just that it is distributed across different parts of the documentation.
"
2758,"cuDNN DSO loaded in command line, but not by apache","GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

-rw-r--r-- 1 root root   322936 May 23 07:11 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 May 23 07:11 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 May 23 07:11 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 May 23 07:11 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 May 23 07:11 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 61453024 May 24 06:29 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 61453024 May 24 06:29 /usr/local/cuda/lib64/libcudnn.so.4
-rwxr-xr-x 1 root root 61453024 May 24 06:29 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 May 24 06:29 /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally

Segmentation fault (core dumped)

If installed from sources, provide the commit hash:
### Steps to reproduce
1. Install a Flask app along this tutorial: http://www.datasciencebytes.com/bytes/2015/02/24/running-a-flask-app-on-aws-ec2/
2. Install an image classification web app along this tutorial, but using tensorflow instead of caffe: https://clearsite.io/blog/2016/01/24/using-caffe-in-a-flask-application/
   3.
### What have you tried?
1. I tried various AWS EC2 AMI with tensorflow installed, and always the same problem. 
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

error.log of apache server:

I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:99] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH:
I tensorflow/stream_executor/cuda/cuda_dnn.cc:1562] Unable to load cuDNN DSO
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally

if I import tensorflow from command line:

I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally

echo $LD_LIBRARY_PATH
/usr/local/cuda/lib64
"
2756,Dataset in GPU memory: updating specific elements in existing tf.Variable,"My machine has a Titan X card so I would like to use the memory as efficient as possible to avoid expensive data transfer between the CPU and GPU. Therefore, I want to have as many images as possible (let's say 5 GB) on the GPU memory inside a `tf.Variable` or `tf.constant`. However, I also want to update these data tensors after a number of iterations (_e.g._ a replay memory). For training, I then only need to send sample indices to the GPU and use `tf.slice` to generate a training batch.

My question is what the correct way is to update specific elements in an existing `tf.Variable`? I already found methods using `tf.scatter_update` and `tf.slice`:

http://stackoverflow.com/questions/34685947/adjust-single-value-within-tensor-tensorflow
http://stackoverflow.com/questions/37593960/set-k-largest-elements-of-a-tensor-to-zero-in-tensorflow

But these methods seem cumbersome and tricky. Are there better ways of updating existing variables? 
"
2754,iOS example running bug,"### Environment info

Operating System: iOS
### Steps to reproduce
1. Follow the contrib/makefile/README to install the tensorflow iOS core lib
2. Download the graph .pb files and copy them in the .xcodeproj
3. Run the example, an error is logged
### Logs or other output that would be helpful

```
Running model failed:Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs
    [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false](DecodeJpeg/contents)]]
```

Is there a modification to do to the building of the lib to include jpeg ops?

Other notes:
- the version of Eigen downloaded in the `Makefile` is not the same as the one configured in the `.xcodeproj` (the include path uses another version hash), I kept the one from the `Makefile`
- after downloading http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz as indicated in the `README`, the `.pb` and `.txt` files don't have the same names as the ones in the iOS examples, I renamed them, although I'm not sure if the examples refer to the same model

Those last issues seem fixed by https://github.com/tensorflow/tensorflow/commit/a9d1af0cf55a28e46b0527dc927e249eafea4418#diff-05f2ac6ab411cf0c1e4ad1d7b96caf22R45
"
2753,C++ compilation of rule '@highwayhash//:sip_hash' failed (Tensorflow serving on Android),"Operating System: Ubuntu 16 64bit

Installed:
Android NDK (r10e / r11c), 
Android SDK (Latest), 
Tensorflow (Latest), 
Tensorflow serving (Latest), 
Bazel (0.2.1 / 0.2.3)

I can build android projects (SDK and NDK) with bazel, build Tensorflow with bazel and build android jni projects with bazel. 

This is the Error I get when trying to build an android project which uses tensorflow serving: ($ bazel build //MouthDetection:android).

`ERROR: /home/michiel/.cache/bazel/_bazel_michiel/224c8e6cc63c3cf5a14b148ed24603d7/external/highwayhash/BUILD:17:1: C++ compilation of rule '@highwayhash//:sip_hash' failed: arm-linux-androideabi-gcc failed: error executing command external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gcc -fstack-protector-strong -fpic -ffunction-sections -funwind-tables ... (remaining 38 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from external/highwayhash/highwayhash/sip_hash.h:23:0,
                 from external/highwayhash/highwayhash/sip_hash.cc:15:
external/highwayhash/highwayhash/state_helpers.h: In function 'void highwayhash::UpdateState(const char*, highwayhash::uint64, State*)':
external/highwayhash/highwayhash/state_helpers.h:36:76: error: there are no arguments to 'static_assert' that depend on a template parameter, so a declaration of 'static_assert' must be available [-fpermissive]
   static_assert((kPacketSize & (kPacketSize - 1)) == 0, ""Size must be 2^i."");
                                                                            ^
external/highwayhash/highwayhash/state_helpers.h:36:76: note: (if you use '-fpermissive', G++ will accept your code, but allowing the use of an undeclared name is deprecated)
In file included from external/highwayhash/highwayhash/sip_hash.cc:15:0:
external/highwayhash/highwayhash/sip_hash.h: At global scope:
external/highwayhash/highwayhash/sip_hash.h:31:9: error: expected nested-name-specifier before 'Key'
   using Key = uint64[2];
         ^
external/highwayhash/highwayhash/sip_hash.h:34:38: error: 'Key' does not name a type
   explicit INLINE SipHashState(const Key& key) {
                                      ^
external/highwayhash/highwayhash/sip_hash.h: In constructor 'highwayhash::SipHashState::SipHashState(const int&)':
external/highwayhash/highwayhash/sip_hash.h:35:39: error: invalid types 'const int[int]' for array subscript
     v0 = 0x736f6d6570736575ull ^ key[0];
                                       ^
external/highwayhash/highwayhash/sip_hash.h:36:39: error: invalid types 'const int[int]' for array subscript
     v1 = 0x646f72616e646f6dull ^ key[1];
                                       ^
external/highwayhash/highwayhash/sip_hash.h:37:39: error: invalid types 'const int[int]' for array subscript
     v2 = 0x6c7967656e657261ull ^ key[0];
                                       ^
external/highwayhash/highwayhash/sip_hash.h:38:39: error: invalid types 'const int[int]' for array subscript
     v3 = 0x7465646279746573ull ^ key[1];
                                       ^
external/highwayhash/highwayhash/sip_hash.h: At global scope:
external/highwayhash/highwayhash/sip_hash.h:114:50: error: 'Key' in 'class highwayhash::SipHashState' does not name a type
 static INLINE uint64 SipHash(const SipHashState::Key& key, const char* bytes,
                                                  ^
external/highwayhash/highwayhash/sip_hash.h: In function 'highwayhash::uint64 highwayhash::SipHash(const int&, const char*, highwayhash::uint64)':
external/highwayhash/highwayhash/sip_hash.h:116:52: error: no matching function for call to 'ComputeHash(const int&, const char*&, const uint64&)'
   return ComputeHash<SipHashState>(key, bytes, size);
                                                    ^
external/highwayhash/highwayhash/sip_hash.h:116:52: note: candidate is:
In file included from external/highwayhash/highwayhash/sip_hash.h:23:0,
                 from external/highwayhash/highwayhash/sip_hash.cc:15:
external/highwayhash/highwayhash/state_helpers.h:63:8: note: template<class State> highwayhash::uint64 highwayhash::ComputeHash(const typename State::Key&, const char*, highwayhash::uint64)
 uint64 ComputeHash(const typename State::Key& key, const char* bytes,
        ^
external/highwayhash/highwayhash/state_helpers.h:63:8: note:   template argument deduction/substitution failed:
external/highwayhash/highwayhash/state_helpers.h: In substitution of 'template<class State> highwayhash::uint64 highwayhash::ComputeHash(const typename State::Key&, const char*, highwayhash::uint64) [with State = highwayhash::SipHashState]':
external/highwayhash/highwayhash/sip_hash.h:116:52:   required from here
external/highwayhash/highwayhash/state_helpers.h:63:8: error: no type named 'Key' in 'class highwayhash::SipHashState'
In file included from external/highwayhash/highwayhash/sip_hash.cc:15:0:
external/highwayhash/highwayhash/sip_hash.h: At global scope:
external/highwayhash/highwayhash/sip_hash.h:120:60: error: 'Key' in 'class highwayhash::SipHashState' does not name a type
 static INLINE uint64 ReduceSipTreeHash(const SipHashState::Key& key,
                                                            ^
Target //MouthDetection:android failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 32.618s, Critical Path: 18.78s
`

Does anyone know a solution to this problem
"
2751,"Fail to build tensorflow pip - ""...external"" failed: No such file or directory ","I'm using bazel 0.2.3 as well, Ubuntu 16.04 + GCC 5.3.1, Cuda 7.5 + cudnn 5.0.5 .
I strictly followed https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installation-for-linux, but run into the same error 

> $ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
> Wed Jun 8 17:48:44 PDT 2016 : === Using tmpdir: /tmp/tmp.67PiK9GeAe
> rsync: change_dir ""/home/jiapei/Downloads/machinelearning/deeplearning/tensorflow//bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/external"" failed: No such file or directory (2)
> rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1183) [sender=3.1.1]

I noticed that I do **NOT** have the subfolder **external**, but only a folder **org_tensorflow**. In addition, I do **NOT** have a folder **main** .

> .../pip_package/build_pip_package.runfiles$ ls 
> d3                             iron_collapse               iron_range_behavior        paper_dropdown_menu  paper_styles
> dagre                          iron_dropdown               iron_resizable_behavior    paper_header_panel   paper_tabs
> eigen_archive                  iron_fit_behavior           iron_selector              paper_icon_button    paper_toggle_button
> es6_promise                    iron_flex_layout            iron_validatable_behavior  paper_input          paper_toolbar
> font_roboto                    iron_form_element_behavior  lodash                     paper_item           plottable
> graphlib                       iron_icon                   MANIFEST                   paper_material       polymer
> **init**.py                    iron_icons                  neon_animation             paper_menu           promise_polyfill
> iron_a11y_announcer            iron_iconset_svg            org_tensorflow             paper_menu_button    protobuf
> iron_a11y_keys_behavior        iron_input                  paper_behaviors            paper_progress       six_archive
> iron_ajax                      iron_list                   paper_button               paper_radio_button   web_animations_js
> iron_autogrow_textarea         iron_menu_behavior          paper_checkbox             paper_radio_group    webcomponentsjs
> iron_behaviors                 iron_meta                   paper_dialog               paper_ripple
> iron_checked_element_behavior  iron_overlay_behavior       paper_dialog_behavior      paper_slider

Can anybody help please?

Cheers
Pei
"
2750,Host a TensorBuilder patch for TensorFlow,"Hi,

> [TensorBuilder](https://github.com/cgarciae/tensorbuilder) is light-weight extensible library that enables you to easily create complex deep neural networks using functions from any Tensor-based library through a functional fluent immutable API based on the Builder Pattern. As a side effect, TensorBuilder is a library that gives expressive power to any Tensor-based library that decide to implement a TensorBuilder patch.

TensorBuilder hosts a patch for `tensorflow`, using this patch you can rewrite the code like this

```
import tensorflow as tf

x = tf.placeholder(tf.float32, shape=[None, 5])
keep_prob = tf.placeholder(tf.float32)

net = tf.contrib.layers.fully_connected(x, 10, activation_fn=tf.nn.tanh) # tanh(x * w + b)
net = tf.nn.dropout(net, keep_prob) # dropout(x, keep_prob)
h =  tf.contrib.layers.fully_connected(net, 3, activation_fn=tf.nn.softmax) # softmax(x * w + b)
```

as this 

```
import tensorflow as tf
import tensorbuilder as tb
import tensorbuilder.patches.tensorflow.slim

x = tf.placeholder(tf.float32, shape=[None, 5])
keep_prob = tf.placeholder(tf.float32)

h = (
    x.builder()
    .fully_connected(10, activation_fn=tf.nn.tanh)
    .map(tf.nn.dropout, keep_prob)
    .fully_connected(3, activation_fn=tf.nn.softmax)
    .tensor()
)
```

or even like this using a stronger patch

```
import tensorflow as tf
import tensorbuilder as tb
import tensorbuilder.patches.tensorflow.patch

x = tf.placeholder(tf.float32, shape=[None, 5])
keep_prob = tf.placeholder(tf.float32)

h = (
    x.builder()
    .tanh_layer(10) 
    .dropout(keep_prob)
    .softmax_layer(3)
    .tensor()
)
```

The patch for the `tensorflow` library currently has full support for branching, see this example with the strong patch

``` python
import tensorflow as tf
import tensorbuilder as tb
import tensorbuilder.patches.tensorflow.patch

x = tf.placeholder(tf.float32, shape=[None, 5])
keep_prob = tf.placeholder(tf.float32)

h = (
    x.builder()
    .fully_connected(10)
    .branch(lambda root:
    [
        root
        .relu_layer(3)
    ,
        root
        .tanh_layer(9)
        .branch(lambda root2:
        [
          root2
          .sigmoid_layer(6)
        ,
          root2
          .dropout(keep_prob)
          .softmax_layer(8)
        ])
    ])
    .sigmoid_layer(6) #<== This connects all the branches to a single output layer
    .tensor()
)
```

TensorBuilder even has a DSL that you get for free, so you could rewrite the previous as

```
import tensorflow as tf
import tensorbuilder as tb
import tensorbuilder.patches.tensorflow.patch
import tensorbuilder.dsl as dl #<== Notice the alias

x = tf.placeholder(tf.float32, shape=[None, 5])
keep_prob = tf.placeholder(tf.float32)

h = x.builder().pipe(
    dl.fully_connected(10),
    [
        dl.relu_layer(3)
    ,
        (dl.tanh_layer(9),
        [
            dl.sigmoid_layer(6)
        ,
            dl
            .dropout(keep_prob)
            .softmax_layer(8)
        ])
    ],
    dl.sigmoid_layer(6)
    .tensor()
)
```
### Invitation

I'd like to invite you to eventually host the TensorFlow patch for TensorBuilder on the TensorFlow library, because TensorBuilder really is just an empty shell, it doesn't even know about tensors, its a sort of functional tool for making non-composable/fluent APIs into composable/fluent APIs (in e.g. Elixir or Elm you wouldn't even need it), but it benefits a lot from libraries, and I am sure that tensorflow users will benefit a lot from it too.
"
2748,Skflow monitor bug?,"I tried to use the monitor functionality from the [latest build of tensorflow](http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastStableBuild/), in order to keep track of validation loss. Here is my code:

`classifier = learn.TensorFlowRNNClassifier(rnn_size=EMBEDDING_SIZE, n_classes=8, cell_type='gru', input_op_fn=input_op_fn, num_layers=3, bidirectional=False, sequence_length=None, batch_size=50, steps=2000, optimizer='Adam', learning_rate=exp_decay, continue_training=False, clip_gradients=5.0)

val_monitor = learn.monitors.ValidationMonitor(X_test, y_test)

classifier.fit(X_train, y_train, val_monitor, logdir='log_rnn')`

Here is the error message:

> Traceback (most recent call last):
>   File ""/home/yangmch/Documents/FB word2vec/RNN/FB RNN.py"", line 38, in <module>
>     classifier.fit(X_train, y_train, val_monitor, logdir='log_rnn')
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 160, in fit
>     monitors=monitors)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 498, in _train_model
>     monitors=monitors)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 225, in train
>     monitor.begin(max_steps=start_step + steps)
> TypeError: unsupported operand type(s) for +: 'int' and 'ValidationMonitor'
"
2746,Missing pywrap_tensorflow,"### Environment info

Operating System: Linux Mint 17 (Ubuntu 14.04)

Installed version of CUDA and cuDNN: 
N/A - running CPU mode only

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
$ python -c ""import tensorflow; print(tensorflow.__version__)""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""tensorflow/python/__init__.py"", line 48, in <module>
    from tensorflow.python import pywrap_tensorflow
ImportError: cannot import name pywrap_tensorflow
```

If installed from sources, provide the commit hash:

```
$ git rev-parse HEAD
b2a812b962f8088a8256d4e6271b9cd425936446
```
### Steps to reproduce
1. In python: import tensorflow
   1a. Alternatively in python: import pywraper_tensorflow
### What have you tried?
1. pip install, pip uninstall/reinstall, built from source
"
2745,running digits.py,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:MAC OSX El Captain

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
   tensorflow
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
   0.8.0

If installed from sources, provide the commit hash:
### Steps to reproduce

1.run run digits.py from examples in tensorflow/tensorflow/examples/skflow directory
2.
3.
### What have you tried?
1. BaseModel **init** does except argument - perhaps i need to update tensorflow but not sure how to using pip
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2742,Ubuntu 16.04 Makefile build,"I was attempting to use the Makefile to test build the library on my Ubuntu system (bazel builds to completion).

```
uname -a -m
Linux gking-ml-vm 4.4.0-21-generic #37-Ubuntu SMP Mon Apr 18 18:33:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
```
### Environment info

Operating System:

```
lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description:    Ubuntu 16.04 LTS
Release:    16.04
Codename:   xenial
```

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
ls -l /path/to/cuda/lib/libcud*
ls: cannot access '/path/to/cuda/lib/libcud*': No such file or directory
```

If installed from sources, provide the commit hash:

```
git show
commit 6431560b7ec3565154cb9cdc9c827db78ccfebe7
Merge: a0085c8 b7c4169
Author: Vijay Vasudevan <vrv@google.com>
Date:   Tue Jun 7 11:32:10 2016 -0700

    Merge pull request #2710 from vrv/branch_124251558

    Branch 124251558
```
### Steps to reproduce

1.)  `bash tensorflow/contrib/makefile/download_dependencies.sh`
2.) `make -f tensorflow/contrib/makefile/Makefile all`
**Fails here**: because protoc installed for Ubuntu 16.04 is `2.6.1`;

```
make -f tensorflow/contrib/makefile/Makefile all
protoc  tensorflow/core/util/test_log.proto --cpp_out /home/gking/Programming/tensorflow/tensorflow/contrib/makefile/gen/proto/
tensorflow/core/util/test_log.proto:2:10: Unrecognized syntax identifier ""proto3"".  This parser only recognizes ""proto2"".
tensorflow/contrib/makefile/Makefile:325: recipe for target '/home/gking/Programming/tensorflow/tensorflow/contrib/makefile/gen/proto/tensorflow/core/util/test_log.pb.cc' failed
make: *** [/home/gking/Programming/tensorflow/tensorflow/contrib/makefile/gen/proto/tensorflow/core/util/test_log.pb.cc] Error 1
```

3.) Even with an updated `protoc` build fails again:

```
gcc --std=c++11 -I/usr/local/include -I. -I/home/gking/Programming/tensorflow/tensorflow/contrib/makefile/downloads/ -I/home/gking/Programming/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-d02e6a705c30 -I/home/gking/Programming/tensorflow/tensorflow/contrib/makefile/gen/host_obj/ -c tensorflow/core/lib/strings/strcat.cc -o /home/gking/Programming/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/lib/strings/strcat.o
In file included from tensorflow/core/lib/strings/strcat.cc:23:0:
./third_party/eigen3/Eigen/Core:1:47: fatal error: eigen-eigen-0c0b79ecd74c/Eigen/Core: No such file or directory
compilation terminated.
tensorflow/contrib/makefile/Makefile:350: recipe for target '/home/gking/Programming/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/lib/strings/strcat.o' failed
make: *** [/home/gking/Programming/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/lib/strings/strcat.o] Error 1
```
### What have you tried?
1. Built a new version of `protoc`:

**What I did (note the dependencies given to fpm aren't correct);**:

```
wget https://github.com/google/protobuf/archive/v3.0.0-beta-3.tar.gz
tar xvzf v3.0.0-beta-3.tar.gz
cd protobuf-3.0.0-beta-3
./autogen.sh
./configure --prefix=/usr
make all
make ctags
make check
make install DESTDIR=/tmp/installdir
fpm -s dir -t deb -p protobufc_3.0.0-beta3_amd64.deb -n protobufc -v 3.0.0-beta3 -d ""libgcc1 >= 1:4.1.1"" -d ""libstdc++6 >= 5.2"" -C /tmp/installdir usr/bin usr/lib usr/include
```

After purging `protobuf-compiler` and other related packages I installed the new `fpm` built package (`sudo dpkg --install protobufc_3.0.0-beta3_amd64.deb`)
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

**EDIT:** Added some additional details.
"
2741,"Does max_pooling3d support strides that are not same along height, width and depth?","I am using tensorflow to train a network that has 3D convolutions and 3D max-pooling layers. Some of the 3D max-pooling layers use a stride of 1 along the depth and strides of 2 along height and depth. This seems to be causing issues.

For example: The following script should print a tensor with values of '82' but somehow some of the values turn out to be -3.40282347e+38 

**import tensorflow as tf

sess = tf.InteractiveSession()
X = tf.Variable(tf.ones([8,16,112,112,3]))
W = tf.Variable(tf.ones([3,3,3,3,64]))
b = tf.Variable(tf.ones([64]))
out = tf.nn.relu(tf.nn.bias_add(tf.nn.conv3d(X, W, strides=[1,1,2,2,1], padding='VALID'),b))
out1 = tf.nn.max_pool3d(out, [1,2,3,3,1], strides=[1,1,2,2,1], padding='VALID')
sess.run(tf.initialize_all_variables())

print out1.eval()**

Additional notes:
- I looked into the tensorflow/python/kernel_tests/pooling_ops_3d_test.py file and all the test cases seem to have the same stride across all dimensions. 
"
2740,ExponentialMovingAverage.average duplicates the current scope name,"Using tensorflow nightly.

``` python
import tensorflow as tf
with tf.name_scope('scope'):
    x = tf.Variable(42, dtype=tf.float32)
    ema = tf.train.ExponentialMovingAverage(decay=0.9)
    apply_op = ema.apply([x])
    average = ema.average(x)
    print average.name   # 'scope/scope/Variable/ExponentialMovingAverage:0'
    print ema.average_name(x)  # 'scope/Variable/ExponentialMovingAverage'
```
"
2736,Installation error on Ubuntu 16.04 64bit machine - $(PYTHON_BIN_PATH) not defined.,"For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

```
uname -a
Linux ubuntu 4.4.0-21-generic #37-Ubuntu SMP Mon Apr 18 18:33:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
```

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA not installed

If installed from sources, provide the commit hash:
https://github.com/tensorflow/tensorflow/commit/592675b2b8d1cabbf923638942ea6f200abe353a
### Steps to reproduce
1. Install the source using `bazel build -c opt //tensorflow/tools/pip_package:build_pip_package`
2. The necessary packages are installed but the error `in cmd attribute of genrule rule //tensorflow/contrib/session_bundle/example:half_plus_two: $(PYTHON_BIN_PATH) not defined.` is raised.
3. The fork is on par with the upstream master.
### What have you tried?
1. Have tried to search for similar issues, but couldn't find anything. Please point to the correct issue in case I am missing some existing issue.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

```
Extracting Bazel installation...
.........
INFO: Waiting for response from Bazel server (pid 8938)...
WARNING: /home/maniteja/.cache/bazel/_bazel_maniteja/98850693c9ebf4963f7f6ed5da9dc97a/external/protobuf/WORKSPACE:1: Workspace name in /home/maniteja/.cache/bazel/_bazel_maniteja/98850693c9ebf4963f7f6ed5da9dc97a/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
WARNING: /home/maniteja/.cache/bazel/_bazel_maniteja/98850693c9ebf4963f7f6ed5da9dc97a/external/highwayhash/WORKSPACE:1: Workspace name in /home/maniteja/.cache/bazel/_bazel_maniteja/98850693c9ebf4963f7f6ed5da9dc97a/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.
WARNING: /home/maniteja/.cache/bazel/_bazel_maniteja/98850693c9ebf4963f7f6ed5da9dc97a/external/re2/WORKSPACE:1: Workspace name in /home/maniteja/.cache/bazel/_bazel_maniteja/98850693c9ebf4963f7f6ed5da9dc97a/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
WARNING: /home/maniteja/FOSS/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
ERROR: /home/maniteja/FOSS/tensorflow/tensorflow/contrib/session_bundle/example/BUILD:45:9: in cmd attribute of genrule rule //tensorflow/contrib/session_bundle/example:half_plus_two: $(PYTHON_BIN_PATH) not defined.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
INFO: Elapsed time: 1356.436s
```

Thanks for your time. Please let me know if any additional information is needed.
"
2734,"RNN: tensorflow.python.framework.errors.InvalidArgumentError: indices[15,0] = 10535 is not in [0, 10000)","Hey. I adapted the example file (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py) to work on my training data. Unfortunately as soon as the training data exceeds a certain size I'm getting an error: http://pastebin.com/JkV7MCQk What could be the issue? How can I debug this?

Might it be an issue with the training data? (http://s000.tinyupload.com/index.php?file_id=02347215266721316111)
"
2732,Mention that GPU reductions are nondeterministic in docs,"# The problem

I am trying out the [MNIST for experts tutorial](https://www.tensorflow.org/versions/r0.7/tutorials/mnist/pros/index.html#deep-mnist-for-experts) and I have inconsistent results on the GPU.
### What do I mean by inconsistent?

With the exactly same network parameters (and randomness removed: read below in the post) every time I run the complete train-then-test process the accuracy is slightly different.
### What have I done to visualize this problem?

For each iteration, I have calculated the differences between the variables (weights, biases) from two _independent but identical_ runs and computed the L1 norm of those differences - <br/>
- [plot](http://i.stack.imgur.com/W5PqZ.png) of L1 norm for the first 1000 iterations in steps of 20.

In a consistent world, these differences should be always zero! 
### How did I remove randomness in the code?
- Removed dropout entirely
- added a graph level seed (`tf.set_random_seed(1234)`). With this the variable initialization is deterministic and also any other randomization in the code. 
- The [MNIST for experts tutorial](https://www.tensorflow.org/versions/r0.7/tutorials/mnist/pros/index.html#deep-mnist-for-experts) uses [this script](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/datasets/mnist.py) to download/load the MNIST data. I have added `numpy.random.seed(3)` in `DataSet.__init__(self, images, labels, fake_data=False, one_hot=False, dtype=dtypes.float32)` in this script to remove randomness during the shuffling process (line 154 in `DataSet.next_batch(self, batch_size, fake_data=False)`)
- `config = tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1)` which goes into the creation of session as `sess = tf.Session(config=config)`
### What system am I using?
- tensorflow 0.8 gpu version (installed via pip)
- OpenSUSE LEAP 42.1 (x86_64)
- Cuda Toolkit 7.5
- CuDNN 4.0
- Tesla K20c card with Nvidia driver 352.79
"
2731,Feature Request: Exporting Model to Eigen Only Environments,"This would be insanely useful. I understand that some operations don't map cleanly to Eigen operations. 

[https://github.com/riga/tfdeploy](https://github.com/riga/tfdeploy) addresses a similar goal and has a reasonable approach to handle custom ops. 

An API where the eigen only computational graph is generated and the ability to ""plug in"" missing ops?
"
2730,TensorBoard feature request: Search for Node,"I have been trying to retrain the inception v3 network and TensorBoard has been the only real way to introspect the network and it's implementation so far.

It would be very useful to be able to find nodes in the graph, by name or other properties. E.g. in my case I am interested in seeing the total_loss node that is being defined here: https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py#L120 To get a greater idea of what it is linked to.
"
2729,TensorBoard inception v3 visualization is horizontal and almost unusable,"### Environment info

Operating System: Linux x64 GPU

Installed version of CUDA and cuDNN: CUDA 7.5, cuDNN v4

If installed from binary pip package, provide: 0.8.0

I've been trying to retrain the inception v3 network using the image_retraining example, and then the inception v3 model in the models repo.

The image_retraining model[1] seems to visualize vertically and it relatively straight forward to look at.

The model from the models repo[2] visualizes horizontally, making zooming in and exploring the model really tricky.

[1] http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz
[2] http://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz
"
2728,Memory leak (on cpu) in 0.9rc (vs. 0.7.1rc),"Hi,
using the provided wheel vor 0.9rc (also reproduced with a fresh install from source) I'm seeing a lot of memory consumption (on the cpu) during training a model (on a gpu (TITAN X) which gets its data from a `tf.FIFOQueue` pinned with `tf.device()` to a cpu). I tested two different dataset sizes and these lead to 600MB and 1.2GB leaked memory respectively accumulated during the training loop (GPU memory consumption stays constant during training time).

This memory leak does not happen at all when running the same code using 0.7.1rc. Additionally,
with 0.9rc setting up the whole graph takes about 600MB vs 400MB with 0.7.1rc.

The code is rather large so it will take a bit to get a MWE to (hopefully) reproduce this issue. I suspect it is tied to using a queue (queues, actually, because the validation set is also feed through a different queue, relying on `tf.template()` to share model parameters). Has something like that been observed beforehand? Any hints how I could try figure out more of the problem myself?
### Environment info

Operating System:
Ubuntu 15.10

Installed version of CUDA and cuDNN: 
CUDA7.5/cuDNN4.0.4

(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rw-r--r-- 1 root root 189170 Jan  1 23:25 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Jan  1 23:25 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Jan  1 23:25 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Jan  1 23:25 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Jan  1 23:25 /usr/local/cuda/lib/libcudart_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed.
   https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally 0.9.0rc0
```
### Steps to reproduce
1. Working on MWE...
### What have you tried?

The described behavior does not happen with 0.7.1rc (UPDATE: also not observed with 0.8rc).
"
2727,tf learn bugs when running DNNClassifier examples,"from sklearn import datasets, metrics

iris = datasets.load_iris()
classifier = learn.DNNClassifier(hidden_units=[10, 20, 10], n_classes=3)
classifier.fit(iris.data, iris.target)
score = metrics.accuracy_score(iris.target, classifier.predict(iris.data))
print(""Accuracy: %f"" % score)

```
Traceback (most recent call last):

  File ""<ipython-input-73-ae8986fb272b>"", line 1, in <module>
    classifier.fit(iris.data, iris.target)

  File ""/home/wenjian/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 181, in fit
    monitors=monitors)

  File ""/home/wenjian/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 498, in _train_model
    monitors=monitors)

  File ""/home/wenjian/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 225, in train
    monitor.begin(max_steps=start_step + steps)

TypeError: unsupported operand type(s) for +: 'int' and 'NoneType'
```
"
2726,Modifying MNIST example to distributed version: could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR,"Operating System: 2 servers(each have 4 GPUs, Titan-x), ubuntu14.04
CUDA 7.5, cuDNN 4.0.7
Tensorflow has been installed with source file with bazel.

MNIST example works well on each single server.
~/tensorflow/tensorflow/models/image/mnist$ python convolutional.py

To make MNIST example as distributed version, I modified convolutional.py as follows.
I refer ""Putting it all together: example trainer program"" in 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/distributed/index.md

```
#Simple, end-to-end, LeNet-5-like convolutional MNIST model example.
#This should achieve a test error of 0.7%. Please keep this model as simple and
#linear as possible, it is meant as a tutorial for simple convolutional models.
#Run with --self_test on the command line to execute a short self-test.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import gzip
import os
import sys
import time

import numpy
from six.moves import urllib
from six.moves import xrange  # pylint: disable=redefined-builtin
import tensorflow as tf


SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/'
WORK_DIRECTORY = 'data'
IMAGE_SIZE = 28
NUM_CHANNELS = 1
PIXEL_DEPTH = 255
NUM_LABELS = 10
VALIDATION_SIZE = 5000  # Size of the validation set.
SEED = 66478  # Set to None for random seed.
BATCH_SIZE = 64
NUM_EPOCHS = 10
EVAL_BATCH_SIZE = 64
EVAL_FREQUENCY = 100  # Number of steps between evaluations.

  ######################################################################################
  #Flags for defining the tf.train.ClusterSpec
tf.app.flags.DEFINE_string(""ps_hosts"", """",
                           ""Comma-separated list of hostname:port pairs"")
tf.app.flags.DEFINE_string(""worker_hosts"", """",
                           ""Comma-separated list of hostname:port pairs"")

  #Flags for defining the tf.train.Server
tf.app.flags.DEFINE_string(""job_name"", """", ""One of 'ps', 'worker'"")
tf.app.flags.DEFINE_integer(""task_index"", 0, ""Index of task within the job"")
  ######################################################################################

tf.app.flags.DEFINE_boolean(""self_test"", False, ""True if running a self test."")
FLAGS = tf.app.flags.FLAGS


def maybe_download(filename):
  """"""Download the data from Yann's website, unless it's already here.""""""
  if not tf.gfile.Exists(WORK_DIRECTORY):
    tf.gfile.MakeDirs(WORK_DIRECTORY)
  filepath = os.path.join(WORK_DIRECTORY, filename)
  if not tf.gfile.Exists(filepath):
    filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)
    with tf.gfile.GFile(filepath) as f:
      size = f.Size()
    print('Successfully downloaded', filename, size, 'bytes.')
  return filepath


def extract_data(filename, num_images):
  """"""Extract the images into a 4D tensor [image index, y, x, channels].

  Values are rescaled from [0, 255] down to [-0.5, 0.5].
  """"""
  print('Extracting', filename)
  with gzip.open(filename) as bytestream:
    bytestream.read(16)
    buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)
    data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)
    data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH
    data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)
    return data


def extract_labels(filename, num_images):
  """"""Extract the labels into a vector of int64 label IDs.""""""
  print('Extracting', filename)
  with gzip.open(filename) as bytestream:
    bytestream.read(8)
    buf = bytestream.read(1 * num_images)
    labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.int64)
  return labels


def fake_data(num_images):
  """"""Generate a fake dataset that matches the dimensions of MNIST.""""""
  data = numpy.ndarray(
      shape=(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS),
      dtype=numpy.float32)
  labels = numpy.zeros(shape=(num_images,), dtype=numpy.int64)
  for image in xrange(num_images):
    label = image % 2
    data[image, :, :, 0] = label - 0.5
    labels[image] = label
  return data, labels


def error_rate(predictions, labels):
  """"""Return the error rate based on dense predictions and sparse labels.""""""
  return 100.0 - (
      100.0 *
      numpy.sum(numpy.argmax(predictions, 1) == labels) /
      predictions.shape[0])


def main(argv=None):  # pylint: disable=unused-argument
  ##########################################################################################
  ps_hosts = FLAGS.ps_hosts.split("","")
  worker_hosts = FLAGS.worker_hosts.split("","")

  # Create a cluster from the parameter server and worker hosts.
  cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})

  # Create and start a server for the local task.
  server = tf.train.Server(cluster,
                           job_name=FLAGS.job_name,
                           task_index=FLAGS.task_index)
  ##########################################################################################
  if FLAGS.self_test:
    print('Running self-test.')
    train_data, train_labels = fake_data(256)
    validation_data, validation_labels = fake_data(EVAL_BATCH_SIZE)
    test_data, test_labels = fake_data(EVAL_BATCH_SIZE)
    num_epochs = 1
  else:
    # Get the data.
    train_data_filename = maybe_download('train-images-idx3-ubyte.gz')
    train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')
    test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')
    test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')

    # Extract it into numpy arrays.
    train_data = extract_data(train_data_filename, 60000)
    train_labels = extract_labels(train_labels_filename, 60000)
    test_data = extract_data(test_data_filename, 10000)
    test_labels = extract_labels(test_labels_filename, 10000)

    # Generate a validation set.
    validation_data = train_data[:VALIDATION_SIZE, ...]
    validation_labels = train_labels[:VALIDATION_SIZE]
    train_data = train_data[VALIDATION_SIZE:, ...]
    train_labels = train_labels[VALIDATION_SIZE:]
    num_epochs = NUM_EPOCHS
  ##########################################################################################
  if FLAGS.job_name == ""ps"":
    server.join()
  elif FLAGS.job_name == ""worker"":
    # Assigns ops to the local worker by default.
    with tf.device(tf.train.replica_device_setter(
        worker_device=""/job:worker/task:%d"" % FLAGS.task_index,
        cluster=cluster)):
  ##########################################################################################
      train_size = train_labels.shape[0]

      # This is where training samples and labels are fed to the graph.
      # These placeholder nodes will be fed a batch of training data at each
      # training step using the {feed_dict} argument to the Run() call below.
      train_data_node = tf.placeholder(
          tf.float32,
          shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))
      train_labels_node = tf.placeholder(tf.int64, shape=(BATCH_SIZE,))
      eval_data = tf.placeholder(
          tf.float32,
          shape=(EVAL_BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))

      # The variables below hold all the trainable weights. They are passed an
      # initial value which will be assigned when we call:
      # {tf.initialize_all_variables().run()}
      conv1_weights = tf.Variable(
          tf.truncated_normal([5, 5, NUM_CHANNELS, 32],  # 5x5 filter, depth 32.
                              stddev=0.1,
                              seed=SEED))
      conv1_biases = tf.Variable(tf.zeros([32]))
      conv2_weights = tf.Variable(
          tf.truncated_normal([5, 5, 32, 64],
                              stddev=0.1,
                              seed=SEED))
      conv2_biases = tf.Variable(tf.constant(0.1, shape=[64]))
      fc1_weights = tf.Variable(  # fully connected, depth 512.
          tf.truncated_normal(
              [IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],
              stddev=0.1,
              seed=SEED))
      fc1_biases = tf.Variable(tf.constant(0.1, shape=[512]))
      fc2_weights = tf.Variable(
          tf.truncated_normal([512, NUM_LABELS],
                              stddev=0.1,
                              seed=SEED))
      fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS]))

      # We will replicate the model structure for the training subgraph, as well
      # as the evaluation subgraphs, while sharing the trainable parameters.
      def model(data, train=False):
        """"""The Model definition.""""""
        # 2D convolution, with 'SAME' padding (i.e. the output feature map has
        # the same size as the input). Note that {strides} is a 4D array whose
        # shape matches the data layout: [image index, y, x, depth].
        conv = tf.nn.conv2d(data,
                            conv1_weights,
                            strides=[1, 1, 1, 1],
                            padding='SAME')
        # Bias and rectified linear non-linearity.
        relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))
        # Max pooling. The kernel size spec {ksize} also follows the layout of
        # the data. Here we have a pooling window of 2, and a stride of 2.
        pool = tf.nn.max_pool(relu,
                              ksize=[1, 2, 2, 1],
                              strides=[1, 2, 2, 1],
                              padding='SAME')
        conv = tf.nn.conv2d(pool,
                            conv2_weights,
                            strides=[1, 1, 1, 1],
                            padding='SAME')
        relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))
        pool = tf.nn.max_pool(relu,
                              ksize=[1, 2, 2, 1],
                              strides=[1, 2, 2, 1],
                              padding='SAME')
        # Reshape the feature map cuboid into a 2D matrix to feed it to the
        # fully connected layers.
        pool_shape = pool.get_shape().as_list()
        reshape = tf.reshape(
            pool,
            [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])
        # Fully connected layer. Note that the '+' operation automatically
        # broadcasts the biases.
        hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)
        # Add a 50% dropout during training only. Dropout also scales
        # activations such that no rescaling is needed at evaluation time.
        if train:
          hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)
        return tf.matmul(hidden, fc2_weights) + fc2_biases

      # Training computation: logits + cross-entropy loss.
      logits = model(train_data_node, True)
      loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(
          logits, train_labels_node))

      # L2 regularization for the fully connected parameters.
      regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +
                      tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))
      # Add the regularization term to the loss.
      loss += 5e-4 * regularizers

      # Optimizer: set up a variable that's incremented once per batch and
      # controls the learning rate decay.
      batch = tf.Variable(0)
      # Decay once per epoch, using an exponential schedule starting at 0.01.
      learning_rate = tf.train.exponential_decay(
          0.01,                # Base learning rate.
          batch * BATCH_SIZE,  # Current index into the dataset.
          train_size,          # Decay step.
          0.95,                # Decay rate.
          staircase=True)
      # Use simple momentum for the optimization.
      optimizer = tf.train.MomentumOptimizer(learning_rate,
                                             0.9).minimize(loss,
                                                           global_step=batch)

      # Predictions for the current training minibatch.
      train_prediction = tf.nn.softmax(logits)

      # Predictions for the test and validation, which we'll compute less often.
      eval_prediction = tf.nn.softmax(model(eval_data))

      # Small utility function to evaluate a dataset by feeding batches of data to
      # {eval_data} and pulling the results from {eval_predictions}.
      # Saves memory and enables this to run on smaller GPUs.
      def eval_in_batches(data, sess):
        """"""Get all predictions for a dataset by running it in small batches.""""""
        size = data.shape[0]
        if size < EVAL_BATCH_SIZE:
          raise ValueError(""batch size for evals larger than dataset: %d"" % size)
        predictions = numpy.ndarray(shape=(size, NUM_LABELS), dtype=numpy.float32)
        for begin in xrange(0, size, EVAL_BATCH_SIZE):
          end = begin + EVAL_BATCH_SIZE
          if end <= size:
            predictions[begin:end, :] = sess.run(
                eval_prediction,
                feed_dict={eval_data: data[begin:end, ...]})
          else:
            batch_predictions = sess.run(
                eval_prediction,
                feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...]})
            predictions[begin:, :] = batch_predictions[begin - size:, :]
        return predictions
      # Run all the initializers to prepare the trainable parameters.
      #saver = tf.train.Saver()#dist
      summary_op = tf.merge_all_summaries()#dist
      init_op = tf.initialize_all_variables()#dist
      #tf.initialize_all_variables().run()
      print('Initialized!')
    ###################################################################################
    # Create a ""supervisor"", which oversees the training process.
    sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),
                             #logdir=""/home/user/tmp"",
                             init_op=init_op,
                             summary_op=summary_op,
                             #saver=saver,
                             global_step=batch)#,
                             #save_model_secs=600)
    ###################################################################################
    # Create a local session to run the training.
    start_time = time.time()
    #with tf.Session() as sess:
    #with sv.managed_session(server.target) as sess:
    with sv.prepare_or_wait_for_session(server.target, config=None) as sess:
      # Loop through training steps.
      for step in xrange(int(num_epochs * train_size) // BATCH_SIZE):
      #step = 0
      #while not sv.should_stop() and step < (int(num_epochs * train_size) // BATCH_SIZE):
        # Compute the offset of the current minibatch in the data.
        # Note that we could use better randomization across epochs.
        offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)
        batch_data = train_data[offset:(offset + BATCH_SIZE), ...]
        batch_labels = train_labels[offset:(offset + BATCH_SIZE)]
        # This dictionary maps the batch data (as a numpy array) to the
        # node in the graph it should be fed to.
        feed_dict = {train_data_node: batch_data,
                     train_labels_node: batch_labels}
        # Run the graph and fetch some of the nodes.
        _, l, lr, predictions = sess.run(
            [optimizer, loss, learning_rate, train_prediction],
            feed_dict=feed_dict)
        if step % EVAL_FREQUENCY == 0:
          elapsed_time = time.time() - start_time
          start_time = time.time()
          print('Step %d (epoch %.2f), %.1f ms' %
                (step, float(step) * BATCH_SIZE / train_size,
                 1000 * elapsed_time / EVAL_FREQUENCY))
          print('Minibatch loss: %.3f, learning rate: %.6f' % (l, lr))
          print('Minibatch error: %.1f%%' % error_rate(predictions, batch_labels))
          print('Validation error: %.1f%%' % error_rate(
              eval_in_batches(validation_data, sess), validation_labels))
          sys.stdout.flush()
      # Finally print the result!
      test_error = error_rate(eval_in_batches(test_data, sess), test_labels)
      print('Test error: %.1f%%' % test_error)
      if FLAGS.self_test:
        print('test_error', test_error)
        assert test_error == 0.0, 'expected 0.0 test_error, got %.2f' % (
            test_error,)
    # Ask for all the services to stop.
    sv.stop()


if __name__ == '__main__':
  tf.app.run()
```
# Commands
## on server1, terminal1

$python convolutional.py --ps_hosts=user-81:2222 --worker_hosts=user-81:2223,user-70:2223 --job_name=ps --task_index=0
## on server1, terminal2

$python convolutional.py --ps_hosts=user-81:2222 --worker_hosts=user-81:2223,user-70:2223 --job_name=worker --task_index=0
## on server2, terminal2

$python convolutional.py --ps_hosts=user-81:2222 --worker_hosts=user-81:2223,user-70:2223 --job_name=worker --task_index=1
# Message & Error
## Common

```
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:0b:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:09:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 2 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:06:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 3 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:05:00.0
Total memory: 12.00GiB
Free memory: 11.86GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 2 3
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y Y Y
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y Y Y
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 2:   Y Y Y Y
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 3:   Y Y Y Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:0b:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)
```
## on server1, terminal1

```
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {localhost:2222, user-70:2222}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {user-81:2223, user-70:2223}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2222
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
E tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 11.27G (12103048448 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 10.14G (10892742656 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 9.13G (9803467776 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 8.22G (8823120896 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
```

...
## on server1, terminal2

```
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {user-81:2222}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:2223, user-70:2224}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2223
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
Initialized!
E0608 20:36:08.411750480   23861 tcp_client_posix.c:173]     failed to connect to 'ipv4:143.248.39.70:2224': socket error: connection refused
E0608 20:36:09.412362146   23861 tcp_client_posix.c:173]     failed to connect to 'ipv4:143.248.39.70:2224': socket error: connection refused
E0608 20:36:11.005026028   23861 tcp_client_posix.c:173]     failed to connect to 'ipv4:143.248.39.70:2224': socket error: connection refused
E0608 20:36:13.191502278   23861 tcp_client_posix.c:173]     failed to connect to 'ipv4:143.248.39.70:2224': socket error: connection refused
WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager
E tensorflow/stream_executor/cuda/cuda_dnn.cc:289] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
E tensorflow/stream_executor/cuda/cuda_dnn.cc:278] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
W tensorflow/stream_executor/stream.cc:301] attempting to perform DNN operation using StreamExecutor without DNN support
Traceback (most recent call last):
  File ""convolutional.py"", line 367, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""convolutional.py"", line 343, in main
    feed_dict=feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 340, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 564, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 637, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 659, in _do_call
    e.code)
tensorflow.python.framework.errors.InternalError: cuDNN launch failure : input shape([64,1,28,28]) filter shape([5,5,1,32])
         [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:worker/replica:0/task:0/gpu:0""](_recv_Placeholder_0_G6, Variable/read_S53)]]
         [[Node: add_5_G12 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/cpu:0"", send_device=""/job:worker/replica:0/task:0/gpu:0"", send_device_incarnation=-6674272897051056682, tensor_name=""edge_106_add_5"", tensor_type=DT_FLOAT, _device=""/job:worker/replica:0/task:0/cpu:0""]()]]
Caused by op u'Conv2D', defined at:
  File ""convolutional.py"", line 367, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""convolutional.py"", line 254, in main
    logits = model(train_data_node, True)
  File ""convolutional.py"", line 220, in model
    padding='SAME')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 295, in conv2d
    data_format=data_format, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1154, in __init__
    self._traceback = _extract_stack()
```
## on server2, terminal2

```
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:0b:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {user-81:2222}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {user-81:2223, localhost:2224}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2224
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
Initialized!
E0608 20:36:48.351331932   18333 tcp_client_posix.c:173]     failed to connect to 'ipv4:143.248.39.81:2223': socket error: connection refused
E0608 20:36:49.352058170   18333 tcp_client_posix.c:173]     failed to connect to 'ipv4:143.248.39.81:2223': socket error: connection refused
E0608 20:36:50.939646814   18333 tcp_client_posix.c:173]     failed to connect to 'ipv4:143.248.39.81:2223': socket error: connection refused
```

Could anybody help me?
## Errors on server1, terminal1

```
E tensorflow/stream_executor/cuda/cuda_dnn.cc:289] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
E tensorflow/stream_executor/cuda/cuda_dnn.cc:278] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
W tensorflow/stream_executor/stream.cc:301] attempting to perform DNN operation using StreamExecutor without DNN support
```
## Errors on server1, terminal2

```
E tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 11.27G (12103048448 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
```
"
2721,"tensorflow  performance of model evaluation using C++ is very lower than  using python. The model was trained by python ,and freezed to loaded by c++.","tensorflow evaluation using c++  has very lower performance, 100 times lower than using python. 
1.The  model was trained using python,  freezed(using freeze_graph.py tool),  and then loaded by c++. 
2.The evaluation speed :  1K+/s using python ,VS 10/s using C++.
"
2719,RNN related API documents,"Do you have any plan to release the RNN related API documents? I still cannot find them in TensorFlow R0.9 API doc: https://www.tensorflow.org/versions/r0.9/api_docs/python/index.html.

This was also asked in StackOverflow: http://stackoverflow.com/questions/37159372/.
"
2716,Add a lite version of libtensorflow-core to Makefile,"The tensorflow iOS libraries created by the makefile have a very large footprint ( > 90 MB ).

To help reduce the size of apps, there should also be a lite version of the libraries, possibly based on the Bazel android_tensorflow_lib_lite target.

Note that Apple prevents apps larger than 100 MB from being downloaded over the air.
"
2715,error looking for libcudart.so.7.0 instead of 7.5 when building from sources (r0.9) even though configured to use cuda 7.5,"### Summary

I've configured everything to use cuda 7.5 / cudnn 5.0.5. After building from source cc example is working fine with libcudart.so.7.5. However when I import tensorflow in python the import fails saying it's unable to load libcudart.so.7.0 - which doesn't and shouldn't exist on my system. I'm not sure why it's looking for that. 
### Environment info

Operating System: Linux 3.19.0-59-generic 14.04.1-Ubuntu

Installed version of CUDA and cuDNN: 7.5.18 & 5.0.5

> memo@MSA-Blade:~$ ls -l /usr/local/cuda/lib64/libcud*
> -rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
> lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
> lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
> -rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
> -rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
> -rwxr-xr-x 1 root root 59909104 Jun  7 10:25 /usr/local/cuda/lib64/libcudnn.so
> -rwxr-xr-x 1 root root 59909104 Jun  7 10:25 /usr/local/cuda/lib64/libcudnn.so.5
> -rwxr-xr-x 1 root root 59909104 Jun  7 10:25 /usr/local/cuda/lib64/libcudnn.so.5.0.5
> -rw-r--r-- 1 root root 58775484 Jun  7 10:25 /usr/local/cuda/lib64/libcudnn_static.a

Note: nvcc is reporting v7.5.17 while installed is v7.5.18

> memo@MSA-Blade:~$ nvcc --version
> nvcc: NVIDIA (R) Cuda compiler driver
> Copyright (c) 2005-2015 NVIDIA Corporation
> Built on Tue_Aug_11_14:27:32_CDT_2015
> Cuda compilation tools, release 7.5, V7.5.17
> memo@MSA-Blade:~$ which nvcc
> /usr/local/cuda/bin/nvcc
> memo@MSA-Blade:~$ ls -l /usr/local/cuda
> lrwxrwxrwx 1 root root 8 Jun  7 11:07 /usr/local/cuda -> cuda-7.5
> memo@MSA-Blade:~$ head /usr/local/cuda/version.txt
> CUDA Version 7.5.18

If installed from sources, provide the commit hash:
tried master: a0085c8a689893a116be72ac83774c0cc3fa59f9
and r0.9: f05f72ee8f6dd91491226fe82f020c00f9fb882d
### Steps to reproduce
1. uninstalled tensorflow 0.7 and purged cuda 7.0/cudnn 4.0. In fact purged all instances of cuda (and restarted) before each attempt
2. followed instructions exactly to install cuda 7.5 (from deb) and cudnn 5.0 (to /usr/local/cuda)
3. reboot
4. clone tensorflow repo 
5. ./configure with no cloud platform support, gpu support 
6. build cc:tutorials_example_trainer (-c opt --config=cuda) -> builds and _runs fine_ 

> memo@MSA-Blade:~/DEV/tensorflow$ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5.18 locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5.0.5 locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5.18 locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5.18 locally
> I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
> name: GeForce GTX 970M
> major: 5 minor: 2 memoryClockRate (GHz) 1.038
> pciBusID 0000:01:00.0
> Total memory: 3.00GiB
> Free memory: 2.60GiB
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:807] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:807] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:807] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:807] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:807] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:807] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:807] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:807] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:807] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:807] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
1. build pip package (-c opt --config=cuda), wheel and sudo pip install -> _FAILS ON IMPORT_

> memo@MSA-Blade:~/DEV/tensorflow$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
> Tue Jun 7 13:08:59 PDT 2016 : === Using tmpdir: /tmp/tmp.wuLJ2u2tY7
> /tmp/tmp.wuLJ2u2tY7 ~/DEV/tensorflow
> Tue Jun 7 13:09:00 PDT 2016 : === Building wheel
> ~/DEV/tensorflow
> Tue Jun 7 13:09:09 PDT 2016 : === Output wheel file is in: /tmp/tensorflow_pkg
> memo@MSA-Blade:~/DEV/tensorflow$ ls -al /tmp/tensorflow_pkg/
> total 47820
> drwxrwxr-x  2 memo memo     4096 Jun  7 13:09 .
> drwxrwxrwt 15 root root   118784 Jun  7 13:09 ..
> -rw-rw-r--  1 memo memo 48839608 Jun  7 13:09 tensorflow-0.9.0rc0-py2-none-any.whl
> memo@MSA-Blade:~/DEV/tensorflow$ sudo pip install /tmp/tensorflow_pkg/tensorflow-0.9.0rc0-py2-none-any.whl 
> [sudo] password for memo: 
> Unpacking /tmp/tensorflow_pkg/tensorflow-0.9.0rc0-py2-none-any.whl
> Requirement already satisfied (use --upgrade to upgrade): numpy>=1.8.2 in /usr/lib/python2.7/dist-packages (from tensorflow==0.9.0rc0)
> Requirement already satisfied (use --upgrade to upgrade): protobuf==3.0.0b2 in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.9.0rc0)
> Requirement already satisfied (use --upgrade to upgrade): wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.9.0rc0)
> Requirement already satisfied (use --upgrade to upgrade): six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.9.0rc0)
> Installing collected packages: tensorflow
> Successfully installed tensorflow
> Cleaning up...
> memo@MSA-Blade:~/DEV/tensorflow$ cd ..
> memo@MSA-Blade:~/DEV$ ipython
> Python 2.7.11 |Anaconda 4.0.0 (64-bit)| (default, Dec  6 2015, 18:08:32) 
> Type ""copyright"", ""credits"" or ""license"" for more information.
> 
> IPython 4.1.2 -- An enhanced Interactive Python.
> ?         -> Introduction and overview of IPython's features.
> %quickref -> Quick reference.
> help      -> Python's own help system.
> object?   -> Details about 'object', use 'object??' for extra details.
> 
> In [1]: import tensorflow
> ImportError                               Traceback (most recent call last)
> <ipython-input-1-a649b509054f> in <module>()
> ----> 1 import tensorflow
> 
> /home/memo/anaconda2/lib/python2.7/site-packages/tensorflow/**init**.py in <module>()
>      21 from **future** import print_function
>      22 
> ---> 23 from tensorflow.python import *
> 
> /home/memo/anaconda2/lib/python2.7/site-packages/tensorflow/python/**init**.py in <module>()
>      47 
>      48 # Import things out of contrib
> ---> 49 from tensorflow import contrib
>      50 
>      51 # Framework
> 
> /home/memo/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/**init**.py in <module>()
>      21 
>      22 # Add projects here, they will show up under tf.contrib.
> ---> 23 from tensorflow.contrib import layers
>      24 from tensorflow.contrib import util
> 
> /home/memo/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/layers/**init**.py in <module>()
>      66 # pylint: disable=unused-import,wildcard-import
>      67 from tensorflow.contrib.layers.python.framework.tensor_util import *
> ---> 68 from tensorflow.contrib.layers.python.layers import *
> 
> /home/memo/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/**init**.py in <module>()
>      20 
>      21 # pylint: disable=wildcard-import
> ---> 22 from tensorflow.contrib.layers.python.layers.initializers import *
>      23 from tensorflow.contrib.layers.python.layers.layers import *
>      24 from tensorflow.contrib.layers.python.layers.regularizers import *
> 
> /home/memo/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/initializers.py in <module>()
>      22 
>      23 from tensorflow.python.framework import dtypes
> ---> 24 from tensorflow.python.ops import random_ops
>      25 
>      26 
> 
> /home/memo/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/random_ops.py in <module>()
>      21 
>      22 from tensorflow.python.framework import dtypes
> ---> 23 from tensorflow.python.framework import ops
>      24 from tensorflow.python.framework import tensor_shape
>      25 from tensorflow.python.framework import tensor_util
> 
> /home/memo/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py in <module>()
>      37 from tensorflow.python.framework import registry
>      38 from tensorflow.python.framework import tensor_shape
> ---> 39 from tensorflow.python.framework import versions
>      40 from tensorflow.python.util import compat
>      41 from tensorflow.python.platform import logging
> 
> /home/memo/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/versions.py in <module>()
>      20 from **future** import print_function
>      21 
> ---> 22 from tensorflow.python import pywrap_tensorflow
>      23 
>      24 **version** = pywrap_tensorflow.**version**
> 
> /home/memo/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()
>      26                 fp.close()
>      27             return _mod
> ---> 28     _pywrap_tensorflow = swig_import_helper()
>      29     del swig_import_helper
>      30 else:
> 
> /home/memo/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in swig_import_helper()
>      22         if fp is not None:
>      23             try:
> ---> 24                 _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
>      25             finally:
>      26                 fp.close()
> 
> ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory
### What have you tried?
1. tried both master and r0.9 branches
2. for cuda and cudnn version numbers tried keeping them system default (/usr/local/cuda is symlinked to /usr/local/cuda-7.5) AND tried giving explicit version numbers (cuda: 7.5, 7.5.18; cudnn: 5, 5.0.5 )
3. If I purge Cuda 7.5 and only use cuda 7.0 / cudnn 4.0.7 it works fine. 
### Logs or other output that would be helpful
"
2714,Support for histogram_summary in either rnn() or dynamic_rnn(),"Hello,
I am trying to add tf.historgram_summary() in my LSTM cells in order to visualize  the output. But currently
neither rnn() or dynamic_rnn() supports writing out summaries. 
For rnn(), The log indicates the summary tensor are invalid, which seems to due to the dynamic unrolling of the rnn loop.

```
Traceback (most recent call last):
  File ""test_dynamic_rnn.py"", line 55, in <module>
    summarys = sess.run(thing, feed_dict=feeds)
  File ""/home/ezheng/tf_head/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 333, in run
    run_metadata_ptr)
  File ""/home/ezheng/tf_head/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 573, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/ezheng/tf_head/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 648, in _do_run
    target_list, options, run_metadata)
  File ""/home/ezheng/tf_head/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 668, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: The tensor returned for dynamic_scope/RNN/cond_2/BasicLSTMCell/HistogramSummary_1:0 was not valid.
```

I am currently constructing rnn() like this

``` python
  outputs, state = tf.nn.rnn(
      cell, inputs, dtype=tf.float32, sequence_length=sequence_length)
```

For dynamic_rnn(), it just hangs when I am trying to obtain summaries with the session.run()
And this is how I am constructing dynamic_rnn()

``` python
  outputs, state = tf.nn.dynamic_rnn(
      cell, inputs=concat_inputs,
      time_major=True, dtype=tf.float32)
```

Wondering if there is plan to support histogram summary with either of these two RNNs. Thanks.
"
2713,how to assign values in Tensor according to the indices?,"I want to assign values in a tensor according to the indices.

For example, According to the pooling values and the corresponding indices output of `tf.nn.max_pool_with_argmax`, I want to put these pooling values back into the original unpooling Tensor given the indices.

According to the trick in [Adjust Single Value within Tensor  TensorFlow](http://stackoverflow.com/questions/34685947/adjust-single-value-within-tensor-tensorflow/34686952#34686952)
I can recreate sparse tensor with the indices.
But here is the problem: `tf.SparseTensor`  should input the unflattened indices i.e. the ndims coordinates list. 
If I use this method, how to unravel the flattened indices obtained by `tf.nn.max_pool_with_argmax` to the normal indices?
If I do not use this method, is there any way in Tensorflow to achieve this work?
Thank you very much.
"
2712,Tensorflow with Pyinstaller,"It seems that Tensorflow does not work with Pyinstaller. I was trying to build a Tensorflow script into a executable file using Pyinstaller on Ubuntu. However the following error is reported:

tensorflow.python.framework.errors.NotFoundError: tensorflow/contrib/layers/python/ops/_bucketization_op.so: cannot open shared object file: No such file or directory
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN:  None
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
### Steps to reproduce
1. Pyinstaller tensorflow_script.py
2. ./tensorflow_script
"
2709,Unable to infer shape of placeholder,"```
myPlaceholder = tf.placeholder(dtype=tf.float32, shape=[4, 5])
tf.shape(myPlaceholder).eval()
```

```
InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [4,5]
```

One shouldn't have to feed a value for the placeholder because the shape is already determined.
"
2708,TensorBoard shows no histograms or events,"Running TensorBoard r0.9 results in graph visualizations as expected but all events and histograms that successfully displayed in r0.8 [are not](http://stackoverflow.com/q/37684739/656912).

Has r0.9 introduced a change to the command line that should be used to launch TensorBoard, or to the code needed to generate events and histograms for TensorBoard to display?

Note that neither new summaries and histograms written with recent runs using r0.9 TensorFlow, nor existing ones written (and displayed) in the past, are displayed. Graphs generated with both releases display as expected.
### Environment info

Operating System: OS X 10.11.5
TensorFlow: .9.0rc0
### Steps to reproduce

`tensorboard --logdir ./tflog --purge_orphaned_data`
### What have you tried?

Reverting to r0.8, which works as it originally did, displaying all events and histograms present in the `tflog`directory provided as the `logdir`. Reinstalling r0.9, which reproduces the error. A second attempt at reinstalling r0.8 resulted in a TensorBoard that displays jus the menu (no content) and uses a different style (a serif face).
"
2706,While loop gradient descent error,"### Environment info

Operating System: Centos 7

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CPU version

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

0.8.0
### Steps to reproduce

Example 1 for Tensorflow 0.8

``` python
import tensorflow as tf
import numpy as np
from tensorflow.python.ops import rnn

class model(object):
    def __init__(self):
        error_position = 1
        vocab_size = 20
        embedding_size = 5
        # Word2vec
        W = tf.Variable(tf.random_normal([vocab_size, embedding_size]),
            trainable=False, name=""W"")
        self.story = []
        story_embedded = []
        # Embedding
        for i in range(4):
            self.story.append(tf.placeholder(tf.int32, shape=[None]))
            story_embedded.append(tf.nn.embedding_lookup(W, self.story[i]))

        self.answer = tf.constant(3, tf.int64)
        answer_weights = tf.Variable(tf.truncated_normal([embedding_size, vocab_size], -0.1, 0.1), name=""answer_weights"")
        # w2v to sentence2vec for story and question
        scell = tf.nn.rnn_cell.GRUCell(embedding_size)
        story_state_array = []

        for i in range(0,4):
            with tf.variable_scope(""tt"", reuse=True if i > 0 else None):
                _, story_state = rnn.rnn(scell, tf.unpack(tf.reshape(story_embedded[i],[4,1,5]), 4), dtype=tf.float32)
                story_state_array.append(story_state)
        storys = tf.concat(0,story_state_array)


        mem_weights = tf.get_variable(""mem_weights"", [embedding_size, embedding_size], initializer=tf.random_normal_initializer())
        l1_weights = tf.get_variable(""l1_weights"", [embedding_size, 1], initializer=tf.random_normal_initializer())

        episodic_gate_unpacked = []
        def body(mem_state_previous, hops):
            mem_state_current = tf.nn.relu(tf.matmul(mem_state_previous, mem_weights))
            hops = tf.add(hops,1)
            return  mem_state_current, hops
        def condition(mem_state_previous, hops):
            z = tf.mul(storys, mem_state_previous)
            e_reshaped = tf.reshape(tf.matmul(z , l1_weights) , [1,-1], name=""e_reshaped"")
            e_gate = tf.nn.softmax(e_reshaped)
            e_unpacked = tf.unpack( tf.reshape(e_gate, [4,1]))
            argmax_e = tf.to_int32(tf.argmax(e_gate, 1)) #should be 1
            return tf.logical_and(tf.less(argmax_e[0], error_position),tf.less(hops,5))

        init_state = tf.constant([[1.0,1.0,1.0,1.0,1.0,]])
        initial_hops = tf.constant(0)
        a_state, _ = tf.while_loop(condition,body,[init_state, initial_hops], back_prop=True)

        # answer
        predicted_answer = tf.matmul(a_state, answer_weights)
        answer = tf.reshape(tf.one_hot(self.answer, vocab_size, 1.0, 0.0), [1,vocab_size])
        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(predicted_answer, answer), name='loss')

        # gradient
        params = tf.trainable_variables()
        self.gradient_norms = []
        self.updates = []
        optimizer = tf.train.AdamOptimizer(0.05)
        gradients = tf.gradients(self.loss, params)
        self.updates = optimizer.apply_gradients(
            zip(gradients, params))
        self.saver = tf.train.Saver(tf.all_variables())

    def step(self,sess):
        feed ={}
        feed[self.story[0].name] = [1,2,3,4]
        feed[self.story[1].name] = [4,5,6,5]
        feed[self.story[2].name] = [7,8,9,8]
        feed[self.story[3].name] = [0,2,3,5]

        print sess.run([self.loss,self.updates],feed)
with tf.Graph().as_default():
    with tf.Session() as sess:
        test_model = model()
        sess.run(tf.initialize_all_variables())
        test_model.step(sess)

```

Example 2 for Tensorflow 0.9

``` python
import tensorflow as tf
import numpy as np
from tensorflow.python.ops import rnn

class model(object):
    def __init__(self):
        error_position = 2
        vocab_size = 20
        embedding_size = 5
        # Word2vec
        W = tf.Variable(tf.random_normal([vocab_size, embedding_size]),
                trainable=False, name=""W"")
        self.story = []
        story_embedded = []
        # Embedding
        for i in range(4):
            self.story.append(tf.placeholder(tf.int32, shape=[None,None]))
            story_embedded.append(tf.nn.embedding_lookup(W, self.story[i]))

        self.question = tf.placeholder(tf.int32, shape=[None,None], name=""Question"")
        question_embedded = tf.nn.embedding_lookup(W, self.question)

        self.answer = tf.constant(3, tf.int64)
        answer_weights = tf.Variable(tf.truncated_normal([embedding_size, vocab_size], -0.1, 0.1), name=""answer_weights"")   
        # w2v to sentence2vec for story and question
        scell = tf.nn.rnn_cell.GRUCell(embedding_size)
        story_state_array = []

        q_cell = tf.nn.rnn_cell.GRUCell(embedding_size)
        _, question_state = tf.nn.rnn(q_cell, tf.unpack(question_embedded, 4), dtype=tf.float32)

        for i in range(0,4):
            with tf.variable_scope(""tt"", reuse=True if i > 0 else None):
                _, story_state = tf.nn.rnn(scell, tf.unpack(story_embedded[i], 4), dtype=tf.float32)
                story_state_array.append(story_state)   

        stories = tf.concat(0,story_state_array)


        mem_weights = tf.get_variable(""mem_weights"", [embedding_size * 2, embedding_size], initializer=tf.random_normal_initializer())
        l1_weights = tf.get_variable(""l1_weights"", [embedding_size, 1], initializer=tf.random_normal_initializer())

        e_unpacked = [] 
        def body(mem_state_previous, hops):
            # context = MGRU(facts_, e_unpacked)
            mem_state_current = tf.nn.relu(tf.matmul(tf.concat(1,[mem_state_previous, question_state]), mem_weights))

            hops = tf.add(hops,1)
            return  mem_state_current, hops
        def condition(mem_state_previous, hops):    
            z = tf.mul(stories, mem_state_previous)
            e_reshaped = tf.reshape(tf.matmul(z , l1_weights) , [1,-1], name=""e_reshaped"")
            e_gate = tf.nn.softmax(e_reshaped)
            e_unpacked = tf.unpack( tf.reshape(e_gate, [4,1]))  
            argmax_e = tf.to_int32(tf.argmax(e_gate, 1)) #should be 1
            return tf.logical_and(tf.less(argmax_e[0], error_position),tf.less(hops,5))


        initial_hops = tf.constant(0)
        a_state, _ = tf.while_loop(condition,body,[question_state, initial_hops], back_prop=True)   

        # answer
        predicted_answer = tf.matmul(a_state, answer_weights)
        answer = tf.reshape(tf.one_hot(self.answer, vocab_size, 1.0, 0.0), [1,vocab_size])
        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(predicted_answer, answer), name='loss')

        # gradient
        params = tf.trainable_variables()   
        self.gradient_norms = []
        self.updates = []
        optimizer = tf.train.AdamOptimizer(0.05)
        gradients = tf.gradients(self.loss, params) 
        self.updates = optimizer.apply_gradients(
            zip(gradients, params))
        self.saver = tf.train.Saver(tf.all_variables())

    def step(self,sess):    
        feed ={}
        feed[self.story[0].name] = [[1],[2],[3],[4]]
        feed[self.story[1].name] = [[4],[5],[6],[5]]
        feed[self.story[2].name] = [[7],[8],[9],[8]]
        feed[self.story[3].name] = [[0],[2],[3],[5]]
        feed[self.question.name] = [[1],[4],[5],[5]]

        print sess.run([self.loss,self.updates],feed)
with tf.Graph().as_default():
    with tf.Session() as sess:
        test_model = model()
        sess.run(tf.initialize_all_variables())
        test_model.step(sess)

```
### What have you tried?

In my `tf.while_loop()`, it calculates attention in each loop. If the attention is beyond certain threshold, it would terminate the `while_loop`. But it does not work as I expected.

In this two situations, it works
1. If I turn `back_prop=False` in `while_loop`, it works.
2. If `argmax_ep_gate[0]` always `< error_position`, it works.

**Hence, the error might appear after several trails** 

Also, we found that in `z = tf.mul(storys, mem_state_previous)`, if `storys` does not generated after `tf.concat(0, story_state_array)` such as a single sentence2vec from `_, story_state = rnn.dynamic_rnn(scell, story_embedded[i], dtype=tf.float32)`, it works.
### Logs or other output that would be helpful

Below log is generated **before** shrinking the example for both Tensorflow 0.8 and 0.9

``` python
Traceback (most recent call last):
  File ""github_issue.py"", line 111, in <module>
    test_model.step(sess)
  File ""github_issue.py"", line 106, in step
    print sess.run([self.loss, self.gradient_norms],feed)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 340, in run
    run_metadata_ptr)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 564, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 637, in _do_run
    target_list, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 659, in _do_call
    e.code)
tensorflow.python.framework.errors.InvalidArgumentError: Inputs to operation gradients/AddN of type AddN must have the same size and shape.  Input 0: [1,5] != input 1: []
     [[Node: gradients/AddN = AddN[N=2, T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](gradients/while/Enter_grad/Exit, gradients/while/Mul/Enter_1_grad/b_acc_3)]]
Caused by op u'gradients/AddN', defined at:
  File ""github_issue.py"", line 109, in <module>
    test_model = model()
  File ""github_issue.py"", line 89, in __init__
    gradients = tf.gradients(self.loss, params)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 431, in gradients
    out_grads = _AggregatedGrads(grads, op, loop_state, aggregation_method)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 676, in _AggregatedGrads
    out_grads[i] = math_ops.add_n(out_grad)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 58, in add_n
    return _op_def_lib.apply_op(""AddN"", inputs=inputs, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1154, in __init__
    self._traceback = _extract_stack()

```

Below log is generated **after** shrinking the example, fixed after 0.9

``` python
Traceback (most recent call last):
  File ""github_issue.py"", line 82, in <module>
    test_model.step(sess)
  File ""github_issue.py"", line 77, in step
    print sess.run([self.loss,self.updates],feed)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 340, in run
    run_metadata_ptr)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 564, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 637, in _do_run
    target_list, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 659, in _do_call
    e.code)
tensorflow.python.framework.errors.InvalidArgumentError: var and grad do not have the same shape[5,5] []
     [[Node: Adam/update_mem_weights/ApplyAdam = ApplyAdam[T=DT_FLOAT, _class=[""loc:@mem_weights""], use_locking=false, _device=""/job:localhost/replica:0/task:0/cpu:0""](mem_weights, mem_weights/Adam, mem_weights/Adam_1, beta1_power/read, beta2_power/read, Adam/learning_rate, Adam/beta1, Adam/beta2, Adam/epsilon, gradients/while/MatMul_1/Enter_grad/b_acc_3)]]
Caused by op u'Adam/update_mem_weights/ApplyAdam', defined at:
  File ""github_issue.py"", line 80, in <module>
    test_model = model()
  File ""github_issue.py"", line 67, in __init__
    zip(gradients, params))
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 299, in apply_gradients
    update_ops.append(self._apply_dense(grad, var))
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/adam.py"", line 129, in _apply_dense
    self._epsilon_t, grad, use_locking=self._use_locking).op
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/gen_training_ops.py"", line 120, in apply_adam
    use_locking=use_locking, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1154, in __init__
    self._traceback = _extract_stack()

```
"
2703,"""ERROR: Cannot find './util/python/python_lib'""","Hello,

I have the following error when I try to compile the pip package from the source code.
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Feb  9 18:48 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 root root       17 Feb  9 18:48 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxrwxr-x 1 root root 61453024 Feb  8 23:12 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-rw-r-- 1 root root 62025862 Feb  8 23:12 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from sources, provide the commit hash: ea9e00a630f91a459dd5858cb22e8cd1a666ba4e
### Steps to reproduce
1. git clone https://github.com/tensorflow/tensorflow
2. cd tensorflow
3. ./configure
4. bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
5. bazel build -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures
### Logs or other output that would be helpful

```
ERROR: /home/plu/git/tensorflow/util/python/BUILD:14:1: Executing genrule //util/python:python_check failed: bash failed: error executing command 
  (cd /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/packages/bin:.:/homes/plu/docker/:/usr/local/cuda-7.5/bin/:/homes/plu/bin/:/usr/local/openmpi-1.10.1/bin/ \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; OUTPUTDIR=""bazel-out/host/genfiles/util/python/""; util/python/python_config.sh --check && touch $OUTPUTDIR/python_checked'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: bash failed: error executing command 
  (cd /homes/plu/.cache/bazel/_bazel_plu/5fecb6612d2e95475ff53a54e377c3f7/tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/packages/bin:.:/homes/plu/docker/:/usr/local/cuda-7.5/bin/:/homes/plu/bin/:/usr/local/openmpi-1.10.1/bin/ \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; OUTPUTDIR=""bazel-out/host/genfiles/util/python/""; util/python/python_config.sh --check && touch $OUTPUTDIR/python_checked'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.


ERROR: Cannot find './util/python/python_lib'.  Did you run configure?
```

But, I do have this folder locally in the Tensorflow repository. Did I do something wrong? Or it is a bug coming from Tensorflow?

Thanks in advance for any help!
"
2702,API doc typo for tf.nn.avg_pool3d and tf.nn.max_pool3d,"In the tensorflow API doc: https://www.tensorflow.org/versions/master/api_docs/python/nn.html#max_pool3d, it states:

ksize: A list of ints that has length >= 5. 1-D tensor of length 5. The size of the window for each dimension of the input tensor. Must have ksize[0] = ksize[1] = 1.

ksize[0] = ksize[1] = 1 must be ksize[0] = ksize[4] = 1 for both average and max pooling 3d layers as detailed here:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/pooling_ops_3d_test.py#L48
"
2699,tf.train.Example?,"In the file

https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/examples/how_tos/reading_data/convert_to_records.py#L64

What does  tf.train.Example()  do?  I couldn't find it anywhere in the documentation.
"
2695,RNN's state_is_tuple doesn't work with initial_state,"Assuming I want to batch series of inputs and propagate the cell state from one session run towards another for an epoch:

```
for batch in epoch:
  state = initial_state.eval()
  feed_dict = {initial_state: state}
  state = sess.run([final_state], feed_dict)
```

Since using state_is_tuple in the cells makes the state be a tuple on return:
- using .eval() doesn't work for an initial state
- subsequent states are returned as tuples and cannot be fed back into the session as tuples
"
2690,Shape inference for Reverse doesn't support unknown shape,"This crashes

```
import tensorflow as tf
dims = tf.placeholder(tf.bool)
tensor = tf.placeholder(tf.int32)
result = tf.reverse(tensor, dims)
print(result.get_shape())

```

Stack trace

```

  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/env_extra_test.runfiles/org_tensorflow/tensorflow/contrib/immediate/python/immediate/env_extra_test.py"", line 39, in testReverse
    result = tf.reverse(tensor, dims)
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/env_extra_test.runfiles/org_tensorflow/tensorflow/python/ops/gen_array_ops.py"", line 1405, in reverse
    name=name)
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/env_extra_test.runfiles/org_tensorflow/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/env_extra_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 2251, in create_op
    set_shapes_for_outputs(ret)
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/env_extra_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 1696, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/env_extra_test.runfiles/org_tensorflow/tensorflow/python/ops/array_ops.py"", line 631, in _ReverseShape
    input_shape = op.inputs[0].get_shape().with_rank(dims_shape[0])
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/env_extra_test.runfiles/org_tensorflow/tensorflow/python/framework/tensor_shape.py"", line 639, in with_rank
    return self.merge_with(unknown_shape(ndims=rank))
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/env_extra_test.runfiles/org_tensorflow/tensorflow/python/framework/tensor_shape.py"", line 816, in unknown_shape
    return TensorShape([Dimension(None)] * ndims)
TypeError: __index__ returned non-(int,long) (type NoneType)
> /Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/env_extra_test.runfiles/org_tensorflow/tensorflow/python/framework/tensor_shape.py(816)unknown_shape()
-> return TensorShape([Dimension(None)] * ndims)

```
"
2689,Issue while importing tensorflow,"Facing issue while importing tensorflow. 
OS: Windows 8
Python version 2.7
Installation method anaconda. 

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Anaconda2\envs\tensorflow_env\lib\site-packages\tensorflow__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""C:\Anaconda2\envs\tensorflow_env\lib\site-packages\tensorflow\python__init__.py"", line 46, in <module>
    _default_dlopen_flags = sys.getdlopenflags()
AttributeError: 'module' object has no attribute 'getdlopenflags'
"
2688,My Changing on Tensorflow is not work,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
OS X EI Capitan version 10.11.5

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce

1.Change the file cifar10_input.py with adding some print in it.
2.rebuild my tensorflow as the https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#installing-from-sources WHICH Section ""Setting up TensorFlow for Development"" instruction.
3.And when I back to cifar10 to run the cifar10_train.py, I found nothing have changed about my revised.
### What have you tried?

1.I try the instruction from other section ""Create the pip package and install"" 
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2687,Cannot build tensorflow from source (Python 3 library not found) ,"Dear TensorFlow developers,

I am trying to install TensorFlow and could already solve a number of problems but I got stuck with the following error message:

```
[sfux@e2190 tensorflow]$ bazel build --verbose_failures -c opt //tensorflow/tools/pip_package:build_pip_package
Warning: ignoring _JAVA_OPTIONS in environment.
WARNING: Output base '/cluster/home/sfux/.cache/bazel/_bazel_sfux/d3b614f4169d4d1d2d1a6ba84ae877cb' is on NFS. This may lead to surprising failures and undetermined behavior.
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
WARNING: /cluster/home/sfux/.cache/bazel/_bazel_sfux/d3b614f4169d4d1d2d1a6ba84ae877cb/external/protobuf/WORKSPACE:1: Workspace name in /cluster/home/sfux/.cache/bazel/_bazel_sfux/d3b614f4169d4d1d2d1a6ba84ae877cb/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
WARNING: /scratch/20837473.tmpdir/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.
WARNING: /cluster/home/sfux/.cache/bazel/_bazel_sfux/d3b614f4169d4d1d2d1a6ba84ae877cb/external/highwayhash/WORKSPACE:1: Workspace name in /cluster/home/sfux/.cache/bazel/_bazel_sfux/d3b614f4169d4d1d2d1a6ba84ae877cb/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.
WARNING: /cluster/home/sfux/.cache/bazel/_bazel_sfux/d3b614f4169d4d1d2d1a6ba84ae877cb/external/re2/WORKSPACE:1: Workspace name in /cluster/home/sfux/.cache/bazel/_bazel_sfux/d3b614f4169d4d1d2d1a6ba84ae877cb/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
INFO: Found 1 target...
ERROR: /scratch/20837473.tmpdir/tensorflow/tensorflow/contrib/session_bundle/example/BUILD:38:1: Executing genrule //tensorflow/contrib/session_bundle/example:half_plus_two failed: bash failed: error executing command 
  (cd /cluster/home/sfux/.cache/bazel/_bazel_sfux/d3b614f4169d4d1d2d1a6ba84ae877cb/execroot/tensorflow && \
  exec env - \
    PATH=/cluster/apps/python/3.3.3/x86_64/bin:/cluster/apps/openblas/0.2.8_seq/x86_64/gcc_4.8.2/bin:/cluster/apps/swig/3.0.5/x86_64/bin:/cluster/apps/bazel/output:/cluster/apps/java/1.8.0_91/x86_64/bin:/cluster/apps/lsf/9.1/linux2.6-glibc2.3-x86_64/etc:/cluster/apps/lsf/9.1/linux2.6-glibc2.3-x86_64/bin:/cluster/apps/modules/bin:/cluster/apps/gcc/4.8.2/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/cluster/home/sfux/bin:/cluster/apps/ansys/v150/fluent/license/lnamd64:/cluster/apps/adm:/cluster/home/sfux/shellscript:/cluster/home/sfux/prog/bash \
    TMPDIR=/scratch/20837473.tmpdir \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; rm -rf /tmp/half_plus_two; /cluster/apps/python/3.3.3/x86_64/bin/python bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two; cp -r /tmp/half_plus_two/* bazel-out/local-py3-opt/genfiles/tensorflow/contrib/session_bundle/example/half_plus_two'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127.
/cluster/apps/python/3.3.3/x86_64/bin/python: error while loading shared libraries: libpython3.3m.so.1.0: cannot open shared object file: No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 2.621s, Critical Path: 0.09s
[sfux@e2190 tensorflow]$ 
```
### Environment info

Operating System:
CentOS 6.7 (Final), Kernel: 2.6.32-504.1.3

Installed version of CUDA and cuDNN: 
I am trying an installation from source (Commit: ea9e00a630f91a459dd5858cb22e8cd1a666ba4e)

Python 3.3 is installed in a non-standard location (/cluster/apps/python/3.3.3/x86_64) and it was installed from source. The bin directory of the Python installation is in $PATH, the directory, where libpython3.3m.so.1.0 is located is in $LD_LIBRARY_PATH and the library has the correct name:

[sfux@e2190 tensorflow]$ ls /cluster/apps/python/3.3.3/x86_64/lib64/libpython3.3m.so.1.0
/cluster/apps/python/3.3.3/x86_64/lib64/libpython3.3m.so.1.0
[sfux@e2190 tensorflow]$ 

[sfux@e2190 tensorflow]$ python3-config --ldflags
-lpthread -ldl -lutil -lm -lpython3.3m -Xlinker -export-dynamic

Any ideas ?
"
2685,"ImportError when I use  ""from tensorflow.models.rnn import rnn, rnn_cell""","I install tensorflow on a new cluster and try to run program on it. 
But I get this error:
`ImportError(""This module is deprecated.  Use tf.nn.rnn_* instead."")`, 

from this line: 
`from tensorflow.models.rnn import rnn, rnn_cell`. 

It seems the new version of TF has changed the way to import rnn, but I don't know how to fix it. (version of TF is 0.9)
"
2682,hessian free optimizer needed,"Hessian free optimizers are successfully applied on neural networks  (especially RNNs). Currently need one in TF!
"
2680,Loading model in Android and No OpKernel was registered to support Op error,"I encountered a problem when using a self-trained face-recognition model to make inference on android platform (using c++ api, just like the android demo). The error says something like this:

```
06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:196 End computing.
06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist E/native: tensorflow_jni.cc:199 Error during inference: Invalid argument: No OpKernel was registered to support Op 'Inv' with these attrs
                                                                      [[Node: incept5b/in4_conv1x1_55/batch_norm/moments/moments_1/divisor = Inv[T=DT_FLOAT](incept5b/in4_conv1x1_55/batch_norm/moments/moments/Const)]]
06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x10 in tid 28605 (tensorflowmnist)
06-05 16:25:11.423 186-186/? I/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** 
```

It is similar to the issue #1269 

I don't understand why it causes an error? 
All the other layers ( from incept3a  to incept5a) have almost the same structures, but there's no error....

Could anyone give me some advice?
Thanks a lot!

The structure of the model I use is like this:

```

def inference_nn4_max_pool_96(images, pool_type, use_lrn, keep_probability, phase_train=True):
  conv1 = _conv(images, 3, 64, 7, 7, 2, 2, 'SAME', 'conv1_7x7', phase_train=phase_train, use_batch_norm=True)
  pool1 = _mpool(conv1,  3, 3, 2, 2, 'SAME')
  if use_lrn:
    lrn1 = tf.nn.local_response_normalization(pool1, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)
  else:
    lrn1 = pool1
  conv2 = _conv(lrn1,  64, 64, 1, 1, 1, 1, 'SAME', 'conv2_1x1', phase_train=phase_train, use_batch_norm=True)
  conv3 = _conv(conv2,  64, 192, 3, 3, 1, 1, 'SAME', 'conv3_3x3', phase_train=phase_train, use_batch_norm=True)
  if use_lrn:
    lrn2 = tf.nn.local_response_normalization(conv3, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)
  else:
    lrn2 = conv3
  pool3 = _mpool(lrn2,  3, 3, 2, 2, 'SAME')

  incept3a = _inception(pool3,    192, 1, 64, 96, 128, 16, 32, 3, 32, 1, 'MAX', 'incept3a', phase_train=phase_train, use_batch_norm=True)
  incept3b = _inception(incept3a, 256, 1, 64, 96, 128, 32, 64, 3, 64, 1, pool_type, 'incept3b', phase_train=phase_train, use_batch_norm=True)
  incept3c = _inception(incept3b, 320, 2, 0, 128, 256, 32, 64, 3, 0, 2, 'MAX', 'incept3c', phase_train=phase_train, use_batch_norm=True)

  incept4a = _inception(incept3c, 640, 1, 256, 96, 192, 32, 64, 3, 128, 1, pool_type, 'incept4a', phase_train=phase_train, use_batch_norm=True)
  incept4b = _inception(incept4a, 640, 1, 224, 112, 224, 32, 64, 3, 128, 1, pool_type, 'incept4b', phase_train=phase_train, use_batch_norm=True)
  incept4c = _inception(incept4b, 640, 1, 192, 128, 256, 32, 64, 3, 128, 1, pool_type, 'incept4c', phase_train=phase_train, use_batch_norm=True)
  incept4d = _inception(incept4c, 640, 1, 160, 144, 288, 32, 64, 3, 128, 1, pool_type, 'incept4d', phase_train=phase_train, use_batch_norm=True)
  incept4e = _inception(incept4d, 640, 2, 0, 160, 256, 64, 128, 3, 0, 2, 'MAX', 'incept4e', phase_train=phase_train, use_batch_norm=True)

  incept5a = _inception(incept4e,    1024, 1, 384, 192, 384, 0, 0, 3, 128, 1, pool_type, 'incept5a', phase_train=phase_train, use_batch_norm=True)
  incept5b = _inception(incept5a, 896, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'MAX', 'incept5b', phase_train=phase_train, use_batch_norm=True)
  pool6 = _apool(incept5b,  3, 3, 1, 1, 'VALID')

  resh1 = tf.reshape(pool6, [-1, 896])
  affn1 = _affine(resh1, 896, 128)
  if keep_probability<1.0:
    affn1 = control_flow_ops.cond(phase_train,
                                  lambda: tf.nn.dropout(affn1, keep_probability), lambda: affn1)
  norm = tf.nn.l2_normalize(affn1, 1, 1e-10, name='embeddings')

  return norm
```
"
2677,Import error,"I am trying to import tensorflow (I have installed on 14.04 LTS and tensorflow 0.8) but it shows atributeError: module 'imp' has no attribute 'find_module'

Traceback (most recent call last): File """", line 1, in File ""/home/prayalankar/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/init.py"", line 23, in from tensorflow.python import \* File ""/home/prayalankar/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/init.py"", line 45, in from tensorflow.python import pywrap_tensorflow File ""/home/prayalankar/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in _pywrap_tensorflow = swig_import_helper() File ""/home/prayalankar/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 18, in swig_import_helper fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(file)]) AttributeError: module 'imp' has no attribute 'find_module'

How to proceed.
"
2671,image_retraining example creates inconsistently named nodes when run multiple times,"I don't know if this is a thing you want to support, but I've been running the image_retraining example from Jupyter like so:

FLAGS._parse_flags()
FLAGS.image_dir = '/data/corpus'
FLAGS.output_graph = '/data/output_graph4.pb'
FLAGS.output_labels = '/data/output_labels4.txt'
FLAGS.bottleneck_dir = '/data/bottleneck/'
FLAGS.model_dir = '/data/imagenet/'

main('')

Unlike the example, I end up running the example multiple times in the same python process, and .: in the same default graph, so everything after the first run is badly named when output, i.e. instead of being named DecodeJpeg, I found DecodeJpeg_3

Adding tf.reset_default_graph() to the top of main fixes this.
"
2669,image_retraining example is extremely slow when cropping/rotating,"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: CUDA 7.5, cuDNN 4
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

$ ls -l /usr/local/cuda/lib64/
total 987720
-rw-r--r-- 1 root root  28585480 Aug 15  2015 libcublas_device.a
lrwxrwxrwx 1 root root        16 Aug 15  2015 libcublas.so -> libcublas.so.7.5
lrwxrwxrwx 1 root root        19 Aug 15  2015 libcublas.so.7.5 -> libcublas.so.7.5.18
-rwxr-xr-x 1 root root  23938736 Aug 15  2015 libcublas.so.7.5.18
-rw-r--r-- 1 root root  28220076 Aug 15  2015 libcublas_static.a
-rw-r--r-- 1 root root    322936 Aug 15  2015 libcudadevrt.a
lrwxrwxrwx 1 root root        16 Aug 15  2015 libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root        19 Aug 15  2015 libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root    383336 Aug 15  2015 libcudart.so.7.5.18
-rw-r--r-- 1 root root    720192 Aug 15  2015 libcudart_static.a
-rwxr-xr-x 1 root root  61453024 Jun  3 17:11 libcudnn.so
-rwxr-xr-x 1 root root  61453024 Jun  3 17:11 libcudnn.so.4
-rwxr-xr-x 1 root root  61453024 Jun  3 17:11 libcudnn.so.4.0.7
-rw-r--r-- 1 root root  62025862 Jun  3 17:11 libcudnn_static.a
lrwxrwxrwx 1 root root        15 Aug 15  2015 libcufft.so -> libcufft.so.7.5
lrwxrwxrwx 1 root root        18 Aug 15  2015 libcufft.so.7.5 -> libcufft.so.7.5.18
-rwxr-xr-x 1 root root 111231960 Aug 15  2015 libcufft.so.7.5.18
-rw-r--r-- 1 root root 115104400 Aug 15  2015 libcufft_static.a
lrwxrwxrwx 1 root root        16 Aug 15  2015 libcufftw.so -> libcufftw.so.7.5
lrwxrwxrwx 1 root root        19 Aug 15  2015 libcufftw.so.7.5 -> libcufftw.so.7.5.18
-rwxr-xr-x 1 root root    447664 Aug 15  2015 libcufftw.so.7.5.18
-rw-r--r-- 1 root root     42206 Aug 15  2015 libcufftw_static.a
lrwxrwxrwx 1 root root        17 Aug 15  2015 libcuinj64.so -> libcuinj64.so.7.5
lrwxrwxrwx 1 root root        20 Aug 15  2015 libcuinj64.so.7.5 -> libcuinj64.so.7.5.18
-rwxr-xr-x 1 root root   5751400 Aug 15  2015 libcuinj64.so.7.5.18
-rw-r--r-- 1 root root   1649726 Aug 15  2015 libculibos.a
lrwxrwxrwx 1 root root        16 Aug 15  2015 libcurand.so -> libcurand.so.7.5
lrwxrwxrwx 1 root root        19 Aug 15  2015 libcurand.so.7.5 -> libcurand.so.7.5.18
-rwxr-xr-x 1 root root  51765952 Aug 15  2015 libcurand.so.7.5.18
-rw-r--r-- 1 root root  51992564 Aug 15  2015 libcurand_static.a
lrwxrwxrwx 1 root root        18 Aug 15  2015 libcusolver.so -> libcusolver.so.7.5
lrwxrwxrwx 1 root root        21 Aug 15  2015 libcusolver.so.7.5 -> libcusolver.so.7.5.18
-rwxr-xr-x 1 root root  37034328 Aug 15  2015 libcusolver.so.7.5.18
-rw-r--r-- 1 root root  16613348 Aug 15  2015 libcusolver_static.a
lrwxrwxrwx 1 root root        18 Aug 15  2015 libcusparse.so -> libcusparse.so.7.5
lrwxrwxrwx 1 root root        21 Aug 15  2015 libcusparse.so.7.5 -> libcusparse.so.7.5.18
-rwxr-xr-x 1 root root  36816424 Aug 15  2015 libcusparse.so.7.5.18
-rw-r--r-- 1 root root  44445334 Aug 15  2015 libcusparse_static.a
lrwxrwxrwx 1 root root        14 Aug 15  2015 libnppc.so -> libnppc.so.7.5
lrwxrwxrwx 1 root root        17 Aug 15  2015 libnppc.so.7.5 -> libnppc.so.7.5.18
-rwxr-xr-x 1 root root    427168 Aug 15  2015 libnppc.so.7.5.18
-rw-r--r-- 1 root root     20664 Aug 15  2015 libnppc_static.a
lrwxrwxrwx 1 root root        14 Aug 15  2015 libnppi.so -> libnppi.so.7.5
lrwxrwxrwx 1 root root        17 Aug 15  2015 libnppi.so.7.5 -> libnppi.so.7.5.18
-rwxr-xr-x 1 root root  63516808 Aug 15  2015 libnppi.so.7.5.18
-rw-r--r-- 1 root root  90106200 Aug 15  2015 libnppi_static.a
lrwxrwxrwx 1 root root        14 Aug 15  2015 libnpps.so -> libnpps.so.7.5
lrwxrwxrwx 1 root root        17 Aug 15  2015 libnpps.so.7.5 -> libnpps.so.7.5.18
-rwxr-xr-x 1 root root   6047400 Aug 15  2015 libnpps.so.7.5.18
-rw-r--r-- 1 root root   8647292 Aug 15  2015 libnpps_static.a
lrwxrwxrwx 1 root root        16 Aug 15  2015 libnvblas.so -> libnvblas.so.7.5
lrwxrwxrwx 1 root root        19 Aug 15  2015 libnvblas.so.7.5 -> libnvblas.so.7.5.18
-rwxr-xr-x 1 root root    456112 Aug 15  2015 libnvblas.so.7.5.18
lrwxrwxrwx 1 root root        24 Aug 15  2015 libnvrtc-builtins.so -> libnvrtc-builtins.so.7.5
lrwxrwxrwx 1 root root        27 Aug 15  2015 libnvrtc-builtins.so.7.5 -> libnvrtc-builtins.so.7.5.18
-rwxr-xr-x 1 root root  22408512 Aug 15  2015 libnvrtc-builtins.so.7.5.18
lrwxrwxrwx 1 root root        15 Aug 15  2015 libnvrtc.so -> libnvrtc.so.7.5
lrwxrwxrwx 1 root root        18 Aug 15  2015 libnvrtc.so.7.5 -> libnvrtc.so.7.5.17
-rwxr-xr-x 1 root root  18199288 Aug 15  2015 libnvrtc.so.7.5.17
lrwxrwxrwx 1 root root        18 Aug 15  2015 libnvToolsExt.so -> libnvToolsExt.so.1
lrwxrwxrwx 1 root root        22 Aug 15  2015 libnvToolsExt.so.1 -> libnvToolsExt.so.1.0.0
-rwxr-xr-x 1 root root     37936 Aug 15  2015 libnvToolsExt.so.1.0.0
-rw-r--r-- 1 root root     25840 Aug 15  2015 libOpenCL.so
drwxr-xr-x 2 root root      4096 Jun  3 13:47 stubs

If installed from binary pip package, provide:
1. Which pip package you installed. Linux x64 w/ GPU support
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

0.8.0
### Steps to reproduce

I've been running the image_retrain example from Jupyter like so:

FLAGS._parse_flags()
FLAGS.image_dir = '/data/corpus'
FLAGS.output_graph = '/data/output_graph4.pb'
FLAGS.output_labels = '/data/output_labels4.txt'
FLAGS.bottleneck_dir = '/data/bottleneck/'
FLAGS.model_dir = '/data/imagenet/'
# FLAGS.flip_left_right = True

FLAGS.random_crop = 5
FLAGS.random_scale = 5
FLAGS.random_brightness = 5

main('')

When I run it without any of the crop/scale options, it runs pretty quickly on my AWS instance; creating the bottlneck images takes under an hour and the training takes minutes for 4k steps.

When I specify those flags, it took on the order of 13 hours to complete when I had ~9k images.

Obviously it has to do more work, but needing to do more than 13x the work to transform 15% of my images seems wrong.
"
2668,Error: unexpected EOF from Bazel server,"==> tensorflow : r0.9   bazel : 0.2.3  gcc:6.1.1  python: 3.5
When i try to compile tensorflow from source on my archlinux(kernel : 4.5.4-1) ,errror occured. Something like "" Linking tensorflow/cc/ops/data_flow_ops_gen_cc [for host]
Error: nexpected EOF from Bazel server.""
"
2667,How to save and restore tensorflow graph and it's state in C++?,"I'm training my model using tensorflow in C++ (I have a lot of stuff in c++ for my model). Python is used only for constructing the graph. So is there way to save and restore graph and its state purely in C++? I know about python tf.train.Saver but as I've understood it is not exists in C++.

Is it possible to get GraphDef from already running session?

Here is StackOverflow question
http://stackoverflow.com/questions/37508771/how-to-save-and-restore-tensorflow-graph-and-its-state-in-c
"
2665,TypeError when using distributed TensorFlow,"I follow the document to run TensorFlow in distributed mode in https://www.tensorflow.org/versions/r0.8/how_tos/distributed/index.html . But I got this error ""TypeError: 'str' object is not callable"".

```
root@b8ff53209db2:/# python trainer.py \
>      --ps_hosts=ps0.example.com:2222,ps1.example.com:2222 \
>      --worker_hosts=worker0.example.com:2222,worker1.example.com:2222 \
>      --job_name=ps --task_index=0
Traceback (most recent call last):
  File ""trainer.py"", line 74, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.4/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""trainer.py"", line 18, in main
    worker_hosts = FLAGS.worker_hosts("","")
TypeError: 'str' object is not callable
```
### Environment info

Operating System: Ubuntu, 4.4.0-22-generic

Installed version of CUDA and cuDNN: None

If installed from binary pip package, provide:

```
pip 8.1.2
Python 3.4.4
tensorflow 0.8.0
```

If installed from sources, provide the commit hash:
### Steps to reproduce
1. `python trainer.py --ps_hosts=""ps0.example.com:2222,ps1.example.com:2222"" --worker_hosts=""worker0.example.com:2222,worker1.example.com:2222"" --job_name=""worker"" --task_index=1`
### Logs or other output that would be helpful

```
Traceback (most recent call last):
  File ""trainer.py"", line 74, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.4/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""trainer.py"", line 18, in main
    worker_hosts = FLAGS.worker_hosts("","")
TypeError: 'str' object is not callable
```
"
2662,contrib/session_bundle does not work with python3,"Branch r0.9 
### Environment info

Operating System: Ubuntu 14.4

Installed version of CUDA and cuDNN: no
### Steps to reproduce
1.  ./configure -> python path = /usr/local/bin/python3
2.  bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

Error with:
//tensorflow/contrib/session_bundle/example:export_half_plus_two
### What have you tried?
1.  Cloning branch r0.8, which does not include the broken target, works
"
2661,Map/Scan/Fold cannot be nested.,"import tensorflow as tf
a=tf.constant([[[1,2,3],[10,20,30]],[[1,2,3],[10,20,30]],[[1,2,3],[10,20,30]],[[1,2,3],[10,20,30]]])

sess=tf.InteractiveSession()
print sess.run(tf.map_fn(lambda x: tf.scan(lambda y,z:tf.add(y,z),x),a))

ERROR:

AlreadyExistsError: Resource _tensor_arrays/map_10/while/scan/TensorArray/N10tensorflow11TensorArrayE
     [[Node: map_10/while/scan/TensorArray = TensorArray[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, tensor_array_name="""", _device=""/job:localhost/replica:0/task:0/cpu:0""](map_10/while/scan/Squeeze/_72, ^_cloopmap_10/while/scan/TensorArrayWrite/index/_19)]]
     [[Node: map_10/while/scan/while/Identity/_73 = _HostSend[T=DT_INT32, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_190_map_10/while/scan/while/Identity"", _device=""/job:localhost/replica:0/task:0/gpu:0""](map_10/while/scan/while/Identity)]]
Caused by op u'map_10/while/scan/TensorArray', defined at:
  File ""/usr/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py"", line 589, in launch_instance
    app.start()
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py"", line 405, in start
    ioloop.IOLoop.instance().start()
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py"", line 162, in start
    super(ZMQIOLoop, self).start()
  File ""/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py"", line 840, in start
    handler_func(fd_obj, events)
  File ""/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(_args, *_kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(_args, *_kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(_args, *_kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 260, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 212, in dispatch_shell
    handler(stream, idents, msg)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 370, in execute_request
    user_expressions, allow_stdin)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py"", line 175, in do_execute
    shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2723, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2825, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2885, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-26-ae3c447b43e3>"", line 2, in <module>
    print sess.run(tf.map_fn(lambda x: tf.scan(lambda y,z:tf.add(y,z),x),a))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.py"", line 259, in map_fn
    swap_memory=swap_memory)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1671, in while_loop
    result = context.BuildLoop(cond, body, loop_vars)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1572, in BuildLoop
    body_result = body(*vars_for_body_with_tensor_arrays)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.py"", line 253, in compute
    ta = ta.write(i, fn(elems_ta.read(i)))
  File ""<ipython-input-26-ae3c447b43e3>"", line 2, in <lambda>
    print sess.run(tf.map_fn(lambda x: tf.scan(lambda y,z:tf.add(y,z),x),a))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.py"", line 319, in scan
    infer_shape=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py"", line 126, in __init__
    tensor_array_name=tensor_array_name, name=scope)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 659, in _tensor_array
    tensor_array_name=tensor_array_name, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 694, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2153, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1153, in __init__
    self._traceback = _extract_stack()
"
2660,Max Pooling NCHW,"In the documentation for the tf.nn.max_pool() op, it is written: 

`data_format: A string. 'NHWC' and 'NCHW' are supported.`

However, when I specify 'NCHW' as the data format, I receive the error ""Default MaxPoolingOp only supports NHWC"" (generated [here](https://github.com/tensorflow/tensorflow/blob/3488ac22f156cbcfd27c242ccbdac58679385ddc/tensorflow/core/kernels/pooling_ops_common.h#L83) in master when this was written). 

It was my understanding that most ops have been ported to NCHW to support CuDNN natively - so I was surprised to see this wasn't implemented. 
"
2655,Feature Request: Support for YARN cluster manager for Distributed TensorFlow,"The Distributed TensorFlow documentation said to open an issue to request support for a specific cluster manager, support for YARN would be beneficial. 

Thanks
"
2654,Saver producing large meta files after long run,"The code is for deep q-learning and for reference it's [here](https://github.com/domluna/deep-rl-gym-tutorials/tree/master/q_learning) and the keras model is [here](https://github.com/domluna/deep-rl-gym-tutorials/blob/master/q_learning/models.py)

Training after 400 timesteps:

save file is 9.7MB
meta file is 25MB

after 2,750,000 timesteps

save file is 9.7MB
meta file is 1.4GB

after 3M timesteps

save file is 9.7MB
meta file is 1.5GB

So the meta file grows over 100MB per 275,000 timesteps. The saver keeps the last 5 checkpoints by default so you could image my shock when I woke up and my Dropbox was full!

Anyway, this kind of growth is unreasonable is there a way to keep it in check?
"
2653,CUDA_VISIBLE_DEVICES not working?,"gpu0 is used by other guys, So I want to use another gpu to run cifar10_train(cifar10_multi_gpu_train).
But it seems that tensorflow still try to use gpu0 even I specify CUDA_VISIBLE_DEVICES=2

$ CUDA_VISIBLE_DEVICES=2 python ~/tensorflow2/lib/python2.7/site-packages/tensorflow/models/image/cifar10/cifar10_train.py --data_dir ~/cifar10_data --train_dir ~/cifar10_train_gpu
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:08:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:08:00.0)
F tensorflow/stream_executor/cuda/cuda_dnn.cc:427] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM
Aborted (core dumped)

$ nvidia-smi
|===============================+======================+======================|
|   0  GeForce GTX TIT...  Off  | 0000:04:00.0     Off |                  N/A |
| 32%   70C    P2   100W / 250W |  10135MiB / 12287MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX TIT...  Off  | 0000:05:00.0     Off |                  N/A |
| 22%   41C    P0    73W / 250W |     23MiB / 12287MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX TIT...  Off  | 0000:08:00.0     Off |                  N/A |
| 22%   41C    P0    67W / 250W |     23MiB / 12287MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |
| 22%   42C    P0    74W / 250W |     23MiB / 12287MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   4  GeForce GTX TIT...  Off  | 0000:84:00.0     Off |                  N/A |
| 22%   39C    P0    75W / 250W |     23MiB / 12287MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   5  GeForce GTX TIT...  Off  | 0000:85:00.0     Off |                  N/A |
| 22%   39C    P0    69W / 250W |     23MiB / 12287MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   6  GeForce GTX TIT...  Off  | 0000:88:00.0     Off |                  N/A |
| 22%   38C    P0    74W / 250W |     23MiB / 12287MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   7  GeForce GTX TIT...  Off  | 0000:89:00.0     Off |                  N/A |
| 22%   38C    P0    69W / 250W |     23MiB / 12287MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      7266    C   /some/app       10111MiB 
"
2652,Backward pass of broadcasting on GPU is non-deterministic,"``` python
import tensorflow as tf

def run(on_gpu):
    tf.reset_default_graph()
    tf.set_random_seed(42)
    with tf.device('/gpu:0' if on_gpu else '/cpu:0'):
        a = tf.random_normal([16, 16])
        b = tf.get_variable('b', shape = [], initializer = tf.constant_initializer(value = 0.0))
        c = a*b
        grad = tf.gradients(c, [b], gate_gradients=tf.train.Optimizer.GATE_GRAPH)[0]

    sess = tf.Session()
    sess.run(tf.initialize_all_variables())
    grad_val = sess.run(grad)
    return grad_val

for i in xrange(20):
    print repr(run(on_gpu=True)),
print ''
for i in xrange(20):
    print repr(run(on_gpu=False)),
```

Result:

```
23.066511 23.066511 23.066513 23.066513 23.066511 23.066513 23.066509 23.066513 23.066513 23.066511 23.066513 23.066511 23.066513 23.066513 23.066509 23.066511 23.066513 23.066513 23.066511 23.066511 
23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509 23.066509
```

As you can see, consistent result across CPU runs but inconsistent result across GPU runs.

No doubt a CUDA reduction order issue, but it'd be really nice if we can have deterministic reduction. I am using tf 0.8.0 (self-compiled against CuDNN v5). CuDNN version is 5005 (not rc)
"
2648,Saver.restore() causes segfault in distributed mode,"I use a custom saver object in distributed mode that operates over a subset of the parameters in my model so that I can perform transfer learning between my models. I'm running into a situation where loading weights for one of my models causes a segfault, and I can't seem to figure out why. I'm running this code:

``` python
...
supervisor = tf.train.Supervisor(is_chief=(task_index == 0),
                                 logdir=log_dir,
                                 init_op=init_op,
                                 saver=None,
                                 summary_op=training_summary_op,
                                 global_step=global_step,
                                 summary_writer=summary_writer)

if task_index != 0:
    logger.info('waiting for session.')
else:
    logger.info('starting session.')
with supervisor.prepare_or_wait_for_session(
        server.target, config=tf.ConfigProto(allow_soft_placement=True)) as sesh:
    if task_index != 0:
        while True:
            if supervisor.should_stop():
                logger.info('training completed')
                return
            if ready.eval(sesh):
                break
            sleep(0.01)
    logger.info('session started.')

    if task_index == 0:
        if isfile(save_file):
            logger.info('loading from save file: %s' % save_file.split('/')[-1])
            saver.restore(sesh, save_file)
        elif transfer_file is not None and isfile(transfer_file):
            logger.info('transfering weights from file: %s' % transfer_file.split('/')[-1])
            loader.restore(sesh, transfer_file)
            logger.info('executing post transfer ops')
            sesh.run(post_transfer_ops)
        sesh.run(is_ready)
...
```

The transfer file exists on both the parameter servers and the chief worker and running the code results in this output:

```
INFO: starting session.
INFO: session started.
INFO: transfering weights from file: test_train5.0.ckpt
Segmentation fault (core dumped)
```

The graph I'm using is identical to one that I can deploy on a single machine without error, I can even load the weights into the local version, but even if an issue with parameter names were the issue I would still hope that it would give me an error instead of a segfault. Note that this issue does not appear for every model, though it is deterministic.
"
2646,Segfaults due to protobuf -std=c++11 mismatch,"I was seeing segfaults in `std::unordered_map`, and the symptoms looked like potential memory corruption.  Took a fair amount of digging in gdb to figure out that it wasn't that, but was just a build/library version issue:
- tensorflow's embedded protobuf is built with `-std=c++11`
- a default protobuf build is built without `-std=c++11`

I'm not super familar with the details of dlopen and symbol resolution, but the `RTLD_GLOBAL` when it loads `_pywrap_tensorflow.so` might be causing it to shadow the symbols in `libprotobuf.so` (for the cpp-enabled protobuf python package).  The C++11 vs non-C++11 libraries use different headers for `std::unordered_map` (in bits vs tr1), and things blow up when they start using the wrong library's version of the code.  (Correct me if my understanding of RTLD_GLOBAL is wrong and that's irrelevant).

In any case, building protobuf with C++11 fixed the segfaults I was seeing.

Now as for solutions, here are some ideas:
- Allow tensorflow to link to an external libprotobuf.so.  This is probably the best solution, since then only one protobuf library is loaded at runtime, and a version check is probably simple to add.
- If RTLD_GLOBAL is a relevant factor, maybe _pywrap_tensorflow.so can be split up and only the parts that actually need to be global can be global.  Or maybe some gcc attributes to control visibility can do the trick.
- Maybe we can shove the embedded protobuf into a namespace so the symbols don't collide

Possibly useful info to reproduce:
- gcc-4.8.x
- libstdc++.so.6.0.19
- r0.8 branch

I've seen some other people post about similar segfault issues and I suspect many of them might be related to this.

Also now that I've found the issue, it seems obvious in retrospect, and a related issue on the protobuf issues is https://github.com/google/protobuf/issues/839.
"
2645,Persistent Tensor deletion fails when tensor was moved,"TLDR; handle movers register Python SessionHandle instead of string session handle, which causes `InternalError: Unable to get element from the feed.` when garbage collection is triggered on moved persistent tensors.

The solution is to replace `self._register_dead_handle(handle)` with `self._register_dead_handle(handle.handle)` in `session.py`
## Discussion

There are two types of handle objects, Python TensorHandle and ""native"" string session handle. The conversion from Python `TensorHandle` object to native handle `string` object is done in `session.py` and `session_ops.py` in one of those 3 ways.
- `self._handle = compat.as_str_any(handle)`
- `str(handle)`
- `handle.handle`

The ""str"" conversion is not very Python since `__str__` is supposed to be used for display/debugging purposes. Some suggestions to make it easier to avoid bugs like above:
1. Annotate which kind of handle object is being dealt with. Perhaps `py_handle` variable should refer to Python TensorHandle objects and `handle` refer to native ""string"" handle objects
2. Only use one kind of conversion method, perhaps as `py_handle.handle`
3. `__str__` method of TensorHandle could be `return`""TensorHandle(%s)""%(self.handle)` for easier debugging
## Test case

```
class EnvTest(tf.test.TestCase):

  def testHandleDeletion(self):
    dtype = tf.float32
    # soft-placement to work around #2587
    config = tf.ConfigProto(log_device_placement=True,
                            allow_soft_placement=True)
    sess = tf.Session(config=config)

    # initial values live on CPU
    with tf.device(""/cpu:0""):
      one = tf.constant(1, dtype=dtype)
      one_handle = sess.run(tf.get_session_handle(one))
      x = tf.get_session_handle(one)
      x_handle = sess.run(tf.get_session_handle(one))

    # addition lives on GPU
    with tf.device(""/gpu:0""):
      add_holder1, add_tensor1 = tf.get_session_tensor(dtype)
      add_holder2, add_tensor2 = tf.get_session_tensor(dtype)
      add_op = tf.add(add_tensor1, add_tensor2)
      add_output = tf.get_session_handle(add_op)


    # add 1 to tensor 20 times
    for i in range(20):
      x_handle = sess.run(add_output, feed_dict={add_holder1: one_handle.handle,
                                                 add_holder2: x_handle.handle})
```

The failure is

```

======================================================================
ERROR: testHandleDeletion (__main__.EnvTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/tensor_handle_test.runfiles/org_tensorflow/tensorflow/contrib/immediate/python/immediate/tensor_handle_test.py"", line 35, in testHandleDeletion
    add_holder2: x_handle.handle})
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/tensor_handle_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 333, in run
    run_metadata_ptr)
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/tensor_handle_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 591, in _run
    self._register_dead_handle(handle)
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/tensor_handle_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 726, in _register_dead_handle
    self.run(fetches, feed_dict=feeds)
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/tensor_handle_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 333, in run
    run_metadata_ptr)
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/tensor_handle_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 587, in _run
    feed_dict_string, options, run_metadata)
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/tensor_handle_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 662, in _do_run
    target_list, options, run_metadata)
  File ""/Users/yaroslavvb/tfimmediate_macbook/tensorflow/bazel-bin/tensorflow/contrib/immediate/tensor_handle_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 682, in _do_call
    raise type(e)(node_def, op, message)
InternalError: Unable to get element from the feed.

```

@yuanbyu @keveman 
"
2642,TF Tutorial refers to cudnn-7.5-linux-x64-v4.tgz,"In the GPU installation section.

Except, all the obvious sources on the [nvidia website](https://developer.nvidia.com/rdp/cudnn-download) only seem to have cudnn-7.0-linux-x64-v4.tgz. 

Is this a typo, or a reference to a now unavailable resource?
"
2641,Error in gradient of reduce_prod,"```
vars = tf.Variable([1., 2.])
tf.initialize_all_variables().run()
tf.gradients(tf.reduce_prod(vars), vars)[0].eval()
```

yields `[ 2.,  1.]` which is correct. But

```
vars = tf.Variable([0., 2.])
tf.initialize_all_variables().run()
tf.gradients(tf.reduce_prod(vars), vars)[0].eval()
```

yields `[ nan,   0.]` which is incorrect. The correct gradient is `[ 2.,  0.]`
"
2640,libpthread.so error with android demo,"Operating System: OSX Yosemite 10.10.5

Followed the [virtualenv installation instructions](https://github.com/hamidb/tensorflow/blob/api20/tensorflow/g3doc/get_started/os_setup.md#virtualenv-installation-virtualenv_install)

r11 release

I followed [these](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android) instructions to run the android demo

Have tried Bazel releases 0.2.3, 0.2.2, 0.2.1 and 0.1.4
Have the latest sdk and ndk

Have tried with all the sdk and ndk info uncommented in Workspace and with the ndk commented out

I get as far as 
`$ bazel build //tensorflow/examples/android:tensorflow_demo`

and I get the following errors:

`ERROR: /Users/lizzya/Documents/tensorflow-master/tensorflow/examples/android/BUILD:41:1: Linking of rule '//tensorflow/examples/android:libpthread.so' failed: false failed: error executing command 
  (cd /private/var/tmp/_bazel_lizzya/3ad59cfd62098d64f5760266c321e9a2/tensorflow-master && \
  exec env - \
  /bin/false -o bazel-out/android-stub_armeabi-v7a-fastbuild/bin/tensorflow/examples/android/libpthread.so -shared -Wl,-S -Wl,@bazel-out/android-stub_armeabi-v7a-fastbuild/bin/tensorflow/examples/android/libpthread.so-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: false failed: error executing command 
  (cd /private/var/tmp/_bazel_lizzya/3ad59cfd62098d64f5760266c321e9a2/tensorflow-master && \
  exec env - \
  /bin/false -o bazel-out/android-stub_armeabi-v7a-fastbuild/bin/tensorflow/examples/android/libpthread.so -shared -Wl,-S -Wl,@bazel-out/android-stub_armeabi-v7a-fastbuild/bin/tensorflow/examples/android/libpthread.so-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
process-wrapper: execvp(""/bin/false"", ...): No such file or directory
Target //tensorflow/examples/android:tensorflow_demo failed to build
INFO: Elapsed time: 1.509s, Critical Path: 0.16s

`
"
2637,Possible way to apply gradients using tf.identity()?,"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 7.5 and R4

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash: 79174afa30046ecdc437b531812f2cb41a32695e
### Steps to reproduce

``` python
import tensorflow as tf

a = tf.constant(1.)
b = tf.Variable(2.)
c = a * b
grad_symbolic = tf.gradients(c, tf.trainable_variables())
grad_vars = [tf.Variable(tf.zeros_like(_)) for _ in tf.trainable_variables()]
grad_zero_ops = [_.assign(tf.zeros_like(_)) for _ in grad_vars]
grad_accum_ops = [grad_vars[i].assign_add(grad_symbolic[i])
                  for i in xrange(len(grad_vars))]
opt = tf.train.GradientDescentOptimizer(1.)
train_op = opt.apply_gradients(zip(
    [tf.identity(_) for _ in grad_vars], tf.trainable_variables()))
sess = tf.Session()
sess.run(tf.initialize_all_variables()) # This will cause error.
# This will run successfully.
# for _ in tf.all_variables():
#     sess.run(tf.initialize_variables([_]))
```
### What have you tried?
1. [workaround](http://stackoverflow.com/questions/35656643/tf-initialize-variables-inconvenience-failedpreconditionerror-tensorflow)
2. But in my real project code, the program stucks into the `variable initialization` for too many minutes if I initialize variables one by one.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

```
Traceback (most recent call last):
  File ""test_identity_gradient_apply.py"", line 26, in <module>
    sess.run(tf.initialize_all_variables()) # This will cause error.
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 333, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 573, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 648, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 668, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value Variable
     [[Node: Variable/read = Identity[T=DT_FLOAT, _class=[""loc:@Variable""], _device=""/job:localhost/replica:0/task:0/cpu:0""](Variable)]]
Caused by op u'Variable/read', defined at:
  File ""test_identity_gradient_apply.py"", line 15, in <module>
    b = tf.Variable(2.)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 211, in __init__
    dtype=dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 319, in _init_from_args
    self._snapshot = array_ops.identity(self._variable, name=""read"")
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 788, in identity
    result = _op_def_lib.apply_op(""Identity"", input=input, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2249, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1224, in __init__
    self._traceback = _extract_stack()

```
"
2636,Segment Fault after Import Tensorflow,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Debian 8.5

Installed version of CUDA and cuDNN:  No
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed: Ubuntu/Linux 64-bit, CPU only
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"": Segment Fault

If installed from sources, provide the commit hash:
### Steps to reproduce
1. Run Python with `python`
2. Import Tensorflow `import tensorflow`
3. Got error `Segment Fault`
### What have you tried?

N/a
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

![screenshot from 2016-06-03 15 51 26](https://cloud.githubusercontent.com/assets/1730504/15772309/fde464e6-29a2-11e6-91bf-0428672c8b52.png)
"
2634,When dose reusebale variable sync between device?,"I want to validate model under training after certain iterations on train set.
The switch between train and validate is controlled by global set.
Training is on GPU:1, while validation is on CPU:0.
If share the variable between GPU and CPU using  tf.get_variable_scope().reuse_variables()
when dose the two copy sync?
Every time after GPU apply_gradients or CPU used them in seesion.run(op on CPU)?
"
2631,error building py package in format of tar.gz,"OS: OS X Yosemite 10.10.4

After installation of dependencies, I build it as following cmds:

delete `bdist_wheel` in `tensorflow/tensorflow/tools/pip_package/build_pip_package.sh`

`${PYTHON_BIN_PATH:-python} setup.py bdist_wheel >/dev/null` to `${PYTHON_BIN_PATH:-python} setup.py`

```


bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

sh +x tensorflow/tensorflow/tools/pip_package/build_pip_package.sh /tmp
```

then I got the package named `tensorflow-0.8.0.tar.gz`, after that I installed it using pip, succeed.

However, when I imported it, I got the error:

```
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: No module named tensorflow
```

Could anybody help me? Any help will be highly appreciated.

Could staff in Google build it or give some valuable instructions?
"
2630,"Getting ""readlink: illegal option -- f"" when switching builds in MacOS","I'm running into this error when building my targets with regular config, and after that trying to build with `config=cuda` in the same directory on latest MacOS (10.11.5) and bazel (0.2.3-homebrew). A work-around is to git-clone into a new directory, and build there with `config=cuda`

```

`/private/var/tmp/_bazel_yaroslavvb/1401dea20c857793b13cff5c293c0db6/tensorflow/'
____[8 / 88] Compiling external/protobuf/python/google/protobuf/internal/api_implementation.cc
____[8 / 165] Compiling external/re2/re2/filtered_re2.cc
____[8 / 313] Compiling external/boringssl_git/crypto/x509/x509_ext.c
____From Executing genrule //third_party/gpus/cuda:cuda_config_check:
readlink: illegal option -- f
usage: readlink [-n] [file ...]
ERROR: /Users/yaroslavvb/tfimmediate_fresh/tensorflow/third_party/gpus/cuda/BUILD:204:1: declared output 'third_party/gpus/cuda/cuda.config' was not created by genrule. This is probably because the genrule actually didn't create this output, or because the output was a directory and the genrule was run remotely (note that only the contents of declared file outputs are copied from genrules run remotely).
ERROR: /Users/yaroslavvb/tfimmediate_fresh/tensorflow/third_party/gpus/cuda/BUILD:204:1: not all outputs were created.
____[195 / 385] Compiling external/protobuf/src/google/protobuf/wrappers.pb.cc [for host]

```
"
2629,"Tensorflow distributed master worker saves unexpected: not raise exception and return the store checkpoint filepath,but check point file is not exist","**In distribution tensorflow  environment. the master worker saves checkpoint  fail.<br>
## saver.save  has return ok_**(not raise exception and return the expected checkpoint file path) *__but, the return checkpoint file is not exist_**.<br>

this is different from the description of the tensorflow api<br>

=============<br>
**the related code is below:**

```
 def def_ps(self):
    self.saver = tf.train.Saver(max_to_keep=100,keep_checkpoint_every_n_hours=3)

def save(self,idx):    
    ret = self.saver.save(self.sess,self.save_model_path,global_step=None,write_meta_graph=False)
    if not os.path.exists(ret):
        msg = ""save model for %u path %s not exists.""%(idx,ret)
        lg.error(msg)
        raise Exception(msg);
```

=============<br>
**the log is below**:

 2016-06-02 21:33:52,323 root         ERROR    save model for 2 path model_path/rl_model_2 not exists.
2016-06-02 21:33:52,323 root         ERROR    has error:save model for 2 path model_path/rl_model_2 not exists.
Traceback (most recent call last):
  File ""d_rl_main_model_dist_0.py"", line 755, in run_worker
    model_a.save(next_model_idx)
  File ""d_rl_main_model_dist_0.py"", line 360, in save
    Trainer.save(self,save_idx)
  File ""d_rl_main_model_dist_0.py"", line 289, in save
    raise Exception(msg);
Exception: save model for 2 path model_path/rl_model_2 not exists.

===========<br>
**not meets the tensorflow api which define Saver.save as below:**

https://www.tensorflow.org/versions/master/api_docs/python/state_ops.html#Saver

tf.train.Saver.save(sess, save_path, global_step=None, latest_filename=None, meta_graph_suffix='meta', write_meta_graph=True)

Returns:

A string: path at which the variables were saved. If the saver is sharded, this string ends with: '-?????-of-nnnnn' where 'nnnnn' is the number of shards created.

Raises:

TypeError: If sess is not a Session.
ValueError: If latest_filename contains path components.
"
2627,Complex Gradients in gather,"### Environment info

Operating System: Linux Ubuntu 14.04 LTS (64bit)

Installed version of CUDA and cuDNN: CUDA 7.5.18 and CUDNN 5.0.4
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed. Tensorflow 0.8.0 Nightly Python2.7 Linux (GPU) [Build 118](http://ci.tensorflow.org/job/nigntly-matrix-linux-gpu/118/)
### Steps to reproduce

I tried to run the following code using the tensorflow pip package  `storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl` 

``` python
import tensorflow as tf

W = tf.Variable(tf.random_uniform( (10,1) ), tf.float32)
W = tf.complex(W, 1.0)
C = tf.constant(1.0, dtype=tf.float32, shape=(3,1))

views = tf.gather(W, [2,1,5])
loss = tf.reduce_mean(tf.square( tf.complex_abs(views) - C))

optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)
train = optimizer.minimize(loss)

init = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)
```

I got
`TypeError: DataType complex64 for attr 'T' not in list of allowed values: float32, float64, int32, int64, uint8, int16, int8, uint16`

I looked it up and found issue #2255 so I installed the nightly build 118, and now I get this when trying to run the same code snippet

``` python
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-1-0671dcd6f73e> in <module>()
      9 
     10 optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)
---> 11 train = optimizer.minimize(loss)
     12 
     13 init = tf.initialize_all_variables()

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.pyc in minimize(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)
    191         aggregation_method=aggregation_method,
    192         colocate_gradients_with_ops=colocate_gradients_with_ops,
--> 193         grad_loss=grad_loss)
    194     return self.apply_gradients(grads_and_vars, global_step=global_step,
    195                                 name=name)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.pyc in compute_gradients(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)
    248         gate_gradients=(gate_gradients == Optimizer.GATE_OP),
    249         aggregation_method=aggregation_method,
--> 250         colocate_gradients_with_ops=colocate_gradients_with_ops)
    251     if gate_gradients == Optimizer.GATE_GRAPH:
    252       grads = control_flow_ops.tuple(grads)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.pyc in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)
    503           if in_grad is not None:
    504             if isinstance(in_grad, ops.Tensor):
--> 505               in_grad.set_shape(t_in.get_shape())
    506             _SetGrad(grads, t_in, in_grad)
    507         if loop_state:

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in set_shape(self, shape)
    402         this tensor.
    403     """"""
--> 404     self._shape = self._shape.merge_with(shape)
    405 
    406   @property

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc in merge_with(self, other)
    568       except ValueError:
    569         raise ValueError(""Shapes %s and %s are not compatible"" %
--> 570                          (self, other))
    571 
    572   def concatenate(self, other):

ValueError: Shapes (?, 1) and () are not compatible
```
"
2626,Profiling: libcupti.so cannot be loaded,"### Environment info

Operating System: Linux Ubuntu 14.04 LTS (64bit)

Installed version of CUDA and cuDNN: CUDA 7.5.18 and CUDNN 4.0.7
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
 ls -l /usr/local/cuda-7.5/lib/libcud*
-rw----r-- 1 root root 189170  2 24 18:12 /usr/local/cuda-7.5/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16  2 24 18:12 /usr/local/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19  2 24 18:12 /usr/local/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwx---r-x 1 root root 311596  2 24 18:12 /usr/local/cuda-7.5/lib/libcudart.so.7.5.18
-rw----r-- 1 root root 558020  2 24 18:12 /usr/local/cuda-7.5/lib/libcudart_static.a
```

```
 ls -l /usr/local/cuda-7.5/lib64/libcud*
-rw----r-- 1 root root   322936  2 24 18:12 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16  2 24 18:12 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19  2 24 18:12 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwx---r-x 1 root root   383336  2 24 18:12 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw----r-- 1 root root   720192  2 24 18:12 /usr/local/cuda-7.5/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13  3  3 03:30 /usr/local/cuda-7.5/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 root root       17  3  3 03:30 /usr/local/cuda-7.5/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxr-xr-x 1 root root 61453024  3  3 03:30 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7
```

If installed from binary pip package, provide:
1. Which pip package you installed : **Tensorflow 0.8.0 Nightly** Python2.7 Linux (GPU) e.g. [Build 118](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/118/)
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"". : 0.8.0

If installed from sources, provide the commit hash:
### Steps to reproduce

Although it is experimental, I am using the GPU profiling functionality with CUPTI. 
1. Run any tensorflow code that uses CUPTI or `tf.RunOptions.FULL_TRACE`.
2. The following error (segfault) occurs.

```
I tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcupti.so. LD_LIBRARY_PATH:
F tensorflow/core/common_runtime/gpu/cupti_wrapper.cc:57] Check failed: f != nullptr could not find cuptiActivityRegisterCallbacksin libcupti DSO; dlerror: /home/wookayin/.virtualenvs/tfdebug/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: cuptiActivityRegisterCallbacks
[1]    82604 abort (core dumped)  python 19-mnist-profiling.py
```

Any TF code that invokes loading of `libcupti.so` will face the same error, but for convenience I will share a code that can run standalone: [19-mnist-profiling.py](https://gist.github.com/wookayin/06631c68bb48fc1d0a4eee77cbbba5f1)
### What have you tried?

The problem is that the shared library `libcupti.so` cannot be loaded. However, in some older nightly version (such as [Build 103](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/103/)) it worked.

UPD: I binary-searched to find the changeset to be blamed. Build 103 works, but [Build 104](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/104/) (Failed) and [Build 105](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/105/) does not work.
I highly suspect that this regression is since commit 6bd964c (but not sure):
- The path to `libcupti.so` would be `/usr/local/cuda/extras/CUPTI/lib64/libcupti.so`.
- After this commit, it seems that path to `libcupti.so` goes wrong. (but why?)

A strange thing to me is that tensorflow already has [a unit test](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/timeline_test.py) for CUPTI and GPU tracing functionalities, so CI must have run this test as well. This bug might be happening in some environments only (like nightly build I installed via `pip`), or it can be a a bazel-related problem (when generating packages).

I have not investigated into this problem in detail; it looks that after some troubleshooting I can figure out what the cause is.

Thanks!
### Logs or other output that would be helpful

N/A
"
2625,Numerically stable summation methods,"It would be nice to be able to use numerically stable summation methods like
- pairwise summation
- Kahan summation

for applications where numerical accuracy is important.
This could work with an optional `stable` keyword argument to `tf.reduce_sum` or via a `tf.stable_reduce_sum` op.

I think implementing Kahan summation in the Eigen tensor library wouldn't be difficult at all, we would simply have to add a stateful `KahanSumReducer`.
It should also be possible to provide a vectorized version.
Pairwise summation might be more difficult, as the reduction code would have to be touched.
"
2621,gpu support error(sampled_loss),"I'm now a little bit hesitated that I have found a similar issue before, however I can't find it now

in the file seq2seq_model.py in translate foloder, I use    with device(""/gpu:0')     instead of cpu, there's an error like this : 

``` javascript
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-10-84f5fbeb6a90> in <module>()
      1 sess = tf.InteractiveSession()
----> 2 nmt.train(sess, train_data, valid_data, EVALUATE_PER)

<ipython-input-6-ca1988aa7469> in train(self, sess, train_data, valid_data, evaluate_per)
    190 
    191             _, cost = self.step(sess, train_encoder_batches[batch_i], train_decoder_batches[batch_i], 
--> 192                                train_target_batches[batch_i], train_target_weight_batches[batch_i], self.train_flag)
    193 
    194             # if the loss is equal to NaN(not a number), raise error

<ipython-input-6-ca1988aa7469> in step(self, sess, encoder_data, decoder_data, target_data, tw_data, train_flag)
    122                 output_feed.append(self.final_outputs[idx])
    123 
--> 124         output = sess.run(output_feed, input_feed)
    125         return output
    126 

/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict)
    313         `Tensor` that doesn't exist.
    314     """"""
--> 315     return self._run(None, fetches, feed_dict)
    316 
    317   def partial_run(self, handle, fetches, feed_dict=None):

/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict)
    509     # Run request and get response.
    510     results = self._do_run(handle, target_list, unique_fetches,
--> 511                            feed_dict_string)
    512 
    513     # User may have fetched the same tensor multiple times, but we

/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict)
    562     if handle is None:
    563       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
--> 564                            target_list)
    565     else:
    566       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
    584         # pylint: disable=protected-access
    585         raise errors._make_specific_exception(node_def, op, error_message,
--> 586                                               e.code)
    587         # pylint: enable=protected-access
    588       six.reraise(e_type, e_value, e_traceback)

InvalidArgumentError: Cannot assign a device to node 'sequence_loss_by_example/sampled_softmax_loss_39/embedding_lookup_1': Could not satisfy explicit device specification '/device:GPU:0'
     [[Node: sequence_loss_by_example/sampled_softmax_loss_39/embedding_lookup_1 = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, validate_indices=true, _device=""/device:GPU:0""](proj_b/read, sequence_loss_by_example/sampled_softmax_loss_39/concat)]]
Caused by op u'sequence_loss_by_example/sampled_softmax_loss_39/embedding_lookup_1', defined at:
  File ""/opt/anaconda2/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/opt/anaconda2/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/opt/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""/opt/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py"", line 592, in launch_instance
    app.start()
  File ""/opt/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py"", line 403, in start
    ioloop.IOLoop.instance().start()
  File ""/opt/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py"", line 151, in start
    super(ZMQIOLoop, self).start()
  File ""/opt/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py"", line 866, in start
    handler_func(fd_obj, events)
  File ""/opt/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/opt/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 433, in _handle_events
    self._handle_recv()
  File ""/opt/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 465, in _handle_recv
    self._run_callback(callback, msg)
  File ""/opt/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 407, in _run_callback
    callback(*args, **kwargs)
  File ""/opt/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/opt/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 260, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/opt/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 212, in dispatch_shell
    handler(stream, idents, msg)
  File ""/opt/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 370, in execute_request
    user_expressions, allow_stdin)
  File ""/opt/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py"", line 175, in do_execute
    shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/opt/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2902, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/opt/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 3006, in run_ast_nodes
    if self.run_code(code, result):
  File ""/opt/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 3066, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-9-bfcd832d993d>"", line 2, in <module>
    BATCH_SIZE, NUM_SAMPLES, MAX_GRADIENT_NORM, LEARNING_RATE, decay_factor = LEARNING_RATE_DECAY_FACTOR)
  File ""<ipython-input-6-ca1988aa7469>"", line 88, in __init__
    self.loss_sequence = seq2seq.sequence_loss_by_example(self.outputs, self.targets, self.tw, self.target_voca, softmax_loss_function = softmax_loss_function)
  File ""seq2seq_mod070_ver5.py"", line 974, in sequence_loss_by_example
    crossent = softmax_loss_function(logit, target)
  File ""<ipython-input-6-ca1988aa7469>"", line 66, in sampled_loss
    self.target_voca)
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn.py"", line 865, in sampled_softmax_loss
    name=name)
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn.py"", line 661, in _compute_sampled_logits
    all_b = embedding_ops.embedding_lookup(biases, all_ids)
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/embedding_ops.py"", line 86, in embedding_lookup
    validate_indices=validate_indices)
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 423, in gather
    validate_indices=validate_indices, name=name)
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2040, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1087, in __init__
    self._traceback = _extract_stack()
```

what's the problem with this?

I heard that there are many device related things modified in release 0.8.0 just because of many of ops are coded with cuda(?)  then why not this part, I mean sampled_loss part in seq2seq_model.py
"
2620,cifar10 gpu core dump,"$python cifar10_train.py --data_dir=/home/lli/cifar10_data
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:04:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 1 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:05:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 2 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:08:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 3 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:09:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
Segmentation fault (core dumped)
"
2619,tf.image.decode_png returns wrong values for uint16 images,"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: CUDA 7.5, cuDNN R4

If installed from sources, provide the commit hash: d8eb4bb6470d4cb3d0f67f2111a39fa50f1c28e5
### Steps to reproduce

Please see the below code. After saving numpy array as uint16 png image, I loaded it using tf.image.decode_png. It returns different values from the original array. 

``` python
import numpy as np
import tensorflow as tf
from skimage import io

original = np.array([[1,4096],[15000,30000]],dtype=np.uint16)
io.imsave('test.png',original)

sk_im = io.imread('test.png')

image = tf.image.decode_png(tf.read_file('test.png'),dtype=tf.uint16)
sess = tf.Session()
tf_im = sess.run(image)

print sk_im
print tf_im
```

Results are

```
sk_im = [[1, 4096], [15000, 30000]] #same as original
tf_im[:,:,0] = [[256, 16], [38970, 12405]]
```

I checked the function works properly in case of uint8 png image.
"
2618,"BUILD ERROR: bazel could not find ""highwayhash/sip_hash.h""","Hi, could you tell me what I should correct?
### Environment info

Operating System: Fedora 23 Server

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): CUDA 7.5.18, cuDNN v4 (4.0.7)
### Steps to reproduce
1. prepare following to the instruction for ""install from source"" on web page
2. downgrade gcc to 4.9.3 and save user's local (because upper version is still in /usr/bin)
3. get bazel from GitHub
4. bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --verbose_failure
### What have you tried?
1. found the error message which seems not to find the include file of ""sip_hash.cc"". 
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

____Loading package: tensorflow/cc
____Loading package: @bazel_tools//tools/android
WARNING: /home/sio/.cache/bazel/_bazel_sio/20abde1548c7cbc7b364a6249f6601f2/external/protobuf/WORKSPACE:1: Workspace name in /home/sio/.cache/bazel/_bazel_sio/20abde1548c7cbc7b364a6249f6601f2/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
____Loading package: @bazel_tools//third_party/java/jdk/langtools
____Loading package: @protobuf//
WARNING: /home/sio/.cache/bazel/_bazel_sio/20abde1548c7cbc7b364a6249f6601f2/external/highwayhash/WORKSPACE:1: Workspace name in /home/sio/.cache/bazel/_bazel_sio/20abde1548c7cbc7b364a6249f6601f2/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.
WARNING: /home/sio/.cache/bazel/_bazel_sio/20abde1548c7cbc7b364a6249f6601f2/external/re2/WORKSPACE:1: Workspace name in /home/sio/.cache/bazel/_bazel_sio/20abde1548c7cbc7b364a6249f6601f2/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
____Loading package: @re2//
____Loading package: @jsoncpp_git//
____Loading package: tensorflow/core/util/ctc
____Loading complete.  Analyzing...
____Found 1 target...
____Building...
____[0 / 1] BazelWorkspaceStatusAction stable-status.txt
____[34 / 351] Creating source manifest for //tensorflow/cc:tutorials_example_trainer
____[43 / 2,637] Creating source manifest for //tensorflow/cc:ops/array_ops_gen_cc [for host]
____[45 / 2,969] Executing genrule @boringssl_git//:err_data_c
____[46 / 2,973] Creating source manifest for //tensorflow/cc:ops/control_flow_ops_gen_cc [for host]
____[50 / 2,977] Compiling external/highwayhash/highwayhash/sip_hash.cc
____[50 / 2,977] Compiling external/jsoncpp_git/src/lib_json/json_reader.cpp
____[50 / 2,977] Executing genrule @farmhash_archive//:configure
**ERROR: /home/sio/.cache/bazel/_bazel_sio/20abde1548c7cbc7b364a6249f6601f2/external/highwayhash/BUILD:17:1: undeclared inclusion(s) in rule '@highwayhash//:sip_hash':
this rule is missing dependency declarations for the following files included by 'external/highwayhash/highwayhash/sip_hash.cc':**
  '/home/sio/usr/local/include/c++/4.9.3/cstddef'
  '/home/sio/usr/local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++config.h'
  '/home/sio/usr/local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/os_defines.h'
  '/home/sio/usr/local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/cpu_defines.h'
  '/home/sio/usr/local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stddef.h'
  '/home/sio/usr/local/include/c++/4.9.3/cstring'
  '/home/sio/usr/local/include/c++/4.9.3/memory'
  '/home/sio/usr/local/include/c++/4.9.3/bits/stl_algobase.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/functexcept.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/exception_defines.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/cpp_type_traits.h'
  '/home/sio/usr/local/include/c++/4.9.3/ext/type_traits.h'
  '/home/sio/usr/local/include/c++/4.9.3/ext/numeric_traits.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/stl_pair.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/move.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/concept_check.h'
  '/home/sio/usr/local/include/c++/4.9.3/type_traits'
  '/home/sio/usr/local/include/c++/4.9.3/bits/stl_iterator_base_types.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/stl_iterator_base_funcs.h'
  '/home/sio/usr/local/include/c++/4.9.3/debug/debug.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/stl_iterator.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/ptr_traits.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/predefined_ops.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/allocator.h'
  '/home/sio/usr/local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++allocator.h'
  '/home/sio/usr/local/include/c++/4.9.3/ext/new_allocator.h'
  '/home/sio/usr/local/include/c++/4.9.3/new'
  '/home/sio/usr/local/include/c++/4.9.3/exception'
  '/home/sio/usr/local/include/c++/4.9.3/bits/atomic_lockfree_defines.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/exception_ptr.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/nested_exception.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/memoryfwd.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/stl_construct.h'
  '/home/sio/usr/local/include/c++/4.9.3/ext/alloc_traits.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/alloc_traits.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/stl_uninitialized.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/stl_tempbuf.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/stl_raw_storage_iter.h'
  '/home/sio/usr/local/include/c++/4.9.3/typeinfo'
  '/home/sio/usr/local/include/c++/4.9.3/bits/hash_bytes.h'
  '/home/sio/usr/local/include/c++/4.9.3/iosfwd'
  '/home/sio/usr/local/include/c++/4.9.3/bits/stringfwd.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/postypes.h'
  '/home/sio/usr/local/include/c++/4.9.3/cwchar'
  '/home/sio/usr/local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stdarg.h'
  '/home/sio/usr/local/include/c++/4.9.3/ext/atomicity.h'
  '/home/sio/usr/local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/gthr.h'
  '/home/sio/usr/local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/gthr-default.h'
  '/home/sio/usr/local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/atomic_word.h'
  '/home/sio/usr/local/include/c++/4.9.3/ext/concurrence.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/stl_function.h'
  '/home/sio/usr/local/include/c++/4.9.3/backward/binders.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/uses_allocator.h'
  '/home/sio/usr/local/include/c++/4.9.3/functional'
  '/home/sio/usr/local/include/c++/4.9.3/tuple'
  '/home/sio/usr/local/include/c++/4.9.3/utility'
  '/home/sio/usr/local/include/c++/4.9.3/bits/stl_relops.h'
  '/home/sio/usr/local/include/c++/4.9.3/initializer_list'
  '/home/sio/usr/local/include/c++/4.9.3/array'
  '/home/sio/usr/local/include/c++/4.9.3/stdexcept'
  '/home/sio/usr/local/include/c++/4.9.3/string'
  '/home/sio/usr/local/include/c++/4.9.3/bits/char_traits.h'
  '/home/sio/usr/local/include/c++/4.9.3/cstdint'
  '/home/sio/usr/local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stdint.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/localefwd.h'
  '/home/sio/usr/local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++locale.h'
  '/home/sio/usr/local/include/c++/4.9.3/clocale'
  '/home/sio/usr/local/include/c++/4.9.3/cctype'
  '/home/sio/usr/local/include/c++/4.9.3/bits/ostream_insert.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/cxxabi_forced.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/range_access.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/basic_string.h'
  '/home/sio/usr/local/include/c++/4.9.3/ext/string_conversions.h'
  '/home/sio/usr/local/include/c++/4.9.3/cstdlib'
  '/home/sio/usr/local/include/c++/4.9.3/cstdio'
  '/home/sio/usr/local/include/c++/4.9.3/cerrno'
  '/home/sio/usr/local/include/c++/4.9.3/bits/functional_hash.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/basic_string.tcc'
  '/home/sio/usr/local/include/c++/4.9.3/bits/unique_ptr.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/shared_ptr.h'
  '/home/sio/usr/local/include/c++/4.9.3/bits/shared_ptr_base.h'
  '/home/sio/usr/local/include/c++/4.9.3/ext/aligned_buffer.h'
  '/home/sio/usr/local/include/c++/4.9.3/backward/auto_ptr.h'.
Target //tensorflow/cc:tutorials_example_trainer failed to build
____Elapsed time: 6.120s, Critical Path: 4.43s
"
2616,[New Feature] Dimension Validation for CNNs ,"In the deep MNIST samples for experts, the dimensions of the example network is defined as follows: 

[5, 5, 1, 32]
[5, 5, 32,64]
[7_7_64, 1024]
[1024, n_classes]

It seems nice for us to implement functions that checks a validity of given network, if we've not done yet. 

Example Error or Warning Messages:

1: u"" Dimension mismatch occurs at forward calculation from %s %s to %s %s: Input_dim=%s but Output_dim=%s  ""%( lower_component, lower_component,  upper_type, upper_name, Input_dim, Output_dim)

""lower_component"" and ""upper_componet"" are either function with out tf.Variable or anything with tf.Varriables.

1-a: u"" Dimension mismatch occurs at forward calculations from linear-layer ""first-linear"" to linear-layer ""out"": Input_dim=1024 but Output_dim=1023"", if 

```
'first-linear': tf.Variable(tf.random_normal([7*7*64, 1024])), 
'out': tf.Variable(tf.random_normal([1023, n_classes])) 
```

2: u"" Dimension mismatch occurs at forward calculation:  Input_dim=%s  of %s %s is not divided by %s*%s, Note that output of %s %s reduce dimension from %s to %s ""%(Input_dim, lower_type, lower_name, out_width, out_height,  lower_type,  lower_name, Input_dim, Output_dim)

2-a u"" Dimension mismatch occurs at forward calculation:  Input_dim=2048  of linear-layer ""wd1"" is not divided by 7*7, Note that output of function ""max_pool"" reduces dimension from 196 to 49 ""

3: u"" Dimension mismatch occurs at forward calculation: At the conv-layer %s, for given weight of W2 =(W1-F+2P)/S+1 isn't an integer, where width W1=%s, F=%s, P=%s, S=%S  ""%(conv_layer_name, filter_size, padding, strides)
"
2614,CUDA 8.0 support,"NVidia CUDA 7.5 distribution for Ubuntu only goes up to Ubuntu 15.04 which is EOL'ed already. So it would be useful to have CUDA 8.0 support which is provided for Ubuntu 16.04
"
2610,per_process_gpu_memory_fraction=1 does not allocate all of the memory,"Seeing this on TF 0.8 with a Titan X. If I don't specify gpu_options at all, the memory allocated to TF is 11736MB. If I set per_process_gpu_memory_fraction=1.0, I only get 11127MB allocated. It's a small difference, but enough to make my large model crash, while the default allocations lets it just squeak in.
"
2609,Feed Cifar10 tutorial with an external image (jpg/png) 32x32 image get label as output,"Hello,

I am trying to use the trained machine based on the Cifar10 tutorial and would like to feed
it with an external image 32x32 (jpg or png). My goal is to be able to get the label as an output.
In other words, I want to feed the Network with a jpeg image of size 32 x 32 with no label as an input and have the inference process give methe tf.argmax(logits, 1). 

I have been trying to do that based on the CIfar10 Tutorial and unfortunately always have issues. especially with the Session concept and the batch concept.

here is the implemented code so far:

``` python

#!/usr/bin/env python

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from datetime import datetime
import math
import time

import tensorflow.python.platform
from tensorflow.python.platform import gfile
import numpy as np
import tensorflow as tf

import cifar10
import cifar10_input
import os
import faultnet_flags
from PIL import Image

FLAGS = tf.app.flags.FLAGS

def evaluate():

  filename_queue = tf.train.string_input_producer(['/home/tensor/.../inputImage.jpg'])

  reader = tf.WholeFileReader()
  key, value = reader.read(filename_queue)

  input_img = tf.image.decode_jpeg(value)

  init_op = tf.initialize_all_variables()

# Problem in here with Graph / session
  with tf.Session() as sess:
    sess.run(init_op)

    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)

    for i in range(1): 
      image = input_img.eval()

    print(image.shape)
    Image.fromarray(np.asarray(image)).show()

# Problem in here is that I have only one image as input and have no label and would like to have
# it compatible with the Cifar10 network
    reshaped_image = tf.cast(image, tf.float32)
    height = FLAGS.resized_image_size
    width = FLAGS.resized_image_size
    resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image, width, height)
    float_image = tf.image.per_image_whitening(resized_image)  # reshaped_image
    num_preprocess_threads = 1
    images = tf.train.batch(
      [float_image],
      batch_size=128,
      num_threads=num_preprocess_threads,
      capacity=128)
    coord.request_stop()
    coord.join(threads)

    logits = faultnet.inference(images)

    # Calculate predictions.
    #top_k_predict_op = tf.argmax(logits, 1)

    # print('Current image is: ')
    # print(top_k_predict_op[0])

    my_classification = sess.run(tf.argmax(logits, 1))

    print ('Predicted ', my_classification[0], "" for your input image."")


def main(argv=None):
  evaluate()

if __name__ == '__main__':
  tf.app.run()
```

Thank your for your help.
N.
"
2607,latest TensorBoard broken in Safari,"Since about a week now there seems something wrong with the TensorBoard demo at https://www.tensorflow.org/tensorboard/index.html#events. The graph shows nicely, but neither events nor histograms show up. This problem seems to be only with the demo -- everything shows up just fine when I run the corresponding code (`mnist_tensorboard.py`) locally.
"
2606,skflow  multiple_gpu.py error,"When I execute python multiple_gpu.py I get following error. I have verified that my installation has cudnn v7 and cuda ( since I can run the translate.py example on gpu)

tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'logistic_regression/HistogramSummary_3/tag': Could not satisfy explicit device specification
 '/device:GPU:1' because no supported kernel for GPU devices is available
         [[Node: logistic_regression/HistogramSummary_3/tag = Const[dtype=DT_STRING, value=Tensor<type: string shape: [] values: logistic_regression.bias>, _device=""/device:GPU:1""]()]]
Caused by op u'logistic_regression/HistogramSummary_3/tag', defined at:
  File ""multiple_gpu.py"", line 39, in <module>
    classifier.fit(X_train, y_train)
  File ""/home/ubuntu/anaconda2/envs/tf/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 242, in fit
"
2605,Feature request: space_to_depth with overlapping blocks (like im2col),"Currently [tf.space_to_depth](https://www.tensorflow.org/versions/r0.7/api_docs/python/array_ops.html#space_to_depth) only works for rearranging non-overlapping blocks into depth. It would be nice if also worked for overlapping blocks, with an extra parameter to set the stride:
- A stride equal to the block size would be equivalent to the current non-overlapping behavior.
- A stride equal to 1 would be equivalent to an im2col operation.

An im2col-like operation could be used to easily implement a locally connected layer (""convolution with unshared weights""), by combining it with an elementwise multiplication with the matrix that contains the local filters, followed by a summation along the channel dimension.
"
2604,Result of tf.reshape() with dynamic shape does not work with tf.train.shuffle_batch(),"I wrote the images into TensorFlow format file, but when I read it like this: 

``` python
features = tf.parse_single_example(
            serialized_example,
            features = {
                'height': tf.FixedLenFeature([], tf.int64),
                'width': tf.FixedLenFeature([], tf.int64),
                'channel': tf.FixedLenFeature([], tf.int64),
                'image': tf.FixedLenFeature([], tf.string),
                'gt': tf.FixedLenFeature([], tf.string),
            })

```

first, the data has no shape infomation, only the batch size, so I reshape it, but parameter shape of tf.reshape() only support list of integers, not a tensor, I don't know why?

second, the data of gt is list, maybe length(gt) > 2, because no shape information, so I can't unpack it

so, why is not shape information available
"
2603,Feature request: Tensorboard streaming,"The new Tensorboard refresh button looks great, and will certainly be a bit more civilized than rapidly swapping the horizontal axis view to update the data. :)

But what if Tensorboard could be optionally updated in real time, whenever a summary writer was flushed? I've written systems before where past data is loaded along with the page, and new data is added continuously via a web socket. Would this work in Tensorboard's current architecture?

If my understanding is correct, Tensorboard currently updates itself every 120 seconds by reading the event files in the log directory. Could Tensorboard also open a local socket and bounce summary updates from a connected Tensorflow process to websocket clients?

I was thinking of hacking a streaming system together on my branch, but I figured I should reach out first to see if this is already in the roadmap. If it isn't, is this feature something you might like to merge if I can get it to work robustly?
"
2602,tensorboard server: base_url support,"### What have you tried?

Running the tensorboard service through a proxy server, which does map a subdirectory to the tensorboard server' root.
### Desired outcome

By providing a way to specify a `base_url`, the server would understand how to treat incoming requests in such a situation. e.g. `://server/subdir/tensorboard/`  `://server/`
"
2600,Support python 3.x based Tensorflow in docker image,"I'm trying to use tensorflow on Docker environment, and it turns out that tensorflow package is missing in python 3.4 dist-package in official docker image. Is there any reason for not supporting it?
"
2599,DaskDataFeeder ignores shuffle argument,"The shuffle argument should not be ignore, because it is confusing to users of the feeder.
"
2598,Hessian (calling tf.gradients twice) of tf.scan fails,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Mac OS X 10.11.2

Installed version of CUDA and cuDNN: None

If installed from sources, provide the commit hash:

4455f81c3dc07a77ac133dec24690968e121370a
### Steps to reproduce

Run the following script:

``` python
import tensorflow as tf

theta = tf.Variable(initial_value=1.)


def fn(x, prev):
    return prev + x * theta

result = tf.scan(fn, [1., 2., 3.])

grad_theta = tf.gradients(result, theta)

tf.gradients(grad_theta, theta)
```

will result in the following error:

```
Traceback (most recent call last):
  File ""sandbox/rocky/tf/small_example.py"", line 13, in <module>
    tf.gradients(grad_theta, theta)
  File ""/Users/dementrock/anaconda/envs/rllab/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 379, in gradients
    to_ops, from_ops)
  File ""/Users/dementrock/anaconda/envs/rllab/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 185, in _PendingCount
    between_ops)
  File ""/Users/dementrock/anaconda/envs/rllab/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 874, in MaybeCreateControlFlowState
    loop_state.AddWhileContext(op, between_op_list, between_ops)
  File ""/Users/dementrock/anaconda/envs/rllab/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 738, in AddWhileContext
    for loop_exit in forward_ctxt.loop_exits:
TypeError: 'NoneType' object is not iterable
```
### What have you tried?

Nothing beyond creating this minimal reproducible example
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2597,Odd crash in Android demo,"### Environment info

Android Demo from 57658eddfab7763058c5316b1af41e77b1bb3b17

I've been trying to build an image classifier for android, and I ran into this exception in the TensorflowClassifier class.

I haven't run into this before despite playing with this for a few days, but I added some logging and will upload more details if I can repro it.

Not sure if anyone cares, but I thought I might as well capture this.
### Logs or other output that would be helpful

Caused by: java.lang.NumberFormatException: Invalid float: ""Android""
   at java.lang.StringToReal.invalidReal(StringToReal.java:63)
   at java.lang.StringToReal.initialParse(StringToReal.java:164)
   at java.lang.StringToReal.parseFloat(StringToReal.java:323)
   at java.lang.Float.parseFloat(Float.java:306)
   at org.tensorflow.demo.TensorflowClassifier.recognizeImage(TensorflowClassifier.java:51)

FWIW the line number in recognizeImage is wrong since I've made changes to the file, but shouldn't have caused this.

[EDIT]: I found that the log message I was getting was ""Android system is not using RGBA_8888 in default"", I guess I'll see what that's about.
"
2596,Udacity readme docker command should not remove container,"The Udacity readme at 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/README.md
suggests starting Docker like this:

`docker run -p 8888:8888 -it --rm b.gcr.io/tensorflow-udacity/assignments:0.5.0`

The `--rm` causes the container to get removed once you end the session, which deletes all your progress so far in the class. It would be better to not suggest `--rm` so that the docker container can then be resumed at a later time.
"
2594,add tf.assert for GPU (maybe also host-memory Const[string] for GPU) was: dynamic_rnn GPU support error ,"When attempting to place dynamic_rnn on the gpu, I get the following error:

```
tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'RNN/Assert/data_2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available
         [[Node: RNN/Assert/data_2 = Const[dtype=DT_STRING, value=Tensor<type: string shape: [] values:  but saw shape: >, _device=""/device:GPU:0""]()]]
```

Full traceback:

```
Traceback (most recent call last):
  File ""test_model2_parallel_buffered.py"", line 84, in <module>
    sess.run(init_op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 333, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 573, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 648, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 668, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'RNN/Assert/data_2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available
         [[Node: RNN/Assert/data_2 = Const[dtype=DT_STRING, value=Tensor<type: string shape: [] values:  but saw shape: >, _device=""/device:GPU:0""]()]]
Caused by op u'RNN/Assert/data_2', defined at:
  File ""test_model2_parallel_buffered.py"", line 47, in <module>
    tower_logits_t = model.inference(frames_t, seq_length_t, BATCH_SIZE)
  File ""/home/woodward/ml/football_plays/model2.py"", line 73, in inference
    _, rnn_state_final_t = tf.nn.dynamic_rnn(rnn_cell, rnn_inputs_t, sequence_length=seq_length_t, initial_state=rnn_initial_state_t, swap_memory=True, time_major=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py"", line 567, in dynamic_rnn
    [_assert_has_shape(sequence_length, [batch_size])]):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py"", line 562, in _assert_has_shape
    packed_shape, "" but saw shape: "", x_shape])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/logging_ops.py"", line 58, in Assert
    return gen_logging_ops._assert(condition, data, summarize, name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_logging_ops.py"", line 37, in _assert
    summarize=summarize, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 410, in apply_op
    as_ref=input_arg.is_ref)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 664, in convert_n_to_tensor
    ret.append(convert_to_tensor(value, dtype=dtype, name=n, as_ref=as_ref))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 620, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.py"", line 179, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.py"", line 166, in constant
    attrs={""value"": tensor_value, ""dtype"": dtype_value}, name=name).outputs[0]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1224, in __init__
    self._traceback = _extract_stack()
```

It seems to have some problem with a tensor shape, but I can't deduce why. This error does not occur if I enclose the tf.nn.dynamic_rnn(...) call in a tf.device('/cpu:0') statement. I am on commit 0050a205bc5521a563ee66baa3b73373d4c0e62e from mid last week.

I am doing data parallel processing and am trying to keep as much as possible on each GPU.
"
2591,"TensorFlow ""Development"" Build Issue","I just built Tensorflow from the most recent source (81db154), and attempted to set it up for a ""development"" install - using `python setup.py develop` after following the instructions in the [documentation](https://www.tensorflow.org/versions/master/get_started/os_setup.html#setting-up-tensorflow-for-development). After doing this, running `import tensorflow` in Python results in a ""package not found"" error. 

I have found that changing the line in the documentation 

```
ln -s ../bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow* .
```

to

```
ln -s ../bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/* .
```

solves the problem (the difference is an extra backtick near the end of the line). Perhaps this was a typo?
"
2589,Request for Schedule learning rate at arbitrary step(echo),"There is only tf.train.exponential_decay for decaying the learning rate at constant step.

However in **ResNet-1001**: ""Identity Mappings in Deep Residual Networks"", arXiv:1603.05027, 2016,
**The learning rate starts from 0.1, and is divided by 10 at 32k and 48k iterations.**
Following [1], for all CIFAR experiments we warm up then training by using a smaller learning rate of 0.01 at the beginning 400 iterations and go back to 0.1 after that.

It's hard to implement in tensor flow since tensor doesnt support python comparison.
The learning rate cant be set in if/else according to global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)
"
2588,Rename atrous_conv2d to dilated_conv2d?,"The name comes from French "" trous"" so it seems there should be an extra underscore in there at least... but this is still unintelligible to non-french speakers. Better would be to use the English word 'dilated'.
"
2587,session_ops should not place Placeholder(<string>) onto GPU,"TLDR; session ops should be changed to always place string handle Placeholder on CPU. Currently it places it on the same device as corresponding `GetSessionTensor` op, which fails when data lives on GPU.

Session ops like `get_session_tensor` consist of string `Placeholder` and `GetSessionTensor` ops. They are created with tf.device(None), and then moved to the same device as the input handle. If input_handle represents tensor on GPU, it will try to move both `Placeholder` and `GetSessionTensor` on the GPU.
However, since there's no implementation of string Placeholder on GPU, this fails with `Could not satisfy explicit device specification`. Since `Placeholder` is meant for reading string through `feed_dict`, the data comes from CPU originally, and there's no performance benefit in using GPU implementation of string placeholder, so it should be pinned to CPU.

Test below fails with `InvalidArgumentError: Cannot assign a device to node 'Placeholder_1': Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.`

```
import tensorflow as tf

class HandleTest(tf.test.TestCase):

  def testHandle(self):
    config = tf.ConfigProto(log_device_placement=True)
    with self.test_session(config=config) as sess:
      dtype=tf.float32
      with tf.device(""/gpu:0""):
        a = tf.constant(1, dtype)

      a_handle = sess.run(tf.get_session_handle(a))
      b_holder, b_tensor = tf.get_session_tensor(dtype)
      print(sess.run(b_tensor, feed_dict={b_holder:
                                          a_handle.handle}))


if __name__ == ""__main__"":
  tf.test.main()

```

@yuanbyu 
"
2586,Persistent tensors get placed onto GPU unexpectedly,"Running `get_session_handle` ops seems to affect where subsequent `get_session_tensor` is placed.
The following fails when built with `config=cuda` with

```
E tensorflow/stream_executor/cuda/cuda_driver.cc:1239] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE; host dst: 0x208a00000; GPU src: 0x1b1a4a0; size: 4=0x4
F tensorflow/core/common_runtime/gpu/gpu_util.cc:296] GPU->CPU Memcpy failed

```

Looking at device placement, it seems that `GetSessionTensor` ops are placed on GPU. Changing `failure_case` to `False` makes the test below pass as everything is placed on CPU as expected.

```
import tensorflow as tf                                                         

class HandleTest(tf.test.TestCase):                                             

  def testHandle(self):                                                         
    with self.test_session() as sess:                                           
      a = tf.constant(1.0)                                                      
      a_handle_op = tf.get_session_handle(a)                                    
      b = tf.constant(2.0)                                                      
      b_handle_op = tf.get_session_handle(b)                                    

      failure_case = True                                                       
      if failure_case:                                                          
        a_p, a_t = tf.get_session_tensor(tf.float32)                            
        b_p, b_t = tf.get_session_tensor(tf.float32)                            
        a_handle = sess.run(a_handle_op)                                        
        b_handle = sess.run(b_handle_op)                                        
      else:                                                                     
        a_handle = sess.run(a_handle_op)                                        
        b_handle = sess.run(b_handle_op)                                        
        a_p, a_t = tf.get_session_tensor(tf.float32)                            
        b_p, b_t = tf.get_session_tensor(tf.float32)                            

      c = tf.add(a_t, b_t)                                                      
      c_handle = sess.run(                                                      
        tf.get_session_handle(c),                                               
        feed_dict={a_p: a_handle.handle,                                        
                   b_p: b_handle.handle})                                       
      self.assertEqual(3.0, c_handle.eval())                                    


if __name__ == ""__main__"":                                                      
  tf.test.main()                                                                

```
"
2584,Why tf.image.decode_jpeg is slower than cv2.imread ?,
2583,On the return values of bidirectional_rnn,"Due to the overhead of `tf.concat` operations, it is recommended to use `state_is_tuple` flag in recurrent neural network layers.
However, I found that in `bidirectional_rnn` implementation, `outputs` (first return value) is returned as a concatenation of `outputs_fw` and `outputs_bw`.
Is there any reason that it should return the concatenated one?
I think it is trace of the days where concatenated states are used, and it would be nice to return forward and backward outputs separately.
It seems that it can be implemented simply without breaking backward compatibility, by adding a flag indicating what should be returned.
"
2577,Support complex numbers in Tensor Transformation Operations,"A number of changes have been made to support complex128, but the the tensor transformation op suite seems to be missing this support (At least in tf.pack and tf.concat). See the example script below which works for float32 and float64, but not complex64 and complex128.
### Environment info

Operating System: Ubuntu 14.04.4

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

``` bash
$ ls -l /usr/local/cuda-7.5/lib64/libcud*
-rw-r--r-- 1 root root    322936 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root        19 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root    383336 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root    720192 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
lrwxrwxrwx 1 3319 users       13 Feb  9 19:48 /usr/local/cuda-7.5/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 3319 users       17 Feb  9 19:48 /usr/local/cuda-7.5/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxrwxr-x 1 3319 users 61453024 Feb  9 00:12 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7
-rw-rw-r-- 1 3319 users 62025862 Feb  9 00:12 /usr/local/cuda-7.5/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed. **Python 2 GPU nightly**
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"". **0.8.0**

If installed from sources, provide the commit hash:
### Steps to reproduce
1. Vary **dtype** in the following test script between `float32, float64, complex64, complex128`
   
   ``` python
   import numpy as np
   import tensorflow as tf
   
   # Data type for this test case
   dtype=np.float64
   
   # Array shapes
   shape=(10,20,30,1)
   # Expected concatenated array shape
   cshape=(10,20,30,4)
   
   # Helpful lambda
   rn = lambda s, d: tf.random_normal(shape=s, dtype=d)
   
   # Produce random arrays of shape depending on the type
   def r(shape, dtype):
       if dtype in (np.float32, np.float64):
           return rn(shape, dtype)
       elif dtype == np.complex64:
           return tf.complex(rn(shape, np.float32), rn(shape, np.float32))
       elif dtype == np.complex128:
           return tf.complex(rn(shape, np.float64), rn(shape, np.float64))
       else:
           raise ValueError(""Unhandled dtype '{dt}'"".format(dt=dtype))
   
   XX = r(shape, dtype)
   XY = r(shape, dtype)
   YX = r(shape, dtype)
   YY = r(shape, dtype)
   
   with tf.device('/gpu:0'):
       concat = tf.concat(3, [XX, XY, YX, YY],)
   
   with tf.Session() as S:
       result = S.run(concat)
       assert result.shape == cshape
   ```
2. If dtype is `np.complex64` of `np.complex128`, the following is thrown:
   
   ``` python
   tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'concat': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
        [[Node: concat = Concat[N=4, T=DT_COMPLEX64, _device=""/device:GPU:0""](concat/concat_dim, Complex, Complex_1, Complex_2, Complex_3)]]
   Caused by op u'concat', defined at:
     File ""tmp/concat_fail.py"", line 32, in <module>
       concat = tf.concat(3, [XX, XY, YX, YY],)
   ```
### What have you tried?

N/A
"
2576,compile error,"### What have you tried?
1. bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

I've got these errors.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
[2,065 / 2,589] Linking tensorflow/core/kernels/libcast_op.pic.lo
INFO: From Compiling tensorflow/core/kernels/batch_matmul_op.cc:
In file included from external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/CXX11Meta.h:14:0,
                 from external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/Tensor:18,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from tensorflow/core/kernels/batch_matmul_op.cc:21:
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void tensorflow::LaunchBatchMatMul<Eigen::ThreadPoolDevice, Scalar>::Run(In, In, bool, bool, Out, int, int) [with In = Eigen::TensorMap<Eigen::Tensor<const std::complex<double>, 3, 1, long int>, 16>; Out = Eigen::TensorMapEigen::Tensor<std::complex<double, 3, 1, long int>, 16>; Scalar = std::complex<double>]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 3, 1, long int>, 16> >, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1ul>, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<std::complex<float >, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 3, 1, long int>, 16> > >, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 3, 1, long int>, 16> > > >]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 3, 1, long int>, 16> >, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1ul>, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 3, 1, long int>, 16> >, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<std::complex<float >, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 3, 1, long int>, 16> > > > >]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 3, 1, long int>, 16> >, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1ul>, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<std::complex<float >, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 3, 1, long int>, 16> > >, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<std::complex<float >, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 3, 1, long int>, 16> > > > >]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void tensorflow::LaunchBatchMatMul<Eigen::ThreadPoolDevice, Scalar>::Run(In, In, bool, bool, Out, int, int) [with In = Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 3, 1, long int>, 16>; Out = Eigen::TensorMapEigen::Tensor<std::complex<float, 3, 1, long int>, 16>; Scalar = std::complex<float>]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<int, 3, 1, long int>, 16> >, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1ul>, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<int, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const int, 3, 1, long int>, 16> > >, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const int, 3, 1, long int>, 16> > > >]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<int, 3, 1, long int>, 16> >, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1ul>, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const int, 3, 1, long int>, 16> >, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<int, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const int, 3, 1, long int>, 16> > > > >]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<int, 3, 1, long int>, 16> >, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1ul>, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<int, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const int, 3, 1, long int>, 16> > >, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<int, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const int, 3, 1, long int>, 16> > > > >]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void tensorflow::LaunchBatchMatMul<Eigen::ThreadPoolDevice, Scalar>::Run(In, In, bool, bool, Out, int, int) [with In = Eigen::TensorMap<Eigen::Tensor<const int, 3, 1, long int>, 16>; Out = Eigen::TensorMap<Eigen::Tensor<int, 3, 1, long int>, 16>; Scalar = int]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<double, 3, 1, long int>, 16> >, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1ul>, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<double, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const double, 3, 1, long int>, 16> > >, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const double, 3, 1, long int>, 16> > > >]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<double, 3, 1, long int>, 16> >, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1ul>, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const double, 3, 1, long int>, 16> >, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<double, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const double, 3, 1, long int>, 16> > > > >]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<double, 3, 1, long int>, 16> >, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1ul>, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<double, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const double, 3, 1, long int>, 16> > >, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<double, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const double, 3, 1, long int>, 16> > > > >]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void tensorflow::LaunchBatchMatMul<Eigen::ThreadPoolDevice, Scalar>::Run(In, In, bool, bool, Out, int, int) [with In = Eigen::TensorMap<Eigen::Tensor<const double, 3, 1, long int>, 16>; Out = Eigen::TensorMap<Eigen::Tensor<double, 3, 1, long int>, 16>; Scalar = double]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<float, 3, 1, long int>, 16> >, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1ul>, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<float, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const float, 3, 1, long int>, 16> > >, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const float, 3, 1, long int>, 16> > > >]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<float, 3, 1, long int>, 16> >, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1ul>, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const float, 3, 1, long int>, 16> >, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<float, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const float, 3, 1, long int>, 16> > > > >]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<0l, Eigen::TensorMap<Eigen::Tensor<float, 3, 1, long int>, 16> >, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1ul>, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<float, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const float, 3, 1, long int>, 16> > >, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_conjugate_op<float, const Eigen::TensorChippingOp<0l, const Eigen::TensorMap<Eigen::Tensor<const float, 3, 1, long int>, 16> > > > >]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h: In static member function 'static void tensorflow::LaunchBatchMatMul<Eigen::ThreadPoolDevice, Scalar>::Run(In, In, bool, bool, Out, int, int) [with In = Eigen::TensorMap<Eigen::Tensor<const float, 3, 1, long int>, 16>; Out = Eigen::TensorMap<Eigen::Tensor<float, 3, 1, long int>, 16>; Scalar = float]':
external/eigen_archive/eigen-eigen-f3a13643ac1f/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:67: warning: array subscript is above array bounds [-Warray-bounds]
   EIGEN_STRONG_INLINE T& operator[](size_t index) { return values[index]; }
                                                                   ^
ERROR: /home/suzuki/tensorflow/tensorflow/core/kernels/BUILD:296:1: C++ compilation of rule '//tensorflow/core/kernels:pad_op' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 ... (remaining 111 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See file:///usr/share/doc/gcc-4.8/README.Bugs for instructions.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
"
2575,while loop endless loop,"### Environment info

Operating System: CentOS 7

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CPU version

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

0.8.0
### Steps to reproduce

I am using TensorFlow to implement a network that needs to use `tf.while_loop()`

```
import tensorflow as tf
import numpy as np
class model(object):
    def __init__(self):
        self.argmax_ep_gate_array = [ tf.placeholder(tf.int32, [None]) for _ in range(10)]
        argmax_ep_gate_array_concat = tf.concat(0, self.argmax_ep_gate_array)
        story_len = tf.constant(7)
        starter = tf.constant(0)
        z = []
        def body(hops):
            hops = tf.add(hops,1)
            z.append(hops)
            return hops
        def condition(hops):
            return tf.logical_and(tf.less(tf.gather(argmax_ep_gate_array_concat, hops),story_len),tf.less(hops,tf.constant(20)))

        self.gate_index = tf.while_loop(condition,body,[starter])
        self.z=tf.concat(0,z)

    def step(self, sess):
        feed={}
        for i in range(10):
            feed[self.argmax_ep_gate_array[i].name]=[i]
        print (sess.run([self.gate_index,self.z],feed))
with tf.Session() as sess:
    while_loop = model()
    sess.run(tf.initialize_all_variables())
    while_loop.step(sess)

```
### What have you tried?

I find that If I want to sess.run() any variable in the body() that is not returned, tensorflow would stuck into endless loop. 
The above example is trivial, but it reveals something. In the real case, I am using `tf.while_loop()` running a RNN which includes y= wx+b something like that, but the `w` and `b` are not returned after while loop. In the forward network, it works fine. However, if I run the back propagation, the program would stuck into endless loop. I suppose the code above reproducing my issue, because back propagation do need to modify `w` and `b`. Or is there any way to handle this issue? 
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
No logs, Just stuck into endless loop
"
2573,avg/max_pool3d description has a bug.,"In file:
[tensorflow/g3doc/api_docs/python/functions_and_classes/shard0/tf.nn.avg_pool3d.md
](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard0/tf.nn.avg_pool3d.md)
[tensorflow/g3doc/api_docs/python/functions_and_classes/shard4/tf.nn.max_pool3d.md
](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard4/tf.nn.max_pool3d.md)
Original:
<b>`ksize`</b>: A list of `ints` that has length `>= 5`.
    1-D tensor of length 5. The size of the window for each dimension of
    the input tensor. Must have `ksize[0] = ksize[1] = 1`.

I think
`ksize[0] = ksize[1] = 1`. should change to `ksize[0] = ksize[4] = 1`, according to the test file https://github.com/tensorflow/tensorflow/blob/712e41cf8b316ef2c33c6dd7fd6ade2b4e93ddc0/tensorflow/python/kernel_tests/pooling_ops_3d_test.py#L48
"
2572,freeze_graph gives Unexpected EOF from Bazel server (Scikit Flow) or gcc internal compiler error,"I can't get the hang of exporting a scikit flow model to a model.pb file to use it with android.
### Environment info

Operating System:16.04 LTS

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
No such file or directory

If installed from binary pip package, provide:
1. Which pip package you installed. -?
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   0.8.0
### Steps to reproduce
1. classifier.save('model/')
2. copy contents of model folder to tensorflow root
3. cd tensorflow && bazel build tensorflow/python/tools:freeze_graph && bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=graph.pbtxt --input_checkpoint=checkpoint --output_graph=/tmp/frozen_graph.pb --output_node_names=softmax --jobs 4 --verbose_failures > output.txt  2>&1

-> should compile a *.pb file from the *.pbtxt file. bazel build tensorflow/python/tools:freeze_graph fails already.

Result after a while of compiling:
Unexpected EOF from Bazel server or gcc internal compiler error
### What have you tried?
1. bazel clean -> only takes longer
2. adding RAM and increasing RAM of VM (11GB of 16GB)
3. --jobs 4
### Logs or other output that would be helpful

![bazel](https://cloud.githubusercontent.com/assets/10122382/15635531/ce333328-25e0-11e6-8b4d-4e753f0d47a5.PNG)
Traceback (most recent call last):
  File ""/home/administrator/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/tensorflow/python/tools/freeze_graph.py"", line 40, in <module>
    import tensorflow as tf
  File ""/home/administrator/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/tensorflow/**init**.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/home/administrator/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/tensorflow/python/**init**.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/administrator/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/home/administrator/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/tensorflow/python/pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ImportError: No module named _pywrap_tensorflow
"
2571,"_pywrap_tensorflow.so: Undefined symbol ""_ZN9perftools8gputools3rng10RngSupport13kMinSeedBytesE""","Hello,

I am trying to bring TensorFlow support to FreeBSD. Considering there is Mac support, I figured FreeBSD support couldn't be too bad to work on. I have hit a few snags along the way but nothing show stopping yet. My latest problem is I'm getting an undefined symbol error. I do not want gpu support for the FreeBSD port, but I can see ::perftools::gputools are scattered all throughout the source code. If you could give me any feedback as to what to look into to fix this, that'd be great.
### Environment info

Operating System: FreeBSD 10.3
Installed version of CUDA and cuDNN: None

If installed from sources, provide the commit hash: d8eb4bb6470d4cb3d0f67f2111a39fa50f1c28e5
### Steps to reproduce
1. Build TensorFlow on FreeBSD 10.3 with Clang 3.8
2. Try to import tensorflow in Python3 REPL
### Things I've tried

I also tried this with Python 2. Same results.
### Logs or other output that would be helpful

```
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.4/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python3.4/site-packages/tensorflow/python/__init__.py"", line 48, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python3.4/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/usr/local/lib/python3.4/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
  File ""/usr/local/lib/python3.4/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
ImportError: /usr/local/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so: Undefined symbol ""_ZN9perftools8gputools3rng10RngSupport13kMinSeedBytesE""
```
"
2570,Adding DecodeJpeg Op to Android results in build errors (jpeg-9a is missing),"I tried to add the jpeg libraries to the Android build so that I could easily use the model I trained using the transfer learning example, after adding the decode_jpeg_op.cc and removing the jpeg exclude from the android core libraries I ran into issues with the jpeg-9a includes from this file not being anywhere in the repo:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/jpeg.h#L26

I'm not sure if this library being missing is just an oversight or whether this is unsupported at the moment. I can probably deal with it not being there by stripping that node out of my graph, it just seems to be a random sharp edge
"
2568,question-words.txt link broken for word2vec,"The link for the word2vec analogy-question text file is borken:
[https://word2vec.googlecode.com/svn/trunk/questions-words.txt](https://word2vec.googlecode.com/svn/trunk/questions-words.txt)
"
2566,Android Example utils fail on models > 64MB,"I've been trying to get started with tensorflow and I wanted to use an image recognition model I trained in the android example, but when I tried to replace the models in the example with my model, it would crash without a lot of information.

I finally figure out that ReadFileToProto in jni_utils.cc does not support reading files larger than 64MB: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/jni/jni_utils.cc#L107

Adding these lines seemed to fix the issue of not being able to load my graph at all:

```
::google::protobuf::io::CodedInputStream coded_stream(&adaptor);
coded_stream.SetTotalBytesLimit(1024LL << 20, 512LL << 20);

coded_stream.Skip(start);
CHECK(message->ParseFromCodedStream(&coded_stream));
```

I'm probably not the first to stumble into this problem, but I feel like I just wasted hours of my life on a trivially avoidable problem and I hope no-one else has to waste time on that little bit of protobuf trivia.
"
2565,examples/skflow/out_of_core_data_classification.py dose not work,"/usr/bin/python2.7 /home/sun/tensorflow/tensorflow/examples/skflow/out_of_core_data_classification.py
Traceback (most recent call last):
  File ""/home/sun/tensorflow/tensorflow/examples/skflow/out_of_core_data_classification.py"", line 47, in <module>
    classifier.fit(X_train, y_train)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 168, in fit
    x, y, n_classes=self.n_classes, batch_size=self.batch_size)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py"", line 116, in setup_train_data_feeder
    X, y, n_classes, batch_size, shuffle=shuffle, epochs=epochs)
TypeError: **init**() got an unexpected keyword argument 'epochs'

Process finished with exit code 1
"
2560,New Feature: 4D Tensor Input for LSTM RNN Neural Network,"Currently TF RNN LSTM accepts this tensor rank:   (ht, mt)  of rank 1

```
 (ht_o, mt_o) = LSTM(ht, mt, W)
 with   ht size is (1 to d)   ,  same for mt
```

Would it be possible to accept rank 2 or rank 3 for the input state of RNN LSTM
    ht size  (1 to m, 1 to s, 1 to d)      : Rank 3 

It would allows Multi-dimensionnal input such as :
    Input  size  (NSample, Mtype, Nchar, Nsequence) 

Especially, it makes sense for Grid LSTM.
"
2559,Need binary release with CUDA 8.0 support,"https://developer.nvidia.com/cuda-release-candidate-download
"
2554,Virtualenv installation failure,"Environment info
Operating System: OS X 10.10.3

We followed the ""Download and Setup"" docs and tried to create a Virtualenv environment in the directory ~/tensorflow but it didn't work well.

```
$ virtualenv --system-site-packages ~/tensorflow

Using base prefix '/Applications/Canopy.app/appdata/canopy-1.7.2.3327.macosx-x86_64/Canopy.app/Contents'
New python executable in /Users/xxx/tensorflow/tensorflow/bin/python
dyld: Library not loaded: @rpath/Python
  Referenced from: /Users/xxx/tensorflow/tensorflow/bin/python
  Reason: no suitable image found.  Did find:
    /Users/xxx/tensorflow/tensorflow/bin/../Python: not a file
ERROR: The executable /Users/xxx/tensorflow/tensorflow/bin/python is not functioning
ERROR: It thinks sys.prefix is u'/Users/xxx/tensorflow' (should be u'/Users/xxx/tensorflow/tensorflow')
ERROR: virtualenv is not compatible with this system or executable
```

In my execution environment, -p option is needed as below.

```
  $ virtualenv --system-site-packages -p /Library/Frameworks/Python.framework/Versions/3.5/bin/python3 ~/tensorflow
```

I think the result of the above command is influenced by the execution environment, so please add the -p option.
"
2553,Add support for circle_ci or travis upon pull request. ,"It would be good to have an automatic and simple first continuous integration rule that will run when a pull request is submitted/updated. We could leverage some of the free services out there to handle this task. I presume both the compilation and the testing will be quite slow but it will provide a first line of filtering. The commands would be the same as in the ci_build so no active maintenance should be required. 
"
2552,Is it possible to calculate two kinds of gradient separately in tensorflow,"```
w_1   = tf.get_variable(""w_1"", shape)   
w_2   = tf.get_variable(""w_2"", shape) 
output = tf.mul(w_1, w_2)
.....
.....
optimizer = tf.train.AdamOptimizer(alpha).minimize(self.cost)
```

As we know, when we run ""optimizer"", tensorflow will caculate gradient and update w_1 & w_2.

But what i want to do is, first, I want to **treat w_1 as a constant**, I just want to caculate gradient and update **only w_2**. Second, **treat w_2 as a constant** and caculate gradient and update **only w_1**. I want to **take turns** to do these things. 

Actually, I have seen this  #before: #834. But I use **BasicLSTMCell** module.  I try this code: `print (tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))`, it shows there are **four** kinds of parameter in my neural network, **which means besides w_1 and w_2, there are other two parameters in  BasicLSTMCell.** 
So, if I use such as `var_list=[w_1]`, the other two parameters in BasicLSTMCell  can not be optimized, How can I do it? 
"
2550,edit_distance_op.cc contains suspicious explicit divide by zeros,"In edit_distance_op.cc, there are several code pieces like:

if (normalize_) output_t(loc) /= 0.0;

is there any specific purpose doing that? As I know, dividing by 0 is not an advocated idea.
"
2549,[install problems] Failed to setup for development from the latest source(2016.5.28).,"### Environment info

Operating System:
`Ubuntu 14.04`
Installed version of CUDA and cuDNN: 

```
-rw-r--r-- 1 root root   322936  8 16  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16  8 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19  8 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336  8 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192  8 16  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13  3 22 10:04 /usr/local/cuda-7.5/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 root root       17  3 22 10:03 /usr/local/cuda-7.5/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxrwxrwx 1 root root 61453024  3 22 10:01 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862  3 22 10:01 /usr/local/cuda-7.5/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?
1. uninstall(including deleting the whole package) and reinstall many times, .
### Logs or other output that would be helpful

(part of the logs)

```
external/protobuf/python/google/protobuf/pyext/message.cc: In instantiation of 'bool google::protobuf::python::CheckAndGetInteger(PyObject*, T*, PyObject*, PyObject*) [with T = long long unsigned int; PyObject = _object]':
external/protobuf/python/google/protobuf/pyext/message.cc:601:45:   required from here
external/protobuf/python/google/protobuf/pyext/message.cc:554:37: warning: deprecated conversion from string constant to 'char*' [-Wwrite-strings]
INFO: From Unknown tensorflow/core/protobuf/master_service.pb.h:
bazel-out/local_linux-opt/genfiles/external/protobuf/src: warning: directory does not exist.
INFO: From Unknown tensorflow/core/protobuf/worker_service.pb.h:
bazel-out/local_linux-opt/genfiles/external/protobuf/src: warning: directory does not exist.
INFO: From Compiling tensorflow/python/pywrap_tensorflow.cc:
bazel-out/local_linux-opt/bin/tensorflow/python/pywrap_tensorflow.cc: In function 'PyObject* _wrap_GetMatchingFiles(PyObject*, PyObject*)':
bazel-out/local_linux-opt/bin/tensorflow/python/pywrap_tensorflow.cc:5659:40: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     for (int i = 0; i < converted.size(); ++i) {
                                        ^
bazel-out/local_linux-opt/bin/tensorflow/python/pywrap_tensorflow.cc: In function 'PyObject* _wrap_PyRecordReader_New(PyObject*, PyObject*)':
bazel-out/local_linux-opt/bin/tensorflow/python/pywrap_tensorflow.cc:3934:111: warning: 'arg2' may be used uninitialized in this function [-Wmaybe-uninitialized]
     result = (tensorflow::io::PyRecordReader *)tensorflow::io::PyRecordReader::New((string const &)*arg1,arg2);
                                                                                                               ^
At global scope:
cc1plus: warning: unrecognized command line option ""-Wno-self-assign"" [enabled by default]
Target //tensorflow/tools/pip_package:build_pip_package up-to-date:
  bazel-bin/tensorflow/tools/pip_package/build_pip_package
INFO: Elapsed time: 206.866s, Critical Path: 50.10s
```

I setup the development by using `python setup.py develop`.
However, the result is always `ImportError: No module named 'tensorflow'`

I think this problem  may be related to the protobuf according to the logs above.  I tried to reinstall many times, but I still can't figure out how to fix this.

Any help is appreciated!
"
2547,"Confusing embedding_lookup docstring, incorrect use of the word ""partition""","The wording in the docstring for nn.embedding_lookup is confusing and refers to subsets as partitions (https://www.tensorflow.org/versions/r0.8/api_docs/python/nn.html#embedding_lookup)

A partition of a set X is a set of nonempty subsets of X such that every element x in X is in exactly one of these subsets (https://en.wikipedia.org/wiki/Partition_of_a_set)

Here is an example of incorrect usage:
""For instance, 13 ids are split across 5 partitions as: [[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]""
That is actually 1 partition of the 13 ids, not 5 partitions.

And this is just really confusing:
""If len(params) > 1, each element id of ids is partitioned between the elements of params according to the partition_strategy. In all strategies, if the id space does not evenly divide the number of partitions, each of the first (max_id + 1) % len(params) partitions will be assigned one more id.""
"
