Issue Number,Issue Title,Issue Body
41109,tensorflow hub pre-trained model hults training on custom given data due to EarlyStopping error,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.

Everything written here is based on this [online link](https://www.tensorflow.org/hub/tutorials/tf2_text_classification) from tensorflow.

```python
import pandas as pd
import numpy as np

import tensorflow as tf
from tensorflow import keras

from tensorflow.keras import layers
from tensorflow.keras import models
from tensorflow.keras.models import load_model
from tensorflow.keras.models import model_from_json
from tensorflow.keras import regularizers
import tensorflow_docs.modeling as tfmodel

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

import tensorflow_hub as hub

partial_x_train_features=np.array([b'south pago pago victor mclaglen jon hall frances farmer olympe bradna gene lockhart douglass dumbrille francis ford ben welden abner biberman pedro cordoba rudy robles bobby stone nellie duran james flavin nina campana alfred e green treasure hunt adventure adventure',
 b'easy virtue jessica biel ben barnes kristin scott thomas colin firth kimberley nixon katherine parkinson kris marshall christian brassington charlotte riley jim mcmanus pip torrens jeremy hooton joanna bacon maggie hickey georgie glen stephan elliott young englishman marry glamorous american brings home meet parent arrive like blast future blow entrenched british stuffiness window comedy romance',
 b'fragments antonin gregori derangere anouk grinberg aurelien recoing niels arestrup yann collette laure duthilleul david assaraf pascal demolon jean baptiste iera richard sammel vincent crouzet fred epaud pascal elso nicolas giraud michael abiteboul gabriel le bomin psychiatrist probe mind traumatized soldier attempt unlock secret drove gentle deeply disturbed world war veteran edge insanity drama war',
 b'milka film taboos milka elokuva tabuista irma huntus leena suomu matti turunen eikka lehtonen esa niemela sirkka metsasaari tauno lehtihalmes ulla tapaninen toivo tuomainen hellin auvinen salmi rauni mollberg small finnish lapland community milka innocent year old girl live mother miss dead father prays god love haymaking employ drama',
 b'sleeping car david naughton judie aronson kevin mccarthy jeff conaway dani minnick ernestine mercer john carl buechler gary brockette steve lundquist billy stevenson michael scott bicknell david coburn nicole hansen tiffany million robert ruth douglas curtis jason david naughton move abandon train car resurrect vicious ghost landlady dead husband mister near fatal encounter comedy horror'])

partial_x_train_plot=np.array([b'treasure hunt adventure',
 b'young englishman marry glamorous american brings home meet parent arrive like blast future blow entrenched british stuffiness window',
 b'psychiatrist probe mind traumatized soldier attempt unlock secret drove gentle deeply disturbed world war veteran edge insanity',
 b'small finnish lapland community milka innocent year old girl live mother miss dead father prays god love haymaking employ',
 b'jason david naughton move abandon train car resurrect vicious ghost landlady dead husband mister near fatal encounter'])

partial_x_train_actors_array=np.array([np.array([b'victor mclaglen', b'jon hall', b'frances farmer',
       b'olympe bradna', b'gene lockhart', b'douglass dumbrille',
       b'francis ford', b'ben welden', b'abner biberman',
       b'pedro de cordoba', b'rudy robles', b'bobby stone',
       b'nellie duran', b'james flavin', b'nina campana'], dtype='|S18'),
np.array([b'jessica biel', b'ben barnes', b'kristin scott thomas',
       b'colin firth', b'kimberley nixon', b'katherine parkinson',
       b'kris marshall', b'christian brassington', b'charlotte riley',
       b'jim mcmanus', b'pip torrens', b'jeremy hooton', b'joanna bacon',
       b'maggie hickey', b'georgie glen'], dtype='|S21'),
np.array([b'gregori derangere', b'anouk grinberg', b'aurelien recoing',
       b'niels arestrup', b'yann collette', b'laure duthilleul',
       b'david assaraf', b'pascal demolon', b'jean-baptiste iera',
       b'richard sammel', b'vincent crouzet', b'fred epaud',
       b'pascal elso', b'nicolas giraud', b'michael abiteboul'],
      dtype='|S18'),
np.array([b'irma huntus', b'leena suomu', b'matti turunen',
       b'eikka lehtonen', b'esa niemela', b'sirkka metsasaari',
       b'tauno lehtihalmes', b'ulla tapaninen', b'toivo tuomainen',
       b'hellin auvinen-salmi'], dtype='|S20'),
np.array([b'david naughton', b'judie aronson', b'kevin mccarthy',
       b'jeff conaway', b'dani minnick', b'ernestine mercer',
       b'john carl buechler', b'gary brockette', b'steve lundquist',
       b'billy stevenson', b'michael scott-bicknell', b'david coburn',
       b'nicole hansen', b'tiffany million', b'robert ruth'], dtype='|S22')], dtype=object)

partial_x_train_reviews=np.array([b'edward small take director alfred e green cast crew uncommonly attractive brilliant assemblage south sea majority curiously undersung piece location far stylize date goldwyn hurricane admittedly riddle cliche formula package visual technical excellence scarcely matter scene stop heart chiseled adonis jon hall porcelain idol frances farmer outline profile s steam background volcano romantic closeup level defies comparison edward small film typically string frame individual work art say outdid do workhorse composer edward ward song score year prior work universal stun phantom opera',
 b'jessica biel probably best know virtuous good girl preacher kid mary camden heaven get tackle classic noel coward role early play easy virtue american interloper english aristocratic family unsettle family matriarch kristin scott thomas noel coward write upper class twit pretension wit keep come kind adopt way adopt oscar wilde george bernard shaw kid grow poverty way talent entertain upper class take coward heart felt modern progressive generally term social trend whittakers easy virtue kind aristocrat anybody like hang party invite noel entertain amelia earhart aviation jessica biel character auto race young widow detroit area course area motor car auto race fresh win monte carlo win young ben barnes heir whittaker estates lot land debt barnes bring biel home family mortify classless american way sense recognize class distinction thing get rid title nobility aristocrats story scott thomas dominate family try desperately estate husband colin firth serve world war horror do probably horror trench war slaughter fact class distinction tend melt combat biel kind like wife rule whittaker roost scandal past threatens disrupt barnes biel marriage form crux story turn fact end really viewer figure eventually happen second film adaption easy virtue silent film direct young alfred hitchcock easy virtue actually premier america london star great american stage actress jane cowl guess coward figure american heroine best american theatergoer british one version easy virtue direct flawlessly stephen elliot fine use period music noel coward cole porter end credit really mock upper class coward tradition play going gets tough tough going believe elliott try say class especially one right stuff course obligatory fox hunt upper class indulge oscar wilde say unspeakable uneatable chance younger generation expose noel coward worth see',
 b'saw night eurocine event movie european country show day european city hear le bomin barely hear derangere la chambre des officiers fortunately surprise discover great talent unknown large audience derangere absolutely astonish play character antonin verset victim post wwi trauma live trouble scene endure month war cast excellent great work cinematography offer really nice shot great landscape stun face edit really subtile bit memory make sense story minute movie show real chill ww archive action flick like sensitive psychologic movie really think absolutely recommend les fragments d antonin let le bomin',
 b'rauni mollberg earth sinful song favorite foreign film establish director major talent film festival circuit get amazing followup milka base work novelist timo mukka till worthy major dvd exposure unlike kaurismaki bros follow double handedly create tongue cheek deadpan finnish film style fan world mollberg commit naturalistic approach film overflow nature life lust earthiness find scandi cinema mainly work famous talent swede vilgot sjoman curious yellow fame director film tabu title imply mollberg effort quite effective sidestep fully treat screen theme incest making adult character father figure real blood relate daddy applies usual merely step father gimmick use countless time american movie incest work matti turunen kristus perkele translate christ devil really common law step dad underage milka beautiful offbeat fashion young girl portray shot irma huntus bring screen sexiness bergman harriet andersson decade earlier create international success summer monika sawdust tinsel imagine actress milka role shame do pursue act career afterward completing strong line leena suomu earth mother type confines act narrow emotional range prove solid rock crucial role bookended spectacularly beautiful shot birch wood winter virtually black white visually color presence milka film quickly develop nature theme presence strange click beak bird talisman early scene milka handyman turunen frolicking naked lake emerge oh natural sex play year old milka man result tastefully shoot intimacy imply ejaculation set trouble come religious aspect remote farm community heavily stress especially enjoy motif spiritual guidance cantor malmstrom quality anti stereotypical play eikka lehtonen instead rigid cruel turn care milka illegitimate baby bear strong romance turunen stud continue service mom woman neighborhood present utterly natural viewer position watch ethnographic exercise moralistic tale powerful technique milka frequently speak directly camera viewer forceful monologue bear crisp sound record sound nature include rain constant motif make milka engross experience view film subtitle knowledge finnish lapp recall best silent era classic direction strong convey dramatic content theme way transcend language kudos mollberg talented cinematographer job work remain obscurity ripe rediscovery',
 b'wonder horror film write woody allen wannabe come like check imaginatively direct typical enjoyable haunt place premise solid makeup effect good job major flaw dialogue overload cheeky wisecrack witticisms sample want scary shopping ex wife hit mark deliver inappropriate moment hero battle evil ghost'])

partial_y_train=[[0,1,0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
 [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
 [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
 [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
 [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]] #multilabel classification
partial_y_train=np.asarray(partial_y_train)
```
```python
# Test variables
x_val_features=np.array([b'corman world exploits hollywood rebel paul w s anderson allan arkush eric balfour paul bartel peter bogdanovich bob burns david carradine gene corman julie corman roger corman joe dante jonathan demme robert niro bruce dern frances doel alex stapleton documentary diy producer director roger corman alternative approach make movie hollywood documentary',
 b'blood bone michael jai white julian sands eamonn walker dante basco nona gaye michelle belegrin bob sapp dick anthony williams francis capra ron yuan kevin kimbo slice ferguson gina carano maurice smith ernest miller kevin phillips ben ramsey los angeles ex take underground fight world storm quest fulfill promise dead friend action drama',
 b'slender man joey king julia goldani telles jaz sinclair annalise basso alex fitzalan taylor richardson javier botet jessica blank michael reilly burke kevin chapman miguel nascimento eddie frateschi oscar wahlberg danny beaton gabrielle lorthe sylvain white small town massachusetts group friend fascinate internet lore slender man attempt prove do actually exist mysteriously go miss horror',
 b'friend ivan lapshin moy drug ivan lapshin andrei boltnev nina ruslanova andrey mironov aleksey zharkov zinaida adamovich aleksandr filippenko yuriy kuznetsov valeriy filonov anatoly slivnikov andrey dudarenko semyon farada nina usatova valeri kuzin lidiya volkova yuri aroyan aleksey german russian provincial town middle stalin great purge ivan lapshin head local police do do drama',
 b'noon till charles bronson jill ireland douglas fowley stan haze damon douglas hector morales bert williams davis roberts betty cole william lanteau larry french michael leclair anne ramsey howard brunner don red barry frank d gilroy spending unforgettable hour outlaw beautiful young widow turn story worldwide famous comedy romance western'])

x_val_plot=np.array([b'documentary diy producer director roger corman alternative approach make movie hollywood',
 b'los angeles ex take underground fight world storm quest fulfill promise dead friend',
 b'small town massachusetts group friend fascinate internet lore slender man attempt prove do actually exist mysteriously go miss',
 b'russian provincial town middle stalin great purge ivan lapshin head local police do do',
 b'spending unforgettable hour outlaw beautiful young widow turn story worldwide famous'])

x_val_actors_array=np.array([np.array([b'paul w.s. anderson', b'allan arkush', b'eric balfour',
       b'paul bartel', b'peter bogdanovich', b'bob burns',
       b'david carradine', b'gene corman', b'julie corman',
       b'roger corman', b'joe dante', b'jonathan demme',
       b'robert de niro', b'bruce dern', b'frances doel'], dtype='|S18'),
 np.array([b'michael jai white', b'julian sands', b'eamonn walker',
       b'dante basco', b'nona gaye', b'michelle belegrin', b'bob sapp',
       b'dick anthony williams', b'francis capra', b'ron yuan',
       b""kevin 'kimbo slice' ferguson"", b'gina carano', b'maurice smith',
       b'ernest miller', b'kevin phillips'], dtype='|S28'),
 np.array([b'joey king', b'julia goldani telles', b'jaz sinclair',
       b'annalise basso', b'alex fitzalan', b'taylor richardson',
       b'javier botet', b'jessica blank', b'michael reilly burke',
       b'kevin chapman', b'miguel nascimento', b'eddie frateschi',
       b'oscar wahlberg', b'danny beaton', b'gabrielle lorthe'],
      dtype='|S20'),
 np.array([b'andrei boltnev', b'nina ruslanova', b'andrey mironov',
       b'aleksey zharkov', b'zinaida adamovich', b'aleksandr filippenko',
       b'yuriy kuznetsov', b'valeriy filonov', b'anatoly slivnikov',
       b'andrey dudarenko', b'semyon farada', b'nina usatova',
       b'valeri kuzin', b'lidiya volkova', b'yuri aroyan'], dtype='|S20'),
 np.array([b'charles bronson', b'jill ireland', b'douglas fowley',
       b'stan haze', b'damon douglas', b'hector morales',
       b'bert williams', b'davis roberts', b'betty cole',
       b'william lanteau', b'larry french', b'michael leclair',
       b'anne ramsey', b'howard brunner', b""don 'red' barry""],
      dtype='|S15')], dtype=object)

x_val_reviews=np.array([b'sam kinison brilliant vulgar obscene use x rated material verbiage express comedic commentary variety topic funny thing tell truth superb laugh film win award best direction best documentary deservedly larry carroll do commendable job interweave live performance peer commentary narrative beverly d angelo richard pryor particularly effective brother kinison executive producer partial host insightful film man finally place let rip',
 b'theme movie tracks dennis hopper rolling thunder devane american home public general idea horror viet nam war bring war home people home understand violence nam strong stuff film depicts homecoming combat weary u s army green berets rent car travel country meet different people pick accidentally kill girl watch high school basketball game totally disillusion come home end similar dennis hopper film tracks tracks freeze frame violent end welcome home soldier boys take graphic conclusion end scene blood craze vet freeze frame leave lasting impact raw brutal beat act intense fan symbolism joe don baker viet nam era movie movie',
 b'loved great comedy know movie guy watch think funny dark performance great think write looked variey review say vibrant snappy surprisingly fresh better living breathe little life increasingly number genre dysfunctional family comedy check variety review want great opinion credible source industry p s archive retrieve review',
 b'longtime classic film buff great come worthwhile film hollywood golden age know exist see doubly nice don ameche film year immediately follow departure fox think better light comedian movie expensively mount romantic comedy family comedy show beautiful new print tcm sets cinematography elaborate idiom life father myrna loy despite reviewer say lubitsch heaven wait good ameche loy masterful job light comedy role ignore old part play loy easily manged sexy charm beautiful despite handicap overly heavy make used entire film obviously hide probably time',
 b'walked movie expect completely different get people use excuse hate movie like act excellent justin chatwin margarita levieva incredibly believable really enjoy material understand people mad people expect teenage horror flick glad depth beauty opinion do like do understand horror obsess teen soundtrack amaze love movie promotion mean trailers lot differently better strongly encourage movie love deep thought provoke beautiful emotional movie'])

y_val=[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
 [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
 [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
 [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
 [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]]
y_val=np.asarray(y_val)
```
As you can see my data are composed of 4 input arrays. The first array contains movie content about a movie, the second array contains the plot summary of movies, the third array is an numpy array of arrays with actor names and the fourth array contains data about movie reviews. 
What I am trying to do is to fit a pre-trained neural network from tensorflow hub (specifically [this neural network](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1))

The process of fitting is the following:
```python
class Callback_Configurations():
    
    MONITOR_METRIC = 'val_loss'
    MINIMUM_DELTA = 1
    PATIENCE = 5
    VERBOSE = 0
    MODE = 'min'
    
def callback(saved_model, model):
    
    weights_fname='{}.h5'.format(saved_model)

    try:
        with open('{}.json'.format(save_model),'r') as f:
            model_json = json.load(f)
        
        model = model_from_json(model_json)
        
        model.load_weights('{}').format(weights_fname)

    except:
        print('\nPre-trained weights not found. Fitting from start')
        pass

    monitor_metric = Callback_Configurations.MONITOR_METRIC
    
    callbacks = [
        tfmodel.EpochDots(),
        
        EarlyStopping(monitor=monitor_metric,
                      min_delta=Callback_Configurations.MINIMUM_DELTA,
                      patience=Callback_Configurations.PATIENCE,
                      verbose=Callback_Configurations.VERBOSE,
                      mode=Callback_Configurations.MODE,
                      restore_best_weights=True), # I get the error here: TypeError: object of type 'NoneType' has no len()

        ModelCheckpoint(filepath=weights_fname,
                        monitor=monitor_metric,
                        verbose=Callback_Configurations.VERBOSE,
                        save_best_only=True,
                        save_weights_only=True), #True, False      
]
    return callbacks

# import the pre-trained model
model = ""https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1""
hub_layer = hub.KerasLayer(model, output_shape=[20], input_shape=[], dtype=tf.string, trainable=True)

# create the neural network structure
model = tf.keras.Sequential(name=""English_Google_News_130GB_witout_OOV_tokens"")
model.add(hub_layer)
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(16, kernel_regularizer=regularizers.l2(0.01),
                                activation='relu'))
model.add(tf.keras.layers.Dropout(0.0))
model.add(tf.keras.layers.Dense(y_val.shape[1],  activation='sigmoid'))

lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(
    0.01,
    decay_steps=int(np.ceil((len(partial_x_train_actors_array)*0.8)//16))*1000,
    decay_rate=1,
    staircase=False)

def optimizer_adam_v2():
    return keras.optimizers.Adam(lr_schedule)

optimizer = optimizer_adam_v2()

model.compile(optimizer=optimizer,
              loss=""binary_crossentropy"",
              metrics=[""accuracy""])

history = model.fit([partial_x_train_features, partial_x_train_plot, partial_x_train_actors_array, partial_x_train_reviews],
                    partial_y_train,
                    steps_per_epoch=int(np.ceil((len(partial_x_train_actors_array)*0.8)//16)),
                    epochs=100,
                    batch_size=16,
                    validation_split=0.2,
                    verbose=2,
                    callbacks=callback(""english_google_news_without_oovtokens"", model))
```

The above code seems to run correctly up to the 5th epoch where I get the following error:

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-74-ec4463fe97aa> in <module>
     34                     validation_split=0.2,
     35                     verbose=0,
---> 36                     callbacks=callback(""english_google_news_without_oovtokens"", model))

~\Documents\anaconda\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--> 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

~\Documents\anaconda\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    395                       total_epochs=1)
    396                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,
--> 397                                  prefix='val_')
    398 
    399     return model.history

~\Documents\anaconda\lib\contextlib.py in __exit__(self, type, value, traceback)
    117         if type is None:
    118             try:
--> 119                 next(self.gen)
    120             except StopIteration:
    121                 return False

~\Documents\anaconda\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in on_epoch(self, epoch, mode)
    769       if mode == ModeKeys.TRAIN:
    770         # Epochs only apply to `fit`.
--> 771         self.callbacks.on_epoch_end(epoch, epoch_logs)
    772       self.progbar.on_epoch_end(epoch, epoch_logs)
    773 

~\Documents\anaconda\lib\site-packages\tensorflow_core\python\keras\callbacks.py in on_epoch_end(self, epoch, logs)
    300     logs = logs or {}
    301     for callback in self.callbacks:
--> 302       callback.on_epoch_end(epoch, logs)
    303 
    304   def on_train_batch_begin(self, batch, logs=None):

~\Documents\anaconda\lib\site-packages\tensorflow_core\python\keras\callbacks.py in on_epoch_end(self, epoch, logs)
   1272           if self.verbose > 0:
   1273             print('Restoring model weights from the end of the best epoch.')
-> 1274           self.model.set_weights(self.best_weights)
   1275 
   1276   def on_train_end(self, logs=None):

~\Documents\anaconda\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py in set_weights(self, weights)
   1282         expected_num_weights += 1
   1283 
-> 1284     if expected_num_weights != len(weights):
   1285       raise ValueError(
   1286           'You called `set_weights(weights)` on layer ""%s"" '

TypeError: object of type 'NoneType' has no len()
```
"
41108,GPU significantly slower than CPU on WSL 2 & nvidia-docker2,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows Subsystem For Linux 2 (WSL 2) with Ubuntu 20 LTS, Kernel 4.19.121-microsoft-standard**
- TensorFlow installed from (source or binary): **binary** (unsure, via pip install)
- TensorFlow version (use command below): **v1.15.2-30-g4386a66 1.15.3**
- Python version: **3.7.8**
- CUDA/cuDNN version: **libcudnn7-dev/now 7.6.4.38-1+cuda10.1 amd64**
- GPU model and memory: **RTX 2070, 8GB**

**Describe the current behavior**

Training is significantly slower on GPU compared to CPU (Intel Xeon E3-1230 v3, 3.30 GHz, 4 Cores)

**Describe the expected behavior**

Training is significantly faster on GPU

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

I'm using nvidia-docker2 with the tensorflow docker containers, I've verified that the GPU is in use when it's configured.

| python | container  | tensorflow | gpu | comment                                   | time      |
| ------ | ---------- | ---------- | --- | ----------------------------------------- | --------- |
| 3.7.8  | latest     | 1.15.3     | no  | desktop                                   | 7m24.035s |
| 3.7.8  | 1.15.2-gpu | 1.15.3     | yes | desktop, tf-gpu package                   | ~166m     |
| 3.7.8  | latest-gpu | 1.15.3     | no  | desktop, tf-gpu package                   | 6m30.067s |
| 3.7.8  | latest-gpu | 2.2.0      | yes | desktop, keras 2.4.x                      | ~175m     | 

I'm using keras with a sequential model (see below), doing reinforcement learning with 180 memory replays (model.fit) per episode.

```
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
reshape (Reshape)            (None, 40, 1)             0         
_________________________________________________________________
conv1d (Conv1D)              (None, 38, 16)            64        
_________________________________________________________________
max_pooling1d (MaxPooling1D) (None, 19, 16)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 17, 16)            784       
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 8, 16)             0         
_________________________________________________________________
flatten (Flatten)            (None, 128)               0         
_________________________________________________________________
dense (Dense)                (None, 48)                6192      
_________________________________________________________________
dense_1 (Dense)              (None, 24)                1176      
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 75        
=================================================================
Total params: 8,291
Trainable params: 8,291
Non-trainable params: 0
```

I'm going to try and provide a minimal python example ASAP.
"
41107,UnimplementedError: Fused conv implementation does not support grouped convolutions for now.,"I follow the TensorFlow tutorial [(https://www.tensorflow.org/tutorials/images/classification)] for image classification when I try to compile the model, it gave me an error like this

> Epoch 1/100
> ---------------------------------------------------------------------------
> UnimplementedError                        Traceback (most recent call last)
> <ipython-input-117-7335ac61164f> in <module>()
>       4     epochs=epochs,
>       5     validation_data=validation_data_gen,
> ----> 6     validation_steps=total_val // batch_size,
>       7 )
> 
> 8 frames
> /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
>      58     ctx.ensure_initialized()
>      59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
> ---> 60                                         inputs, attrs, num_outputs)
>      61   except core._NotOkStatusException as e:
>      62     if name is not None:
> 
> UnimplementedError:  Fused conv implementation does not support grouped convolutions for now.
> 	 [[node sequential_5/conv2d_33/Relu (defined at <ipython-input-115-4d151b570f4c>:6) ]] [Op:__inference_train_function_6419]
> 
> Function call stack:
> train_function

I use my own data and follow the same code as the post, but still got an error like that.
"
41106,"Socket closed when ""LayerNormalization"" was used for tensors of 3 or more dimensions with TPU in colab.","When I used `LayerNormalization` on tensors of 3 or more dimensions in the colab with TPU, I encountered the following error:
> UnavailableError: Socket closed
> Additional GRPC error information:
> {""created"":""@1593962551.753581454"",""description"":""Error received from peer ipv4:10.10.67.202:8470"",""file"":""external/com_github_grpc_grpc/src/core/lib/surface/call.cc"",""file_line"":1056,""grpc_message"":""Socket closed"",""grpc_status"":14}
  
Please find the gist [here](https://colab.research.google.com/gist/gdhy9064/19ac8fafc46bdaa647a8b71bc31c3d2b/-pianist-ipynb.ipynb), thanks.


"
41105,"Comparing tensor dimension in add_loss and ""standard"" (mse) loss","**System information**
- OS Platform and Distribution: Linux, Fedora 30
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7.7
- CUDA/cuDNN version: Cuda version is 10.2
- GPU model and memory: GeForce GTX 1080 Ti, amount global memory: 11178 MBytes


**Current error**
The sample code below gives me this error:
```
ValueError: Shapes must be equal rank, but are 0 and 1
        From merging shape 0 with other shapes. for '{{node AddN}} = AddN[N=2, T=DT_FLOAT](loss/weighted_loss/value, model/new_layer/mul_1)' with input shapes: [], [100].
```
where 100 is the batch size I am using and when I try to add two different loss functions, one coming from the `add_loss` instruction and one defined in the `compile` of Keras (tf-Keras 2.3.0).

**Expected behavior**
If I print the tensors inside the losses, it seems to me that they have the same shape (one entry for each sample of the mini-batch). But then these don't get summed. Is it possible that the 2 losses are summed only after the loss from the compile has been turned to a scalar? So, should I also return a scalar in the `add_loss` function?
I actually wanted to sum the vectors coming from the two losses.


**Standalone code to reproduce the issue**
```
import numpy as np
import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Input

def rate_mse(rate=1e5):
    @tf.function # also needed for printing
    def loss(y_true, y_pred):
        tmp = rate*K.mean(K.square(y_pred - y_true), axis=-1)
#        tf.print('shape %s and rank %s output in mse'%(K.shape(tmp), tf.rank(tmp)))
        tf.print('shape and rank output in mse',[K.shape(tmp), tf.rank(tmp)])
        tf.print('mse loss:',tmp) # print when I put tf.function
        return tmp
    return loss

class newLayer(tf.keras.layers.Layer):
    def __init__(self, rate=5e-2, **kwargs):
        super(newLayer, self).__init__(**kwargs)
        self.rate = rate
        
#    @tf.function # to be commented for NN training
    def call(self, inputs):
        tmp = self.rate*K.mean(inputs*inputs, axis=-1)
        tf.print('shape and rank output in regularizer',[K.shape(tmp), tf.rank(tmp)])
        tf.print('regularizer loss:',tmp)
        self.add_loss(tmp, inputs=True)
        return inputs

tot_n = 10000
xx = np.random.rand(tot_n,1)
yy = np.pi*xx

train_size = int(0.9*tot_n)
xx_train = xx[:train_size]; xx_val = xx[train_size:]
yy_train = yy[:train_size]; yy_val = yy[train_size:]

reg_layer = newLayer()

input_layer = Input(shape=(1,))                                      # input
hidden = Dense(20, activation='relu', input_shape=(2,))(input_layer) # hidden layer
hidden = reg_layer(hidden)
output_layer = Dense(1, activation='linear')(hidden) 

model = Model(inputs=[input_layer], outputs=[output_layer])
model.compile(optimizer='Adam', loss=rate_mse(), experimental_run_tf_function=False)
#model.compile(optimizer='Adam', loss=None, experimental_run_tf_function=False)
history = model.fit(xx_train, yy_train, epochs=50, batch_size = 100, 
                    validation_data=(xx_val,yy_val), verbose=2)

print(model.predict(np.array([[1]]))) # sanity check
```

I would also have a secondary question: why is it necessary to comment the decorator `@tf.function` of the `call` method in `newLayer` in order that this is actually taken into consideration during training? On the other hand, if I remove it from inside function `rate_mse`, this doesn't print anything. Are the two things related between them and with the different possible tensor representations?

Thanks in advance to whoever can help."
41103,get error when runing python captcha_train.py,"hi
Time to run the following code : 
`python captcha_train.py`
im using the flow library:
https://github.com/PatrickLib/captcha_recognize
im installation : 

- python 2.7
- Anaconda2 4.3.1
- TensorFlow 1.1

get this erros :((

`Traceback (most recent call last):
  File ""captcha_train.py"", line 89, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""captcha_train.py"", line 65, in main
    run_train()
  File ""captcha_train.py"", line 57, in run_train
    coord.join(threads)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py"", line 234, in _run
    sess.run(enqueue_op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 778, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 982, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1032, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1052, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: ./data/train.tfrecords
         [[Node: input/ReaderReadV2 = ReaderReadV2[_device=""/job:localhost/replica:0/task:0/cpu:0""](input/TFRecordReaderV2, input/input_producer)]]`
`Caused by op u'input/ReaderReadV2', defined at:
  File ""captcha_train.py"", line 89, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""captcha_train.py"", line 65, in main
    run_train()
  File ""captcha_train.py"", line 19, in run_train
    images, labels = captcha.inputs(train=True, batch_size=FLAGS.batch_size)
  File ""/app/captcha/captcha_model.py"", line 15, in inputs
    return captcha_input.inputs(train, batch_size=batch_size)
  File ""/app/captcha/captcha_input.py"", line 44, in inputs
    image, label = read_and_decode(filename_queue)
  File ""/app/captcha/captcha_input.py"", line 21, in read_and_decode
    _, serialized_example = reader.read(filename_queue)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/io_ops.py"", line 193, in read
    return gen_io_ops._reader_read_v2(self._reader_ref, queue_ref, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 411, in _reader_read_v2
    queue_handle=queue_handle, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2336, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1228, in init
    self._traceback = _extract_stack()`
`NotFoundError (see above for traceback): ./data/train.tfrecords
         [[Node: input/ReaderReadV2 = ReaderReadV2[_device=""/job:localhost/replica:0/task:0/cpu:0""](input/TFRecordReaderV2, input/input_producer)]]
2020-07-02 07:33:55.821848: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2020-07-02 07:33:55.822614: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2020-07-02 07:33:55.823256: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2020-07-02 07:33:55.823711: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.`

please help me"
41102,GPU is not running,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (on Azure VM)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.2.0
- Python version: 3.8.3
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA - 10.1, cuDNN - 7.6.4
- GPU model and memory: NVIDIA Tesla k80



**Describe the problem**
When I'm running  ""tf.test.is_gpu_available()"" I got False.

**Any other info / logs**
I installed c++ redistributable, cuda, cudnn and set the path environments as shown on the tensorflow gpu support.
"
41101,MultiWorkerMirroredStrategy: Multi-workers don't train once synced,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
**No. I used Keras tutorial**: [Multi-worker training with Keras](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
**Chief:** Ubuntu 20.04
**Worker**: Ubuntu 20.04
- TensorFlow installed from (source or binary):**From a Docker image:  tensorflow/tensorflow:latest-gpu**
- TensorFlow version (use command below): **v2.2.0-rc4-8-g2b96f3662b 2.2.0**
- Python version:  **3.6.9**
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: **V10.1.243**
- GPU model and memory:
**Chief: Titan RTX 24 Go
Worker: 4x GTX 1060 6Go**
- You can collect some of this information using our environment capture: [tf_env.txt](https://github.com/tensorflow/tensorflow/files/4874929/tf_env.txt)

**Describe the current behavior**
I'm running the multi_worker_with_keras tutorial on 2 computers: 1 chief and 1 worker, both equipped with different GPUs. 
I run the tutorial into a tensorflow-gpu docker image on each computer. Each computer has been configured to communicate with an ssh key, without a password needed.

1. The single_worker_model part of the tutorial works fine on both computers: each computer go through the epochs individually
2. Regarding the MultiWorkerMirroredStrategy part, If I omit to set TF_CONFIG as an environment variable, both nodes train correctly on their side. Note: On the worker, the strategy distributes the work across the 4 local GPUs as expected.

3. When I run the final script - TF_CONFIG + MultiWorkerMirroredStrategy - by starting the chief first, then the worker, the chief wait for the worker, then they sync. They finally both start epoch 1 and hold.

**Describe the expected behavior**
1. Have both workers to train after logging Epoch 1/60
2. Have both workers to sync


**Standalone code to reproduce the issue**
**On the chief:**
```
docker run --gpus all -it -p 12345:12345 --rm tensorflow/tensorflow:latest-gpu
export TF_CONFIG='{""cluster"": {""worker"": [""192.168.1.31:12345"", ""192.168.1.46:12345""]}, ""task"": {""index"": 0, ""type"": ""worker""}}'
[copy the script to the docker container]
python multi_worker_with_keras.py
```

**On the worker:**
```
docker run --gpus all -it -p 12345:12345 --rm tensorflow/tensorflow:latest-gpu
export TF_CONFIG='{""cluster"": {""worker"": [""192.168.1.31:12345"", ""192.168.1.46:12345""]}, ""task"": {""index"": 1, ""type"": ""worker""}}'
[copy the script to the docker container]
python multi_worker_with_keras.py
```
Note: Only the index changes

**The script:**
```
import tensorflow as tf
import numpy as np

def mnist_dataset(batch_size):
  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()
  x_train = x_train / np.float32(255)
  y_train = y_train.astype(np.int64)
  train_dataset = tf.data.Dataset.from_tensor_slices(
      (x_train, y_train)).shuffle(60000).repeat().batch(batch_size)
  return train_dataset

def build_and_compile_cnn_model():
  model = tf.keras.Sequential([
      tf.keras.Input(shape=(28, 28)),
      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),
      tf.keras.layers.Conv2D(32, 3, activation='relu'),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(128, activation='relu'),
      tf.keras.layers.Dense(10)
  ])
  model.compile(
      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
      metrics=['accuracy'])
  return model


strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

per_worker_batch_size = 512
num_workers = 2

global_batch_size = per_worker_batch_size * num_workers
multi_worker_dataset = mnist_dataset(global_batch_size)

with strategy.scope():
  multi_worker_model = build_and_compile_cnn_model()

multi_worker_model.fit(multi_worker_dataset, epochs=60, steps_per_epoch=60)

```
**Note**: I have raised the number of epochs, steps_per_epoch, and per_worker_batch_size. I have changed the number of num_workers from 4 to 2. 
**Note**: I haven't done the ""ModelCheckpoint callback"" part as I wanted to validate the training sync first.
**Note**: I have tested with auto sharding policy OFF (code from the tutorial), and I don't get the ""Found an unshardable source dataset"" error. But the workers don't train either.
```
options = tf.data.Options()
options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF
dataset_no_auto_shard = multi_worker_dataset.with_options(options)
```


**Other info / logs** 
**On the chief:**
[chief.log](https://github.com/tensorflow/tensorflow/files/4874928/chief.log)
```
2020-07-05 12:52:14.867922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-05 12:52:14.867929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-05 12:52:14.867935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-05 12:52:14.867941: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-05 12:52:14.867948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-05 12:52:14.867954: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-05 12:52:14.867960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-05 12:52:14.868007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-05 12:52:14.868671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-05 12:52:14.869292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-05 12:52:14.869303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-05 12:52:14.869307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-05 12:52:14.869311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-05 12:52:14.869374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-05 12:52:14.870033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-05 12:52:14.870662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:0 with 21960 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:09:00.0, compute capability: 7.5)
2020-07-05 12:52:14.873278: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12345, 1 -> 192.168.1.46:12345}
2020-07-05 12:52:14.873849: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:12345
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
2020-07-05 12:52:22.818158: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:434] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: ""TensorSliceDataset/_2""
op: ""TensorSliceDataset""
input: ""Placeholder/_0""
input: ""Placeholder/_1""
attr {
  key: ""Toutput_types""
  value {
    list {
      type: DT_FLOAT
      type: DT_INT64
    }
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: 28
        }
        dim {
          size: 28
        }
      }
      shape {
      }
    }
  }
}

Epoch 1/60
2020-07-05 12:52:25.479341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-05 12:52:25.731883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7

```


**On the worker:**
[worker.log](https://github.com/tensorflow/tensorflow/files/4874930/worker.log)
```
2020-07-05 12:52:20.891307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-05 12:52:20.891332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-05 12:52:20.891358: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-05 12:52:20.891383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-05 12:52:20.891407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-05 12:52:20.891431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-05 12:52:20.891455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-05 12:52:20.898699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3
2020-07-05 12:52:20.898900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-05 12:52:20.898916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3 
2020-07-05 12:52:20.898928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y Y Y 
2020-07-05 12:52:20.898938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N Y Y 
2020-07-05 12:52:20.898948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   Y Y N Y 
2020-07-05 12:52:20.898958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   Y Y Y N 
2020-07-05 12:52:20.904332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:worker/replica:0/task:1/device:GPU:0 with 5644 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:19:00.0, compute capability: 6.1)
2020-07-05 12:52:20.905569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:worker/replica:0/task:1/device:GPU:1 with 5644 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1060 6GB, pci bus id: 0000:1a:00.0, compute capability: 6.1)
2020-07-05 12:52:20.906769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:worker/replica:0/task:1/device:GPU:2 with 5644 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1060 6GB, pci bus id: 0000:67:00.0, compute capability: 6.1)
2020-07-05 12:52:20.907967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:worker/replica:0/task:1/device:GPU:3 with 5631 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1060 6GB, pci bus id: 0000:68:00.0, compute capability: 6.1)
2020-07-05 12:52:20.915563: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 192.168.1.31:12345, 1 -> localhost:12345}
2020-07-05 12:52:20.917163: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:12345
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
2020-07-05 12:52:22.833446: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:434] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: ""TensorSliceDataset/_2""
op: ""TensorSliceDataset""
input: ""Placeholder/_0""
input: ""Placeholder/_1""
attr {
  key: ""Toutput_types""
  value {
    list {
      type: DT_FLOAT
      type: DT_INT64
    }
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: 28
        }
        dim {
          size: 28
        }
      }
      shape {
      }
    }
  }
}

Epoch 1/60
2020-07-05 12:52:25.979992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-05 12:52:26.242036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
```"
41100,Broken link in www.tensorflow.org/resources/learn-ml,"https://www.tensorflow.org/resources/learn-ml
-> The four areas of machine learning education
-> Build your own projects
-> [colab]
-> https://colab.research.google.com/github/tensorflow/docs/blob/r2.0rc/site/en/r2/tutorials/keras/basic_classification.ipynb

Gives me ""Notebook not found""
Fetch for https://api.github.com/repos/tensorflow/docs/contents/site/en/r2/tutorials/keras?per_page=100&ref=r2.0rc failed: {
  ""message"": ""No commit found for the ref r2.0rc"",
  ""documentation_url"": ""https://developer.github.com/v3/repos/contents/""
}
"
41099,Installation error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.2.0
- Python version: 3.6 / 3.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): - 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: -
- GPU model and memory: NVIDIA GeForce GTX 960 6,0 GB



**Describe the problem**
While having installed the Tensorflow package via Pycharm Keras does not work. It does not want to import the Sequential Model from Keras. We want to run a unit test on a Keras-based neural network an it is not working. Here is my error message:

Error
Traceback (most recent call last):
  File ""C:\Users\Philip\AppData\Local\Programs\Python\Python36\lib\unittest\case.py"", line 59, in testPartExecutor
    yield
  File ""C:\Users\Philip\AppData\Local\Programs\Python\Python36\lib\unittest\case.py"", line 601, in run
    testMethod()
  File ""C:\Users\Philip\AppData\Local\Programs\Python\Python36\lib\unittest\loader.py"", line 34, in testFailure
    raise self._exception
ImportError: Failed to import test module: test_neural_network
Traceback (most recent call last):
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Philip\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Philip\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Das angegebene Modul wurde nicht gefunden.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\venv\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from tensorflow.keras.layers.experimental.preprocessing import RandomRotation
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\venv\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\venv\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Philip\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Philip\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Das angegebene Modul wurde nicht gefunden.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Philip\AppData\Local\Programs\Python\Python36\lib\unittest\loader.py"", line 153, in loadTestsFromName
    module = __import__(module_name)
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\hw08_neural_networks\test_neural_network.py"", line 2, in <module>
    from hw08_neural_networks import get_data, lstm, cnn
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\hw08_neural_networks\lstm.py"", line 2, in <module>
    from keras.models import Sequential
  File ""D:\Uni\SS 20\Computerlinguistische Anwendungen\jophya\src\venv\lib\site-packages\keras\__init__.py"", line 6, in <module>
    'Keras requires TensorFlow 2.2 or higher. '
ImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`



Assertion failed

Assertion failed


Ran 1 test in 0.050s

FAILED (errors=1)

Process finished with exit code 1

Assertion failed

Assertion failed



Has anybody any advise?
Thank you in advance
**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
41098,TFlite runtime wheel not supported,"**System information**
- Ubuntu 20.04 with linux kernel 5.7.1
- Bare Python 3.8.2 and Conda Env with Python 3.7.6

**The problem**
 
When trying to install *tflite_runtime* I get the following error:
```
$ pip3 install https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-linux_x86_64.whl
ERROR: tflite_runtime-2.1.0.post1-cp37-cp37m-linux_x86_64.whl is not a supported wheel on this platform.
```
I've tried a bare installation in Python 3.8.2 and in a conda environment with python 3.7.6. Same error for each try."
41097,Unexpected crash when loading a modified saved_model.pb file,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.0.2-0-g2c2fdd3205 2.0.2

- Python version:
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): clang++ 10.0
- CUDA/cuDNN version: No
- GPU model and memory: No

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I used the LibFuzzer to mutate an intact saved_model.pb file and uses `LoadSavedModel` C API to load it.
Instead of returning a `Status` whose `.ok()` is `false`, the program directly crashes with following errors:

```
2020-06-20 15:29:05.816403: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /home/xxx/Playground/tensorflow/saved_model/crashes
2020-06-20 15:29:05.817167: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }
2020-06-20 15:29:05.829727: I tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/map.h:1059] CHECK failed: it != end(): key not found: value
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: it != end(): key not found: value
[1]    26722 abort (core dumped)  ./loader_test
```
**Describe the expected behavior**
Since `LoadSavedModel` returns an `Status` object, the `Status.ok()` should return `false`, rather than a direct crash.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```c++
#include ""tensorflow/cc/saved_model/loader.h""
#include ""tensorflow/cc/saved_model/constants.h""
#include ""tensorflow/cc/saved_model/tag_constants.h""

#include <fstream>
using namespace tensorflow;
int main(){
        const string export_dir = ""/home/xxx/Playground/saved_model/intact""; // original pb file --> Status.ok() == true
        const string export_dir2 = ""/home/xxx/Playground/saved_model/test""; // modified pb file --> Status.ok() == false
        const string export_dir3 = ""/home/xxx/Playground/saved_model/crashes""; // modified pb file --> crash
        SavedModelBundle bundle;
        SessionOptions session_options;
        RunOptions run_options;
	    std::cout<<""hello""<<std::endl;
        if(LoadSavedModel(session_options, run_options, export_dir, {kSavedModelTagServe}, &bundle).ok()){
		std::cout<<""Load Successful!""<<std::endl;
	}
	std::cout<<""-------------------------""<<std::endl;
	if(LoadSavedModel(session_options, run_options, export_dir2, {kSavedModelTagServe}, &bundle).ok()){
		std::cout<<""Load Successful!""<<std::endl;
	}
	std::cout<<""-------------------------""<<std::endl;
	if(LoadSavedModel(session_options, run_options, export_dir3, {kSavedModelTagServe}, &bundle).ok()){
		std::cout<<""Load Successful!""<<std::endl;
	}
	std::cout<<""-------------------------""<<std::endl;

    }
```
[saved_model.zip](https://github.com/tensorflow/tensorflow/files/4874697/saved_model.zip)
[libfuzzer output.txt](https://github.com/tensorflow/tensorflow/files/4874698/libfuzzer.output.txt)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

I attached three saved_model.pb files and the log of libfuzzer as well.

**Personal understanding**
I think the following codes in `tensorflow/core/grappler/costs/graph_properties.cc` lead to the error
```c++
  Status MaybeUpdateNodeContextOutput(const NodeDef& node, const bool is_fed,
                                      NodeContext* c) {
    // Propagate tensors and shape tensors unless the node is fed.
    // TODO(bsteiner) We should still propagate the shapes to the ports that
    // aren't fed in the case of a ShapeN node.

    InferenceContext* ic = c->inference_context.get();
    if (!is_fed) {
      if (IsConstant(node)) {
        c->output_tensor_protos.resize(1);
        const TensorProto& tensor_proto = node.attr().at(""value"").tensor(); // at(""xx"") if ""xx"" does not exist will bring a crash
```
Once the `value` attribute cannot be obtained, an exception will be thrown."
41095,categorical_crossentropy with label smoothing support on tf.bfloat,"It seems that when enabling label smoothing, categorical_crossentropy only supports inputs in float32, so not useful when using tf.bfloat on TPU. I changed it to the following to make it work:
```
from tensorflow.python.framework import ops
from tensorflow.python.ops import math_ops
from tensorflow.python.framework import smart_cond
from tensorflow.python.keras import backend as K
from tensorflow.python.ops import array_ops

def categorical_crossentropy(y_true,
                             y_pred,
                             from_logits=False,
                             label_smoothing=0):

  y_pred = ops.convert_to_tensor_v2(y_pred)
  y_true = math_ops.cast(y_true, y_pred.dtype)
  label_smoothing = ops.convert_to_tensor_v2(label_smoothing, dtype=tf.bfloat16)

  def _smooth_labels():
    num_classes = math_ops.cast(array_ops.shape(y_true)[1], y_pred.dtype)
    return y_true * (1.0 - label_smoothing) + (label_smoothing / num_classes)

  y_true = smart_cond.smart_cond(label_smoothing,
                                 _smooth_labels, lambda: y_true)
  return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)
```"
41094,TFLite inference is slower than benchmark reported,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 4
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2.0
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
While I benchmark the tflite model using the benchmark tool, latency is only 6ms. However, when I actually run this inside an apk, the latency increases to 11ms. I'm wondering if it's due to the usage of buffer copy? Do they actually take that much time (~4ms)? Could you please suggest an alternative option that would be faster?

**Describe the expected behavior**

**Standalone code to reproduce the issue**

```
void mask_speech(const float* input, float* mask) {
    TfLiteTensor* tflite_input = TfLiteInterpreterGetInputTensor(interpreter, 0);
    TfLiteTensorCopyFromBuffer(tflite_input, input, NUM_INPUT * sizeof(float));
    TfLiteInterpreterInvoke(interpreter);
    const TfLiteTensor* tflite_output = TfLiteInterpreterGetOutputTensor(interpreter, 0);
    TfLiteTensorCopyToBuffer(tflite_output, mask, NUM_OUTPUT * sizeof(float));
}
```

Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41093,tf.keras.layers.DepthwiseConv2D and tf.keras.layers.SeparableConv2D does not handle kernel regularizer correctly.,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS 7.3
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: NA
-   **TensorFlow installed from (source or binary)**: binary, from anaconda
-   **TensorFlow version (use command below)**: 2.2.0
-   **Python version**: 3.7.7
-   **Bazel version (if compiling from source)**: NA
-   **GCC/Compiler version (if compiling from source)**: NA
-   **CUDA/cuDNN version**: 10.1 / 7.6.5
-   **GPU model and memory**: NVIDIA Tesla V100 / 32GB
-   **Exact command to reproduce**: Source code below

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

kernel_regularizer parameter on tf.keras.layers.DepthwiseConv2D and  tf.keras.layers.SeparableConv2D does not register the loss to model losses, despite of bias_regularizer works. I'll describe full test code below.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Expected case 1: Dense layer
```python
m = tf.keras.models.Sequential()
m.add(tf.keras.layers.Dense(3, input_dim=5, kernel_regularizer=tf.keras.regularizers.l2(1.0E-01), bias_regularizer=tf.keras.regularizers.l2(1.0E-01)))
m.add(tf.keras.layers.Dense(3, input_dim=5, kernel_regularizer=tf.keras.regularizers.l2(1.0E-01)))
print(m.losses)
```
Output:
```
[<tf.Tensor: shape=(), dtype=float32, numpy=0.19434488>,
 <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,
 <tf.Tensor: shape=(), dtype=float32, numpy=0.22874394>]
```

Expected case 2: Conv2D layer
```python
m = tf.keras.models.Sequential()
m.add(tf.keras.layers.Input(32, 32, 3))
m.add(tf.keras.layers.Conv2D(3, 3, kernel_regularizer=tf.keras.regularizers.l2(1.0E-01), bias_regularizer=tf.keras.regularizers.l2(1.0E-01)))
m.add(tf.keras.layers.Conv2D(3, 3, kernel_regularizer=tf.keras.regularizers.l2(1.0E-01)))
print(m.losses)
```
Output:
```
[<tf.Tensor: shape=(), dtype=float32, numpy=0.29766324>,
 <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,
 <tf.Tensor: shape=(), dtype=float32, numpy=0.7301255>]
```

Expected case 3: ConvLSTM2D layer
```python
m = tf.keras.models.Sequential()
m.add(tf.keras.layers.Input(3, 32, 32, 3))
m.add(tf.keras.layers.ConvLSTM2D(3, 3, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(1.0E-01), bias_regularizer=tf.keras.regularizers.l2(1.0E-01)))
m.add(tf.keras.layers.ConvLSTM2D(3, 3, kernel_regularizer=tf.keras.regularizers.l2(1.0E-01)))
print(m.losses)
```
Output:
```
[<tf.Tensor: shape=(), dtype=float32, numpy=0.47271797>,
 <tf.Tensor: shape=(), dtype=float32, numpy=0.3>,
 <tf.Tensor: shape=(), dtype=float32, numpy=0.49562755>]
```



Does not expected case 1: DepthwiseConv2D layer
```python
m = tf.keras.models.Sequential()
m.add(tf.keras.layers.Input(32, 32, 3))
m.add(tf.keras.layers.DepthwiseConv2D(3, 3, kernel_regularizer=tf.keras.regularizers.l2(1.0E-01), bias_regularizer=tf.keras.regularizers.l2(1.0E-01)))
m.add(tf.keras.layers.DepthwiseConv2D(3, 3, kernel_regularizer=tf.keras.regularizers.l2(1.0E-01)))
print(m.losses)
```
Output:
```
[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>]
```

Does not expected case 2: SeparableConv2D layer
```python
m = tf.keras.models.Sequential()
m.add(tf.keras.layers.Input(32, 32, 3))
m.add(tf.keras.layers.SeparableConv2D(3, 3, kernel_regularizer=tf.keras.regularizers.l2(1.0E-01), bias_regularizer=tf.keras.regularizers.l2(1.0E-01)))
m.add(tf.keras.layers.SeparableConv2D(3, 3, kernel_regularizer=tf.keras.regularizers.l2(1.0E-01)))
print(m.losses)
```
Output:
```
[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>]
```

Am I have a mistake using regularizer with these layers?"
41092,Unable to use tf-hub models locally,"I've been working on a task using bert model [.](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2) As per the instructions I've added the line:

bert_layer = hub.KerasLayer(""https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2"", trainable=True)

But problem comes when it downloads the model again on every run. That's annoying. I've already spent a lot of time on searching How to download and work with tf-hub models . But i got no proper answer. That's why I'm here for guidance from official tf team.

I've downloaded the .tar.gz file from https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2 and extracted the file. It contains <assets, variable, saved_model.pb>.

I've tried this
`
os.environ[""TFHUB_CACHE_DIR""] = r'C:\Users\devendra\PycharmProjects\NeuralMachineTranslation\tf_hub'

handle = ""https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2""
hashlib.sha1(handle.encode(""utf8"")).hexdigest()
print(hashlib.sha1(handle.encode(""utf8"")).hexdigest())  #to rename directory


embed = hub.load(""https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2"")
print('Loaded')
print(embed)
`
but it is giving me error:
`FileNotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C:\Users\devendra\PycharmProjects\NeuralMachineTranslation\tf_hub/ce53fe6769d2ac3a260e92555120c54e1aecbea6/variables/variables
 If trying to load on a different device from the computational device, consider using setting the `experimental_io_device` option on tf.saved_model.LoadOptions to the io_device such as '/job:localhost'.
`

I've using tensorflow and tf-hub latest upto the version on Ubuntu 18.04

 Now please guide me how to use the model properly and efficiently. Please provide concerned information and script. Thanking You."
41091,Loaded runtime CuDNN library: 7.3.1 but source was compiled with: 7.5.0.,"**I have checked everywhere else for a solution and this is my last resort**
Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:no
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Windows 10 v2004
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:conda/pip (unsure bc installed with both b4)
-   **TensorFlow version**: 1.13.2 gpu
-   **Python version**: 3.7
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**: 10.0 + 7.5.0 , 9.2 + 7.5.0 and 9.0 7.5.0
-   **GPU model and memory**: GTX 1060 6g
-   **Exact command to reproduce**: 

### Describe the problem
It says i have cudnn 7.3.1 but I haven't / don't think I have installed it at any point and have only ever installed 7.5.0.

### Source code / logs
020-07-05 01:42:25.906817: E tensorflow/stream_executor/cuda/cuda_dnn.cc:324] Loaded runtime CuDNN library: 7.3.1 but source was compiled with: 7.5.0.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
2020-07-05 01:42:25.916794: E tensorflow/stream_executor/cuda/cuda_dnn.cc:324] Loaded runtime CuDNN library: 7.3.1 but source was compiled with: 7.5.0.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
"
41090,Issue using segment_prod in custom keras layer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- TensorFlow installed from (source or binary): nightly
- TensorFlow version (use command below): nightly
- Python version: colab


I'm trying to write a custom keras layer that uses `segment_prod` on model features, i.e., not the batch dimension. To do that, I've been using tf.transpose to put the feature dimensions first, and then transposing the resulting calculation. Forward calculation seems to work using this approach, but there appears to be an issue with gradients with `segment_prod`: the following code fails with `LookupError: gradient registry has no entry for: SegmentProd`:

```python
class MyLayer1(layers.Layer):

  def call(self, inputs):

    segments = tf.constant([0, 0, 0, 1, 1])
    return tf.transpose(
        tf.math.segment_prod(tf.transpose(inputs), segments))

inputs = layers.Input(10)
embed = layers.Embedding(20, 5)(inputs)
output = MyLayer1()(embed)
output = layers.GlobalAveragePooling1D()(output)
model = tf.keras.Model(inputs, output)

X = np.random.randint(20, size=(100, 10))
y = np.random.randn(100,2)

model.compile(loss='mae')
model.fit(X, y)
```


Replacing `tf.math.segment_prod` with other operations, like `tf.math.unsorted_segment_prod(..., num_segments=2)` or `tf.math.segment_sum` seems to work, however.

Colab gist:
https://colab.research.google.com/gist/pstjohn/8fa2faf274679742ba628290a94c2b2b/untitled0.ipynb"
41089,Invalid link in documentation to code: https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb,"TensorFlow documentation issue. 

## URL(s) with the issue:
The link/page not found(404); ""images -> object detection API"" under https://www.tensorflow.org/tutorials/
namely: https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb

## Description of issue (what needs changing):
Material was moved to https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb"
41087,Tensorflow Check failed: status == CUDNN_STATUS_SUCCESS (7 vs. 0)Failed to set cuDNN stream,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 8.1
- TensorFlow installed from (source or binary): Conda installation
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.10
- CUDA version: 10.1.243
- cuDNN version:  7.6.5 (windows 7)
- GPU model and memory: GTX 1060 6GB

**Describe the current behavior**
When I run my tensorflow keras model it will sometimes stop after an epoch and throw the following error:

```
    tensorflow/stream_executor/dnn.cc:613] CUDNN_STATUS_EXECUTION_FAILED
    in tensorflow/stream_executor/cuda/cuda_dnn.cc(1867): 'cudnnRNNForwardTraining( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.handles(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_desc.handle(), output_c_data->opaque(), workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'
    2020-06-27 17:19:45.741256: F tensorflow/stream_executor/cuda/cuda_dnn.cc:189] Check failed: status == CUDNN_STATUS_SUCCESS (7 vs. 0)Failed to set cuDNN stream.
```


**Describe the expected behavior**
It should run the model without any crashes.

**Standalone code to reproduce the issue**
Im using the GPU version of tensorflow and it has worked without problems up until about 3 days ago when it began giving me this error. I also have the following callbacks in my model so that it saves checkpoints and epochs locally. Please note I am using Autokeras thus why the nodes have the ak. library prefix. However it works just like keras, it just automatically tries to find the best set of hyperparameters when running the .fit function.

```
input_node = ak.Input()
    #output_node1 = ak.Normalization()(input_node)
    output_node1 = ak.RNNBlock(return_sequences=True,
                               layer_type='lstm')(input_node)
    output_node2 = ak.RNNBlock(return_sequences=True,
                               layer_type='lstm')(output_node1)
    output_node3 = ak.RNNBlock(return_sequences=True,
                               layer_type='lstm')(output_node2)
    output_node4 = ak.RNNBlock(layer_type='lstm')(output_node3)
    output_node5 = ak.DenseBlock()(output_node4)
    output_node = ak.Merge()(
        [output_node1, output_node2, output_node3, output_node4, output_node5])
    output_nodefinal = ak.ClassificationHead()(output_node)
    
    my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True, monitor=""val_accuracy"", mode=""auto""),
                    tf.keras.callbacks.ModelCheckpoint(filepath=""D:\AutoKerasProject\TimeseriesCallbackModel\TimeseriesCallbackModel"", save_weights_only=True, monitor='val_accuracy', mode='auto', save_best_only=True)]
    
    classifier = ak.AutoModel(
        inputs=input_node, outputs=output_nodefinal, max_trials=500, directory=""D:\AutoKerasProject\TimeseriesModel"", overwrite=True)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41086,FAILED: Build did NOT complete successfully,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.13
- Python version: 3.6
- Installed using virtualenv? pip? conda?: Conda
- Bazel version (if compiling from source): 0.21.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: just building for CPU
- GPU model and memory: GTX 980

I am following the instructions laid out in this tutorial (starting at Step 2) to convert my model for use by tflite:
https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#part-1---how-to-train-convert-and-run-custom-tensorflow-lite-object-detection-models-on-windows-10

everything seems to work find until I try and build using babel with this command:
> bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

It start off fine and runs for a while but then fails with this output:

INFO: From Linking tensorflow/python/gen_lookup_ops_py_wrappers_cc.exe:
   Creating library bazel-out/x64_windows-opt/bin/tensorflow/python/gen_lookup_ops_py_wrappers_cc.lib and object bazel-out/x64_windows-opt/bin/tensorflow/python/gen_lookup_ops_py_wrappers_cc.exp
INFO: From Linking tensorflow/python/gen_script_ops_py_wrappers_cc.exe:
   Creating library bazel-out/x64_windows-opt/bin/tensorflow/python/gen_script_ops_py_wrappers_cc.lib and object bazel-out/x64_windows-opt/bin/tensorflow/python/gen_script_ops_py_wrappers_cc.exp
INFO: From Linking tensorflow/python/gen_bitwise_ops_py_wrappers_cc.exe:
   Creating library bazel-out/x64_windows-opt/bin/tensorflow/python/gen_bitwise_ops_py_wrappers_cc.lib and object bazel-out/x64_windows-opt/bin/tensorflow/python/gen_bitwise_ops_py_wrappers_cc.exp
INFO: From Linking tensorflow/python/gen_ragged_conversion_ops_py_wrappers_cc.exe:
   Creating library bazel-out/x64_windows-opt/bin/tensorflow/python/gen_ragged_conversion_ops_py_wrappers_cc.lib and object bazel-out/x64_windows-opt/bin/tensorflow/python/gen_ragged_conversion_ops_py_wrappers_cc.exp
INFO: From Linking tensorflow/python/gen_ragged_math_ops_py_wrappers_cc.exe:
   Creating library bazel-out/x64_windows-opt/bin/tensorflow/python/gen_ragged_math_ops_py_wrappers_cc.lib and object bazel-out/x64_windows-opt/bin/tensorflow/python/gen_ragged_math_ops_py_wrappers_cc.exp
**ERROR: C:/tensorflow-build/tensorflow/tensorflow/python/BUILD:293:1: C++ compilation of rule '//tensorflow/python:bfloat16_lib' failed (Exit 2): cl.exe failed: error executing command**
  cd C:/users/james/_bazel_james/j7bi4x5j/execroot/org_tensorflow
  SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE;C:\Program Files (x86)\Windows Kits\10\include\10.0.10240.0\ucrt;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.6\include\um;C:\Program Files (x86)\Windows Kits\8.1\include\shared;C:\Program Files (x86)\Windows Kits\8.1\include\um;C:\Program Files (x86)\Windows Kits\8.1\include\winrt;
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\BIN\amd64;C:\WINDOWS\Microsoft.NET\Framework64\v4.0.30319;C:\WINDOWS\Microsoft.NET\Framework64\;C:\Program Files (x86)\Windows Kits\8.1\bin\x64;C:\Program Files (x86)\Windows Kits\8.1\bin\x86;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.6 Tools\x64\;;C:\WINDOWS\system32
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/ProgramData/Anaconda3/envs/tensorflow-build/python.exe
    SET PYTHON_LIB_PATH=C:/ProgramData/Anaconda3/envs/tensorflow-build/lib/site-packages
    SET TEMP=C:\Users\james\AppData\Local\Temp
    SET TF_DOWNLOAD_CLANG=0
    SET TF_NEED_CUDA=0
    SET TF_NEED_OPENCL_SYCL=0
    SET TF_NEED_ROCM=0
    SET TMP=C:\Users\james\AppData\Local\Temp
  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_python /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python /Ibazel-out/x64_windows-opt/bin/external/local_config_python /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/lmdb /Ibazel-out/x64_windows-opt/genfiles/external/lmdb /Ibazel-out/x64_windows-opt/bin/external/lmdb /Iexternal/org_sqlite /Ibazel-out/x64_windows-opt/genfiles/external/org_sqlite /Ibazel-out/x64_windows-opt/bin/external/org_sqlite /Iexternal/png_archive /Ibazel-out/x64_windows-opt/genfiles/external/png_archive /Ibazel-out/x64_windows-opt/bin/external/png_archive /Iexternal/icu /Ibazel-out/x64_windows-opt/genfiles/external/icu /Ibazel-out/x64_windows-opt/bin/external/icu /Iexternal/grpc /Ibazel-out/x64_windows-opt/genfiles/external/grpc /Ibazel-out/x64_windows-opt/bin/external/grpc /Iexternal/com_github_nanopb_nanopb /Ibazel-out/x64_windows-opt/genfiles/external/com_github_nanopb_nanopb /Ibazel-out/x64_windows-opt/bin/external/com_github_nanopb_nanopb /Iexternal/boringssl /Ibazel-out/x64_windows-opt/genfiles/external/boringssl /Ibazel-out/x64_windows-opt/bin/external/boringssl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_python/numpy_include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python/numpy_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/numpy_include /Iexternal/local_config_python/python_include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python/python_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/python_include /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cuda/include/crt /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include/crt /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include/crt /Iexternal/png_archive /Ibazel-out/x64_windows-opt/genfiles/external/png_archive /Ibazel-out/x64_windows-opt/bin/external/png_archive /Iexternal/icu/icu4c/source/common /Ibazel-out/x64_windows-opt/genfiles/external/icu/icu4c/source/common /Ibazel-out/x64_windows-opt/bin/external/icu/icu4c/source/common /Iexternal/grpc/include /Ibazel-out/x64_windows-opt/genfiles/external/grpc/include /Ibazel-out/x64_windows-opt/bin/external/grpc/include /Iexternal/grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/genfiles/external/grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/bin/external/grpc/third_party/address_sorting/include /Iexternal/boringssl/src/include /Ibazel-out/x64_windows-opt/genfiles/external/boringssl/src/include /Ibazel-out/x64_windows-opt/bin/external/boringssl/src/include /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /DSQLITE_OMIT_DEPRECATED /DGRPC_ARES=0 /DPB_FIELD_32BIT=1 /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=""redacted"" -D__TIMESTAMP__=""redacted"" -D__TIME__=""redacted"" /Gy /Gw -w /arch:AVX /Fobazel-out/x64_windows-opt/bin/tensorflow/python/_objs/bfloat16_lib/bfloat16.obj /c tensorflow/python/lib/core/bfloat16.cc
Execution platform: @bazel_tools//platforms:host_platform
**tensorflow/python/lib/core/bfloat16.cc(634): error C2664: 'bool tensorflow::`anonymous-namespace'::Initialize::<lambda_d0df84676ae54709cf34c880a157d294>::operator ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void *)' to 'PyUFuncGenericFunction'
tensorflow/python/lib/core/bfloat16.cc(634): note: None of the functions with this name in scope match the target type**
tensorflow/python/lib/core/bfloat16.cc(638): error C2664: 'bool tensorflow::`anonymous-namespace'::Initialize::<lambda_d0df84676ae54709cf34c880a157d294>::operator ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void *)' to 'PyUFuncGenericFunction'
tensorflow/python/lib/core/bfloat16.cc(638): note: None of the functions with this name in scope match the target type
tensorflow/python/lib/core/bfloat16.cc(641): error C2664: 'bool tensorflow::`anonymous-namespace'::Initialize::<lambda_d0df84676ae54709cf34c880a157d294>::operator ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void *)' to 'PyUFuncGenericFunction'
tensorflow/python/lib/core/bfloat16.cc(641): note: None of the functions with this name in scope match the target type
tensorflow/python/lib/core/bfloat16.cc(645): error C2664: 'bool tensorflow::`anonymous-namespace'::Initialize::<lambda_d0df84676ae54709cf34c880a157d294>::operator ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void *)' to 'PyUFuncGenericFunction'
tensorflow/python/lib/core/bfloat16.cc(645): note: None of the functions with this name in scope match the target type
tensorflow/python/lib/core/bfloat16.cc(649): error C2664: 'bool tensorflow::`anonymous-namespace'::Initialize::<lambda_d0df84676ae54709cf34c880a157d294>::operator ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void *)' to 'PyUFuncGenericFunction'
tensorflow/python/lib/core/bfloat16.cc(649): note: None of the functions with this name in scope match the target type
tensorflow/python/lib/core/bfloat16.cc(653): error C2664: 'bool tensorflow::`anonymous-namespace'::Initialize::<lambda_d0df84676ae54709cf34c880a157d294>::operator ()(const char *,PyUFuncGenericFunction,const std::array<int,3> &) const': cannot convert argument 2 from 'void (__cdecl *)(char **,npy_intp *,npy_intp *,void *)' to 'PyUFuncGenericFunction'
tensorflow/python/lib/core/bfloat16.cc(653): note: None of the functions with this name in scope match the target type
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 107.347s, Critical Path: 59.11s
INFO: 206 processes: 206 local.
**FAILED: Build did NOT complete successfully**
"
41085,Converting RESIZE_NEAREST_NEIGHBOR,"**System information**
- OS Ubuntu 20.04
- TensorFlow installed from binary
- TensorFlow version (2.1,2.2,2.3)-Explained below

**Command used to run the converter or code if youre using the Python API**
import tensorflow as tf
import numpy as np
import sys

if len(sys.argv) < 2:
    print(f""Usage: %s model.h5"" % (sys.argv[0]))
    sys.exit(1)

model = tf.keras.models.load_model(sys.argv[1])
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
def representative_dataset_gen():
  for _ in range(250):
    data = np.random.uniform(0.0, 1.0, size=(1, 416, 416, 3)).astype(np.float32)
    yield [data]
converter.representative_dataset = representative_dataset_gen
tflite_model = converter.convert()

with open('out.tflite', ""wb"") as f:
    f.write(tflite_model)`

**The output from the converter invocation**
error: failed while converting: 'main'
Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag): ResizeNearestNeighbor

**h5 model**
https://drive.google.com/file/d/1iYGntXy-uAiIwxhlfOQEopqNacCPM5_P/view?usp=sharing
**Explanation of the whole problem**
https://github.com/google-coral/edgetpu/issues/152
**In short**
I tried to run the model on Coral TPU and I ran into a problem when I converted the model to .tflite using tf 2.2 and 2.3 because when I went to convert this .tflite model using edgetpu_compiler I got an error:
Edge TPU Compiler version 2.1.302470888
ERROR: Didn't find op for builtin opcode 'RESIZE_NEAREST_NEIGHBOR' version '3'

ERROR: Registration failed.

Invalid model: yolo_rcj.tflite
Model could not be parsed.

But when I used older versions of tf (1.15,2.0) I got this error:
error: failed while converting: 'main'
Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag): ResizeNearestNeighbor
But when I used TensorFlow 2.1 to convert, it worked. 

I am writing this problem because I think it will be a problem in the future"
41084,Wrong Error message,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
For 1d dimension error, it shows 2d error message.
But on using 1d's property it works.

**Describe the expected behavior**
It should raise an error saying that input dimension should be 3

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41083,Requirement already up to date when running pip install --upgrade tensorflow. Stuck at version 1.14.0,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Rasbian GNU/Linux 10
- TensorFlow installed from: python3 -m pip
- TensorFlow version: 1.14.0 trying to get to 2.+
- Python version: 3.7.3
- Installed using virtualenv: pip
- CUDA/cuDNN version: Not sure, this is an off-the-shelf Raspberry Pi 4
- GPU model and memory: ^



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I tend to write scripts on my MacBook Pro and transfer them to my Raspberry Pi to run indefinitely. I set up my first LTSM network (so excited) and got it predicting and training. Brought it to the Pi, it threw an error while training complaining about the shape. After much googling I found a github issue where someone said this was fixed in tensorflow 2. Realized the pi was running tensorflow 1.14.0.

Long story short I've gone through all of the system requirements (upgrade pip, python is correct version, raspbian is correct version) and when I run `pip install --upgrade tensorflow` the console prints `Requirement already up to date: tensorflow....` and tensorflow remains at 1.14.0.


**Any other info / logs**
I figure this is a system requirement issue but it seems like the Raspberry Pi satisfies everything."
41081,Zero AUROC when validation set is only comprised of positive labels,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Tested on Ubuntu 18.04 and MacOS Catalina 10.15.5
- TensorFlow installed from (source or binary): installed from Conda (tensorflow-gpu) on Ubuntu and from pip on MacOS
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.6 (on both machines)
- CUDA/cuDNN version: 11.0 (on Ubuntu machine)
- GPU model and memory: 4 NVIDIA V100 GPUs

**Describe the current behavior**
The AUROC is zero when there are no negatives in the validation set. This may lead users to believe that the model is not performing correctly, while it is just an error related to a misuse of the AUROC metric.

**Describe the expected behavior**
The AUROC should be NaN when no negatives are present in the validation set. This way the user is aware that there is something wrong with the metric that is being used, with the possibility to add a warning since there is a 0/0 somewhere in the computation of the AUROC.

**Standalone code to reproduce the issue**
```python
from tensorflow.keras.metrics import AUC
metric = AUC()
metric.update_state([1, 1, 1], [1, 0.5, 0.3])
metric.result()
```

I believe that similar issues also happen for other metrics, as uncanny values were displayed also for Recall and Precision, but I have not identified a simple reproducible example."
41080,Relink `/usr/local/lib/libtensorflow_framework.so.2' with `/lib/x86_64-linux-gnu/libz.so.1' for IFUNC symbol `crc32_z',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: libtensorflow nightly build
- Python version: 
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: NVIDIA Quadro RTX5000


I have a trained model which I want to execute from my c++ program. My c++ program is a big piece of software that also uses google protocol buffers/ Intel MKL / Intel IPP / Boost. Linking goes through when I link to libtensorflow c API. However, when I run my exe I get a segmentation fault with the message given in subject line. If I write a separate program with libtensorflow without using any of the other dependencies mentioned above, things work fine.

1) Downloaded nightly build of libtensorflow (other older versions also lead to the same crash)
2) compiled and linked my main program. Execution results in crash
3) Execution works fine if I run with a sample code without linking to other libraries mentioned above


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
41078,Dataset error with uc_merced dataset,"**System information**
- Using Google Colab's default TF installation
- TensorFlow version: 2.2.0
- Python version: 3.6

**Describe the current behavior**
Dataset's samples are not all of the expected 256x256x3 shape, I found 44 out of 2100 samples with different shape. Currently, during preprocessing, I have to rescale the image if necessary.

**Describe the expected behavior**
All samples should have 256x256x3 shape.

**Standalone code to reproduce the issue**
```
import tensorflow.compat.v2 as tf
import tensorflow_datasets as tfds

dataset, info = tfds.load('uc_merced',
                            split='train',
                            as_supervised=True,
                            with_info=True,
                            shuffle_files=True)

exp_shape = (256, 256, 3)
n = 0
for sample in dataset.take(-1):
    if sample[0].shape != exp_shape:
        n += 1

print('Found {} samples with wrong shape'.format(n))
```

**Other info / logs**
`Found 44 samples with wrong shape`

**Additional notes**
This may seem to be a problem with the original dataset (http://weegee.vision.ucmerced.edu/datasets/landuse.html). If a fix is not possible, it may be a good idea to add a note in the documentation page https://www.tensorflow.org/datasets/catalog/uc_merced to let new users know about the issue.
Alternatively, a possible solution that the user would have to implement is something like:
```
def correct_dims(x, y):
    some_resizing_function(x, (256, 256, 3))
```
and after loading the dataset:
```
dataset = dataset.map(correct_dims)
```
"
41077,docs: code style: says to install clang-tidy then examples use clang-format,"## URL(s) with the issue:

https://www.tensorflow.org/community/contribute/code_style

## Description of issue (what needs changing):

Docs say to install `clang-tidy` but the example given says to run `clang-format`. Is this intended? I would have expected to run `clang-tidy`."
41076,"tf.data, construct a batch with different data? Are there easy ways to do it? TensorFlow1.15","I want to construct a batch of data with batchsize 16, using `tf.data`, where `[:8]` is a kind of data A, `[8:16]` is a kind of data B.

It is easy to do without `tf.data`. If use `tf.data`, the code could be:

```
def _decode_record(record, name_to_features):
    example = tf.parse_single_example(record, name_to_features)
    return example

dataA = tf.data.TFRecordDataset(input_files)
dataA = dataA.apply(
            tf.contrib.data.map_and_batch(
                lambda record: _decode_record(record, name_to_features),
                batch_size=batch_size)
           )
```
How to do it next? I try:
```
dataB = tf.data.TFRecordDataset(input_files2)
dataB = dataB.apply(
            tf.contrib.data.map_and_batch(
                lambda record: _decode_record(record, name_to_features),
                batch_size=batch_size)
           )
dataC = dataA.concatenate(dataB) 
```
But `concatenate` is: Append the whole dataset `dataB` to the end of `dataA`.

For `concatenate`, note that `name_to_features` should be same for `dataA` and `dataB`, which means I should pad a lot dummy data.

I don't want to use `tf.cond` or `tf.where` to judge different data inside the `model_fn` of `tf.estimator`, where it is also very hard to debug.

Are there easy ways to do it?

Thank you."
41075,TPU errro InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified;,"TPU is not working with any version greater than TF 2.2.0 . Even in TF 2.2.0, it gets stuck indefinitely. 

https://colab.research.google.com/gist/legacyai/0895547e3d7fa573aab03a2073afff7e/tpu.ipynb"
41074,"All operations are tensorflow operations, or wrapped with @tf.function, but still getting ""NotImplementedError: TPUStrategy.run(fn, ...) does not support pure eager execution. please make sure the function passed into strategy.run is a tf.function...""","
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom code

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab, python 3 default. 

- TensorFlow installed from (source or binary): Google Colab, python 3 default. 

- TensorFlow version (use command below):  tensorflow:2.2.0
- Python version: 3.6.9
- GPU model and memory: Using colab TPU

**Describe the current behavior** 

Even though I wrapped all my functions, and am only using Tensorflow functions, I get this error 

>NotImplementedError: TPUStrategy.run(fn, ...) does not support pure eager execution. please make sure the function passed into strategy.run is a tf.function or strategy.run is called inside a tf.function if eager behavior is enabled.



**Describe the expected behavior**

Model should train on TPU without 

**Standalone code to reproduce the issue**

Here is a colab notebook that reproduces the error. 

https://colab.research.google.com/drive/11Yo1mdnKA3DqZCr_UpZI4umY8tpBpDzS?usp=sharing

The code also needs a datafile on GCP, since it is training on a TPU. Here's a link to the sample data file. 

https://drive.google.com/file/d/106gSmcClyshu98SDQ9VsUVOhd-LYamVq/view?usp=sharing

```
%tensorflow_version 2.x
!pip install transformers --q

!gcloud auth login

'''NEED TO RUN THIS CELL TWICE TO AVOID ERROR'''

from google.colab import auth
auth.authenticate_user()

project_id = 'machinelearning-264918'
!gcloud config set project {project_id}

!pip install tfa-nightly
import tensorflow_addons as tfa

from transformers import TFBertModel, AutoModel, TFRobertaModel
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import (Dense,
                                     Dropout)
import tensorflow_addons as tfa
import numpy as np
import os
from copy import deepcopy 
from time import time

logger = tf.get_logger()
logger.info(tf.__version__)

autotune = tf.data.experimental.AUTOTUNE

try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
    print('strategy.num_replicas_in_sync', strategy.num_replicas_in_sync)
    logger.info('Running with TPUStrategy on TPU {} with {} cores '
                .format(tpu.cluster_spec().as_dict()['worker'],
                        strategy.num_replicas_in_sync))
    batch_size = 16 * strategy.num_replicas_in_sync
except Exception:
    # raise ValueError
    strategy = tf.distribute.OneDeviceStrategy(device='/gpu:0')
    logger.warning('Failed initializing TPU! Running on GPU')
    batch_size = 16

class Dora_A(tf.keras.Model):
    def __init__(self, **kwargs):
        super(Dora_A, self).__init__(**kwargs)
        self.bioRoberta = TFRobertaModel.from_pretrained('allenai/biomed_roberta_base', from_pt=True)

    def call(self, inputIds):
        queryInputs, passageInputs = inputIds

        Q_outputs = self.bioRoberta(queryInputs)[0]
        P_outputs = self.bioRoberta(passageInputs)[0]

        dotProductMatrix = tf.linalg.matmul(Q_outputs, P_outputs, transpose_b=True, name='mm')

        return dotProductMatrix

@tf.function
def loss_fn(_, probs):
    '''
        1. Every sample is its own positive, and  the rest of the
            elements in the batch are its negative.
        2. Each TPU core gets 1/8 * global_batch_size elements, hence
            compute shape dynamically.
        3. Dataset produces dummy labels to make sure the loss_fn matches
            the loss signature of keras, actual labels are computed inside this
            function.
        4. Inputs are logits, for better numerical stability.
    '''
    bs = tf.shape(probs)[0]
    labels = tf.eye(bs, bs)
    return tf.losses.categorical_crossentropy(labels,
                                              probs,
                                              from_logits=True)

CLS_inputID = tf.constant([0])
SEP_inputID = tf.constant([2])

@tf.function
def _parse_example(example_proto):
    features = {
        'bioRoberta_SentenceIndex': tf.io.VarLenFeature( dtype=tf.int64),
        'BioRoberta_IDs': tf.io.VarLenFeature( dtype=tf.int64),
    }

    parsed_example_dict = tf.io.parse_single_example(example_proto, features)
    bertIds = parsed_example_dict['BioRoberta_IDs']
    bertIds = tf.sparse.to_dense(bertIds)
    bertIds = tf.cast(bertIds, dtype=tf.int32)

    queryPiece = tf.slice(bertIds, [0], [510])
    restPassagePiece = tf.slice(bertIds, [0], [510])
    # add special tokens for proper input into the model 
    queryBertInput = tf.concat( [CLS_inputID, queryPiece, SEP_inputID], axis=0)
    paragraphBertInput = tf.concat( [CLS_inputID, restPassagePiece, SEP_inputID], axis=0)

    return queryBertInput, paragraphBertInput

config_name = 'model_a'
base_dir = 'gs://a-dora-semantic-scholar'
model_dir = os.path.join(base_dir, config_name)
tensorboard_dir = os.path.join(model_dir, 'logs_' + str(time()))
tfrecords_pattern_train = os.path.join(base_dir, 'VersionA_00022*')
tfrecords_pattern_val = os.path.join(base_dir, 'VersionA_00022*')


if 'COLAB_TPU_ADDR' in os.environ:
    print('Setting tf.data objects')
    with strategy.scope():
        filenames = tf.io.gfile.glob(tfrecords_pattern_train)
        train_dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=autotune)
        train_dataset = train_dataset.map(
                                        _parse_example, num_parallel_calls=autotune)
        train_dataset = train_dataset.shuffle(130_000, seed=1000, reshuffle_each_iteration=True)
        train_dataset = train_dataset.padded_batch(batch_size, padding_values=(1, 1))
        train_dataset = train_dataset.prefetch(autotune)
        train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())

with strategy.scope():
    model = Dora_A(dynamic=True)
    model.layers[0].trainable = False
    model.compile(loss=loss_fn,
                    optimizer=tfa.optimizers.AdamW(weight_decay=1e-5, 
                                                   learning_rate=1e-5, 
                                                   epsilon=1e-06))

model.fit(train_dataset)
```

**Other Attempts to fix** 

I decorated the call function, so that my model class looked like this

```
class Dora_A(tf.keras.Model):
    def __init__(self, **kwargs):
        super(Dora_A, self).__init__(**kwargs)
        self.bioRoberta = TFRobertaModel.from_pretrained('allenai/biomed_roberta_base', from_pt=True)

    @tf.function
    def call(self, inputIds):
        queryInputs, passageInputs = inputIds

        Q_outputs = self.bioRoberta(queryInputs)[0]
        P_outputs = self.bioRoberta(passageInputs)[0]

        dotProductMatrix = tf.linalg.matmul(Q_outputs, P_outputs, transpose_b=True, name='mm')

        return dotProductMatrix
```

But I got the same error message. 

I also tried decorating my tf.data parse function

I tried disabling eager execution, but got an error when trying to compile the model. 

It seems that when eager mode is disabled, I can not use distributed strategies for a subclassed model. The error message is
>ValueError: We currently do not support distribution strategy with a `Sequential` model that is created without `input_shape`/`input_dim` set in its first layer or a subclassed model.
This happens during `model.compile`.

Here is a link to a different colab notebook I tried for this 

https://colab.research.google.com/drive/1OhFgxbFoAEsLCDqpwBbe3P8owdJHMcUZ?usp=sharing

Here is a related questionhttps://stackoverflow.com/questions/60444486/use-tf-distribute-strategies-with-tf-keras-model-subclassing


It's been suggested either to use the sequential or functional API, but it seems that I can only use model subclassing. I am unable to use Sequential in the non-minimalized version of my architecture because it has two pipelines. And the functional api has its own issues, which I describe it in this github issue ( https://github.com/tensorflow/tensorflow/issues/40638#event-3468314954 ) but the summary is somehow the functional api seems to be deleting model weights and whole layers for my architecture. 

**Other info / logs** 

```
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
<ipython-input-12-50bee5f74f82> in <module>()
----> 1 model.fit(train_dataset)

4 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
    846                 batch_size=batch_size):
    847               callbacks.on_train_batch_begin(step)
--> 848               tmp_logs = train_function(iterator)
    849               # Catch OutOfRangeError for Datasets of unknown size.
    850               # This blocks until the batch has finished executing.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in train_function(iterator)
    570       data = next(iterator)
    571       outputs = self.distribute_strategy.run(
--> 572           self.train_step, args=(data,))
    573       outputs = reduce_per_replica(
    574           outputs, self.distribute_strategy, reduction='first')

/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py in run(self, fn, args, kwargs, options)
    166   def run(self, fn, args=(), kwargs=None, options=None):
    167     """"""See base class.""""""
--> 168     validate_run_function(fn)
    169 
    170     # Note: the target function is converted to graph even when in Eager mode,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py in validate_run_function(fn)
    104       and not (callable(fn) and isinstance(fn.__call__, def_function.Function)):
    105     raise NotImplementedError(
--> 106         ""TPUStrategy.run(fn, ...) does not support pure eager ""
    107         ""execution. please make sure the function passed into ""
    108         ""`strategy.run` is a `tf.function` or ""

NotImplementedError: TPUStrategy.run(fn, ...) does not support pure eager execution. please make sure the function passed into `strategy.run` is a `tf.function` or `strategy.run` is called inside a `tf.function` if eager behavior is enabled.
```

**StackOverflow Question** 

I also put a stack overflow question for this issue, in case I may have overlooked something, but it's been up for a few days, with a bounty, and no further insights. 

https://stackoverflow.com/questions/62650379/error-when-running-on-tpu-notimplementederror-tpustrategy-runfn-does-n
"
41073,tf.feature_column.shared_embeddings cannot be saved,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.15.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CPU only
- GPU model and memory: CPU only

**Describe the current behavior**
![ 2020-07-04 10 29 16](https://user-images.githubusercontent.com/4080524/86503500-3a340380-bde1-11ea-823c-66f2d55f715c.jpg)

**Describe the expected behavior**
should save the model successfully

**Standalone code to reproduce the issue**
```py
import tensorflow as tf
from tensorflow import feature_column
tf.compat.v1.disable_eager_execution()

# Define categorical colunm for our text feature, which is preprocessed into sequence of tokens
text_column = feature_column.sequence_categorical_column_with_vocabulary_list(key='text', vocabulary_list=list(['asd', 'asdf']))

max_length = 6
sequence_feature_layer_inputs = {}
sequence_feature_layer_inputs['text'] = tf.keras.Input(
    shape=(max_length,), name='text', dtype=tf.string)

text_embedding = feature_column.shared_embeddings([text_column], dimension=64)

# below is ok to save
# text_embedding = feature_column.embedding_column(text_column, dimension=8)

# Define SequenceFeatures layer to pass feature_columns into Keras model
sequence_feature_layer = tf.keras.experimental.SequenceFeatures(text_embedding)

# note here that SequenceFeatures layer produce tuple of two tensors as output. We need just first to pass next.
sequence_feature_layer_outputs, _ = sequence_feature_layer(
    sequence_feature_layer_inputs)
x = tf.keras.layers.Conv1D(8, 4)(sequence_feature_layer_outputs)
x = tf.keras.layers.MaxPooling1D(2)(x)
x = tf.keras.layers.Dense(256, activation='relu')(x)
x = tf.keras.layers.Dropout(0.2)(x)
x = tf.keras.layers.GlobalAveragePooling1D()(x)
# This example supposes binary classification, as labels are 0 or 1
x = tf.keras.layers.Dense(1, activation='sigmoid')(x)

model = tf.keras.models.Model(
    inputs=[v for v in sequence_feature_layer_inputs.values()], outputs=x)

model.summary()

# This example supposes binary classification, as labels are 0 or 1
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy']
              #run_eagerly=True
              )

model.save('model.h5')
```
"
41071,version cocossd 2.0.4 does not work use 2.0.3 model,so after the update 2.0.4 for coco-ssd cdn kept saying issues about loadmodelgraph undefined so I thought I would let you guys know to use 2.0.3 with this https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.0.3 in your script tags otherwise you have have bad time cuz it didnt work when I just had https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd right after da update liek bro u gonna just make a new version dat ruin everyding.  LOL but ye jus bein bro lul
41069,Edge TPU Compiler Failed to Compile,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS
- TensorFlow installed from (source or binary): anaconda
- TensorFlow version (or github SHA if from source): 2.2.0
- Edge TPU Compiler version 2.1.302470888

**Command used to run the converter or code if youre using the Python API**

```
edgetpu_compiler quantized.tflite
```

**The output from the converter invocation**

```
Edge TPU Compiler version 2.1.302470888
ERROR: :129 std::abs(input_product_scale - bias_scale) <= 1e-6 * std::min(input_product_scale, bias_scale) was not true.
ERROR: Node number 40 (FULLY_CONNECTED) failed to prepare.
```

**Failure details**
I have used the same quantizing and converting to tflite code before and it works fine on a different structured model. I use it to convert .h5 keras models to tflite models. It works if I create a model based off MobileNet with additional dense layers
```
base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(200,200,3), dropout=.2)
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
x = Dense(1024, activation='relu')(x)
x = Dense(512,activation='relu')(x)
types = Dense(20,activation='softmax')(x)
model = Model(inputs=base_model.input,outputs=types)
```

But if I try to convert model with 2 outputs like this, I get the aformentioned error when compiling.
```
base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(200,200,3), dropout=.2)
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
x = Dense(1024, activation='relu')(x)
x = Dense(512,activation='relu')(x)
types = Dense(20,activation='softmax')(x)

y = base_model.output
y = GlobalAveragePooling2D()(y)
y = Dense(512, activation='relu')(y)
y = Dense(1024, activation='relu')(y)
y = Dense(512, activation='relu')(y)
values = Dense(3, activation='sigmoid')(y)

model = Model(inputs=base_model.input, outputs=[types,values])
```

I can get the same error if I attempt to load the quantized model.
```
interpreter = tf.lite.Interpreter(model_path='path/to/model/quantized.tflite')
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

print(""shape:"", output_details[0]['shape'])
print(""shape:"", output_details[1]['shape'])
```
Output is as expected:
```
shape: [ 1 20]
shape: [1 3]
```

If I then
```
#reshape for input of batch size 32
interpreter.resize_tensor_input(input_details[0]['index'], (32, 200, 200, 3))
interpreter.resize_tensor_input(output_details[0]['index'], (32, 20))
#interpreter.resize_tensor_input(output_details[1]['index'], (32, 3))
interpreter.allocate_tensors()
```
**Output:**
```
RuntimeError                              Traceback (most recent call last)
 in 
      3 interpreter.resize_tensor_input(output_details[0]['index'], (32, 20))
      4 # interpreter.resize_tensor_input(output_details[1]['index'], (32, 3))
----> 5 interpreter.allocate_tensors()
      6 

~/Software/anaconda3/envs/Tensorflow2/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter.py in allocate_tensors(self)
    245   def allocate_tensors(self):
    246     self._ensure_safe()
--> 247     return self._interpreter.AllocateTensors()
    248 
    249   def _safe_to_run(self):

~/Software/anaconda3/envs/Tensorflow2/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py in AllocateTensors(self)
    108 
    109     def AllocateTensors(self):
--> 110         return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
    111 
    112     def Invoke(self):

RuntimeError: tensorflow/lite/kernels/kernel_util.cc:106 std::abs(input_product_scale - bias_scale) <= 1e-6 * std::min(input_product_scale, bias_scale) was not true.Node number 40 (FULLY_CONNECTED) failed to prepare.
```
Again, this error does not occur when the model has one output."
41067,TypeError: can't pickle _thread.RLock objects while using cross_validate,"Hi,

I had a keras model and I converted that to scikit model using kerasclassifier but looks like there is some issue with how I am transforming object.


I am getting this error while using the cross_validate function @ https://github.com/Neetu162/DeepLearningResearch/blob/677d1ddeb6f345716a457b977c26cbe14efa7bb0/Demo/classify_demo.py#L83
```
  File ""/home/osboxes/anaconda3/lib/python3.7/site-packages/joblib/parallel.py"", line 797, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File ""/home/osboxes/anaconda3/lib/python3.7/queue.py"", line 167, in get
    raise Empty
Empty
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""/home/osboxes/DeepLearningResearch/Demo/classify_demo.py"", line 171, in <module>
    main()
  File ""/home/osboxes/DeepLearningResearch/Demo/classify_demo.py"", line 83, in main
    cv_result = cross_validate(model, perm_inputs_1, cv=5, return_train_score=True, n_jobs=1)
  File ""/home/osboxes/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py"", line 73, in inner_f
    return f(**kwargs)
  File ""/home/osboxes/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py"", line 248, in cross_validate
    for train, test in cv.split(X, y, groups))
  File ""/home/osboxes/anaconda3/lib/python3.7/site-packages/joblib/parallel.py"", line 1004, in __call__
    if self.dispatch_one_batch(iterator):
  File ""/home/osboxes/anaconda3/lib/python3.7/site-packages/joblib/parallel.py"", line 808, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File ""/home/osboxes/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py"", line 248, in <genexpr>
    for train, test in cv.split(X, y, groups))
  File ""/home/osboxes/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py"", line 73, in inner_f
    return f(**kwargs)
  File ""/home/osboxes/anaconda3/lib/python3.7/site-packages/sklearn/base.py"", line 87, in clone
    new_object_params[name] = clone(param, safe=False)
  File ""/home/osboxes/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py"", line 73, in inner_f
    return f(**kwargs)
  File ""/home/osboxes/anaconda3/lib/python3.7/site-packages/sklearn/base.py"", line 71, in clone
    return copy.deepcopy(estimator)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/home/osboxes/anaconda3/lib/python3.7/copy.py"", line 169, in deepcopy
    rv = reductor(4)
TypeError: can't pickle _thread.RLock objects
```

Is there anything incorrect on how I am using the KerasClassifier or cross_validate ?"
41066,Rename tf.nn.swish to tf.nn.silu to give appropriate credit,"The swish was originally coined the ""SiLU"" in https://arxiv.org/pdf/1606.08415.pdf and https://arxiv.org/abs/1702.03118 long before the swish paper. Renaming other peoples' exact same ideas is unacceptable and tensorflow's naming convention implicitly erases the research and work of people outside of Google.
This request inspired by a [recent discussion](https://www.reddit.com/r/MachineLearning/comments/hkiyir/r_google_has_a_credit_assignment_problem_in/), but this problem has been brought up every few months for the past few years. In light of recent efforts to make the ML community more equitable and _fair_, this is a no-brainer and long overdue.

**Will this change the current api? How?**
tf.nn.swish ought to be renamed tf.nn.silu and both of the aforementioned papers will be cited in the documentation. At the very least they should be documented in the swish documentation already."
41063,How to load tensorflow lite during the reboot process ,"Hi, 

I am using Raspberry Pi 4, Model B, 8 GB RAM, Raspbian OS, Python 3.7. 
I am running on an object detection script that uses edgetpu.tflite model.  It works perfectly. Now I am trying to run that script automatically when I power up the Pi. 

I have tried this solution: 

    sudo nano /home/pi/.bashrc

add 

    echo Running at boot 
    sudo python /home/pi/sample.py

it gives me this error: 
    
        Running at boot
    Traceback (most recent call last):
      File ""sample.py"", line 92, in <module>
        from tensorflow.lite.python.interpreter import Interpreter
    ModuleNotFoundError: No module named 'tensorflow'


How can I run the script which uses modules like TensorFlow and TensorFlow Lite during the reboot or at the power-up? 

"
41062,Memory error when Tensorflow 2 tries to allocate memory on GPU,"**System information**
- OS - Linux Ubuntu 20.04 LTS
- TensorFlow installed inside virtualenv using pip
- TensorFlow version = 2.2.0
- Python version = 3.8.2
- CUDA Version = 11.0
- GPU model = NVIDIA GeForce GTX 1080, memory = 11175MiB


**Describe the problem**

My nvidia driver has crushed recently, so I had to reinstall it. I managed to install cuda (v 11.0), cudnn and the nvidia driver (450.36.06). I run the nvidia tests (on mnist) and it passed (I could follow the GPU utilization via nvidia-smi). 
After installing the Tensorflow 2.2. in venv using pip, I run into some problems with symbolic links. Doing

```python
import tensorflow as tf

tf.test.is_gpu_available()
```
returned ``False``and run into problem such as this
``
2020-07-03 10:24:44.272145: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib64:
``
I fixed the above by manually adding the missing links (using ``sudo ln -s ``) inside ``/usr/local/cuda-11.0/lib64``. 

Having fixed the problems with symlinks I run ``sudo ldconfig`` with clean output.
Now I have the following output in python
```python
import tensorflow as tf

print( ""\n"".join( [str(s) for s in  tf.config.list_physical_devices() ]  ) )
# outputs
# PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')
# PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU')
# PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')
# PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')

tf.test.is_gpu_available()
# returns True
```

The problem I encounter currently, is with memory allocation on GPU. Doing 
```python
import tensorflow as tf

t = tf.random.uniform(shape=[10, 20], dtype=tf.float32)

# crushes with 
# 2020-07-03 16:01:39.472212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device #(/job:localhost/replica:0/task:0/device:GPU:0 with 9845 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
#python: malloc.c:2379: sysmalloc: Assertion `(old_top == initial_top (av) && old_size == 0) || ((unsigned long) (old_size) >= #MINSIZE && prev_inuse (old_top) && ((unsigned long) old_end & (pagesize - 1)) == 0)' failed.
#Aborted (core dumped)
```

Any ideas why Tensorflow cannot utilize GPU when cuda and cudnn are properly installed ?


**Logs**

```
Python 3.8.2 (default, Apr 27 2020, 15:53:34) 
[GCC 9.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> 
>>> import tensorflow as tf
>>> 
>>> tf.test.is_gpu_available()
WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
2020-07-03 15:59:14.239096: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-03 15:59:14.267287: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3000000000 Hz
2020-07-03 15:59:14.267698: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0c24000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-03 15:59:14.267710: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-03 15:59:14.269133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-03 15:59:14.360070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 15:59:14.360411: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f783c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-03 15:59:14.360425: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-07-03 15:59:14.360526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 15:59:14.360784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2020-07-03 15:59:14.360901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-03 15:59:14.362118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-03 15:59:14.362697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-03 15:59:14.362817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-03 15:59:14.364159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-03 15:59:14.364461: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-03 15:59:14.364529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-03 15:59:14.364584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 15:59:14.364873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 15:59:14.365113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-03 15:59:14.365133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-03 15:59:14.365478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-03 15:59:14.365487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-03 15:59:14.365491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-03 15:59:14.365544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 15:59:14.365811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 15:59:14.366070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/device:GPU:0 with 9845 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
True
>>> 
>>> t = tf.random.uniform(shape=[10, 20], dtype=tf.float32)
2020-07-03 16:01:39.467677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 16:01:39.468289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2020-07-03 16:01:39.468335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-03 16:01:39.468351: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-03 16:01:39.468363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-03 16:01:39.468374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-03 16:01:39.468386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-03 16:01:39.468397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-03 16:01:39.468408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-03 16:01:39.468459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 16:01:39.468843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 16:01:39.469303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-03 16:01:39.469608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 16:01:39.470192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2020-07-03 16:01:39.470212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-03 16:01:39.470222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-03 16:01:39.470232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-03 16:01:39.470241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-03 16:01:39.470250: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-03 16:01:39.470260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-03 16:01:39.470270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-03 16:01:39.470306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 16:01:39.470799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 16:01:39.471223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-03 16:01:39.471245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-03 16:01:39.471250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-03 16:01:39.471255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-03 16:01:39.471310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 16:01:39.471776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-03 16:01:39.472212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9845 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
python: malloc.c:2379: sysmalloc: Assertion `(old_top == initial_top (av) && old_size == 0) || ((unsigned long) (old_size) >= MINSIZE && prev_inuse (old_top) && ((unsigned long) old_end & (pagesize - 1)) == 0)' failed.
Aborted (core dumped)
```


```
$nvidia-smi
Fri Jul  3 16:06:39 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  On   | 00000000:01:00.0  On |                  N/A |
| 13%   55C    P0    63W / 250W |    572MiB / 11175MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1225      G   /usr/lib/xorg/Xorg                 35MiB |
|    0   N/A  N/A      1672      G   /usr/lib/xorg/Xorg                193MiB |
|    0   N/A  N/A      1877      G   /usr/bin/gnome-shell              130MiB |
|    0   N/A  N/A      3326      G   ...AAAAAAAAA= --shared-files      191MiB |
+-----------------------------------------------------------------------------+
```

```
$nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Wed_May__6_19:09:25_PDT_2020
Cuda compilation tools, release 11.0, V11.0.167
Build cuda_11.0_bu.TC445_37.28358933_0
```
"
41061,C++ compilation of rule '//tensorflow/python:bfloat16_lib' failed (Exit 1) tensorflow/python/lib/core/bfloat16.cc,"I'm trying to build tf 1.15 from source (cpu-only), in order to convert an object detection model to tflite.

<pre>bazel build --config=v1 //tensorflow/tools/pip_package:build_pip_package
</pre>
------------------------

### System information


-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04
-   **TensorFlow installed from (source or binary)**: source
-   **TensorFlow version (use command below)**: 1.15
-   **Python version**: 3.8
-   **Installed using virtualenv? pip? conda?: conda
-   **Bazel version (if compiling from source)**: 0.26.1
-   **GCC/Compiler version (if compiling from source)**: 7.5.0

<pre><font color=""#CC0000""><b>ERROR: </b></font>/home/user/tensorflow/tensorflow/python/BUILD:329:1: C++ compilation of rule &apos;//tensorflow/python:bfloat16_lib&apos; failed (Exit 1)
tensorflow/python/lib/core/bfloat16.cc: In function &apos;bool tensorflow::{anonymous}::Initialize()&apos;:
tensorflow/python/lib/core/bfloat16.cc:634:36: error: no match for call to &apos;(tensorflow::{anonymous}::Initialize()::&lt;lambda(const char*, PyUFuncGenericFunction, const std::array&lt;int, 3&gt;&amp;)&gt;) (const char [6], &lt;unresolved overloaded function type&gt;, const std::array&lt;int, 3&gt;&amp;)&apos;
                       compare_types)) {
                                    ^
tensorflow/python/lib/core/bfloat16.cc:608:60: note: candidate: tensorflow::{anonymous}::Initialize()::&lt;lambda(const char*, PyUFuncGenericFunction, const std::array&lt;int, 3&gt;&amp;)&gt;
                             const std::array&lt;int, 3&gt;&amp; types) {
                                                            ^
tensorflow/python/lib/core/bfloat16.cc:608:60: note:   no known conversion for argument 2 from &apos;&lt;unresolved overloaded function type&gt;&apos; to &apos;PyUFuncGenericFunction {aka void (*)(char**, const long int*, const long int*, void*)}&apos;
tensorflow/python/lib/core/bfloat16.cc:638:36: error: no match for call to &apos;(tensorflow::{anonymous}::Initialize()::&lt;lambda(const char*, PyUFuncGenericFunction, const std::array&lt;int, 3&gt;&amp;)&gt;) (const char [10], &lt;unresolved overloaded function type&gt;, const std::array&lt;int, 3&gt;&amp;)&apos;
                       compare_types)) {
                                    ^
tensorflow/python/lib/core/bfloat16.cc:608:60: note: candidate: tensorflow::{anonymous}::Initialize()::&lt;lambda(const char*, PyUFuncGenericFunction, const std::array&lt;int, 3&gt;&amp;)&gt;
                             const std::array&lt;int, 3&gt;&amp; types) {
                                                            ^
tensorflow/python/lib/core/bfloat16.cc:608:60: note:   no known conversion for argument 2 from &apos;&lt;unresolved overloaded function type&gt;&apos; to &apos;PyUFuncGenericFunction {aka void (*)(char**, const long int*, const long int*, void*)}&apos;
tensorflow/python/lib/core/bfloat16.cc:641:77: error: no match for call to &apos;(tensorflow::{anonymous}::Initialize()::&lt;lambda(const char*, PyUFuncGenericFunction, const std::array&lt;int, 3&gt;&amp;)&gt;) (const char [5], &lt;unresolved overloaded function type&gt;, const std::array&lt;int, 3&gt;&amp;)&apos;
   if (!register_ufunc(&quot;less&quot;, CompareUFunc&lt;Bfloat16LtFunctor&gt;, compare_types)) {
                                                                             ^
tensorflow/python/lib/core/bfloat16.cc:608:60: note: candidate: tensorflow::{anonymous}::Initialize()::&lt;lambda(const char*, PyUFuncGenericFunction, const std::array&lt;int, 3&gt;&amp;)&gt;
                             const std::array&lt;int, 3&gt;&amp; types) {
                                                            ^
tensorflow/python/lib/core/bfloat16.cc:608:60: note:   no known conversion for argument 2 from &apos;&lt;unresolved overloaded function type&gt;&apos; to &apos;PyUFuncGenericFunction {aka void (*)(char**, const long int*, const long int*, void*)}&apos;
tensorflow/python/lib/core/bfloat16.cc:645:36: error: no match for call to &apos;(tensorflow::{anonymous}::Initialize()::&lt;lambda(const char*, PyUFuncGenericFunction, const std::array&lt;int, 3&gt;&amp;)&gt;) (const char [8], &lt;unresolved overloaded function type&gt;, const std::array&lt;int, 3&gt;&amp;)&apos;
                       compare_types)) {
                                    ^
tensorflow/python/lib/core/bfloat16.cc:608:60: note: candidate: tensorflow::{anonymous}::Initialize()::&lt;lambda(const char*, PyUFuncGenericFunction, const std::array&lt;int, 3&gt;&amp;)&gt;
                             const std::array&lt;int, 3&gt;&amp; types) {
                                                            ^
tensorflow/python/lib/core/bfloat16.cc:608:60: note:   no known conversion for argument 2 from &apos;&lt;unresolved overloaded function type&gt;&apos; to &apos;PyUFuncGenericFunction {aka void (*)(char**, const long int*, const long int*, void*)}&apos;
tensorflow/python/lib/core/bfloat16.cc:649:36: error: no match for call to &apos;(tensorflow::{anonymous}::Initialize()::&lt;lambda(const char*, PyUFuncGenericFunction, const std::array&lt;int, 3&gt;&amp;)&gt;) (const char [11], &lt;unresolved overloaded function type&gt;, const std::array&lt;int, 3&gt;&amp;)&apos;
                       compare_types)) {
                                    ^
tensorflow/python/lib/core/bfloat16.cc:608:60: note: candidate: tensorflow::{anonymous}::Initialize()::&lt;lambda(const char*, PyUFuncGenericFunction, const std::array&lt;int, 3&gt;&amp;)&gt;
                             const std::array&lt;int, 3&gt;&amp; types) {
                                                            ^
tensorflow/python/lib/core/bfloat16.cc:608:60: note:   no known conversion for argument 2 from &apos;&lt;unresolved overloaded function type&gt;&apos; to &apos;PyUFuncGenericFunction {aka void (*)(char**, const long int*, const long int*, void*)}&apos;
tensorflow/python/lib/core/bfloat16.cc:653:36: error: no match for call to &apos;(tensorflow::{anonymous}::Initialize()::&lt;lambda(const char*, PyUFuncGenericFunction, const std::array&lt;int, 3&gt;&amp;)&gt;) (const char [14], &lt;unresolved overloaded function type&gt;, const std::array&lt;int, 3&gt;&amp;)&apos;
                       compare_types)) {
                                    ^
tensorflow/python/lib/core/bfloat16.cc:608:60: note: candidate: tensorflow::{anonymous}::Initialize()::&lt;lambda(const char*, PyUFuncGenericFunction, const std::array&lt;int, 3&gt;&amp;)&gt;
                             const std::array&lt;int, 3&gt;&amp; types) {
                                                            ^
tensorflow/python/lib/core/bfloat16.cc:608:60: note:   no known conversion for argument 2 from &apos;&lt;unresolved overloaded function type&gt;&apos; to &apos;PyUFuncGenericFunction {aka void (*)(char**, const long int*, const long int*, void*)}&apos;
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
<font color=""#4E9A06"">INFO: </font>Elapsed time: 1344.879s, Critical Path: 142.68s
<font color=""#4E9A06"">INFO: </font>765 processes: 765 local.
<font color=""#CC0000""><b>FAILED:</b></font> Build did NOT complete successfully
</pre>

--------
I've already downgraded numpy to <1.19.0, as mentioned in [#40688](https://github.com/tensorflow/tensorflow/issues/40688), but that didn't solve the problem.

"
41060,UnknownError:    CUDNN_STATUS_BAD_PARAM,"This bug is a continuation of solving this problem:
https://github.com/tensorflow/tensorflow/issues/40877

**System information**
- Have I written custom code with tensorflow.keras.layers.LSTM layer:
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed: from source ""bazel build --config=opt --config=cuda --config=mkl --copt=-march=native //tensorflow/tools/pip_package:build_pip_package""
- TensorFlow version: v1.12.1-35676-g89798077df 2.4.0
- Python version: 3.6.9
- Bazel version: Python 3.6.9
- GCC/Compiler version: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
- CUDA/cuDNN version: 10.2 / 8.0
- GPU model and memory: NVIDIA GeForce RTX 2080 TI 11G

The previously described error no longer occurs. No less, when trying to use the LSTM layer, another error appeared
```
UnknownError                              Traceback (most recent call last)
<ipython-input-24-66b029fffc15> in <module>
      1 # train
----> 2 hist = textClassifier.train(X_train[:10000], y_train[:10000])
      3 hist

<ipython-input-21-d0b8fb2d36c8> in train(self, X, y, w2v_model, verbose, X2)
    308 
    309     def train(self, X, y, w2v_model=None, verbose=0, X2=None):
--> 310         self.fit(X, y, w2v_model, verbose, X2)
    311         return self.hist
    312 

<ipython-input-21-d0b8fb2d36c8> in fit(self, X, y, w2v_model, verbose, X2)
    301                                   epochs           = self.epochs,
    302                                   batch_size       = self.batch_size,
--> 303                                   shuffle          = False)
    304 
    305         self.model      = model

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--> 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1097                 batch_size=batch_size):
   1098               callbacks.on_train_batch_begin(step)
-> 1099               tmp_logs = train_function(iterator)
   1100               if data_handler.should_sync:
   1101                 context.async_wait()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    838         # Lifting succeeded, so variables are initialized and we can run the
    839         # stateless function.
--> 840         return self._stateless_fn(*args, **kwds)
    841     else:
    842       canon_args, canon_kwds = \

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2842     with self._lock:
   2843       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2844     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2845 
   2846   @property

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)
   1845                            resource_variable_ops.BaseResourceVariable))],
   1846         captured_inputs=self.captured_inputs,
-> 1847         cancellation_manager=cancellation_manager)
   1848 
   1849   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1921       # No tape is watching; skip to running the function.
   1922       return self._build_call_outputs(self._inference_function.call(
-> 1923           ctx, args, cancellation_manager=cancellation_manager))
   1924     forward_backward = self._select_forward_and_backward_functions(
   1925         args,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    548               inputs=args,
    549               attrs=attrs,
--> 550               ctx=ctx)
    551         else:
    552           outputs = execute.execute_with_cancellation(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

UnknownError:    CUDNN_STATUS_BAD_PARAM
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1130): 'cudnnSetRNNDescriptor_v8( rnn_desc.get(), rnn_algo, rnn_mode, bias_mode, direction_mode, input_mode, data_type, compute_type, math_type, input_size, hidden_size, cell_size, num_layers, dropout_desc.handle(), aux_flags)'
	 [[{{node CudnnRNN}}]]
	 [[functional_3/bidirectional_1/forward_lstm_1/PartitionedCall]] [Op:__inference_train_function_13519]

Function call stack:
train_function -> train_function -> train_function
```

```bash
root@RedShark:/usr# python3 -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
2020-07-03 00:10:58.059582: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
v1.12.1-35676-g89798077df 2.4.0
```
If I turn off cuda ( os.environ['CUDA_VISIBLE_DEVICES'] = '' ), everything works fine on cpu.
"
41059,C++ compilation error when building tensorflow/examples/android:tensorflow.demo,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.4
- Python version: 3.8.3
- Installed using virtualenv? pip? conda?: source
- Bazel version (if compiling from source): 3.3.0
- GCC/Compiler version (if compiling from source): Java JDK 11, Android ndk 20 and MSVS 2019
- CUDA/cuDNN version: NA
- GPU model and memory: NA


Brief description:
I have been trying to get this demo to work all week, getting various errors along the way.  However, I have run into this problem that doesn't have similar previously reported issues.  I get about 15 min into the bazel build command and it throws this error: ERROR: C:/users/adamr/tensorflow/tensorflow/examples/android/BUILD:23:10: C++ compilation of rule '//tensorflow/examples/android:libtensorflow_demo.so' failed (Exit 1): clang failed: error executing command

I have tried several versions of Android NDK and tried both MSVS 2017 and 2019. I also have msys64 installed and placed in my computers PATH.

After failed bazel build command, I clear the contents of my _bazel_adamr folder and run bazel clean --expunge.


Sequence of commands (all run on cmd):
git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git
cd tensorflow

python configure.py
***
location of python: C:\Users\adamr\AppData\Local\Programs\Python\Python38\python.exe
Python libraries: C:\Users\adamr\AppData\Local\Programs\Python\Python38\lib\site-packages
ROCm support? N
CUDA support? N
optimization flags? Default
override eigen strong inline? n
interactively configure WORKSPACE? y
Android NDK path: C:/Users/adamr/AppData/Local/Android/android-ndk-r20b
NDK API: default
Android SDK: C:/Users/adamr/AppData/Local/Android/Sdk
SDK API: 29
Build tools: 30.0.0-rc4
***


bazel build -c opt --fat_apk_cpu=armeabi-v7a --record_rule_instantiation_callstack --experimental_repo_remote_exec --verbose_failures //tensorflow/examples/android:tensorflow_demo --host_crosstool_top=@bazel_tools//tools/cpp:toolchain


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Attached error Log:
[TensoflowDemoError.txt](https://github.com/tensorflow/tensorflow/files/4869078/TensoflowDemoError.txt)

"
41058,not able to reinstall tensorflow,">>> import tensorflow
Traceback (most recent call last):
  File ""C:\Users\harsh\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\harsh\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\harsh\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\envs\gpuenv\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\envs\gpuenv\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\harsh\AppData\Roaming\Python\Python36\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\harsh\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\harsh\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\harsh\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\harsh\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\harsh\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\envs\gpuenv\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\envs\gpuenv\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime."
41057,Build from Souce Failed Dependencies cudnn_stub.cc,"Hi All,

I have not been able to figure out what I need to do to fix this error, or what I have done wrong:

> ERROR: C:/users/jason/tensorflow/tensorflow/stream_executor/cuda/BUILD:319:11: undeclared inclusion(s) in rule '//tensorflow/stream_executor/cuda:cudnn_stub': this rule is missing dependency declarations for the following files included by 'tensorflow/stream_executor/cuda/cudnn_stub.cc': 'tensorflow/stream_executor/cuda/cudnn_version.h'
> Target //tensorflow/tools/pip_package:build_pip_package failed to build
> INFO: Elapsed time: 1331.616s, Critical Path: 270.82s
> INFO: 5993 processes: 5993 local.
> FAILED: Build did NOT complete successfully

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from: source
- TensorFlow version:
- Python version: 3.7.7
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 3.3.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.0
- GPU model and memory: RTX2070
- Intel(R0 Core i9-9980HK CPU


**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
The last few steps I completed were:
1. cd tensorflow
2. python ./configure/py
  - No to ROCM support
  - Yes to CUDA support
  - Computer capability 6.1,7.5 (because I have an RTZ2070 and GTX1080TI). The second was not attached while running this.
  - Yes to eigen strong line
  - No to andriod workspace builds
3. bazel build //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
> INFO: From Compiling tensorflow/compiler/xla/shape_util.cc:
> C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.26.28801\include\numeric(35): warning C4244: '=': conversion from '_Ty' to '_Ty', possible loss of data
>         with
>         [
>             _Ty=tensorflow::int64
>         ]
>         and
>         [
>             _Ty=int
>         ]
> tensorflow/compiler/xla/shape_util.cc(1570): note: see reference to function template instantiation '_Ty std::accumulate<const __int64*,int,std::multiplies<tensorflow::int64>>(const _InIt,const _InIt,_Ty,_Fn)' being compiled
>         with
>         [
>             _Ty=int,
>             _InIt=const __int64 *,
>             _Fn=std::multiplies<tensorflow::int64>
>         ]
> INFO: From Compiling tensorflow/compiler/xla/service/hlo_lexer.cc:
> C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.26.28801\include\utility(152): warning C4244: 'initializing': conversion from '_Ty' to '_Ty2', possible loss of data
>         with
>         [
>             _Ty=google::protobuf::uint64
>         ]
>         and
>         [
>             _Ty2=unsigned int
>         ]
> tensorflow/compiler/xla/service/hlo_lexer.cc(415): note: see reference to function template instantiation 'std::pair<unsigned int,unsigned int>::pair<unsigned int&,size_t,0>(_Other1,_Other2 &&) noexcept' being compiled
>         with
>         [
>             _Other1=unsigned int &,
>             _Other2=size_t
>         ]
> tensorflow/compiler/xla/service/hlo_lexer.cc(415): note: see reference to function template instantiation 'std::pair<unsigned int,unsigned int>::pair<unsigned int&,size_t,0>(_Other1,_Other2 &&) noexcept' being compiled
>         with
>         [
>             _Other1=unsigned int &,
>             _Other2=size_t
>         ]
> ERROR: C:/users/jason/tensorflow/tensorflow/stream_executor/cuda/BUILD:319:11: undeclared inclusion(s) in rule '//tensorflow/stream_executor/cuda:cudnn_stub':
> this rule is missing dependency declarations for the following files included by 'tensorflow/stream_executor/cuda/cudnn_stub.cc':
>   'tensorflow/stream_executor/cuda/cudnn_version.h'
> Target //tensorflow/tools/pip_package:build_pip_package failed to build
> INFO: Elapsed time: 1331.616s, Critical Path: 270.82s
> INFO: 5993 processes: 5993 local.
> FAILED: Build did NOT complete successfully
"
41055,APK size increased,I am using TensorFlow posenet module but it increases my APK size drastically is there any way to reduce model size.
41054,Could not find a version that satisfies the requirement tensorflow-gpu==1.15.0,"1.15.0 version is available as can be show here:
https://pypi.org/project/tensorflow-gpu/1.15.0/

However while running the command:

> pip install tensorflow-gpu==1.15.0

I am getting the following output:

  Could not find a version that satisfies the requirement tensorflow-gpu==1.15.0 (from versions: 0.12.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.3.0, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.8.0, 1.9.0, 1.10.0, 1.10.1, 1.11.0, 1.12.0, 1.12.2, 1.12.3, 1.13.1, 1.13.2, 1.14.0, 2.0.0a0, 2.0.0b0, 2.0.0b1)
No matching distribution found for tensorflow-gpu==1.15.0
"
41053,Add a method to save and load the optimizer.,"In TensorFlow 2.2 there is the capability to save a model with its optimizer.
This is fine, but I run in situations where I want to save the weights and the optimizer separately (conflating training, metrics architecture and weights in a single model object is a bit confusing too imho).
If I try to pickle the optimizer and then reload it, it looks like the contents of the the loaded optimizer are identical to the previous one, but when training the losses are different.

I tested this by creating a model, training it for 4 epochs, collecting losses and its predictions, then training a model for 2 epochs, saving weights and pickling the optimizer, reloading it and training for 2 more epochs. I  reset the random seed where appropriate.
What happens is that, if the optimizer is stateless like SGD, the predictions and all losses are identical (so you can pickle and unpickle a stateless optimizer, good!), but if I try to use a stateful optimizer like Adam,  losses and predictions differ (although all the variables are loaded correclty, as seen from manual inspection).
This suggests that there is something missing somewhere in my code that is not obvious. A save and load mechanism for the optimizer that takes care of whatever else is needed would be greatly appreciated.

Here's my code for you to replicate the issue.

```python
import pickle

import numpy as np
import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.optimizers import Adam

#optimizer_type = SGD  # this works
optimizer_type = Adam  # this does not work

np.random.seed(42)

x = np.array(range(100), dtype=np.float32).reshape(-1, 1)
x_batched = np.split(x, 2)
y = 2 * x + 1 + np.random.normal(size=x.shape[0]).reshape(-1, 1)
y_batched = np.split(y, 2)

loss_fn = MeanSquaredError()


class MyModel(Model):
    def __init__(self):
        super().__init__()
        self.d1 = Dense(5, activation='relu', dtype=tf.float32)
        self.d2 = Dense(1, dtype=tf.float32)

    def call(self, inputs, **kwargs):
        return self.d2(self.d1(inputs))


def train_step(model, loss_fn, optimizer, x, y):
    with tf.GradientTape() as tape:
        logits = model(x, training=True)
        loss_value = loss_fn(y, logits)
    grads = tape.gradient(loss_value, model.trainable_weights)
    optimizer.apply_gradients(zip(grads, model.trainable_weights))
    return loss_value


def optimize(model, loss_fn, optimizer, epochs):
    losses = []
    for epoch in range(epochs):
        for x_batch, y_batch in zip(x_batched, y_batched):
            loss_value = train_step(model, loss_fn, optimizer, x_batch,
                                    y_batch)
            losses.append(loss_value.numpy())
    return losses


# train 4 epochs

tf.random.set_seed(42)
model = MyModel()
optimizer = optimizer_type(learning_rate=1e-3)
losses = optimize(model, loss_fn, optimizer, epochs=4)
pred = model(x_batched[0])

# train 2 epochs

tf.random.set_seed(42)
model = MyModel()
optimizer = optimizer_type(learning_rate=1e-3)
losses2 = optimize(model, loss_fn, optimizer, epochs=2)
model.save_weights('weights')
with open('opt.pkl', 'wb') as f:
    pickle.dump(optimizer, f)

# load and train 2 more epochs

model = MyModel()
model.load_weights('weights')
with open('opt.pkl', 'rb') as f:
    optimizer = pickle.load(f)
losses2.extend(optimize(model, loss_fn, optimizer, epochs=2))
pred2 = model(x_batched[0])

print(losses)
print(losses2)
print(pred)
print(pred2)

assert losses == losses2
assert np.all(pred == pred2)

```"
41051,Error with the TF Dataset -Plant_Village ,"

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Google Collab
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.2.0
- Python version:  3.6

**Describe the current behavior**

It happens when we(@Mtrejo and @DYuusha) try to use tfds.load of 'plant_village, it throws this error: 
DownloadError: Failed to get url https://data.mendeley.com/datasets/tywbtsjrjv/1/files/127d0761-7c63-46f0-b08e-d0d9f7cad9da/Plant_leaf_diseases_dataset_without_augmentation.zip. HTTP code: 404.

And it's because, the url is different from the ones in the docs.
**The correct one:** https://data.mendeley.com/datasets/tywbtsjrjv/1/files/d5652a28-c1d8-4b76-97f3-72fb80f94efc/Plant_leaf_diseases_dataset_without_augmentation.zip 

**The one in plant_village.py**: https://data.mendeley.com/datasets/tywbtsjrjv/1/files/127d0761-7c63-46f0-b08e-d0d9f7cad9da/Plant_leaf_diseases_dataset_without_augmentation.zip

**Describe the expected behavior**
Success of the tfds.load


**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1aZ4EjqnNa8g0fWg9lccdJLmr0KU4ZL8r?usp=sharing

"
41049, Failed launching ResizeNearestNeighbor,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):2.3.0-rc0
- Python version:3.6.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:7.6.5.32-1+cuda10.2
- GPU model and memory:mx150

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
tensorflow.python.framework.errors_impl.InternalError: Failed launching ResizeNearestNeighbor [Op:ResizeNearestNeighbor]
![Screenshot from 2020-07-03 13-07-02](https://user-images.githubusercontent.com/17592563/86433753-27142b80-bd2e-11ea-8eec-604f6e875fce.png)
[tf_env.txt](https://github.com/tensorflow/tensorflow/files/4867906/tf_env.txt)
**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
tf.image.resize(tf.ones([1,416,416,3]),[200,100],tf.image.ResizeMethod.NEAREST_NEIGHBOR, preserve_aspect_ratio=True)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Related https://github.com/google/automl/pull/536

I used GPU

I can't meet any bug when I ran GPU kernel tests."
41048,Can I compile the source code of TF1.10 with gcc8.3,"**I use gcc8.3, but when installing TF1.10, the error is as follows. Can I compile the source code of TF1.10 with gcc8.3**

command: `python -m joyTf/ --model deepwalk ...`

```
Log:
_OPS_PATH=/export/home/lijunli/joyGraph/joyOps/lib/libjoy_ops.so
Traceback (most recent call last):
  File ""/export/home/joyGraph-env/python_3.6/lib/python3.6/runpy.py"", line 183, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File ""/export/home/joyGraph-env/python_3.6/lib/python3.6/runpy.py"", line 142, in _get_module_details
    return _get_module_details(pkg_main_name, error)
  File ""/export/home/joyGraph-env/python_3.6/lib/python3.6/runpy.py"", line 109, in _get_module_details
    __import__(pkg_name)
  File ""/export/home/lijunli/joyGraph/joyTf/__init__.py"", line 18, in <module>
    from joyTf.python.joy_ops import *
  File ""/export/home/lijunli/joyGraph/joyTf/python/joy_ops/__init__.py"", line 22, in <module>
    from joyTf.python.joy_ops.base import initialize_graph
  File ""/export/home/lijunli/joyGraph/joyTf/python/joy_ops/base.py"", line 34, in <module>
    JOY_OPS = tf.load_op_library(_OPS_PATH)
  File ""/export/home/joyGraph-env/python_3.6/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py"", line 61, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)
tensorflow.python.framework.errors_impl.NotFoundError: /export/home/lijunli/joyGraph/joyOps/lib/libjoy_ops.so: undefined symbol: _ZN10tensorflow12OpDefBuilder4AttrENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
```

**It is strange that this error is not reported when I use tf1.10-gpu on the GPU machine, 
but it is still the same when using other tf1.x-gpu versions.
What is the cause of this error**

Thank you for the answer!
"
41046,TF Lite Interpreter: Segmentation Fault,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary, nightly
- TensorFlow version (or github SHA if from source): 2.5.0-dev20200629


**Command used to run the converter or code if youre using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
import numpy as np
import sentencepiece as spm

model_path = ""./save/use/use.tflite""
spm_path = ""./save/use/assets/universal_encoder_8k_spm.model""

sp = spm.SentencePieceProcessor()
sp.Load(spm_path)

def process_to_IDs_in_sparse_format(sp, sentences):
    # An utility method that processes sentences with the sentence piece processor
    # 'sp' and returns the results in tf.SparseTensor-similar format:
    # (values, indices, dense_shape)
    ids = [sp.EncodeAsIds(x) for x in sentences]
    max_len = max(len(x) for x in ids)
    dense_shape = (len(ids), max_len)
    values = [item for sublist in ids for item in sublist]
    indices = [[row, col] for row in range(len(ids)) for col in range(len(ids[row]))]
    values = np.array(values, dtype=np.int64)
    indices = np.array(indices, dtype=np.int64)
    dense_shape = np.array(dense_shape, dtype=np.int64)
    return (values, indices, dense_shape)

sentences = [""The quick brown fox jumps over the lazy dog.""]
values, indices, dense_shape = process_to_IDs_in_sparse_format(sp, sentences)

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=model_path)

input_details = interpreter.get_input_details()
# 0: indicies, 2: values, 3: dense shape
interpreter.resize_tensor_input(input_details[0][""index""], indices.shape)
interpreter.resize_tensor_input(input_details[1][""index""], values.shape)
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.set_tensor(input_details[0][""index""], indices)
interpreter.set_tensor(input_details[1][""index""], values)
interpreter.set_tensor(input_details[2][""index""], dense_shape)
interpreter.invoke()
p = interpreter.get_tensor(output_details[0][""index""])
```

**The output from the converter invocation**

```
2020-07-02 17:08:47.449467: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
INFO: Created TensorFlow Lite delegate for select TF ops.
2020-07-02 17:08:48.181872: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-07-02 17:08:48.207514: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2799925000 Hz
2020-07-02 17:08:48.209674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558142710b70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-02 17:08:48.209733: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-02 17:08:48.219289: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-07-02 17:08:48.272890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-02 17:08:48.273257: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5581427d67a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-02 17:08:48.273274: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060, Compute Capability 6.1
2020-07-02 17:08:48.273430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-02 17:08:48.273715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1
coreClock: 1.6705GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s
2020-07-02 17:08:48.273753: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-07-02 17:08:48.275067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-07-02 17:08:48.276322: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-07-02 17:08:48.276612: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-07-02 17:08:48.278014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-07-02 17:08:48.278841: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-07-02 17:08:48.281714: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-07-02 17:08:48.281885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-02 17:08:48.282357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-02 17:08:48.282658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-07-02 17:08:48.282721: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-07-02 17:08:48.625586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-02 17:08:48.625634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-07-02 17:08:48.625640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-07-02 17:08:48.625841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-02 17:08:48.626194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-02 17:08:48.626500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4986 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
INFO: TfLiteFlexDelegate delegate: 5 nodes delegated out of 256 nodes with 1 partitions.

Segmentation fault (core dumped)
```

**Also, please include a link to the saved model or GraphDef**

```
# Model: Univeral Sentence Encoder Lite 2
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
tf.enable_resource_variables()
import tensorflow_hub as hub


module = hub.Module(""https://tfhub.dev/google/universal-sentence-encoder-lite/2"")
input_placeholder = tf.sparse_placeholder(tf.int64, shape=[None, None])
encodings = module(inputs=dict(values=input_placeholder.values,
                               indices=input_placeholder.indices,
                               dense_shape=input_placeholder.dense_shape))
with tf.Session() as session:
    session.run([tf.global_variables_initializer(), tf.tables_initializer()])
    output_dir = ""./save/use""
    tf.saved_model.simple_save(session, output_dir,
                               inputs={""text"": input_placeholder}, outputs={""embedding"": encodings},
                               legacy_init_op=tf.tables_initializer()
                               )

# Convert to TFLite
import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model(""./save/use"")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
converter.experimental_new_converter = True
tflite_model = converter.convert()
open(""./save/use/use.tflite"", ""wb"").write(tflite_model)
```

**Failure details**

- This may be caused by the delegate ops (tf.AddV2, tf.ListDiff), but any clarity on the seg fault or how to fix it would be much appreciated.

**Any other info / logs**



"
41045,Error when loading a Subclass model with tf.keras.Sequential blocks inside ,"#### System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): pip install tensorflow-gpu
TensorFlow version: 2.2.0
Python version: 3.7.0
CUDA/cuDNN version: 11.0 / v8.0.1
GPU model and memory: NVIDIA V100
Problem encountered:


#### Problem encountered:

Please excuse me if this is not a bug but my lack of understanding on model saving. I will make it down right away if so.

I've written a code training ResNet-50 model using tf.keras.Model and tf.keras.layers.Layer APIs as below. As you can see, this a very common example of a Subclass model using tf.keras.Sequential() API as part of the model to stack Residual blocks.  

The problem is that I can save the model without any issue using 
``` model.save(MODEL_DIR, save_format='tf') ``` However, loading the trained model using ``` tf.keras.models.load_model(MODEL_DIR)``` is a pain since it throws errors like the below. I'm wondering whether using tf.keras.Sequential() API inside tf.keras.Model class possibly causes this issue. The error seems to point out that something is missing with sequential blocks. 


``` 
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-58-ce50dde7e33e> in <module>
----> 1 tf.keras.models.load_model(MODEL_DIR)

/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile)
    188     if isinstance(filepath, six.string_types):
    189       loader_impl.parse_saved_model(filepath)
--> 190       return saved_model_load.load(filepath, compile)
    191 
    192   raise IOError(

/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/load.py in load(path, compile)
    114   # TODO(kathywu): Add saving/loading of optimizer, compiled losses and metrics.
    115   # TODO(kathywu): Add code to load from objects that contain all endpoints
--> 116   model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
    117 
    118   # pylint: disable=protected-access

/opt/conda/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py in load_internal(export_dir, tags, loader_cls)
    602       loader = loader_cls(object_graph_proto,
    603                           saved_model_proto,
--> 604                           export_dir)
    605       root = loader.get(0)
    606       if isinstance(loader, Loader):

/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/load.py in __init__(self, *args, **kwargs)
    186     self._models_to_reconstruct = []
    187 
--> 188     super(KerasObjectLoader, self).__init__(*args, **kwargs)
    189 
    190     # Now that the node object has been fully loaded, and the checkpoint has

/opt/conda/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py in __init__(self, object_graph_proto, saved_model_proto, export_dir)
    121       self._concrete_functions[name] = _WrapperFunction(concrete_function)
    122 
--> 123     self._load_all()
    124     self._restore_checkpoint()
    125 

/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _load_all(self)
    213 
    214     # Finish setting up layers and models. See function docstring for more info.
--> 215     self._finalize_objects()
    216 
    217   @property

/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _finalize_objects(self)
    508 
    509     # Initialize graph networks, now that layer dependencies have been resolved.
--> 510     self._reconstruct_all_models()
    511 
    512   def _unblock_model_reconstruction(self, layer_id, layer):

/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _reconstruct_all_models(self)
    539       raise ValueError('Error when loading from SavedModel -- the following '
    540                        'models could not be initialized: {}'
--> 541                        .format(uninitialized_model_names))
    542 
    543   def _reconstruct_model(self, model_id, model, layers):

ValueError: Error when loading from SavedModel -- the following models could not be initialized: ['sequential_72', 'sequential_78', 'sequential_63', 'sequential_75', 'sequential_67', 'sequential_73', 'sequential_79', 'sequential_71', 'sequential_62', 'sequential_68', 'sequential_74', 'sequential_66']
```


Model construction 

```
class BottleNeck(tf.keras.layers.Layer):  
    expansion = 4 

    def __init__(self, in_channels, out_channels, stride=1):
        super(BottleNeck, self).__init__()
        self.conv1 = tf.keras.layers.Conv2D(filters=out_channels, kernel_size=(1, 1), use_bias=False)  
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.pad1 = tf.keras.layers.ZeroPadding2D(padding=(1, 1))
        self.conv2 = tf.keras.layers.Conv2D(filters=out_channels, kernel_size=(3, 3), strides=(stride, stride), use_bias=False) 
        self.bn2 = tf.keras.layers.BatchNormalization()
        self.conv3 = tf.keras.layers.Conv2D(filters=out_channels * BottleNeck.expansion, kernel_size=(1, 1), use_bias=False)
        self.bn3 = tf.keras.layers.BatchNormalization()
        
        self.downsample = tf.keras.Sequential()

        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:            
            self.downsample.add(tf.keras.layers.Conv2D(filters=out_channels * BottleNeck.expansion, kernel_size=(1, 1), strides=(stride, stride), use_bias=False))
            self.downsample.add(tf.keras.layers.BatchNormalization())
  
    def call(self, inputs, training=None):
        out = self.conv1(inputs)
        out = self.bn1(out)
        out = tf.nn.relu(out)

        out = self.pad1(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out = tf.nn.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)
        
        down = self.downsample(inputs)
        out += down
        out = tf.nn.relu(out)

        return out

    
class ResNet(tf.keras.Model):
    def __init__(self, dataset, block, num_blocks, num_classes):
        super(ResNet, self).__init__()        
        self.dataset = dataset
        if self.dataset.startswith('cifar'):
            self.in_channels = 64
            self.pad1 = tf.keras.layers.ZeroPadding2D(padding=(1, 1))
            self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), use_bias=False)  
            self.bn1 = tf.keras.layers.BatchNormalization()
            self.relu = tf.nn.relu

            self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)
            self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
            self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2) 
            self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2) 
            self.avgpool = tf.keras.layers.AveragePooling2D(pool_size=(4, 4))
            self.fc = tf.keras.layers.Dense(num_classes)

    def _make_layer(self, block, out_channels, num_blocks, stride=1, training=None):     
        strides = [stride] + [1] * (num_blocks - 1)
        layers = tf.keras.Sequential()        
        for stride in strides:
            layers.add(block(self.in_channels, out_channels, stride))
            self.in_channels = out_channels * block.expansion
            
        return layers

    def call(self, x, training=None):
        if self.dataset == 'cifar10' or self.dataset == 'cifar100':
            
            x = self.pad1(x)
            x = self.conv1(x)
            x = self.bn1(x)
            x = self.relu(x)
            x = self.layer1(x, training=training)
            x = self.layer2(x, training=training)
            x = self.layer3(x, training=training)
            x = self.layer4(x, training=training)
            x = self.avgpool(x)
            x = tf.keras.layers.Flatten()(x)
            x = self.fc(x)

        return x

```


"
41042,tf.keras.layers.LSTM + tf.function fails to compute jacobian with pfor on GPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `Yes`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Ubuntu 16.04`
- TensorFlow installed from (source or binary): `Binary`
- TensorFlow version (use command below): `v1.12.1-34938-g99fea8da0d 2.3.0-rc0`
- Python version: `3.7`
- CUDA/cuDNN version:
```
$ conda list | grep cud
cudatoolkit               10.1.243             h6bb024c_0
cudnn                     7.6.5                cuda10.1_0
```
- GPU model and memory: `Nvidia GeForce GTX 1080 Ti`

**Describe the current behavior**
TensorFlow crashes when computing `GradientTape.jacobian`s for an output of `tf.keras.layers.LSTM` within a `tf.function`, when running on GPU.

**Describe the expected behavior**
The graph compiles correctly and efficiently computes the jacobian.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf


batch_size, sequence_length = 2, 3

x_input = tf.keras.layers.Input(
    shape=(sequence_length, 1),
    name='input',
    dtype=tf.float32)

mask_input = tf.keras.layers.Input(
    shape=(sequence_length, ),
    name='mask',
    dtype=tf.bool)


out = tf.keras.layers.LSTM(
    units=8,
    return_sequences=True,
    return_state=False,
)(x_input, mask=mask_input)
out = tf.keras.layers.Dense(1, activation='linear')(out)
model = tf.keras.Model((x_input, mask_input), out)

x = tf.random.uniform(
    (batch_size, sequence_length, x_input.shape[-1]),
    dtype=x_input.dtype)

mask = tf.sequence_mask(
    tf.random.uniform(
        (batch_size, ), minval=0, maxval=sequence_length, dtype=tf.int32),
    maxlen=sequence_length,
)[..., ::-1]


@tf.function(experimental_relax_shapes=True)
def compute_jacobian():
    y_true = tf.zeros(batch_size)
    with tf.GradientTape() as tape:
        y = model((x, mask))
        y = tf.reduce_sum(y, axis=1)
        loss = tf.losses.MSE(y_pred=y, y_true=y_true)

    jacobian = tape.jacobian(
        loss, model.trainable_variables, experimental_use_pfor=True)

    return jacobian


jacobian = compute_jacobian()
```

**Other info / logs**
Running the above code results in a huge error trace and finally outputs:
> NotImplementedError: Vectorization tried to stack variant tensor Tensor(""gradients/while_grad/gradients/grad_ys_4/pfor/Identity:0"", shape=(), dtype=variant). This is likely because vectorization of that variant is not fully supported yet.



I know that the pfor flag is experimental, and setting `experimental_use_pfor=False` would make the code run. However, in that case the resulting graph runs so slow that it's effectively unusable even for simple 2-element jacobian. Using `parallel_iterations=10, experimental_use_pfor=False` above results in the following warning, which might have something to do with the slowness:
> 2020-07-03 08:31:26.889383: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] function_optimizer failed: Invalid argument: Input 0 of node while/enter/_15 was passed bool from functional_1/lstm/PartitionedCall:5 incompatible with expected int32.
2020-07-03 08:31:26.933046: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] layout failed: Out of range: src_output = 26, but num_outputs is only 26
2020-07-03 08:31:26.978710: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] function_optimizer failed: Invalid argument: Input 0 of node while/enter/_15 was passed bool from functional_1/lstm/PartitionedCall:5 incompatible with expected int32.
2020-07-03 08:31:27.036554: W tensorflow/core/common_runtime/process_function_library_runtime.cc:773] Ignoring multi-device function optimization failure: Invalid argument: Input 0 of node while/enter/_15 was passed bool from functional_1/lstm/PartitionedCall:5 incompatible with expected int32.


Any workarounds would also be much appreciated and I'd even be happy to contribute a fix for this if one would be doable without much c++ experience."
41041,Cuda 11.0 with cuDNN v8.0.1 problem when using GPU : libcudnn.so.7: cannot open shared object file,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Debian GNU/Linux 10 (buster)`
- TensorFlow installed from (source or binary): `binary`
- TensorFlow version: `2.2.0`
- Python version: `3.7.0`
- Installed using virtualenv: from `pyenv` using `pip`
- CUDA/cuDNN version: `11.0 / v8.0.1`
- GPU model and memory: `NVIDIA Corporation TU102 [GeForce RTX 2080 Ti Rev. A]`

**Problem encountered:**

I first installed cuda 11.0 using [runfile](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=runfilelocal):
```bash
wget http://developer.download.nvidia.com/compute/cuda/11.0.1/local_installers/cuda_11.0.1_450.36.06_linux.run
sudo sh cuda_11.0.1_450.36.06_linux.run
```
Then installed cuDNN v8.0.1 (`cuDNN Library for Linux (x86)`) following Nvidia website : [https://developer.nvidia.com/rdp/cudnn-download](https://developer.nvidia.com/rdp/cudnn-download)

```bash
tar -xzvf cudnn-x.x-linux-x64-v8.x.x.x.tgz

sudo cp cuda/include/cudnn*.h /usr/local/cuda/include
sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64
sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*
```

I configured some PATH variables into my `~/.bashrc` and reload it using `source`:
```bash
export PATH=/usr/local/cuda-11.0/bin:${PATH}
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:${LD_LIBRARY_PATH}
export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:${LD_LIBRARY_PATH}
export CUDA_HOME=/usr/local/cuda
```

**_Encountered problem_** with `libcudnn.so.7` which is not found: 
```bash
2020-07-02 21:06:53.502117: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib64:/usr/local/cuda/lib64:
2020-07-02 21:06:53.502124: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
```

The problem was as I installed cuDNN v8.0.1, hence the expected share object file is now (and cannot be found by TensorFlow):
```bash
/usr/local/cuda/lib64/libcudnn.so.8
```
I do not know if I have to reconfigure TensorFlow to tell him the cuDNN version. I fixed the problem (worst fix ever) doing:

```bash
sudo mv /usr/local/cuda/lib64/libcudnn.so.8 /usr/local/cuda/lib64/libcudnn.so.7
```

Now, TensorFlow can recognized the share object file... When lauching a neural network training script, now my GPU is used and seems to work well:
```bash
I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
...
Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10211 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:2d:00.0, compute capability: 7.5)
```

Can you please tell me how I can fix this problem following a better way always using my virtualenv ?
"
41040,'Tensor' object has no attribute '_numpy' for `concat`,"Hi! 
I'm working on a custom implementation of Physics Informed Deep Learning model from [this paper](https://arxiv.org/abs/1711.10561) and while rewriting a snippet with custom gradient it turns out to be not working for me for latest tensorflow version. 

I've rewritten [this snippet](https://github.com/maziarraissi/PINNs/blob/master/appendix/continuous_time_inference%20(Burgers)/Burgers.py#L105):

```python3
self.x_u_tf = tf.placeholder(tf.float32, shape=[None, self.x_u.shape[1]])
self.t_u_tf = tf.placeholder(tf.float32, shape=[None, self.t_u.shape[1]])  
self.net_f(self.x_f_tf, self.t_f_tf)

def net_u(self, x, t):
    u = self.neural_net(tf.concat([x,t],1), self.weights, self.biases)
    return u
    
def net_f(self, x,t):
    u = self.net_u(x,t)
    u_t = tf.gradients(u, t)[0]
    u_x = tf.gradients(u, x)[0]
    u_xx = tf.gradients(u_x, x)[0]
    f = u_t + u*u_x - self.nu*u_xx
```

to the latest API with GradientTape (**link to collab notebook with error below**) and it throws `AttributeError: 'Tensor' object has no attribute '_numpy'` for `g.gradient(ur, x)`. It turns out that for case without `concat` it works so it looks like `concat` changed behavior.
Example from the paper is operational for older version so I would be thankful for help figuring out this `concat` issue. 

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.5
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.7

**Describe the current behavior**
`GradientTape.gradient()` throws `AttributeError: 'Tensor' object has no attribute '_numpy'` for a case that older tensorflow version has been working.

**Standalone code to reproduce the issue**

Reproduced error in Colab: 

https://colab.research.google.com/drive/1xZ7ZRdtHazS8-gp7uqgdbNE6d-AzUOiS?usp=sharing
"
41039,Error when building tflite 2.3.0-rc0 metal delegate on macOS,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.2
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0-rc0
- Python version: 3.6.4
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 3.1.0
- GPU model and memory: AMD Radeon R9 M370X 2 GB



**Describe the problem**
The metal delegate dylib for macOS fails to build using the recommended command from the BUILD file (`tensorflow/lite/delegates/gpu/BUILD:L181`).

**Provide the exact sequence of commands / steps that you executed before running into the problem**
From `tensorflow-2.3.0-rc0/`:
```
bazel build -c opt --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt -fvisibility=default --linkopt -s --strip always --cxxopt=-std=c++14 --apple_platform_type=macos //tensorflow/lite/delegates/gpu:tensorflow_lite_gpu_dylib
```

**Any other info / logs**
Running the above command produces error log:
```
bazel build -c opt --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt -fvisibility=default --linkopt -s --strip always --cxxopt=-std=c++14 --apple_platform_type=macos //tensorflow/lite/delegates/gpu:tensorflow_lite_gpu_dylib
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=174
INFO: Reading rc options for 'build' from /Users/njassal/dev/tensorflow/tensorflow-2.3.0-rc0/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /Users/njassal/dev/tensorflow/tensorflow-2.3.0-rc0/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from /Users/njassal/dev/tensorflow/tensorflow-2.3.0-rc0/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/Users/njassal/.virtualenvs/tensorflow-2.2.0/bin/python3 --action_env PYTHON_LIB_PATH=/Users/njassal/.virtualenvs/tensorflow-2.2.0/lib/python3.6/site-packages --python_path=/Users/njassal/.virtualenvs/tensorflow-2.2.0/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=1
INFO: Found applicable config definition build:v2 in file /Users/njassal/dev/tensorflow/tensorflow-2.3.0-rc0/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /Users/njassal/dev/tensorflow/tensorflow-2.3.0-rc0/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:macos in file /Users/njassal/dev/tensorflow/tensorflow-2.3.0-rc0/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Repository io_bazel_rules_docker instantiated at:
  no stack (--record_rule_instantiation_callstack not enabled)
Repository rule git_repository defined at:
  /private/var/tmp/_bazel_njassal/c07bdfc7f101779d38a8eaaebedd6122/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18: in <toplevel>
INFO: Repository eigen_archive instantiated at:
  no stack (--record_rule_instantiation_callstack not enabled)
Repository rule tf_http_archive defined at:
  /Users/njassal/dev/tensorflow/tensorflow-2.3.0-rc0/third_party/repo.bzl:134:19: in <toplevel>
ERROR: /private/var/tmp/_bazel_njassal/c07bdfc7f101779d38a8eaaebedd6122/external/cpuinfo/BUILD.bazel:96:1: Configurable attribute ""srcs"" doesn't match this configuration (would a default condition help?).
Conditions checked:
 @cpuinfo//:linux_x86_64
 @cpuinfo//:linux_arm
 @cpuinfo//:linux_armhf
 @cpuinfo//:linux_armv7a
 @cpuinfo//:linux_armeabi
 @cpuinfo//:linux_aarch64
 @cpuinfo//:macos_x86_64
 @cpuinfo//:windows_x86_64
 @cpuinfo//:android_armv7
 @cpuinfo//:android_arm64
 @cpuinfo//:android_x86
 @cpuinfo//:android_x86_64
 @cpuinfo//:ios_x86_64
 @cpuinfo//:ios_x86
 @cpuinfo//:ios_armv7
 @cpuinfo//:ios_arm64
 @cpuinfo//:ios_arm64e
 @cpuinfo//:watchos_x86_64
 @cpuinfo//:watchos_x86
 @cpuinfo//:watchos_armv7k
 @cpuinfo//:watchos_arm64_32
 @cpuinfo//:tvos_x86_64
 @cpuinfo//:tvos_arm64
WARNING: Download from https://mirror.bazel.build/github.com/Maratyszcza/FP16/archive/4dfe081cf6bcd15db339cf2680b9281b8451eeb3.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found
ERROR: Analysis of target '//tensorflow/lite/delegates/gpu:tensorflow_lite_gpu_dylib' failed; build aborted: 

/private/var/tmp/_bazel_njassal/c07bdfc7f101779d38a8eaaebedd6122/external/cpuinfo/BUILD.bazel:96:1: Configurable attribute ""srcs"" doesn't match this configuration (would a default condition help?).
Conditions checked:
 @cpuinfo//:linux_x86_64
 @cpuinfo//:linux_arm
 @cpuinfo//:linux_armhf
 @cpuinfo//:linux_armv7a
 @cpuinfo//:linux_armeabi
 @cpuinfo//:linux_aarch64
 @cpuinfo//:macos_x86_64
 @cpuinfo//:windows_x86_64
 @cpuinfo//:android_armv7
 @cpuinfo//:android_arm64
 @cpuinfo//:android_x86
 @cpuinfo//:android_x86_64
 @cpuinfo//:ios_x86_64
 @cpuinfo//:ios_x86
 @cpuinfo//:ios_armv7
 @cpuinfo//:ios_arm64
 @cpuinfo//:ios_arm64e
 @cpuinfo//:watchos_x86_64
 @cpuinfo//:watchos_x86
 @cpuinfo//:watchos_armv7k
 @cpuinfo//:watchos_arm64_32
 @cpuinfo//:tvos_x86_64
 @cpuinfo//:tvos_arm64
INFO: Elapsed time: 0.123s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded, 0 targets configured)
```
"
41038,Accuracy Benchmarks,"Hi,

I am trying to find the baseline results for Top-1 accuraciesfor different tensorflow models .
I found more than one link. Could not decide which accuracies are latest and valid results. Below are the links for your reference. Let me know which link to be considered  for baseline/latest.

https://www.tensorflow.org/lite/performance/model_optimization 
https://blog.tensorflow.org/2020/04/quantization-aware-training-with-tensorflow-model-optimization-toolkit.html 
https://blog.tensorflow.org/2019/06/tensorflow-integer-quantization.html 
https://www.tensorflow.org/lite/guide/hosted_models 


Thank you,
Praveen.

"
41036, error: 'tfl.concatenation',"```
ConverterError                            Traceback (most recent call last)
<ipython-input-162-bce3c984534c> in <module>
      6 )
      7 converter.optimizations = [tf.lite.Optimize.DEFAULT]
----> 8 tflite_model = converter.convert()
      9 with tf.io.gfile.GFile('model.tflite', 'wb') as f:
     10   f.write(tflite_model)

~/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)
   1082           input_tensors=self._input_tensors,
   1083           output_tensors=self._output_tensors,
-> 1084           **converter_kwargs)
   1085     else:
   1086       result = _toco_convert_graph_def(

~/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    494       input_data.SerializeToString(),
    495       debug_info_str=debug_info_str,
--> 496       enable_mlir_converter=enable_mlir_converter)
    497   return data
    498 

~/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    225       stdout = _try_convert_to_unicode(stdout)
    226       stderr = _try_convert_to_unicode(stderr)
--> 227       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    228   finally:
    229     # Must manually cleanup files.

ConverterError: See console for info.
loc(""Concat_165""): error: 'tfl.concatenation' op dimension size of dimension #3 of operand #0 must be equal to dimension size of dimension #3 of output, expected 40, got 20
Traceback (most recent call last):
  File ""/home/ubuntu/anaconda3/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: <unknown>:0: error: loc(""Concat_165""): 'tfl.concatenation' op dimension size of dimension #3 of operand #0 must be equal to dimension size of dimension #3 of output, expected 40, got 20
```
I am converting a fronzen graph (.pb) to tflite and encountered this error. I have no idea why this is happen. Please help me.
Using below code for conversion.

```
import tensorflow as tf
converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(
    graph_def_file = 'weights/yolov5s_v1.pb', 
    input_arrays = ['images'],
    output_arrays = ['output','463','482'] 
)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

```"
41035,FP32 model performance is better than quant model using TFLite on raspi 3 for mobilenetv2 ,"Hi,

I have checked out the the tensorflow master and built the tflite library on raspi3. When I use the label_image.cpp and pass in the  mobilenet_v2_1.0_224.tflite and execute , its performance is better than mobilenet_v2_1.0_224_quant.tflite model .  Ideally quant model performance should better than FP32. Below are the numbers that are observed  
For FP32 -332 ms
For quant  model - 538 ms.

Is this a known issue? Could you check the same on your side and clarify.

Note: I do not see the same issue with mobilenetv1_1.0_224.tflite model. In mobilenetv1 quant model performs better than FP32.

Thank you,
Praveen.

"
41034,Error while saving a model with one layer having a list of one ragged item,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 2.3.rc0
- TensorFlow version (use command below):
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
If you try to save a model which has a layer that takes only one ragged input in a list you can save it but not load it. 

**Describe the expected behavior**
To be able to load it back. 

**Standalone code to reproduce the issue**

````
import tensorflow as tf
class Test(tf.keras.layers.Layer):
  def call(self, inputs):
    return inputs[0][0][0]

a = tf.keras.layers.Input(ragged=True, shape=(None,))
m = tf.keras.models.Model(a, Test()([a]))
m.save('test')
tf.keras.models.load_model('test')
`````
> ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (1 total):
    * tf.RaggedTensor(values=Tensor(""inputs:0"", shape=(None,), dtype=float32), row_splits=Tensor(""inputs_1:0"", shape=(None,), dtype=int64))
  Keyword arguments: {}
Expected these arguments to match one of the following 1 option(s):
Option 1:
  Positional arguments (1 total):
    * [RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int64)]
  Keyword arguments: {}




**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Link to gist: https://colab.research.google.com/gist/tanguycdls/cfbed31d313c247d2dc9d12bc19148cc/untitled20.ipynb"
41033,Abandon the use of abseil internal API absl::base_internal::NominalCPUFrequency,"Currently, an Abseil internal API is used [here](https://github.com/tensorflow/tensorflow/blob/62b6c316d2a9a1fb06aefb086856e76241280c08/tensorflow/core/platform/default/port.cc#L348), but according to Abseil's [Compatibility Guidelines](https://abseil.io/about/compatibility), the internal API should not be used outside of Abseil library.

The reason I raise this issue is that this API has been broken on s390x machines for a while, as I was trying to fix this issue, the Abseil community told me that this method was not called by any Abseil code, and Tensorflow should not depend on this API, see [here](https://github.com/abseil/abseil-cpp/pull/728#issuecomment-652044095). So even though this API is working on most architectures, I suggest abandon the use of this API and try to find an alternative one to avoid depending on Abseil internal APIs."
41032,ImportError: Traceback,"

**System information**
- Windowns 10
- 
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version: Python 3.7.7
- Installed using virtualenv? pip? conda?: pip install tensorflow    was(2.1.1)  and      pip install --upgrade tensorflow    was (2.2)
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: galaxy gt 1030 (2Gb) / 8Gb(ram)

ImportError: Traceback (most recent call last):
  File ""C:\Users\thiag\miniconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\thiag\miniconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\thiag\miniconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\thiag\miniconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\thiag\miniconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Uma rotina de inicializao da biblioteca de vnculo dinmico (DLL) falhou.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.



"
41031,Segmentation Fault tflite::ops::builtin::transpose_conv::ResizeCol2ImTensor,"@tensorflow/micro
@tensorflow/lite

**System information**
Hardware : Freescale i.MX6 Quad/DualLite
Processor: ARMv7 Processor rev 10 (v71)
OS Platform and Distribution: Yocto built Linux distribution (kernel 4.9.4+)
The tf-lite library was built with common options and using default makefile: https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/lite/tools/make/Makefile
API : CPP

**Describe the problem**
I trained a custom UNet and wanted to deploy it on the hardware using TFLite. Other custom models I've trained and converted to TF Lite work just fine but for this particular model I get a segmentation fault during `AllocateTensors()`.
Working with the python API does not result in errors and works just fine.

The relevant code : 
```
	/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
	Licensed under the Apache License, Version 2.0 (the ""License"");
	you may not use this file except in compliance with the License.
	You may obtain a copy of the License at
	    http://www.apache.org/licenses/LICENSE-2.0
	Unless required by applicable law or agreed to in writing, software
	distributed under the License is distributed on an ""AS IS"" BASIS,
	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	See the License for the specific language governing permissions and
	limitations under the License.
	==============================================================================*/


	#include <cstdio>
	#include <iostream>
	#include <iomanip>
	#include ""tensorflow/lite/interpreter.h""
	#include ""tensorflow/lite/kernels/register.h""
	#include ""tensorflow/lite/model.h""
	#include ""tensorflow/lite/optional_debug_tools.h""
	#include <time.h>
	#include <sys/time.h>
	#include <string>

	// This is an example that is minimal to read a model
	// from disk and perform inference. There is no data being loaded
	// that is up to you to add as a user.
	//
	// NOTE: Do not add any dependencies to this that cannot be built with
	// the minimal makefile. This example must remain trivial to build with
	// the minimal build tool.
	//
	// Usage: minimal <tflite model>

	using namespace tflite;
	using namespace std;

	#define TFLITE_MINIMAL_CHECK(x)                              \
	  if (!(x)) {                                                \
	    fprintf(stderr, ""Error at %s:%d\n"", __FILE__, __LINE__); \
	    exit(1);                                                 \
	  }

	double get_wall_time(){
	    struct timeval time;
	    if (gettimeofday(&time,NULL)){
		//  Handle error
		return 0;
	    }
	    return (double)time.tv_sec + (double)time.tv_usec * .000001;
	}
	double get_cpu_time(){
	    return (double)clock() / CLOCKS_PER_SEC;
	}

	int main(int argc, char* argv[]) {
	  if (argc < 2) {
	    fprintf(stderr, ""minimal <tflite model>\n"");
	    return 1;
	  }

	  const char* filename = argv[1];
	  int startt, endd;
	  startt = clock();
	  // Load model
	  std::unique_ptr<tflite::FlatBufferModel> model =
	      tflite::FlatBufferModel::BuildFromFile(filename);
	  TFLITE_MINIMAL_CHECK(model != nullptr);

	  // Build the interpreter
	  tflite::ops::builtin::BuiltinOpResolver resolver;
	  InterpreterBuilder builder(*model, resolver);
	  std::unique_ptr<Interpreter> interpreter;
	  int numthreads=stoi(argv[2]);
	  std::cout << ""allocating "" << numthreads << "" threads"" << std::endl;
	  builder(&interpreter, numthreads);
	  //interpreter->SetNumThreads(numthreads);
	  std::cout << ""threads allocated"" << std::endl;

	  TFLITE_MINIMAL_CHECK(interpreter != nullptr);
	  printf(""first minimal check done \n"");
	  endd = clock();

	  // Allocate tensor buffers.
	  printf(""allocating tensors..\n"");
	  TFLITE_MINIMAL_CHECK(interpreter->AllocateTensors() == kTfLiteOk);
	  printf(""=== Pre-invoke Interpreter State ===\n"");
	  //tflite::PrintInterpreterState(interpreter.get());

	  double time_taken = double(endd-startt)/double(CLOCKS_PER_SEC);
	  std::cout << ""a number of threads should be selected"" << std::endl;
	  std::cout << ""Time taken to load in the model in tflite using CPP API :"" << fixed << time_taken << std::setprecision(5);
	  std::cout << "" sec "" << std::endl;


	  // Fill input buffers
	  std::cout << ""inputs : "" << interpreter->inputs().size() << ""\n"";
	  std::cout << ""inputs(0) name : "" << interpreter->GetInputName(0) << ""\n"";
	  std::cout << ""tensors size: "" << interpreter->tensors_size() << ""\n"";
	  std::cout << ""nodes size: "" << interpreter->nodes_size() << ""\n"";
	  int startinput = clock();
	  int input = interpreter->inputs()[0];
	  std::cout << ""input.1 : "" << input <<""\n"";
	  const std::vector<int> inputs = interpreter->inputs();
	  const std::vector<int> outputs = interpreter->outputs();
	  std::cout << ""number of inputs: "" <<inputs.size() << ""\n"";
	  std::cout << ""number of outputs: "" <<outputs.size() << ""\n"";

	  TfLiteIntArray* dims = interpreter->tensor(input)->dims;
	  int test0 = dims->data[0];
	  int wanted_channels = dims->data[1];
	  int wanted_height = dims->data[2];
	  int wanted_width = dims->data[3];
	  int test4 = dims->data[4];
	  int test5 = dims->data[5];
	  int test6 = dims->data[6];
	  std::cout << ""type of input tensor: "" << interpreter->tensor(input)->type << std::endl;
	  std::cout << ""height, width, channels of input : "" << wanted_height << "" "" << wanted_width << "" ""<< wanted_channels <<  "" "" << test0 << "" "" << test4 << "" "" << test5 << "" "" << test6 << std::endl;

	  int outputint = interpreter->outputs()[0];
	  TfLiteIntArray* dimso = interpreter->tensor(outputint)->dims;
	  int wanted_heighto = dimso->data[1];
	  int wanted_widtho = dimso->data[2];
	  int wanted_channelso = dimso->data[3];
	  std::cout << ""type of output tensor: "" << interpreter->tensor(outputint)->type << std::endl;
	  std::cout << ""height, width, channels of output : "" << wanted_heighto << "" "" << wanted_widtho << "" ""<< wanted_channelso << std::endl;

	  float* input_data_ptr = interpreter->typed_tensor<float>(input);


	  float valuefloat = 0.5;
	  std::cout << ""here we go with 3x480x640"" << std::endl;
	  for (int k=0; k<640; k++){
	    for (int i=0; i<3; ++i){
		for (int j=0; j<480; j++){
		    *(input_data_ptr)=valuefloat;
		    input_data_ptr++;
		    }
		}
	  }


	  int stopinput = clock();
	  double time_taken2 = double(stopinput-startinput)/double(CLOCKS_PER_SEC);
	  std::cout << ""Time taken to load data :"" << fixed << time_taken2 << std::setprecision(5);
	  std::cout << "" sec "" << std::endl;

	   // Run inference
	   std::cout << ""start inference with "" << numthreads << "" threads""<< std::endl;
	  //  Start Timers
	  double wall0 = get_wall_time();
	  double cpu0  = get_cpu_time();
	  TFLITE_MINIMAL_CHECK(interpreter->Invoke() == kTfLiteOk);
	  //  Stop Timers
	  double wall1 = get_wall_time();
	  double cpu1  = get_cpu_time();
	  std::cout << ""wall time : "" << wall1 - wall0 << std::endl;
	  std::cout << ""CPU time : "" << cpu1 - cpu0 << std::endl;

	  printf(""\n\n=== Post-invoke Interpreter State ===\n"");
	  //tflite::PrintInterpreterState(interpreter.get());

	  // Read output buffers
	  // TODO(user): Insert getting data out code.
	  int output_idx = interpreter->outputs()[0];
	  float* output = interpreter->typed_tensor<float>(output_idx);
	  std::cout << ""OUTPUT: "" << *output << std::endl;


	  return 0;
	}
```

The model I've been using is a custom UNet I trained in TensorFlow and converted to TFLite using post training quantization (full integer quantization-except for the inputs).

**Please provide the exact sequence of commands/steps when you ran into the problem**
Running gdb and checking the stacktrace results in the following:
![image](https://user-images.githubusercontent.com/29673343/86367843-bfea6e80-bc7c-11ea-9113-f4d8e40be423.png)


For the record, I have another model converted with TF_OPS, next to the TF_LITE_BUILTIN_OPS. The binary on the hardware only supports TF_LITE_BUILTIN_OPS, and then the error looks different from what I am encountering now, namely like so : 

![image](https://user-images.githubusercontent.com/29673343/86368076-0e980880-bc7d-11ea-93f5-6b801da25755.png)


How do I go about this problem? What is causing this? "
41029,Error while reading resource variable _AnonymousVar285 from Container,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
41028,"LSTM behaving differently with recurrent activation ""sigmoid"" and tf.keras.activations.sigmoid","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 3.10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.6.1
- GPU model and memory: Tesla V100-SXM2-32GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Using tf.keras.layers.LSTM(units, recurrent_activation=tf.keras.activations.sigmoid) - My training is not converging
Using tf.keras.layers.LSTM(units, recurrent_activation='sigmoid') - Same training is converging
Also the time taken in former is higher than the latter. This I have found that in recurrent_v2.py, it is checking if recurrent_activation == 'sigmoid' which fails in case of tf.keras.activations.sigmoid, so the former one is not using CuDNN while latter one is using. What is different in those two cases is that the latter one is converging using CuDNN while the former one is not converging at all not using CuDNN.

**Describe the expected behavior**
Training should converge for both of the above however training time variation is understood as former is not using CuDNN but the latter one is using.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
No error is coming just training is acting differently

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
59516,request nvidia DALI support,The framework now is not supporting nvidia DALI to accelerate data preprocessing. GPU training is slow for imagenet.
41027,"AutoGraph could not transform with ""Cause: Inconsistent ASTs detected"" with pymc4","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
  * Yes, with [pymc4](https://github.com/pymc-devs/pymc4)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
  * Ubuntu 16.04 on WSL (WSL1)
  * Windows version : Windows 10 1909 (18363.900) 
- TensorFlow installed from (source or binary):
  * binary
- TensorFlow version (use command below):
  * v1.12.1-35610-gd8c49c2fde 2.4.0-dev20200701
- Python version:
  * Python 3.8.3, built from source
- CUDA/cuDNN version:
- GPU model and memory:
  * No GPU

**Describe the current behavior**
When I execute a script which uses pymc4, TF writes logs which says:
```
WARNING:tensorflow:AutoGraph could not transform <function _convert_function_call.<locals>.f at 0x7f2d04ec3f70> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Inconsistent ASTs detected. This is a bug. Cause: 
inconsistent values for field args: [<gast.gast.Name object at 0x7f2d04d7b370>] and []Diff:
```
**Describe the expected behavior**
The script runs without the warning log from TF.

**Standalone code to reproduce the issue**
1. Install pymc4 with ```pip install pymc4```
   * This will also install TF
1. Run [this script](https://gist.github.com/Isa-rentacs/aef5629956b17493072f44478bf0d3dd)

**Other info / logs** 
The log is available on [this gist](https://gist.github.com/Isa-rentacs/72ca156134a172d56cbe4ae5da827003)"
41026,ucf101 video dataset seems to be gone,"The ucf101 activity recognition dataset seems to have been completely removed. There's a link here https://www.tensorflow.org/datasets/catalog/ucf101 and when you go further both the landing page and the .zip file results in 404 errors. 

To be honest I am a little surprised that Google wasn't hosting these datasets. You could link it up in Colaboratory so you didn't even have to download anything when using them from there. Just an idea.
"
41025,Installation broken - Tensorflow 2.2 Cuda 10.1 Ubuntu 18.04,"This is essentially the same issue to  #36121 with Tensorflow 2.2. The issue doesn't list a proper solution, only led to an update of documentation, that is now apparently again out of date.

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version: 2.2
- Python version:  3.7.5
- Installed using virtualenv? pip? conda?: virtualenv 20.0.25
- CUDA/cuDNN version: 10.1
- GPU model and memory: GeForce RTX 2070 with Max-Q Design/PCIe/SSE2


**Describe the problem**
I'm following the installation instructions:
https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_101

Finished these steps (no errors):

    #Add NVIDIA package repositories
    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.1.243-1_amd64.deb
    sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub
    sudo dpkg -i cuda-repo-ubuntu1804_10.1.243-1_amd64.deb
    sudo apt-get update
    wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb
    sudo apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb
    sudo apt-get update
    
    # Install NVIDIA driver
    sudo apt-get install --no-install-recommends nvidia-driver-430
    # Reboot. Check that GPUs are visible using the command: nvidia-smi

`nvidia-smi` returns:
    NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2

Two notable points:

- 440 was fetched
- CUDA is listed as 10.2 (although the next step of installation tries to install 10.1:

    sudo apt-get install --no-install-recommends \
        cuda-10-1 \
        libcudnn7=7.6.4.38-1+cuda10.1  \
        libcudnn7-dev=7.6.4.38-1+cuda10.1

This gives same error as #36121:

    The following packages have unmet dependencies:
     cuda-10-1 : Depends: cuda-runtime-10-1 (>= 10.1.243) but it is not going to be installed
             Depends: cuda-demo-suite-10-1 (>= 10.1.243) but it is not going to be installed


The discussion in #36121 is bit unclear on resolution and differs slightly in driver/library version numbers.
I'm on a freshly installed system and I have *not* attempted to install the dependencies manually, before consulting you.

Thank you!
 
"
41024,"Overhead of calling "" ModifyGraphWithDelegate() ""","**System information**
- I have written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):
- Mobile device : Qualcomm 855
- TensorFlow installed from source:
- TensorFlow version r.14:
- Python version 3.6:
- Bazel version : 3.1:
- GCC/Compiler version : ndk21_rb
- GPU model and memory:

We are running inference on GPU using TFLite. We observed that invoking ModifyGraphWithDelegate() takes 22 second on Qualcomm 855 device.
This time is so huge, We are not able to find any other way to reduce the 22 second overhead.

Is there any way to get ride of this overhead.
Could you please help me .

"
41023,[RNN] Loading quantized LSTM model with state handling into TF Lite interpreter fails.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOs / Ubuntu 18.04
- TensorFlow installed from (source or binary): binary / pip
- TensorFlow version (or github SHA if from source): 2.3.0rc0


**Command used to run the converter or code if youre using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import  LSTM, Input


in_dat = Input(batch_shape=(1,1,128))
in_states = Input(batch_shape=(1,1,128,2))


in_state = [in_states[:,0,:,0], in_states[:,0,:,1]]
out_dat, state_h, state_c = LSTM(128, 
                                 return_sequences=True, 
                                 return_state=True)(in_dat, initial_state=in_state)

out_states = tf.stack([state_h, state_c],axis=-1)

model = Model(inputs=[in_dat, in_states], 
                           outputs=[out_dat, out_states])


converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
with tf.io.gfile.GFile('test_model.tflite', 'wb') as f:
      f.write(tflite_model)

interpreter = tf.lite.Interpreter(model_path='./test_model.tflite')
```

**The output from the converter invocation**
Conversion works fine, the interpreter can not load the model:
```
2020-07-02 10:58:39.439478: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd0c32e2e10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-02 10:58:39.439818: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Applications/anaconda3/envs/tf23env/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2020-07-02 10:58:41.751516: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /Applications/anaconda3/envs/tf23env/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2020-07-02 10:58:48.388047: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.
2020-07-02 10:58:48.388077: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.
2020-07-02 10:58:48.395287: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /var/folders/p4/yptj61953073c48n66hnlr100000gp/T/tmpu_2uf65d
2020-07-02 10:58:48.419914: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }
2020-07-02 10:58:48.419953: I tensorflow/cc/saved_model/loader.cc:234] Reading SavedModel debug info (if present) from: /var/folders/p4/yptj61953073c48n66hnlr100000gp/T/tmpu_2uf65d
2020-07-02 10:58:48.509456: I tensorflow/cc/saved_model/loader.cc:199] Restoring SavedModel bundle.
2020-07-02 10:58:48.669926: I tensorflow/cc/saved_model/loader.cc:183] Running initialization op on SavedModel bundle at path: /var/folders/p4/yptj61953073c48n66hnlr100000gp/T/tmpu_2uf65d
2020-07-02 10:58:48.753087: I tensorflow/cc/saved_model/loader.cc:303] SavedModel load for tags { serve }; Status: success: OK. Took 358438 microseconds.
2020-07-02 10:58:49.363263: I tensorflow/lite/tools/optimize/quantize_weights.cc:211] Skipping quantization of tensor arg5 because it has fewer than 1024 elements (128).
Traceback (most recent call last):
  File ""test_tf_lite.py"", line 41, in <module>
    interpreter_1 = tf.lite.Interpreter(model_path='./test_model.tflite')
  File ""/Applications/anaconda3/envs/tf23env/lib/python3.7/site-packages/tensorflow/lite/python/interpreter.py"", line 198, in __init__
    model_path, self._custom_op_registerers))
ValueError: Did not get operators, tensors, or buffers in subgraph 1.
```

**Also, please include a link to the saved model or GraphDef**


[test_model.tflite.zip](https://github.com/tensorflow/tensorflow/files/4863193/test_model.tflite.zip)


**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Model can not be loaded by the interpreter
- Without quantization, conversion, loading and invoke works fine.
- Worked before with a tf-nightly, but I don't know anymore which one.
- Same behaviour on MacOs and Linux
- Same behaviour when converting from SavedModel format
- Same behaviour with tf-lite runtime


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
41022,ModuleNotFoundError: No module named 'tensorflow.compiler.tf2tensorrt',"Hello.

I have created a small python application using tensorflow 2.2.0 and can run it with no problem using python 3.7.4
Then I use pyinstaller to make a package of my project. 
But when I try to run pyinstaller compiled version, I get this error (line 14 is ""import tensorflow as tf"").

```
Traceback (most recent call last):
  File ""test_wx1.py"", line 14, in <module>
  File ""/usr/local/lib/python3.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 623, in exec_module
    exec(bytecode, module.__dict__)
  File ""tensorflow/__init__.py"", line 41, in <module>
  File ""/usr/local/lib/python3.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 623, in exec_module
    exec(bytecode, module.__dict__)
  File ""tensorflow/python/__init__.py"", line 74, in <module>
  File ""/usr/local/lib/python3.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 623, in exec_module
    exec(bytecode, module.__dict__)
  File ""tensorflow/python/ops/standard_ops.py"", line 117, in <module>
  File ""/usr/local/lib/python3.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 623, in exec_module
    exec(bytecode, module.__dict__)
  File ""tensorflow/python/compiler/tensorrt/__init__.py"", line 22, in <module>
  File ""/usr/local/lib/python3.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 623, in exec_module
    exec(bytecode, module.__dict__)
  File ""tensorflow/python/compiler/tensorrt/trt_convert.py"", line 79, in <module>
  File ""tensorflow/python/util/lazy_loader.py"", line 62, in __getattr__
  File ""tensorflow/python/util/lazy_loader.py"", line 45, in _load
  File ""importlib/__init__.py"", line 127, in import_module
ModuleNotFoundError: No module named 'tensorflow.compiler.tf2tensorrt'
```

I cannot find any information Googling, so maybe you could help? 
Or maybe this is solely pyinstaller's responsibility and I should ask them?"
41021,Error when saving weights in h5 format for layer with nested layers,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7

**Describe the current behavior**
Given a layer with nested layers, when trying to save weights in h5 format, fails with ```RuntimeError: Unable to create link (name already exists)```

**Standalone code to reproduce the issue**
```python
import tensorflow as tf

from tensorflow.keras import datasets, layers, models
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

class NestedLayers(tf.keras.layers.Layer):
    def __init__(self):
        super(NestedLayers, self).__init__()
        self.units = [layers.Conv2D(16, (3,3), name=""conv_2d_0""),
                      layers.Conv2D(16, (3,3), name=""conv_2d_1""),
                      layers.Conv2D(16, (3,3), name=""conv_2d_2"")]

    def build(self, input_shape):
        for i in range(0,2):
            unit_input_shape = list(input_shape)
            unit_input_shape[-1] = 1
            unit = self.units[i]
            unit.build(unit_input_shape)

    def call(self, inputs):
        split_inputs = tf.split(value=inputs,
                                 num_or_size_splits=3,
                                 axis=-1,
                                 name=""conv_grp_split"")
        outputs = []
        for i in range(0,2):
            out = self.units[i](split_inputs[i])
            outputs.append(out)
        out = tf.keras.layers.concatenate(outputs, axis=-1, name=""conv_grp_concat"")
        return  out

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

model = models.Sequential()
model.add(layers.InputLayer(input_shape=(32, 32, 3)))
model.add(NestedLayers())
model.add(layers.Flatten())
model.add(layers.Dense(10, activation='softmax'))
model.summary()

import datetime
log_dir = ""logs/fit/"" + datetime.datetime.now().strftime(""%Y%m%d-%H%M%S"")

check_pt = tf.keras.callbacks.ModelCheckpoint(
                os.path.join(log_dir, ""model.ckpt.{epoch:04d}-{val_loss:.06f}.hdf5""),
                monitor='val_loss',
                verbose=1,
                save_best_only=False,
                save_weights_only=True,
                mode='max',
                period=1)

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_images, train_labels, epochs=2,
                    validation_data=(test_images, test_labels),
                    callbacks = [check_pt])

```

Fails with the following:
Epoch 00001: saving model to logs/fit/20200702-114230/model.ckpt.0001-1.949398.hdf5
Traceback (most recent call last):
  File ""/nfs/site/home/tkrimer/work/mbe/dlo/src/internal_utils/train_cifar10_tf_2/nested_layers_save.py"", line 78, in <module>
    callbacks = [tensorboard_callback, check_pt])
  File ""/localdrive/users/tkrimer/venv/tf_2.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/localdrive/users/tkrimer/venv/tf_2.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 876, in fit
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/localdrive/users/tkrimer/venv/tf_2.1/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py"", line 365, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/localdrive/users/tkrimer/venv/tf_2.1/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py"", line 1177, in on_epoch_end
    self._save_model(epoch=epoch, logs=logs)
  File ""/localdrive/users/tkrimer/venv/tf_2.1/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py"", line 1223, in _save_model
    self.model.save_weights(filepath, overwrite=True)
  File ""/localdrive/users/tkrimer/venv/tf_2.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 1151, in save_weights
    hdf5_format.save_weights_to_hdf5_group(f, self.layers)
  File ""/localdrive/users/tkrimer/venv/tf_2.1/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 639, in save_weights_to_hdf5_group
    param_dset = g.create_dataset(name, val.shape, dtype=val.dtype)
  File ""/localdrive/users/tkrimer/venv/tf_2.1/lib/python3.7/site-packages/h5py/_hl/group.py"", line 139, in create_dataset
    self[name] = dset
  File ""/localdrive/users/tkrimer/venv/tf_2.1/lib/python3.7/site-packages/h5py/_hl/group.py"", line 373, in __setitem__
    h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl)
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper
  File ""h5py/h5o.pyx"", line 202, in h5py.h5o.link
RuntimeError: Unable to create link (name already exists)
"
41020,Failed to build 1.15.3 release with GCC9.3,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):   https://github.com/tensorflow/tensorflow/archive/v1.15.3.zip
- TensorFlow version: 1.15.3
- Python version: 3.8
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): GCC 9.3
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the problem**
Build failed with error message:
```
external/grpc/src/core/lib/gpr/log_linux.cc:43:13: error: ambiguating new declaration of 'long int gettid()'
   43 | static long gettid(void) { return syscall(__NR_gettid); }
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
bazel --output_user_root=$build_dir build --config=mkl --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mavx512f --copt=-mavx512cd  //tensorflow/tools/pip_package:build_pip_package 2>&1 | tee /root/build.log
```

Refer to this issue: https://github.com/grpc/grpc/issues/20043
May need to upgrade the grpc version.
"
41019,'fit' takes a dataset with increasing batch size,"**System information**
- TensorFlow version (you are using): 2.2
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
I have a custom model to train a text classifier. So far (tensorflow 2.1) we overwrote all important methods of `tf.keras.models.Model`, e.g. `fit`, `predict` etc. One of the reasons for that was that we wanted to adapt the batch size of our dataset every epoch. So, during the first epoch we would have, for example, a batch size of 16, in the next iteration the batch size would increase to 20, and so on. Until we reach an upper limit.

Here is the method that generates our tf.Dataset. We would call this method every epoch to get a dataset with the desired batch size.
```
def as_tf_dataset(
    self, batch_size: int, batch_strategy: Text = SEQUENCE, shuffle: bool = False
) -> tf.data.Dataset:
    """"""Create tf dataset.""""""

    shapes, types = self._get_shapes_types()

    return tf.data.Dataset.from_generator(
        lambda batch_size_: self._gen_batch(batch_size_, batch_strategy, shuffle),
        output_types=types,
        output_shapes=shapes,
        args=([batch_size]),
    )
```

With Tensorflow 2.2. it is possible to just overwrite `train_step` and `test_step` instead of `fit` etc (we followed this [guide](https://keras.io/guides/customizing_what_happens_in_fit/)). This would simplify our code quite a bit and would allow us to use callbacks. 
However, when we would overwriting `train_step` instead of `fit` we would loose the possibility to control the dataset, e.g. adapt the batch size of the dataset every epoch. `fit` just takes a dataset and with the help of a `DataHandler` it create a new iterator over that dataset every epoch. 

I am not sure how to solve this, but maybe we could allow users to define a custom `DataHandler` that takes care of the dataset generation. 

**Who will benefit with this feature?**
Any users that use a `tf.keras.models.Model`.
"
41018,"error: tensorflow::error has not been declared----Status(tensorflow::error::Code code, tensorflow::StringPiece msg);","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution : Linux Ubuntu 16.04
- TensorFlow installed from :    source
- TensorFlow version :  1.14
- Python version:   3.5
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version :  5.4.0 20160609
- CUDA/cuDNN version: 10.0/7.6.5
- GPU model and memory:  GF1080 TI



**Describe the current behavior**

I am a newer to c++, I want to accomplish CNN model with c++ tensorflow API. I follow the manual on the Internet and finishe tensorflow compiling and  generate the libtensorflow_cc.so file.   Now I want to build a test using cmake 3.13.0, I create a ""CMakeLists.txt"" and execute
'''
cmake .
make
'''

the errors:

'''
[make[2]: Warning: File '/home/john/tensorflow/tensorflow/contrib/makefile/downloads/eigen/Eigen/src/Core/arch/NEON/Complex.h' has modification time 11068 s in the future
[ 50%] Building CXX object CMakeFiles/tensorflow_cc_test.dir/hello.cpp.o
In file included from /home/john/tensorflow/tensorflow/core/lib/core/errors.h:21:0,
                 from /home/john/tensorflow/tensorflow/core/platform/env.h:24,
                 from /home/john//tensorflow_cc_test/hello.cpp:1:
/home/john/tensorflow/tensorflow/core/lib/core/status.h:45:22: error: tensorflow::error has not been declared
   Status(tensorflow::error::Code code, tensorflow::StringPiece msg);
                      ^
/home/john/tensorflow/tensorflow/core/lib/core/status.h:45:34: error: expected ) before code
   Status(tensorflow::error::Code code, tensorflow::StringPiece msg);
                                  ^
/home/john/tensorflow/tensorflow/core/lib/core/status.h:56:15: error: error in namespace tensorflow does not name a type
   tensorflow::error::Code code() const {
               ^
/home/john/tensorflow/tensorflow/core/lib/core/status.h:90:17: error: error in namespace tensorflow does not name a type
     tensorflow::error::Code code;
                 ^
In file included from /home/john/tensorflow/tensorflow/core/platform/env.h:24:0,
                 from /home/john//tensorflow_cc_test/hello.cpp:1:
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:30:23: error: error in namespace tensorflow does not name a type
 typedef ::tensorflow::error::Code Code;
                       ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function void tensorflow::errors::AppendToMessage(tensorflow::Status*, Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:65:15: error: class tensorflow::Status has no member named code
       status->code(),
               ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::Cancelled(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:103:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Cancelled, CANCELLED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsCancelled(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:103:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Cancelled, CANCELLED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:103:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Cancelled, CANCELLED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::InvalidArgument(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:104:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(InvalidArgument, INVALID_ARGUMENT)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsInvalidArgument(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:104:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(InvalidArgument, INVALID_ARGUMENT)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:104:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(InvalidArgument, INVALID_ARGUMENT)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::NotFound(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:105:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(NotFound, NOT_FOUND)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsNotFound(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:105:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(NotFound, NOT_FOUND)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:105:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(NotFound, NOT_FOUND)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::AlreadyExists(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:106:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(AlreadyExists, ALREADY_EXISTS)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsAlreadyExists(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:106:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(AlreadyExists, ALREADY_EXISTS)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:106:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(AlreadyExists, ALREADY_EXISTS)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::ResourceExhausted(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:107:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(ResourceExhausted, RESOURCE_EXHAUSTED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsResourceExhausted(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:107:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(ResourceExhausted, RESOURCE_EXHAUSTED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:107:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(ResourceExhausted, RESOURCE_EXHAUSTED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::Unavailable(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:108:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Unavailable, UNAVAILABLE)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsUnavailable(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:108:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Unavailable, UNAVAILABLE)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:108:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Unavailable, UNAVAILABLE)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::FailedPrecondition(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:109:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(FailedPrecondition, FAILED_PRECONDITION)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsFailedPrecondition(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:109:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(FailedPrecondition, FAILED_PRECONDITION)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:109:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(FailedPrecondition, FAILED_PRECONDITION)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::OutOfRange(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:110:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(OutOfRange, OUT_OF_RANGE)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsOutOfRange(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:110:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(OutOfRange, OUT_OF_RANGE)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:110:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(OutOfRange, OUT_OF_RANGE)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::Unimplemented(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:111:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Unimplemented, UNIMPLEMENTED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsUnimplemented(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:111:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Unimplemented, UNIMPLEMENTED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:111:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Unimplemented, UNIMPLEMENTED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::Internal(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:112:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Internal, INTERNAL)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsInternal(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:112:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Internal, INTERNAL)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:112:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Internal, INTERNAL)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::Aborted(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:113:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Aborted, ABORTED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsAborted(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:113:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Aborted, ABORTED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:113:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Aborted, ABORTED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::DeadlineExceeded(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:114:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(DeadlineExceeded, DEADLINE_EXCEEDED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsDeadlineExceeded(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:114:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(DeadlineExceeded, DEADLINE_EXCEEDED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:114:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(DeadlineExceeded, DEADLINE_EXCEEDED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::DataLoss(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:115:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(DataLoss, DATA_LOSS)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsDataLoss(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:115:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(DataLoss, DATA_LOSS)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:115:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(DataLoss, DATA_LOSS)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::Unknown(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:116:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Unknown, UNKNOWN)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsUnknown(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:116:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Unknown, UNKNOWN)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:116:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Unknown, UNKNOWN)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::PermissionDenied(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:117:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(PermissionDenied, PERMISSION_DENIED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsPermissionDenied(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:117:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(PermissionDenied, PERMISSION_DENIED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:117:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(PermissionDenied, PERMISSION_DENIED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function tensorflow::Status tensorflow::errors::Unauthenticated(Args ...):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:95:9: error: error is not a member of tensorflow
         ::tensorflow::error::CONST,                                      \
         ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:118:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Unauthenticated, UNAUTHENTICATED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: In function bool tensorflow::errors::IsUnauthenticated(const tensorflow::Status&):
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:19: error: const class tensorflow::Status has no member named code
     return status.code() == ::tensorflow::error::CONST;                  \
                   ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:118:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Unauthenticated, UNAUTHENTICATED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:100:43: error: tensorflow::error has not been declared
     return status.code() == ::tensorflow::error::CONST;                  \
                                           ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:118:1: note: in expansion of macro DECLARE_ERROR
 DECLARE_ERROR(Unauthenticated, UNAUTHENTICATED)
 ^
/home/john/tensorflow/tensorflow/core/lib/core/errors.h: At global scope:
/home/john/tensorflow/tensorflow/core/lib/core/errors.h:158:21: error: tensorflow::error has not been declared
 using ::tensorflow::error::OK;
                     ^
CMakeFiles/tensorflow_cc_test.dir/build.make:62: recipe for target 'CMakeFiles/tensorflow_cc_test.dir/hello.cpp.o' failed
make[2]: *** [CMakeFiles/tensorflow_cc_test.dir/hello.cpp.o] Error 1
CMakeFiles/Makefile2:72: recipe for target 'CMakeFiles/tensorflow_cc_test.dir/all' failed
make[1]: *** [CMakeFiles/tensorflow_cc_test.dir/all] Error 2
Makefile:83: recipe for target 'all' failed
make: *** [all] Error 2
'''

I can not search Internet for anythin about this, can somebody help?
"
41016,Add the steps related to Pickling the Tokenization in Text Classification Tutorial,"## URL(s) with the issue: https://www.tensorflow.org/tutorials/text/text_classification_rnn

## Description of issue (what needs changing): 
Can include the Code related to Pickling the Tokenization and then Loading the Pickle File while predicting on the Loaded Saved Model.

### Clear description : 
Recently, I have worked on a `Text Classification project`. Everything was good and the Model is `95%` Accurate. But when performing `Predictions` after `Loading the Saved Model`, and while performing Inference using `Tensorflow Serving`, **Model's Predictions were very poor**. After investigating for more than 10 days, we figured out that we need to **Save the Tokenizations in a Pickle File and then Load that Pickle File while Performing Predictions on a Loaded Saved Model or using TF Serving or using TF Lite**.

### Code that can be added in the Documentation: 

Below code needs to be added after the command, `tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)`


```
import pickle

# Saving the Tokenization in Pickle File

with open('tokenizer.pickle', 'wb') as handle:
    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)

```

Also, below code needs to be added before the command, `train_sequences = tokenizer2.texts_to_sequences(Train_Resume_Data)`

```
# Loading the Tokeniztion Pickle File
with open('tokenizer.pickle', 'rb') as handle:
    tokenizer2 = pickle.load(handle)
```

This will help all the Developers working on Text Classification projects or any other NLP Task. Thanks."
41014,tf.estimator.predict cannot run consecutively on Colab TPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab TPU
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Colab Jupyter Notebook
- TensorFlow version (use command below):1-15.2
- Python version: 3.6
- Bert-tensorflow version: 1.0.1

**Describe the current behavior**
I don't know if this is a good place to report the tf.estimator.predict API bug. I am trying to use bert-tensorflow to do fine tuning. After the estimator.train, I used tf.estimator.predict to predict the test dataset twice in sequence with 2 checkpoints (both different or same checkpoints). The two predict calls are in 2 separate jupyter cells. For the first predict, it runs ok, the prediction probabilities are returned as expected. For the second predict, it stuck in the logging info ""Shutting down InfeedController thread"" and not move further. I've tried several method to make the 2nd predict run as the 1st one, but it just not works out. To provide more information, I just paste the log where the 2nd predict stuck:

> INFO:tensorflow:  name = bert/encoder/layer_23/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*
> INFO:tensorflow:  name = bert/encoder/layer_23/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*
> INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*
> INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*
> INFO:tensorflow:  name = output_weights:0, shape = (2, 1024)
> INFO:tensorflow:  name = output_bias:0, shape = (2,)
> INFO:tensorflow:Done calling model_fn.
> INFO:tensorflow:TPU job name worker
> INFO:tensorflow:Graph was finalized.
> INFO:tensorflow:Restoring parameters from gs://sr2pr/liuyi_test_early_stop/early_stop_ckpts/model.ckpt-853
> INFO:tensorflow:Running local_init_op.
> INFO:tensorflow:Done running local_init_op.
> INFO:tensorflow:Init TPU system
> INFO:tensorflow:Initialized TPU in 0 seconds
> INFO:tensorflow:Starting infeed thread controller.
> INFO:tensorflow:Starting outfeed thread controller.
> INFO:tensorflow:Initialized dataset iterators in 0 seconds
> INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.
> INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.
> INFO:tensorflow:Outfeed finished for iteration (0, 0)
> INFO:tensorflow:Stop infeed thread controller
> INFO:tensorflow:Shutting down InfeedController thread.
> 

I do know the estimator.predict returns a iterator/generator, which prevents interleaving calls as indicated in the official tensorflow document. I think my case is not interleaving operation? I don't know if this is caused by colab or the predict API? and any idea to work around this bug? 

Currently, I have no way to run predict twice unless I shutdown the Colab, close the browser tab, upload the jupyter notebook, and reinitialize everything and configure everything again. 

Any possible discussions that may help are appreciated.
"
41012,tflite RuntimeError: Encountered unresolved custom op: CombinedNonMaxSuppression.Node number 148 (CombinedNonMaxSuppression) failed to prepare.,"**System information**
- Linux 
- TF 2.5.0-dev20200629

**Command used to run the converter or code if youre using the Python API**

Converter:

```
    converter = tf.lite.TFLiteConverter.from_saved_model(curr_dir + ""saved_model_2"")
    converter.experimental_new_converter = True
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                           tf.lite.OpsSet.SELECT_TF_OPS]
    converter.allow_custom_ops = True

    tflite_model = converter.convert()
```

Inference:

```
# Load the TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=""./model.tflite"")
interpreter.allocate_tensors()
print(""all ok"")

# # Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# # Test the model on random input data.
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

# # The function `get_tensor()` returns a copy of the tensor data.
# # Use `tensor()` in order to get a pointer to the tensor.
output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
```


**The output from the converter invocation**

```
  File ""inference.py"", line 19, in <module>
    interpreter.invoke()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py"", line 524, in invoke
    self._interpreter.Invoke()
RuntimeError: Encountered unresolved custom op: CombinedNonMaxSuppression.Node number 148 (CombinedNonMaxSuppression) failed to prepare.
```

I'm wondering why the flex delegate couldn't prepare the CombinedNonMaxSuppression function, even though I have the `SELECT_TF_OPS` flag enabled?"
41009,Layer is not connected issue while accessing intermediate layer from custom callback if model is built by sub-classing,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04.2 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
Binary
- TensorFlow version (use command below):
v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version:
Python 3.7.3
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
CUDA 10.2
- GPU model and memory:
NVIDIA TITAN X (Pascal), ~12GB

**Describe the current behavior**
I've a simple model and need access of intermediate layers within a custom callback to get intermediate predictions. If I build the model by sub-classing, I get the error `AttributeError: Layer dense is not connected`.

**Describe the expected behavior**
It shouldn't cause any error and be able to get predictions using intermediate layers.

**Standalone code to reproduce the issue**
```
import tensorflow as tf
import numpy as np

X = np.ones((8,16))
y = np.sum(X, axis=1)

class CustomCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        get_output = tf.keras.backend.function(
            inputs = self.model.layers[0].input,
            outputs = self.model.layers[1].output
        )
        print(""\nLayer output: "", get_output(X))

class Model(tf.keras.Model):
    def build(self, input_shape):
        self.dense1 = tf.keras.layers.Dense(units=32)
        self.dense2 = tf.keras.layers.Dense(units=1)
        
    def call(self, input_tensor):
        x = self.dense1(input_tensor)
        x = self.dense2(x)
        return x

model = Model()
model.compile(optimizer='adam',loss='mean_squared_error', metrics='accuracy')
model.fit(X,y, epochs=2, callbacks=[CustomCallback()])
```

**Other info / logs** 
Traceback:
```---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-3-dd6e118e08d6> in <module>
     11 model = Model()
     12 model.compile(optimizer='adam',loss='mean_squared_error', metrics='accuracy')
---> 13 model.fit(X,y, epochs=2, callbacks=[CustomCallback()])

/opt/anaconda3/envs/brats/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

/opt/anaconda3/envs/brats/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
    874           epoch_logs.update(val_logs)
    875 
--> 876         callbacks.on_epoch_end(epoch, epoch_logs)
    877         if self.stop_training:
    878           break

/opt/anaconda3/envs/brats/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py in on_epoch_end(self, epoch, logs)
    363     logs = self._process_logs(logs)
    364     for callback in self.callbacks:
--> 365       callback.on_epoch_end(epoch, logs)
    366 
    367   def on_train_batch_begin(self, batch, logs=None):

<ipython-input-2-a1f33c1e2e52> in on_epoch_end(self, epoch, logs)
      8     def on_epoch_end(self, epoch, logs=None):
      9         get_output = tf.keras.backend.function(
---> 10             inputs = self.model.layers[0].input,
     11             outputs = self.model.layers[1].output
     12         )

/opt/anaconda3/envs/brats/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in input(self)
   1806     if not self._inbound_nodes:
   1807       raise AttributeError('Layer ' + self.name +
-> 1808                            ' is not connected, no input to return.')
   1809     return self._get_node_attribute_at_index(0, 'input_tensors', 'input')
   1810 

AttributeError: Layer dense is not connected, no input to return.
```
If I build the model using functional API as shown below, it works fine:
```
initial = tf.keras.layers.Input((16,))
x = tf.keras.layers.Dense(units=32)(initial)
final = tf.keras.layers.Dense(units=1)(x)

model = tf.keras.Model(initial, final)
model.compile(optimizer='adam',loss='mean_squared_error', metrics='accuracy')
model.fit(X,y, epochs=2, callbacks=[CustomCallback()])
```
[Here's](https://stackoverflow.com/q/62668398/2679778) the stackoverflow question I created on the same issue."
41005,"tf.where doc on Args ""x"" seems incorrect","## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/where#args_1

## Description of issue (what needs changing):
For Args ""x"".
Original:
If provided, a Tensor which is of the same type as y, and has a shape broadcastable with condition and y.
Should be:
If provided, a Tensor which is of the same type as **x**, and has a shape broadcastable with condition and y.
"
41003,OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7

**Describe the current behavior**
Getting 'OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution' error , while Eager execution is actually enabled

**Standalone code to reproduce the issue**
```python
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf

from tensorflow.keras import datasets, layers, models
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

model = models.Sequential()
model.add(layers.InputLayer(input_shape=(32, 32, 3)))
model.add(layers.Conv2D(16, (3,3)))
model.add(layers.Flatten())
model.add(layers.Dense(10, activation='softmax'))
model.summary()

def to_list(x):
  if isinstance(x, list):
    return x
  return [x]

outs = []
for l in model.layers:
    output_tensors = [to_list(inbound.output_tensors)[0] for inbound in l.inbound_nodes]
    outs.append(output_tensors)

ins = []
for l in model.layers:
    input_tensors = [to_list(inbound.input_tensors)[0] for inbound in l.inbound_nodes]
    ins.append(input_tensors)

assert tf.executing_eagerly()
for i_tensor in ins:
    if i_tensor in outs:
        print(""BOOM"")


```
Note that it passes the assertion, making sure the eager execution is on, but still raises the error on the if statement and suggests to 'Use Eager execution'. What am I missing? The eager execution is on by default in TF 2.2

"
41000,Support matmul operation for tf.complex64,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab CPU
- TensorFlow version (or github SHA if from source): 2.2.0

[Colab example](https://colab.research.google.com/drive/1_2YSQ21OwpxGhbdrDznNUsL77aesBynH?usp=sharing)

Note: I wouldn't mind to use `tf.einsum` instead, but that's not supported at all.
Also, not sure which operation *are* supported for `tf.complex`.

Thanks"
40999,.pb object detection model with 1 output tensor conversion to 4 output tensors,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10, build 7601: SP1
& Linux 16.04 guest
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
[Google Coral Edge Dev Board
](https://coral.ai/products/dev-board/)- TensorFlow installed from (source or binary):
Pip
- TensorFlow version:
2.3.0-dev20200620
- Python version: 3.7
- Installed using virtualenv? pip? conda?: Pip
- Bazel version (if compiling from source): N/A 
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A CPU only
- GPU model and memory: N/A CPU only

-------------------------------------------------------------------------------------------------------------------------

**Describe the problem**
This problem is somewhat related to comment [#547708153](https://github.com/tensorflow/tensorflow/issues/33774#issuecomment-547708153) and subsequent answers.

Using Microsoft Azure CustomVision (as in above issue), I trained and labelled a tensorflow object detection model. Azure allows you to download this object detection model directly to .pb or .tflite. 

The output of the .pb object detection model looks like this:
![pzN0L](https://user-images.githubusercontent.com/14267992/86273918-ef2aae00-bb9e-11ea-965f-057c216d2c20.png)

This appears to be a single output tensor model on an object detection model. How does one convert to 4 output tensors as required by mobile devices?

-------------------------------------------------------------------------------------------------------------------------

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Attempting to convert to .tflite with tflite_convert and quantization (note --enable_v1_converter flag enabled as per the answers in the above thread)
```
python tflite_convert.py \
--output_file=model.tflite \
--graph_def_file=model.pb \
--enable_v1_converter \
--inference_type=QUANTIZED_UINT8 \
--input_shapes=1,416,416,3  \
--input_arrays=Placeholder \
--output_arrays=model_outputs \
--mean_values=128 \
--std_dev_values=128 \
--allow_custom_ops \
--change_concat_input_ranges=false \
--allow_nudging_weights_to_use_fast_gemm_kernel=true
```

This command creates a model.tflite. The tensor output of this .tflite is identical to the tensor in the .pb file above

The rest of this works, but for repeatability purposes I will continue. I then drag this .tflite into the guest linux account and push it onto the Edge device
`mdt push model.tflite`

The .tflite is now on the Coral Edge board, so I set it up to run
```
export DEMO_FILES=""/usr/lib/python3/dist*/edgetpu/demo""
sudo cp model.tflite DEMO_FILES

export DISPLAY=:0 && edgetpu_detect \
-- source /dev/video1:YUY2:1280x720:20/1 \
--model ${DEMO_FILES}/model.tflite
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Coral Edge Output confirms only one tensor (the ValueError is noted in their [docs](https://coral.ai/docs/reference/edgetpu.detection.engine/))
```
INFO: Initialized TensorFlow Lite runtime.
Traceback (most recent call last):
  File ""/usr/bin/edgetpu_detect"", line 11, in <module>
    load_entry_point('edgetpuvision==1.0', 'console_scripts', 'edgetpu_detect')()
  File ""/usr/lib/python3/dist-packages/edgetpuvision/detect.py"", line 207, in main
    run_app(add_render_gen_args, render_gen)
  File ""/usr/lib/python3/dist-packages/edgetpuvision/apps.py"", line 70, in run_app
    display=args.displaymode):
  File ""/usr/lib/python3/dist-packages/edgetpuvision/gstreamer.py"", line 240, in run_gen
    inference_size = render_overlay_gen.send(None)  # Initialize.
  File ""/usr/lib/python3/dist-packages/edgetpuvision/detect.py"", line 144, in render_gen
    engines, titles = utils.make_engines(args.model, DetectionEngine)
  File ""/usr/lib/python3/dist-packages/edgetpuvision/utils.py"", line 53, in make_engines
    engine = engine_class(model_path)
  File ""/usr/lib/python3/dist-packages/edgetpu/detection/engine.py"", line 77, in __init__
    'This model has {}.'.format(output_tensors_sizes.size)))
ValueError: Dectection model should have 4 output tensors!This model has 1.
```

And finally, personally I have used Google's AutoML vision to train a model and push it onto the Edge device. The output of the AutoML looks like the following. This output (4 tensors) works on the Edge device. 

![Hzl6A](https://user-images.githubusercontent.com/14267992/86274029-108b9a00-bb9f-11ea-8cea-629093a2d49a.png)

Many thanks for any ideas!
"
40997,Keras optional Input with default value,"**System information**
- TensorFlow version (you are using): 2.3.rc0
- Are you willing to contribute it (Yes/No): yes


**Describe the feature and the current behavior/state.**
For one of my models i have multiple inputs with some of them only used at inference time and with a default value to 1 during training. 
To support that i currently create two models with the functional api, one with those optional inputs and one connected to a constant but it's quite complex to put in place. 

**Will this change the current api? How?**
We could add a new parameter to Input(default_value=) we would need to pass the shape and type as well and make sure the default matches the condition. 
It exists in Tensorflow here: https://www.tensorflow.org/api_docs/python/tf/compat/v1/placeholder_with_default

**Who will benefit with this feature?**
Users with models with a large number of inputs with some features not used during either inference or training.

**Any Other info.**
"
40996,TF 2.1 Automatic Mixed Precision Training Loss Not Going Down,"I'm trying to use automatic mixed precision in TensorFlow 2.1.0, but my training loss has not been going down.

I'm using the follow code snippets:

tf.keras.mixed_precision.experimental.set_policy('mixed_float16')

optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
optimizer = tf.keras.mixed_precision.experimental.LossScaleOptimizer(optimizer, ""dynamic"")

def _compute_apply_gradients(x):
        with tf.GradientTape() as tape:
            loss, metric_value = _compute_loss(x)
            loss = _optimizer.get_scaled_loss(loss)
        gradients = tape.gradient(loss, _model.trainable_variables)
        gradients = _optimizer.get_unscaled_gradients(gradients)
        _optimizer.apply_gradients(zip(gradients, _model.trainable_variables))
        return loss, metric_value

For calculating my loss, I'm doing the following:

outputs_logits, _ = _model(images, is_training=True)
loss = tf.nn.softmax_cross_entropy_with_logits(logits=outputs_logits, labels=labels)

I also added dtype='float32' to the final layer of my model, which is a U-Net.

When training, my loss starts from a really high value and then gradually decreases down to ~2.x, which is normal for regular training, and then just stops from there on - never going down. I have TensorFlow 2.1, Python 3.7.7, and a GPU with compute capability > 7.0.

Could this be an issue in TensorFlow? Has anyone else had this issue?

Or could it be an issue with the loss function? Thanks


"
40994,SavedModel of Keras Model does not save the trainable status,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Google Colab
- TensorFlow installed from: binary
- TensorFlow version (use command below): v2.2.0-0-g2b96f3662b 2.2.0
- Python version: 3.6.9
- CUDA/cuDNN version: -
- GPU model and memory: -



**Describe the current behavior**

Set `trainable` for some layers of a Keras model to `False` and save the model via `model.save(..., save_format='tf')`. Loading the model again with `tf.keras.load_model(...)` does not restore the value of `trainable` but sets the value to `True`.

**Describe the expected behavior**

I would expect the `trainable` flag to saved and loaded correctly.

**Standalone code to reproduce the issue**

https://colab.research.google.com/drive/1tYvRK8mxfvU3_SVV9P97dKUV6W9Hue_S?usp=sharing
"
40992,Run micro speech example on Apollo 2,"Sorry to bother you.

I tried to run micro speech example provided by Tensorflow Lite on Apollo 2 blue EVB but failed.

Once I load this code, the function failed.

![image](https://user-images.githubusercontent.com/61425756/86256122-d5459700-bbaf-11ea-9619-417071056778.png)

I would like to ask if Apollo 2 blue has C++11 compatibility.

Or could you tell me why this happen?

Thank you!"
40991,SavedModel file does not exist at:  try.h5/{saved_model.pbtxt|saved_model.pb},"Hi, I am trying to load a saved model using load_model('path') but i am getting the following error :

**SavedModel file does not exist at: C:\Users\YASH\try.h5/{saved_model.pbtxt|saved_model.pb}**
The path provided is correct.
i see the same issue raises at #22480 but the solutions provided there didn't worked for me.

system info:
OS: windows 10
python version : '3.7.7'
tensorflow version :  '2.2.0' 

here is a simpler version of code : 
from tensorflow.keras.applications.vgg16 import VGG16
model = VGG16(weights='imagenet', include_top=True)
model.save('try.h5')

after saving it when i tried to load it again using the following code:
mod = load_model('C:\\Users\\YASH\\try.h5')
i got the following error:

---------------------------------------------------------------------------
OSError                                   Traceback (most recent call last)
<ipython-input-9-455ec8db1264> in <module>
----> 1 mod = load_model('C:\\Users\\YASH\\try.h5')

~\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\keras\saving\save.py in load_model(filepath, custom_objects, compile)
    187       filepath = str(filepath)
    188     if isinstance(filepath, six.string_types):
--> 189       loader_impl.parse_saved_model(filepath)
    190       return saved_model_load.load(filepath, compile)
    191 

~\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\saved_model\loader_impl.py in parse_saved_model(export_dir)
    111                   (export_dir,
    112                    constants.SAVED_MODEL_FILENAME_PBTXT,
--> 113                    constants.SAVED_MODEL_FILENAME_PB))
    114 
    115 

OSError: SavedModel file does not exist at: C:\Users\YASH\try.h5/{saved_model.pbtxt|saved_model.pb}
"
40989,_MklSoftmax 2-2.5x Slower in 1.15 Compared to 1.14 and 1.13,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `intelaipg/intel-optimized-tensorflow:1.14.0-mkl-py3` and `intelaipg/intel-optimized-tensorflow:1.15.2-mkl-py3`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): see OS
- Python version: 3.6
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
We found that the `_MklSoftmax` operation is quite a bit slower in 1.15 than it was in Tf 1.13 and 1.14, about 2-2.5x worse. 

**Describe the expected behavior**
Comparable speed to previous versions.

**Standalone code to reproduce the issue**
n/a but confirmed by @NeoZhangJianyu (see https://github.com/tensorflow/tensorflow/issues/39851#issuecomment-652150250)

**Other info / logs**
n/a
"
40988,Too much information of GPU in output while running simple code,"This template is for miscellaneous issues not covered by the other issue categories.

Python 3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
2020-07-01 18:46:30.457181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
>>> a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
2020-07-01 18:49:32.218612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-07-01 18:49:32.251014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.2GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2020-07-01 18:49:32.258807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-07-01 18:49:32.265844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-07-01 18:49:32.272713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-07-01 18:49:32.277604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-07-01 18:49:32.285003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-07-01 18:49:32.292380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-07-01 18:49:32.305864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-07-01 18:49:32.310903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-01 18:49:32.314028: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-07-01 18:49:32.326897: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21c2acb81f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-01 18:49:32.333259: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-01 18:49:32.337469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.2GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2020-07-01 18:49:32.346985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-07-01 18:49:32.351459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-07-01 18:49:32.356745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-07-01 18:49:32.362342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-07-01 18:49:32.366372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-07-01 18:49:32.371184: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-07-01 18:49:32.377026: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-07-01 18:49:32.381145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-01 18:49:32.930263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-01 18:49:32.938544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
2020-07-01 18:49:32.941809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
2020-07-01 18:49:32.944603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4602 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-07-01 18:49:32.955792: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21c539aa230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-01 18:49:32.961195: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060, Compute Capability 7.5
>>> b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])
>>> c = tf.matmul(a, b)
2020-07-01 18:51:13.160931: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
>>> print(c)
tf.Tensor(
[[22. 28.]
 [49. 64.]], shape=(2, 2), dtype=float32)
>>>

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
40987,properly setting up and compiling in windows with tensorflow c api,"https://www.tensorflow.org/install/lang_c

Add,window eg with at least mingw or cmake,or simply from cmd line/*terminal* with gcc/g++?

For example, why should someone use this method? How is it useful?
Well,you see i wanted to make sure when I use it in production in the years to come I can make sure.
I as an individual can make it work even if I am stranded on an island with no internet.
With probably only a disk filled with backup of binaries and backup of OS in iso.etc. 

Is the link to the source code correct?yes

Are all parameters defined and formatted correctly?yes

Are return values defined?yes

I need help in getting it to work.After getting it to work. Then ,well I will contribute respectively.

My trial,as known we need to setup path point to the compiler path/*area.Then we declare lib included files right?
Then we go to source code,take all bam,compiled piece of essence.

Below is my attempt.well second attempt

D:\Coding\C\ALLCinone>set PATH=D:\Coding\C\ALLCinone\MinGW64\bin;D:\Coding\C\ALLCinone\MinGW64\x86_64-w64-mingw32\bin;C:\Windows\system32;C:\Windows;(Bloated Winapps path don't need to bother)

D:\Coding\C\ALLCinone>cmd /k""set includepath=E:\Coding\C\WinGW\include;E:\Coding\C\WinGW\msys\1.0\include""

D:\Coding\C\ALLCinone>cd D:\Coding\C\3rdpartylib\libtensorflow-gpu-windows-x86_64-\include

D:\Coding\C\3rdpartylib\libtensorflow-gpu-windows-x86_64-\include>set includepath=%includepath%;%cd%

D:\Coding\C\3rdpartylib\libtensorflow-gpu-windows-x86_64-\include>cd D:\Coding\C\ljwversrccodes\testtensorflow\test2

D:\Coding\C\ljwversrccodes\testtensorflow\test2>gcc hello_tf.c -l""%includepath%"" -o hello_tf
hello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory
 #include <tensorflow/c/c_api.h>
                                ^
compilation terminated.

D:\Coding\C\ljwversrccodes\testtensorflow\test2>%includepath%
The system cannot find the drive specified.

D:\Coding\C\ljwversrccodes\testtensorflow\test2>echo %includepath%
E:\Coding\C\WinGW\include;E:\Coding\C\WinGW\msys\1.0\include;D:\Coding\C\3rdpartylib\libtensorflow-gpu-windows-x86_64-\include

D:\Coding\C\ljwversrccodes\testtensorflow\test2>cd D:\Coding\C\3rdpartylib\libtensorflow-gpu-windows-x86_64-\include\tensorflow

D:\Coding\C\3rdpartylib\libtensorflow-gpu-windows-x86_64-\include\tensorflow>set includepath=%includepath%;%cd%

D:\Coding\C\3rdpartylib\libtensorflow-gpu-windows-x86_64-\include\tensorflow>cd D:\Coding\C\3rdpartylib\libtensorflow-gpu-windows-x86_64-\include\tensorflow

D:\Coding\C\3rdpartylib\libtensorflow-gpu-windows-x86_64-\include\tensorflow>cd D:\Coding\C\ljwversrccodes\testtensorflow\test2

D:\Coding\C\ljwversrccodes\testtensorflow\test2>gcc hello_tf.c -l""%includepath%"" -o hello_tf
hello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory
 #include <tensorflow/c/c_api.h>
                                ^
compilation terminated.

D:\Coding\C\ljwversrccodes\testtensorflow\test2>gcc hello_tf.c -L""%includepath%"" -o hello_tf
hello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory
 #include <tensorflow/c/c_api.h>
                                ^
compilation terminated.

D:\Coding\C\ljwversrccodes\testtensorflow\test2>g++ hello_tf.c -L""%includepath%"" -o hello_tf
hello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory
 #include <tensorflow/c/c_api.h>
                                ^
compilation terminated.

D:\Coding\C\ljwversrccodes\testtensorflow\test2>g++ hello_tf.c -I""%includepath%"" -o hello_tf
hello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory
 #include <tensorflow/c/c_api.h>
                                ^
compilation terminated.

D:\Coding\C\ljwversrccodes\testtensorflow\test2>g++ hello_tf.c -I%includepath% -o hello_tf
hello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory
 #include <tensorflow/c/c_api.h>
                                ^
compilation terminated.

D:\Coding\C\ljwversrccodes\testtensorflow\test2>g++ hello_tf.c -I%includepath% -o hello_tf
hello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory
 #include <tensorflow/c/c_api.h>
                                ^
compilation terminated.

D:\Coding\C\ljwversrccodes\testtensorflow\test2>g++ hello_tf.c -I %includepath% -o hello_tf
hello_tf.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory
 #include <tensorflow/c/c_api.h>
                                ^
compilation terminated.

D:\Coding\C\ljwversrccodes\testtensorflow\test2>#(someone please save me from this hell.w)


"
40986,Frozen TF2.0 model to TF1.x pb model,"Linux, Tensorflow2.0
i also want to convert TF2.0 model() to TF1.x pb model to inference C++, but i meet another problem. please read the page [https://github.com/esdu/misc/blob/master/bug_report_lstm_freeze.ipynb], i get same problem, 
if use keras.layers.GruCell i whill get ""tensorflow.python.framework.errors_impl.InvalidArgumentError: Input 7 of node prefix/out_model/rnn/while was passed float from prefix/rnn/bias:0 incompatible with expected resource.""
if use keras.layers.GruCell i whill get ""ValueError: Input 0 of node import/lstm/while/ReadVariableOp/Enter was passed float from import/lstm/kernel:0 incompatible with expected resource."""
40985,ValueError: Unrolling requires a fixed number of timesteps.,"Hi, I am trying to build a model with tensorflow 2.1.0. I was getting this error in model.fit. Can anyone please let me know how this can be resolved? 

checkpoint = ModelCheckpoint('test/checkpointv7', monitor='acc', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]
model.fit(input_data, output_data,batch_size=2, epochs=20, callbacks=callbacks_list)

Epoch 1/20
 8/10 [=======================>......] - ETA: 1s - loss: 1.9467 - acc: 0.1915     
Epoch 00001: acc improved from -inf to 0.21429, saving model to test/checkpointv7
Traceback (most recent call last):
  File ""MLtxt2txtv7.py"", line 633, in <module>
    model.fit(input_data, output_data,batch_size=2, epochs=20, callbacks=callbacks_list)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 397, in fit
    prefix='val_')
  File ""/usr/lib64/python3.6/contextlib.py"", line 88, in __exit__
    next(self.gen)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 771, in on_epoch
    self.callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py"", line 302, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py"", line 992, in on_epoch_end
    self._save_model(epoch=epoch, logs=logs)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py"", line 1029, in _save_model
    self.model.save(filepath, overwrite=True)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1008, in save
    signatures, options)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py"", line 115, in save_model
    signatures, options)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py"", line 886, in save
    checkpoint_graph_view)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_serialization.py"", line 74, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py"", line 142, in list_functions
    self._serialization_cache)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 2420, in _list_functions_for_serialization
    .list_functions_for_serialization(serialization_cache))
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py"", line 91, in list_functions_for_serialization
    fns = self.functions_to_serialize(serialization_cache)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 80, in functions_to_serialize
    serialization_cache).functions_to_serialize)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 95, in _get_serialized_attributes
    serialization_cache)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/model_serialization.py"", line 53, in _get_serialized_attributes_internal
    serialization_cache))
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 104, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 162, in wrap_layer_functions
    original_fns = _replace_child_layer_functions(layer, serialization_cache)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 258, in _replace_child_layer_functions
    serialization_cache).functions)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 95, in _get_serialized_attributes
    serialization_cache)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 104, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 162, in wrap_layer_functions
    original_fns = _replace_child_layer_functions(layer, serialization_cache)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 258, in _replace_child_layer_functions
    serialization_cache).functions)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 95, in _get_serialized_attributes
    serialization_cache)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 104, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 172, in wrap_layer_functions
    '{}_layer_call_and_return_conditional_losses'.format(layer.name))
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 513, in add_function
    self.add_trace(*self._input_signature)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 428, in add_trace
    trace_with_training(True)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 426, in trace_with_training
    fn.get_concrete_function(*args, **kwargs)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 557, in get_concrete_function
    return super(LayerCall, self).get_concrete_function(*args, **kwargs)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 909, in get_concrete_function
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 534, in wrapper
    ret = method(*args, **kwargs)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py"", line 113, in wrap_with_training_arg
    lambda: replace_training_and_call(False))
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py"", line 59, in smart_cond
    pred, true_fn=true_fn, false_fn=false_fn, name=name)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/smart_cond.py"", line 54, in smart_cond
    return true_fn()
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py"", line 112, in <lambda>
    lambda: replace_training_and_call(True),
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py"", line 108, in replace_training_and_call
    return wrapped_call(*args, **kwargs)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 576, in call_and_return_conditional_losses
    return layer_call(inputs, *args, **kwargs), layer.get_losses_for(inputs)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/recurrent_v2.py"", line 417, in call
    zero_output_for_mask=self.zero_output_for_mask)
  File ""/home/iiit/revanth.parvathaneni/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 3926, in rnn
    raise ValueError('Unrolling requires a fixed number of timesteps.')
ValueError: Unrolling requires a fixed number of timesteps.
"
40984,A function that is wrapped with tf.function gives wrong gradients on loss functions that are themselves wrapped by the same decorator,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
No
- TensorFlow installed from (source or binary):
Binary
- TensorFlow version (use command below):
2.2.0
- Python version:
3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

I have two versions of loss function, one decorated with tf.function and the other not,  and I have two functions that compute the gradients using these two loss functions, one decorate with tf.function and the other not . When I use the gradient function that is not decorate I get the same results for both the loss function. However, when I use the gradient function that is decorated I get different results and in particular I get a wrong result for the loss function that is decorated.

**Describe the expected behavior**

I would expect all of the above to give the same result.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/1erNOChp355OTiCwWiizPdjA1OT1s3HYV?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40983,adding Mixout module,"**System information**
- TensorFlow version (you are using): tf-1.15
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
Mixout is a module proposed [here](https://openreview.net/pdf?id=HkgaETNtDB). In short, it resembles dropout, but rather than setting the randomly selected weights to zero, it replaces them with the weights in the pre-trained model. By doing so it helps to improve the stability in downstream fine-tuning tasks.

**Will this change the current api? How?**
Yes, it would require a new API like `tf.nn.mixout` with similar signature with `tf.nn.dropout`

**Who will benefit with this feature?**
People who wanna use BERT in downstream tasks with small datasets. This feature (as claimed in the paper) improve stability.

**Any Other info.**
A [pytorch version](https://github.com/bloodwass/mixout) has been provided by the author. "
40982,UnknownError:  [_Derived_]  CUDNN_STATUS_BAD_PARAM,"# System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: Yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Colab
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

### Describe the problem
When using `mask_zero=True` in `tf.keras.layers.Embedding` in a GPU environment LSTM layers causes:

```
UnknownError:  [_Derived_]  CUDNN_STATUS_BAD_PARAM
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1496): 'cudnnSetRNNDataDescriptor( data_desc.get(), data_type, layout, max_seq_length, batch_size, data_size, seq_lengths_array, (void*)&padding_fill)'
	 [[{{node cond_17/then/_0/CudnnRNNV3}}]]
	 [[model/time_distributed_1/lstm/StatefulPartitionedCall]] [Op:__inference_train_function_16505]

Function call stack:
train_function -> train_function -> train_function
```

Full error trace is attached. 

[error_trace.txt.zip](https://github.com/tensorflow/tensorflow/files/4857504/error_trace.txt.zip)

Here's how we defined our network:

```
# Input and embeddings for words
word_in = Input(shape=(max_len, max_len_word,))

# Word level embedding
emb_word = TimeDistributed(
    Embedding(input_dim=(n_words + 2), 
        output_dim=200,
        input_length=max_len_word, 
        weights=[get_embedding_matrix(word_index, 
            embedding_path, embedding_dim)], 
        trainable=False,
        mask_zero=True
	)	
)(word_in)

# Word LSTM to get sent encodings by words
emb_sent = TimeDistributed(LSTM(units=32, return_sequences=False))(emb_word)

main_lstm = Bidirectional(LSTM(units=64, return_sequences=True))(emb_sent)
out = TimeDistributed(Dense(n_tags + 1, activation=""softmax""))(main_lstm)

model = Model([word_in], out)
```

A few observations:
- When using a CPU environment, this issue does not show up. 
- When using `mask_zero=False` this issue does not show up but leads to misleading accuracy as obvious. 

### Source code / logs
[Colab Notebook](https://colab.research.google.com/gist/sayakpaul/b18aeca12e36f0f367e19548b81bf6a7/whats_the_news_model_baseline-1.ipynb). 

"
40981,New model from same config not equal,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
```
 nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019
Cuda compilation tools, release 10.1, V10.1.105
```
- GPU model and memory: Nvidia MX110 2GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""` v2.2.0-rc4-8-g2b96f3662b 2.2.0


**Describe the current behavior**
I created a basic model and saved its configuration using `get_config()`
**Describe the expected behavior**
I created a new model using the same configuration `tf.keras.Sequential.from_config()` and compared configurations of both, but both were not equal.
**Standalone code to reproduce the issue**

Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import json
import numpy as np

# Build the model

model = Sequential([
    Dense(units=32, input_shape=(32, 32, 3), activation='relu', name='dense_1'),
    Dense(units=10, activation='softmax', name='dense_2')
])
config_dict = model.get_config()

model_same_config = tf.keras.Sequential.from_config(config_dict)
print('Same config:', 
      model.get_config() == model_same_config.get_config())
print('Same value for first weight matrix:', 
      np.allclose(model.weights[0].numpy(), model_same_config.weights[0].numpy()))
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40980,tf2.1.0 training efficiency problem ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.7 
- CUDA/cuDNN version: 10.1.0/7.6.4
- GPU model and memory: Tesla V100*4  32478MiB


**Describe the current behavior**
I use tf2.1.0 keras API to build network and use tf API to build a semantic segmentation distillation loss. And I find that the training speed is about 42.1 epochs/day. I try to adjust the ""batch size""but the result is almost the same.

If I use tf1.10.0 tf API to build network and loss,  the training speed is about 134  epochs/day.

**Describe the expected behavior**
TF2.1.0 Training speed is not lower than tf1.10.0.

**Standalone code to reproduce the issue**
I call function ""pairwise_suprvise"" to calculate my loss(The student_feature/teacher_feature shape is [N, 512, 512, 3]):

My code is linked:  https://github.com/chenpengf0223/semantic_segmentation_distillation/blob/master/distillation_loss.py"
40978,"importing tensorflow gives error ""illegal instruction""","Hi.. I am trying to install tensorflow  in my python3 virtual environment.
OS- centos 7.8kvm
tensorflow installed from binary
tensorflow version 1.15.0
python version 3.6.8
installed in virtualenv  using pip with the command
`TMPDIR=/data/vincents/ pip install --cache-dir=/data/vincents/ --build /data/vincents/ tensorflow==1.15.0`
I have 2GB RAM and I am using 2GB swap memory


this is my CPU info
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                2
On-line CPU(s) list:   0,1
Thread(s) per core:    1
Core(s) per socket:    1
Socket(s):             2
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 13
Model name:            QEMU Virtual CPU version 2.5+
Stepping:              3
CPU MHz:               2397.222
BogoMIPS:              4794.44
Hypervisor vendor:     KVM
Virtualization type:   full
L1d cache:             32K
L1i cache:             32K
L2 cache:              4096K
L3 cache:              16384K
NUMA node0 CPU(s):     0,1
Flags:                 fpu de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pse36 clflush mmx fxsr sse sse2 syscall nx lm rep_good nopl xtopology eagerfpu pni cx16 x2apic hypervisor lahf_lm

I have succeeded to install tensorflow=1.15.0, but whenever  I try to import it in a python shell in throws error
`illegal instruction`
![106207928_274334003654354_6896801223456467874_n](https://user-images.githubusercontent.com/35559892/86229455-8c8edd80-bbb1-11ea-8e2b-af699107dcd3.jpg)

DO I NEED TO UPGRADE MY SERVER TO 4CPU? OR IS THERE SOME OTHER PROBLEM?

N.B: I CANNOT SWITCH TO ANY OTHER VERSION. I NEED EXACTLY THIS VERSION

"
40977,"Bug: You must feed a value for placeholder tensor X with dtype Y and shape [?,?]","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS High Sierra
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): >= 2.0
- Python version: 3.6
- Running on: CPUs (But I guess it happens on GPUs as well)

From my experience, this kind of errors happens very often. Here is a (dumb) example where I write a custom layer and pass some parameters when I call that layer. Running the following code results in the below error:
```
import tensorflow as tf
from tensorflow.keras import backend as K

class CustomEmbedding(tf.keras.layers.Layer):
    def __init__(self, masking_boolean, vocab, dimension, **kwargs):
        self.masking_boolean = masking_boolean
        self.vocab = vocab
        self.dimension = dimension
        super(CustomEmbedding, self).__init__(**kwargs)
    def build(self, input_shape):
        self.kernel = self.add_weight(name='kernel', 
                                      shape=(self.vocab, self.dimension),
                                      initializer='glorot_uniform', dtype='float32',
                                      trainable=True)
        super(CustomEmbedding, self).build(input_shape)
    def call(self, inputs):
        return tf.nn.embedding_lookup(params=self.kernel, ids=inputs)
    def compute_mask(self, inputs, mask=None):
        return self.masking_boolean

    def compute_output_shape(self, input_shape):
        return (K.shape(input_shape)[0], K.shape(input_shape)[1], self.dimension)

def main():
    def create_model():
        sentence = tf.keras.layers.Input(dtype='int32', shape=(None,), name='sentence')
        pos_ids_mask_boolean = K.not_equal(0, sentence)
        pos_ids_mask_float = K.cast(pos_ids_mask_boolean, dtype='float32')
        a = CustomEmbedding(pos_ids_mask_boolean, 500, 512)(sentence)
        a = a*pos_ids_mask_float
        model = tf.keras.models.Model(inputs=[sentence], outputs=a)
        return model
    model = create_model()

if __name__ == '__main__':
    main()
```
```
tensorflow.python.framework.errors_impl.InvalidArgumentError:  You must feed a value for placeholder tensor 'sentence' with dtype int32 and shape [?,?]
[[node sentence (defined at bug.py:32) ]] [Op:__inference_keras_scratch_graph_33]
```

Fixing this for this case is actually easy because this example is small (see the code below). Nonetheless when it comes to a large project it is hard to find and debug this (it is a nightmare, actually, because I have to remove a lot of code to simplify the model until I find the root of the error).


```
import tensorflow as tf
from tensorflow.keras import backend as K

class CustomEmbedding(tf.keras.layers.Layer):
    def __init__(self, masking_boolean, vocab, dimension, **kwargs):
        self.masking_boolean = masking_boolean
        self.vocab = vocab
        self.dimension = dimension
        super(CustomEmbedding, self).__init__(**kwargs)
    def build(self, input_shape):
        self.kernel = self.add_weight(name='kernel', 
                                      shape=(self.vocab, self.dimension),
                                      initializer='glorot_uniform', dtype='float32',
                                      trainable=True)
        super(CustomEmbedding, self).build(input_shape)
    def call(self, inputs):
        return tf.nn.embedding_lookup(params=self.kernel, ids=inputs)
    def compute_mask(self, inputs, mask=None):
        return self.masking_boolean

    def compute_output_shape(self, input_shape):
        return (K.shape(input_shape)[0], K.shape(input_shape)[1], self.dimension)

def main():
    def create_model():
        sentence = tf.keras.layers.Input(dtype='int32', shape=(None,), name='sentence')
        pos_ids_mask_boolean = K.not_equal(0, sentence)
        pos_ids_mask_float = K.cast(K.not_equal(0, sentence), dtype='float32')
        a = CustomEmbedding(pos_ids_mask_boolean, 500, 512)(sentence)
        a = a*pos_ids_mask_float
        model = tf.keras.models.Model(inputs=[sentence], outputs=a)
        return model
    model = create_model()

if __name__ == '__main__':
    main()

```

So I posted it here to raise the issue. I hope the TF team will fix it soon. 


"
40976,Query result not show aliased functions,"If we search `tf.argmax` in [tensorflow r1.15 documentation](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/math/argmax), no result get for tf 1.x

However, if search ""tf.math.argmax"", you will get it.

But they're both annations:
```Python
# pylint: disable=redefined-builtin
@tf_export(v1=[""math.argmax"", ""argmax""])         # !!!! This line
@deprecation.deprecated_args(None, ""Use the `axis` argument instead"",
                             ""dimension"")
@_set_doc(
    gen_math_ops.arg_max.__doc__.replace(""dimensions"", ""axes"").replace(
        ""dimension"", ""axis""))
def argmax(input,
           axis=None,
           name=None,
           dimension=None,
           output_type=dtypes.int64):
  axis = deprecation.deprecated_argument_lookup(
      ""axis"", axis, ""dimension"", dimension)
  return argmax_v2(input, axis, output_type, name)
```

Why only show the first aliased annotation in documentation? "
40975,Resizing in Tensorflow Lite,"Dear Tensorflow developers, 
I have got a trained model that has Conv, GlobalAveargePooling, Fully Connected, Reshape, and Deconve (upsampling) layers.  I converted the frozen graph to tflite and this model with fixed input size didn't have any errors when running but when resizing I get below error.
""Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/kernel_util.cc:224 d1 == d2 || d1 == 1 || d2 == 1 was not true. Node number 94 (ADD) failed to prepare.""
anybody can help me?
Thanks!"
40974,Import error-- OSError: [WinError 193] %1 is not a valid Win32 application,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.2
- Python version:3.8 64 bit
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.0
- GPU model and memory: RTX 2060, 6GB 



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
![tensorflow](https://user-images.githubusercontent.com/55295294/86224846-05d50300-bba7-11ea-989f-9ff087e62858.PNG)
i have installed all the requirement given in tensorflow website but keep getting this error. I have one more question- if everything is 64 bit then why it is showing win32?

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40973,distribute keras sparse feature training error,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
""16.04.6 LTS (Xenial Xerus)""
- TensorFlow installed from  
binary
- TensorFlow version (use command below):
2.2.0
- Python version:
3.7.3
- CUDA/cuDNN version:
- GPU model and memory:
Tesla P40  22919MiB


**Standalone code to reproduce the issue** (only part of the code)
```python
import tensorflow as tf
import tensorflow.keras.backend as K
import sys

from datetime import date, timedelta
from tensorflow.keras.layers import *
from tensorflow.keras import Model, Sequential
from meta import ModelMeta
from dataset import train_input_fn
from layers import EmbedLayerForSparse
from deepctr.layers import InnerProductLayer, PredictionLayer
batch_thread_number = 15
batch_size = 8192
dimension = 16

strategy = tf.distribute.experimental.CentralStorageStrategy()
with strategy.scope():
    inputs = {}
    outputs = {}
    for k, v in capacity_map.items():
        inputs[k] = Input(shape=(v,), sparse=True, name=k)
        outputs[k] = EmbedLayerForSparse(vocabulary_size=v, embedding_size=dimension, embed_initializer=tf.keras.initializers.he_normal(), n\
ame='SparseLayer'+k)(inputs[k])
    linear = list(outputs.values())
    inner = InnerProductLayer()([Reshape((1, dimension))(f) for f in outputs.values()])
    inner_reshaped = Reshape((inner.get_shape().as_list()[1],))(inner)
    concat = Concatenate(axis=1)(linear + [inner_reshaped])
    outputs = ReLU()(BatchNormalization()(concat))
    outputs = Dense(512)(outputs)
    outputs = ReLU()(BatchNormalization()(outputs))
    outputs = Dense(128)(outputs)
    outputs = ReLU()(BatchNormalization()(outputs))
    outputs = Dense(1)(outputs)
    outputs = PredictionLayer(use_bias=False)(outputs)

    model = tf.keras.Model(inputs=list(inputs.values()), outputs=outputs)
    model_meta = ModelMeta(model, candidate_meta)
    initial_learning_rate = 0.001
    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
            initial_learning_rate,
            decay_steps=1000,
            decay_rate=0.96,
            staircase=True)
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.kera\
s.metrics.AUC(num_thresholds=10000)])
    print('compile complete')
with strategy.scope():
  while start_date < end_date:
    dataset = train_input_fn('/path/to' + start_date.isoformat(), batch_thread_number, batch_size, capacity_map)
    model.fit(dataset, batch_size=batch_size, callbacks=[tf.keras.callbacks.TensorBoard(log_dir='/logs/' + start_date.isoformat(), profile_batch=0)])
    model.save('model.' + start_date.isoformat())
    start_date += timedelta(days=1)
    break

```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
work.log:
hon.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
No similar op available at this time.
WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/parsing_config.py:719: sparse_merge (from tensorflow.pyt
hon.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
No similar op available at this time.
2020-07-01 16:16:14.067956: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[6689] = [527,217950] is repeated
2020-07-01 16:16:14.123837: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[8964] = [527,217950] is repeated
2020-07-01 16:16:14.556197: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[6689] = [527,217950] is repeated
2020-07-01 16:16:14.606631: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[20296] = [446,1263545] is repeated
2020-07-01 16:16:14.605999: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[20296] = [446,1263545] is repeated
2020-07-01 16:16:14.670875: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[8964] = [527,217950] is repeated
2020-07-01 16:16:14.806522: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[2997] = [104,246925] is repeated
2020-07-01 16:16:15.025014: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[27417] = [1409,577748] is repeated
2020-07-01 16:16:15.616607: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[121] = [1,827513] is repeated
2020-07-01 16:16:34.125064: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[115717] = [4149,1289703] is repeated
2020-07-01 16:16:34.184952: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
2020-07-01 16:16:34.187837: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[183021] = [4086,3891] is repeated
Traceback (most recent call last):
  File ""pnn.py"", line 67, in <module>
    model.fit(dataset, batch_size=batch_size, callbacks=[tf.keras.callbacks.TensorBoard(log_dir='/logs/' + start_date.isoformat(), profile_ba
tch=0)])
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 848, in fit
    tmp_logs = train_function(iterator)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1665, in _filtered_call
    self.captured_inputs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 598, in call
    ctx=ctx)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError:  indices[6689] = [527,217950] is repeated
	 [[{{node SerializeManySparse_10}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]]
	 [[IteratorGetNext]] [Op:__inference_train_function_25126]

Function call stack:
train_function



ps.log:
2020-07-01 16:16:34.184952: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[183021] = [4086,3891] is repeated
2020-07-01 16:16:34.187837: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at serialize_sparse_op.cc:382 : Invalid argumen
t: indices[183021] = [4086,3891] is repeated
Traceback (most recent call last):
  File ""pnn.py"", line 67, in <module>
    model.fit(dataset, batch_size=batch_size, callbacks=[tf.keras.callbacks.TensorBoard(log_dir='/logs/' + start_date.isoformat(), profile_ba
tch=0)])
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 848, in fit
    tmp_logs = train_function(iterator)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1665, in _filtered_call
    self.captured_inputs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 598, in call
    ctx=ctx)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError:  indices[6689] = [527,217950] is repeated
	 [[{{node SerializeManySparse_10}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]]
	 [[IteratorGetNext]] [Op:__inference_train_function_25126]

Function call stack:
train_function
"
40972,Official Docker Image Build that Sugget GPU Support Utilizes CPU Only,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): official Docker image (tensorflow/tensorflow:1.12.3-gpu-py3)
- TensorFlow version: 1.12.3
- Python version: 3.5.2
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: (unchanged as is in the official docker image)
- GPU model and memory: GTX1050, 4042MiB



**Describe the problem**
Official release of docker image `tensorflow/tensorflow:1.12.3-gpu-py3` suggests gpu support in its tag, yet it does not utilize GPU. 

I have `nvidia-docker` (the native support version, with the `--gpus all` syntax) installed correctly. I've verified it thorugh additional test in `tensorflow/tensorflow:1.15.2-gpu-py3`, it worked fine, unlike `tensorflow/tensorflow:1.12.3-gpu-py3`.
**Provide the exact sequence of commands / steps that you executed before running into the problem**
- Run python3 in a container created from `tensorflow/tensorflow:1.12.3-gpu-py3`
`docker run -it --rm --gpus all tensorflow/tensorflow:1.12.3-gpu-py3 python3`
- Execute the following code
```
import tensorflow as tf
with tf.device(""gpu:0""):
     c=tf.constant(0)

with tf.Session() as sess:
     sess.run(c)
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

After executing code in container created from `tensorflow/tensorflow:1.12.3-gpu-py3`, the error suggests that there is no avaliable GPU device:
```
InvalidArgumentError (see above for traceback): Cannot assign a device for operation Const: Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.
	 [[node Const (defined at <stdin>:2)  = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [] values: 0>, _device=""/device:GPU:0""]()]]
```

The code above works fine in `tensorflow/tensorflow:1.15.2-gpu-py3`.
"
40969,"Missing ""Connected to"" column in model summary","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04.2 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
Binary
- TensorFlow version (use command below):
v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version:
Python 3.7.3
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
10.2
- GPU model and memory:
TITAN X (Pascal), ~12GB

**Describe the current behavior**
`model.summary()` output is missing column `Connected to`

**Describe the expected behavior**
it should contain the column

**Standalone code to reproduce the issue**
```
import tensorflow as tf

def res_net_block(shape):
    filters = shape[-1]

    inputs = tf.keras.layers.Input(shape)
    x = tf.keras.layers.Conv3D(filters=filters, kernel_size=3, padding='same')(inputs)
    outputs = x + inputs

    return tf.keras.Model(inputs, outputs)

def encoder(shape):
    kernel_size = 3
    strides = 2

    inputs = tf.keras.layers.Input(shape)
    outputs = res_net_block(inputs.shape[1:])(inputs)

    return tf.keras.Model(inputs, outputs)

shape = [256,256,128,1]
model = encoder(shape)
model.summary()
```
Summary output looks like below:
```
Model: ""model_36""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_42 (InputLayer)        [(None, 256, 256, 128, 1) 0         
_________________________________________________________________
model_35 (Model)             (None, 256, 256, 128, 1)  28        
=================================================================
Total params: 28
Trainable params: 28
Non-trainable params: 0
_________________________________________________________________
```

**Other info / logs**
Interestingly, if I move the addition out of `res_net_block` into `encoder`, display is as expected.
```
def res_net_block(shape):
    filters = shape[-1]

    inputs = tf.keras.layers.Input(shape)
    outputs = tf.keras.layers.Conv3D(filters=filters, kernel_size=3, padding='same')(inputs)

    return tf.keras.Model(inputs, outputs)

def encoder(shape):
    kernel_size = 3
    strides = 2

    inputs = tf.keras.layers.Input(shape)
    x = res_net_block(inputs.shape[1:])(inputs)
    outputs = x + inputs # This addition is not here in previous code, instead it's inside `res_net_block` function

    return tf.keras.Model(inputs, outputs)
```
Output with above function definitions:
```
Model: ""model_38""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_44 (InputLayer)           [(None, 256, 256, 12 0                                            
__________________________________________________________________________________________________
model_37 (Model)                (None, 256, 256, 128 28          input_44[0][0]                   
__________________________________________________________________________________________________
tf_op_layer_AddV2_20 (TensorFlo [(None, 256, 256, 12 0           model_37[1][0]                   
                                                                 input_44[0][0]                   
==================================================================================================
Total params: 28
Trainable params: 28
Non-trainable params: 0
__________________________________________________________________________________________________
```"
40967,Plase Help!,"package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto: cannot find package ""github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto"" in any of:
        c:\go\src\github.com\tensorflow\tensorflow\tensorflow\go\core\protobuf\for_core_protos_go_proto (from $GOROOT)
        C:\Users\JairForero\go\src\github.com\tensorflow\tensorflow\tensorflow\go\core\protobuf\for_core_protos_go_proto (from $GOPATH)"
40965,End2end Transformer Training by Using Ragged Tensor ,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (tf nightly):
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
I'd like to write a [transformer model](https://www.tensorflow.org/tutorials/text/transformer) by end2end using Ragged Tensor to speed up training. However, I found that there're some ops that Ragged Tensor could not support, ex. `matmul`, `relu`.  Do you have plan to support the other tf ops for Ragged Tensor?

In general, there are two kinds of ops to support:
1. Ragged Tensor op could reuse the kernel written for regular tensor. ex. `relu`
2. Ragged Tensor op could not reuse the kernel written for regular tensor. ex. `logits = tf.einsum(""BTNH,BFNH->BNFT"", key, query)`, where dimension `F` and `T` are ragged.

**Will this change the current api? How?** No.

**Who will benefit with this feature?**

Those models with batches of variable-length sequential inputs, ex. Transformer.

**Any Other info.**
"
40959,How to verify Tensorflow install,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/install/pip#windows_1

## Description of issue (what needs changing): The documentation gives a command to ""verify the install""... but NO clear indication of what should be the result. I get a list of 9 warnings (all CUDA-related) interspersed with 8 information messages. Finally there is a ""tf.tensor(72.93745, shape=(), dtype=float32)"" at the end. Is this correct? How would I know?

### Clear description

See above

### Correct links

Is the link to the source code correct? n/a

### Parameters defined

Are all parameters defined and formatted correctly? n/a

### Returns defined

Are return values defined? n/a

### Raises listed and defined

n/a

### Usage example

Is there a usage example? Half of one - it lacks any output to check against, or instructions on how to interpret the result

### Request visuals, if applicable

n/a

### Submit a pull request?

No - I am far too new to github/tensorflow to ask sensible questions, let alone give sensible answers
"
40956,ESP32 doenst run correct anymore - Person Detection with Esp32 Camera,"Hello Folks,

the project build in ESP32 even 4.0, 4.1, 4.2 or latest master of esp-idf build correct but when running there is an error with the camera acquisition.

./components/esp32-camera/driver/camera.c:1412 (discriminator 2)

or in ./components/esp32-camera/driver/camera.c:1415 (discriminator 2)

So, right now cant tell if a tensorflow lite/micro problem or with the camera driver/settings on it.

Can someone in this area test it again???"
40955,BinaryOp vs OpKernel in Im2Col,"I have just started to create my custom OP based on ""conv_ops_using_gemm.cc"" and ""quantized_conv_ops.cc"". I want to modify the im2col algorithm inside TensorFlow to improve the performance of the inference. 

I have some questions in both files. I have some question from what I understood from the tutorial and  conv_ops_using_gemm.cc shown is the following:

1. There are some methods called **ClassName+OP** or **ClassName+functor**, I did not get the difference between them in the TensorFlow library context.
2. These classes OpKernel or BinaryOp, I do not get what are they responsible for and How I can understand them more deeply from the documentation. 
3. In [Part(1),](https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/conv_ops_using_gemm.cc#L565) what I understood, it is a registration for the kernel on the CPU to be called from the python by ""tf.nn.conv2d()"", but I did not get how conv2d are called Im2ColConvFunctor from Conv2DUsingGemmOp class at the end of this class using ""conv_factor"" in [Part(2)](https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/conv_ops_using_gemm.cc#L551).

Part(1):

```
#define REGISTER_CPU(T) \
 REGISTER_KERNEL_BUILDER( \
 Name(""Conv2D"").Device(DEVICE_CPU).TypeConstraint<T>(""T""), \
 Conv2DUsingGemmOp< \
 T, Im2ColConvFunctor<T, T, T, FastGemmFunctor<T, T, T>>>);
```

Part(2):

```
 TConvFunctor conv_functor;
 conv_functor(context, input.flat<T>().data(), batch, input_rows, input_cols,
 in_depth, filter.flat<T>().data(), filter_rows, filter_cols,
 out_depth, stride_rows, stride_cols, padding_,
 output->flat<T>().data(), out_rows, out_cols);
```"
40951,Problems building TensorRT engine. 'TypeError: Expected at most 1 positional arguments',"[MCNet_Model_30%_SNR10+.zip](https://github.com/tensorflow/tensorflow/files/4880911/MCNet_Model_30._SNR10%2B.zip)
(https://github.com/tensorflow/tensorflow/files/4858531/saved_model.zip)
<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Nvidia JetPack 4.4 (binary)
- TensorFlow version (use command below): tensorflow 2.1.0+nv20.4
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Receiving ""TypeError"" when I try to build the TensorRT engine. The dataset is custom and the initial saved TF model file (saved_model.pb) is attached below. This is a similar issue as seen at #34708, and I have tried everything suggested there with no luck. I have also tried changing the input shape (changing channels and batch size), but this seems to have no effect. 

**Describe the expected behavior**
Trying to convert a TF saved model and build a tensorRT engine to be saved.



**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
`import tensorflow as tf 
import numpy as np
from tensorflow.python.compiler.tensorrt import trt_convert as trt

tf.enable_eager_execution()
tf.keras.backend.set_learning_phase(0)

# User input
input_path = '/home/xv/my-recognition-python/custom_model/MCNet_Model_30%_SNR10+'
output_path = '/home/xv/my-recognition-python/custom_model/TensorRT'
precision = 'FP16'

#params = tf.experimental.tensorrt.ConversionParams(precision_mode=precision)
#converter = tf.experimental.tensorrt.Converter(input)

# Conversion Parameters
conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS
conversion_params = conversion_params._replace(
    max_workspace_size_bytes=(1<<32))
conversion_params = conversion_params._replace(precision_mode=""FP16"")
conversion_params = conversion_params._replace(
    maximum_cached_engines=100)

# Convert, Build and Save
tf.compat.v1.enable_eager_execution()
converter = trt.TrtGraphConverterV2(input_saved_model_dir=input_path,conversion_params=conversion_params)
converter.convert()
def my_input_fn():
    input = np.random.normal(size=(32,2,1024,1)).astype(np.float32)
    return input
converter.build(input_fn=my_input_fn)
converter.save(output_path)`

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
`Traceback (most recent call last):
  File ""tf2tensorrt.py"", line 31, in <module>
    converter.build(input_fn=my_input_fn)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/compiler/tensorrt/trt_convert.py"", line 1040, in build
    self._converted_func(*map(ops.convert_to_tensor, inp))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1551, in __call__
    return self._call_impl(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1570, in _call_impl
    ).format(self._num_positional_args, self._arg_keywords, args))
TypeError: Expected at most 1 positional arguments (and the rest keywords, of ['input_1']), got (<tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.6344961 ],
        [-1.4673657 ],
        [ 0.15545663],
        ...,
        [-0.0928062 ],
        [-1.3549978 ],
        [ 0.9633423 ]],

       [[-1.0417418 ],
        [-2.0699146 ],
        [-0.30908048],
        ...,
        [-0.11305276],
        [-1.1771021 ],
        [ 1.3303916 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.02007438],
        [ 0.5109657 ],
        [-1.2260785 ],
        ...,
        [-0.54254615],
        [-0.8100358 ],
        [ 0.27891546]],

       [[ 1.3610845 ],
        [ 0.24926041],
        [-0.16650145],
        ...,
        [-0.54429305],
        [-0.32332402],
        [-1.0127826 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 0.62289035],
        [ 0.29980063],
        [ 0.2861899 ],
        ...,
        [ 0.9005576 ],
        [-0.62317663],
        [-0.06627446]],

       [[-0.10040612],
        [-0.09332627],
        [ 1.1089867 ],
        ...,
        [ 1.0935025 ],
        [ 0.08065958],
        [-1.2275263 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.0846673 ],
        [ 0.51114583],
        [ 1.4352379 ],
        ...,
        [ 0.95028365],
        [ 2.7874076 ],
        [ 0.77085507]],

       [[ 0.58681023],
        [ 1.0490478 ],
        [-1.3703693 ],
        ...,
        [ 1.8135824 ],
        [-0.23638606],
        [ 0.18856032]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.45678732],
        [ 1.6005052 ],
        [-0.8796155 ],
        ...,
        [-0.9854982 ],
        [-0.9157079 ],
        [-0.65166223]],

       [[ 1.6831336 ],
        [-1.6157633 ],
        [-1.553059  ],
        ...,
        [ 0.34703007],
        [-0.14187814],
        [ 0.73059773]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 0.4139533 ],
        [ 0.50489587],
        [ 0.65386546],
        ...,
        [-0.40917957],
        [ 1.7364669 ],
        [-0.99362046]],

       [[ 0.27688766],
        [ 0.58144623],
        [ 0.40299714],
        ...,
        [ 0.7578483 ],
        [ 0.9832838 ],
        [ 1.002946  ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-1.0991313 ],
        [-2.3144197 ],
        [-0.98326117],
        ...,
        [ 0.37580004],
        [-1.4070382 ],
        [ 0.95411766]],

       [[ 1.328169  ],
        [ 0.704368  ],
        [ 1.4499707 ],
        ...,
        [ 0.60652196],
        [ 1.4832685 ],
        [ 0.684714  ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.11087849],
        [-0.07940213],
        [ 0.50273675],
        ...,
        [-0.5097304 ],
        [ 1.4458168 ],
        [-1.2201035 ]],

       [[-0.5431153 ],
        [-0.42222708],
        [ 1.092256  ],
        ...,
        [-0.04186005],
        [ 0.9809653 ],
        [-0.7850843 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 1.0818578e+00],
        [-4.6179372e-01],
        [ 4.2473122e-01],
        ...,
        [-1.0006120e+00],
        [ 1.9919460e-03],
        [ 8.5118961e-01]],

       [[-1.8546258e+00],
        [ 7.0895630e-01],
        [ 2.0718536e+00],
        ...,
        [-2.4367233e-01],
        [ 6.7389584e-01],
        [ 9.7365260e-01]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 1.0906012 ],
        [-0.06402431],
        [ 0.91972494],
        ...,
        [-0.52831906],
        [ 1.2781252 ],
        [-0.06841598]],

       [[-1.341631  ],
        [ 0.53109026],
        [-0.11353733],
        ...,
        [ 1.1344278 ],
        [ 1.4150394 ],
        [ 1.2143872 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.36829016],
        [ 1.0754083 ],
        [ 0.16599853],
        ...,
        [-1.1099495 ],
        [-0.70543027],
        [-2.4914129 ]],

       [[-0.25961915],
        [-0.33185184],
        [-1.9378744 ],
        ...,
        [-0.64549893],
        [ 0.21132562],
        [-0.6391495 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.6435254 ],
        [-0.1136331 ],
        [ 0.25582156],
        ...,
        [ 0.00787924],
        [ 1.2224247 ],
        [ 1.2220552 ]],

       [[ 1.384727  ],
        [ 1.9391284 ],
        [ 0.04586202],
        ...,
        [ 0.06961127],
        [-0.03484035],
        [ 0.17856297]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 0.28783402],
        [-1.0524169 ],
        [-1.0904337 ],
        ...,
        [ 0.43865943],
        [-0.97926116],
        [ 0.2378908 ]],

       [[ 0.9016964 ],
        [-0.06834929],
        [-1.0139452 ],
        ...,
        [-0.15281294],
        [ 1.0535744 ],
        [-0.21410678]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 1.0744122 ],
        [-0.56937873],
        [-0.11793306],
        ...,
        [ 1.4719427 ],
        [-0.44377735],
        [-0.9831226 ]],

       [[-1.5557859 ],
        [ 1.0128443 ],
        [ 2.067592  ],
        ...,
        [-0.48884177],
        [-0.5740634 ],
        [-0.293522  ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 0.8241517 ],
        [ 1.8754789 ],
        [-0.8107462 ],
        ...,
        [-0.7464624 ],
        [-1.9949435 ],
        [-1.5022945 ]],

       [[ 0.63984567],
        [ 0.47466007],
        [-0.0431034 ],
        ...,
        [-0.8277903 ],
        [-0.30004153],
        [-1.1758301 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.13899833],
        [-0.6309596 ],
        [-0.54699975],
        ...,
        [ 0.5980539 ],
        [-0.5291892 ],
        [ 0.20535517]],

       [[ 0.07299482],
        [-1.5210488 ],
        [-2.2613964 ],
        ...,
        [ 1.0103334 ],
        [ 0.8114666 ],
        [-0.6411918 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.9746104 ],
        [ 0.43699232],
        [ 0.86292136],
        ...,
        [-2.000652  ],
        [ 0.19808927],
        [-0.58109105]],

       [[ 3.002488  ],
        [-0.27825996],
        [ 0.7989333 ],
        ...,
        [-0.34547755],
        [-0.576817  ],
        [ 0.47699323]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 0.7425528 ],
        [-0.88114923],
        [ 1.2816385 ],
        ...,
        [ 0.61273754],
        [-0.43834418],
        [-1.0978663 ]],

       [[-0.21802038],
        [-0.10342378],
        [-0.6027409 ],
        ...,
        [-0.09381349],
        [-2.0900886 ],
        [ 0.34896147]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-1.4537004 ],
        [-0.23114291],
        [-0.5871747 ],
        ...,
        [ 1.7588977 ],
        [-0.64653444],
        [-0.8479624 ]],

       [[-0.8888948 ],
        [ 0.667874  ],
        [-0.11591944],
        ...,
        [ 1.5969365 ],
        [ 0.3887264 ],
        [ 2.6164393 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.71152514],
        [ 0.31899413],
        [ 0.59584296],
        ...,
        [-0.4681486 ],
        [-0.18287487],
        [-0.6718022 ]],

       [[-0.536758  ],
        [ 0.16100785],
        [ 1.1793295 ],
        ...,
        [-1.6710243 ],
        [-1.2068127 ],
        [-0.71454585]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-1.8764349 ],
        [-0.4220016 ],
        [-0.3832036 ],
        ...,
        [ 0.396611  ],
        [ 0.4031959 ],
        [ 0.35724488]],

       [[-0.65015966],
        [ 0.2224573 ],
        [ 0.20525123],
        ...,
        [-0.45926374],
        [ 0.6471609 ],
        [ 0.3332496 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 0.80413526],
        [ 1.1347907 ],
        [ 0.94075084],
        ...,
        [ 0.00755476],
        [ 0.06562049],
        [ 1.1542311 ]],

       [[-1.5574476 ],
        [ 0.69488364],
        [ 0.6990288 ],
        ...,
        [ 1.4017487 ],
        [-0.59805775],
        [-1.2751728 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.40774116],
        [-0.9957925 ],
        [ 0.7808731 ],
        ...,
        [-0.41433212],
        [ 0.5268629 ],
        [-0.9951206 ]],

       [[-1.3662847 ],
        [ 0.4806584 ],
        [-0.9774015 ],
        ...,
        [ 1.8218778 ],
        [-1.0483685 ],
        [-0.40153572]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 0.03537908],
        [ 0.30871132],
        [-0.43272868],
        ...,
        [ 0.78636587],
        [ 0.12341707],
        [-0.4693344 ]],

       [[ 0.08255825],
        [-1.047672  ],
        [ 0.5959074 ],
        ...,
        [-1.0461427 ],
        [-1.0181618 ],
        [ 1.9093345 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.66075665],
        [ 1.8946798 ],
        [-0.23847736],
        ...,
        [ 1.020657  ],
        [ 0.20324162],
        [ 1.6452681 ]],

       [[ 0.4298775 ],
        [-1.6225889 ],
        [-0.75322384],
        ...,
        [ 0.02752435],
        [ 1.7630118 ],
        [ 0.6711645 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.46049008],
        [-0.7228323 ],
        [ 0.49198708],
        ...,
        [-2.6658268 ],
        [ 0.5688557 ],
        [ 1.2088995 ]],

       [[-0.32607743],
        [-0.4941861 ],
        [-0.4495856 ],
        ...,
        [ 0.46143514],
        [ 0.04375907],
        [-1.2433708 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-2.1594412 ],
        [-1.7406673 ],
        [-0.34877333],
        ...,
        [-0.18708955],
        [-1.3062778 ],
        [ 1.0276945 ]],

       [[ 0.8192844 ],
        [ 1.2739064 ],
        [-1.1833884 ],
        ...,
        [ 0.5369094 ],
        [-1.4730651 ],
        [-0.5227384 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 0.9111539 ],
        [ 1.0799477 ],
        [ 0.5658374 ],
        ...,
        [-0.05691434],
        [ 0.50694185],
        [-0.5104034 ]],

       [[-0.5456287 ],
        [ 0.5273403 ],
        [ 0.7272648 ],
        ...,
        [-0.35712332],
        [ 0.8400177 ],
        [ 1.5469983 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.02717604],
        [-2.182759  ],
        [-0.95963657],
        ...,
        [-0.1727186 ],
        [ 1.0064832 ],
        [ 1.1638952 ]],

       [[ 0.9377752 ],
        [ 0.15913202],
        [ 0.39370653],
        ...,
        [-0.26473373],
        [-0.09181631],
        [-2.8304796 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 0.37767184],
        [-1.506959  ],
        [-0.28660896],
        ...,
        [-0.3206233 ],
        [ 1.5128583 ],
        [ 0.5174895 ]],

       [[ 0.23141655],
        [ 1.4028056 ],
        [-0.33944097],
        ...,
        [ 0.45577055],
        [ 1.2758701 ],
        [ 0.7810977 ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[-0.72600114],
        [ 0.75190115],
        [-0.8629814 ],
        ...,
        [-0.6400315 ],
        [ 0.45446384],
        [ 0.4231863 ]],

       [[ 0.66919667],
        [-1.4157479 ],
        [-1.7317768 ],
        ...,
        [-0.06310534],
        [ 0.3752666 ],
        [ 1.365589  ]]], dtype=float32)>, <tf.Tensor: shape=(2, 1024, 1), dtype=float32, numpy=
array([[[ 0.34559423],
        [-1.4900172 ],
        [ 0.913667  ],
        ...,
        [ 2.4927645 ],
        [-1.9354457 ],
        [-0.31414458]],

       [[-0.93749714],
        [-0.3028151 ],
        [ 0.6019532 ],
        ...,
        [-0.18828262],
        [ 0.52485734],
        [ 0.5387431 ]]], dtype=float32)>). When calling a concrete function, positional arguments may not be bound to Tensors within nested structures.
`"
40949,ssd_mobilenet_v2_mnasfpn_shared_box_predictor_320x320_coco_sync_2020_05_18.tar.gz error run in android,"
use tensflow_models/ssd_mobilenet_v2_mnasfpn_shared_box_predictor_320x320_coco_sync_2020_05_18/model.tflite in 
https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android  get this error:

E/AndroidRuntime: FATAL EXCEPTION: main
    Process: org.tensorflow.lite.examples.detection, PID: 19711
    java.lang.RuntimeException: java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:133)
        at org.tensorflow.lite.examples.detection.DetectorActivity.onPreviewSizeChosen(DetectorActivity.java:99)
        at org.tensorflow.lite.examples.detection.CameraActivity$7.onPreviewSizeChosen(CameraActivity.java:446)
        at org.tensorflow.lite.examples.detection.CameraConnectionFragment.setUpCameraOutputs(CameraConnectionFragment.java:357)
        at org.tensorflow.lite.examples.detection.CameraConnectionFragment.openCamera(CameraConnectionFragment.java:362)
        at org.tensorflow.lite.examples.detection.CameraConnectionFragment.access$300(CameraConnectionFragment.java:66)
        at org.tensorflow.lite.examples.detection.CameraConnectionFragment$3.onSurfaceTextureAvailable(CameraConnectionFragment.java:171)
        at android.view.TextureView.getTextureLayer(TextureView.java:390)
        at android.view.TextureView.draw(TextureView.java:339)
        at android.view.View.updateDisplayListIfDirty(View.java:20754)
        at android.view.View.draw(View.java:21607)
        at android.view.ViewGroup.drawChild(ViewGroup.java:4558)
        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4333)
        at android.view.View.updateDisplayListIfDirty(View.java:20740)
        at android.view.View.draw(View.java:21607)
        at android.view.ViewGroup.drawChild(ViewGroup.java:4558)
        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4333)
        at android.view.View.updateDisplayListIfDirty(View.java:20740)
        at android.view.View.draw(View.java:21607)
        at android.view.ViewGroup.drawChild(ViewGroup.java:4558)
        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4333)
        at android.view.View.draw(View.java:21884)
        at android.view.View.updateDisplayListIfDirty(View.java:20754)
        at android.view.View.draw(View.java:21607)
        at android.view.ViewGroup.drawChild(ViewGroup.java:4558)
        at androidx.coordinatorlayout.widget.CoordinatorLayout.drawChild(CoordinatorLayout.java:1246)
        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4333)
        at android.view.View.draw(View.java:21884)
        at android.view.View.updateDisplayListIfDirty(View.java:20754)
        at android.view.View.draw(View.java:21607)
        at android.view.ViewGroup.drawChild(ViewGroup.java:4558)
        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4333)
        at android.view.View.updateDisplayListIfDirty(View.java:20740)
        at android.view.View.draw(View.java:21607)
        at android.view.ViewGroup.drawChild(ViewGroup.java:4558)
        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4333)
        at android.view.View.updateDisplayListIfDirty(View.java:20740)
        at android.view.View.draw(View.java:21607)
        at android.view.ViewGroup.drawChild(ViewGroup.java:4558)
        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4333)
        at android.view.View.updateDisplayListIfDirty(View.java:20740)
        at android.view.View.draw(View.java:21607)
        at android.view.ViewGroup.drawChild(ViewGroup.java:4558)
        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4333)
        at android.view.View.updateDisplayListIfDirty(View.java:20740)
        at android.view.View.draw(View.java:21607)
        at android.view.ViewGroup.drawChild(ViewGroup.java:4558)
        at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4333)
        at android.view.View.draw(View.java:21884)
        at com.android.internal.policy.DecorView.draw(DecorView.java:1082)
        at android.view.View.updateDisplayListIfDirty(View.java:20754)
        at android.view.ThreadedRenderer.updateViewTreeDisplayList(ThreadedRenderer.java:725)
        at android.view.ThreadedRenderer.updateRootDisplayList(ThreadedRenderer.java:731)
        at android.view.ThreadedRenderer.draw(ThreadedRenderer.java:840)
        at android.view.ViewRootImpl.draw(ViewRootImpl.java:3935)
        at android.view.ViewRootImpl.performDraw(ViewRootImpl.java:3709)
        at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:3017)
E/AndroidRuntime:     at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1876)
        at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:8499)
        at android.view.Choreographer$CallbackRecord.run(Choreographer.java:949)
        at android.view.Choreographer.doCallbacks(Choreographer.java:761)
        at android.view.Choreographer.doFrame(Choreographer.java:696)
        at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:935)
        at android.os.Handler.handleCallback(Handler.java:873)
        at android.os.Handler.dispatchMessage(Handler.java:99)
        at android.os.Looper.loop(Looper.java:214)
        at android.app.ActivityThread.main(ActivityThread.java:7050)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:494)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:965)
     Caused by: java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model
        at org.tensorflow.lite.NativeInterpreterWrapper.createModelWithBuffer(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:72)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:52)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:114)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:131)
        	... 69 more
E/System: Uncaught exception thrown by finalizer
E/System: java.lang.NullPointerException: Attempt to invoke virtual method 'void org.tensorflow.lite.NativeInterpreterWrapper.close()' on a null object reference
        at org.tensorflow.lite.Interpreter.close(Interpreter.java:252)
        at org.tensorflow.lite.Interpreter.finalize(Interpreter.java:259)
        at java.lang.Daemons$FinalizerDaemon.doFinalize(Daemons.java:250)
        at java.lang.Daemons$FinalizerDaemon.runInternal(Daemons.java:237)
        at java.lang.Daemons$Daemon.run(Daemons.java:103)
        at java.lang.Thread.run(Thread.java:764)
"
40947,Tensorflow2.2 not installing on python 3.8,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip3 install tensorflow
- TensorFlow version:2.2.0
- Python version:3.8
- Installed using virtualenv? pip? conda?:using pip 20.1.1
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I am getting this error even i satisfied all the requirement

ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
ERROR: No matching distribution found for tensorflow

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40946,bazel build label_image,"i change some code in label_image/main.cc,   when i use 

bazel build //tensorflow/examples/label_image:label_image

command to compile label_image,  it builds all the source code. how can I only compile this one specific file label_image/main.cc?
thanks "
40945,Error:while importing Tensorflow in Jupyter notebook,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA
- TensorFlow installed from (source or binary):NA
- TensorFlow version:2.2
- Python version:3.7
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):NA
- GCC/Compiler version (if compiling from source):NA
- CUDA/cuDNN version:NA
- GPU model and memory:NA



**Describe the problem**
While i am trying to import Tensorflow in Jupyter notebook i am facing this issue.I have uninstalled anaconda and reinstalled ,still i am facing this issue.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
import tensorflow as tf

**Any other info / logs**---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59 

~/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~/anaconda3/lib/python3.7/imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

~/anaconda3/lib/python3.7/imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: libhipsparse.so.0: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-64156d691fe5> in <module>
----> 1 import tensorflow as tf

~/.local/lib/python3.7/site-packages/tensorflow/__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~/.local/lib/python3.7/site-packages/tensorflow/python/__init__.py in <module>
     48 import numpy as np
     49 
---> 50 from tensorflow.python import pywrap_tensorflow
     51 
     52 # Protocol buffers

~/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>
     67 for some common reasons and solutions.  Include the entire stack trace
     68 above this error message when asking for help."""""" % traceback.format_exc()
---> 69   raise ImportError(msg)
     70 
     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""/home/ravikrishnak/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/ravikrishnak/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/ravikrishnak/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/ravikrishnak/anaconda3/lib/python3.7/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/ravikrishnak/anaconda3/lib/python3.7/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libhipsparse.so.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.


Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40944,tensorflow:Layer will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria (using with GRU layer and dropout),"When trying to follow along F. Chollet's ""Deep Learning with Python"" listing 6.40 I encounter this warning:
`WARNING:tensorflow:Layer gru_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU`
after executing the following code:
```python
input_tensor = layers.Input((None, float_data.shape[-1]))
kmodel = layers.GRU(32, dropout=0.2, recurrent_dropout=0.2)(input_tensor)
output_tensor = layers.Dense(1)(kmodel)
model = models.Model(input_tensor, output_tensor)
```
My imports are:
```python
import os

import numpy as np
import matplotlib.pyplot as plt

from typing import Tuple

from tensorflow.keras import models, layers
from tensorflow.keras.optimizers import RMSprop
```

Note that if I don't use `dropout` and `recurrent_dropout` in the `GRU` layer everything works fine and fast. In the case I do use dropout like in the code above, it still works but with **very** slow performance.

System information:
Python 3.7.7
tensorflow-gpu 2.2.0
GPU: Cuda compilation tools, release 10.1, V10.1.243 on GeForce RTX 2080 Ti 11016MiB
OS: Ubuntu 18.04.4 LTS
"
40942,High memory consumption with model.fit in TF 2.x,"**System information**

- Have I written custom code: Yes
- OS Platform and Distribution: CentOS Linux 7
- Mobile device: Not verified on mobile devices
- TensorFlow installed from: binary, via `pip install tf-nightly`
- TensorFlow version: 2.5.0-dev20200626
- Python version: 3.6.8
- CUDA/cuDNN version: 10.1 / 7
- GPU model and memory: Tesla V100 32 GB

**Describe the current behavior**

Model training with the Keras API consumes high amount of system memory. It looks like the memory used by `model.fit` is proportional to the size of the training data provided as numpy arrays, with the proportionality constant being approximately 1. In other words, if the numpy arrays `x` and `y` are, say, 8 GB in total, then `model.fit(x,y,...)` will use another 8 GB (plus some overhead). So the memory usage by `model.fit` uses is twice the data size (plus some overhead).

The same concerns the validation data. If validation data are passed as numpy arrays to `model.fit` via the argument `validation_data`, then the memory use of `model.fit` seems to duplicate the size of the validation data arrays.

The described effect is also present if I wrap the numpy arrays containing the data in TF Datasets.

In the code attached below, one may change the variable `K` to vary the size of the data and test the above described behavior. It is straightforward to estimate the data size (e.g. with `K=5000` the data arrays in the below code should be ca. 7.32 GB in total). The whole Python process associated with this code uses approximately twice this much RAM plus some overhead independent of the data size. One may comment out the line containing `model.fit` to check that it is the point at which the high memory consumption starts.

**Describe the expected behavior**

It would be reasonable to expect that the memory usage by the test code was approximately the data size plus some overhead independent of the data size (not twice the data size plus overhead).

**A bit of history**

This is a continuation of the issue #35030, concerning TF 2.0 and 2.1. I opened the latter issue in December 2019 and now @karmel have stated that that issue is very long and asked me to test if the issue persists in TF-nightly and open a new issue if necessary. So yes, the problem persists, and here I open a new issue.

The problem appeared first in the release `2.0.0-rc0`. In the earlier releases up to `2.0.0-b1` inclusive the memery usage by the below test code was ca. the size of the data arrays plus an overhead independent of the data size. Starting from `2.0.0-rc0` it became twice the data size plus overhead and it was true at least until `2.1.0`.

Next, in `2.2.0`, the situation changed a bit:

- When using numpy arrays to pass data to `model.fit`, there was a memory leak about 0.5 x data size in each epoch. In other words, if the size of the data arrays was ca. 8 GB, then the memory usage was increasing ca. 4 GB each epoch.
- When wrapping the data arrays in TF datasets and then passing to `model.fit`, then the behavior was the same in TF 2.2 as in 2.1 and 2.0, namely the memory usage was twice the data size plus overhead.

Now, in the nightly release `2.5.0-dev20200626` we are back to the previous situation, namely the memory usage is twice the data size plus overhead, regardless of whether numpy arrays or datasets are used to pass the data to `model.fit`.

**An important note on reproducibility**

The issue has occurred to be not reproducible in colab! In #35030, I reported the issue for my local machine and some other participants also managed to reproduce it locally but not in colab. Some were trying to reproduce it in colab without success. Similarly, the results I report now are not from colab.

Also, for some reason the issue cannot be captured when using `libmemusage.so` to measure the memory usage. To capture the issue, I use `ps au` in Linux terminal or Python module `psutil`.

**Standalone code to reproduce the issue**

Since this issue is in fact a continuation of #35030, I use the same test code here.

```python
import tensorflow as tf
import numpy as np

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Lambda, Conv2D

print(""Tensorflow version: {}"".format(tf.__version__),flush=True)

K = 5000 # Number of images
N = 512  # Image size

MAX_SIGNAL = 5000 # The values of the training data range from 0 to this

def build_model():
  '''Create a simple test model.'''
  
  inputs = Input((N,N,1))
  s = Lambda(lambda x: x / MAX_SIGNAL) (inputs)
  s = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(s)
  outputs = s

  return Model(inputs=[inputs], outputs=[outputs])

# Generate some random data
x_train = np.random.randint(MAX_SIGNAL+1,size=(K,N,N,1),dtype=np.uint16) # Should be 2 560 000 kB
y_train = np.random.randint(1+1         ,size=(K,N,N,1),dtype=np.bool)   # Should be 1 280 000 kB
x_val   = np.random.randint(MAX_SIGNAL+1,size=(K,N,N,1),dtype=np.uint16) # Should be 2 560 000 kB
y_val   = np.random.randint(1+1         ,size=(K,N,N,1),dtype=np.bool)   # Should be 1 280 000 kB
# In total, the above arrays should be 7 680 000 kB

model = build_model()

optimizer = tf.keras.optimizers.Adam()
loss = tf.keras.losses.BinaryCrossentropy()

model.compile(optimizer=optimizer, loss=loss)
model.fit(x=x_train, y=y_train, validation_data=(x_val,y_val), batch_size=8, epochs=10)
```

The above is meant to reproduce the issue with data passed to `model.fit` as numpy arrays. To test the behavior with TF datasets, replace the last line with the following:

```python
ds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(8)
ds_val = tf.data.Dataset.from_tensor_slices((x_val,y_val)).batch(8)
model.fit(ds_train, validation_data=ds_val, epochs=10)
```"
40940,Question about how tensorflow mlir library works ?,"I was wondering as to how the tensorflow mlir library is used to reduce code from the tf dialect to an executable for a gpu, which dialects are involved in this conversion ?, are there multiple choices and are there any advantages to each of them ?. (and does ths have anything to do with the gpu dialect specified in the mlir documentation : https://mlir.llvm.org/docs/Dialects/GPU/)"
40939, Could not open edgetpu.tflite ,"I have generated my own object detection model. For that I have used pre quantized 'ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18' model.  I have used TensorFlow 1.15 version, I haven't converted the model using Bazel and TOCO. I have quantized the model before converting it to the edgetpu model because it is already a quantized, model. 

I have converted the frozen graph model using: 

    tflite_convert \
    --graph_def_file=tflite/tflite_graph.pb \ 
     --output_file=tflite/detect.tflite \ 
     --output_format=TFLITE \
     --input_shapes=1,300,300,3 \
     --input_arrays=normalized_input_image_tensor \
     --     output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \
     --inference_type=QUANTIZED_UINT8 \
     --mean_values=128 \
     --std_dev_values=127 \
     --change_concat_input_ranges=false \
     --allow_custom_ops

Then I have converted that model into edge tpu using: 

    ! edgetpu_compiler ""/content/drive/My Drive/detect (1).tflite""

The  compilation message: 

     Edge TPU Compiler version 2.1.302470888

     Model compiled successfully in 568 ms.

     Input model: /content/drive/My Drive/detect (1).tflite
     Input size: 5.34MiB
     Output model: detect (1)_edgetpu.tflite
     Output size: 5.75MiB
     On-chip memory used for caching model parameters: 5.66MiB
     On-chip memory remaining for caching model parameters: 1.96MiB
     Off-chip memory used for streaming uncached model parameters: 0.00B
     Number of Edge TPU subgraphs: 1
     Total number of operations: 64
     Operation log: detect (1)_edgetpu.log

     Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.
     Number of operations that will run on Edge TPU: 63
     Number of operations that will run on CPU: 1
     See the operation log file for individual operation details.

When I am running the example script I got from 'https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/TFLite_detection_video.py'

It gives me this kind of error. 

    python3 detection_picam.py --model /home/pi/ detection_model/detection_edgetpu.tflite --labels /home/pi /detection_model/labelmap.txt --edgetpu
    Traceback (most recent call last):
       File ""detection_picam.py"", line 135, in <module>
         experimental_delegates=[load_delegate('libedgetpu.so.1.0')])
      File ""/home/pi/.local/lib/python3.7/site-packages/tflite_runtime/interpreter.py"", line 204, in __init__
        model_path, self._custom_op_registerers))
    ValueError: Could not open '/home/pi/detection_model/detection_edgetpu.tflite/edgetpu.tflite'.

Is there any problem with the detection_edgetpu.tflite model? What can be the solution here? 
 "
40938,Calculating output_shapes and output_types of a dataset in python or C++?,"In current tensorflow implementation, almost all dataset ops have attributes:
```
    .Attr(""output_types: list(type) >= 1"")
    .Attr(""output_shapes: list(shape) >= 1"")
```
However, most of these attributes are not used since many ops won't change them, like `cache`, `repeat`, `prefetch` and these two attributes are calculated in C++ part again for `batch` and `padded_batch`. Are we going to remove those unnecessary attributes? And for the shapes that are calculated twice, shall we leave the C++ version or the python version?

If there are any modification needed, I'd love to contribute :).

Gently ping @jsimsa @aaudiber "
40937,module 'tensorflow.keras.layers' has no attribute 'Conv1DTranspose',"from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import Sequential

model = keras.Sequential(
    [
        layers.Input(shape=(288, 1)),
        layers.Conv1D(
            filters=32, kernel_size=7, padding=""same"", strides=2, activation=""relu""
        ),
        layers.Dropout(rate=0.2),
        layers.Conv1D(
            filters=16, kernel_size=7, padding=""same"", strides=2, activation=""relu""
        ),
        layers.Conv1DTranspose(
            filters=16, kernel_size=7, padding=""same"", strides=2, activation=""relu""
        ),
        layers.Dropout(rate=0.2),
        layers.Conv1DTranspose(
            filters=32, kernel_size=7, padding=""same"", strides=2, activation=""relu""
        ),
        layers.Conv1DTranspose(filters=1, kernel_size=7, padding=""same""),
    ]
)
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=""mse"")
model.summary()"
40936,"Saved_model exported from TrtGraphConverterV2 demands an extra ""global_step"" as input, while original saved_model does not","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): official docker image (tensorflow/tensorflow:2.2.0-gpu)
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: Python 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: (unchanged in official docker image)
- GPU model and memory: GTX 1050

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
A `saved_model` exported from `estimator.export_saved_model` works as expected in tensorflow/serving, while TensorRT optimized version of model demands an extra `global_step` as input. Besides, the rest of the inputs are renamed as `input_1`, ...
**Describe the expected behavior**
The inputs in optimized version of `saved_model` should be consistent with the signature definitions in the original saved_model. ""global_step"" is for tensorboard logging and should not be export as model input.
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
import os
from tensorflow.python.compiler.tensorrt import trt_convert as trt
from tensorflow.python.saved_model import tag_constants, signature_constants
from tensorflow.python.framework import convert_to_constants


def input_fn_builder(is_training):
    def input_fn(params):
        batch_size = 20
        num_examples = 100
        x = tf.expand_dims(tf.constant([float(i) for i in range(num_examples)], dtype=tf.float32), axis=1)
        y = 2 * x + 1
        d = tf.data.Dataset.from_tensor_slices({""x"": x, ""y"": y})

        if is_training:
            d = d.repeat()
            d = d.shuffle(buffer_size=5)

        d = d.batch(batch_size=batch_size)
        return d

    return input_fn


def model_fn_builder(optimizer):
    def model_fn(features, labels, mode, params):
        x = features[""x""]
        if ""y"" in features:
            y = features[""y""]
        else:
            y = labels
        model = tf.keras.Sequential([tf.keras.layers.Dense(1)])

        def loss_fn():  # For training stage only.
            out = model(x, training=True)
            loss = tf.keras.losses.mean_squared_error(y_true=y, y_pred=out)
            loss = tf.reduce_mean(loss)
            return loss

        training = (mode == tf.estimator.ModeKeys.TRAIN)
        model.trainable = training
        out = model(x, training=False)
        if mode == tf.estimator.ModeKeys.PREDICT:
            pred_dict = {""out"": out}
            return tf.estimator.EstimatorSpec(mode, pred_dict)
        loss = tf.keras.losses.mean_squared_error(y_true=y, y_pred=out)
        loss = tf.reduce_mean(loss)
        train_op = None
        if mode == tf.estimator.ModeKeys.TRAIN:
            optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()
            trainable_variables = model.trainable_variables
            train_op = optimizer.minimize(loss_fn, var_list=trainable_variables)
        return tf.estimator.EstimatorSpec(mode, predictions=out, loss=loss, train_op=train_op,
                                          eval_metric_ops={})

    return model_fn


output_dir = ""./trt_test""
checkpoint_dir = os.path.join(output_dir, ""checkpoint"")
saved_model_dir = os.path.join(output_dir, ""saved_model"")
trt_saved_model_dir = os.path.join(output_dir, ""trt_saved_model"")

# Train a simple regression model
optimizer = tf.optimizers.SGD(learning_rate=5e-7)
run_config = tf.estimator.RunConfig(model_dir=output_dir, save_checkpoints_steps=100, keep_checkpoint_max=5)

estimator = tf.estimator.Estimator(model_fn_builder(optimizer),
                                   config=run_config, params={})
train_spec = tf.estimator.TrainSpec(input_fn_builder(is_training=True), max_steps=1000)
eval_spec = tf.estimator.EvalSpec(input_fn_builder(is_training=False), throttle_secs=0)
tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
print(""Training complete"")
# Export as saved_model
features = {""x"": tf.keras.Input(shape=(1,), dtype=tf.float32)}
serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(features=features)
estimator.export_saved_model(saved_model_dir, serving_input_receiver_fn)
# Convert to TensorRT

input_saved_model_dir = os.path.join(saved_model_dir, os.listdir(saved_model_dir)[0])

converter = trt.TrtGraphConverterV2(input_saved_model_dir=input_saved_model_dir)
converter.convert()
converter.save(trt_saved_model_dir)

saved_model_loaded = tf.saved_model.load(
    trt_saved_model_dir, tags=[tag_constants.SERVING])
print(saved_model_loaded.signatures)

graph_func = saved_model_loaded.signatures[
    signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]
frozen_func = convert_to_constants.convert_variables_to_constants_v2(
    graph_func)


def wrap_func(*args, **kwargs):
    # Assumes frozen_func has one output tensor
    return frozen_func(*args, **kwargs)[0]


x = tf.constant([[1.]])
# output = wrap_func(x)  # Error, The function demands ""global_step"" besides parameter ""input_1""
output = wrap_func(tf.constant(0), x)  # Error, cannot feed a resource tensor with scalar

```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

I assume that `optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()` this contributes to the problem. Without it the estimator won't log `steps/sec` & `global_step` in tensorboard. I have to leave it untouched unless I've found alternative ways for doing this in the official document. "
40935,tflite micro mbed image recognition example accuracy difference for custom model,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): 2.1
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Arm mbed os Disco F746NG

When running tests for custom model,getting different results as compared to using python(floating point model)

1.Convert model to tflite :
converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)
tflite_model = converter.convert()
open('./converted_model_v1.tflite', 'wb').write(tflite_model)
![image](https://user-images.githubusercontent.com/63789049/86102915-becd0c00-bad9-11ea-9a38-dfe0e4c0c0d2.png)


2.created image header with test images 18 :
for i,j in enumerate(image_list[:]):
    print(j)
    im = Image.open(j)
    im = im.resize((32,32))
    im = (np.array(im))

    r = im[:,:,0].flatten()
    g = im[:,:,1].flatten()
    b = im[:,:,2].flatten()
    label = [i//6]
    if i==0:
        out = np.array(list(label)+list(b)+list(g)+list(r),np.uint8)
        
    else:
        out=np.append(out,np.array(list(label)+list(b)+list(g)+list(r),np.uint8))

out.tofile(""tflite_sliced_images.bin"")

xxd -i tflite_sliced_images.bin test_image.h

3.Accessing outputs using :
data.f[0],
data.f[1],
data.f[2]







"
40934,"Colab kernal crash when specify""report_tensor_allocations_upon_oom""","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
No
- TensorFlow installed from (source or binary):
Colab
- TensorFlow version (use command below):
1.15.2
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

When running this [colab](https://colab.research.google.com/drive/1I9eQDqYT4qBQT-jUXvOkvzoTKXB83Hy3?usp=sharing) notebook, the python kernel gets crashed.
If I remove the `options=tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True)` or set `report_tensor_allocations_upon_oom ` to False, the notebook works fine.

**Describe the expected behavior**
**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1I9eQDqYT4qBQT-jUXvOkvzoTKXB83Hy3?usp=sharing
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40933,d,d
40932,Please add a example for tf.compat.v1.estimator.experimental.KMeans in savemodel load example ,"python3.6
tensorflow2.0.0

error:KeyError: 'predict'

code:
import numpy as np
import tensorflow as tf

if __name__ == '__main__':
    num_points = 100
    dimensions = 1
    points = np.random.uniform(0, 1000, [num_points, dimensions])
    num_clusters = 5
    kmeans = tf.compat.v1.estimator.experimental.KMeans(
        num_clusters=num_clusters, use_mini_batch=False)

    def input_fn():
        return tf.data.Dataset.from_tensors(tf.convert_to_tensor(points, dtype=tf.float32)).repeat(1)
    # train
    num_iterations = 10
    previous_centers = None
    for _ in range(num_iterations):
        kmeans.train(input_fn)
        cluster_centers = kmeans.cluster_centers()
        if previous_centers is not None:
            print('delta:', cluster_centers - previous_centers)
        previous_centers = cluster_centers
        print('score:', kmeans.score(input_fn))
    print('cluster centers:', cluster_centers)

    input_column = tf.feature_column.numeric_column(""x"")
    serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(
        tf.feature_column.make_parse_example_spec([input_column]))
    estimator_path = kmeans.export_saved_model(""./data/"", serving_input_fn)

    imported = tf.saved_model.load(""./data/1593503127/"")
    print(imported.signatures[""predict""])


reference documents
https://www.tensorflow.org/guide/saved_model#savedmodels_from_estimators
https://www.tensorflow.org/api_docs/python/tf/compat/v1/estimator/experimental/KMeans#export_saved_model

"
40931,C++ compilation of rule '@llvm//:binary_format' failed (Exit 2) ,"I am running TensorFlow 1.15 CPU version, Bazel 0.24.1, Spyder Anaconda 3.7 64 bit, and Windows 10. I am trying to build TensorFlow from the source using Bazel.
When I am running this command 'bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package '
It is throwing me this error.

    INFO: From ProtoCompile tensorflow/core/profiler/tfprof_options.pb.h:
    bazel-out/x64_windows-opt/genfiles/external/com_google_protobuf/src: warning: directory does not exist.
    bazel-out/x64_windows-opt/genfiles/external/com_google_protobuf/src: warning: directory does not exist. 
    bazel-out/x64_windows-opt/genfiles/external/com_google_protobuf/src: warning: directory does not exist.
    bazel-out/x64_windows-opt/genfiles/external/com_google_protobuf/src: warning: directory does not exist.
    ERROR: C:/users/ravi/_bazel_ravi/mxogbt5u/external/llvm/BUILD.bazel:1327:1: C++ compilation of rule '@llvm//:binary_format' 
    failed (Exit 2): cl.exe failed: error executing command
      cd C:/users/ravi/_bazel_ravi/mxogbt5u/execroot/org_tensorflow
      SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE;C:\Program Files (x86)\Windows Kits\10\include\10.0.10240.0\ucrt;C:\Program Files (x86)\Windows Kits\8.1\include\shared;C:\Program Files (x86)\Windows Kits\8.1\include\um;C:\Program Files (x86)\Windows Kits\8.1\include\winrt;
        SET PATH=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\BIN\amd64;C:\WINDOWS\Microsoft.NET\Framework64\v4.0.30319;C:\WINDOWS\Microsoft.NET\Framework64\;C:\Program Files (x86)\Windows Kits\8.1\bin\x64;C:\Program Files (x86)\Windows Kits\8.1\bin\x86;;C:\WINDOWS\system32
        SET PWD=/proc/self/cwd
        SET PYTHON_BIN_PATH=C:/Users/Ravi/anaconda3/envs/tensorflow4/python.exe
        SET PYTHON_LIB_PATH=C:/Users/Ravi/anaconda3/envs/tensorflow4/lib/site-packages
        SET TEMP=C:\Users\Ravi\AppData\Local\Temp
        SET TF2_BEHAVIOR=0
        SET TF_CONFIGURE_IOS=0
        SET TMP=C:\Users\Ravi\AppData\Local\Temp
      C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /Iexternal/llvm /Ibazel-out/x64_windows-opt/genfiles/external/llvm /Ibazel-out/x64_windows-opt/bin/external/llvm /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/llvm/include /Ibazel-out/x64_windows-opt/genfiles/external/llvm/include /Ibazel-out/x64_windows-opt/bin/external/llvm/include /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_CRT_NONSTDC_NO_DEPRECATE /D_CRT_NONSTDC_NO_WARNINGS /D_SCL_SECURE_NO_DEPRECATE /D_SCL_SECURE_NO_WARNINGS /DUNICODE /D_UNICODE /DLLVM_ENABLE_STATS /D__STDC_LIMIT_MACROS /D__STDC_CONSTANT_MACROS /D__STDC_FORMAT_MACROS /DLLVM_BUILD_GLOBAL_ISEL /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=""redacted"" -D__TIMESTAMP__=""redacted"" -D__TIME__=""redacted"" /Gy /Gw -w -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX -Zc:inline -Zc:strictStrings -Zc:rvalueCast -Oi -wd4141 -wd4146 -wd4180 -wd4244 -wd4258 -wd4267 -wd4291 -wd4345 -wd4351 -wd4355 -wd4456 -wd4457 -wd4458 -wd4459 -wd4503 -wd4624 -wd4722 -wd4800 -wd4100 -wd4127 -wd4512 -wd4505 -wd4610 -wd4510 -wd4702 -wd4245 -wd4706 -wd4310 -wd4701 -wd4703 -wd4389 -wd4611 -wd4805 -wd4204 -wd4577 -wd4091 -wd4592 -wd4319 -wd4324 -w14062 -we4238 /Fobazel-out/x64_windows-opt/bin/external/llvm/_objs/binary_format/Dwarf.obj /c external/llvm/lib/BinaryFormat/Dwarf.cpp
    Execution platform: @bazel_tools//platforms:host_platform
     external/llvm/include\llvm/Support/Compiler.h(79): fatal error C1189: #error:  LLVM requires at least MSVC 2017.
    Target //tensorflow/tools/pip_package:build_pip_package failed to build
     INFO: Elapsed time: 1150.456s, Critical Path: 326.66s
    INFO: 1003 processes: 1003 local.
    FAILED: Build did NOT complete successfully


My python config (python ./configure.py) looks like this:

    (tensorflow4) C:\tensorflow-make\tensorflow>python ./configure.py
    WARNING: Running Bazel server needs to be killed, because the startup options are different.
    WARNING: An illegal reflective access operation has occurred
    WARNING: Illegal reflective access by com.google.protobuf.UnsafeUtil 
    (file:/C:/Users/Ravi/_bazel_Ravi/install/41e4b00c041f69b9ddd856a8576133ae/_embedded_binaries/A-server.jar) to field java.nio.Buffer.address
    WARNING: Please consider reporting this to the maintainers of com.google.protobuf.UnsafeUtil
    WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
    WARNING: All illegal access operations will be denied in a future release
    WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
    You have bazel 0.24.1- (@non-git) installed.
    Please specify the location of python. [Default is C:\Users\Ravi\anaconda3\envs\tensorflow4\python.exe]:


    Found possible Python library paths:
      C:\Users\Ravi\anaconda3\envs\tensorflow4\lib\site-packages
    Please input the desired Python library path to use.  Default is [C:\Users\Ravi\anaconda3\envs\tensorflow4\lib\site-packages]

    Do you wish to build TensorFlow with XLA JIT support? [y/N]: n
    No XLA JIT support will be enabled for TensorFlow.

    Do you wish to build TensorFlow with ROCm support? [y/N]: n
    No ROCm support will be enabled for TensorFlow.

    Do you wish to build TensorFlow with CUDA support? [y/N]: n
    No CUDA support will be enabled for TensorFlow.

    Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]:


    Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: n
    Not overriding eigen strong inline, some compilations could take more than 20 mins.

    Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
            --config=mkl            # Build with MKL support.
            --config=monolithic     # Config for mostly static monolithic build.
            --config=gdr            # Build with GDR support.
            --config=verbs          # Build with libverbs support.
            --config=ngraph         # Build with Intel nGraph support.
            --config=numa           # Build with NUMA support.
            --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
            --config=v2             # Build TensorFlow 2.x instead of 1.x.
    Preconfigured Bazel build configs to DISABLE default on features:
            --config=noaws          # Disable AWS S3 filesystem support.
            --config=nogcp          # Disable GCP support.
            --config=nohdfs         # Disable HDFS support.
            --config=noignite       # Disable Apache Ignite support.
            --config=nokafka        # Disable Apache Kafka support.
            --config=nonccl         # Disable NVIDIA NCCL support.

It would be great If someone can guide me to understand and solve this problem."
40930,tf.lite.TFLiteConverter.from_keras_model().convert() raise error with tf.keras.mixed_precision.experimental.Policy(),"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**: binary
-   **TensorFlow version (use command below)**: v2.2.0-rc4-8-g2b96f3662b 2.2.0
-   **Python version**: 3.8.2
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**: CUDA 10.1 / cuDNN 7.6.5
-   **GPU model and memory**:  NVIDIA GeForce GTX 970 / 4 Go
-   **Exact command to reproduce**:


### Describe the problem
Steps to reproduce the bug: execute the code provided with 'mixed_float16' mixed_precision policy.

In this situation we want to build a tflite model of an already quantitized model using  `tf.keras.mixed_precision.experimental.Policy(""mixed_float16"")`

But when executing the following, Tensorflow will crash and raise an ""error: non-broadcastable operands"" with some memory error.
```
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
```
If we pass mixed_precision_policy_arg to None and thus deactivate mixed_precision policy, everything goes fine.

Thanks you and have a good day!

### Source code / logs
Source code:
```
import tensorflow as tf
from tensorflow.keras.layers import Input, Lambda, Dense, Dropout
from tensorflow.keras.optimizers import Optimizer
from tensorflow.keras import backend as K
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model

# Activate mixed precision policy
mixed_precision_policy_arg: str = ""mixed_float16""
if mixed_precision_policy_arg is not None:
    mixed_precision_policy = tf.keras.mixed_precision.experimental.Policy(
        mixed_precision_policy_arg)
    tf.keras.mixed_precision.experimental.set_policy(
        mixed_precision_policy)

# Size parameters for the model
img_height, img_width, img_depth = 224, 224, 3

# Model definition
inp = Input(shape=(int(img_height), int(img_width),
                    int(img_depth)))
mobilenet_model = MobileNetV2(input_shape=(int(img_height),
                                            int(img_width),
                                            int(img_depth)),
                                alpha=0.35,
                                include_top=False,
                                weights='imagenet',
                                input_tensor=inp,
                                pooling='avg')
out = Dense(1, activation='tanh')(mobilenet_model.output)

# Build the whole model.
model = Model(inputs=inp, outputs=out)

#Convert to tflite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
# Save the TF Lite model.
with tf.io.gfile.GFile('./model.tflite', 'wb') as f:
    f.write(tflite_model)

```



Output logs:

```
2020-06-30 08:37:15.257384: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-06-30 08:37:15.262414: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-30 08:37:15.267142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:08:00.0 name: GeForce GTX 970 computeCapability: 5.2
coreClock: 1.253GHz coreCount: 13 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 208.91GiB/s
2020-06-30 08:37:15.276114: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-06-30 08:37:15.287313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-30 08:37:15.292024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-06-30 08:37:15.305367: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-06-30 08:37:15.310125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-06-30 08:37:15.325054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-06-30 08:37:15.338802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-30 08:37:15.343460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-30 08:37:15.356369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-30 08:37:15.361262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
2020-06-30 08:37:15.374944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-06-30 08:37:15.378461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2991 MB memory) -> physical GPU (device: 0, name: GeForce GTX 970, pci bus id: 0000:08:00.0, compute capability: 5.2)
2020-06-30 08:37:15.525109: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-30 08:37:15.530484: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-06-30 08:37:15.536242: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-30 08:37:17.175576: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-06-30 08:37:17.180393: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-30 08:37:17.184777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce GTX 970 computeCapability: 5.2
coreClock: 1.253GHz coreCount: 13 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 208.91GiB/s
2020-06-30 08:37:17.193569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-06-30 08:37:17.207166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-30 08:37:17.211906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-06-30 08:37:17.224565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-06-30 08:37:17.240773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-06-30 08:37:17.245702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-06-30 08:37:17.260413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-30 08:37:17.274603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-30 08:37:17.278648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-30 08:37:17.292135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
2020-06-30 08:37:17.295110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
2020-06-30 08:37:17.308571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2991 MB memory) -> physical GPU (device: 0, name: GeForce GTX 970, pci bus id: 0000:08:00.0, compute capability: 5.2)
2020-06-30 08:37:17.530109: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-30 08:37:17.535068: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 433 nodes (-350), 442 edges (-316), time = 31.294ms.
2020-06-30 08:37:17.540858: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 433 nodes (0), 442 edges (0), time = 7.549ms.
Traceback (most recent call last):
  File ""c:\Users\Mathieu\Code\tfissue\tflite_issue.py"", line 49, in <module>
    tflite_model = converter.convert()
  File ""C:\Program Files\Python\lib\site-packages\tensorflow\lite\python\lite.py"", line 514, in convert
    result = _toco_convert_impl(
  File ""C:\Program Files\Python\lib\site-packages\tensorflow\lite\python\convert.py"", line 491, in toco_convert_impl
    data = toco_convert_protos(
  File ""C:\Program Files\Python\lib\site-packages\tensorflow\lite\python\convert.py"", line 227, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-06-30 08:37:18.218076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-06-30 08:37:20.341895: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.
2020-06-30 08:37:20.342069: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.
2020-06-30 08:37:20.420203: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-06-30 08:37:20.428378: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1803e4c72d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:  
2020-06-30 08:37:20.428713: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-30 08:37:20.429873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-06-30 08:37:20.453669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:08:00.0 name: GeForce GTX 970 computeCapability: 5.2
coreClock: 1.253GHz coreCount: 13 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 208.91GiB/s
2020-06-30 08:37:20.454062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-06-30 08:37:20.457145: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-30 08:37:20.459818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-06-30 08:37:20.460738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-06-30 08:37:20.464328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-06-30 08:37:20.466349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-06-30 08:37:20.472167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-30 08:37:20.472361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-30 08:37:21.033060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-30 08:37:21.033405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
2020-06-30 08:37:21.033543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
2020-06-30 08:37:21.033777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2854 MB memory) -> physical GPU (device: 0, name: GeForce GTX 970, pci bus id: 0000:08:00.0, compute capability: 5.2)
2020-06-30 08:37:21.037082: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1805bff0530 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:  
2020-06-30 08:37:21.037386: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 970, Compute Capability 5.2
loc(callsite(""model/Conv_1_bn/FusedBatchNormV3""(""C:\Program Files\Python\lib\site-packages\tensorflow\python\eager\def_function.py"":865:0) at callsite(""C:\Program Files\Python\lib\site-packages\tensorflow\python\eager\def_function.py"":959:0 at callsite(""C:\Program Files\Python\lib\site-packages\tensorflow\lite\python\lite.py"":435:0 at ""c:\Users\Mathieu\Code\tfissue\tflite_issue.py"":48:0)))): error: non-broadcastable operands
Windows fatal exception: access violation

Current thread 0x00001e54 (most recent call first):
  File ""c:\program files\python\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 50 in execute
  File ""c:\program files\python\lib\site-packages\absl\app.py"", line 250 in _run_main
  File ""c:\program files\python\lib\site-packages\absl\app.py"", line 299 in run
  File ""c:\program files\python\lib\site-packages\tensorflow\python\platform\app.py"", line 40 in run
  File ""c:\program files\python\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 93 in main
  File ""C:\Program Files\Python\Scripts\toco_from_protos.exe\__main__.py"", line 7 in <module>
  File ""c:\program files\python\lib\runpy.py"", line 86 in _run_code
  File ""c:\program files\python\lib\runpy.py"", line 193 in _run_module_as_main
```
"
40929,TF2.1.0 Build,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):window10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version:2.1.0
- Python version:3.7
- Installed using virtualenv? pip? conda?:anaconda virtualenv
- Bazel version (if compiling from source):0.29.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1
- GPU model and memory:8G



**Describe the problem**ERROR: C:/tensorflow-2.1.0/tensorflow/core/kernels/BUILD:786:1: C++ compilation of rule '//tensorflow/core/kernels:eigen_contraction_kernel_with_mkl' failed (Exit 2)

**Provide the exact sequence of commands / steps that you executed before running into the problem**
python configure.py
bazel build --config=opt //tensorflow/tools/lib_package:libtensorflow

**Any other info / logs**
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocale
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstring
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdexcept
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\exception
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\type_traits
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstddef
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstddef
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\initializer_list
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\malloc.h
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_exception.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\eh.h
: :                C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_terminate.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstring
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory0
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdint
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ymath.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cfloat
: :                 C:\Windows Kits\10\include\10.0.18362.0\ucrt\float.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cwchar
: :                 C:\Windows Kits\10\include\10.0.18362.0\ucrt\wchar.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wconio.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wdirect.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wio.h
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_share.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wprocess.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/stat.h
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/types.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\new
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xutility
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\utility
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\iosfwd
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\crtdbg.h
: :                   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new_debug.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xatomic0.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\intrin.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\setjmp.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\immintrin.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\wmmintrin.h
: :                  C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\nmmintrin.h
: :                   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\smmintrin.h
: :                    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tmmintrin.h
: :                     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\pmmintrin.h
: :                      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\emmintrin.h
: :                       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmmintrin.h
: :                        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mmintrin.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ammintrin.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\typeinfo
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_typeinfo.h
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocinfo
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocinfo.h
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\locale.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xfacet
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\system_error
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cerrno
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\share.h
: :  external/grpc/include\grpcpp/support/time.h
: :   external/grpc/include\grpcpp/impl/codegen/time.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\chrono
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ratio
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xtimec.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthrcommon.h
: :    external/grpc/include\grpc/impl/codegen/grpc_types.h
: :     external/grpc/include\grpc/impl/codegen/compression_types.h
: :     external/grpc/include\grpc/impl/codegen/slice.h
: :      external/grpc/include\grpc/impl/codegen/gpr_slice.h
: :     external/grpc/include\grpc/impl/codegen/status.h
INFO: From Compiling external/icu/icu4c/source/common/cstr.cpp:
cl:  warning D9002 :-std=c++14
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/utypes.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/umachine.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ptypes.h
: :     C:\Windows Kits\10\include\10.0.18362.0\ucrt\stddef.h
: :      C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\sal.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ConcurrencySal.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vadefs.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/platform.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uconfig.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uvernum.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdint.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/urename.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uversion.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\float.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/putil.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unistr.h
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstddef
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\yvals.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xkeycheck.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\crtdefs.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\use_ansi.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/char16ptr.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/rep.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uobject.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/std_string.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\string
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\istream
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ostream
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ios
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocnum
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\climits
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cmath
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\math.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math_defines.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtgmath.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtr1common
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdlib
: :             C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdlib.h
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_malloc.h
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_search.h
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdlib.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdio
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdio.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdio.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_stdio_config.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\streambuf
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xiosbase
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocale
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstring
: :             C:\Windows Kits\10\include\10.0.18362.0\ucrt\string.h
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memory.h
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memcpy_s.h
: :                C:\Windows Kits\10\include\10.0.18362.0\ucrt\errno.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_string.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstring.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdexcept
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\exception
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\type_traits
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstddef
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\initializer_list
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\malloc.h
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_exception.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\eh.h
: :                C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_terminate.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstring
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory0
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdint
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ymath.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cfloat
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cwchar
: :                 C:\Windows Kits\10\include\10.0.18362.0\ucrt\wchar.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wconio.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wctype.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wdirect.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wio.h
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_share.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wprocess.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wtime.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/stat.h
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/types.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\new
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xutility
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\utility
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\iosfwd
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\crtdbg.h
: :                   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new_debug.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xatomic0.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\intrin.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\setjmp.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\immintrin.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\wmmintrin.h
: :                  C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\nmmintrin.h
: :                   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\smmintrin.h
: :                    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tmmintrin.h
: :                     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\pmmintrin.h
: :                      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\emmintrin.h
: :                       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmmintrin.h
: :                        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mmintrin.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ammintrin.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\typeinfo
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_typeinfo.h
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocinfo
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocinfo.h
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\ctype.h
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\locale.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xfacet
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\system_error
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cerrno
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\share.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/stringpiece.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/bytestream.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\cstr.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\charstr.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\cmemory.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/localpointer.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\memory
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\uinvchar.h
INFO: From Compiling external/grpc/src/cpp/server/server_builder.cc:
cl:  warning D9002 :-std=c++14
: :  external/grpc/include\grpcpp/server_builder.h
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\climits
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\yvals.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xkeycheck.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\crtdefs.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\sal.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ConcurrencySal.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vadefs.h
: :      C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\use_ansi.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\map
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tuple
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\new
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\exception
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\type_traits
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstddef
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstddef
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\stddef.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdlib
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdlib.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_malloc.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_search.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdlib.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\initializer_list
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtr1common
: :       C:\Windows Kits\10\include\10.0.18362.0\ucrt\malloc.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_exception.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\eh.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_terminate.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xutility
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\utility
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\iosfwd
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdio
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdio.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdio.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_stdio_config.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstring
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\string.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memory.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memcpy_s.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\errno.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_string.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstring.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cwchar
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\wchar.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wconio.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wctype.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wdirect.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wio.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_share.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wprocess.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wtime.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/stat.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/types.h
: :        C:\Windows Kits\10\include\10.0.18362.0\ucrt\crtdbg.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new_debug.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtree
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory0
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdint
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdint.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ymath.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cfloat
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\float.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cmath
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\math.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math_defines.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtgmath.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xatomic0.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\intrin.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\setjmp.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\immintrin.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\wmmintrin.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\nmmintrin.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\smmintrin.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tmmintrin.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\pmmintrin.h
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\emmintrin.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmmintrin.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mmintrin.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ammintrin.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdexcept
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstring
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\memory
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\typeinfo
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_typeinfo.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vector
: :   external/grpc/include\grpc/compression.h
: :    external/grpc/include\grpc/impl/codegen/port_platform.h
: :     C:\Windows Kits\10\include\10.0.18362.0\um\windows.h
: :      C:\Windows Kits\10\include\10.0.18362.0\shared\winapifamily.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\winpackagefamily.h
: :      C:\Windows Kits\10\include\10.0.18362.0\shared\sdkddkver.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\excpt.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdarg.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :      C:\Windows Kits\10\include\10.0.18362.0\shared\windef.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\minwindef.h
: :        C:\Windows Kits\10\include\10.0.18362.0\shared\specstrings.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\specstrings_strict.h
: :          C:\Windows Kits\10\include\10.0.18362.0\shared\specstrings_undef.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\driverspecs.h
: :          c:\windows kits\10\include\10.0.18362.0\shared\sdv_driverspecs.h
: :        C:\Windows Kits\10\include\10.0.18362.0\um\winnt.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\ctype.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\kernelspecs.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\basetsd.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\guiddef.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack4.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\pshpack4.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack4.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack2.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack2.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\pshpack2.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack8.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack1.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack1.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\apiset.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\ktmtypes.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winbase.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\apisetcconv.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\minwinbase.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\apiquery2.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\processenv.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\fileapifromapp.h
: :        C:\Windows Kits\10\include\10.0.18362.0\um\fileapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\debugapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\utilapiset.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\handleapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\errhandlingapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\fibersapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\namedpipeapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\profileapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\heapapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\ioapiset.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\synchapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\interlockedapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\processthreadsapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\sysinfoapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\memoryapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\enclaveapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\threadpoollegacyapiset.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\threadpoolapiset.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\jobapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\jobapi2.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\wow64apiset.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\libloaderapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\securitybaseapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\namespaceapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\systemtopologyapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\processtopologyapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\securityappcontainer.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\realtimeapiset.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\winerror.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\timezoneapi.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\wingdi.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winuser.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\pshpack2.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\poppack.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\tvout.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winnls.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\datetimeapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\stringapiset.h
: :        C:\Windows Kits\10\include\10.0.18362.0\um\winnls.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\wincon.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\wincontypes.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\consoleapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\consoleapi2.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\consoleapi3.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winver.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\verrsrc.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winreg.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\reason.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winnetwk.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\wnnc.h
: :      C:\Windows Kits\10\include\10.0.18362.0\shared\stralign.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winsvc.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\mcx.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\imm.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\ime_cmodes.h
: :    external/grpc/include\grpc/impl/codegen/compression_types.h
: :    external/grpc/include\grpc/slice.h
: :     external/grpc/include\grpc/support/port_platform.h
: :     external/grpc/include\grpc/impl/codegen/slice.h
: :      external/grpc/include\grpc/impl/codegen/gpr_slice.h
: :     external/grpc/include\grpc/support/sync.h
: :      external/grpc/include\grpc/impl/codegen/gpr_types.h
: :      external/grpc/include\grpc/impl/codegen/sync.h
: :       external/grpc/include\grpc/impl/codegen/sync_generic.h
: :        external/grpc/include\grpc/impl/codegen/atm.h
: :         external/grpc/include\grpc/impl/codegen/atm_windows.h
: :       external/grpc/include\grpc/impl/codegen/sync_windows.h
: :   external/grpc/include\grpc/support/cpu.h
: :   external/grpc/include\grpc/support/workaround_list.h
: :   external/grpc/include\grpcpp/impl/channel_argument_option.h
: :    external/grpc/include\grpcpp/impl/server_builder_option.h
: :     external/grpc/include\grpcpp/impl/server_builder_plugin.h
: :      external/grpc/include\grpcpp/support/config.h
: :       external/grpc/include\grpcpp/impl/codegen/config.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\string
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\istream
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ostream
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ios
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocnum
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\streambuf
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xiosbase
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocale
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocinfo
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocinfo.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\locale.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xfacet
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\system_error
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cerrno
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\share.h
: :     external/grpc/include\grpcpp/support/channel_arguments.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\list
: :      external/grpc/include\grpc/grpc.h
: :       external/grpc/include\grpc/status.h
: :        external/grpc/include\grpc/impl/codegen/status.h
: :       external/grpc/include\grpc/byte_buffer.h
: :        external/grpc/include\grpc/impl/codegen/byte_buffer.h
: :         external/grpc/include\grpc/impl/codegen/grpc_types.h
: :        external/grpc/include\grpc/slice_buffer.h
: :       external/grpc/include\grpc/impl/codegen/connectivity_state.h
: :       external/grpc/include\grpc/impl/codegen/propagation_bits.h
: :       external/grpc/include\grpc/support/time.h
: :        C:\Windows Kits\10\include\10.0.18362.0\ucrt\time.h
: :   external/grpc/include\grpcpp/impl/codegen/server_interceptor.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\atomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xatomic.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    external/grpc/include\grpcpp/impl/codegen/interceptor.h
: :     external/grpc/include\grpcpp/impl/codegen/byte_buffer.h
: :      external/grpc/include\grpcpp/impl/codegen/core_codegen_interface.h
: :       external/grpc/include\grpc/impl/codegen/byte_buffer_reader.h
: :       external/grpc/include\grpcpp/impl/codegen/status.h
: :        external/grpc/include\grpcpp/impl/codegen/status_code_enum.h
: :      external/grpc/include\grpcpp/impl/codegen/serialization_traits.h
: :      external/grpc/include\grpcpp/impl/codegen/slice.h
: :       external/grpc/include\grpcpp/impl/codegen/string_ref.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\algorithm
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\iostream
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\iterator
: :     external/grpc/include\grpcpp/impl/codegen/metadata_map.h
: :      external/grpc/include\grpc/impl/codegen/log.h
: :    external/grpc/include\grpcpp/impl/codegen/rpc_method.h
: :     external/grpc/include\grpcpp/impl/codegen/channel_interface.h
: :      external/grpc/include\grpcpp/impl/codegen/call.h
: :       external/grpc/include\grpcpp/impl/codegen/call_hook.h
: :      external/grpc/include\grpcpp/impl/codegen/time.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\chrono
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ratio
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xtimec.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthrcommon.h
: :  external/grpc/include\grpc/support/log.h
: :  external/grpc/include\grpcpp/impl/service_type.h
: :   external/grpc/include\grpcpp/impl/codegen/service_type.h
: :    external/grpc/include\grpcpp/impl/codegen/rpc_service_method.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\functional
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xfunctional
: :    external/grpc/include\grpcpp/impl/codegen/server_interface.h
: :     external/grpc/include\grpcpp/impl/codegen/completion_queue_tag.h
: :     external/grpc/include\grpcpp/impl/codegen/server_context.h
: :      external/grpc/include\grpcpp/impl/codegen/call_op_set.h
: :       C:\Windows Kits\10\include\10.0.18362.0\ucrt\assert.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\array
: :       external/grpc/include\grpcpp/impl/codegen/call_op_set_interface.h
: :       external/grpc/include\grpcpp/impl/codegen/client_context.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mutex
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thread
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthread
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xtime
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthreads.h
: :        external/grpc/include\grpcpp/impl/codegen/client_interceptor.h
: :        external/grpc/include\grpcpp/impl/codegen/create_auth_context.h
: :         external/grpc/include\grpcpp/impl/codegen/security/auth_context.h
: :       external/grpc/include\grpcpp/impl/codegen/completion_queue.h
: :        external/grpc/include\grpcpp/impl/codegen/grpc_library.h
: :       external/grpc/include\grpcpp/impl/codegen/intercepted_channel.h
: :       external/grpc/include\grpcpp/impl/codegen/interceptor_common.h
: :      external/grpc/include\grpcpp/impl/codegen/callback_common.h
: :  external/grpc/include\grpcpp/resource_quota.h
: :  external/grpc/include\grpcpp/server.h
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\condition_variable
: :   external/grpc/include\grpc/support/atm.h
: :   external/grpc/include\grpcpp/completion_queue.h
: :   external/grpc/include\grpcpp/impl/call.h
: :   external/grpc/include\grpcpp/impl/rpc_service_method.h
: :   external/grpc/include\grpcpp/security/server_credentials.h
: :    external/grpc/include\grpc/grpc_security_constants.h
: :    external/grpc/include\grpcpp/security/auth_metadata_processor.h
: :     external/grpc/include\grpcpp/security/auth_context.h
: :     external/grpc/include\grpcpp/support/status.h
: :     external/grpc/include\grpcpp/support/string_ref.h
: :  external/grpc\src/core/lib/gpr/useful.h
: :  external/grpc\src/cpp/server/thread_pool_interface.h
INFO: From Compiling external/icu/icu4c/source/common/cwchar.cpp:
cl:  warning D9002 :-std=c++14
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/utypes.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/umachine.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ptypes.h
: :     C:\Windows Kits\10\include\10.0.18362.0\ucrt\stddef.h
: :      C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\sal.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ConcurrencySal.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vadefs.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/platform.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uconfig.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uvernum.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdint.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/urename.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uversion.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\float.h
INFO: From Compiling external/icu/icu4c/source/common/caniter.cpp:
cl:  warning D9002 :-std=c++14
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/utypes.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/umachine.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ptypes.h
: :     C:\Windows Kits\10\include\10.0.18362.0\ucrt\stddef.h
: :      C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\sal.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ConcurrencySal.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vadefs.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/platform.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uconfig.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uvernum.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdint.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/urename.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uversion.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\float.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/caniter.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uobject.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unistr.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstddef
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\yvals.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xkeycheck.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\crtdefs.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\use_ansi.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/char16ptr.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/rep.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/std_string.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\string
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\istream
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ostream
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ios
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocnum
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\climits
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cmath
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\math.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math_defines.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtgmath.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtr1common
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdlib
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdlib.h
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_malloc.h
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_search.h
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdlib.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdio
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdio.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdio.h
: :             C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_stdio_config.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\streambuf
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xiosbase
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocale
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstring
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\string.h
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memory.h
: :                C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memcpy_s.h
: :                 C:\Windows Kits\10\include\10.0.18362.0\ucrt\errno.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_string.h
: :                  C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstring.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdexcept
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\exception
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\type_traits
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstddef
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\initializer_list
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\malloc.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_exception.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\eh.h
: :                 C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_terminate.h
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstring
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory0
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdint
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ymath.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cfloat
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cwchar
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\wchar.h
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wconio.h
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wctype.h
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wdirect.h
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wio.h
: :                    C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_share.h
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wprocess.h
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wtime.h
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/stat.h
: :                    C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/types.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\new
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new.h
: :                  C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xutility
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\utility
: :                  C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\iosfwd
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\crtdbg.h
: :                    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new_debug.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xatomic0.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\intrin.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\setjmp.h
: :                  C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\immintrin.h
: :                  C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\wmmintrin.h
: :                   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\nmmintrin.h
: :                    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\smmintrin.h
: :                     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tmmintrin.h
: :                      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\pmmintrin.h
: :                       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\emmintrin.h
: :                        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmmintrin.h
: :                         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mmintrin.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ammintrin.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\typeinfo
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_typeinfo.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocinfo
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocinfo.h
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\ctype.h
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\locale.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xfacet
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\system_error
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cerrno
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\share.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/stringpiece.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/bytestream.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/normalizer2.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uniset.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ucpmap.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unifilt.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unifunct.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unimatch.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uset.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uchar.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/stringoptions.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/localpointer.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\memory
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unorm2.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/usetiter.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ustring.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/putil.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uiter.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/utf16.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/utf.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\cmemory.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\hash.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\uhash.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\uelement.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\normalizer2impl.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ucptrie.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/utf8.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unorm.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\mutex.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\umutex.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\atomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xatomic.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\condition_variable
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthread
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthrcommon.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xtime
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xtimec.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\time.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthreads.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tuple
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mutex
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\chrono
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ratio
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\functional
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xfunctional
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thread
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uclean.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\putilimp.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\udataswp.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdarg.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\uset_imp.h
INFO: From Compiling external/icu/icu4c/source/common/ucnv_io.cpp:
cl:  warning D9002 :-std=c++14
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/utypes.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/umachine.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ptypes.h
: :     C:\Windows Kits\10\include\10.0.18362.0\ucrt\stddef.h
: :      C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\sal.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ConcurrencySal.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vadefs.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/platform.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uconfig.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uvernum.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdint.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/urename.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uversion.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\float.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ucnv.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ucnv_err.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uenum.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/localpointer.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\memory
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory0
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdint
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\yvals.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xkeycheck.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\crtdefs.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\use_ansi.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdlib
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdlib.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_malloc.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_search.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdlib.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ymath.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cfloat
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\climits
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cmath
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\math.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math_defines.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtgmath.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtr1common
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cwchar
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\wchar.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memcpy_s.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\errno.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_string.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wconio.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_stdio_config.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wctype.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wdirect.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wio.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_share.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wprocess.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdio.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstring.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wtime.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/stat.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/types.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstddef
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstddef
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\initializer_list
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\new
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\exception
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\type_traits
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\malloc.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_exception.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\eh.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_terminate.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xutility
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\utility
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\iosfwd
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdio
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdio.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstring
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\string.h
: :             C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memory.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\crtdbg.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new_debug.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xatomic0.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\intrin.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\setjmp.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\immintrin.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\wmmintrin.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\nmmintrin.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\smmintrin.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tmmintrin.h
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\pmmintrin.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\emmintrin.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmmintrin.h
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mmintrin.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ammintrin.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\typeinfo
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_typeinfo.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/udata.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\umutex.h
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\atomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xatomic.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\condition_variable
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthread
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthrcommon.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xtime
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xtimec.h
: :       C:\Windows Kits\10\include\10.0.18362.0\ucrt\time.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthreads.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tuple
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mutex
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\chrono
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ratio
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\functional
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xfunctional
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstring
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\system_error
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cerrno
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdexcept
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thread
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uclean.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uobject.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\putilimp.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/putil.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\uarrsort.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\uassert.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\udataswp.h
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdarg.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\cstring.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\cmemory.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\ctype.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\ucnv_io.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\uenumimp.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\ucln_cmn.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\ucln.h
INFO: From Compiling external/icu/icu4c/source/common/cstring.cpp:
cl:  warning D9002 :-std=c++14
: :  C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdlib.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\sal.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ConcurrencySal.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vadefs.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_malloc.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_search.h
: :    C:\Windows Kits\10\include\10.0.18362.0\ucrt\stddef.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdlib.h
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :  C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdio.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdio.h
: :    C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_stdio_config.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/utypes.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/umachine.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ptypes.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/platform.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uconfig.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uvernum.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdint.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/urename.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uversion.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\float.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\cmemory.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\string.h
: :    C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memory.h
: :     C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memcpy_s.h
: :      C:\Windows Kits\10\include\10.0.18362.0\ucrt\errno.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_string.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :    C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstring.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/localpointer.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\memory
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory0
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdint
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\yvals.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xkeycheck.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\crtdefs.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\use_ansi.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdlib
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ymath.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cfloat
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\climits
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cmath
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\math.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math_defines.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtgmath.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtr1common
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cwchar
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\wchar.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wconio.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wctype.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wdirect.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wio.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_share.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wprocess.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wtime.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/stat.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/types.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstddef
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstddef
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\initializer_list
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\new
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\exception
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\type_traits
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\malloc.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_exception.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\eh.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_terminate.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xutility
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\utility
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\iosfwd
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdio
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstring
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\crtdbg.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new_debug.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xatomic0.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\intrin.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\setjmp.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\immintrin.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\wmmintrin.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\nmmintrin.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\smmintrin.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tmmintrin.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\pmmintrin.h
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\emmintrin.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmmintrin.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mmintrin.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ammintrin.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\typeinfo
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_typeinfo.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uobject.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\cstring.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\ctype.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\uassert.h
INFO: From Compiling external/icu/icu4c/source/common/characterproperties.cpp:
cl:  warning D9002 :-std=c++14
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/utypes.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/umachine.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ptypes.h
: :     C:\Windows Kits\10\include\10.0.18362.0\ucrt\stddef.h
: :      C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\sal.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ConcurrencySal.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vadefs.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/platform.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uconfig.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uvernum.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdint.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/urename.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uversion.h
: :   C:\Windows Kits\10\include\10.0.18362.0\ucrt\float.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/localpointer.h
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\memory
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory0
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdint
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\yvals.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xkeycheck.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\crtdefs.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\use_ansi.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdlib
: :       C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdlib.h
: :        C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_malloc.h
: :        C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_search.h
: :        C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdlib.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ymath.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cfloat
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\climits
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cmath
: :        C:\Windows Kits\10\include\10.0.18362.0\ucrt\math.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math_defines.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtgmath.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtr1common
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cwchar
: :        C:\Windows Kits\10\include\10.0.18362.0\ucrt\wchar.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memcpy_s.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\errno.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_string.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wconio.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_stdio_config.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wctype.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wdirect.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wio.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_share.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wprocess.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdio.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstring.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wtime.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/stat.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/types.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstddef
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstddef
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\initializer_list
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\new
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\exception
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\type_traits
: :        C:\Windows Kits\10\include\10.0.18362.0\ucrt\malloc.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_exception.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\eh.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_terminate.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xutility
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\utility
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\iosfwd
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdio
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdio.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstring
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\string.h
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memory.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\crtdbg.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new_debug.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xatomic0.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\intrin.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\setjmp.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\immintrin.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\wmmintrin.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\nmmintrin.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\smmintrin.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tmmintrin.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\pmmintrin.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\emmintrin.h
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmmintrin.h
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mmintrin.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ammintrin.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\typeinfo
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_typeinfo.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uchar.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/stringoptions.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ucpmap.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/ucptrie.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/utf8.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/utf.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/umutablecptrie.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uniset.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unifilt.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unifunct.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uobject.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unimatch.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unistr.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/char16ptr.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/rep.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/std_string.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\string
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\istream
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ostream
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ios
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocnum
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\streambuf
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xiosbase
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocale
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdexcept
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstring
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocinfo
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocinfo.h
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\ctype.h
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\locale.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xfacet
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\system_error
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cerrno
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\share.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/stringpiece.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/bytestream.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uset.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uscript.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\cmemory.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\mutex.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\umutex.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\atomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xatomic.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xxatomic
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\condition_variable
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthread
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthrcommon.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xtime
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xtimec.h
: :        C:\Windows Kits\10\include\10.0.18362.0\ucrt\time.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthreads.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tuple
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mutex
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\chrono
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ratio
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\functional
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xfunctional
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thread
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uclean.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\putilimp.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/putil.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\normalizer2impl.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/normalizer2.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unorm2.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/unorm.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/uiter.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\unicode/utf16.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\udataswp.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdarg.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\uset_imp.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\uassert.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\ubidi_props.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\ucase.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\utrie2.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\ucln_cmn.h
: :   c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\ucln.h
: :  c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\icu\icu4c\source\common\uprops.h
ERROR: C:/tensorflow-2.1.0/tensorflow/core/kernels/BUILD:786:1: C++ compilation of rule '//tensorflow/core/kernels:eigen_contraction_kernel_with_mkl' failed (Exit 2)
cl:  warning D9002 :-std=c++14
: :  .\tensorflow/core/kernels/eigen_contraction_kernel.h
: :   .\third_party/eigen3/unsupported/Eigen/CXX11/Tensor
: :    external/eigen_archive\unsupported/Eigen/CXX11/Tensor
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\../../../Eigen/Core
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/DisableStupidWarnings.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/Macros.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cmath
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\yvals.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xkeycheck.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\crtdefs.h
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\sal.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ConcurrencySal.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vadefs.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt.h
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\use_ansi.h
: :        C:\Windows Kits\10\include\10.0.18362.0\ucrt\math.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math.h
: :         C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_math_defines.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtgmath.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xtr1common
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdlib
: :           C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdlib.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_malloc.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_search.h
: :             C:\Windows Kits\10\include\10.0.18362.0\ucrt\stddef.h
: :            C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdlib.h
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/ConfigureVectorization.h
: :       C:\Windows Kits\10\include\10.0.18362.0\ucrt\malloc.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mmintrin.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\emmintrin.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmmintrin.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\pmmintrin.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tmmintrin.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\smmintrin.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\nmmintrin.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\immintrin.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\wmmintrin.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\new
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\exception
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\type_traits
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstddef
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstddef
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\initializer_list
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_exception.h
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\eh.h
: :          C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_terminate.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new.h
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\complex
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ymath.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ccomplex
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\sstream
: :        C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\string
: :         C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\istream
: :          C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ostream
: :           C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ios
: :            C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocnum
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\climits
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdio
: :              C:\Windows Kits\10\include\10.0.18362.0\ucrt\stdio.h
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstdio.h
: :                C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_stdio_config.h
: :             C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\streambuf
: :              C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xiosbase
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocale
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstring
: :                 C:\Windows Kits\10\include\10.0.18362.0\ucrt\string.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memory.h
: :                   C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_memcpy_s.h
: :                    C:\Windows Kits\10\include\10.0.18362.0\ucrt\errno.h
: :                    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_string.h
: :                     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wstring.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdexcept
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xstring
: :                  C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory0
: :                   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cstdint
: :                    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdint.h
: :                     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :                   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\limits
: :                    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cfloat
: :                     C:\Windows Kits\10\include\10.0.18362.0\ucrt\float.h
: :                    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cwchar
: :                     C:\Windows Kits\10\include\10.0.18362.0\ucrt\wchar.h
: :                      C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wconio.h
: :                      C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wctype.h
: :                      C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wdirect.h
: :                      C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wio.h
: :                       C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_share.h
: :                      C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wprocess.h
: :                      C:\Windows Kits\10\include\10.0.18362.0\ucrt\corecrt_wtime.h
: :                      C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/stat.h
: :                       C:\Windows Kits\10\include\10.0.18362.0\ucrt\sys/types.h
: :                   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xutility
: :                    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\utility
: :                     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\iosfwd
: :                      C:\Windows Kits\10\include\10.0.18362.0\ucrt\crtdbg.h
: :                       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_new_debug.h
: :                   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xatomic0.h
: :                   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\intrin.h
: :                    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :                    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\setjmp.h
: :                     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :                    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ammintrin.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\typeinfo
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime_typeinfo.h
: :                  C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocinfo
: :                 C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xlocinfo.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\ctype.h
: :                  C:\Windows Kits\10\include\10.0.18362.0\ucrt\locale.h
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xfacet
: :               C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\system_error
: :                C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cerrno
: :               C:\Windows Kits\10\include\10.0.18362.0\ucrt\share.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xcomplex
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/MKL_support.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\cassert
: :       C:\Windows Kits\10\include\10.0.18362.0\ucrt\assert.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\functional
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xfunctional
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\tuple
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\algorithm
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\xmemory
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\array
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\iterator
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/Constants.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/Meta.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/ForwardDeclarations.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/StaticAssert.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/XprHelper.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/Memory.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/IntegralConstant.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/SymbolicIndex.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/NumTraits.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/MathFunctions.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/GenericPacketMath.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/MathFunctionsImpl.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/Default/ConjHelper.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/Default/Half.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/Default/TypeCasting.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/Default/GenericPacketMathFunctionsFwd.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/SSE/PacketMath.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/SSE/TypeCasting.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/SSE/Complex.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/AVX/PacketMath.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/AVX/TypeCasting.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/AVX/Complex.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/SSE/MathFunctions.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/AVX/MathFunctions.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/Default/Settings.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/arch/Default/GenericPacketMathFunctions.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/functors/TernaryFunctors.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/functors/BinaryFunctors.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/functors/UnaryFunctors.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/functors/NullaryFunctors.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/functors/StlFunctors.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/functors/AssignmentFunctors.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/IndexedViewHelper.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/ReshapedHelper.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/ArithmeticSequence.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/IO.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/DenseCoeffsBase.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/DenseBase.h
: :       c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\core\../plugins/CommonCwiseUnaryOps.h
: :       c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\core\../plugins/BlockMethods.h
: :       c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\core\../plugins/IndexedViewMethods.h
: :        c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\plugins\IndexedViewMethods.h
: :       c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\core\../plugins/ReshapedMethods.h
: :        c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\plugins\ReshapedMethods.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/MatrixBase.h
: :       c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\core\../plugins/CommonCwiseBinaryOps.h
: :       c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\core\../plugins/MatrixCwiseUnaryOps.h
: :       c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\core\../plugins/MatrixCwiseBinaryOps.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/EigenBase.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Product.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/CoreEvaluators.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/AssignEvaluator.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Assign.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/ArrayBase.h
: :       c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\core\../plugins/MatrixCwiseUnaryOps.h
: :       c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\core\../plugins/ArrayCwiseUnaryOps.h
: :       c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\core\../plugins/CommonCwiseBinaryOps.h
: :       c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\core\../plugins/MatrixCwiseBinaryOps.h
: :       c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src\core\../plugins/ArrayCwiseBinaryOps.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/BlasUtil.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/DenseStorage.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/NestByValue.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/ReturnByValue.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/NoAlias.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/PlainObjectBase.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Matrix.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Array.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/CwiseTernaryOp.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/CwiseBinaryOp.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/CwiseUnaryOp.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/CwiseNullaryOp.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/CwiseUnaryView.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/SelfCwiseBinaryOp.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Dot.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/StableNorm.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Stride.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/MapBase.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Map.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Ref.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Block.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/VectorBlock.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/IndexedView.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Reshaped.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Transpose.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/DiagonalMatrix.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Diagonal.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/DiagonalProduct.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Redux.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Visitor.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Fuzzy.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Swap.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/CommaInitializer.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/GeneralProduct.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Solve.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Inverse.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/SolverBase.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/PermutationMatrix.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Transpositions.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/TriangularMatrix.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/SelfAdjointView.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/GeneralBlockPanelKernel.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/Parallelizer.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/ProductEvaluators.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/GeneralMatrixVector.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/GeneralMatrixMatrix.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/SolveTriangular.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/GeneralMatrixMatrixTriangular.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/SelfadjointMatrixVector.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/SelfadjointMatrixMatrix.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/SelfadjointProduct.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/SelfadjointRank2Update.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/TriangularMatrixVector.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/TriangularMatrixMatrix.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/TriangularSolverMatrix.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/products/TriangularSolverVector.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/BandMatrix.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/CoreIterators.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/ConditionEstimator.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/BooleanRedux.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Select.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/VectorwiseOp.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/PartialReduxEvaluator.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Random.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Replicate.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/Reverse.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/ArrayWrapper.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/StlIterators.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/GlobalFunctions.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\eigen\src/Core/util/ReenableStupidWarnings.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\../SpecialFunctions
: :      C:\Windows Kits\10\include\10.0.18362.0\ucrt\math.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\../../Eigen/src/Core/util/DisableStupidWarnings.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\src/SpecialFunctions/BesselFunctionsImpl.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\src/SpecialFunctions/BesselFunctionsPacketMath.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\src/SpecialFunctions/BesselFunctionsHalf.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\src/SpecialFunctions/BesselFunctionsFunctors.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\src/SpecialFunctions/BesselFunctionsArrayAPI.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\src/SpecialFunctions/SpecialFunctionsImpl.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\src/SpecialFunctions/SpecialFunctionsPacketMath.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\src/SpecialFunctions/SpecialFunctionsHalf.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\src/SpecialFunctions/SpecialFunctionsFunctors.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\src/SpecialFunctions/SpecialFunctionsArrayAPI.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\../../Eigen/src/Core/util/ReenableStupidWarnings.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\../../../Eigen/src/Core/util/DisableStupidWarnings.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/util/CXX11Meta.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vector
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src\util\EmulateArray.h
: :      c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src\util\CXX11Workarounds.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/util/MaxSizeVector.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\random
: :     C:\Windows Kits\10\include\10.0.18362.0\um\windows.h
: :      C:\Windows Kits\10\include\10.0.18362.0\shared\winapifamily.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\winpackagefamily.h
: :      C:\Windows Kits\10\include\10.0.18362.0\shared\sdkddkver.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\excpt.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :      C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\stdarg.h
: :       C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\vcruntime.h
: :      C:\Windows Kits\10\include\10.0.18362.0\shared\windef.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\minwindef.h
: :        C:\Windows Kits\10\include\10.0.18362.0\shared\specstrings.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\specstrings_strict.h
: :          C:\Windows Kits\10\include\10.0.18362.0\shared\specstrings_undef.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\driverspecs.h
: :          c:\windows kits\10\include\10.0.18362.0\shared\sdv_driverspecs.h
: :        C:\Windows Kits\10\include\10.0.18362.0\um\winnt.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\kernelspecs.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\basetsd.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\guiddef.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack4.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\pshpack4.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack4.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack2.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack2.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\pshpack2.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack8.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack1.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\pshpack1.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         c:\windows kits\10\include\10.0.18362.0\shared\poppack.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\apiset.h
: :         C:\Windows Kits\10\include\10.0.18362.0\shared\ktmtypes.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winbase.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\apisetcconv.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\minwinbase.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\apiquery2.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\processenv.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\fileapifromapp.h
: :        C:\Windows Kits\10\include\10.0.18362.0\um\fileapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\debugapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\utilapiset.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\handleapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\errhandlingapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\fibersapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\namedpipeapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\profileapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\heapapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\ioapiset.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\synchapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\interlockedapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\processthreadsapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\sysinfoapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\memoryapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\enclaveapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\threadpoollegacyapiset.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\threadpoolapiset.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\jobapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\jobapi2.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\wow64apiset.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\libloaderapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\securitybaseapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\namespaceapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\systemtopologyapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\processtopologyapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\securityappcontainer.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\realtimeapiset.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\winerror.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\timezoneapi.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\wingdi.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winuser.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\pshpack2.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\poppack.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\tvout.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winnls.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\datetimeapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\stringapiset.h
: :        C:\Windows Kits\10\include\10.0.18362.0\um\winnls.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\wincon.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\wincontypes.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\consoleapi.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\consoleapi2.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\consoleapi3.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winver.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\verrsrc.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winreg.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\reason.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winnetwk.h
: :       C:\Windows Kits\10\include\10.0.18362.0\shared\wnnc.h
: :      C:\Windows Kits\10\include\10.0.18362.0\shared\stralign.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\winsvc.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\mcx.h
: :      C:\Windows Kits\10\include\10.0.18362.0\um\imm.h
: :       C:\Windows Kits\10\include\10.0.18362.0\um\ime_cmodes.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMacros.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorForwardDeclarations.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMeta.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorFunctors.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorCostModel.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorDeviceDefault.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorDeviceThreadPool.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorDeviceGpu.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorDeviceSycl.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorIndexList.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorDimensionList.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorDimensions.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorInitializer.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorTraits.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorRandom.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorUInt128.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorIntDiv.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorGlobalFunctions.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBase.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBlock.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBlockV2.h
c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBlockV2.h(736): error C2061: : Kind
c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBlockV2.h(842): note:   Eigen::internal::StridedLinearBufferCopy<Scalar,IndexType> 
c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBlockV2.h(745): error C2061: : Kind
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorEvaluator.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorExpr.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorReduction.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorReductionGpu.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorArgMax.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorConcatenation.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorContractionMapper.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorContractionBlocking.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorContraction.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorContractionThreadPool.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorContractionGpu.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorConversion.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorConvolution.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorFFT.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorPatch.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorImagePatch.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorVolumePatch.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBroadcasting.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorChipping.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorInflation.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorLayoutSwap.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMorphing.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorPadding.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorReverse.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorShuffling.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorStriding.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorCustomOp.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorEvalTo.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorForcedEval.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorGenerator.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorAssign.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorScan.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorTrace.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorExecutor.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorDevice.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorStorage.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/Tensor.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorFixedSize.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorMap.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorRef.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorIO.h
: :     c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\../../../Eigen/src/Core/util/ReenableStupidWarnings.h
: :   .\third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\third_party\eigen3\unsupported\eigen\cxx11\src/FixedPoint/FixedPointTypes.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\iostream
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\third_party\eigen3\unsupported\eigen\cxx11\src/FixedPoint/MatMatProduct.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\third_party\eigen3\unsupported\eigen\cxx11\src/FixedPoint/MatVecProduct.h
: :   external/mkl_dnn/include\mkldnn.h
: :    c:\users\pc\_bazel_pc\76nnpvfi\execroot\org_tensorflow\external\mkl_dnn\include\mkldnn_types.h
: :    bazel-out/x64_windows-opt/bin/external/mkl_dnn/include\mkldnn_version.h
: :   .\tensorflow/core/platform/dynamic_annotations.h
: :    .\tensorflow/core/platform/platform.h
: :    .\tensorflow/core/platform/default/dynamic_annotations.h
: :  C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\mutex
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\chrono
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\ratio
: :    C:\Windows Kits\10\include\10.0.18362.0\ucrt\time.h
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xtimec.h
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthrcommon.h
: :   C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thread
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\memory
: :    C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthread
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xtime
: :     C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE\thr/xthreads.h
Target //tensorflow/tools/lib_package:libtensorflow failed to build
INFO: Elapsed time: 77.662s, Critical Path: 11.34s
INFO: 418 processes: 418 local.
FAILED: Build did NOT complete successfully
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40928,"get error ""assert initial_state is None and constants is None""","operating system: Linux
TensorFlow version: Tensroflow2.0
        
         ```
import tensorflow as tf
from absl import logging

class ModelRnn(tf.keras.Model):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        layers = tf.keras.layers
        input_feature = layers.Input(
            shape=(None, 40, 1),
            dtype=tf.float32
        )
        inner = layers.Conv2D(
            filters=16,
            kernel_size=(41, 11),
            strides=(2, 2),
            padding=""same"",
            use_bias=False,
            data_format=""channels_last"",
        )(input_feature)
        inner = layers.BatchNormalization()(inner)
        inner = tf.nn.relu6(inner)
        inner = layers.Conv2D(
            filters=16,
            kernel_size=(21, 11),
            strides=(2, 1),
            padding=""same"",
            use_bias=False,
            data_format=""channels_last"",
        )(inner)
        inner = layers.BatchNormalization()(inner)
        inner = tf.nn.relu6(inner)
        _, _, dim, channels = inner.get_shape().as_list()
        output_dim = dim * channels
        inner = layers.Reshape((-1, output_dim))(inner)
        gru = tf.keras.layers.GRUCell(1024)
        initial = gru.get_initial_state(inputs=inner)
        inner, last_state = tf.keras.layers.RNN(
            cell=gru,
            return_sequences=True,
            return_state=True
        )(inputs=[inner], initial_state=[initial])
        inner = layers.BatchNormalization()(inner)
        inner = layers.Dense(1024, activation=tf.nn.relu6)(inner)
        inner = layers.Dense(10)(inner)
        self.net = tf.keras.Model(inputs=[input_feature], outputs=[inner]) 
         
    def call(self, samples, training=None):
        return self.out(samples, training=training)

if __name__ == ""__main__"":
    rnn = ModelRnn()
     
    inputs = tf.random.normal([32, 100, 40, 1])
    labels = tf.random.normal([32, 25, 10])
    
    loss_func = tf.keras.losses.CategoricalCrossentropy(from_logits=True)
    num = 0
    while num < 10:
        with tf.GradientTape() as tape:
            logits, state = rnn(inputs, training=True) 
            loss = loss_func(labels, logits)
            print(""loss: "", loss)
            grads = tape.gradient(loss, rnn.trainable_variables)
            optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
            optimizer.apply_gradients(zip(grads, rnn.trainable_variables))
        num += 1
    rnn.save_weights(""net.h5"")


```
 i use these code in my model ,when i run, i get error ""assert initial_state is None and constants is None"", hope some advice"
40927,how to convert  save RNN-based model(TF2.0) as TF1.x pb format,"Tensorflow 2.0
Linux
`
`import tensorflow as tf
from absl import logging

class ModelRnn(tf.keras.Model):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        layers = tf.keras.layers
        input_feature = layers.Input(
            shape=(None, 40, 1),
            dtype=tf.float32
        )
        inner = layers.Conv2D(
            filters=16,
            kernel_size=(41, 11),
            strides=(2, 2),
            padding=""same"",
            use_bias=False,
            data_format=""channels_last"",
        )(input_feature)
        inner = layers.BatchNormalization()(inner)
        inner = tf.nn.relu6(inner)
        inner = layers.Conv2D(
            filters=16,
            kernel_size=(21, 11),
            strides=(2, 1),
            padding=""same"",
            use_bias=False,
            data_format=""channels_last"",
        )(inner)
        inner = layers.BatchNormalization()(inner)
        inner = tf.nn.relu6(inner)
        _, _, dim, channels = inner.get_shape().as_list()
        output_dim = dim * channels
        inner = layers.Reshape((-1, output_dim))(inner)
        gru = tf.keras.layers.GRUCell(1024)
        inner, last_state = tf.keras.layers.RNN(
            cell=gru,
            return_sequences=True,
            return_state=True
        )(inputs=[inner])
        inner = layers.BatchNormalization()(inner)
        inner = layers.Dense(1024, activation=tf.nn.relu6)(inner)
        inner = layers.Dense(10)(inner)
        self.net = tf.keras.Model(inputs=[input_feature], outputs=[inner]) 
         
    def call(self, samples, training=None):
        return self.out(samples, training=training)

if __name__ == ""__main__"":
    rnn = ModelRnn()
     
    inputs = tf.random.normal([32, 100, 40, 1])
    labels = tf.random.normal([32, 25, 10])
    
    loss_func = tf.keras.losses.CategoricalCrossentropy(from_logits=True)
    num = 0
    while num < 10:
        with tf.GradientTape() as tape:
            logits, state = rnn(inputs, training=True) 
            loss = loss_func(labels, logits)
            print(""loss: "", loss)
            grads = tape.gradient(loss, rnn.trainable_variables)
            optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
            optimizer.apply_gradients(zip(grads, rnn.trainable_variables))
        num += 1
    rnn.save_weights(""net.h5"")
`
`"
40924,Build failure - missing dependency declarations LLVM,"With the current trunk at 8b87c1a09bf156ca9a42d9f72fad07da62100318 (Jun 29), even after a bazel clean, I see:

```
$  CC=clang CXX=clang++ bazel  --per_file_copt=llvm-project@-UNDEBUG   --linkopt=""-fuse-ld=lld""    //tensorflow/compiler/mlir/xla/tests:all
...
INFO: Found 1 target and 40 test targets...
ERROR: /ws/2cca323f33485b8e970325d856ce9b72/external/llvm-project/llvm/BUILD:665:1: undeclared inclusion(s) in rule '@llvm-project//llvm:count':
this rule is missing dependency declarations for the following files included by 'external/llvm-project/llvm/utils/count/count.c':
  '/usr/lib64/clang/10.0.0/include/stddef.h'
  '/usr/lib64/clang/10.0.0/include/stdarg.h'
INFO: Elapsed time: 0.140s, Critical Path: 0.02s
INFO: 0 processes.
```

```
$ clang --version
clang version 10.0.0 (Fedora 10.0.0-2.fc32)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /usr/bin
$ bazel --version
bazel 3.1.0
```

OS: Fedora 32, x86-64


"
40922,TensorFlow allocates memory for input tensor twice,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.24.1-3.0
- GCC/Compiler version (if compiling from source): 4.8.5
- CUDA/cuDNN version:
- GPU model and memory: 2x Nvidia GTX 1070, 8 GB

**Describe the current behavior**
When I run a simple TensorFlow model on multiple replicas (GPUs or workers), the memory for the input tensor is allocated twice. For example, if it should take up 1 GB of memory, TensorFlow instead allocates two chunks which each take up 1 GB of memory. This only happens when running with multiple GPUs or multiple workers. On GTXs 1070, for example, which have 8 GB of memory, it runs out of memory even if the input is only 6 GB in size.

**Describe the expected behavior**
TensorFlow should only allocate enough memory to hold the input once.

**Standalone code to reproduce the issue**
```
import tensorflow as tf
from tensorflow import keras


def get_dataset():
    # 6 GB: 1.5 billion elements, 4 bytes each
    # To reproduce, set this to ~2/3rds of your GPU memory and run with 2 GPUs
    x = tf.zeros([1000, 1000, 1500], dtype=tf.float32)
    x = tf.data.Dataset.from_tensors(x)

    y = tf.constant([5])
    y = tf.data.Dataset.from_tensor_slices(y)

    dataset = tf.data.Dataset.zip((x, y))
    dataset = dataset.batch(1)
    dataset = dataset.repeat()
    return dataset


def main():
    # Create dataset
    dataset = get_dataset()

    strategy = tf.distribute.MirroredStrategy()
    # Should be at least 2 replicas
    print(""REPLICAS IN SYNC: {}"".format(strategy.num_replicas_in_sync))
    with strategy.scope():
        # Construct model
        model = keras.Sequential(
            layers=[
                tf.keras.layers.ReLU(),
                tf.keras.layers.Conv2D(100, 1),
                tf.keras.layers.Dense(1),
            ]
        )
        model.compile(
            optimizer=keras.optimizers.Adam(),
            loss=keras.losses.MeanSquaredError(),
        )

    model.fit(x=dataset, steps_per_epoch=10, epochs=10)


if __name__ == ""__main__"":
    main()
```

**Other info / logs**
This error is reliably reproducible on different GPUs, Estimator as well as Keras models, etc.
The relevant portions of the log are:
```
2020-06-29 16:48:26.218671: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:434] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.59GiB (rounded to 6000000000)
Current allocation summary follows.
2020-06-29 16:48:26.218755: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:934] BFCAllocator dump for GPU_0_bfc
...
2020-06-29 16:48:26.219218: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (268435456): 	Total Chunks: 2, Chunks in use: 1. 7.03GiB allocated for chunks. 5.59GiB in use in bin. 5.59GiB client-requested in use in bin.
...
2020-06-29 16:48:26.219290: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:970] Next region of size 7553739520
2020-06-29 16:48:26.219310: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f7ef0000000 of size 256 next 1
2020-06-29 16:48:26.219327: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f7ef0000100 of size 1280 next 2
2020-06-29 16:48:26.219343: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f7ef0000600 of size 6000000000 next 3
2020-06-29 16:48:26.219358: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f8055a0c200 of size 256 next 4
2020-06-29 16:48:26.219373: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f8055a0c300 of size 256 next 5
...
2020-06-29 16:48:26.219865: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f8055a9f000 of size 600320 next 12
2020-06-29 16:48:26.219880: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f8055b31900 of size 600064 next 13
2020-06-29 16:48:26.219895: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7f8055bc4100 of size 600064 next 27
2020-06-29 16:48:26.219911: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 7f8055c56900 of size 1551335936 next 18446744073709551615
2020-06-29 16:48:26.219925: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:995]      Summary of in-use Chunks by size: 
2020-06-29 16:48:26.219944: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:998] 25 Chunks of size 256 totalling 6.2KiB
2020-06-29 16:48:26.219962: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:998] 6 Chunks of size 512 totalling 3.0KiB
2020-06-29 16:48:26.219978: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 1280 totalling 1.2KiB
2020-06-29 16:48:26.219995: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:998] 2 Chunks of size 600064 totalling 1.14MiB
2020-06-29 16:48:26.220013: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 600320 totalling 586.2KiB
2020-06-29 16:48:26.220030: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 6000000000 totalling 5.59GiB
2020-06-29 16:48:26.220047: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:1002] Sum Total of in-use chunks: 5.59GiB
2020-06-29 16:48:26.220062: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:1004] total_region_allocated_bytes_: 7553739520 memory_limit_: 7553739648 available bytes: 128 curr_region_allocation_bytes_: 15107479552
2020-06-29 16:48:26.220086: I external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:1010] Stats: 
Limit:                  7553739648
InUse:                  6001811200
MaxInUse:               6001812736
NumAllocs:                      87
MaxAllocSize:           6000000000

2020-06-29 16:48:26.220120: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:439] ********************************************************************************____________________
```

As you can see, the memory allocator has already allocated 6 GB, but wants to again allocate an additional 6 GB. In other contexts (tf.Estimator), I sometimes observe that TensorFlow is not even aware that it has allocated this excess memory. That is, it prints some debug information about which tensors were allocated and their memory sizes, but the giant input tensor is missing from this list, even though it has clearly been allocated according to the memory allocator."
40920,E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tensorflow-gpu==1.8.0
- TensorFlow version (use command below): v1.8.0.0-g93bc2e2072
- Python version: Python 2.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: CUDA 9.0 / cuDNN 7.5.1
- GPU model and memory: 

**Describe the current behavior**
When the training start, the error is shown as following:
> 2020-06-29 14:30:40.010427: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE

And when I am trying use 'nvidia-smi' command, the error is shown as following:
> NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.

I tried the solution descried in https://github.com/tensorflow/tensorflow/issues/16860, and I tried reinstall tensorflow-gpu, They all did not work... Does anyone know how to deal with it? Really appreciate it!
"
40919,Cannot add tensor to the batch: number of elements does not match (while Iterating through dataset elements).,"System info:
Os: MacOs catalina (10.15.5 )
Tensorflow: 2.0.0 installed over anaconda navigator (1.9.12 python 3.7) enviroment

**Code:** 

```python
# Load dataset from TFRecord file:
dataset = tf.data.TFRecordDataset(filenames=data_dir)
parsed_dataset = dataset.map(parsing_fn).batch(32)
print(parsed_dataset)
for image,label in parsed_dataset.take(2):
    print(image, label)
```
> Output:
```
<BatchDataset shapes: ((None, None) (None,)), types: (tf.float32, tf.int64)>

InvalidArgumentError: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [810000], [batch]: [243712] [Op:IteratorGetNextSync]
```
# Helper functions below
( TFRecord writed using tensorflow 1.14.0 over google colaboratory)
## Parsing function:

```python
def parsing_fn(serialized):

    features = \
        {
            'image': tf.FixedLenFeature([], tf.string),
            'label': tf.FixedLenFeature([], tf.int64)
        }

    # Parse the serialized data so we get a dict with our data.
    parsed_example = tf.parse_single_example(serialized=serialized,
                                             features=features)

    # Get the image as raw bytes.
    image_raw = parsed_example['image']

    # Decode the raw bytes so it becomes a tensor with type.
    image = tf.decode_raw(image_raw, tf.uint8)
    
    # The type is now uint8 but we need it to be float.
    image = tf.cast(image, tf.float32)

    label = parsed_example['label']

    return image, label
```
## Code used to create the TFRecord files
```python

    with tf.python_io.TFRecordWriter(out_path) as writer:

          data = \
              {
                  'image': wrap_bytes(img_bytes),
                  'label': wrap_int64(label)
              }

          # Wrap the data as TensorFlow Features.
          feature = tf.train.Features(feature=data)

          # Wrap again as a TensorFlow Example.
          example = tf.train.Example(features=feature)

          # Serialize the data.
          serialized = example.SerializeToString()
            
          # Write the serialized data to the TFRecords file.
          writer.write(serialized)
```
```python
def wrap_int64(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

def wrap_bytes(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))
```
"
40918,Error: undefined reference to 'TfLiteGpuDelegateV2Create' with libtensorflowlite_gpu_gl.so,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Android Studio Pixel XL emulator
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.1.1
- Python version: 3.7
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 3.2.0
- GCC/Compiler version (if compiling from source): gcc version 5.3.0
- CUDA/cuDNN version: No
- GPU model and memory: 

**Describe the problem**
Hello everyone, I want to start with the fact that I have successfully installed libtensorflowlite.so and everything works in Anroid Stuido native cpp code, but when i connected libtensorflowlite_gpu_gl.so the following error occurs:


**Provide the exact sequence of commands / steps that you executed before running into the problem**
Im trying to run app on device and get undefined reference to 'TfLiteGpuDelegateV2Create'

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

tart of the code that led to the error
```
#include <jni.h>
#include <android/log.h>

#include <fcntl.h>      // NOLINT(build/include_order)
#include <getopt.h>     // NOLINT(build/include_order)
#include <sys/time.h>   // NOLINT(build/include_order)
#include <sys/types.h>  // NOLINT(build/include_order)
#include <sys/uio.h>    // NOLINT(build/include_order)
#include <unistd.h>     // NOLINT(build/include_order)
#include <stdio.h>

#include <cstdarg>
#include <cstdio>
#include <cstdlib>
#include <fstream>
#include <iomanip>
#include <iostream>
#include <map>
#include <memory>
#include <sstream>
#include <string>
#include <unordered_set>
#include <vector>

#include <opencv2/core.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/objdetect.hpp>
#include <opencv2/imgcodecs.hpp>
#include <opencv2/face.hpp>
#include ""opencv2/opencv.hpp""
#include <opencv2/videoio.hpp>
#include ""opencv2/video/video.hpp""
#include <opencv2/highgui/highgui.hpp>

#include ""label_image.h""

#include <string>
#include <fstream>

#include ""tensorflow/lite/delegates/nnapi/nnapi_delegate.h""
#include ""tensorflow/lite/delegates/xnnpack/xnnpack_delegate.h""
#include ""tensorflow/lite/examples/label_image/bitmap_helpers.h""
#include ""tensorflow/lite/examples/label_image/get_top_n.h""
#include ""tensorflow/lite/kernels/register.h""
#include ""tensorflow/lite/optional_debug_tools.h""
#include ""tensorflow/lite/profiling/profiler.h""
#include ""tensorflow/lite/string_util.h""
#include ""tensorflow/lite/tools/evaluation/utils.h""

#include ""tensorflow/lite/delegates/gpu/delegate.h""

#include ""3rdparty/nlohmann/json.hpp""

using namespace cv;
using namespace std;
auto* delegate = TfLiteGpuDelegateV2Create(/*default options=*/nullptr);
```

and my CMakeLists.txt
```
# For more information about using CMake with Android Studio, read the
# documentation: https://d.android.com/studio/projects/add-native-code.html

# Sets the minimum version of CMake required to build the native library.

cmake_minimum_required(VERSION 3.4.1)

include_directories(${OpenCV_DIR}/jni/include)
include_directories(C:/_projects/android_tensorflow_opencv/tensorflow/distribution/include)

add_library( lib_opencv SHARED IMPORTED )
add_library( libtensorflowlite SHARED IMPORTED )

add_library( libgl_delegate SHARED IMPORTED )


set_target_properties(lib_opencv PROPERTIES IMPORTED_LOCATION ${OpenCV_DIR}/libs/${ANDROID_ABI}/libopencv_java4.so)
set_target_properties(libtensorflowlite PROPERTIES IMPORTED_LOCATION C:/_projects/android_tensorflow_opencv/tensorflow/distribution/jniLibs/${ANDROID_ABI}/libtensorflowlite.so)

set_target_properties(libgl_delegate PROPERTIES IMPORTED_LOCATION C:/_projects/android_tensorflow_opencv/tensorflow/distribution/gpuLibs/${ANDROID_ABI}/libtensorflowlite_gpu_gl.so)

# Creates and names a library, sets it as either STATIC
# or SHARED, and provides the relative paths to its source code.
# You can define multiple libraries, and CMake builds them for you.
# Gradle automatically packages shared libraries with your APK.

add_library( # Sets the name of the library.
        native-lib

        # Sets the library as a shared library.
        SHARED

        # Provides a relative path to your source file(s).
        native-lib.cpp)

# Searches for a specified prebuilt library and stores the path as a
# variable. Because CMake includes system libraries in the search path by
# default, you only need to specify the name of the public NDK library
# you want to add. CMake verifies that the library exists before
# completing its build.

find_library( # Sets the name of the path variable.
        log-lib

        # Specifies the name of the NDK library that
        # you want CMake to locate.
        log)

# Specifies libraries CMake should link to your target library. You
# can link multiple libraries, such as libraries you define in this
# build script, prebuilt third-party libraries, or system libraries.

target_link_libraries( # Specifies the target library.
        native-lib

        libgl_delegate

        lib_opencv

        libtensorflowlite

        # Links the target library to the log library
        # included in the NDK.
        ${log-lib})
```

Error log
```
[1/2] Building CXX object CMakeFiles/native-lib.dir/native-lib.cpp.o
[2/2] Linking CXX shared library C:\_projects\android_tensorflow_opencv\app\build\intermediates\cmake\debug\obj\armeabi-v7a\libnative-lib.so
FAILED: C:/_projects/android_tensorflow_opencv/app/build/intermediates/cmake/debug/obj/armeabi-v7a/libnative-lib.so 
cmd.exe /C ""cd . && C:\Users\samoh\AppData\Local\Android\Sdk\ndk\20.1.5948944\toolchains\llvm\prebuilt\windows-x86_64\bin\clang++.exe --target=armv7-none-linux-androideabi21 --gcc-toolchain=C:/Users/samoh/AppData/Local/Android/Sdk/ndk/20.1.5948944/toolchains/llvm/prebuilt/windows-x86_64 --sysroot=C:/Users/samoh/AppData/Local/Android/Sdk/ndk/20.1.5948944/toolchains/llvm/prebuilt/windows-x86_64/sysroot -fPIC -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -fno-addrsig -march=armv7-a -mthumb -Wa,--noexecstack -Wformat -Werror=format-security  -frtti -fexceptions -O0 -fno-limit-debug-info  -Wl,--exclude-libs,libgcc.a -Wl,--exclude-libs,libatomic.a -static-libstdc++ -Wl,--build-id -Wl,--warn-shared-textrel -Wl,--fatal-warnings -Wl,--exclude-libs,libunwind.a -Wl,--no-undefined -Qunused-arguments -Wl,-z,noexecstack -shared -Wl,-soname,libnative-lib.so -o C:\_projects\android_tensorflow_opencv\app\build\intermediates\cmake\debug\obj\armeabi-v7a\libnative-lib.so CMakeFiles/native-lib.dir/native-lib.cpp.o  C:/_projects/android_tensorflow_opencv/tensorflow/distribution/gpuLibs/armeabi-v7a/libtensorflowlite_gpu_gl.so C:/opencv/opencv4_1_0_contrib_/sdk/native/libs/armeabi-v7a/libopencv_java4.so C:/_projects/android_tensorflow_opencv/tensorflow/distribution/jniLibs/armeabi-v7a/libtensorflowlite.so -llog -latomic -lm && cd .""
C:/_projects/android_tensorflow_opencv/app/src/main/cpp/native-lib.cpp:56: error: undefined reference to 'TfLiteGpuDelegateV2Create'
clang++: error: linker command failed with exit code 1 (use -v to see invocation)
ninja: build stopped: subcommand failed.
```"
40917,Unexpected (incomplete ?) 4-bit quantization-aware training conversion,"**System information**
- OS Platform and Distribution : Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):  nightly docker image 
- TensorFlow version (or github SHA if from source): 2.3.0-dev20200618


**Command used to run the converter or code if youre using the Python API**

From this gist:

https://gist.github.com/corvoysier/906818ec1de2a84be31156d09042fce4

Type the following command:

```
python mnist_qat_nbit.py --save
```
This will produce three files:
- a `mnist_baseline.h5` non-quantized float model,
- a `mnist_qat.h5` quantized float model,
- a `mnist_integer.tflite` converted 4-bit integer model ([mnist_integer.tflite.zip](https://github.com/tensorflow/tensorflow/files/4846585/mnist_integer.tflite.zip))

You can dump the intermediate outputs of the inference of a single image using this command ([inference.txt](https://github.com/tensorflow/tensorflow/files/4846566/inference.txt)):

```
python mnist_tflite_debug.py -m mnist_integer.tflite
```

The 4-bit quantization configurations (and their associated quantizers) are defined in `n_bit_qat_helpers.py` and are just sub-classes of the base TFMOT QAT classes. 

**Failure details**

The model is converted without errors, but the weights and activations are not exactly quantized as expected.

Expected:

- filters should be int8 in the range [-7,7],
- biases should be int32,
- activations should be uint8 in the range [0, 15].

Obtained:

- filters are 4-bit quantized int8 in the range [-127, 127],
- biases are int32 (correct),
- activations are non-quantized int8.
  "
40916,`tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function,"Hi, I am a beginner. Could anyone explain me this error please?

- Error is:

    OperatorNotAllowedInGraphError Traceback (most recent call last) in 1 data = scaled_close 2 ----> 3 lstm = RNN_LSTM(input_dim = 28, seq_size = 28) 4 lstm.train(data) 5 lstm.test(data)
    
    in init(self, input_dim, seq_size, hidden_dim, learning_rate, batch_size, epochs, keep_prob) 42 # Loss function and optimizer 43 ---> 44 self.cost = tf.nn.l2_loss(self.output, self.Y) 45 self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost) 46
    
     in l2_loss(t, name) 4737 try: 4738 _, _, _op, _outputs = _op_def_library._apply_op_helper( -> 4739 ""L2Loss"", t=t, name=name) 4740 except (TypeError, ValueError): 4741 result = _dispatch.dispatch(
    
     in _apply_op_helper(op_type_name, name, **keywords) 351 inputs = [] 352 input_types = [] --> 353 with g.as_default(), ops.name_scope(name) as scope: 354 355 # Perform input type inference
    
     in enter(self) 6294 try: 6295 self._name_scope = g.name_scope(self._name) -> 6296 return self._name_scope.enter() 6297 except: 6298 if self._g_manager is not None:
    
     in enter(self) 110 del self.args, self.kwds, self.func 111 try: --> 112 return next(self.gen) 113 except StopIteration: 114 raise RuntimeError(""generator didn't yield"") from None
    
     in name_scope(self, name) 4016 above. 4017 """""" -> 4018 if name: 4019 if isinstance(name, compat.bytes_or_text_types): 4020 name = compat.as_str(name)
    
     in bool(self) 776  TypeError. 777 """""" --> 778 self._disallow_bool_casting() 779 780 def nonzero(self):
    
     in _disallow_bool_casting(self) 546 else: 547 # Default: V1-style Graph execution. --> 548 self._disallow_in_graph_mode(""using a tf.Tensor as a Python bool"") 549 550 def _disallow_iteration(self):
    
     in _disallow_in_graph_mode(self, task) 535 raise errors.OperatorNotAllowedInGraphError( 536 ""{} is not allowed in Graph execution. Use Eager execution or decorate"" --> 537 "" this function with @tf.function."".format(task)) 538 539 def _disallow_bool_casting(self):
    
    OperatorNotAllowedInGraphError: using a tf.Tensor as a Python bool is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.

- The code is:

class RNN_LSTM:
    
    def __init__(self, input_dim, seq_size, hidden_dim = 128, learning_rate = 0.01, batch_size = 128, epochs = 1, keep_prob = 1.0):
    
        # Hyperparameters
        
        self.input_dim = input_dim
        self.seq_size = seq_size
        self.hidden_dim = hidden_dim
        self.learning_rate = learning_rate
        self.batch_size = batch_size
        self.epochs = epochs
        self.keep_prob = keep_prob
    
        # Input and target placeholders ###
        
        X = tf.placeholder(""float"", [None, self.seq_size, self.input_dim])
        Y = tf.placeholder(""float"", [None, 1])
    
        # Weights & biases ###
        
        weights = tf.Variable(tf.random_normal([self.hidden_dim, 1]), name='weights')
        biases =  tf.Variable(tf.random_normal([1]), name='b')
                
        self.X = X
        self.Y = Y
        self.weights = weights
        self.biases = biases
        self.output = self.lstm()                
    
        # Loss function and optimizer
        
        self.cost = tf.nn.l2_loss(self.output, self.Y)
        self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)
    
        self.accuracy = 1. - (tf.reduce_mean(tf.abs((self.output - self.Y)/self.Y )))
         
        # Needed to save the session
        
        self.saver = tf.train.Saver()
    
    def lstm(self):
        '''
        Prepare the input shape for the lstm. Actual shape is (batch_size, seq_size, input_dim),
        the required shape is 'seq_size' tensors list of shape (batch_size, n_input)
        
        '''
        
        X = self.X
        # Permuting batch_size and seq_size
        X = tf.transpose(X, [1, 0, 2])
        
        # Reshaping to (seq_size*batch_size, input_dim)
        X = tf.reshape(X, [-1, self.input_dim])
        
        # Split to get a list of 'seq_size' tensors of shape (batch_size, input_dim)
        X = tf.split(X, self.seq_size, 0)
                
        # Create lstm and add the dropout
        
        lstm_cell = rnn_cell.LSTMCell(self.hidden_dim, use_peepholes=True)
        lstm_cell = rnn_cell.DropoutWrapper(lstm_cell, input_keep_prob=self.keep_prob, output_keep_prob=self.keep_prob)
        outputs, states = rnn.static_rnn(lstm_cell, X, dtype=tf.float32)
        
        output = tf.matmul(outputs[-1], self.weights) + self.biases
        
        return output
    
    
    def train(self, data, target):
    
        with tf.Session() as sess:
            sess.run(tf.initialize_all_variables())
    
            for epoch in range(self.epochs):
                epoch_loss = 0
                i = 0
    
                Y = tf.placeholder(""float"", [None, 1])
    
                while i < int(len(data)/self.batch_size):
    
                    start = i * self.batch_size
                    end = (i+1) * self.batch_size
    
                    batch_x = np.array(data[start:end])
                    batch_y = np.array(target[start:end])
                    #print(i, batch_y.shape)
                    batch_x = np.reshape(batch_x, (self.batch_size, self.seq_size, self.input_dim))
                    batch_y = np.reshape(batch_y, (self.batch_size, 1))
    
                    #print(batch_x, '\n \n \n', batch_y)
    
                    _, c = sess.run([self.optimizer, self.cost], feed_dict={self.X: batch_x, self.Y: batch_y})
                    epoch_loss += c
                    i += 1
    
                if (epoch+1) % 100 == 0:
                    print('Epoch', epoch + 1, 'completed out of', self.epochs, ', train loss:', epoch_loss)
    
            save_path = self.saver.save(sess, './LSTM.ckpt')
            print('Accuracy', self.accuracy.eval({self.X: data.reshape((-1, self.seq_size, self.input_dim)),
                                                  self.Y: target.reshape(-1, 1)}))
    
    def test(self, data, target):
    
        with tf.Session() as sess:
            self.saver.restore(sess, './LSTM.ckpt')
            prediction = sess.run(self.output, feed_dict={self.X: data.reshape((-1, self.seq_size, self.input_dim))})
            target.reshape((-1, 1))
    
            for i in range(10):
    
                print('prediction: ', prediction[i], 'target: ', target[i])
    
            print('Accuracy', self.accuracy.eval({self.X: data.reshape((-1, self.seq_size, self.input_dim)),
                                                  self.Y: target.reshape(-1, 1)}))
            plt.plot(prediction, linewidth=0.3, color='r', label='Predicted values')
            plt.plot(target, linewidth=0.3, color='g', label='Target values')
            plt.legend()
            plt.show()
    
Thank you!


"
40915,`Package                Version,"`Package                Version
---------------------- -------------------
absl-py                0.9.0
astor                  0.8.1
astunparse             1.6.3
cachetools             4.0.0
certifi                2019.11.28
chardet                3.0.4
gast                   0.2.2
google-auth            1.11.3
google-auth-oauthlib   0.4.1
google-pasta           0.2.0
grpcio                 1.27.2
h5py                   2.10.0
idna                   2.9
Keras-Applications     1.0.8
Keras-Preprocessing    1.1.0
keyboard               0.13.4
Markdown               3.2.1
mss                    5.0.0
numpy                  1.18.2
oauthlib               3.1.0
opt-einsum             3.2.0
pip                    20.0.2
protobuf               3.11.3
pyasn1                 0.4.8
pyasn1-modules         0.2.8
requests               2.23.0
requests-oauthlib      1.3.0
rsa                    4.0
scipy                  1.4.1
setuptools             41.2.0
six                    1.14.0
tb-nightly             2.2.0a20200320
tensorboard            2.1.1
tensorboard-plugin-wit 1.6.0.post2
tensorflow             2.1.0
tensorflow-estimator   2.1.0
termcolor              1.1.0
tf-estimator-nightly   2.3.0.dev2020032001
urllib3                1.25.8
Werkzeug               1.0.0
wheel                  0.34.2
wrapt                  1.12.1`

_Originally posted by @gragundier in https://github.com/tensorflow/tensorflow/issues/37756#issuecomment-601865269_"
40914,TFLite quant model run on the android phone have no speed up than float model,"i train a CNN + DNN model by Quantization-aware training way, get two tflite model (quant 945k and float 3.7M, same structure). but in the phone there is no speed up.
"
40912,save_model() fails with custom layer and SavedModel format,"- Have I written custom code: Yes
- OS Platform and Distribution: MacOS 10.15.5, running an official Docker image
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.9
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A
**Current behavior**
I have defined a custom Keras layer which acts as a learnable lookup table. The layer is functional and learns throughout training. I am able to save the Keras model using both `model.save('/path/to/dir')` and `model.save('/path/to/dir/model.h5')`.

However, `tf.keras.models.load_model('/path/to/dir')` fails whereas the H5 model seems to load properly with `tf.keras.models.load_model('/path/to/dir/model.h5', custom_objects = {""Lookup"": Lookup})`. Passing `custom_objects` to the SavedModel call (without `.h5`) makes no difference.

You can see in the logs that the SavedModel loader doesn't know the lookup table's shape.

**Describe the expected behavior**
Both save/load implementations should work.

**Standalone code to reproduce the issue**

```
import tensorflow as tf

class Lookup(tf.keras.layers.Layer):
    def __init__(self, depth: int = 3, **kwargs):
        super().__init__(**kwargs)

        self.depth = depth
        self.texture = None

    def build(self, input_shape):
        lookup_shape = input_shape[1:-1] + [self.depth]

        self.lookup_table = self.add_weight('lookup_table', lookup_shape, 'float32',
                                       initializer='random_normal',
                                       trainable=True)
        super().build(input_shape)

    def call(self, inputs, **kwargs):
        entries = tf.gather_nd(params=self.lookup_table,
                                      indices=inputs,
                                      name='lookup_call')

        return entries

    def get_config(self):
        config = super().get_config()
        config.update({""depth"": self.depth})
        return config
    
custom_objects = {""Lookup"": Lookup}

lookup = Lookup()

x = tf.keras.Input(shape=(2,2), dtype='int32')
y = lookup(x)
model = tf.keras.Model(x, y)
model.compile()

model.save('/tmp/lookup_test')
loaded_model = tf.keras.models.load_model('/tmp/lookup_test', custom_objects=custom_objects)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
In  [1]:
Line 40:    loaded_model = tf.keras.models.load_model('/tf/external/model/lookup_test', custom_objects=custom_objects)

File /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py, in load_model:
Line 190:   return saved_model_load.load(filepath, compile)

File /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py, in load:
Line 116:   model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)

File /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py, in load_internal:
Line 604:   export_dir)

File /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py, in __init__:
Line 188:   super(KerasObjectLoader, self).__init__(*args, **kwargs)

File /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py, in __init__:
Line 116:   meta_graph.graph_def.library))

File /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/function_deserialization.py, in load_function_def_library:
Line 311:   func_graph = function_def_lib.function_def_to_graph(copy)

File /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/function_def_to_graph.py, in function_def_to_graph:
Line 63:    importer.import_graph_def_for_function(graph_def, name="""")

File /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py, in import_graph_def_for_function:
Line 412:   graph_def, validate_colocation_constraints=False, name=name)

File /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py, in _import_graph_def_internal:
Line 501:   raise ValueError(str(e))

ValueError: indices.shape[-1] must be <= params.rank, but saw indices shape: [?,2,2] and params shape: [] for '{{node lookup/lookup_call}} = ResourceGatherNd[Tindices=DT_INT32, _output_shapes=[[?,2]], dtype=DT_FLOAT](lookup_lookup_call_resource:0, inputs:0)' with input shapes: [], [?,2,2].
---------------------------------------------------------------------------
```"
40911,Inconsistent prediction by model using Attention layer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina 10.15.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7.7
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Context**
While building a text classification model, we are using `tf.keras.layers.Attention`. Inputs are of the type 1d numpy array, each of the same shape padded by 0 at the end, and all starts with a start token, currently chosen as 1. The values are ID assigned to different words in the vocabulary.

**Describe the expected behavior**
Suppose for 4 sentences, inputs are a, b, c, d. Then we expect that `model.predict([a,b,c,d])` will be same as `np.concatenate([model.predict(np.expand_dims(a, axis=0), np.expand_dims(b, axis=0), np.expand_dims(c, axis=0), np.expand_dims(d, axis=0)], axis=0)`. 

**Describe the current behavior**
But we are not getting the expected result and there is a significant difference between the predicted probabilities. Sometimes even the position of the maximum probability will vary. So the result using `argmax` is not consistent.

**Observations**
1. If we remove Attention layer this inconsistency won't be there. 
2. Inconsistency is not affected by permutation. `[a, b, c, d]` will give same result as `[c, a, b, d]`.

**Standalone code to reproduce the issue**
```python
import numpy as np
from tensorflow import keras

tr_x = np.random.randint(0, 1024, size=(200, 50))
tr_y = np.random.randint(0, 4, 200)

il = keras.Input(shape=(50,))
el = keras.layers.Embedding(1024, 256)(il)
gl_out, gl_st = keras.layers.GRU(64, return_sequences=True, return_state=True)(el)
al = keras.layers.Attention()([gl_out, gl_st])
gl = keras.layers.GRU(16)(al)
ol = keras.layers.Dense(4, activation=""softmax"")(gl)

m = keras.Model(inputs=il, outputs=ol)
m.compile(""adam"", ""sparse_categorical_crossentropy"")

m.fit(tr_x, tr_y, epochs=16)

# Checking for inconsistency
ts_x = np.random.randint(0, 1024, size=(4, 50))
print(m.predict(ts_x))
print(m.predict(ts_x[:1]))
print(m.predict(ts_x[1:2]))
print(m.predict(ts_x[2:3]))
print(m.predict(ts_x[3:]))

# Checking for Permutation
x = np.random.randint(0, 1024, size=(8, 50))
p = np.random.permutation(8)
a = m.predict(x[p])
b = m.predict(x)[p]
np.testing.assert_allclose(a, b, 1e-3)
```

Is it an expected behavior or we are missing something in the code?

Thanks
"
40910,LLVM requires at least MSVC 2017,"Hi, 
I am following this tutorial (https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi) in order to convert my TensorFlow frozen model into tflite using TOCO. I am stuck at Step 2e. Build the TensorFlow package. 
When I am running this command 'bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package '. It is giving me this kind of error.  I have used tensorflow 1.15, Windows 10 OS, Bazel 0.24.1, Anaconda Spyder 64 bit. 

Trace Back: 

    ERROR: C:/users/ravi/_bazel_ravi/mxogbt5u/external/llvm/BUILD.bazel:2263:1: C++ compilation of rule '@llvm//:mc' failed (Exit 
    2): cl.exe failed: error executing command
      cd C:/users/ravi/_bazel_ravi/mxogbt5u/execroot/org_tensorflow
      SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE;C:\Program Files (x86)\Windows 
    Kits\10\include\10.0.10240.0\ucrt;C:\Program Files (x86)\Windows Kits\8.1\include\shared;C:\Program Files (x86)\Windows 
    Kits\8.1\include\um;C:\Program Files (x86)\Windows Kits\8.1\include\winrt;
        SET PATH=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\BIN\amd64;C:\WINDOWS\Microsoft.NET\Framework64\v4.0.30319;C:\WINDOWS\Microsoft.NET\Framework64\;C:\Program Files (x86)\Windows Kits\8.1\bin\x64;C:\Program Files (x86)\Windows Kits\8.1\bin\x86;;C:\WINDOWS\system32
        SET PWD=/proc/self/cwd
        SET PYTHON_BIN_PATH=C:/Users/Ravi/anaconda3/envs/tensorflow-make/python.exe
        SET PYTHON_LIB_PATH=C:/Users/Ravi/anaconda3/envs/tensorflow-make/lib/site-packages
        SET TEMP=C:\Users\Ravi\AppData\Local\Temp
        SET TF2_BEHAVIOR=0
        SET TF_CONFIGURE_IOS=0
        SET TMP=C:\Users\Ravi\AppData\Local\Temp
      C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /Iexternal/llvm /Ibazel-out/x64_windows-opt/genfiles/external/llvm /Ibazel-out/x64_windows-opt/bin/external/llvm /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/llvm/include /Ibazel-out/x64_windows-opt/genfiles/external/llvm/include /Ibazel-out/x64_windows-opt/bin/external/llvm/include /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_CRT_NONSTDC_NO_DEPRECATE /D_CRT_NONSTDC_NO_WARNINGS /D_SCL_SECURE_NO_DEPRECATE /D_SCL_SECURE_NO_WARNINGS /DUNICODE /D_UNICODE /DLLVM_ENABLE_STATS /D__STDC_LIMIT_MACROS /D__STDC_CONSTANT_MACROS /D__STDC_FORMAT_MACROS /DLLVM_BUILD_GLOBAL_ISEL /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=""redacted"" -D__TIMESTAMP__=""redacted"" -D__TIME__=""redacted"" /Gy /Gw -w -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX -Zc:inline -Zc:strictStrings -Zc:rvalueCast -Oi -wd4141 -wd4146 -wd4180 -wd4244 -wd4258 -wd4267 -wd4291 -wd4345 -wd4351 -wd4355 -wd4456 -wd4457 -wd4458 -wd4459 -wd4503 -wd4624 -wd4722 -wd4800 -wd4100 -wd4127 -wd4512 -wd4505 -wd4610 -wd4510 -wd4702 -wd4245 -wd4706 -wd4310 -wd4701 -wd4703 -wd4389 -wd4611 -wd4805 -wd4204 -wd4577 -wd4091 -wd4592 -wd4319 -wd4324 -w14062 -we4238 /Fobazel-out/x64_windows-opt/bin/external/llvm/_objs/mc/MCAsmInfoELF.obj /c 
    external/llvm/lib/MC/MCAsmInfoELF.cpp
    Execution platform: @bazel_tools//platforms:host_platform
    external/llvm/include\llvm/Support/Compiler.h(79): fatal error C1189: #error:  LLVM requires at least MSVC 2017.
     Target //tensorflow/tools/pip_package:build_pip_package failed to build
    INFO: Elapsed time: 327.786s, Critical Path: 57.27s
    INFO: 14 processes: 14 local.
    FAILED: Build did NOT complete successfully

What should I do to overcome this problem?  "
40909,Cannot save Model with Custom Layer : tensorflow.python.framework.errors_impl.InvalidArgumentError: 'func' argument to TF_GraphCopyFunction cannot be null,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu
- TensorFlow installed from: pip
- TensorFlow version: 
Git version : v2.2.0-rc4-8-g2b96f3662b 
Tensorflow version: 2.2.0
- Python version: 3.7



**Describe the current behavior**
For an NLP project, in order to directly preprocess data in a model , I have implemented a custom tokenization layer with a StaticHashTable (see below). Afterwards, I prepend this layer to a base model. Everything seems working fine, I even can make computations with the model.


**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.


```python
import pickle
import tensorflow as tf

tokenizer = pickle.load(tokenizer_path) ##pickled tf.keras tokenizer

class OwnPadder(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(OwnPadder, self).__init__(name = ""padder"", trainable = False, **kwargs)
        self.tokenizer_keys = tf.constant(list(tokenizer.word_index.keys()), dtype = tf.string)
        self.tokenizer_values = tf.constant(list(tokenizer.word_index.values()), dtype = tf.int32)
        self.initializer = tf.lookup.KeyValueTensorInitializer(keys = self.tokenizer_keys,
                 values= self.tokenizer_values, key_dtype = tf.string, value_dtype = tf.int32)
        self.table = tf.lookup.StaticHashTable(self.initializer, default_value=tf.constant(-1), name = ""static_hash"")

    def call(self, inputs, **kwargs):
        pipe = tf.strings.split(inputs)
        pipe = pipe.to_tensor(shape = pipe.bounding_shape(), name = ""uniform_tensor"")[:,0,:]
        tokenized = self.table.lookup(pipe, name = ""tokenize"")
        masked = tf.ragged.boolean_mask(tokenized, tokenized>0)
        res = masked.to_tensor(shape = [None, 100], name =""oad"")
        return res

    def get_config(self):
        config = super(OwnPadder, self).get_config()
        return config

[...]

base_model = tf.keras.models.load_model(base_model_path)
base_model.trainable = False
input_text = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name = ""input"")
 x = OwnPadder()(input_text)
 for layers in base_model.layers:
     x = layers(x)

holistic_model = tf.keras.models.Model(inputs = input_text, outputs = x)
holistic_model.compile()
final_model_path
holistic_model.save(final_model_path, save_format = ""tf"")

```
So, no bug here, everything seems fine until I try to serve with TensorflowServing, where the serving made a segmentation fault...
I tried to make a diagnostic with `saved_model_cli` shell command with the newly saved model, which gave me expected inputs/outputs signatures, but ended with a weird TF Error.

```python
WARNING:tensorflow:From $conda_envlib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2020-06-29 06:24:26.528835: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-06-29 06:24:26.528907: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2020-06-29 06:24:26.528947: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nlp-compute-2.sesamm.com): /proc/driver/nvidia/version does not exist
2020-06-29 06:24:26.529160: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-29 06:24:26.566924: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2397160000 Hz
2020-06-29 06:24:26.574709: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f85f0000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-29 06:24:26.574758: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Exception ignored in: <function CapturableResourceDeleter.__del__ at 0x7f86ba4de8c8>
Traceback (most recent call last):
  File ""$conda_env/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py"", line 191, in __del__
    self._destroy_resource()
  File ""$conda_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""$conda_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""$conda_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 506, in _initialize
    *args, **kwds))
  File ""$conda_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""$conda_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""$conda_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""$conda_env/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""$conda_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""$conda_env/lib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py"", line 241, in restored_function_body
    return _call_concrete_function(function, inputs)
  File ""$conda_envlib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py"", line 72, in _call_concrete_function
    result = function._call_flat(tensor_inputs, function._captured_inputs)  # pylint: disable=protected-access
  File ""$conda_env/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py"", line 101, in _call_flat
    cancellation_manager)
  File ""$conda_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1760, in _call_flat
    flat_outputs = forward_function.call(ctx, args_with_tangents)
  File ""$conda_envlib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 627, in call
    executor_type=executor_type)
  File ""$conda_envlib/python3.7/site-packages/tensorflow/python/ops/functional_ops.py"", line 1165, in partitioned_call
    f.add_to_graph(graph)
  File ""$conda_envlib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 543, in add_to_graph
    g._add_function(self)
  File ""$conda_env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 3187, in _add_function
    gradient)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 'func' argument to TF_GraphCopyFunction cannot be null
```
Please notice that the base model (without preprocessing layer) doesn't give this issue, and can be perfectly served via TensorflowServing. So I assume this is a matter of serialization of the new layer. Moreover, I tried to fit the new model from scratch (by fitting with raw data, compiling and saving preprocessed), and it also gave me an error. 

Do you have any hint how to fix this ? What am I doing wrong here ? Many thanks in advance ! "
40908,Using zeros_like in tensorflow with keras add_loss leads to error,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 4.4.0-109-generic
- TensorFlow installed from (source or binary): binary
- Python version: 3.6
- CUDA/cuDNN version:
- GPU model and memory:

git_version == v2.0.0-rc2-26-g64c3d38
version == 2.0.0


### ISSUE

If I run the following code, I get an the error ""InternalError: Invalid tape state."". However, if I switch tf.keras.backend.zeros_like(x) to ones_like(x) the issue disappears. It appears that the issue is arising from the zeros_like()
`imgin = tf.keras.Input((112,112,3))
x = tf.keras.layers.GlobalAvgPool2D()(imgin)
x = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)
x_ = tf.keras.layers.Dense(1, activation=""sigmoid"")(x)
model = tf.keras.Model(imgin, x_)
model.add_loss(tf.keras.losses.binary_crossentropy(tf.keras.backend.zeros_like(x), x))
model.compile(""Adam"", ""binary_crossentropy"")
model.train_on_batch(tf.ones((1,112,112,3)), [1])`"
40907,"KeyError: 'Failed to format this callback filepath: ""checkpoint_5000/checkpoint_{epoch:02d}_{batch:04d}"". Reason: \'batch\''","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Installed using Pip
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
```
 nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019
Cuda compilation tools, release 10.1, V10.1.105
```
- GPU model and memory: NVIDIA MX110 2GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""` v2.2.0-rc4-8-g2b96f3662b 2.2.0


**Describe the current behavior**
I am following a tutorial where we can save model weights in Tensorflow. We are saving weights every 5000 training points. Code of instructor and my code is same. But his version is 2.0, and my version is 2.2.0. There is error so I guess it is a bug in version.
**Describe the expected behavior**
It should save the model weights every 5k training points.
**Standalone code to reproduce the issue**

```
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D

from tensorflow.keras.callbacks import ModelCheckpoint



(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
x_train = x_train / 255.0
x_test = x_test / 255.0

def get_new_model():
    model = Sequential([
        Conv2D(filters=16, input_shape=(32, 32, 3), kernel_size=(3, 3), 
               activation='relu', name='conv_1'),
        tf.keras.layers.BatchNormalization(),
        Conv2D(filters=8, kernel_size=(3, 3), activation='relu', name='conv_2'),
        MaxPooling2D(pool_size=(4, 4), name='pool_1'),
        tf.keras.layers.BatchNormalization(),
        Conv2D(filters=8, kernel_size=(3, 3), activation='relu', name='conv_3'),
        MaxPooling2D(pool_size=(4, 4), name='pool_2'),
        Flatten(name='flatten'),
        Dense(units=32, activation='relu', name='dense_1'),
        tf.keras.layers.Dropout(0.5),
        Dense(units=10, activation='softmax', name='dense_2')
    ])
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model


checkpoint_5000_path = 'checkpoint_5000/checkpoint_{epoch:02d}_{batch:04d}'

model = get_new_model()
checkpoint_5000 = ModelCheckpoint(filepath=checkpoint_5000_path, verbose=True, save_weights_only=True,
                                  save_freq=5000)
model.fit(x_train, y_train, batch_size=10, validation_data=(x_test,y_test), epochs=3, verbose= True, callbacks=[checkpoint_5000])

```
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Full traceback is 

```

---------------------------------------------------------------------------

KeyError                                  Traceback (most recent call last)

C:\Anaconda\envs\myenv\lib\site-packages\tensorflow\python\keras\callbacks.py in _get_file_path(self, epoch, logs)
   1243         # placeholders can cause formatting to fail.
-> 1244         return self.filepath.format(epoch=epoch + 1, **logs)
   1245       except KeyError as e:

KeyError: 'batch'


During handling of the above exception, another exception occurred:

KeyError                                  Traceback (most recent call last)

<ipython-input-11-cc68dad1ac2c> in <module>
      7 checkpoint_5000 = ModelCheckpoint(filepath=checkpoint_5000_path, verbose=True, save_weights_only=True,
      8                                   save_freq=5000)
----> 9 model.fit(x_train, y_train, batch_size=10, validation_data=(x_test,y_test), epochs=3, verbose= True, callbacks=[checkpoint_5000])
     10 
     11 

C:\Anaconda\envs\myenv\lib\site-packages\tensorflow\python\keras\engine\training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

C:\Anaconda\envs\myenv\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
    853                 context.async_wait()
    854               logs = tmp_logs  # No error, now safe to assign to logs.
--> 855               callbacks.on_train_batch_end(step, logs)
    856         epoch_logs = copy.copy(logs)
    857 

C:\Anaconda\envs\myenv\lib\site-packages\tensorflow\python\keras\callbacks.py in on_train_batch_end(self, batch, logs)
    388     if self._should_call_train_batch_hooks:
    389       logs = self._process_logs(logs)
--> 390       self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)
    391 
    392   def on_test_batch_begin(self, batch, logs=None):

C:\Anaconda\envs\myenv\lib\site-packages\tensorflow\python\keras\callbacks.py in _call_batch_hook(self, mode, hook, batch, logs)
    296     for callback in self.callbacks:
    297       batch_hook = getattr(callback, hook_name)
--> 298       batch_hook(batch, logs)
    299     self._delta_ts[hook_name].append(time.time() - t_before_callbacks)
    300 

C:\Anaconda\envs\myenv\lib\site-packages\tensorflow\python\keras\callbacks.py in on_train_batch_end(self, batch, logs)
    613     """"""
    614     # For backwards compatibility.
--> 615     self.on_batch_end(batch, logs=logs)
    616 
    617   @doc_controls.for_subclass_implementers

C:\Anaconda\envs\myenv\lib\site-packages\tensorflow\python\keras\callbacks.py in on_batch_end(self, batch, logs)
   1160       self._batches_seen_since_last_saving += 1
   1161       if self._batches_seen_since_last_saving >= self.save_freq:
-> 1162         self._save_model(epoch=self._current_epoch, logs=logs)
   1163         self._batches_seen_since_last_saving = 0
   1164 

C:\Anaconda\envs\myenv\lib\site-packages\tensorflow\python\keras\callbacks.py in _save_model(self, epoch, logs)
   1194                   int) or self.epochs_since_last_save >= self.period:
   1195       self.epochs_since_last_save = 0
-> 1196       filepath = self._get_file_path(epoch, logs)
   1197 
   1198       try:

C:\Anaconda\envs\myenv\lib\site-packages\tensorflow\python\keras\callbacks.py in _get_file_path(self, epoch, logs)
   1245       except KeyError as e:
   1246         raise KeyError('Failed to format this callback filepath: ""{}"". '
-> 1247                        'Reason: {}'.format(self.filepath, e))
   1248     else:
   1249       # If this is multi-worker training, and this worker should not

KeyError: 'Failed to format this callback filepath: ""checkpoint_5000/checkpoint_{epoch:02d}_{batch:04d}"". Reason: \'batch\''
```"
40906,Segmentation fault in keras.backend.temporal_padding,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Segfault occurs when passing the tuple of large values for `padding`.

**Describe the expected behavior**
No segfault.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf

x = [[[3, 2, 3],
        [1, 3, 4]],

       [[3, 1, 2],
        [3, 2, 4]],

       [[4, 4, 2],
        [1, 1, 1]]]
padding = (1130323445, 1510667856)

tf.keras.backend.temporal_padding(x, padding)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
Segmentation fault (core dumped)
```"
40905,Process killed on tf.dynamic_partition,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Describe the current behavior**
tf.dynamic_partition with a large `num_partitions` hangs while consuming lots of memory  and the process is killed after a while. 

**Describe the expected behavior**
I would expect a memory allocation warning message rather than a hang followed by the killed process.  

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf

partitions = [0, 0, 1, 1, 0]
num_partitions = 100000000 
data = [10, 20, 30, 40, 50]

output = tf.dynamic_partition(data, partitions, num_partitions)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
Killed
```
"
40904,"ERROR: tf.function, tf.data.Dataset, tensorflow-gpu incompatible  ","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- TensorFlow version (use command below): 2.3.0 (affects all TF > 2.0.0 )
- Python version: 3.7


**Describe the current behavior**

I encountered an error when a `tf.data.Dataset` object is created or modified inside a `tf.function` graph *while* using tensorflow-gpu. Based on other issues, it seems this is caused by TF improperly placing the _VariantWrapper on a GPU. A _VariantWrapper is caused when a dataset object is created or modified inside a tf.function graph. 

Here is a small [Colab gist](https://colab.research.google.com/drive/1L_k_jomuAwKoM7RdiR-PLj7AfNZQVzh1?usp=sharing) highlighting code snippet of this issue and the related issues: [issue1](https://github.com/tensorflow/tensorflow/issues/34112), [issue2](https://github.com/tensorflow/tensorflow/issues/34519). This error has persisted since tf>2.0.0.

To put it plainly, **does this mean we should avoid wrapping any dataset operations in a tf.function**? 

eg.
```python
# Error
@tf.function
def f():
    dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3], [4, 5, 6]))
    for e in tf.range(3):
        for x, y in dataset:
            tf.print(x, y, e)
f()
```

```python
#Succeeds outside graph
dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3], [4, 5, 6]))

@tf.function
def f():
    for e in tf.range(3):
        for x, y in dataset: # `dataset` is transformed into `_VariantWrapper` rather than staying as a `tf.data.Dataset` object
            tf.print(x, y, e)
f()
```

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Colab: https://colab.research.google.com/drive/1L_k_jomuAwKoM7RdiR-PLj7AfNZQVzh1?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The complete error message is: 
```python 
No unary variant device copy function found for direction: 1 and Variant type_index: 
tensorflow::data::(anonymous namespace)::DatasetVariantWrapper
```
"
40900,Where is imgae_recognition_model.cc in image_recognition_experimental?,"Sorry to bother. I would like to run the image recognition model by Keil but I could not find ""image recognition model data"".

Could you tell me where the document is?

Or could you tell me where I can find the tutorial about how to train this model?"
40899,"tf nightly not supporting EXP, stack and depth to space layers on gpu","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android Studio
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) Redmi note 7
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): nightly
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

tf nightly not supporting EXP, stack and depth to space layers on gpu

**Describe the expected behavior**

these layers should be supported as per documentation.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.


    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
    implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40898,Failed to run the tflite model on Interpreter due to Internal Error,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0-dev20200617
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2
- GPU model and memory: 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I am trying to run a neural machine translator on android. The model runs perfectly on my jupyter notebook but when I used the generated tflite model to get predictions on android, it throws the error ```java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/concatenation.cc:73 t->dims->data[d] != t0->dims->data[d] (8 != 1) Node number 84 (CONCATENATION) failed to prepare.``` 

This is strange because I have provided the exact same input dimensions as I did in my jupyter notebook. 

As the error pointed, there was something wrong with dimensions at node 84. So I went ahead and visualised the tflite file using Netron. I have zoomed the concatenation node, you can find the pic of the node along with input and output dimensions [here](https://i.stack.imgur.com/3unpX.png). You can find the whole generated graph [here](https://drive.google.com/file/d/1DXxuke12NwwFREaSJyaoXrSNJ_nmjZ4O/view).

As it turns out, the concatenation node at location 84 isn't actually concatenating, you can see this from the input and output dimensions. It just spits out a 1X1X1 matrix after processing 1X1X1 and 1X1X256 matrix. But is this responsible for the crash? Is the node computing correctly?

Also, could anyone please explain me what does the error mean by t->dims->data[d] != t0->dims->data[d] what is d?
**Describe the expected behavior**

The tflite model should be able to make predictions

**Standalone code to reproduce the issue**
Please find the tflite file [here](https://drive.google.com/file/d/1zCHHbg20FPfRqqGEho8XtppMcmzxMKG8/view?usp=sharing). You can reproduce the error using the following snippet on android once you have the Interpreter ```tfLite``` initialised:

```
        HashMap<Integer, Object> outputVal = new HashMap<>();
        for(int i=0; i<2; i++) outputVal.put(i, new float[1][5]);
        float[][] inp_test = new float[1][8];
        float[][] enc_hidden = new float[1][1024];
        float[][] dec_input = new float[1][1];
        float[][] dec_test = new float[1][8];

        tfLite.runForMultipleInputsOutputs(new Object[] {inp_test,enc_hidden, dec_input, dec_test},outputVal);
```
My gradle dependencies:
```
dependencies {
    implementation fileTree(dir: 'libs', include: ['*.jar'])

    implementation 'androidx.appcompat:appcompat:1.1.0'
    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'
    // This dependency adds the necessary TF op support.
    implementation 'androidx.constraintlayout:constraintlayout:1.1.3'
    testImplementation 'junit:junit:4.12'
    androidTestImplementation 'androidx.test.ext:junit:1.1.1'
    androidTestImplementation 'androidx.test.espresso:espresso-core:3.2.0'
}
```
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Here is the code for the model:
It is highly inspired by this guide: https://www.tensorflow.org/tutorials/text/nmt_with_attention 

```

Tx = 8
def Partial_model():
    outputs = []
    X = tf.keras.layers.Input(shape=(Tx,))
    partial = tf.keras.layers.Input(shape=(Tx,))
    enc_hidden = tf.keras.layers.Input(shape=(units,))
    dec_input = tf.keras.layers.Input(shape=(1,))
    
    d_i = dec_input
    e_h = enc_hidden
    X_i = X
    
    enc_output, e_h = encoder(X, enc_hidden)
    
    
    dec_hidden = enc_hidden
    print(dec_input.shape, 'inp', dec_hidden.shape, 'dec_hidd')
    for t in range(1, Tx):
        print(t, 'tt')
      # passing enc_output to the decoder
        predictions, dec_hidden, _ = decoder(d_i, dec_hidden, enc_output)
#         outputs.append(predictions)
        print(predictions.shape, 'pred')
        d_i = tf.reshape(partial[:, t], (-1, 1))
        print(dec_input.shape, 'dec_input')
    
    predictions, dec_hidden, _ = decoder(d_i, dec_hidden, enc_output)
    d_i = tf.squeeze(d_i)
    
    outputs.append(tf.math.top_k(predictions, 5))
    
    return tf.keras.Model(inputs = [X, enc_hidden, dec_input, partial], outputs = [outputs[0][0], outputs[0][1]])




class Encoder():
  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):
    self.batch_sz = batch_sz
    self.enc_units = enc_units
    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
    self.gru = tf.keras.layers.GRU(self.enc_units,
                                   return_sequences=True,
                                   return_state=True,
                                   recurrent_initializer='glorot_uniform')

  def __call__(self, x, hidden):
    x = self.embedding(x)
    output, state = self.gru(x, initial_state = hidden)
    print(output.shape, hidden.shape, ""out"", ""hid"")
    return output, state


  def initialize_hidden_state(self):
    return tf.zeros((self.batch_sz, self.enc_units))



class BahdanauAttention():
  def __init__(self, units):
    self.W1 = tf.keras.layers.Dense(units)
    self.W2 = tf.keras.layers.Dense(units)
    self.V = tf.keras.layers.Dense(1)

  def __call__(self, query, values):
    # query hidden state shape == (batch_size, hidden size)
    # query_with_time_axis shape == (batch_size, 1, hidden size)
    # values shape == (batch_size, max_len, hidden size)
    # we are doing this to broadcast addition along the time axis to calculate the score
    print(query.shape, 'shape')
    query_with_time_axis = tf.expand_dims(query, 1)
    # score shape == (batch_size, max_length, 1)
    # we get 1 at the last axis because we are applying score to self.V
    # the shape of the tensor before applying self.V is (batch_size, max_length, units)
    print(""2"")
    score = self.V(tf.nn.tanh(
        self.W1(query_with_time_axis) + self.W2(values)))
    print(""3"")

    # attention_weights shape == (batch_size, max_length, 1)
    attention_weights = tf.nn.softmax(score, axis=1)

    # context_vector shape after sum == (batch_size, hidden_size)
    context_vector = attention_weights * values
    context_vector = tf.reduce_sum(context_vector, axis=1)
    
    return context_vector, attention_weights


class Decoder():
  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):
    self.dec_units = dec_units
    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
    self.gru = tf.keras.layers.GRU(self.dec_units,
                                   return_sequences=True,
                                   return_state=True,
                                   recurrent_initializer='glorot_uniform')
    self.fc = tf.keras.layers.Dense(vocab_size)

    # used for attention
    self.attention = BahdanauAttention(self.dec_units)

  def __call__(self, x, hidden, enc_output):
    # enc_output shape == (batch_size, max_length, hidden_size)
    context_vector, attention_weights = self.attention(hidden, enc_output)
    
    print(context_vector.shape, 'c_v', attention_weights.shape, ""attention_w"")

    # x shape after passing through embedding == (batch_size, 1, embedding_dim)
    x = self.embedding(x)

    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)
    print(x.shape, 'xshape', context_vector.shape, 'context')
    expanded_dims = tf.expand_dims(context_vector, 1)
    x = tf.concat([expanded_dims, x], axis=-1)

    # passing the concatenated vector to the GRU
    output, state = self.gru(x)

    # output shape == (batch_size * 1, hidden_size)
    output = tf.reshape(output, (-1, output.shape[2]))

    # output shape == (batch_size, vocab)
    x = self.fc(output)

    return x, state, attention_weights




```
The snippet I used to generate the tflite file:
```
converter = tf.lite.TFLiteConverter.from_keras_model(partial_model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('goog_nmt_v2.tflite', 'wb') as f:
f.write(tflite_model)
```

And this is the error log: 
```
2020-06-29 01:16:38.290 8824-8824/com.example.inmt_offline E/AndroidRuntime: FATAL EXCEPTION: main
    Process: com.example.inmt_offline, PID: 8824
    java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/concatenation.cc:73 t->dims->data[d] != t0->dims->data[d] (8 != 1)
    Node number 84 (CONCATENATION) failed to prepare.
    
        at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:158)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:343)
        at com.example.inmt_offline.MainActivity.runModel(MainActivity.java:207)
        at com.example.inmt_offline.MainActivity.access$400(MainActivity.java:30)
        at com.example.inmt_offline.MainActivity$1.onClick(MainActivity.java:83)
        at android.view.View.performClick(View.java:7870)
        at android.widget.TextView.performClick(TextView.java:14970)
        at android.view.View.performClickInternal(View.java:7839)
        at android.view.View.access$3600(View.java:886)
        at android.view.View$PerformClick.run(View.java:29363)
        at android.os.Handler.handleCallback(Handler.java:883)
        at android.os.Handler.dispatchMessage(Handler.java:100)
        at android.os.Looper.loop(Looper.java:237)
        at android.app.ActivityThread.main(ActivityThread.java:7814)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1068)
```"
40896,TimeDistributed Layer Does Not Support Multiple Outputs,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from source or binary: No
- TensorFlow version: 2.2.0
- Python version: 3.6.9
- CUDA/cuDNN version: 10.1/7.6.4
- GPU model and memory: Tesla V100 - 16GB

**Describe the current behavior**
The [TimeDistributed layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed) does not support layers with multiple outputs. This issue is also related to #35824, where the missing support for multiple inputs is mentioned, which leads to the overall missing support for nested structures of inputs and outputs.

**Describe the expected behavior**
The TimeDistributed wrapper should support the wrapping of layers with multiple inputs and multiple outputs.

**Standalone code to reproduce the issue**
```
import tensorflow as tf


class CustomLayer(tf.keras.layers.Layer):
    def __init__(self, name=None, **kwargs):
        super(CustomLayer, self).__init__(name=name, **kwargs)
        self.conv_1 = tf.keras.layers.Conv2D(filters=1, kernel_size=(1, 1))
        self.conv_2 = tf.keras.layers.Conv2D(filters=1, kernel_size=(1, 1))

    def call(self, inputs):
        output_1 = self.conv_1(inputs)
        output_2 = self.conv_2(inputs)

        return output_1, output_2

    def compute_output_shape(self, input_shape):
        output_shape_1 = self.conv_1.compute_output_shape(input_shape)
        output_shape_2 = self.conv_2.compute_output_shape(input_shape)

        return output_shape_1, output_shape_2


if __name__ == ""__main__"":
    inputs = tf.keras.Input(shape=(None, None, None, 1))

    custom_layer = CustomLayer()
    output_1, output_2 = tf.keras.layers.TimeDistributed(custom_layer)(inputs)

```
**Other info / logs**
```
File ""/reproduce/template.py"", line 29, in <module>
    output_1, output_2 = tf.keras.layers.TimeDistributed(custom_layer)(inputs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 922, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/wrappers.py"", line 246, in call
    output_shape = self.compute_output_shape(input_shape).as_list()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/wrappers.py"", line 192, in compute_output_shape
    child_output_shape = tensor_shape.TensorShape(child_output_shape)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 771, in __init__
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 771, in <listcomp>
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 716, in as_dimension
    return Dimension(value)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 200, in __init__
    None)
  File ""<string>"", line 3, in raise_from
TypeError: Dimension value must be integer or None or have an __index__ method, got TensorShape([None, None, None, 1])
```"
40895,nested gradients for convolution layer fail under tf.function,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): pip tf_nightly
- TensorFlow version (use command below): v1.12.1-35353-gcbb94efa58 2.5.0-dev20200628
- Python version:3.6.9
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: 10.1
- GPU model and memory: GeForce GTX 1050 Ti with Max-Q 4 Gb

**Describe the current behavior**
The code below works in eager mode, but fails with the following error if using tf.function

```
Traceback (most recent call last):
  File ""bugreport.py"", line 55, in <module>
    value = func(x)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 823, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 697, in _initialize
    *args, **kwds))
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2870, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3227, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3089, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 986, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 600, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""bugreport.py"", line 48, in func
    grads = tape.gradient(loss, variables)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py"", line 1073, in gradient
    unconnected_gradients=unconnected_gradients)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py"", line 77, in imperative_grad
    compat.as_str(unconnected_gradients.value))
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py"", line 162, in _gradient_function
    return grad_fn(mock_op, *out_grads)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py"", line 50, in _Conv2DBackpropInputGrad
    strides=op.get_attr(""strides""),
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py"", line 121, in get_attr
    raise KeyError(attr)
KeyError: 'strides'
```

**Describe the expected behavior**
I would expect this code to work the same under eager mode or wrapped with tf.function.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf

shape = (2, 3, 3, 5, 7)
init = tf.random.normal(shape=shape, dtype=tf.float32)
weights = tf.Variable(initial_value=init, trainable=True, shape=shape, dtype=tf.float32)

def conv(x):
    kernel = tf.reshape(tf.eye(3 * 3, dtype=x.dtype), shape=(3, 3, 1, 3 * 3))

    x = tf.reshape(x, shape=(2 * 5, 1, 4, 4))
    x = tf.nn.conv2d(x, kernel, strides=(1,1), padding='SAME', data_format='NCHW')
    x = tf.reshape(x, shape=(2, 5 * 3 * 3, 4 * 4))

    W = tf.reshape(weights, shape=(2, 3 * 3, 5, 7))
    W = tf.transpose(W, perm=[0, 2, 1, 3])
    W = tf.reshape(W, shape=(2, 5 * 3 * 3, 7))
    
    y = tf.linalg.matmul(W, x, transpose_a=True)
    y = tf.reshape(y, shape=(2, 7, 4, 4))
    y = tf.square(y)

    return y

def func_flat(x_flat):
    x_unflat = tf.reshape(x_flat, shape=(2, 5, 4, 4))

    with tf.GradientTape() as tape:
        tape.watch(x_unflat)
        y = conv(x_unflat)
        u = tf.reduce_sum(y, axis=[-3, -2, -1])
        u = tf.reshape(u, shape=(2, 1))

    jac = tape.batch_jacobian(u, x_unflat)
    return jac

variables = [weights]

@tf.function(autograph=False)
def func(x):
    with tf.GradientTape() as tape:
        tape.watch(weights)

        y_flat = func_flat(x)
        loss = tf.reduce_sum(tf.square(y_flat))

    grads = tape.gradient(loss, variables)

    return tf.reduce_sum(grads)


x = tf.random.normal(shape=(2, 5 * 4 * 4), dtype=tf.float32)

value = func(x)
print(value)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40894,directory structure has changed,"This is a Codelabs doc bug

## URL(s) with the issue:
https://codelabs.developers.google.com/codelabs/recognize-flowers-with-tensorflow-on-android/#3

## Description of issue (what needs changing):
Change directory structure from
examples/lite/codelabs/flower_classification/start
to
examples/lite/codelabs/flower_classification/android/start

{Admittedly, a minor issue, but am I doing this right?}"
40893,d,d
40892,model.set_inputs does not work for keras model,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS Linux release 7.7.1908 (Core) 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: Python 3.6.10 :: Anaconda, Inc.
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: No
- GPU model and memory: No

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
model.set_inputs does not work for keras model. 
After setting model._set_inputs, the model.inputs and model.outputs are still all None. 
The bug happens for tensorflow>=2.2. It works fine for tensorflow<2.2.
**Describe the expected behavior**
model.inputs will tell the shape [1,64] and model.outputs tell the shape [1,10]
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf

class MYMODEL(tf.keras.Model):
    def __init__(self):
        super(MYMODEL, self).__init__()
        self.dense1 = tf.keras.layers.Dense(10)
    def call(self, inputs):
        output = self.dense1(inputs)
        return output

model_keras = MYMODEL()

input_spec = tf.TensorSpec([1, 64], tf.int32)
model_keras._set_inputs(input_spec, training=False)

# keras_input = tf.keras.Input([64], batch_size=1, dtype=tf.int32)
# keras_output = model_keras(keras_input, training=False)
# model_keras = tf.keras.Model(keras_input, keras_output)

print(model_keras.inputs)
print(model_keras.outputs)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Although I can set inputs by adding an additional input layer before keras model as in the comment of source code as above.
I still want to know whether it is a bug."
40891,trying model with different sizes (The first argument to `Layer.call` must always be passed),"I face problem when I try to build model and try different batch sizes 
 code 
```
def model():
    model = Sequential()
    model.add(Dense(64, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1, activation='linear'))

    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])
    return model 

batch_sizes = [32, 64, 128, 256, 512]

fig = plt.figure(figsize=(12, 12))
for i in range(1, 6):

    fig.add_subplot(2, 3, i)
    model = model()
    history= model.fit(x, y, batch_size=batch_sizes[i-1], 
                        validation_data=(x_test, y_test), verbose=0,epochs=100)
   plt.plot(history.history['loss'], label='train')
    plt.plot(history.history['val_loss'], label='validation')
    plt.legend(['train', 'test'], loc='upper right')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.title('model loss in batch size = '+str(batch_sizes[i-1]), pad=-80)
```


it gives this error 
```
----> 7     model = model()
      8     history= model.fit(x, y, batch_size=batch_sizes[i-1], 
      9                         validation_data=(x_test, y_test), verbose=0,epochs=100)

~\anaconda3\envs\teachopencadd\lib\site-packages\tensorflow\python\keras\engine\base_layer.py in __call__(self, *args, **kwargs)
    798     else:
    799       raise ValueError(
--> 800           'The first argument to `Layer.call` must always be passed.')
    801 
    802     call_context = base_layer_utils.call_context()

ValueError: The first argument to `Layer.call` must always be passed.
        
```"
40890,Tensorflow Installation via windows command prompt,"Hi,
I have python 3.8 in my computer (windows-10 64 bit) and i'm getting error while installing tensor via command prompt.
Below are the lines i executed:
C:\Program Files (x86)\Python38-32\Scripts>pip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-2.2.0-cp38-cp38m-window.whl

ERROR: tensorflow-2.2.0-cp38-cp38m-window.whl is not a supported wheel on this platform. 

Need help to install.

NOTE: I'm able to install tensorflow-1.12.0 . But during import i'm getting error
ImportError: No module named '_pywrap_tensorflow_internal'"
40888,How to enable XNNPACK on android using official repository?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: armv7 and v8
- TensorFlow version: 2.2.0
- Installed using virtualenv?
    implementation 'org.tensorflow:tensorflow-lite:2.2.0'
    implementation 'org.tensorflow:tensorflow-lite-gpu:2.2.0'
    implementation 'org.tensorflow:tensorflow-lite-support:0.0.0-nightly'

**Describe the problem**

I am using tflite on android using below repos. Is the XNNPACK enabled by default on android or is there anything else required to enable it?
```
    implementation 'org.tensorflow:tensorflow-lite:2.2.0'
    implementation 'org.tensorflow:tensorflow-lite-gpu:2.2.0'
    implementation 'org.tensorflow:tensorflow-lite-support:0.0.0-nightly'
```"
40886,How can I use tensorflow with Graphcore IPU,"I want to test performance with graphcore IPU, but I don't know how to do with tensorflow. Someone can help me to do this?"
40885,tf.GradientTape.batch_jacobian fails on compiled tf.function due to assert op,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): pip tf-nightly
- TensorFlow version (use command below): v1.12.1-35353-gcbb94efa58 2.5.0-dev20200628
- Python version: 3.7.6
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: 10.1
- GPU model and memory: GeForce GTX 1050 Ti with Max-Q Design 4 Gb


**Describe the current behavior**

tf.GradientTape.batch_jacobian fails to run on compiled tf.function due to an unsupported graph assert.

**Describe the expected behavior**
I would expect batch_jacobian to work the same in compiled or uncompiled tf.function

**Standalone code to reproduce the issue**

```python
import tensorflow as tf

@tf.function(experimental_compile=True)
def func(x):
    with tf.GradientTape() as tape:
        tape.watch(x)
        y = tf.square(x)

    jac = tape.batch_jacobian(y, x)

    return jac

x = tf.zeros(shape=(2, 2), dtype=tf.float32)
jac = func(x)
```
fails with this error
```
Traceback (most recent call last):
  File ""bugreport.py"", line 14, in <module>
    jac = func(x)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 775, in __call__
    result = self._call(*args, **kwds)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 846, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1847, in _filtered_call
    cancellation_manager=cancellation_manager)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1923, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 550, in call
    ctx=ctx)
  File ""/home/abdo/tmp/venv/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Function invoked by the following node is not compilable: {{node __inference_func_203}} = __inference_func_203[_XlaMustCompile=true, config_proto=""\n\007\n\003CPU\020\001\n\007\n\003GPU\020\0012\005*\0010J\0008\001\202\001\000"", executor_type=""""](dummy_input).
Uncompilable nodes:
assert_equal_1/Assert/Const: unsupported op: Const op with type DT_STRING is not supported by XLA.
	Stacktrace:
		Node: __inference_func_203, function: 
		Node: assert_equal_1/Assert/Const, function: __inference_func_203

assert_equal_1/Assert/Const_1: unsupported op: Const op with type DT_STRING is not supported by XLA.
	Stacktrace:
		Node: __inference_func_203, function: 
		Node: assert_equal_1/Assert/Const_1, function: __inference_func_203

assert_equal_1/Assert/Const_2: unsupported op: Const op with type DT_STRING is not supported by XLA.
	Stacktrace:
		Node: __inference_func_203, function: 
		Node: assert_equal_1/Assert/Const_2, function: __inference_func_203

assert_equal_1/Assert/Assert/data_0: unsupported op: Const op with type DT_STRING is not supported by XLA.
	Stacktrace:
		Node: __inference_func_203, function: 
		Node: assert_equal_1/Assert/Assert/data_0, function: __inference_func_203

assert_equal_1/Assert/Assert/data_1: unsupported op: Const op with type DT_STRING is not supported by XLA.
	Stacktrace:
		Node: __inference_func_203, function: 
		Node: assert_equal_1/Assert/Assert/data_1, function: __inference_func_203

assert_equal_1/Assert/Assert/data_3: unsupported op: Const op with type DT_STRING is not supported by XLA.
	Stacktrace:
		Node: __inference_func_203, function: 
		Node: assert_equal_1/Assert/Assert/data_3, function: __inference_func_203
 [Op:__inference_func_203]

```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The problem vanishes if I remove the assert_equal on line 1276 in `tensorflow/python/eager/backprop.py`

```python
    ...
    with ops.control_dependencies(
        [check_ops.assert_equal(batch_size, source_shape[0])]):
      target = array_ops.reshape(target, [batch_size, target_row_size])
    ...

```
I'd be happy to submit a PR, however I am not sure how to replace the assert with a compile-friendly version."
40884,Pinned scipy dependency,"**System information**
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.2.0
- Python version: 3.7
- Installed using: pip

**Describe the problem**
Pinned `scipy` dependency. Accepted requirements should be greater than or equal to the version tested by devs, but here are just equal (currently pinned to 1.4.1).

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
pip install scipy
pip install tensorflow
```

**Any other info / logs**
```
ERROR: tensorflow 2.2.0 has requirement scipy==1.4.1; python_version >= ""3"", but you'll have scipy 1.5.0 which is incompatible.
```
"
40882,Building C API under Windows 10 fails,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 2.2
- Python version: 3.5
- Installed using virtualenv? pip? conda?: No
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): Build Tools VC 19
- CUDA/cuDNN version: 10.1, cudann 7.6
- GPU model and memory: RTX 2080 Ti 11 Gb


**Describe the problem**
Building C API fails with this command:
`bazel build --config=opt --config=cuda --incompatible_strict_action_env=false --define=no_tensorflow_py_deps=true //tensorflow:libtensorflow.so`

Error:
```
LINK : warning LNK4217: symbol 'TF_DeleteDimensionHandle' defined in 'libops.lo(ops.o)' is imported by 'libbitcast_op_lib.lo(bitcast.o)' in function '""void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,unsigned __int64,unsigned __int64,struct TF_Status *)"" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@_K2PEAUTF_Status@@@Z)'
ERROR: D:/dev/tensorflow/tensorflow/BUILD:677:1: declared output 'tensorflow/libtensorflow.so.2' is a dangling symbolic link
ERROR: D:/dev/tensorflow/tensorflow/BUILD:677:1: not all outputs were created or valid
Target //tensorflow:libtensorflow.so failed to build
INFO: Elapsed time: 8143.925s, Critical Path: 1171.29s
INFO: 6722 processes: 6722 local.
FAILED: Build did NOT complete successfully
```
"
40880,Eager execution is turned off with a custom train_step() function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2
- Python version: 3.7

**Describe the current behavior**
According to the TF documentation, from TF 2.0 onwards Eager Execution is enabled by default: https://www.tensorflow.org/guide/eager

In TF 2.2, train_step function was added so we can create custom training loops using Subclassing API (thanks for that!). An expected behaviour would be that eager execution is enabled by default in this train_step function (according to docs and a common sense). 

When train_step function is implemented Eager execution is disabled even if it was previously enabled. It is not possible to switch it back to eager execution (e.g. by forcing tf.compat.v1.enable_eager_execution in the train step function). I would also suspect that it might be happening for test_step and predict_step but I haven't checked that yet.

**Describe the expected behavior**
train_step, predict_step and test_step run in eager mode by default.

**Standalone code to reproduce the issue**
_Link to colab notebook:_
https://colab.research.google.com/drive/1LZmKSlzYgOpX_pjnpB7P5EiRxm9_2CmN?usp=sharing

_Copy-paste version below_
``` Python
import tensorflow as tf
import numpy as np
print(tf.__version__) # Has to be 2.2

# Example modified from: https://keras.io/api/models/model/
class MyModel(tf.keras.Model):
    def __init__(self):
        super(MyModel, self).__init__()
        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)
        self.dense2 = tf.keras.layers.Dense(1, activation=tf.nn.softmax)

    def compile(self, optimizer, loss, metric):
        """"""
        Overriden .compile() method to initialize
        optimizer, loss, and metric for train_step function
        """"""
        super().compile()
        self.opt = optimizer
        self.loss = loss
        self.metric = metric  
    
    def train_step(self, data):
        print(f""Eager execution mode: {tf.executing_eagerly()}"")
        X, y = data
        
        # Track gradients
        with tf.GradientTape() as tape:
             y_pred = self.call(X)
             loss = self.loss(y, y_pred)
        
        # Compute and modify the weights
        grads = tape.gradient(loss, self.trainable_weights)
        self.opt.apply_gradients(zip(grads, self.trainable_weights))        

        # Compute metric
        metric = self.metric(y, y_pred)
        return {""loss"": loss, ""metric"": metric}
    
    def call(self, inputs):
        x = self.dense1(inputs)
        return self.dense2(x)

if __name__ == ""__main__"":
    # Should be True
    print(f""Eager execution mode: {tf.executing_eagerly()}"")

    X = np.random.rand(10, 4)
    y = np.random.randint(0, 2, (10, 1))
    model = MyModel()
    model.compile(tf.keras.optimizers.Adam(), 
                tf.keras.losses.BinaryCrossentropy(),
                tf.keras.metrics.Accuracy())
    # Should print True
    model.fit(X, y)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
![image](https://user-images.githubusercontent.com/33067446/85945306-403b6780-b93d-11ea-8b7f-21486eb9fe1d.png)

"
40879,Why models with different parameter size all allocate all the GPU memory,"I use tensorflow-gpu 1.15 trains models , and for resnet models with different parameter size, they all allocate all the memory for a V100 GPU. However, when I train a larger transformer model, it only allocate a part of the memory.  When I set:
fraction = round(0.5, 1)
    # config = tf.ConfigProto()
    # sess_config.gpu_options.per_process_gpu_memory_fraction = fraction
    config = tf.ConfigProto()
    gpu_option = tf.GPUOptions(allow_growth=True,per_process_gpu_memory_fraction=fraction)
    config.allow_soft_placement=True
    config.gpu_options.allow_growth = True
    with tf.Session(config=config) as sess:
the gpu_options do not work effectively.  May the code cause this problem?
![image](https://user-images.githubusercontent.com/34976119/85942146-1c3a4f00-b95a-11ea-86b5-a8a2d808db51.png)
"
40878,Bug when serializing optimizer with `tf.keras.utils.serialize_keras_object` but works fine with `tf.keras.optimizers.serialize`,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.8
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA


**Describe the current behavior**
I have provided two code snippets for serializing and deserializing Keras optimizer. One of them works and other doesn't.

**Describe the expected behavior**
Both the code snippets should work.

**Standalone code to reproduce the issue**

<a href=""https://colab.research.google.com/github/SpikingNeuron/tfpy_warrior/blob/master/try_optimizer_serialization.ipynb"" target=""_parent""><img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Open In Colab""/></a>

For your quick reference, I provide here the two code snippets

### Snippet 1 - does not work

```python
import tensorflow.keras as tk
opt = tk.optimizers.Adam()
opt_ser = tk.utils.serialize_keras_object(opt)
opt_deser = tk.utils.deserialize_keras_object(opt_ser)
print(opt_deser)
```

### Snippet 2 - works

```python
import tensorflow.keras as tk
opt = tk.optimizers.Adam()
opt_ser = tk.optimizers.serialize(opt)
opt_deser = tk.optimizers.deserialize(opt_ser)
print(opt_deser)
```
"
40877,"Check failed: cudnnSetRNNMatrixMathType(rnn_desc.get(), math_type) == CUDNN_STATUS_SUCCESS (3 vs. 0)","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): SOURCE
- TensorFlow version (use command below): LATEST FROM GIT
- Python version: 3.8.1
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: 11 / 8.0.1
- GPU model and memory: GeForce RTX 2070

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Errors out with this line when i ran a sequential model

F tensorflow/stream_executor/cuda/cuda_dnn.cc:1186] Check failed: cudnnSetRNNMatrixMathType(rnn_desc.get(), math_type) == CUDNN_STATUS_SUCCESS (3 vs. 0)

**Standalone code to reproduce the issue**

model = keras.Sequential()
model.add(
  keras.layers.Bidirectional(
    keras.layers.LSTM(
      units=128, 
      input_shape=(X_train.shape[1], X_train.shape[2])
    )
  )
)
model.add(keras.layers.Dropout(rate=0.2))
model.add(keras.layers.Dense(units=1))
model.compile(loss='mean_squared_error', optimizer='adam')

**Error happens at this line,**
history = model.fit(
    X_train, y_train, 
    epochs=30, 
    batch_size=32, 
    validation_split=0.1,
    shuffle=False
)

"
40876,TFL Classify keeps stopping on Pixel 3.,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
40875,Failed to load the native TensorFlow runtime.,"Traceback (most recent call last):
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\vmathesh\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\vmathesh\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\vmathesh\AppData\Local\Programs\Python\Python37\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""C:\Users\vmathesh\AppData\Local\Programs\Python\Python37\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\vmathesh\Vinod\Task\Python\RASA\venv\Scripts\rasa.exe\__main__.py"", line 7, in <module>
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\rasa\__main__.py"", line 82, in main
    set_log_level(log_level)
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\rasa\utils\common.py"", line 71, in set_log_level
    update_tensorflow_log_level()
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\rasa\utils\common.py"", line 112, in update_tensorflow_log_level
    import tensorflow as tf
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\vmathesh\AppData\Local\Programs\Python\Python37\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\users\vmathesh\vinod\task\python\rasa\venv\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\vmathesh\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 243, in load_module
  File ""C:\Users\vmathesh\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
40874,in docker tensorflow/tensorflow:latest-gpu was unable to find libcuda.so DSO,"sudo docker run --gpus all -it --rm tensorflow/tensorflow:latest-gpu
python -c ""import tensorflow as tf; tf.config.list_physical_devices('GPU')""

```
2020-06-27 10:14:59.618701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-27 10:14:59.618726: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (-1)
2020-06-27 10:14:59.618744: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: fd26039ac692
2020-06-27 10:14:59.618752: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: fd26039ac692
2020-06-27 10:14:59.618821: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
2020-06-27 10:14:59.618853: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 440.82.0
```
Docker version 19.03.12, build 48a66213fe

NVIDIA 440.82

I install nvidia-container-toolkit

In my host it works,but in docker I get ""was unable to find libcuda.so DSO """
40872,failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error,"python 3.6
tensorflow-gpu 1.13.1
CUDA 10.0.130
Cudnn 7.6.5

I used TensorFlow-GPU 1.13.1 to train my faster-rcnn modelbut I could not use GPU to accelerate the training processjust could use CPU to train the model, and I run the codesimport tensorflow as tf tf.test.is_gpu_available() .

And the error as show:
2020-06-28 08:13:08.860753: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2020-06-28 08:13:08.936714: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error
2020-06-28 08:13:08.953830: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: DESKTOP-PSVDSUR
2020-06-28 08:13:08.959987: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: DESKTOP-PSVDSUR
False

In addition, the acceleration performance of GPU can be used normally in the past.
So, I hope you can help me to solve my problem, thanks!"
40871,AutoGraph not working ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.15.5
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 2.2
- Python version: 3.7.7

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I am trying to run a basic lenet5 model and it will not run.  I am copying the model from a book, Hands on Computer Vision with TensorFlow2.  When I run it, I get a warning that says I should report it:

WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7ff5121fa440> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.

I also get an error later in the run:

  File ""/Users/toddwimer/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py"", line 180, in assert_input_compatibility
    str(x.shape.as_list()))

ValueError: Input 0 of layer sequential_4 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [32, 28, 28]
I do not get an output.

**Describe the expected behavior**
I expect the code to run and produce a trained model.

**Standalone code to reproduce the issue**
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
import numpy as np
print(tf.__version__)

num_classes = 10
img_rows, img_cols = 28, 28
num_channels = 1
input_shape = (img_rows, img_cols, num_channels)
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
model = Sequential()
model.add(Conv2D(6, kernel_size=(5,5), padding='same', activation='relu',
                 input_shape=input_shape, name='conv1'))
model.add(MaxPooling2D(pool_size=(2,2), name='pool1'))
model.add(Conv2D(16, kernel_size=(5,5), activation='relu', name='conv2'))
model.add(MaxPooling2D(pool_size=(2,2), name='pool2'))
model.add(Flatten(name='flatten'))
model.add(Dense(120, activation='relu', name='dense1'))
model.add(Dense(84, activation='relu', name='dense2'))
model.add(Dense(10, activation='softmax', name='output'))
model.compile(optimizer='sgd',
 loss='sparse_categorical_crossentropy',
 metrics=['accuracy'])
model.fit(x_train, y_train, batch_size=32, epochs=80, verbose=1, validation_data=(x_test,y_test))
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40870,I already has tensorflow installed,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
![image](https://user-images.githubusercontent.com/31926010/85931140-c2953e80-b8df-11ea-8b98-930cc9170a8d.png)
but getting this error on import tensorflow"
40869,module 'keras.backend' has no attribute 'get_session',"
**System information**
- macOS 10.15.5
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.2.0
- Python version: 3.8.3

hey guys! just got a trouble, can't find any ansewrs at web, can some one help me?

**Error:**
Traceback (most recent call last):
  File ""/Users/a/PycharmProjects/untitled/venv/main.py"", line 7, in <module>
    detector = ObjectDetection()
  File ""/Users/a/PycharmProjects/untitled/venv/lib/python3.7/site-packages/imageai/Detection/__init__.py"", line 88, in __init__
    self.sess = K.get_session()
AttributeError: module 'keras.backend' has no attribute 'get_session


**code:**
from imageai.Detection import ObjectDetection
import tensorflow.keras.backend
import os

exec_path = os.getcwd()
detector = ObjectDetection()
detector.setModelTypeAsRetinaNet()
detector.setModelPath(os.path.join(exec_path, ""resnet50_coco_best_v2.0.1.h5""))
detector.loadModel()

List = detector.detectObjectsFromImage(input_image=os.path.join(exec_path, ""traffic_jam.jpg""),
                                       output_image_path=os.path.join(exec_path, ""new_traffic_jam.jpg"")
                                       )


"
40867,using tf.GPUOptions in tf 2.x,"what is the proper call for this in version of tensorflow 2.x ?
tf.GPUOptions(per_process_gpu_memory_fraction=0.3) # i used this with tf.compat.v1 , GPUOptions is not available in 2.x , can someone help me use my gpu cores without using gpuoptions ,coz i dont want to use compat v1"
40866,TFLu wrong predictions for optimized model,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: macOS 10.14.16 and Ubuntu 18.04.4 LTS
- TensorFlow installed from: source
- Tensorflow version: TF v2.2
- Target platform: ARM Mbed OS (bare-metal) on STM32L4
- MCU Compiler: GCC ARM (GNU Arm Embedded Toolchain 9-2020-q2-update)

**Describe the problem**

Running an optimized model (see code snippet for generation below) on the MCU results in wrong predictions. Those predictions differ depending on the build profile (see more below).
Running the model locally with the TF Lite Interpreter works flawlessly.

**Please provide the exact sequence of commands/steps when you ran into the problem**

I'm currently benchmarking multiple models on the STM32L4 and want to verify the accuracy on the MCU itself by sending the test data and the results back and forth via UART.
This works flawlessly for the converted model without any optimizations:
```python
converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)
tflite_model = converter.convert()
open('./TFLite-model/LeNet-MNIST.tflite', 'wb').write(tflite_model)
```

This also works flawlessly for the model with full int8 quantization:
```python
converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.representative_dataset = yield_representative_dataset
tflite_model = converter.convert()
open('./TFLite-model/LeNET-MNIST_int8ops.tflite', 'wb').write(tflite_model)
```

However, the predictions are wrong when only using `[tf.lite.Optimize.DEFAULT]` - where only some of the weights are quantized.
```python
converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
open('./TFLite-model/LeNet-MNIST_optimized.tflite', 'wb').write(tflite_model)
```

Everything works flawlessly on the local TFLite Interpreter, and the problem only occurs with the mentioned model **with and without cmsis-nn** on the MCU.

Building with the `release.json` profile (mainly `-Os`) always results in the following prediction independent from the input:
```
[0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0]
```

However, building with the `debug.json` profile (`-Og`) always results in different wrong outputs but reproducible with the same input e.g.:
```
[0.1012007445, 0.1061911806, 0.0979489163, 0.1032304987, 0.1272625774, 0.0807816312, 0.0818515792, 0.0830543563, 0.0847685188, 0.1337099075]
```


**Things I already tried**
- the model works flawlessly on the TF Lite interpreter on my host machines
- the model is correctly ported to the MCU
    - no TFLu runtime errors
    - verified the input and output tensors size and datatypes (as expected float32)
- there is ongoing computation on the MCU and I can even benchmark each layer individually

I currently don't have a second MCU at hand to test this.

---

Given that all the other models run flawlessly on the MCU and that the output depends on the compiler optimizations, I'm a bit clueless and expect some problem with TFLu.

The only difference from the optimized to the non-optimized model are the quantized weights in the fully-connected layers, I expect a problem somewhere there.
Furthermore the fully int8 quantized model runs flawlessly.
So I would restricte the error to kernels which use the int8 quantized weights, but still do the computation in float32 -- this is the only spot where I do see a difference of the model architectures.

Thankful for any feedback and pointers.

**Attachements**
[GDrive Folder](https://drive.google.com/drive/folders/1bXUNiN5vrr1n1mrFuKsB0_h_nLqd0DD5?usp=sharing)
- [model architecture](https://drive.google.com/file/d/1UKt578IcToaQJdPrIVAvRexwb6XEyJBd/view?usp=sharing)
- the original keras model
- the converted optimized model which gives wrong predictions
"
40864,Colab TPU failing with distribution strategy on a dataset hosted on a public GCS bucket,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: Yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Colab
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

### Describe the problem
I have hosted the cats-vs-dogs dataset on a public GCS bucket. I have created the dataset pipeline using `tf.data`. After building the model inside the `TPUStrategy` scope and compiling it, I am calling `.fit`. Currently, it results into:

```
TypeError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py:174 run  **
        return self.extended.tpu_run(fn, args, kwargs, options)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py:867 tpu_run
        return func(args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py:916 tpu_function
        maximum_shape = tensor_shape.TensorShape([None] * rank)

    TypeError: can't multiply sequence by non-int of type 'NoneType'
```

Note that I am using Colab TPUs here. The larger log file is attached. In this particular case, we have included image stylization in the data input pipeline as one would notice. Without the stylization, the training seems to be working fine. Here's the [Colab Notebook](https://colab.research.google.com/gist/sayakpaul/5c897959a8b472311d6b745d494cdd7f/texturecnn.ipynb) that confirms that. 

### Source code / logs
Here's the [Colab Notebook](https://colab.research.google.com/gist/sayakpaul/90a946d414eea1380d0c814f4cd025ce/shapecnn.ipynb). You can choose to not install `wandb`, in that case just comment out the `wandb` imports and remove `WandbCallback()` from the callback list while calling `model.fit()`. 

[error_trace.txt.zip](https://github.com/tensorflow/tensorflow/files/4840232/error_trace.txt.zip)"
40863,Access feature map regions in keras custom layer and assigning values to output layer.,"I am creating a custom layer where I have to access the individual map windows and do operations on them, but because the model sends in none type as the first dimension of the input, I am unable to iterate over or access the region. Some help would be greatly appreciated. Here is the link to the full problem and the code:
[stack_overflow_link](https://stackoverflow.com/questions/62564980/access-image-regions-in-keras-custom-layer-and-assigning-values-to-the-output)"
40862,Link Broken on tutorials/images/object detection API,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

This link is broken https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb

![image](https://user-images.githubusercontent.com/6630197/85917788-7c979680-b85d-11ea-8d93-0fae5b8d9bf2.png)

### Correct links

Is the link to the source code correct?

Yes, this one [https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb)


### Submit a pull request?

No.
"
40860,protoc not using the right environment - build failure,"The tensorflow build I have with commit 80768cb23a3a4314c52af0b48a6bcf23ca541e19 fails here apparently because `protoc` is being passed an empy environment - as such it doesn't pick up the right libstdc++. A log with the `-s` option is attached below. 

OS: CentOS Linux release 7.7.1908 (Core)
gcc (GCC) 8.2.0
bazel: 3.1.0

```
$ bazel build -s tensorflow/core/data/service:all
...
ERROR: /net/uday-dev/srv/nfs/uday-data/ws/tensorflow-private/tensorflow/core/data/service/BUILD:310:1: Action tensorflow/core/data/service/master.grpc.pb.h failed (Exit 1)
bazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)
bazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)
bazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)
bazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)
```
Passing `-s` reveals:

```
exec env - \
  bazel-out/host/bin/external/com_google_protobuf/protoc '--plugin=protoc-gen-PLUGIN=bazel-out/host/bin/external/com_github_grpc_grpc/src/compiler/grpc_cpp_plugin' '--PLUGIN_out=generate_mock_code=true:bazel-out/k8-opt/bin' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=bazel-out/k8-opt/bin/external/com_google_protobuf/_virtual_imports/any_proto' '--proto_path=bazel-out/k8-opt/bin/external/com_google_protobuf/_virtual_imports/api_proto' '--proto_path=bazel-out/k8-opt/bin/external/com_google_protobuf/_virtual_imports/source_context_proto' '--proto_path=bazel-out/k8-opt/bin/external/com_google_protobuf/_virtual_imports/type_proto' '--proto_path=bazel-out/k8-opt/bin/external/com_google_protobuf/_virtual_imports/compiler_plugin_proto' '--proto_path=bazel-out/k8-opt/bin/external/com_google_protobuf/_virtual_imports/descriptor_proto' '--proto_path=bazel-out/k8-opt/bin/external/com_google_protobuf/_virtual_imports/duration_proto' '--proto_path=bazel-out/k8-opt/bin/external/com_google_protobuf/_virtual_imports/empty_proto' '--proto_path=bazel-out/k8-opt/bin/external/com_google_protobuf/_virtual_imports/field_mask_proto' '--proto_path=bazel-out/k8-opt/bin/external/com_google_protobuf/_virtual_imports/struct_proto' '--proto_path=bazel-out/k8-opt/bin/external/com_google_protobuf/_virtual_imports/timestamp_proto' '--proto_path=bazel-out/k8-opt/bin/external/com_google_protobuf/_virtual_imports/wrappers_proto' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=.' '--proto_path=bazel-out/k8-opt/bin' tensorflow/core/data/service/master.proto)
ERROR: /net/uday-dev/srv/nfs/uday-data/ws/tensorflow-private/tensorflow/core/data/service/BUILD:310:1: Action tensorflow/core/data/service/master.grpc.pb.h failed (Exit 1)
bazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)
bazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)
bazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)
bazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)
```

Why is protoc being executed with an empty environment (`env -`) here instead of using the environment with which everything else is being built? Using an empty environment here will make it pick the wrong libstdc++ (/usr/lib64/libstdc++.so.6) instead of the one available with LD_LIBRARY_PATH where those symbols are available.

A similar issue was reported in the past (https://github.com/bazelbuild/bazel/issues/1358) but the workaround there of adding `env=ctx.configuration.default_shell_env` to the `ctx.action` call in `third_party/systemlibs/protobuf.bzl` doesn't help here. If this was fixed in a later commit upstream, I'd appreciate a pointer to the commit - I couldn't immediately tell from the log. Thanks."
40859,still windows unavailable for build,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 2004
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0-rc.0
- Python version: 3.8.3 x64
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 3.3.0 x64
- GCC/Compiler version (if compiling from source): Visual Studio 2019
- CUDA/cuDNN version: 10.2 / 7.6.5
- GPU model and memory:  RTX2080Ti GDDR6 11GB



**Describe the problem**
build with gpu error
**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
.\configure
bazel build --copt=-nvcc_options=disable-warnings --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
ERROR: D:/repo/tensorflow/tensorflow/core/kernels/BUILD:3782:18: C++ compilation of rule '//tensorflow/core/kernels:tridiagonal_matmul_op_gpu' failed (Exit 1): python.exe failed: error executing command
  cd C:/users/alan-workstation/_bazel_alan-workstation/ibqopsat/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2
    SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.26.28801\ATLMFC\include;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.26.28801\include;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\ucrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\winrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\cppwinrt
    SET LIB=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.26.28801\ATLMFC\lib\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.26.28801\lib\x64;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\lib\um\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.18362.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.18362.0\um\x64;
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\\Extensions\Microsoft\IntelliCode\CLI;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.26.28801\bin\HostX64\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\TeamFoundation\Team Explorer;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\MSBuild\Current\bin\Roslyn;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Team Tools\Performance Tools\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Team Tools\Performance Tools;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\\x64;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.8 Tools\x64\;C:\Program Files (x86)\HTML Help Workshop;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\FSharp\;C:\Program Files (x86)\Windows Kits\10\bin\10.0.18362.0\x64;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\\MSBuild\Current\Bin;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\Tools\;;C:\WINDOWS\system32;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\CMake\Ninja;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\VC\Linux\bin\ConnectionManagerExe
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Anaconda3/python.exe
    SET PYTHON_LIB_PATH=C:/Anaconda3/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\ALAN-W~1\AppData\Local\Temp
    SET TF2_BEHAVIOR=1
    SET TF_CONFIGURE_IOS=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=7.5
    SET TF_ENABLE_XLA=1
    SET TF_NEED_CUDA=1
    SET TMP=C:\Users\ALAN-W~1\AppData\Local\Temp
  C:/Anaconda3/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/libjpeg_turbo /Ibazel-out/x64_windows-opt/bin/external/libjpeg_turbo /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Iexternal/mkl_dnn /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn /Iexternal/curl /Ibazel-out/x64_windows-opt/bin/external/curl /Iexternal/boringssl /Ibazel-out/x64_windows-opt/bin/external/boringssl /Iexternal/jsoncpp_git /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git /Iexternal/aws /Ibazel-out/x64_windows-opt/bin/external/aws /Iexternal/aws-c-common /Ibazel-out/x64_windows-opt/bin/external/aws-c-common /Iexternal/aws-c-event-stream /Ibazel-out/x64_windows-opt/bin/external/aws-c-event-stream /Iexternal/aws-checksums /Ibazel-out/x64_windows-opt/bin/external/aws-checksums /Iexternal/cub_archive /Ibazel-out/x64_windows-opt/bin/external/cub_archive /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cusolver_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cufft_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/curand_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cusparse_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/cub_archive/_virtual_includes/cub /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/gif/windows /Ibazel-out/x64_windows-opt/bin/external/gif/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /Iexternal/local_config_cuda/cuda/cusolver/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cusolver/include /Iexternal/local_config_cuda/cuda/cufft/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cufft/include /Iexternal/local_config_cuda/cuda/curand/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/curand/include /Iexternal/mkl_dnn/include /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/include /Iexternal/mkl_dnn/src /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src /Iexternal/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/common /Iexternal/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu /Iexternal/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/gemm /Iexternal/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/xbyak /Iexternal/curl/include /Ibazel-out/x64_windows-opt/bin/external/curl/include /Iexternal/boringssl/src/include /Ibazel-out/x64_windows-opt/bin/external/boringssl/src/include /Iexternal/jsoncpp_git/include /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git/include /Iexternal/aws/aws-cpp-sdk-core/include /Ibazel-out/x64_windows-opt/bin/external/aws/aws-cpp-sdk-core/include /Iexternal/aws/aws-cpp-sdk-s3/include /Ibazel-out/x64_windows-opt/bin/external/aws/aws-cpp-sdk-s3/include /Iexternal/aws/aws-cpp-sdk-transfer/include /Ibazel-out/x64_windows-opt/bin/external/aws/aws-cpp-sdk-transfer/include /Iexternal/aws-c-common/include /Ibazel-out/x64_windows-opt/bin/external/aws-c-common/include /Iexternal/aws-c-event-stream/include /Ibazel-out/x64_windows-opt/bin/external/aws-c-event-stream/include /Iexternal/aws-checksums/include /Ibazel-out/x64_windows-opt/bin/external/aws-checksums/include /Iexternal/local_config_cuda/cuda/cusparse/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cusparse/include /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /DCURL_STATICLIB /DPLATFORM_WINDOWS /DENABLE_CURL_CLIENT /DOPENSSL_IS_BORINGSSL /DTF_USE_SNAPPY /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /showIncludes /MD /O2 /DNDEBUG /w /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI -nvcc_options=disable-warnings /std:c++14 -x cuda -DGOOGLE_CUDA=1 -Xcuda-fatbinary=--compress-all --no-cuda-include-ptx=all --cuda-include-ptx=sm_75 --cuda-gpu-arch=sm_75 -DGOOGLE_CUDA=1 -DTENSORFLOW_USE_NVCC=1 -DTENSORFLOW_USE_XLA=1 -DTENSORFLOW_MONOLITHIC_BUILD /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /wd4577 /DNOGDI /DTF_COMPILE_LIBRARY -nvcc_options=relaxed-constexpr -nvcc_options=ftz=true /Fobazel-out/x64_windows-opt/bin/tensorflow/core/kernels/_objs/tridiagonal_matmul_op_gpu/tridiagonal_matmul_op_gpu.cu.o /c tensorflow/core/kernels/tridiagonal_matmul_op_gpu.cu.cc
Execution platform: @local_execution_config_platform//:platform
cl : Command line warning D9002 : ignoring unknown option '--no-cuda-include-ptx=all'
cl : Command line warning D9002 : ignoring unknown option '--cuda-include-ptx=sm_75'
cl : Command line warning D9002 : ignoring unknown option '--cuda-gpu-arch=sm_75'
.\tensorflow/core/kernels/cuda_sparse.h(39): error: identifier ""cusparseDnMatDescr_t"" is undefined

.\tensorflow/core/kernels/cuda_sparse.h(40): error: identifier ""cusparseSpMatDescr_t"" is undefined

.\tensorflow/core/kernels/cuda_sparse.h(41): error: identifier ""cusparseSpMMAlg_t"" is undefined

3 errors detected in the compilation of ""C:/Users/ALAN-W~1/AppData/Local/Temp/nvcc_inter_files_tmp_dir/tmp8susqlh4/tridiagonal_matmul_op_gpu.cu.cpp1.ii"".
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 2236.805s, Critical Path: 165.63s
INFO: 4808 processes: 4808 local.
FAILED: Build did NOT complete successfully
```"
40858,how to improve accuracy for an example code at tensorflow.org ,"I am trying to run some example Deep learning python3 code on databricks/GPU. The code is from https://www.tensorflow.org/tutorials/keras/text_classification_with_hub#evaluate_the_model

I got the results :

    training loss: 0.0762 - training accuracy: 0.9929 
     validation_loss: 0.5734 - validation_accuracy: 0.8628

The example said

      ""This fairly naive approach achieves an accuracy of about 87%. With more advanced approaches, the model should get closer to 95%.""

I want to find how to improve the accuracy.

From the results, I think it is overfitting. So, I tried to add l1 and l2 regularizer and dropout.

     embedding = ""https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1""
     hub_layer = hub.KerasLayer(embedding, input_shape=[], 
                       dtype=tf.string, trainable=True)
  
     tf.keras.regularizers.l1_l2(l1=0.04, l2=0.01)  # L1 + L2 penalties
      model = tf.keras.Sequential()
     model.add(hub_layer)
     model.add(tf.keras.layers.Dense(8, activation='relu'))
     model.add(tf.keras.layers.Dropout(rate=0.3))
     model.add(tf.keras.layers.Dense(1))

I have tried different dropout (0.2, 0.3, 0.5, 0.7) and l1/l2 regularizers (0.01, 0.02, 0.04).

I have reduced the units in the first hidden layer from 16 to 8. I have tried Reducing (Versus Delaying) Overfitting in Neural Network and how to reduce overfitting in neural networks?

But, no improvement. How can I reduce the overfitting ?

thanks"
40857,ImportError: cannot import name device_spec,"
Traceback (most recent call last):
  File ""object_detection/builders/model_builder_tf1_test.py"", line 21, in <module>
    from object_detection.builders import model_builder
  File ""/home/magdalena/models/research/object_detection/builders/model_builder.py"", line 19, in <module>
    from object_detection.builders import anchor_generator_builder
  File ""/home/magdalena/models/research/object_detection/builders/anchor_generator_builder.py"", line 23, in <module>
    from object_detection.anchor_generators import flexible_grid_anchor_generator
  File ""/home/magdalena/models/research/object_detection/anchor_generators/flexible_grid_anchor_generator.py"", line 19, in <module>
    from object_detection.anchor_generators import grid_anchor_generator
  File ""/home/magdalena/models/research/object_detection/anchor_generators/grid_anchor_generator.py"", line 27, in <module>
    from object_detection.utils import ops
  File ""/home/magdalena/models/research/object_detection/utils/ops.py"", line 28, in <module>
    import tf_slim as slim
  File ""/home/magdalena/.local/lib/python2.7/site-packages/tf_slim/__init__.py"", line 25, in <module>
    from tf_slim.layers import *
  File ""/home/magdalena/.local/lib/python2.7/site-packages/tf_slim/layers/__init__.py"", line 25, in <module>
    from tf_slim.layers.layers import *
  File ""/home/magdalena/.local/lib/python2.7/site-packages/tf_slim/layers/layers.py"", line 30, in <module>
    from tf_slim.ops import variables
  File ""/home/magdalena/.local/lib/python2.7/site-packages/tf_slim/ops/variables.py"", line 27, in <module>
    from tensorflow.python.framework import device_spec as tf_device
ImportError: cannot import name device_spec


Python = 2.7
Tensorflow = 1.13.1
Ubuntu 18.04.4

What could be the problem and how can i solve this issue?
"
40856,TFTRT combinednms fail in in TRT 6 and TF 1.15.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10.0 cuDNN 7.6.3
- GPU model and memory:

**Describe the current behavior**
TensorRT 6 support is added by https://github.com/tensorflow/tensorflow/pull/32397 which include three changes: header files, fall to fp16, and combined nms WAR last output dim.

However in 1.15 release, only header file change is cherry-picked https://github.com/tensorflow/tensorflow/pull/32828, as a result, two other change is missing. TFTRT CombinedNMS is no workable with TRT 6.

**Describe the expected behavior**

Should also cherry-pick other two changes.
"
40855,"tfrecords on s3 very slow on tf-nightly, not tensorflow 2.2","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.14.6
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-35161-gd659eb9c0d 2.3.0-dev20200625
- Python version: 3.7.1



**Describe the current behavior**

Loading tfrecord data from s3 is slow in the nightly version. Following script takes 0.8 seconds on tf2.2 but 5 seconds on tf-nightly. The effects are more pronounced with slow network speeds. 

**Describe the expected behavior**

tfrecord streaming should be as fast in tf-nightly as in tf2.2. 

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1Q5zsGJYKrogNGqfQ6DXds4AKWEXSzwKx?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40852,tf.keras.backend.repeat_elements does not support negative indexing on tensors with dynamic shape,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 and Google Colab
-   **TensorFlow installed from (source or binary)**: binary
-   **TensorFlow version (use command below)**: v2.2.0-0-g2b96f3662b 2.2.0
-   **Python version**: 3.7
-   **CUDA/cuDNN version**: 10.1
-   **GPU model and memory**: Colab GPU

### Describe the problem
The implementation of repeat_elements behave differently whether the input tensor has static or dynamic shape.
For tensors with dynamic shape it does not accept negative indexing for the axis parameter.
For tensors with static shape it accepts negative indexing for the axis parameter.
TensorFlow follow standard python indexing rules. 
There is a workaround using positive indexing.

**How to reproduce**
Run the repeat_elements with axis=-1 and tf.config.experimental_run_functions_eagerly(False)
Note the resulting array
Run with tf.config.experimental_run_functions_eagerly(True)
Note the resulting array
Set axis=1 and repeat 1-4
Note that input_signature parameter in tf.function is there to reproduce a scenario of a graph with the tensor x with dynamic shape.

### Source code / logs

```
import tensorflow as tf
import tensorflow.keras.backend as K
import numpy as np
```
```
@tf.function(input_signature=[tf.TensorSpec(shape=[None, None], dtype=tf.int32)])
def f(x):
  x = K.repeat_elements(x, rep=3, axis=-1)
  return x

tf.config.experimental_run_functions_eagerly(True)
v = tf.Variable([[0, 1],[2, 3]])
f(v)
```
> <tf.Tensor: shape=(2, 6), dtype=int32, numpy=
> array([[0, 0, 0, 1, 1, 1],
>        [2, 2, 2, 3, 3, 3]], dtype=int32)>
```
@tf.function(input_signature=[tf.TensorSpec(shape=[None, None], dtype=tf.int32)])
def f(x):
  x = K.repeat_elements(x, rep=3, axis=-1)
  return x

tf.config.experimental_run_functions_eagerly(False)
v = tf.Variable([[0, 1],[2, 3]])
f(v)
```
> <tf.Tensor: shape=(2, 6), dtype=int32, numpy=
> array([[0, 1, 2, 3, 0, 1],
>        [2, 3, 0, 1, 2, 3]], dtype=int32)>"
40850,Resource Exhausted when re-training Half of Efficientnet b0 on V100 32GB.,"Hi All,
    i am experiencing a scenario where i can train anEfficientNetB0 ([efficientnet](https://github.com/qubvel/efficientnet)) with a batch size of 4 . when i cut the model at some layer and make a new (smaller) model out of it , the same training is throwing Resource Exhausted error . `

`Working implementation`

```
model_conv = efn.EfficientNetB0(weights='/work/source/pre_trained/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5',include_top=False,input_tensor=input_layer)
model = tf.keras.Sequential()
model.add(tf.keras.layers.TimeDistributed(model_conv, input_shape=(3, 1024,1024,3)))
model.add(tf.keras.layers.GlobalAveragePooling3D())
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(classes_n - 1))
model.add(tf.keras.layers.Activation('sigmoid', dtype='float32', name='predictions'))
```

`Not Working implementation`

```
input_layer = tf.keras.layers.Input(shape=(1024,1024,3))
model_conv = efn.EfficientNetB0(weights='/work/source/pre_trained/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5',
                                include_top=False,input_tensor=input_layer)

model_conv = tf.keras.Model(model_conv.input,model_conv.get_layer('block6d_add').output)
model_conv = tf.keras.models.load_model('./models_cut/effb0_5block.h5')
model = tf.keras.Sequential()
model.add(tf.keras.layers.TimeDistributed(model_conv, input_shape=(3, 1024,1024,3)))
model.add(tf.keras.layers.GlobalAveragePooling3D())
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(classes_n - 1))
model.add(tf.keras.layers.Activation('sigmoid', dtype='float32', name='predictions'))
```


Error
```
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[15,64,64,672] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]
```"
40847,Training has slowed down 46 times when fit on TF2.0 compared to TF1.15?,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux AMI 2018.03, rhel fedora
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA
- TensorFlow installed from (source or binary):I installed via pip install tensorflow==2.0.0
- TensorFlow version (use command below): 2.0.0 and 1.15.2
- Python version: 3.6.10 
- Bazel version (if compiling from source):NA
- GCC/Compiler version (if compiling from source):NA
- CUDA/cuDNN version: Cuda compilation tools: release 10.0, V10.0.130
- GPU model and memory: NVIDIA Corporation GV100GL [Tesla V100 SXM2 16GB] (rev a1)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I would like to serve my keras model with TensorFlow serving using a TensorFlow SavedModel format.  I was following TF's tutorial on how to do that at this link https://www.tensorflow.org/tfx/tutorials/serving/rest_simple.   I found out though that this requires TF2.x.  So I installed TF2.0.0 and tried to refit my model using all the same code.  However, the training time takes 46 times as long(=46 times more expensive) in TF2.0.0 as compared to TF1.15.2.  So I can't continue that path.   Obviously there have been some changes in TF2.0.0, suggesting I may need to change how I create models and fit them?  However, I don't know what I should do.
**Describe the expected behavior**
I expect that TF2.0.0 be able to fit models at speeds that are comparable to TF1.15.2
**Standalone code to reproduce the issue**
I don't know if you need to see all of the model (it is an encode-decode model for object detection).  Here is the troublesome bit and the output receive (in TF1.15.2 and TF2.0.0)
```
#create the model
model = Model(input_img,d1)

#review the model   
model.summary()

#Compile the model
model.compile(optimizer=optimizer,loss=theLoss,metrics =['accuracy'])

#save the only the best weights acheived during training
filepath='weights.best.hdf5'
checkpoint = ModelCheckpoint(filepath, monitor='val_acc',verbose=1,save_best_only=True,mode='max')
callbacks_list=[checkpoint]

y_train = to_categorical(y_train,num_classes=2)
X_train = X_train

#fit model
model.fit(X_train,y_train,validation_split=(0.15),epochs=1,batch_size=2,verbose=1,callbacks=callbacks_list,shuffle=True)
```
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Here is the logs for the fitting of the first epoch.  First in TF1.15 and then in TF2.0.0

TF1.15 (51 seconds per epoch)
`
Train on 850 samples, validate on 150 samples
848/850 [============================>.] - ETA: 0s - loss: 44.0265 - acc: 0.5417
Epoch 00001: val_acc improved from -inf to 0.97858, saving model to weights.best.hdf5
850/850 [==============================] - 50s 59ms/sample - loss: 44.0126 - acc: 0.5419 - val_loss: 37.6455 - val_acc: 0.9786
`

TF2.0 ( 2324 seconds per epoch.  Side note, TF2.0 skipped saving the best model weights using the checkpoint?)
`
Train on 850 samples, validate on 150 samples
848/850 [============================>.] - ETA: 5s - loss: 44.8913 - accuracy: 0.5424 WARNING:tensorflow:Can save best model only with val_acc available, skipping.
850/850 [==============================] - 2324s 3s/sample - loss: 44.8785 - accuracy: 0.5425 - val_loss: 41.7605 - val_accuracy: 0.0883
`
"
40845,third_party/flatbuffers references missing filemirror.tensorflow.org/https://github.com/google/flatbuffers/archive/a4b2884e4ed6116335d534af8f58a84678b74a17.zip,"**Describe the problem**
Some of our builds are failing (but the failure is not directly related to this missing file):
> WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/https://github.com/google/flatbuffers/archive/a4b2884e4ed6116335d534af8f58a84678b74a17.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found

The URL is from TensorFlow r2.2 https://github.com/tensorflow/tensorflow/blob/r2.2/third_party/flatbuffers/workspace.bzl#L11

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
$ wget ""https://storage.googleapis.com/mirror.tensorflow.org/https://github.com/google/flatbuffers/archive/a4b2884e4ed6116335d534af8f58a84678b74a17.zip""
--2020-06-26 20:59:28--  https://storage.googleapis.com/mirror.tensorflow.org/https://github.com/google/flatbuffers/archive/a4b2884e4ed6116335d534af8f58a84678b74a17.zip
Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:4007:815::2010, 216.58.213.176, 172.217.22.144, ...
Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:4007:815::2010|:443... connected.
HTTP request sent, awaiting response... 404 Not Found
2020-06-26 20:59:29 ERROR 404: Not Found.
```

However, the second URL is fine:
```
wget ""https://github.com/google/flatbuffers/archive/a4b2884e4ed6116335d534af8f58a84678b74a17.zip""
--2020-06-26 20:59:50--  https://github.com/google/flatbuffers/archive/a4b2884e4ed6116335d534af8f58a84678b74a17.zip
Resolving github.com (github.com)... 140.82.118.3
Connecting to github.com (github.com)|140.82.118.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://codeload.github.com/google/flatbuffers/zip/a4b2884e4ed6116335d534af8f58a84678b74a17 [following]
--2020-06-26 20:59:50--  https://codeload.github.com/google/flatbuffers/zip/a4b2884e4ed6116335d534af8f58a84678b74a17
Resolving codeload.github.com (codeload.github.com)... 140.82.112.10
Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: unspecified [application/zip]
Saving to: 'a4b2884e4ed6116335d534af8f58a84678b74a17.zip'

a4b2884e4ed6116335d534af8f58a84678b74a17.zip                                                              [   <=>                                                                                                                                                                                                                                                                   ] 564.91K   749KB/s               ^
```"
40844,Implementation of T-LSTM keras layer,"This is a feature request regarding the implementation of T-LSTM cells. This feature enables taking into account time within unevenly sampled data, like medical consulting, queue arrivals, traffic flow and so on.

References:
Paper: [Patient Subtyping via Time-Aware LSTM Networks](https://www.kdd.org/kdd2017/papers/view/patient-subtyping-via-time-aware-lstm-networks)
[Tensorflow implementation by the author](https://www.google.com/url?sa=t&source=web&rct=j&url=https://github.com/illidanlab/T-LSTM&ved=2ahUKEwiU2PS3lKDqAhVkGbkGHf9LDOwQFjAAegQIAxAB&usg=AOvVaw1hTrTDWbewgCVIfbk94_-j)"
40842,how can i run tensorflow in second gpu ,"I am tired to make TensorFlow 2.1 to work in the second , third, fourth GPU  
but every time TensorFlow uses the first GPU 
I have 4 GPU and I want to train 4 model each model in different GPU 

**System information**
- windows 10 x64 
- python 3.6 
- TensorFlow  2.1 
- nvcc: NVIDIA (R) Cuda compiler driver
 Copyright (c) 2005-2019 NVIDIA Corporation
 Built on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019
 Cuda compilation tools, release 10.1, V10.1.105
- GPU : Tesla K20Xm
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 441.22       Driver Version: 441.22       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K20Xm         TCC  | 00000000:03:00.0 Off |                    0 |
| N/A   29C    P8    18W / 235W |      9MiB /  5696MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K20Xm         TCC  | 00000000:04:00.0 Off |                    0 |
| N/A   26C    P8    18W / 235W |      9MiB /  5696MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K20Xm         TCC  | 00000000:83:00.0 Off |                    0 |
| N/A   22C    P8    18W / 235W |      9MiB /  5696MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K20Xm         TCC  | 00000000:84:00.0 Off |                  N/A |
| N/A   21C    P8    18W / 235W |      9MiB /  5696MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
I tired before run jupyter notebook write this command 
set CUDA_VISIBLE_DEVICES=0 & jupyter notebook
set CUDA_VISIBLE_DEVICES=1 & jupyter notebook
set CUDA_VISIBLE_DEVICES=2 & jupyter notebook
set CUDA_VISIBLE_DEVICES=3 & jupyter notebook
also inside jupyter  
import os
os.environ[""CUDA_VISIBLE_DEVICES""]=""1,2,3""
what is solution please ??
"
40840,Python3.9 support,"Has anyone tried to build tensorflow for Python3.9? For the assembly, everything seems to go fine, except for troubles with installing some pypi packages (Maybe there is a problem in Windows, installing using .wheel passes). Almost all the necessary packages are present except for grpcio. It turns out, we just need to wait until it appears."
40839,"tf.io.decode_image(img, channels=3) outputs 4 channels when reading 4-channel BMP","**EDIT:** attached a sample BMP file
[rgb32.zip](https://github.com/tensorflow/tensorflow/files/4845825/rgb32.zip)

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution: Windows 10
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version: 2.2.0
- Python version: 3.7.7

**Describe the current behavior**
When reading in a **4-channel BMP**:
- `tf.io.decode_image(img, channels=3)` gives shape **(..., ..., 4) instead of (..., ..., 3)**
- `tf.io.decode_bmp(img, channels=3)` gives the following error
```
Traceback (most recent call last):
  File ""channels.py"", line 44, in <module>
    loop()
  File ""channels.py"", line 14, in loop
    img = tf.io.decode_bmp(img, channels=3)
  File ""C:\Users\mattchee\Miniconda3\lib\site-packages\tensorflow\python\ops\gen_image_ops.py"", line 899, in decode_bmp
    _ops.raise_from_not_ok_status(e, name)
  File ""C:\Users\mattchee\Miniconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 6653, in raise_from_not_ok_status     
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: channels attribute 3 does not match bits per pixel from file 4 [Op:DecodeBmp]
```

I'm following [this guide](https://www.tensorflow.org/tutorials/load_data/images#load_using_tfdata) to load images efficiently so `tf.keras.preprocessing.image.load_img(img_path, color_mode=""rgb"")` is not an option.

**Describe the expected behavior**
This is inconsistent with `tf.io.decode_image(img, channels=3)` and `tf.io.decode_png(img, channels=3)` which give shape (..., ..., 3) when reading a 4-channel PNG.

Both `tf.io.decode_image(img, channels=3)` and `tf.io.decode_bmp(img, channels=3)` would be expected to give shape (..., ..., 3) when reading in a 4-channel BMP.

**Standalone code to reproduce the issue**
```python
img = tf.io.read_file(img_path)
img = tf.io.decode_image(img, channels=3)
print(img.shape) # This prints (64, 127, 4)
```
Or
```python
img = tf.io.read_file(img_path)
img = tf.io.decode_bmp(img, channels=3) # Error
print(img.shape)
```"
40838,issue with parallelizing dataset,"tensorflow version: '2.1.0'

I am trying the dataset pipeline from tensorflow web page: https://www.tensorflow.org/guide/data_performance. on P3.8x GPU, Amazon EC2.
it is mentioned that using
```
benchmark(
    tf.data.Dataset.range(2)
    .interleave(ArtificialDataset)
)
```
we can parallelize dataset, however I get a total different behavior.
I increased the num_samples in given ArtificialDataset to 1000, and changed the benchmark to print the sample
```
def benchmark(dataset, num_epochs=1):
         start_time = time.perf_counter()
         for epoch_num in range(num_epochs):
             for sample in dataset:
                 # Performing a training step
                 tf. print(sample)
                 time.sleep(0.01)
         tf.print(""Execution time:"", time.perf_counter() - start_time)
```
and when I run
```
benchmark(
         tf.data.Dataset.range(2)
         .interleave(ArtificialDataset)
     )
```
I get
```
[0]
Execution time: 0.10175556794274598
```
for 
```
benchmark(
         tf.data.Dataset.range(4)
         .interleave(ArtificialDataset)
     )
```
I get
```
[0]
[0]
[0]
[1]
[1]
[2]
Execution time: 0.29265988897532225
```
which means it doesn't go through the whole dataset. what I am expecting based on documentation is that it should open up 2 datasets, each with 1000 samples and in parallel generates the numbers. if not how can I get this functionality using this dataset API?



"
40837,"""12 bytes lost due to alignment ..."" error on magic_wand example for SparkFun Edge","@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OSX Catalina (10.15.5)
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): 44f2f014e5d84e195af7de6f9d9400df3d3a00dd
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): SparkFun Edge

**Describe the problem**
Cannot view/display any debug information from UART output but receive an error instead, using screen command: 

`screen ${DEVICENAME} 115200 `

I also tried to explicitly substitute the actual device name, but I get the same error result. I only get this single line of output, indicating something is wrong:

`12 bytes lost due to alignment. To avoid this loss, please make sure the tensor_arena is 16 bytes aligned.`

Note: I have followed this same sequence (and settings) on other examples for SparkFun Edge (**Hello World** and **Person Detection**) and for both of those builds, I do get proper/expected UART debug output using screen, so this error seems specific to the magic_wand example.

Every time I then reset the board, I get this same error repeated in screen.

**Please provide the exact sequence of commands/steps when you ran into the problem**
I followed the readme instructions for the example exactly:
tensorflow/lite/micro/examples/magic_wand/README.md, under the ""Deploy to SparkFun Edge"", Specifically, from the root directory cloned from GitHub, I executed these commands:

```
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge magic_wand_bin

cp tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/tools/apollo3_scripts/keys_info0.py \
tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/tools/apollo3_scripts/keys_info.py

python3 tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/tools/apollo3_scripts/create_cust_image_blob.py \
--bin tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/magic_wand.bin \
--load-address 0xC000 \
--magic-num 0xCB \
-o main_nonsecure_ota \
--version 0x0

python3 tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/tools/apollo3_scripts/create_cust_wireupdate_blob.py \
--load-address 0x20000 \
--bin main_nonsecure_ota.bin \
-i 6 \
-o main_nonsecure_wire \
--options 0x1

export BAUD_RATE=921600
export DEVICENAME=/dev/tty.usbserial-A50285BI
```
and then flash the binary using the boatload button sequence as described while executing this command:

```
python3 tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/tools/apollo3_scripts/uart_wired_update.py \
-b ${BAUD_RATE} ${DEVICENAME} \
-r 1 \
-f main_nonsecure_wire.bin \
-i 6
```

All commands seem to execute correctly, no errors displayed, and boatload process is successful. After hitting the board reset button, I get the yellow light blinking rapidly after a few seconds (I assume it is working at this point). Then, using the screen command to view UART output, I get the above error instead of the expected output of ""Magic Starts!"".
"
40836,[TF 2.3.0] [Intel MKL] OMP Threads are created with variable number when we compile with XLA flag ON,"Attn: @penpornk 
### **Issue:**
**_The number of OMP thread created varies for the same model across multiple runs._**

**_This also causes varied performance across multiple runs for the same model on same platform with same setting/tuning parameters._**

### **Issue Detailed:**
With options: **_--data-num-inter-threads=1 --data-num-intra-threads=28 --socket-id=0_**
When running benchmarks for RN50 inference on master branch(HEAD) with OMP_NUM_THREADS set to 28:  

We notice threads being created to be - 156 threads . **_(Incorrect)_**
Using May 24th commit sha: (fbc4da8201f5c3acecb998854d087c663f1f5cd8) - 28 threads are created **_(correct)_**

### **Observation:**
**_Disabling the XLA compile flag_** by setting TF_ENABLE_XLA=0 **_creates the proper number of 28 threads_** in current master (HEAD). **_(Correct)_**

### **_How to Reproduce:_**
Run resnet_50_v1.5 inference with XLA on the latest master
https://github.com/IntelAI/models/blob/master/benchmarks/image_recognition/tensorflow/resnet50v1_5/README.md#fp32-inference-instructions
"
40834,class_weight based on predicted labels rather than true labels,"**System information**
- TensorFlow version (you are using): tensorflow 2.0
- Are you willing to contribute it (Yes/No): No, I am currently unable to do so.



**Describe the feature and the current behavior/state.**

Let's stick to a two-class classification problem as an example to keep things simple so we can borrow concepts from the confusion matrix.

So I assume (since this doesn't seem to be documented) that class_weight weighs based on the true labels.
If this is the case then this would allow us to increase the recall of our model, as doing so puts more emphasis on true positives and false negatives.

But what if we want to increase precision instead? We should be able to do so by weighing classes based on the predicted labels instead, as this would put more emphasis on true positives and false positives instead. 

**Will this change the current api? How?**

This could be done by creating an extra parameter for the fit function called ""predicted_class_weight"".
Then to avoid confusion the old ""class_weight"" should be renamed to ""true_class_weight"".

**Who will benefit with this feature?**

One of the biggest drawbacks of the Keras API in its current state is that it's seemingly impossible to put emphasis on precision rather than recall.

There are numerous classification problems that require precision over recall. So this would benefit a lot of data scientists.

**Any Other info.**

/"
40832,XLA throws an error when beta1 = 0 in Adam optimizer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7
- CUDA/cuDNN version: 7.6
- GPU model and memory: GTX 1070


**Describe the current behavior**
Throws an error when beta1 = 0.

**Describe the expected behavior**
No errors.

**Standalone code to reproduce the issue**
https://colab.research.google.com/gist/fengyang0317/26486c2740955cff9c88f7d02e9832a0/use-xla-with-tf-function.ipynb
"
40831,Post-training quantization,"Hi everyone,

I've recently worked with the 2 models: ""conv"" and ""low_latency_conv"" of the speech_commands example.
```
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/speech_commands
```
I succeed to obtain respectively, 88% and 81% of testing accuracy.
I'd like to use a quantization of int16 (int8 will be just as good), but I can't because of the tf.contrib.quantize function which is deprecated in tf2.0. It advises me to install tf1.15, unfortunately, I'm not allowed to install it.

I've tried this solution which seems interesting:
```
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_quant_model = converter.convert()
```

With a pbtxt saved model, the ""from_saved_model"" function crash with the error :
```
OSError: Cannot parse file saved_model.pbtxt': 1:1 : Message type ""tensorflow.SavedModel"" has no field named ""node""..
```
And when I convert it to a frozen model (with freeze.py) to have a ""save_model.pb"", it crashes in""converter.convert()""
with the error:
```
""ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.""
```

Has anyone found a way to quantize it ?

P.S.: In the description of the create_conv_model function (in models.py), I think the second layer [MaxPool] is missing in the code.

**System information**
- Windows 7
- TensorFlow 2.1.0
"
40830,The tenorflow_framework shared object contains public HWLOC symbols. which causes HWLOC unexpected behavior it links dynamically with some other library.,"**System information**
- Have I written custom code: No
- OS Platform and Distribution: Ubuntu 16.04, Fedora 30 (and possibly any other Linux)
- TensorFlow installed from: C binary package (libtensorflow-cpu-linux-x86_64-1.14.0.tar.gz)
- TensorFlow version (use command below): 1.14.0
- Python version: Not applicable

**Describe the current behavior**

When I run `nm libtensorflow_framework.so.1.14.0 | grep T | grep hwloc` on Linux, I get the following output:

```
...
00000000012d9fc0 T hwloc_bitmap_copy
00000000012d9fb0 T hwloc_bitmap_dup
00000000012da6e0 T hwloc_bitmap_fill
00000000012dbc20 T hwloc_bitmap_first
00000000012dbc90 T hwloc_bitmap_first_unset
00000000012d9ea0 T hwloc_bitmap_free
...
00000000012e78a0 T hwloc_topology_insert_group_object
00000000012e7a50 T hwloc_topology_insert_misc_object
00000000012e7110 T hwloc_topology_is_thissystem
00000000012e7b00 T hwloc_topology_load
00000000012e5bf0 T hwloc_topology_reconnect
00000000012e8330 T hwloc_topology_restrict
...
```
And many other publicly available HWLOC interfaces that are included in` tenorflow_framework.so` as public symbols.

So when some application linked with TensorFlow and some other library that dynamically links with HWLOC, then part of HWLOC interfaces calls located inside `libhwloc.so` but other interfaces located inside `tensorflow_framework.so` shared object. 

Libraries dependencies structure:

![tensorflow+hwloc](https://user-images.githubusercontent.com/22097249/85857265-2de8ee80-b7c2-11ea-823e-600e2840f4e6.png)

For example, when the library(""Some Lib"" on the scheme) call `hwloc_topology_init` then it goes to the HWLOC library located inside `tensorflow_framework.so`. But when it calls the `hwloc_topology_get_complete_cpuset` method, then it goes to the shared HWLOC library. This means that we have two instances of HWLOC library which are divided between two shared objects.

This situation causes HWLOC unexpected behavior inside other libraries (e.g. the ""Some Lib"" library on the scheme).

**Describe the expected behavior**

The expected behavior is to not deliver any HWLOC interfaces as part of public interface of the TensorFlow shared object.

**Standalone code to reproduce the issue:**

To reproduce this issue, we need at least two source code files: for the application and for the library.

some_lib.cpp:
```c++
#include <iostream>
#include <hwloc.h>

void print_bitmap(hwloc_const_bitmap_t bitmap) {
    if (bitmap == NULL) {
        printf(""mask is: NULL\n"");
        return;
    }
    char* buf = new char[256];
    hwloc_bitmap_snprintf(buf, 256, bitmap);
    printf(""mask is: %s\n"", buf);
    delete [] buf;
}

extern void print_topology_info() {
    hwloc_topology_t topology;
    hwloc_cpuset_t   process_cpu_affinity_mask;
    hwloc_nodeset_t  process_node_affinity_mask;

    // Parse topology
    hwloc_topology_init( &topology );
    hwloc_topology_load( topology );

    // Getting process affinity mask
    process_cpu_affinity_mask  = hwloc_bitmap_alloc();
    process_node_affinity_mask = hwloc_bitmap_alloc();

    hwloc_get_cpubind(topology, process_cpu_affinity_mask, 0);
    hwloc_cpuset_to_nodeset(topology, process_cpu_affinity_mask, process_node_affinity_mask);

    print_bitmap(process_cpu_affinity_mask);
    print_bitmap(process_node_affinity_mask);
    printf(""Complete:\n"");
    print_bitmap(hwloc_topology_get_complete_cpuset(topology));
    print_bitmap(hwloc_topology_get_complete_nodeset(topology));
    printf(""Allowed:\n"");
    print_bitmap(hwloc_topology_get_allowed_cpuset(topology));
    print_bitmap(hwloc_topology_get_allowed_nodeset(topology));
}
```

application.cpp:
```
#include <iostream>

extern void print_topology_info();

int main() {
    print_topology_info();
}
```

Build steps:
```
# another compiler is also applicable
g++ -c -fpic some_lib.cpp
g++ -shared -o some_lib.so some_lib.o -lhwloc

g++ application.cpp -o some_app -ltensorflow some_lib.so
```
Output:
```
mask is: 0x000000ff
mask is: 0x0
Complete:
mask is: NULL
mask is: 0x00000001
Allowed:
mask is: 0x000000ff
mask is: 0x00000001
```

Expected output:
```
mask is: 0x000000ff
mask is: 0xf...f
Complete:
mask is: 0x000000ff
mask is: 0xf...f
Allowed:
mask is: 0x000000ff
mask is: 0xf...f
```

**Other info/logs** :

Proofs of different HWLOC interfaces location:

Here is some information that was obtained via GDB during application debugging:

Shared objects location:
```
0x00007fffecdf1430  0x00007fffece1869a - tbbbind -> hwloc
0x00007fffed750e80  0x00007fffee5971b4 - libtensorflow_framework.so.1 (static hwloc)
```
Method addresses (can be easily correlated with corresponding shared object):
```
0x7fffecdf66a0 <hwloc_topology_init> - tbbbind -> hwloc
0x7fffecdf80c0 <hwloc_topology_load> - tbbbind -> hwloc
0x7fffecdfe2a0 <hwloc_get_cpubind>   - tbbbind -> hwloc
0x7fffeef4d6c8 <hwloc_cpuset_to_nodeset(hwloc_topology_t, hwloc_const_cpuset_t, hwloc_nodeset_t)> - libtensorflow_framework.so.1 (static hwloc)
0x7fffeef4d644 <hwloc_topology_get_complete_cpuset(hwloc_topology_t)> - libtensorflow_framework.so.1 (static hwloc)
0x7fffeef4d686 <hwloc_topology_get_complete_nodeset(hwloc_topology_t)> - libtensorflow_framework.so.1 (static hwloc)
0x7fffeef4d665 <hwloc_topology_get_allowed_cpuset(hwloc_topology_t)> - libtensorflow_framework.so.1 (static hwloc)
0x7fffeef4d6a7 <hwloc_topology_get_allowed_nodeset(hwloc_topology_t)> - libtensorflow_framework.so.1 (static hwloc)
```

**Workaround:**
Add `-lhwloc` flag to application compilation string to directly link the HWLOC shared object. After this change, all HWLOC interfaces will be located within the HWLOC shared object.
"
40829,Different depth wise convolution for different images in the batch,"Hello, I have a situation where I want to apply different depth wise convolutions to different image in a samples batch.
Lets say I have a batch of N images of shape (H x W x C) and N depthwise conv2d filter of shape (K x K x C x 1) I want to apply each one of these N convolutions to each one of the images. Normally, we can do this with tf.unstack along axis 0 on the batch of image and the convolution kernels volume and then process each of images apart using tf.nn.deptwise_conv2d and use tf.concat to build the final result. However, I can't do this cause N is the batch size inside a kerase layer so its value is unkown before compiling the model. Can you suggest a solution or make a version of tf.nn.deptwise_conv2d that supports seperate convolution kernels for separate images?"
40827,Incorrect TF nightly version,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version: 2.3
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
`pip install tf-nightly` installs TF v2.5. Shouldn't it be TF v2.3???

PyPI link - https://pypi.org/project/tf-nightly-gpu/2.5.0.dev20200626/

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
import tensorflow as tf
print(tf.__version__)
```
**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40826,"Invalid argument: Input to reshape is a tensor with 4300800 values, but the requested shape has 19268370432","Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 2.2.0
Python version: 3.8
Bazel version (if compiling from source): 2.0
GCC/Compiler version (if compiling from source): 9.3.0
CUDA/cuDNN version:
GPU model and memory: Radeon VII

Hi,

I am using bert-for-tf2 over tensorflow 2.2.0,  keras 2.4.3, and the AMD rocm 3.5.1 environment, and sometimes I get an error like the following one:

File ""bert-decept.py"", line 543, in
history = fit_model(model, data, BATCH_SIZE, EPOCHS, tensorboard_callback, model_checkpoint_callback,
File ""bert-decept.py"", line 438, in fit_model
history = model.fit(
File ""/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py"", line 766, in fit
return func.fit(
File ""/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 649, in fit
return fit_loop(
File ""/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 386, in model_iteration
batch_outs = f(ins_batch)
File ""/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py"", line 3631, in call
fetched = self._callable_fn(*array_vals,
File ""/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py"", line 1470, in call
ret = tf_session.TF_SessionRunCallable(self._session._session,
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
(0) Invalid argument: Input to reshape is a tensor with 4300800 values, but the requested shape has 19268370432
[[{{node bert_1/encoder/layer_7/attention/self/query/Tensordot}}]]
[[Func/training_2/AdamW/gradients/gradients/bert_1/encoder/layer_7/output/dropout_62/cond_grad/StatelessIf/then/_11515/input/_23174/_9837]]
(1) Invalid argument: Input to reshape is a tensor with 4300800 values, but the requested shape has 19268370432
[[{{node bert_1/encoder/layer_7/attention/self/query/Tensordot}}]]
0 successful operations.
0 derived errors ignored.

or

File ""bert-decept.py"", line 543, in
history = fit_model(model, data, BATCH_SIZE, EPOCHS, tensorboard_callback, model_checkpoint_callback,
File ""bert-decept.py"", line 438, in fit_model
history = model.fit(
File ""/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py"", line 766, in fit
return func.fit(
File ""/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 649, in fit
return fit_loop(
File ""/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 386, in model_iteration
batch_outs = f(ins_batch)
File ""/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py"", line 3631, in call
fetched = self._callable_fn(*array_vals,
File ""/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py"", line 1470, in call
ret = tf_session.TF_SessionRunCallable(self._session._session,
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
(0) Invalid argument: Size 0 must be non-negative, not -1737945760
[[{{node bert/encoder/layer_5/attention/self/query/Tensordot/Reshape}}]]
[[Func/training/AdamW/gradients/gradients/bert/encoder/layer_9/output/dropout_30/cond_grad/StatelessIf/then/_696/input/_2295/_3389]]
(1) Invalid argument: Size 0 must be non-negative, not -1737945760
[[{{node bert/encoder/layer_5/attention/self/query/Tensordot/Reshape}}]]

At least in my non-experienced eyes it seems like an invalid pointer reference. The error does not happen for the CPU backend. Does anyone have any idea/insight about what might be the problem? Is there any other information that I could probably provide to solve this? I have also reported this in the rocm tensorflow repo https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/issues/1026

Best regards
Panagiotis"
40825,Quantized tflite model's inference slower than the un-quantized tflite model on Raspberry Pi,"**Issue** 
I have two keras models, named as model1.h5 and model2.h5.

- They are converted into tflite model, named as model1.tflite and model2.tflite through code:

```
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
```

- They are quantized and converted into tflite model, named as quanmodel1.tflite and quanmodel2.tflite through code:
```
converter = tf.lite.TFLiteConverter.from_keras_model(model) 
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_quant_model = converter.convert()
```
When I run the four tflite models on Raspberry Pi for inference, I find the inference speed per image (listed below) is strange:

- model1.tflite (model size 240 KB) -- 0.1s;
- quanmodel1.tflite (model size 68KB) -- 0.2s;
- model2.tflite (model size 1990 KB) -- 0.17s;
- quanmodel2.tflite (model size 514 KB) -- 0.1s.

Why the inference speed of model1.tflite is faster than that of quantized model (quanmodel1.tflite) while model2.tflite is slower than that of quanmodel2.tflite?"
40824,Saver not created because there are no variables in the graph to restore,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10
- TensorFlow installed from (source or binary):source
- TensorFlow version (use command below): 2.2.0
- Python version: 3.74
- GPU model and memory: Intel(R) HD Graphics 530

I write in C# and use ML.net but the error comes from Tensorflow library.
While trying to Fit the model
`ITransformer model = trainingPipeline.Fit(trainingDataView);
`
 it gives following error:
Saver not created because there are no variables in the graph to restore"
40823,Dot model generation not working when input_shape is not specified (Maybe just missing error message) ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.4 / 20.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2.0
- Python version: 3.8.2


**Current behavior**

When using an arbitrary network architecture but without **input_shape** being defined in the first layer, the `plot_model` and `model_to_dot` functions do not work properly (at least from my point of view). The dot model returned only contains a node for the model name (_sequential_ in this case), the saved image only contains this _sequential_-node as well. 

![image](https://user-images.githubusercontent.com/23249088/85840675-324ee080-b79d-11ea-9141-e3051175a657.png)


**Describe the expected behavior**

Using Python 3.7 with Keras (2.3.1) and Tensorflow (2.1.0) the functions would generate the model without specifying an input shape. With Tensorflow 2.2 this behavior broke.

Since the input_shape is an optional parameter this should not happen without throwing an error/exception in my opinion. If this is a desired behavior then I would at least expect an error message which would tell me that an input shape is missing. 

But if the model builds and trains without the input shape, then it should also be convertible to a dot format or image.


**Standalone code to reproduce the issue**

```
from keras.utils import plot_model
from keras.models import Sequential
from keras.layers import Conv2D

model = Sequential()

# Does not work
model.add(Conv2D(32, (3, 3), padding=""same"", activation=""relu""))

# Works
# model.add(Conv2D(32, (3, 3), input_shape=(1, 100, 100), padding=""same"", activation=""relu""))

plot_model(model, 'model.png')
```

**Output of model to dot**

Not working:

digraph G {
concentrate=True;
dpi=96;
rankdir=TB;
node [shape=record];
140054209647712 [label=sequential];
}

Working:

digraph G {
concentrate=True;
dpi=96;
rankdir=TB;
node [shape=record];
139879434642768 [label=""conv2d_input: InputLayer""];
139879443480480 [label=""conv2d: Conv2D""];
139879434642768 -> 139879443480480;
}"
41802,Process finished with exit code 139 (interrupted by signal 11: SIGSEGV),"```
import os
import zipfile
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator

print(tf.__version__)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
path ='/media/jake/mark-4tb3/input/datasets/cats_and_dogs_filtered/'

train_dir = os.path.join(path + 'train')
validation_dir = os.path.join(path + 'validation')
base_dir = path + 'cats_and_dogs_filtered/'
# Directory with our training cat pictures
train_cats_dir = os.path.join(train_dir, 'cats')
train_dogs_dir = os.path.join(validation_dir,'dogs')
validation_cats_dir = os.path.join(validation_dir,'cats')
validation_dogs_dir = os.path.join(validation_dir,'dogs')


model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])


model.compile(loss='binary_crossentropy',
              optimizer=RMSprop(lr=1e-4),
              metrics=['accuracy'])

# All images will be rescaled by 1./255
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Flow training images in batches of 20 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
        train_dir,  # This is the source directory for training images
        target_size=(150, 150),  # All images will be resized to 150x150
        batch_size=20,
        # Since we use binary_crossentropy loss, we need binary labels
        class_mode='binary')

# Flow validation images in batches of 20 using test_datagen generator
validation_generator = test_datagen.flow_from_directory(
        validation_dir,
        target_size=(150, 150),
        batch_size=10,
        class_mode='binary')

history = model.fit(
      train_generator,
      steps_per_epoch=100,  # 2000 images = batch_size * steps
      epochs=100,
      validation_data=validation_generator,
      validation_steps=10,  # 1000 images = batch_size * steps
      verbose=2)
print('start')
import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()
```

Python Version : 3.7.3
Tensorflow Version : 2.0-gpu 
OS: Ubuntu 19.10
cuda-version :10.2 


`Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)
`


=====================================
jupyer lab error message

```
 23:09:35.676 LabApp] Starting buffering for 9f1747f3-2ef3-4674-9138-d24f57c4c2a5:5200ed2a-c87d-480b-b325-a681221a239d
2020-06-26 23:09:38.208214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-26 23:09:38.286106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:0b:00.0
2020-06-26 23:09:38.286735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:42:00.0
2020-06-26 23:09:38.286880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-06-26 23:09:38.287654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-06-26 23:09:38.287729: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64
2020-06-26 23:09:38.287777: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64
2020-06-26 23:09:38.287821: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64
2020-06-26 23:09:38.287863: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64
2020-06-26 23:09:38.290019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-26 23:09:38.290041: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-06-26 23:09:45.449530: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-26 23:09:45.473556: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3492915000 Hz
2020-06-26 23:09:45.474671: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4dc7330 executing computations on platform Host. Devices:
2020-06-26 23:09:45.474700: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2020-06-26 23:09:45.661486: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4def5d0 executing computations on platform CUDA. Devices:
2020-06-26 23:09:45.661527: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2020-06-26 23:09:45.661537: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2020-06-26 23:09:45.661754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-26 23:09:45.661774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      
[I 23:09:50.294 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 9f1747f3-2ef3-4674-9138-d24f57c4c2a5 restarted
```
"
40822,Not able to install tensorflow through pip,"
![issue](https://user-images.githubusercontent.com/45734921/85836310-00537380-b7c9-11ea-818e-d678d1534409.png)


- OS Platform and Distribution : win 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version: 2.2
- Python version: 3.7
- Installed using : pip with no virtual env


So I tried to install tensorflow >= 2.0.0 with pip and no virtual env, but it always says ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none) and ERROR: No matching distribution found for tensorflow. Can anyone help me with it? Thanks.

"
40821,Tensorflow-Lite for Flutter,"There is only one plugin of Flutter which is not official.
Any plan to make a plugin for Flutter ?"
40820,How can I enable aws during running configure?,"@tensorflower-gardener @gunan 
Environment:
Ubuntu 16.04
python 3.6
bazel 0.26.0

I built tensorflow 1.14 from source. I want to enable aws, but I did not find anyway.
How can I enable it?"
40819,Installation error,"After installing tensorflow-gpu=2.0.0, ""import tensorflow as tf"" reports an error
AttributeError: module 'tensorflow' has no attribute 'compat'

How to deal with it?"
40818,Tensorflow models getting lag on safari-12 and safari-13 (Iphone5 to Iphone 8 and MAC IOS 12),"Hello,

We ran the web-version of tensor-flow models([facemesh](https://github.com/tensorflow/tfjs-models/tree/master/facemesh)) on safari-12/safari-13 version on different devices like iphon5 to iphone8 and MAC(IOS12).


But the model's inferences getting slowed down and facing lag on these devices.

Please suggest me any improvement can be done on this platforms (like safari-12/13 and iphone5 to iphone 8 and MAC IOS-12).

 "
40816,tensorflow 2.0 got following messages,"tensorflow 2.0 


2.2.0

```
2020-06-26 12:33:16.881206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-26 12:33:16.915893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:0b:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-06-26 12:33:16.916635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: 
pciBusID: 0000:42:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-06-26 12:33:16.916743: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-06-26 12:33:16.916777: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory
2020-06-26 12:33:16.916811: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory
2020-06-26 12:33:16.916842: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory
2020-06-26 12:33:16.916874: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory
2020-06-26 12:33:16.916904: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory
2020-06-26 12:33:16.918834: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-26 12:33:16.918850: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-06-26 12:33:16.919060: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-26 12:33:16.942414: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3493110000 Hz
2020-06-26 12:33:16.943646: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf28000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-26 12:33:16.943667: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-26 12:33:16.945443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-26 12:33:16.945458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      
Found 2000 images belonging to 2 classes.

Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)
```"
40815,Segmentation fault when using my own tflite-model for example projects during tests,"@tensorflow/micro

**Short version of the question:**
My problem is, that when I try to run a test from **any example project with my own tflite-model, than I always get a segmentation fault**. I'm training the tflite-model in Google colab. After that, I download the tflite-model convert it to a ...model.cc and run ""test_example_project_test"". And like I said, for my own tflite-models I get a segmentation fault if I use other tflite-models (from other projects, just for testing) than I don't get a segmentation fault. I don't know what causes this problem as I'm using exactly the same model-structure than in the hello_world_example Google Colab script, but with my own dataset.



**Long version of the question:**
**System information**
- Host OS Platform and Distribution: **Linux Ubuntu 18.04**
- TensorFlow installed from (source or binary):
- Tensorflow version: **2.2.0**
- Target platform: **Arm Mbed OS**
- Launch pad: **Disco-F746NG + CAM-Shield**

**Describe the problem**

Hi. After following the tutorials with success, I'm trying now to build my own small TensorFlow Lite project.
For achieving this, I use the ""image_recognition_experimental"" example as template.
I renamed the copied template folder to my own project as ""image_recognition"" and changed all source files, header files and the Makefile.inc accordingly.
The problem is now, that when I want to run the test by entering: ""sudo make -f tensorflow/lite/micro/tools/make/Makefile test_image_recognition_test"" **with my own tflite-model** then I always get a segmentation fault.
I tried a lot of different things (as described below) to find out what causes this problem, but I wasn't able to find it out.
That's why I'm asking you guys if you can help me identifying the problem?

**Please provide the exact sequence of commands/steps when you ran into the problem**

**1. Step:**
I copied the folder ""image_recognition_experimental"" in the path ""/home/tensorflow/tensorflow/lite/micro/examples"" and gave it the name ""image_recognition""

**2. Step:**
I changed the #include directives in the source and header files accordingly. For example:
This: `#include ""tensorflow/lite/micro/examples/image_recognition_experimental/util.h""`
was changed to this: `#include ""tensorflow/lite/micro/examples/image_recognition/util.h""`
What was of course pretty straightforward.

**3. Step:**
I changed the Makefile.inc similar to before by adapting the paths, but I also deleted the ""download model"" instruction and inserted the path to the model instead.
Here is the resulting content of Makefile.inc:
```


IMAGE_RECOGNITION_HDRS := \
tensorflow/lite/micro/examples/image_recognition/image_recognition_model.h \
tensorflow/lite/micro/examples/image_recognition/image_provider.h \
tensorflow/lite/micro/examples/image_recognition/stm32f746_discovery/image_util.h \
tensorflow/lite/micro/examples/image_recognition/stm32f746_discovery/display_util.h \
tensorflow/lite/micro/examples/image_recognition/util.h

IMAGE_RECOGNITION_SRCS := \
tensorflow/lite/micro/examples/image_recognition/image_recognition_model.cc \
tensorflow/lite/micro/examples/image_recognition/main.cc \
tensorflow/lite/micro/examples/image_recognition/stm32f746_discovery/image_provider.cc \
tensorflow/lite/micro/examples/image_recognition/stm32f746_discovery/image_util.cc \
tensorflow/lite/micro/examples/image_recognition/stm32f746_discovery/display_util.cc

IMAGE_RECOGNITION_TEST_SRCS := \
tensorflow/lite/micro/examples/image_recognition/image_recognition_test.cc \
tensorflow/lite/micro/examples/image_recognition/image_recognition_model.cc

IMAGE_RECOGNITION_TEST_HDRS := \
tensorflow/lite/micro/examples/image_recognition/image_recognition_model.h \
tensorflow/lite/micro/examples/image_recognition/util.h

include $(wildcard tensorflow/lite/micro/examples/image_recognition/*/Makefile.inc)

ifneq ($(filter disco_f746ng,$(ALL_TAGS)),)
  MBED_PROJECT_FILES += \
    BSP_DISCO_F746NG.lib \
    LCD_DISCO_F746NG.lib
endif

$(eval $(call microlite_test,image_recognition,\
$(IMAGE_RECOGNITION_SRCS),$(IMAGE_RECOGNITION_HDRS)))

$(eval $(call microlite_test,image_recognition_test,\
$(IMAGE_RECOGNITION_TEST_SRCS),$(IMAGE_RECOGNITION_TEST_HDRS)))
```

**4. Step:**
I copied the model with the filename ""image_recognition_model.cc"" (which was downloaded before) from ""tensorflow/lite/micro/tools/make/downloads/image_recognition_model/"" into the project path ""tensorflow/lite/micro/examples/image_recognition"".
 
**5. Step:**
I ran the test by entering: ""sudo make -f tensorflow/lite/micro/tools/make/Makefile test_image_recognition_test"".
It worked.

**6. Step**
Now I used my own model (which is not really useful for solving a task, I only wanted to load it into the interpreter). For making it usable, I deleted the old image_recognition_model.cc and gave my model this name. Then I inserted the header-file and adapted the data-types and so on. But when I now enter: ""sudo make -f tensorflow/lite/micro/tools/make/Makefile test_image_recognition_test"", 
I always get the following result:
```
tensorflow/lite/micro/tools/make/Makefile:297: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/ruy'
tensorflow/lite/micro/tools/make/Makefile:297: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/ruy'
tensorflow/lite/micro/tools/make/Makefile:297: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_grayscale'
tensorflow/lite/micro/tools/make/Makefile:297: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_grayscale'
tensorflow/lite/micro/testing/test_linux_binary.sh tensorflow/lite/micro/tools/make/gen/linux_x86_64/bin/image_recognition_test '~~~ALL TESTS PASSED~~~'
Segmentation fault (core dumped)
tensorflow/lite/micro/examples/image_recognition/Makefile.inc:34: recipe for target 'test_image_recognition_test' failed
make: *** [test_image_recognition_test] Error 139
```

**7. Step:**
Now I played around and tried several things:
- I increased `const int tensor_arena_size = 50 * 1024;` in image_recognition_test.cc to 500 * 1024 -> still segmentation fault
- I used all_ops_resolver instead of micro_ops_resolver -> still segmentation fault
- I copied the model from the hello_world example and renamed it to ""image_recogniton_model"" and adapted it -> it worked, **no** segmentation fault
- So I thought maybe it's my TensorFlow Python code and I copied the code for the hello_world-model from: https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/train/train_hello_world_model.ipynb#scrollTo=cr1VLfotanf6 and build a similar model with the same instructions but for my own data -> still segmentation fault
- So I thought maybe I do something wrong by converting the tf-model to a tf-lite model. So I ran the colab research hello_world model training, downloaded the tf-lite model, converted it to a cc-file by xxd and ran again the test. -> it worked, **no** segmentation fault.

--> So here I am, totally confused and not knowing why I always get segmentation faults for my own models. The only difference between my code and the example code for the hello-world-model-training is that my datasets are arranged differently.
Below is my Python code for creating the tf-lite model (I'm not only a TensorFlow Lite noob, I'm also a TensorFlow noob as well, learned everything from the official tutorials and the TinyML book)


```
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
from tensorflow import keras

AUTOTUNE = tf.data.experimental.AUTOTUNE

import IPython.display as display
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import os
from os import walk


import pathlib
tf.__version__

from google.colab import drive
drive.mount('/content/gdrive')

# here is some code for getting the file names and creating labels. It's long and messy so I censored it
# there are only two labels, a 1 means object and a 0 means not an object
# ...

objectDataset = tf.data.Dataset.from_tensor_slices((objectFilenames, objectLabels))
notObjectDataset = tf.data.Dataset.from_tensor_slices((notObjectFilenames, notObjectLabels))

dataset = objectDataset.concatenate(notObjectDataset)

dataset = dataset.shuffle(18138)

def _parse_function(filename, label):
    image_string = tf.io.read_file(filename)
    image_decoded = tf.image.decode_jpeg(image_string, channels=3)
    image = tf.cast(image_decoded, tf.float32)
    resized_image = tf.image.resize(image, [32, 32])
    grayscale_image = tf.image.rgb_to_grayscale(resized_image)
    return grayscale_image, label


dataset = dataset.map(_parse_function)
dataset = dataset.batch(1)

datasetSize = tf.data.experimental.cardinality(dataset).numpy()

trainSize = int(0.7 * datasetSize)
testSize = int(0.15 * datasetSize)
valSize = int(0.15 * datasetSize)

trainDataset = dataset.take(trainSize)
testDataset = dataset.skip(trainSize)
valDataset = dataset.skip(trainSize)

testDataset = dataset.take(testSize)
valDataset = dataset.skip(testSize)
valDataset = dataset.take(valSize) 


print(tf.data.experimental.cardinality(trainDataset).numpy())
print(tf.data.experimental.cardinality(testDataset).numpy())
print(tf.data.experimental.cardinality(valDataset).numpy())



# The following code is copied from train_hello_world_model 
# I know that it doesn't make sense like this with my dataset now, I only want a proof-of-concept)

model = tf.keras.Sequential()

# First layer takes a scalar input and feeds it through 16 ""neurons"". The
# neurons decide whether to activate based on the 'relu' activation function.
model.add(tf.keras.layers.Dense(1024, activation='relu', input_shape=(32,32,1)))

# The new second layer may help the network learn more complex representations
model.add(tf.keras.layers.Dense(2, activation='relu'))

# Final layer is a single neuron, since we want to output a single value
model.add(tf.keras.layers.Dense(2))

# Compile the model using a standard optimizer and loss function for regression
model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])

model.summary()

history = model.fit(trainDataset, epochs=1, batch_size=64,
                    validation_data=(ValDataset))


model.save(""my_model"")

%cd /content/gdrive/My\ Drive
%pwd


# Convert the model to the TensorFlow Lite format without quantization
converter = tf.lite.TFLiteConverter.from_keras_model(model)

tflite_model = converter.convert()

# Save the model to disk
open(""model.tflite"", ""wb"").write(tflite_model)

!dir

from google.colab import files
files.download('model.tflite') 
```

"
40814,CUDA illegal error access error when running distributed mixed precision,"Whenever I try to train a model using MirroredStrategy and mixed precision, at an indeterminate time, I get the following error:

```
./tensorflow/core/kernels/conv_2d_gpu.h:970] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, kNumThreads, kTileSize, kTileSize, conjugate>, total_tiles_count, kNumThreads, 0, d.stream(), input, input_dims, output) status: Internal: an illegal memory access was encountered
2020-06-25 00:45:27.788127: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered
2020-06-25 00:45:27.788208: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
```

Unfortunately, I don't have a simply example to reproduce this and can't include my entire code. But maybe other people are having similar issues and can produce a better example.

I'm running tensorflow 2.2.0 on ubuntu 18.04. CUDA 10.1.243, CuDNN 7.6.5 using two RTX 2080 ti cards. I get the same error on a V100.
"
40812,"Add ""align_corners"" and ""half_pixel_centers"" as argument to tf.image.resize ","tf.compat.v1.image.resize_nearest_neighbor, tf.compat.v1.image.resize_bilinear and tf.compat.v1.image.resize_bicubic all have ""align_corners"" and ""half_pixel_centers"" as argument for user to set or unset.
Can tf.image.resize provides ""align_corners"" and ""half_pixel_centers"" as argument for user to use too? 

**System information**
- TensorFlow version (you are using): 2.2.0

**Who will benefit with this feature?**
For user who is currently using ""align_corners"" and ""half_pixel_centers"" in tf.compat.v1.image.resize_nearest_neighbor, tf.compat.v1.image.resize_bilinear and tf.compat.v1.image.resize_bicubic, want to migrate to use tf.image.resize 

"
40810,segmentation fault in ctc_decode function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Segmentation fault occurs in `tf.keras.backend.ctc_decode` when passing a large value for `top_paths` and setting `greedy` to `False`. If it is far large enough to be out of range of `int32`, the function handles the error properly by throwing an exception in python, but when it is around the boundary of the range, the function produces a segfault.

**Describe the expected behavior**
No segfault. 

**Standalone code to reproduce the issue**
```python
import tensorflow as tf

y_pred = [[[4.7, 3.2, 2.8],
        [4.9, 1.0, 3.0]],

       [[3.9, 3.8, 1.4],
        [1.0, 1.6, 3.8]],

       [[4.0 , 4.5, 3.9],
        [2.2, 2.2, 4.5]]]
input_length = [3, 2, 2]
top_paths = 2147483697

tf.keras.backend.ctc_decode(y_pred, input_length, False, 100, top_paths)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
Segmentation fault (core dumped)
```
"
40806,[TFTRT] Possible issue with Conv2D converter without `is_dynamic_op= True`,"@tfeher @bixia1 FYI

As discussed yesterday, here are the steps to reproduce:

```python
import os
import numpy as np
import shutil

import tensorflow as tf

from tensorflow.python.compiler.tensorrt import trt_convert as trt
from tensorflow.python.saved_model import tag_constants

from distutils.version import LooseVersion

IS_DYNAMIC_OP = True

if LooseVersion(tf.__version__) >= LooseVersion(""2.0.0""):
    import tensorflow.compat.v1 as tf

tf.logging.set_verbosity(tf.logging.ERROR)

with tf.Graph().as_default() as _g:
    with tf.Session(graph=_g) as sess:

        saved_model_loaded = tf.saved_model.load(
            export_dir=""model-export/1591942827/"",
            tags=[tag_constants.SERVING],
            sess=sess
        )

        # Get tensors (input and output) by name
        input_tensor = _g.get_tensor_by_name(""input_tensor:0"")  # [None, 224, 224, 3]
        output_probs = _g.get_tensor_by_name(""resnext101-32x4d/output/softmax:0"")
        output_class_id = _g.get_tensor_by_name(""ArgMax:0"")

        print(""Bottleneck Block 0 0:"")
        for layer in tf.global_variables():
            if ""btlnck_block_0_0"" in layer.name:
                print(""\t[*]"", layer.name, layer.get_shape())

        print(""\nRunning Raw Saved Model - No TF-TRT:\n"")

        for idx in range(10):
            probs, class_id = sess.run(
                [output_probs, output_class_id],
                feed_dict={input_tensor: np.random.random((10, 224, 224, 3))}
            )
            print(""[{}] - {}"".format(idx, class_id))

        default_graph_def = _g.as_graph_def()

        output_node_names = [
            'resnext101-32x4d/output/softmax',
            'ArgMax',
        ]
        frozen_graph_def = tf.graph_util.convert_variables_to_constants(
            sess,
            tf.get_default_graph().as_graph_def(),
            output_node_names=output_node_names
        )
        frozen_graph_def = tf.graph_util.remove_training_nodes(frozen_graph_def)

with tf.Graph().as_default() as _g:
    with tf.Session(graph=_g) as sess:

        converter = trt.TrtGraphConverter(
            input_saved_model_dir='model-export/1591942827/',
            is_dynamic_op=IS_DYNAMIC_OP,
        )
        converter.convert()

        tftrt_savedir=""model-export/tftrt_model/""

        if os.path.exists(tftrt_savedir):
            shutil.rmtree(tftrt_savedir)

        converter.save(output_saved_model_dir=tftrt_savedir)

        tf.saved_model.loader.load(
             sess,
             [tf.saved_model.tag_constants.SERVING],
             export_dir='model-export/tftrt_model/'
        )
        input_tensor = _g.get_tensor_by_name(""input_tensor:0"")  # [None, 224, 224, 3]
        output_probs = _g.get_tensor_by_name(""resnext101-32x4d/output/softmax:0"")
        output_class_id = _g.get_tensor_by_name(""ArgMax:0"")

        print(""\nRunning TF-TRT Saved Model:\n"")
        for idx in range(10):
            # Inference on single image
            probs, class_id = sess.run(
                [output_probs, output_class_id],
                feed_dict={input_tensor: np.random.random((10, 224, 224, 3))}
            )
            print(""[{}] - {}"".format(idx, class_id))
```

The output to expect when `IS_DYNAMIC_OP = True`:

```bash
Bottleneck Block 0 0:
	[*] resnext101-32x4d/btlnck_block_0_0/shortcut/conv2d/conv2d/kernel:0 (1, 1, 64, 256)
	[*] resnext101-32x4d/btlnck_block_0_0/shortcut/conv2d/BatchNorm/gamma:0 (256,)
	[*] resnext101-32x4d/btlnck_block_0_0/shortcut/conv2d/BatchNorm/beta:0 (256,)
	[*] resnext101-32x4d/btlnck_block_0_0/shortcut/conv2d/BatchNorm/moving_mean:0 (256,)
	[*] resnext101-32x4d/btlnck_block_0_0/shortcut/conv2d/BatchNorm/moving_variance:0 (256,)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_1/conv2d/kernel:0 (1, 1, 64, 128)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_1/BatchNorm/gamma:0 (128,)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_1/BatchNorm/beta:0 (128,)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_1/BatchNorm/moving_mean:0 (128,)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_1/BatchNorm/moving_variance:0 (128,)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_2/bottleneck_2group_filter:0 (3, 3, 4, 128)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_2/BatchNorm/gamma:0 (128,)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_2/BatchNorm/beta:0 (128,)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_2/BatchNorm/moving_mean:0 (128,)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_2/BatchNorm/moving_variance:0 (128,)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_3/conv2d/kernel:0 (1, 1, 128, 256)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_3/BatchNorm/gamma:0 (256,)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_3/BatchNorm/beta:0 (256,)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_3/BatchNorm/moving_mean:0 (256,)
	[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_3/BatchNorm/moving_variance:0 (256,)

Running Raw Saved Model - No TF-TRT:

[0] - [644 644 644 644 644 644 644 644 644 644]
[1] - [644 644 644 644 644 644 644 644 644 644]
[2] - [644 644 644 644 644 644 644 644 644 644]
[3] - [644 644 644 644 644 644 644 644 644 644]
[4] - [644 644 644 644 644 644 644 644 644 644]
[5] - [644 644 644 644 644 644 644 644 644 644]
[6] - [644 644 644 644 644 644 644 644 644 644]
[7] - [644 644 644 644 644 644 644 644 644 644]
[8] - [644 644 644 644 644 644 644 644 644 644]
[9] - [644 644 644 644 644 644 644 644 644 644]

Running TF-TRT Saved Model:

[0] - [644 644 644 644 644 644 644 644 644 644]
[1] - [644 644 644 644 644 644 644 644 644 644]
[2] - [644 644 644 644 644 644 644 644 644 644]
[3] - [644 644 644 644 644 644 644 644 644 644]
[4] - [644 644 644 644 644 644 644 644 644 644]
[5] - [644 644 644 644 644 644 644 644 644 644]
[6] - [644 644 644 644 644 644 644 644 644 644]
[7] - [644 644 644 644 644 644 644 644 644 644]
[8] - [644 644 644 644 644 644 644 644 644 644]
[9] - [644 644 644 644 644 644 644 644 644 644]
```

However if you switch `IS_DYNAMIC_OP = False`, you will get the following error:

```bash
2020-06-25 20:00:30.873406: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:654] Number of TensorRT candidate segments: 1
2020-06-25 20:00:31.110705: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1153] Linked TensorRT version: 7.1.2
2020-06-25 20:00:31.110856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer.so.7
2020-06-25 20:00:31.110866: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1154] Loaded TensorRT version: 7.1.2
2020-06-25 20:00:31.111660: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer_plugin.so.7
2020-06-25 20:00:41.767166: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: kernel weights has count 4608 but 147456 was expected
2020-06-25 20:00:41.767218: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: count of 4608 weights in kernel, but kernel dimensions (3,3) with 128 input channels, 128 output channels and 1 groups were specified. Expected Weights count is 128 * 3*3 * 128 / 1 = 147456
2020-06-25 20:00:41.767790: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: kernel weights has count 4608 but 147456 was expected
2020-06-25 20:00:41.767807: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: count of 4608 weights in kernel, but kernel dimensions (3,3) with 128 input channels, 128 output channels and 1 groups were specified. Expected Weights count is 128 * 3*3 * 128 / 1 = 147456
2020-06-25 20:00:41.767817: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: kernel weights has count 4608 but 147456 was expected
2020-06-25 20:00:41.767827: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: count of 4608 weights in kernel, but kernel dimensions (3,3) with 128 input channels, 128 output channels and 1 groups were specified. Expected Weights count is 128 * 3*3 * 128 / 1 = 147456
2020-06-25 20:00:41.767836: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: kernel weights has count 4608 but 147456 was expected
2020-06-25 20:00:41.767845: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: count of 4608 weights in kernel, but kernel dimensions (3,3) with 128 input channels, 128 output channels and 1 groups were specified. Expected Weights count is 128 * 3*3 * 128 / 1 = 147456
Segmentation fault (core dumped)
```

Attached you will find the SavedModel you need to reproduce: https://drive.google.com/file/d/1b0AdSFDTKnOP7SXJqNbUUWsNCgfXzETU/view?usp=sharing

------------------

Something is definitely wrong here because: `kernel weights has count 4608 but 147456 was expected` and 4608 (what is inside the SavedModel) is the correct value. TF-TRT is just doing a bad assertion here. TF-TRT is wrong. Should be 4608 and be ""all green"".

"
40805,LSTM loss and accuracy values differ greatly between GPU and CPU implementation,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from: conda
- TensorFlow version: 2.2.0
- Python version: 3.7.7
- CUDA/cuDNN version: CUDA Version 10.1.243
- GPU model and memory: Nvidia GeForce 920M

**Describe the current behavior**
I've attached a <code>main.py</code> that should be able to replicate the error. When training a LSTM model the results differ by an order of magnitude (in the log sense) between GPU and CPU implementations.

(I've also attached the <code>dataset.txt</code> file that I quickly parsed because I cannot share the corpus
I am currently utilizing.)

I've tested over multiple runs and this effect doesn't occur on the GRU RNN, only LSTM.

Its rather hacky but I've used
<code> os.environ['CUDA_VISIBLE_DEVICES'] = '-1' </code>
to switch between GPU and CPU implementations and there is on <code>line 12</code> in <code>main.py</code>

GPU:
    Epoch 1 Train Loss 7.8753 Train Accuracy 46.6 Time 17.16
    Epoch 2 Train Loss 7.1481 Train Accuracy 49.0 Time 11.74 
    Epoch 3 Train Loss 6.9079 Train Accuracy 49.0 Time 13.47 

CPU:
    Epoch 1 Train Loss 6.6438 Train Accuracy 39.8 Time 16.51
    Epoch 2 Train Loss 4.6425 Train Accuracy 40.4 Time 11.57
    Epoch 3 Train Loss 4.4195 Train Accuracy 40.4 Time 11.73

**Describe the expected behavior**
I understand there should be small floating point error difference, as well as difference between random initialization, but the
loss values should at least be similar.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem.

Apologies, this may not be exact minimum:

[dataset.txt](https://github.com/tensorflow/tensorflow/files/4833424/dataset.txt)

```
import os
import sys
import time
from datetime import datetime
import tensorflow as tf
import tensorflow_datasets as tfds
import math
import random
import numpy as np

# the important bit 
#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

class LSTM_generator(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz):
        super(LSTM_generator, self).__init__()
        self.batch_sz = batch_sz
        self.hidden_units = hidden_units
        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,
                                                   output_dim=embedding_dim,
                                                   mask_zero=True)
        self.LSTM = tf.keras.layers.LSTM(self.hidden_units,
                                        return_sequences=True,
                                        return_state=True)
        self.fc = tf.keras.layers.Dense(vocab_size)

    def call(self, inp, states):
        mask = self.embedding.compute_mask(inp)
        
        x = self.embedding(inp)

        output, hidden, cell = self.LSTM(x,initial_state=states,mask=mask)

        x = self.fc(output)

        return x, (hidden, cell)

    def initialize_hidden_state(self):
        return tf.zeros((self.batch_sz,self.hidden_units)), tf.zeros((self.batch_sz,self.hidden_units))

# Converts str to list of str word 'tokens'

def tokenize(inp):
    words = []
    buffer = """"
    for let in inp:
        if chr(let) == "" "":
            words.append(buffer)
            buffer = """"
        else:
            buffer = buffer + chr(let)

    words.append(buffer)

    return words

def split_input_target(sequence):   
    input_text = sequence[:-1]
    target_text = sequence[1:]
    return input_text, target_text

dataset_path = 'dataset.txt'
aug_dataset_path = 'aug.txt'
vocabulary_set = set()

dataset = tf.data.TextLineDataset(dataset_path)

# get vocab
for text_tensor in dataset:
    some_tokens = tokenize(text_tensor.numpy())
    vocabulary_set.update(some_tokens)

encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)

def encode(text_tensor):
    encoded_text = encoder.encode(text_tensor.numpy())

    return tf.cast(encoded_text,tf.int64)

def encode_map_fn(text):
    encoded_text = tf.py_function(encode,inp=[text],Tout=tf.int64)

    encoded_text.set_shape([None])

    return encoded_text

raw_dataset = dataset.map(encode_map_fn)

# split dataset into sources and targets
dataset_split = raw_dataset.map(split_input_target)

# model parameters 
embedding_dim = 8
rnn_units = 64
batch_size = 64
epochs = 60
sens_to_generate = 8000
temperature = 1.0
vocab_size = encoder.vocab_size
max_seq_len_to_generate = 30
BUFFER_SIZE = 10000

# pad and batch the training datasets
dataset_batched_padded = dataset_split.padded_batch(batch_size,
                                        padded_shapes=([None,],[None,]),
                                        drop_remainder=True).shuffle(BUFFER_SIZE)

generator = LSTM_generator(vocab_size, embedding_dim, rnn_units, batch_size)

# signatures help tf run faster - tracing or something
train_step_signature = [
    tf.TensorSpec(shape=(batch_size, None), dtype=tf.int64),
    tf.TensorSpec(shape=(batch_size, None), dtype=tf.int64),
    (tf.TensorSpec(shape=(batch_size, rnn_units), dtype=tf.float32),
    tf.TensorSpec(shape=(batch_size, rnn_units), dtype=tf.float32))]

optimizer = tf.keras.optimizers.Adam()

loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
                        from_logits=True, reduction='none')           

def loss_function(real, pred):
    return tf.reduce_mean(loss_object(real, pred))

# Define metrics
train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)
train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')

# define a single training step
@tf.function(input_signature=train_step_signature)
def train_step(inp, tar, hidden):
    with tf.GradientTape() as tape:
        predictions, hidden = generator(inp,hidden)

        loss = loss_function(tar, predictions)

    gradients = tape.gradient(loss, generator.trainable_variables)

    optimizer.apply_gradients(zip(gradients, generator.trainable_variables))

    train_loss(loss)
    train_accuracy(tar, predictions)

for epoch in range(epochs):
    start = time.time()
    
    # initializing the hidden state at the start of every epoch
    hidden = generator.initialize_hidden_state()
    
    # loop through training set
    steps_per_epoch = 0
    for (batch, (inp, tar)) in enumerate(dataset_batched_padded):
        train_step(inp, tar, hidden)

        if batch % 1 == 0:
            sys.stdout.write(""Epoch %d Batch %d Loss %.4f \r"" % (
                epoch + 1, batch, train_loss.result()
            ) )
            sys.stdout.flush()
        
        steps_per_epoch += 1
            
    print('-' * 89)
    print ('Epoch {} Train Loss {:.4f} Train Accuracy {:.1f} Time {:.2f}'.format(epoch + 1, 
                                                    train_loss.result(),
                                                    train_accuracy.result()*100,
                                                    (time.time() - start)))

    # Reset metrics every epoch
    train_loss.reset_states()
    train_accuracy.reset_states()
```
"
40804,Could not load dynamic library 'cudart64_101.dll',"**System information**
- Windows 10
- Laptop: Asus gl553vw
- TensorFlow installed with pip
- tensorflow-gpu 2.2.0
- Python 3.8.3
- CUDA version 10.1 (update2)
- cudnn-10.1-windows10-x64-v7.6.5.32
- Nvidia GTX 960M

I want to use tensorflow with GPU but I keep receiving this error Could not load dynamic library 'cudart64_101.dll' when I import Tensorflow.

<details><summary>the output of `pip list`:</summary>

```
Package                  Version
------------------------ -----------
absl-py                  0.9.0
astunparse               1.6.3
cachetools               4.1.0
certifi                  2020.6.20
chardet                  3.0.4
gast                     0.3.3
google-auth              1.18.0
google-auth-oauthlib     0.4.1
google-pasta             0.2.0
grpcio                   1.30.0
h5py                     2.10.0
idna                     2.9
Keras-Preprocessing      1.1.2
Markdown                 3.2.2
numpy                    1.19.0
oauthlib                 3.1.0
opt-einsum               3.2.1
pip                      19.2.3
protobuf                 3.12.2
pyasn1                   0.4.8
pyasn1-modules           0.2.8
requests                 2.24.0
requests-oauthlib        1.3.0
rsa                      4.6
scipy                    1.4.1
setuptools               41.2.0
six                      1.15.0
tensorboard              2.2.2
tensorboard-plugin-wit   1.6.0.post3
tensorflow-gpu           2.2.0
tensorflow-gpu-estimator 2.2.0
termcolor                1.1.0
urllib3                  1.25.9
Werkzeug                 1.0.1
wheel                    0.34.2
wrapt                    1.12.1
```
</details>

<details><summary>the output of `pip debug --verbose`:</summary>

```
pip version: pip 19.2.3 from c:\users\ghassen\downloads\lisadetection\lisadetection\venv2\lib\site-packages\pip (python 3.8)
sys.version: 3.8.3 (tags/v3.8.3:6f8c832, May 13 2020, 22:37:02) [MSC v.1924 64 bit (AMD64)]
sys.executable: c:\users\ghassen\downloads\lisadetection\lisadetection\venv2\scripts\python.exe
sys.getdefaultencoding: utf-8
sys.getfilesystemencoding: utf-8
locale.getpreferredencoding: cp1252
sys.platform: win32
sys.implementation:
  name: cpython
Config variable 'Py_DEBUG' is unset, Python ABI tag may be incorrect
Compatible tags: 15
  cp38-cp38-win_amd64
  cp38-none-win_amd64
  py3-none-win_amd64
  cp38-none-any
  cp3-none-any
  py38-none-any
  py3-none-any
  py37-none-any
  py36-none-any
  py35-none-any
  py34-none-any
  py33-none-any
  py32-none-any
  py31-none-any
  py30-none-any
```

</details>

For `import tensorflow as tf` this is the output:

```
2020-06-24 14:50:11.230153: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-06-24 14:50:11.236957: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
```

<details>
<summary>and for `tf.test.is_gpu_available()` the output is:</summary>
```
WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
2020-06-24 14:51:00.146205: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-06-24 14:51:00.171655: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21868deee70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-24 14:51:00.182635: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-24 14:51:00.190956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-06-24 14:51:01.031439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s
2020-06-24 14:51:01.045344: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-06-24 14:51:01.051842: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found
2020-06-24 14:51:01.058515: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2020-06-24 14:51:01.065241: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2020-06-24 14:51:01.072266: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found
2020-06-24 14:51:01.080353: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusparse64_10.dll'; dlerror: cusparse64_10.dll not found
2020-06-24 14:51:01.087954: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found
2020-06-24 14:51:01.095638: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-06-24 14:51:01.186835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-24 14:51:01.194906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
2020-06-24 14:51:01.198498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
2020-06-24 14:51:01.206694: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21876e35be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-24 14:51:01.214517: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 960M, Compute Capability 5.0
False
```
</details>


"
40802,ModuleNotFoundError: No module named 'tensorflow.contrib',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:3.6
- Installed using virtualenv? pip? conda?:conda
- GPU model and memory:



**Describe the problem**
  File ""main.py"", line 6, in <module>
    import tflearn
  File ""C:\Users\V\Anaconda3\envs\chatbot\lib\site-packages\tflearn\__init__.py"", line 4, in <module>
    from . import config
  File ""C:\Users\V\Anaconda3\envs\chatbot\lib\site-packages\tflearn\config.py"", line 5, in <module>
    from .variables import variable
  File ""C:\Users\V\Anaconda3\envs\chatbot\lib\site-packages\tflearn\variables.py"", line 7, in <module>
    from tensorflow.contrib.framework.python.ops import add_arg_scope as contrib_add_arg_scope
ModuleNotFoundError: No module named 'tensorflow.contrib'

**Provide the exact sequence of commands / steps that you executed before running into the problem**
python main.py is only command I ran

full code:
import nltk
from nltk.stem.lancaster import LancasterStemmer  #for stemming
stemmer  = LancasterStemmer()

import numpy
import tflearn
import tensorflow
import random
import json

#file import
with open(""intents.json"") as file:
	data = json.load(file)
	print(data)


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40801,tf.io.gfile.GFile truncates gzipped files loaded from Google Cloud buckets,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.5
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): `v2.2.0-rc4-8-g2b96f3662b 2.2.0`
- Python version: 3.6.2
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

Loading a CSV file with `tf.io.gfile.GFile(""gs://my-bucket/my-file.csv"")` from a Google Cloud bucket is truncating the results for gzipped files.

E.g. one test file is stored with gzip compression & has a compressed filesize of 45kb, but an uncompressed size of 170kb. Reading from the file via `GFile.read()` only outputs 45kb of (uncompressed) data, then the file closes. Checking the size of the file with `GFile.size()` reports 45kb.

There don't appear to be any options available regarding compression, and the data is correctly uncompressed, but truncated

**Describe the expected behavior**

The entire file is returned, and `GFile.size()` returns the uncompressed filesize.

**Standalone code to reproduce the issue**

https://colab.research.google.com/drive/15xXT8nXAr0cqjmvV1-JMu3es4e9a34xL?usp=sharing
"
40800,Is it possible to use TensorFlow 2.2 with Cuda 10.0?,"**System information**
Linux Ubuntu 18.04
TensorFlow 2.2.0 (installed using pip)
Python 3.6.9
Cuda 10.0/ cuDNN 7.6.5
GPU: nVIDIA GTX 1080 Ti

**Describe the problem**
I have a working setup with the above system configuration and TF 2.0. I would like to check out TF 2.2 (and also use some packages which only support TF >=2.2). However, I do not want to touch my cuda setup as I am afraid it could cause other unintended issues.

Question: Is it possible to run TF 2.2 on top of Cuda 10.0? For example, by editing symlinks, recompiling etc.? If yes, can you direct me to any documentation with the steps (or explain here)? If not possible, is there any TF confirmed way of upgrading cuda 10.0 to cuda 10.2?

I have tried running TF 2.2 with cuda 10.0 but it does not seem to be able to detect cuda packages (although it detects GPU)

```
>>> tf.config.list_physical_devices('GPU')
2020-06-25 23:20:36.860274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-25 23:20:36.865225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-25 23:20:36.866048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-06-25 23:20:36.866331: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-06-25 23:20:36.866444: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory
2020-06-25 23:20:36.866550: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory
2020-06-25 23:20:36.866653: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory
2020-06-25 23:20:36.866757: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory
2020-06-25 23:20:36.866878: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory
2020-06-25 23:20:36.872785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-25 23:20:36.872828: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
```

CUDA Version Check:
```
/usr/local/cuda/bin/nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130
```

NVIDIA Driver: 430.50


It works fine with TF 2.0.0

```
2020-06-25 23:25:12.242640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:01:00.0
2020-06-25 23:25:12.242832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-06-25 23:25:12.243852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-06-25 23:25:12.244711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-06-25 23:25:12.244930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-06-25 23:25:12.246136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-06-25 23:25:12.247112: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-06-25 23:25:12.249902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
```


Thanks!"
40799,"ValueError: Shapes (1, 107, 3) and (1, 107, 2) are incompatible","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab system(Linux version 4.19.104+ )
- TensorFlow installed from (source or binary):colab system installed it 
- TensorFlow version (use command below): tf2.2.0
- Python version: 3.6


**Describe the current behavior**
I am doing some work about tensor train decomposition.
      

- Firstly, I represent a video with tensor. The tensor  dimension is 4 which shape can be see with [ frames, width, heights,channels]. And the tensor shape is [107, 60, 80, 3]. 
- Secondly, I convert the tf tensor to TT tensor via t3f library. 
- Thirdly, I write a Riemann dimension reduction function for the TT tensor. 
- In the end, I reduce  the TT tensor dimension via my function. But the bug come out in the end step.

What I want to say is that the bug didn't come out when I represent another data with tensor which shape is [107, 60, 80, 2] .In that situtation code runned very good.

The exit:

>  ---------------------------------------------------------------------------
> ValueError                                Traceback (most recent call last)
> ipython-input-34-e5f2500494ee in module()
>       1 log = []
>       2 for i in range(1000):
> ----> 3     F = step()
>       4     if i % 10 == 0:
>       5         print(F)
> 
> 4 frames
> /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py in assert_is_compatible_with(self, other)
>    1115     """"""
>    1116     if not self.is_compatible_with(other):
> -> 1117       raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
>    1118 
>    1119   def most_specific_compatible_shape(self, other):
> 
> ValueError: Shapes (1, 107, 3) and (1, 107, 2) are incompatible

**Describe the expected behavior**
I expect the video convert to TT tensor can also be reduced dimension by my function been mentioned above without any error just as the shape [107, 60, 80, 2] data.  


**Standalone code to reproduce the issue**
Here is the bug code colab address [Link](https://colab.research.google.com/drive/1Qz-TBBAbnflKioPn-YxxFwl59K3DVlWb?usp=sharing)
Here is the video data address which shape is [107, 60, 80, 3] [Link](https://drive.google.com/file/d/1DVB7ReloEKTkqRBFyj8Uop6_FKf-oBYe/view?usp=sharing)
Here is the another data address which shape is [107, 60, 80, 2] [Link](https://drive.google.com/file/d/1DNS5xCMikgsvye1NZRmdDl3ebcG10ves/view?usp=sharing)

#33948 
@jvishnuvardhan    "
40797,Cannot test op using mutlithreading,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): master
- Python version: 3.6.0
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.12)
- CUDA/cuDNN version: None
- GPU model and memory: None

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Still only single thread is being used even if I uncommented https://github.com/petewarden/tensorflow_makefile/blob/master/tensorflow/python/kernel_tests/sparse_tensor_dense_matmul_op_test.py#L168.

Here is how I tested it:
VLOG(0) << worker_threads.num_threads;

Output:
1

**Describe the expected behavior**
VLOG(0) << worker_threads.num_threads;

Expected Output:
100

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Uncomment:
https://github.com/petewarden/tensorflow_makefile/blob/master/tensorflow/python/kernel_tests/sparse_tensor_dense_matmul_op_test.py#L168.

bazel build -c opt --copt=-mavx --copt=-msse4.2 --copt=-O3 tensorflow/python/kernel_tests:sparse_tensor_dense_matmul_op_test

./bazel-bin/tensorflow/python/kernel_tests/sparse_tensor_dense_matmul_op_test --benchmarks

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40796,tf.debugging.enable_check_numerics() doesn't work on TPUs,"Adding that line produces this traceback:
```
File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 848, in fit
    tmp_logs = train_function(iterator)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 1665, in _filtered_call
    self.captured_inputs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 598, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py"", line 140, in execute_with_callbacks
    callback(op_name, tuple(inputs), attrs, tensors, name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/debug/lib/check_numerics_callback.py"", line 294, in callback
    path_length_limit=self._path_length_limit))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/debug/lib/check_numerics_callback.py"", line 164, in get_check_numerics_error_message
    message += ""  shape: %s\n"" % (tensor.shape,)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1067, in shape
    six.raise_from(core._status_to_exception(e.code, e.message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError:  Compilation failure: Detected unsupported operations when trying to compile graph cluster_train_function_12198995384642658803[] on XLA_TPU_JIT: DebugNumericSummaryV2 (No registered 'DebugNumericSummaryV2' OpKernel for XLA_TPU_JIT devices compatible with node node my_model/embedding/embedding_lookup/ReadVariableOp/DebugNumericSummaryV2 (defined at tools/model-trainer.py:268) )node my_model/embedding/embedding_lookup/ReadVariableOp/DebugNumericSummaryV2 (defined at tools/model-trainer.py:268) 
        TPU compilation failed
         [[tpu_compile_succeeded_assert/_449904103826306356/_3]]
```"
40795,Error when computing gradients of a reloaded SavedModel containing an if clause,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.2.0, 2.3.0-dev20200622
- Python version: 3.7.6
- CUDA/cuDNN version: CUDA 10.1.243 - cuDNN 7.6.4
- GPU model and memory: Tesla K80, 12GB

**Describe the current behavior**

Computing gradients of a reloaded SavedModel containing an if clause raises an error.

When I save a model containing an if clause as follows:

```python
import tensorflow as tf

class CondModel(tf.keras.models.Model):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.dense_layer = tf.keras.layers.Dense(units=1)

    def call(self, inputs, training=None):
        if training:
            return self.dense_layer(inputs)
        else:
            return self.dense_layer(inputs)


m = CondModel()
m.__call__ = tf.function(m.__call__)
m.__call__.get_concrete_function(
    inputs=tf.TensorSpec(shape=[1, 1]), 
    training=tf.TensorSpec(shape=None, dtype=tf.bool)
)
tf.saved_model.save(m, 'saved_model')
```

and I try to load it back and get gradients **in a new process** as:

```python
import tensorflow as tf

reloaded = tf.saved_model.load('saved_model')

with tf.GradientTape() as tape:
    reloaded(inputs=[[1]], training=False)
```

then error message below happens. If however I execute the following code it works all right:

```python
import tensorflow as tf

# --- HACK ---
def f(x):
    if x:
        pass 
    
tf.function(f).get_concrete_function(
    x=tf.TensorSpec(shape=None)
)
# -------------

reloaded = tf.saved_model.load('saved_model')

with tf.GradientTape() as tape:
    reloaded(inputs=[[1]], training=False)
```

Also if I reload in the same process in which I did the saving no error happens (so to reproduce the error the above snippets should be excuted in different processes).

**Error message:**

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2485       with c_api_util.tf_buffer() as buf:
-> 2486         pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)
   2487         data = pywrap_tf_session.TF_GetBuffer(buf)

InvalidArgumentError: Operation 'StatefulPartitionedCall' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    330     try:
--> 331       xla_compile = op.get_attr(""_XlaCompile"")
    332       xla_separate_compiled_gradients = op.get_attr(

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2489       # Convert to ValueError for backwards compatibility.
-> 2490       raise ValueError(str(e))
   2491     x = attr_value_pb2.AttrValue()

ValueError: Operation 'StatefulPartitionedCall' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

LookupError                               Traceback (most recent call last)
~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    606           try:
--> 607             grad_fn = ops.get_gradient_function(op)
    608           except LookupError:

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in get_gradient_function(op)
   2654     op_type = op.type
-> 2655   return _gradient_registry.lookup(op_type)
   2656 

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/registry.py in lookup(self, name)
     96       raise LookupError(
---> 97           ""%s registry has no entry for: %s"" % (self._name, name))

LookupError: gradient registry has no entry for: If

During handling of the above exception, another exception occurred:

LookupError                               Traceback (most recent call last)
<ipython-input-1-c7239ff2b139> in <module>
      4 
      5 with tf.GradientTape() as tape:
----> 6     reloaded(inputs=[[1]], training=False)

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py in _call_attribute(instance, *args, **kwargs)
    494 
    495 def _call_attribute(instance, *args, **kwargs):
--> 496   return instance.__call__(*args, **kwargs)
    497 
    498 

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    844               *args, **kwds)
    845       # If we did not create any variables the trace we have is good enough.
--> 846       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
    847 
    848     def fn_with_cond(*inner_args, **inner_kwds):

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)
   1840                            resource_variable_ops.BaseResourceVariable))],
   1841         captured_inputs=self.captured_inputs,
-> 1842         cancellation_manager=cancellation_manager)
   1843 
   1844   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1921         possible_gradient_type,
   1922         executing_eagerly)
-> 1923     forward_function, args_with_tangents = forward_backward.forward()
   1924     if executing_eagerly:
   1925       flat_outputs = forward_function.call(

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in forward(self)
   1431     """"""Builds or retrieves a forward function for this call.""""""
   1432     forward_function = self._functions.forward(
-> 1433         self._inference_args, self._input_tangents)
   1434     return forward_function, self._inference_args + self._input_tangents
   1435 

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in forward(self, inference_args, input_tangents)
   1187       (self._forward, self._forward_graph, self._backward,
   1188        self._forwardprop_output_indices, self._num_forwardprop_outputs) = (
-> 1189            self._forward_and_backward_functions(inference_args, input_tangents))
   1190     return self._forward
   1191 

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _forward_and_backward_functions(self, inference_args, input_tangents)
   1339     outputs = self._func_graph.outputs[:self._num_inference_outputs]
   1340     return self._build_functions_for_outputs(
-> 1341         outputs, inference_args, input_tangents)
   1342 
   1343 

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _build_functions_for_outputs(self, outputs, inference_args, input_tangents)
    897             self._func_graph.inputs,
    898             grad_ys=gradients_wrt_outputs,
--> 899             src_graph=self._func_graph)
    900 
    901       captures_from_forward = [

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    667                 # functions.
    668                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--> 669                                          lambda: grad_fn(op, *out_grads))
    670               else:
    671                 # For function call ops, we add a 'SymbolicGradient'

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    334       xla_scope = op.get_attr(""_XlaScope"").decode()
    335     except ValueError:
--> 336       return grad_fn()  # Exit early
    337 
    338   if not xla_compile:

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py in <lambda>()
    667                 # functions.
    668                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--> 669                                          lambda: grad_fn(op, *out_grads))
    670               else:
    671                 # For function call ops, we add a 'SymbolicGradient'

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _rewrite_forward_and_call_backward(self, op, *doutputs)
    710   def _rewrite_forward_and_call_backward(self, op, *doutputs):
    711     """"""Add outputs to the forward call and feed them to the grad function.""""""
--> 712     forward_function, backwards_function = self.forward_backward(len(doutputs))
    713     if not backwards_function.outputs:
    714       return backwards_function.structured_outputs

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in forward_backward(self, num_doutputs)
    619     if forward_backward is not None:
    620       return forward_backward
--> 621     forward, backward = self._construct_forward_backward(num_doutputs)
    622     self._cached_function_pairs[num_doutputs] = (forward, backward)
    623     return forward, backward

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _construct_forward_backward(self, num_doutputs)
    667           args=[], kwargs={},
    668           signature=signature,
--> 669           func_graph=backwards_graph)
    670       backwards_graph_captures = backwards_graph.external_captures
    671       captures_from_forward = [

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    977         _, original_func = tf_decorator.unwrap(python_func)
    978 
--> 979       func_outputs = python_func(*func_args, **func_kwargs)
    980 
    981       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _backprop_function(*grad_ys)
    657             self._func_graph.inputs,
    658             grad_ys=grad_ys,
--> 659             src_graph=self._func_graph)
    660 
    661     with self._func_graph.as_default():

~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    621               raise LookupError(
    622                   ""No gradient defined for operation '%s' (op type: %s)"" %
--> 623                   (op.name, op.type))
    624         if loop_state:
    625           loop_state.EnterGradWhileContext(op, before=False)

LookupError: No gradient defined for operation 'cond_model/cond' (op type: If)
```"
40794,Error when computing gradients of a reloaded SavedModel containing an if clause,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): only the snippet below.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.2.0, 2.3.0-dev20200622
- Python version: 3.7.6
- CUDA/cuDNN version: CUDA 10.1.243 - cuDNN 7.6.4
- GPU model and memory: Tesla K80, 12GB

**Describe the current behavior**

Computing gradients of a reloaded SavedModel containing an if clause raises an error.

If I save a model containing an if clause as follows:

``````



**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40793,Question: fake-quantize layers are also called from TF-Lite,"Hi TensorFlow developers. 

I'm facing a behavior with TensorFlow lite quantized models that I can't figure out.

I published a question in StackOverflow but didn't get a helpful response for now: https://stackoverflow.com/questions/62433410/tensorflow-fake-quantize-layers-are-also-called-from-tf-lite/62524147.

I think that what I'm actually looking for, is how do I force the C++ code to run only with integer ops (for example, the minimal.cc sample).

**
Note 1:
When I'm training without quantization aware and then post-quantize the model, I see what I expect to see when running the C++ code. Only integer ops are running (except gemlowp) and I can understand exactly what the code is doing and which quantization parameters are used and how they are used.

Note 2:
My main goal is to simulate HW int8 arithmetic in Python based on TF Lite quantized models. So I understand how to do it for post-quantized models. My issues are with quantized-aware models.
**

Thanks in advance for any advice..."
40791,Documentation Error: padded_shapes isn't provided in padded_batch method.,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/tutorials/keras/text_classification

## Description of issue (what needs changing): Under heading 'Prepare the data for training'  in first code snippet 
BUFFER_SIZE = 1000

train_batches = (
    train_data
    .shuffle(BUFFER_SIZE)
    .padded_batch(32))

test_batches = (
    test_data
    .padded_batch(32))

padded_shape isn't provided while it is mandatory i guess. Also when i was following this tutorial i got the error: ""TypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'""

So please update the documentation. And also please help me out what should be the padded_shapes for this example. 
I've read the documentation for padded_batch but i still got different errors. Thank You


For example, why should someone use this method? How is it useful?

### Correct links


Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
40790,Could not detect op for DEPTHWISE_CONV_2D,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10, Mbed Studio
- TensorFlow installed from (source or binary):
Source
- Tensorflow version (commit SHA if source):
2.1.0, 896c9220929e85fec93c6587330f19815f71e589
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):
Arm Mbed OS

**Describe the problem**
Person detection example does not work out of the box and gives runtime errors on STM DISCO-F746NG. 

**Please provide the exact sequence of commands/steps when you ran into the problem**
1. Clone tensorflow source. 
2. Make projects: `make -f tensorflow/lite/micro/tools/make/Makefile generate_projects`
3. Try to run person_detection example. 

Output: 
""Could not detect op for builtin op code DEPTHWISE_CONV_2D"" 

I couldn't find any documentation on which commit of the Tensorflow source I should use. I have tried a few commits of the tensorflow/lite/micro repo with varying degrees of failure, Please suggest one that will compile cleanly and run with no errors. 


"
40788,TPU UnimplementedError: ,"In [1]: # TPU detection 
   ...: import tensorflow as tf 
   ...: try: 
   ...:     tpu = tf.distribute.cluster_resolver.TPUClusterResolver(zone=""asia-east1-c"", tpu='node-1') 
   ...:     print(""Well done TPU"") 
   ...: except ValueError: 
   ...:     tpu = None 
   ...:  
   ...: # TPUStrategy for distributed training 
   ...: if tpu: 
   ...:     tf.config.experimental_connect_to_cluster(tpu) 
   ...:     tf.tpu.experimental.initialize_tpu_system(tpu) 
   ...:     strategy = tf.distribute.experimental.TPUStrategy(tpu) 
   ...: else:  # default strategy that works on CPU and single GPU 
   ...:     strategy = tf.distribute.get_strategy() 
   ...:                                                                                                                                                                                                                                                                                                                                               
Well done TPU
2020-06-25 05:14:29.750280: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-06-25 05:14:29.756093: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz
2020-06-25 05:14:29.756581: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a41541e180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-25 05:14:29.756623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-25 05:14:29.756743: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
E0625 05:14:29.759021301   24154 socket_utils_common_posix.cc:222] check for SO_REUSEPORT: {""created"":""@1593062069.759011126"",""description"":""SO_REUSEPORT unavailable on compiling system"",""file"":""external/com_github_grpc_grpc/src/core/lib/iomgr/socket_utils_common_posix.cc"",""file_line"":190}
2020-06-25 05:14:29.762198: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.164.19.178:8470}
2020-06-25 05:14:29.762229: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:54154}
2020-06-25 05:14:29.773350: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.164.19.178:8470}
2020-06-25 05:14:29.773386: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:54154}
2020-06-25 05:14:29.773901: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:54154
INFO:tensorflow:Initializing the TPU system: node-1
INFO:tensorflow:Initializing the TPU system: node-1
2020-06-25 05:14:29.848183: E tensorflow/core/common_runtime/eager/context.cc:556] Failed to register function remotely due to 
This shouldn't happen, please file a bug to tensorflow team.
INFO:tensorflow:Clearing out eager caches
INFO:tensorflow:Clearing out eager caches
---------------------------------------------------------------------------
UnimplementedError                        Traceback (most recent call last)
<ipython-input-1-f4a150040101> in <module>
     10 if tpu:
     11     tf.config.experimental_connect_to_cluster(tpu)
---> 12     tf.tpu.experimental.initialize_tpu_system(tpu)
     13     strategy = tf.distribute.experimental.TPUStrategy(tpu)
     14 else:  # default strategy that works on CPU and single GPU

~/miniconda3/envs/mccb/lib/python3.7/site-packages/tensorflow/python/tpu/tpu_strategy_util.py in initialize_tpu_system(cluster_resolver)
    101     context.context()._clear_caches()  # pylint: disable=protected-access
    102 
--> 103     serialized_topology = output.numpy()
    104 
    105     # TODO(b/134094971): Remove this when lazy tensor copy in multi-device

~/miniconda3/envs/mccb/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in numpy(self)
    959     """"""
    960     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.
--> 961     maybe_arr = self._numpy()  # pylint: disable=protected-access
    962     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr
    963 

~/miniconda3/envs/mccb/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in _numpy(self)
    927       return self._numpy_internal()
    928     except core._NotOkStatusException as e:
--> 929       six.raise_from(core._status_to_exception(e.code, e.message), None)
    930 
    931   @property

~/miniconda3/envs/mccb/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

UnimplementedError: 
"
40787,tf.image.random_flip_left_right should be also to apply to a list of tsor,"**System information**
- TensorFlow version (you are using): 2.2.0
- Are you willing to contribute it (Yes/No): yes


**Describe the feature and the current behavior/state.**
Add support to randomly flip image for a list o tensor images instead a single tensor. tf.image.random_flip_left_right, random_flip_top_bottom..
The problem is that for segmentation training, we wants to use data augment to randomly flip the input left or right. But there is no way the flip the ground true (the labels) together. 
Since  we don't know which direction the random flip api is flipping to. Batching make it worse since each image will flip randomly. We need to  modify the api to take  either a single tensor or a list of tensors and flip the images together in the same direction. which is required  for  image segmentation.


**Will this change the current api? How?**
No. We can detect the input argument is a list or single tensor

**Who will benefit with this feature?**

**Any Other info.**
"
40786,It seems be issues to tflite model,#https://github.com/google/mediapipe/issues/845
40785,the link to stable version of this codelab is broken ,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
40784,"Jetson Nano build fails with missing ""cudnn_version"" string (default=7)","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Ubuntu 16.04 for Nvidia Jetson Nano (Tegra ARM64)
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.1.1
- Python version: 2.7.17 and 3.6.9 (issue occurs with both)
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: CUDA 10.2 cuDNN 8.0.0
- GPU model and memory: Nvidia Maxwell 4GB LPDDR4

**Describe the problem**
Build halts due to missing tuple entry (instead of blank string) for option 9: cudnn_version
The default as set in ""configure.py"" is cuDNN 7, but this is not reflected in the dictionary.
I have cuDNN version 8 installed but it has not been detected by the build script.
Everything else has been detected fine before this point (line 1318 in ""configure.py"").

**Provide the exact sequence of commands / steps that you executed before running into the problem**
""sudo ./configure"" and say ""Y/y"" all dependencies (including python, computecpp, CUDA etc.)

**Any other info / logs**
![tensorflow2-debug](https://user-images.githubusercontent.com/8195854/85642678-16a6e580-b68a-11ea-8c51-7c6282261786.png)

"
40781,TFLite quantized hard_swish operator precision issue,"Hi TFlite team,

Git hash: b8a267a9fe95dea518cb04c726031e96874d26a0, dated at Jun 9 2020

Description:

When I run quantized mobilenet v3, I found an infrequent precision issue in quantized hard_swish operator. Let me directly walk through the example to start. 

Note I already stripped off every other operators in mobilenet v3 models and tensor resized to [1] to make it clear and easier to run. The text below is the tflite .mlir. 
```
module attributes {tfl.description = ""TOCO Converted."", tfl.schema_version = 3 : i32} {
  func @main(%arg0: tensor<1x!quant.uniform<u8:f32, 0.13308307528495789:105>>) -> tensor<1x!quant.uniform<u8:f32, 0.075572937726974487:5>> attributes {tf.entry_function = {inputs = ""input"", outputs = ""MobilenetV3/expanded_conv_6/expand/hard_swish/mul_1""}} {
    %0 = ""tfl.hard_swish""(%arg0) : (tensor<1x!quant.uniform<u8:f32, 0.13308307528495789:105>>) -> tensor<1x240x!quant.uniform<u8:f32, 0.075572937726974487:5>>
    return %0 : tensor<1x!quant.uniform<u8:f32, 0.075572937726974487:5>>
  }
}
```
A mismatch happens here when input element is 128, and here's how I calculate the expected number:

real_input_value = (quantized_input_value - input_zp) * input_scale = (128 - 105) * 0.13308307528495789 = 3.0609113
real_output_value = x * relu6(x+3) / 6 = x (if x > 3) = 3.0609113
quantized_output_value = round_to_nearest(real_output_value / output_scale) + output_zp = 3.0609113 / 0.075572937726974487 + 5 = round(40.502742) + 5 = 41 + 5 = 46


while tflite gives me answer of 45 in this case, which I don't think is correct. And that's because when rescaling output back to quantized space, the number is too close to 40.5, and tflite reference implementation might lose precision somewhere so it gets < 40.5 in this case, and leads to output=45 eventually. Btw, all other quantized input numbers are running fine.

When I looked at the reference implementation under tflite/kernel/reference/reference_ops.h, it seems like it's using fixed point s0.15 to represent the relu-ish value, even when it's 1.0, which leads to a error factor of 32767 / 32768 for each fixed16_t multiplier. If I have to guess, that could be a source of error. Another possibility could be float vs double. I noticed in HardSwishPrepare it stores input and output scales as float type instead of double.

Thanks in advance!"
40772,d,d
40771,"Tensorflow 2 - oneDNN 1.x build fails searching for i_malloc.h, mkl_cblas.h on non-x86 machines.","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
NAME=""CentOS Linux""
VERSION=""8 (Core)""

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): source
- TensorFlow version: master & 2.2.0
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): GCC 8.3.1
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Describe the problem**
I am building Tensorflow with oneDNN 1.4.0 on an Aarch64 machine, which causes issues when searching for MKL-ML header files (e.g. i_malloc.h). 

Example log 1:

``` 
/home/../tensorflow-nb/packages/tensorflow/tensorflow/core/common_runtime/BUILD:1018:1: C++ compilation of rule '//tensorflow/core/common_runtime:mkl_cpu_allocator' failed (Exit 1)
In file included from tensorflow/core/common_runtime/mkl_cpu_allocator.cc:18:
./tensorflow/core/common_runtime/mkl_cpu_allocator.h:33:10: fatal error: i_malloc.h: No such file or directory
 #include ""i_malloc.h""
 ^~~~~~~~~~~~
compilation terminated.
```
Example log 2:
```
ERROR: /home/.../tensorflow-nb/packages/tensorflow/tensorflow/core/kernels/BUILD:4109:1: C++ compilation of rule '//tensorflow/core/kernels:mkl_batch_matmul_op' failed (Exit 1)
tensorflow/core/kernels/mkl_batch_matmul_op.cc:31:10: fatal error: mkl_cblas.h: No such file or directory
 #include ""mkl_cblas.h""
          ^~~~~~~~~~~~~
compilation terminated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: /home/.../tensorflow-nb/packages/tensorflow/tensorflow/lite/toco/python/BUILD:84:1 C++ compilation of rule '//tensorflow/core/kernels:mkl_batch_matmul_op' failed (Exit 1) 
```

In previous Tensorflow versions  (1.x), for example, when building with the older mkldnn library 0.21.x, these header files were removed with mkldnn ifdefs (INTEL_MKL_DNN_ONLY):
https://github.com/tensorflow/tensorflow/blob/590d6eef7e91a6a7392c8ffffb7b58f2e0c8bc6b/tensorflow/core/common_runtime/mkl_cpu_allocator.h#L32

 while these ifdefs are not activated when building with the new oneDNN 1.x (with for e.g -DENABLE_MKLDNN_V1)

There are several sources that have this issue (this is from a successful x86 build):
```
./tensorflow/core/kernels/_objs/mkl_transpose_op/mkl_transpose_op.pic.d:3: external/mkl_linux/include/mkl_trans.h \
./tensorflow/core/kernels/_objs/mkl_transpose_op/mkl_transpose_op.pic.d:5: external/mkl_linux/include/mkl_types.h \
./tensorflow/core/kernels/_objs/mkl_batch_matmul_op/mkl_batch_matmul_op.pic.d:51: external/mkl_linux/include/mkl_cblas.h \
./tensorflow/core/kernels/_objs/mkl_batch_matmul_op/mkl_batch_matmul_op.pic.d:52: external/mkl_linux/include/mkl_types.h \
./tensorflow/core/common_runtime/_objs/mkl_cpu_allocator/mkl_cpu_allocator.pic.d:623: external/mkl_linux/include/i_malloc.h
./tensorflow/core/common_runtime/_objs/threadpool_device/threadpool_device.pic.d:718: tensorflow/core/lib/core/bits.h external/mkl_linux/include/i_malloc.h \ 
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
bazel build --config=v2 --config=mkl  \
    --copt=""-mtune=native"" --copt=""-march=armv8-a"" --copt=""-O3"" --copt=""-fopenmp"" \
    --cxxopt=""-mtune=native"" --cxxopt=""-march=armv8-a"" --cxxopt=""-O3"" --cxxopt=""-fopenmp"" \
    --linkopt=""-lm"" --linkopt=""-fopenmp"" \
    --config=noaws  --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" \
    //tensorflow/tools/pip_package:build_pip_package
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40768,Got OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function when writing custom layer.,"I wrote the following custom layer
```python
'''
Divide every 656 input vector into a group, get an output vector for each group
Input: 1) Output of sentence encoder (None, 152 * 656, 100)
       2) The concatenated user vector width dimension (100)
Output: Dimension (152, 100)
'''
class SentenceToDocument(Layer):

    def __init__(self, sentence_number, units=SENTENCE_MEM_DIM, **kwargs):
        super(SentenceToDocument, self).__init__(**kwargs)
        self.sentence_number = sentence_number
        self.units = units

    def build(self, input_shape):
        self.vw = self.add_weight(
            shape=(self.units, 1),
            initializer=""random_normal"",
            trainable=True
        )
        self.wh = self.add_weight(
            shape=(self.units, 100),
            initializer=""random_normal"",
            trainable=True
        )
        self.wu = self.add_weight(
            shape=(self.units, 100),
            initializer=""random_normal"",
            trainable=True
        )
        self.bw = self.add_weight(
            shape=(self.units, 1),
            initializer=""random_normal"",
            trainable=True
        )

    def call(self, inputs):
        res = tf.TensorArray(tf.float32, size=0, dynamic_size=True)
        for idx, v in inputs[0]:
            sentence_output = v
            user_vec = inputs[1][idx]
            section_size = inputs[0].shape[1] // self.sentence_number
            sentences = [sentence_output[i*section_size:(i+1)*section_size] for i in range(self.sentence_number)]
            res_per_sen = tf.TensorArray(tf.float32, size=0, dynamic_size=True)
            for sentence in sentences:
                e = []
                u = user_vec
                for word in sentence:
                    word = tf.reshape(word, (-1, 1))
                    u = tf.reshape(u, (-1, 1))
                    wh = tf.matmul(self.wh, word)
                    wu = tf.matmul(self.wu, u)
                    tan = tf.tanh(wh + wu + self.bw)
                    e.append(tf.matmul(tf.transpose(self.vw), tan))
                sum_e = sum([tf.exp(i) for i in e])
                alpha = [tf.exp(i) / sum_e for i in e]
                s = tf.TensorArray(tf.float32, size=0, dynamic_size=True)
                for i in sentence.shape[0]:
                    s.write(s.size(), alpha[i] * sentence[i])
                res_per_sen.write(res_per_sen.size(), s.stack())
            res.write(res.size(), res_per_sen)
        return res.stack()
```

I was using this layer in the middle of my model, it accepts two inputs, as described in the comment. For each data within the batch, it is supposed to first divide the data into several groups, then do some operations together with u with is another input, and the number of u is the same to the number of he groups. I thought it will output tensor with dimension (None, 152, 100), but I got the error below. I'm using tf-nightly and python 3.7.7 and Anaconda.

```
Traceback (most recent call last):
  File ""C:\Users\*****\Anaconda3\envs\night\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 1107, in _functional_construction_call
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""C:\Users\*****\Anaconda3\envs\night\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 258, in wrapper
    raise e.ag_error_metadata.to_exception(e)
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: in user code:

    main.py:132 call  *
        for idx, v in inputs[0]:
    C:\Users\*****\Anaconda3\envs\night\lib\site-packages\tensorflow\python\framework\ops.py:503 __iter__
        self._disallow_iteration()
    C:\Users\*****\Anaconda3\envs\night\lib\site-packages\tensorflow\python\framework\ops.py:499 _disallow_iteration
        self._disallow_in_graph_mode(""iterating over `tf.Tensor`"")
    C:\Users\*****\Anaconda3\envs\night\lib\site-packages\tensorflow\python\framework\ops.py:479 _disallow_in_graph_mode
        "" this function with @tf.function."".format(task))

    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""main.py"", line 286, in <module>
    user_sentence_output = SentenceToDocument(max_sentence)([c1, con_user_vec])
  File ""C:\Users\*****\Anaconda3\envs\night\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 926, in __call__
    input_list)
  File ""C:\Users\*****\Anaconda3\envs\night\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 1114, in _functional_construction_call
    '\n""""""')
TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.
Encountered error:
""""""
in user code:

    main.py:132 call  *
        for idx, v in inputs[0]:
    C:\Users\*****\Anaconda3\envs\night\lib\site-packages\tensorflow\python\framework\ops.py:503 __iter__
        self._disallow_iteration()
    C:\Users\*****\Anaconda3\envs\night\lib\site-packages\tensorflow\python\framework\ops.py:499 _disallow_iteration
        self._disallow_in_graph_mode(""iterating over `tf.Tensor`"")
    C:\Users\*****\Anaconda3\envs\night\lib\site-packages\tensorflow\python\framework\ops.py:479 _disallow_in_graph_mode
        "" this function with @tf.function."".format(task))

    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.

""""""
```"
40767,How to use both CPU and GPU for training in distributed training,"Hi, I'd like to know how to use both CPU and GPU for training, this is how my solution looks like, but it only uses the GPU.

strategy = tf.distribute.MirroredStrategy(devices=['CPU', 'DML'])

If I do,

with tf.device('CPU'):
    model.fit(....)

This uses the CPU, how can I use both to speed up things a little."
40766,Cannot run .py file,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Windows 10)**:
-  **TensorFlow installed from (source)**:
-   **TensorFlow version (3.6)**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version 9**:
-   **GPU model and memory nvidia gtx 1050 ti 4gb**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

C:\Users\marea\Desktop\Things\Practica\COD\ImageProcessing>python ""ImageProcessing.py""
Traceback (most recent call last):
  File ""ImageProcessing.py"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\marea\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 27, in <module>
    from tensorflow._api.v2 import audio
  File ""C:\Users\marea\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\_api\v2\audio\__init__.py"", line 8, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\marea\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""C:\Users\marea\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\core\framework\graph_pb2.py"", line 6, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""C:\Users\marea\AppData\Local\Programs\Python\Python36\lib\site-packages\google\protobuf\descriptor.py"", line 48, in <module>
    from google.protobuf.pyext import _message
ImportError: DLL load failed: The specified procedure could not be found."
40764,how to convert frozen graph (.pb and .pbtxt) model into quantized edge.tflite model ,"I have created one object detection model (.pb and .pbtxt) using 'faster_rcnn_inception_v2_coco_2018_01_28' model I found from TensorFlow zoo. It works fine on windows but I want to use this model on google coral edge TPU. How can I convert my frozen model into edgetpu.tflite quantized model? 
"
40762,"tfcompile  --target_triple=""armv7em-none-eabi"" calling wrong libraries","I found a bug inside tfcompile especially if your compiling for ARM embedded devices the  --target_triple=""armv7em-none-eabi"" is calling incorrect functions when compiling. This should be compatible with arm-none-eabi-gcc libraries and one example is libgcc.a in the none-eabi version it does not have a function called __multi3 however in every other version such as gnu and linux its availble. So when tfcompile generates the files the compiler can not find the function __multi3.

Is there a possible work around to this?

**System information**
- OS Platform and Distribution ( Linux Ubuntu 18):
- TensorFlow installed from (source):
- TensorFlow version (1.5 > ):
- Python version: 3.6
- Bazel version (0.10 > ):
- GCC/Compiler version (if compiling from source):
"
40760,CUDA_ERROR_OUT_OF_MEMORY when converting model to tflite with the new experimental converter,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Scientific Linux 7.6, Nitrogen
- TensorFlow installed from (source or binary): anaconda
- TensorFlow version (or github SHA if from source): 2.2.0


**Command used to run the converter or code if youre using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Convert the model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()```

**The output from the converter invocation**

```
---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-17-1cbca637a6c6> in <module>
      2 converter = tf.lite.TFLiteConverter.from_keras_model(model)
      3 # converter.experimental_new_converter = False
----> 4 tflite_model = converter.convert()
      5 
      6 # # Save the TF Lite model.

~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)
    516         input_tensors=input_tensors,
    517         output_tensors=output_tensors,
--> 518         **converter_kwargs)
    519 
    520     if self._is_calibration_quantize():

~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    494       input_data.SerializeToString(),
    495       debug_info_str=debug_info_str,
--> 496       enable_mlir_converter=enable_mlir_converter)
    497   return data
    498 

~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    225       stdout = _try_convert_to_unicode(stdout)
    226       stderr = _try_convert_to_unicode(stderr)
--> 227       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    228   finally:
    229     # Must manually cleanup files.

ConverterError: See console for info.
2020-06-24 13:49:09.713424: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.
2020-06-24 13:49:09.713504: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.
2020-06-24 13:49:09.727632: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-06-24 13:49:09.733205: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3000000000 Hz
2020-06-24 13:49:09.734188: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558fe1a42f80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-24 13:49:09.734222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-24 13:49:09.735171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-24 13:49:09.741175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 13:49:09.742017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s
2020-06-24 13:49:09.742210: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-24 13:49:09.744013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-24 13:49:09.745773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-24 13:49:09.746089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-24 13:49:09.748160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-24 13:49:09.749163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-24 13:49:09.753168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-24 13:49:09.753338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 13:49:09.753698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 13:49:09.754068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-24 13:49:09.754113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-24 13:49:09.801823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-24 13:49:09.801860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-06-24 13:49:09.801898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-06-24 13:49:09.802119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 13:49:09.802588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 13:49:09.802907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 13:49:09.803250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-06-24 13:49:09.805103: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558fe25c8fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-24 13:49:09.805141: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060 6GB, Compute Capability 6.1
2020-06-24 13:49:09.807773: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 11.81M (12386304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.808353: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 10.63M (11147776 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.808846: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 9.57M (10033152 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.809396: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 8.61M (9029888 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.809879: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 7.75M (8126976 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.810419: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 6.98M (7314432 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.810917: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 6.28M (6583040 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.813411: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: out of memory
Fatal Python error: Aborted

Current thread 0x00007fe187194740 (most recent call first):
  File ""/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 56 in execute
  File ""/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/absl/app.py"", line 250 in _run_main
  File ""/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/absl/app.py"", line 299 in run
  File ""/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40 in run
  File ""/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 93 in main
  File ""/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/bin/toco_from_protos"", line 11 in <module>```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
The conversion is not successful and returns CUDA_ERROR_OUT_OF_MEMORY. However, if I set the experimental_new_converter flag to False, it works.

**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40758,Apparent memory leak when using multiple input tensors with Go,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04, 20.04, Mac OS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Nop
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0.1, 2.2. Bug also present in the master branch.
- Python version: Not using python.
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: not using
- GPU model and memory: not using

**Describe the current behaviour**
When serving a model using Go and CPUs where the model has multiple input tensors, memory usage goes up until we run out and restart. The leak is in 'C' memory, not the Go heap.

**Describe the expected behaviour**
Memory usage does not increase

**Standalone code to reproduce the issue**

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

There's an apparent C memory leak serving models with Go & CPUs if you use multiple input tensors and use Session.Run. It isn't in fact a ""leak"" - the executors_ hashmap in tensorflow::DirectSession just grows very large. This is caused by an unfortunate interaction between Go's random map iteration and the keys generated for this hashmap in DirectSession::GetOrCreateExecutor.

The Go session.Run interface takes a map[tf.Output]*tf.Tensor to describe the input tensors. From this the Go TF code extracts a list of input tensor operations. Since in Go map iteration order is random, the order of this list is random and likely changes every time. The session converts this to a list of input names, which remains in random order. When we reach DirectSession:GetOrCreateExecutor the key for the executor cache is partially built from this randomly ordered list of names. 

GetOrCreateExecutor actually builds two keys: one in the supplied order and then one in sorted order. Both are kept in the executors_ hashmap. The unsorted version is present as a performance improvement.

The number of possible unique keys generated from n randomly ordered names is n! In my case I have 23 inputs, so 23 names and 23! possibilities. 23! is  approximately 2.58 * 10^22. We rapidly run out of memory storing these unsorted keys.

I think the fix will be to order the inputs in the Go code (in newCRunArgs). I'm planning to submit a PR with a fix along these lines.

"
40757,Memory leak in macOS Catalina 10.15,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  macOS Catalina 10.15.5
- TensorFlow installed from (source or binary): from conda install
- TensorFlow version (use command below):  1.15
- Python version: 3.7.6

**Describe the current behavior**

When I run a tensorflow code on my Macbook, the memory usage keeps rising. Then I tried the following::
-I simplified the code to the following form and still can reproduce the problem.
-I found that this problem occurs only when running train_op. So I attempt to change the ""sigmoid_cross_entropy_with_logits"" to ""softmax_cross_entropy_with_logits"", the memory leak disappeared. I dont know why.
-I ran this code in the Windows 10 and docker. And the memory leak also disappeared.

The activity monitor shows that the memory usage, and it continues to grow (most of them are swap).
![123](https://user-images.githubusercontent.com/12993399/85534520-fc4a1900-b643-11ea-8968-5d5242e83cc2.png)


**Standalone code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf
from tqdm import tqdm

data_x = np.array([[72, 20], [16, 20]], dtype=np.int32)
data_y = np.array([[0], [1]])

x = tf.placeholder(tf.float32, [2, 2], name='x')
y = tf.placeholder(tf.float32, [2, 1], name='y')

outputs = tf.layers.dense(x, 1, use_bias=True)

# loss = tf.reduce_mean(tf.pow(y - outputs, 2))
loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=outputs))    #softmax_cross_entropy_with_logits
train_op = tf.train.AdamOptimizer(0.001).minimize(loss)
init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    for i in tqdm(range(10000000)):
        sess.run([loss, train_op], feed_dict={x: data_x, y: data_y})
```

"
40755,Mapping a function on dataset is very slow compared to one-by-one application in a loop,"**System information**
- I have written custom code
- OS - Linux Ubuntu 20.04 LTS
- TensorFlow installed by pip (inside venv)
- TensorFlow version = 2.2.0
- Python version = 3.8.2
- CUDA Version = 10.2 
- GPU model = NVIDIA GeForce GTX 1080, memory = 11175MiB

**Describe the current behavior**

I have a tf.data.Dataset object build of _tensor slices_ . I'm applying some computation on this dataset, call it ``compute``,  using the ``map`` functionality of tf.data.Dataset. Unrolling the result of this mapping, i.e. iterating over the elements of the mapped dataset, takes considerably longer than a simple looping over the tensors and applying the ``compute`` one-by-one on each tensor. Here is a code to reproduce the issue. 

**Standalone code to reproduce the issue**

The code below is stored in a file called ``test.py``.
```python
import tensorflow as tf

class Test:
    def __init__(self):
        gpus = tf.config.experimental.list_physical_devices('GPU')
        if gpus:
            tf.config.experimental.set_memory_growth(gpus[0], True)

    @tf.function
    def compute(self, tensor):
        # some dummy computation with a tensor
        print('python.print ===> tracing compute ... ')

        res = 100*tensor
        res = tf.signal.rfft(res)  # perform some computationally heavy task

        return res

    def test_on_ds(self, N):
        # apply self.compute on a dataset made of N random tensors of length 10000

        tensors = tf.random.uniform(shape=[N, 10000], dtype=tf.float32)
        ds      = tf.data.Dataset.from_tensor_slices(tensors)

        t1 = tf.timestamp()
        count  = tf.constant(0, dtype=tf.int32)

        ds1 = ds.map(self.compute)
        for tensor in ds1:
            count += 1

        t2 = tf.timestamp()
        tf.print('time elapsed=', t2 - t1 )

        return t2 - t1

    def test_on_tensors(self, N):
        # apply self.compute on a N random tensors of length 10000

        tensors = tf.random.uniform(shape=[N, 10000], dtype=tf.float32)

        t1 = tf.timestamp()
        count  = tf.constant(0, dtype=tf.int32)

        for i in tf.range(N):
            x = self.compute( tensors[i] )
            count += 1

        t2 = tf.timestamp()
        tf.print('time elapsed=', t2 - t1 )

        return t2 - t1
```

**Logs** 

Let us now run the above code.

```python

import tensorflow as tf
import test

T = test.Test()

a = []
for _ in range(10):
    a.append( T.test_on_ds(100) )

# the result of tf.print

# time elapsed= 1.0664479732513428
# time elapsed= 1.063709020614624
# time elapsed= 1.0634510517120361
# time elapsed= 1.0631310939788818
# time elapsed= 1.0632259845733643
# time elapsed= 1.0634918212890625
# time elapsed= 1.0678679943084717
# time elapsed= 1.0707681179046631
# time elapsed= 1.0651659965515137
# time elapsed= 1.0619449615478516

# average runtime ~ 1.06 sec

b = [] 
for _ in range(10):
    b.append(T.test_on_tensors(100))

# the result of tf.print

# time elapsed= 0.04901123046875
# time elapsed= 0.04906916618347168
# time elapsed= 0.049163103103637695
# time elapsed= 0.049206018447875977
# time elapsed= 0.05437779426574707
# time elapsed= 0.053722143173217773
# time elapsed= 0.053966999053955078
# time elapsed= 0.053440093994140625
# time elapsed= 0.053852081298828125
# time elapsed= 0.054525852203369141

# average runtime ~ 0.05 sec

```

"
40754,model.fit taking 30 minutes to set-up but only 3ms to run an epoch,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
-Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
-OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux ubuntu 20.04 LTS
-Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
-TensorFlow installed from (source or binary): via pip3
-TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
-Python version: 3.8.2
-Bazel version (if compiling from source): N/A
-GCC/Compiler version (if compiling from source): N/A
-CUDA/cuDNN version: 10.1
-GPU model and memory: GeForce RTX 2070 8gb

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

When running model.fit it takes around 30 minutes each epoch before the progress bar shows up. the actual step then takes around 3ms to complete. is there any way to speed this up? and what is happening during these 30 minutes? I'm using Jupyter Notebook to run the code.

**Describe the expected behavior**

Not letting model.fit take 30 minutes per epoch.

**Standalone code to reproduce the issue**
```
import matplotlib.pyplot as plt
 import numpy as np
 import pandas as pd
 from sklearn.model_selection import train_test_split

 import tensorflow as tf

 from tensorflow.keras import layers

 from tensorflow.keras import Model
 from tensorflow.keras.models import *
 from tensorflow.keras.layers import *
 from tensorflow.keras.callbacks import *
 from tensorflow.keras.optimizers import *
 from tensorflow.keras.utils import to_categorical, plot_model
 dataset_controller = pd.read_csv(""data_template_braincap.csv"")
 randomint = round((len(dataset_controller.index) * 0.8))
 randomint2 = round(len(dataset_controller.index) - randomint)
 train=dataset_controller.head(randomint)
 test=dataset_controller.tail(randomint2)
 X_train = train.drop(['actual time', 'timestamp bci', 'timestamp controller', 'left stick x:', 'left stick y:', 'right stick x:', 'right stick y:', 'a:', 'b:', 'x:', 'y:', 'right trigger:'], axis = 1)
 y_train = train['a:']
 X_test = test.drop(['actual time', 'timestamp bci', 'timestamp controller', 'left stick x:', 'left stick y:', 'right stick x:', 'right stick y:', 'a:', 'b:', 'x:', 'y:', 'right trigger:'], axis = 1)
 y_test = test['a:']


 y_train = y_train.head(len(y_train)-256)

 y_train = y_train.values.reshape((1, len(y_train), 1))
 X_train = X_train.shift(periods=-256, fill_value=0)
 X_train = X_train.head(len(X_train)-256)
 X_train = X_train.values.reshape((1, len(X_train), 19))
 model = tf.keras.Sequential()
 model.add((layers.SimpleRNN(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False)))
 model.add(Dropout(0.3))
 model.add(Dense(1024))
 model.add(Dense(1024))
 model.add(Dense(1024))
 model.add(Dense(1))
 model.compile(optimizer=""adam"", loss=""mean_squared_error"")
 model.summary()
 model.fit(X_train, y_train, epochs=500, batch_size=2048)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

the dataset has 31 columns and 339972 rows. the first 5 rows look like this:
```
0,44295.68,15337.95,-187500.02,-187500.02,-56777.86,-41605.74,-73884.49,-78516.45,-187500.02,6256.72,-187500.02,-64932.48,-53366.2,-59987.21,-187500.02,-24877.74,0.0,0.0,0.0,14:08:15.156,1591358895156,1591358895164,0,12,0,0,0,0,0,0,0
1,43882.2,14582.72,-187500.02,-187500.02,-57811.38,-43702.24,-74505.63,-79345.52,-187500.02,-17205.57,-187500.02,-62077.83,-52917.82,-57371.2,-187500.02,-32231.13,0.02,0.972,0.168,14:08:15.214,1591358895214,1591358895172,0,12,0,0,0,0,0,0,0
2,44356.3,15663.66,-187500.02,-187500.02,-55410.51,-41974.36,-72097.02,-76903.34,-187500.02,-2991.58,-187500.02,-63242.92,-52042.46,-58320.08,-187500.02,-29449.72,0.0,0.0,0.0,14:08:15.214,1591358895214,1591358895180,0,12,0,0,0,0,0,0,0
3,43967.04,14665.94,-187500.02,-187500.02,-58229.8,-42705.06,-75319.74,-80001.02,-187500.02,-3170.95,-187500.02,-64025.45,-53815.11,-59228.72,-187500.02,-26920.17,0.0,0.0,0.0,14:08:15.214,1591358895214,1591358895188,0,12,0,0,0,0,0,0,0
4,44212.8,15311.93,-187500.02,-187500.02,-55950.53,-43095.84,-72422.33,-77356.32,-187500.02,-15505.09,-187500.02,-61992.98,-51984.52,-57185.35,-187500.02,-33186.15,0.0,0.0,0.0,14:08:15.214,1591358895214,1591358895196,0,9,0,0,0,0,0,0,0 
```
Keras output during model.fit:
```
Epoch 1/500
1/1 [==============================] - 0s 3ms/step - loss: 0.3895
Epoch 2/500
1/1 [==============================] - 0s 4ms/step - loss: 232.1620
Epoch 3/500
1/1 [==============================] - 0s 4ms/step - loss: 20.5877
Epoch 4/500
1/1 [==============================] - 0s 3ms/step - loss: 51.7856
```

"
40753,[TF2.2] Saving checkpoint failed when there is `dataset.shuffle` in dataset flow. ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:  v2.2.0-rc4-8-g2b96f3662b 2.2.0


**Describe the current behavior**
I follow the **[guide](https://www.tensorflow.org/guide/data)** to do checkpoint.
When there is `dataset.shuffle`, Saving checkpoint failed with the following information.
```
tensorflow.python.framework.errors_impl.FailedPreconditionError: ShuffleDatasetOp(4)::ReshufflingDataset depends on random seed generator resource. [Op:SerializeIterator]
```

**Describe the expected behavior**

**Standalone code to reproduce the issue**
```
import tensorflow as tf

class Net(tf.keras.Model):
  """"""A simple linear model.""""""

  def __init__(self):
    super(Net, self).__init__()
    self.l1 = tf.keras.layers.Dense(5)

  def call(self, x):
    return self.l1(x)
  
def toy_dataset():
  inputs = tf.range(10.)[:, None]
  labels = inputs * 5. + tf.range(5.)[None, :]

  dataset = tf.data.Dataset.from_tensor_slices(
    dict(x=inputs, y=labels)).repeat()
  dataset = dataset.shuffle(4).batch(2)
  return dataset

net = Net()

def train_step(net, example, optimizer):
  """"""Trains `net` on `example` using `optimizer`.""""""
  with tf.GradientTape() as tape:
    output = net(example['x'])
    loss = tf.reduce_mean(tf.abs(output - example['y']))
  variables = net.trainable_variables
  gradients = tape.gradient(loss, variables)
  optimizer.apply_gradients(zip(gradients, variables))
  return loss
  

opt = tf.keras.optimizers.Adam(0.1)
dataset = toy_dataset()
iterator = iter(dataset)
ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)
manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)

def train_and_checkpoint(net, manager):
  ckpt.restore(manager.latest_checkpoint)
  if manager.latest_checkpoint:
    print(""Restored from {}"".format(manager.latest_checkpoint))
  else:
    print(""Initializing from scratch."")

  for _ in range(50):
    example = next(iterator)
    loss = train_step(net, example, opt)
    ckpt.step.assign_add(1)
    if int(ckpt.step) % 10 == 0:
      save_path = manager.save()
      print(""Saved checkpoint for step {}: {}"".format(int(ckpt.step), save_path))
      print(""loss {:1.2f}"".format(loss.numpy()))
      
train_and_checkpoint(net, manager)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached."
40751,Tensorflow-rocm GPU useage confirmation,"**System information**
- OS Platform and Distribution : Linux Ubuntu 20.04 LTS
- TensorFlow installed from (source or binary): tensorflow-rocm
- TensorFlow version: 2.2.0
- Python version: 3.8
- Installed using virtualenv? pip? conda?: pip3
- Rocm version: 3.5.1
- GPU model and memory: RX580



**The problem**
while importing the tensorflow api module there is no issue but while im trying to confirm that its running on gpu
with the following code : ```print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))```
the issue pops up


**logs**
```
2020-06-24 14:42:51.220457: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libhip_hcc.so'; dlerror: libhip_hcc.so: cannot open shared object file: No such file or directory
2020-06-24 14:42:51.220491: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Failed precondition: Could not load dynamic library 'libhip_hcc.so'; dlerror: libhip_hcc.so: cannot open shared object file: No such file or directory
Aborted (core dumped)
```
**Additional Info**
I have setup the tensorflow-rocm with the following commands :
```
sudo apt install libnuma-dev
wget -q -O - http://repo.radeon.com/rocm/apt/debian/rocm.gpg.key | sudo apt-key add -
echo 'deb [arch=amd64] http://repo.radeon.com/rocm/apt/debian/ xenial main' | sudo tee /etc/apt/sources.list.d/rocm.list
sudo apt install rocm-dkms
sudo usermod -a -G video $LOGNAME
echo 'export PATH=$PATH:/opt/rocm/bin:/opt/rocm/profiler/bin:/opt/rocm/opencl/bin' | sudo tee -a /etc/profile.d/rocm.sh
sudo apt install rocm-libs miopen-hip rccl
pip3 install tensorflow-rocm
```"
40750,Failed to get convolution algorithm. This is probably because cuDNN failed to initialize,"Tensorflow version 2.2.0
Tensorlow nightly installed
Tensorflow nighlty-gpu installed

conda list cudnn gives
version 7.6.5 build         cuda10.1_0

nvidia-smi reports 
driver version 446.14     cuda version 11.0

Nvidia 1660TI graphica card.  
Windows 10 Pro 64 bit.

the version numbers should be ok as per the Tensorflow webside https://www.tensorflow.org/install/gpu

Code to train model and use callbacks.  The error is much worse when i use verbose=1, so changed to verbose =10 as per suggestion from previous run error message.
```
log_dir = ""logs/fit/"" + datetime.datetime.now().strftime(""%Y%m%d-%H%M"")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, 
                                                      histogram_freq=1,
                                                      write_images=True,
                                                      update_freq = 'batch')


print(datetime.datetime.now().strftime(""%Y%m%d-%H:%M""))
history = model.fit(
        train_data_gen,
        batch_size = BATCH_SIZE,
        epochs=EPOCHS,
        verbose = 10,
        validation_data=val_data_gen,
        callbacks = tensorboard_callback)

print(datetime.datetime.now().strftime(""%Y%m%d-%H:%M""))
```

ERROR Message
20200624-10:18
Epoch 1/25
Traceback (most recent call last):

  File ""<ipython-input-9-127169b78b1e>"", line 15, in <module>
    callbacks = tensorboard_callback)

  File ""C:\Users\cilli\anaconda3\envs\project\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)

  File ""C:\Users\cilli\anaconda3\envs\project\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 848, in fit
    tmp_logs = train_function(iterator)

  File ""C:\Users\cilli\anaconda3\envs\project\lib\site-packages\tensorflow\python\eager\def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)

  File ""C:\Users\cilli\anaconda3\envs\project\lib\site-packages\tensorflow\python\eager\def_function.py"", line 611, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable

  File ""C:\Users\cilli\anaconda3\envs\project\lib\site-packages\tensorflow\python\eager\function.py"", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access

  File ""C:\Users\cilli\anaconda3\envs\project\lib\site-packages\tensorflow\python\eager\function.py"", line 1665, in _filtered_call
    self.captured_inputs)

  File ""C:\Users\cilli\anaconda3\envs\project\lib\site-packages\tensorflow\python\eager\function.py"", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))

  File ""C:\Users\cilli\anaconda3\envs\project\lib\site-packages\tensorflow\python\eager\function.py"", line 598, in call
    ctx=ctx)

  File ""C:\Users\cilli\anaconda3\envs\project\lib\site-packages\tensorflow\python\eager\execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)

UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node resnet50/conv1_conv/Conv2D (defined at <ipython-input-3-0d7d4ce5ce9a>:8) ]] [Op:__inference_train_function_17457]

Function call stack:
train_function"
40748,"Gradient calculation of tf.reduce_prod runs in CPU, inducing performance impact","<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): _Yes_
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): _Ubuntu 19.04_
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: _No_
- TensorFlow installed from (source or binary): _binary_
- TensorFlow version (use command below): _2.2.0_
- Python version: _3.7.7_
- Bazel version (if compiling from source): _N/A_
- GCC/Compiler version (if compiling from source): _N/A_
- CUDA/cuDNN version: _CUDA Version 10.2.89_
- GPU model and memory: _GeForce RTX 2080 8G_

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Gradient of tf.reduce_prod() runs in CPU instead of GPU, which induces lots of memcopy between GPU & CPU as shown in profiler, and slows down entire training / prediction process as GPU & CPU ops interleaves (Kernel Launch Time would dominate in the profiler report).
Pertinent code can be found [here](https://github.com/tensorflow/tensorflow/blob/4f341bb742718721563ce6dccb965c85a1fbdcf5/tensorflow/python/ops/math_grad.py#L270)

**Describe the expected behavior**
Expect the gradient to be calculated in GPU and streamline the whole process (especially in a typical RNN while loop)

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
_To be provided_

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
_To be provided_"
40747,kronecker product,Doesn't it have a function of kronecker product like np.kron in numpy?
40746,kronecker product,Doesn't it have a function of kronecker  product like np.kron in numpy?
40743,keras.Model using EmbeddingColumn with pre-trained ckpt fail to be reconstructed without the original ckpt,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pre-installed in Colab
- TensorFlow version (use command below): v2.2.0-0-g2b96f3662b
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:

**Describe the current behavior**
`keras.Model` using `EmbeddingColumn` with pre-trained checkpoint in a `DenseFeatures` layer, after exported to `SavedModel`, cannot be reconstructed without the original embedding checkpoint.

**Describe the expected behavior**
`SavedModel` exported from `keras.Model` should be fully self-contained and be able to be reconstructed from solely the saved model directory for the sake of portability.

**Standalone code to reproduce the issue**
```
import shutil

import numpy as np
import tensorflow as tf

# build and checkpoint mock pre-trained embeddings
EMBD_INPUT_DIM = 1000
EMBD_OUTPUT_DIM = 64

mock_pretrained_embd = tf.Variable(tf.initializers.GlorotNormal()(shape=(EMBD_INPUT_DIM, EMBD_OUTPUT_DIM)), trainable=True)

ckpt = tf.train.Checkpoint(embeddings=mock_pretrained_embd)
ckpt.write('ckpt/mock_embd_ckpt')

# build keras.Model using EmbeddingColumn in DenseFeatures layer
embd_column = tf.feature_column.embedding_column(
    tf.feature_column.categorical_column_with_identity(key='id', num_buckets=EMBD_INPUT_DIM),
    dimension=EMBD_OUTPUT_DIM,
    ckpt_to_load_from='ckpt/mock_embd_ckpt',
    tensor_name_in_ckpt='embeddings/.ATTRIBUTES/VARIABLE_VALUE',
    trainable=True
)
features_layer = tf.keras.layers.DenseFeatures([embd_column])

x = {'id': tf.keras.Input(shape=(None,), dtype=tf.int64, name='id')}
y = features_layer(x)
y = tf.keras.layers.Dense(1, name='out')(y)
model = tf.keras.Model(inputs=x, outputs=y)
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam())

# fit model on mock data to have embeddings updated
TRAIN_BATCH = 64

id_len = np.random.randint(low=0, high=15)
x = {'id': tf.convert_to_tensor(np.random.randint(low=0, high=EMBD_OUTPUT_DIM+1, size=(TRAIN_BATCH, id_len)))}
y = tf.convert_to_tensor(np.random.randint(low=0, high=2, size=(TRAIN_BATCH, 1)), tf.float32)

for i in range(100):
  model.train_on_batch(x=x, y=y)

# export model
model.save('mock_model')

# re-construct keras.Model & SavedModel and invoke on mock data
TEST_INPUT_BATCH = 10
TEST_INPUT_ID_LEN = 5

test_inputs = {'id': tf.random.uniform((TEST_INPUT_BATCH, TEST_INPUT_ID_LEN), minval=0, maxval=EMBD_INPUT_DIM, dtype=tf.int64)}

loaded_keras_model = tf.keras.models.load_model('mock_model')
loaded_keras_model(test_inputs)

loaded_model = tf.saved_model.load('mock_model')
serving_default_fn = loaded_model.signatures['serving_default']
serving_default_fn(**test_inputs)

# remove original embeddings checkpoint and try invoking on mock data again
shutil.rmtree('ckpt')

loaded_keras_model(test_inputs)
serving_default_fn(**test_inputs)
```

**Other info / logs**
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-217-d8ce0286d803> in <module>()
     58 shutil.rmtree('ckpt')
     59 
---> 60 loaded_keras_model(test_inputs)
     61 serving_default_fn(**test_inputs)

15 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    966           with base_layer_utils.autocast_context_manager(
    967               self._compute_dtype):
--> 968             outputs = self.call(cast_inputs, *args, **kwargs)
    969           self._handle_activity_regularization(inputs, outputs)
    970           self._set_mask_metadata(inputs, outputs, input_masks)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py in call(self, inputs, training, mask)
    717     return self._run_internal_graph(
    718         inputs, training=training, mask=mask,
--> 719         convert_kwargs_to_constants=base_layer_utils.call_context().saving)
    720 
    721   def compute_output_shape(self, input_shape):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants)
    886 
    887           # Compute outputs.
--> 888           output_tensors = layer(computed_tensors, **kwargs)
    889 
    890           # Update tensor_dict.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    966           with base_layer_utils.autocast_context_manager(
    967               self._compute_dtype):
--> 968             outputs = self.call(cast_inputs, *args, **kwargs)
    969           self._handle_activity_regularization(inputs, outputs)
    970           self._set_mask_metadata(inputs, outputs, input_masks)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/dense_features.py in call(self, features, cols_to_output_tensors)
    143       with ops.name_scope(column.name):
    144         tensor = column.get_dense_tensor(transformation_cache,
--> 145                                          self._state_manager)
    146         processed_tensors = self._process_dense_tensor(column, tensor)
    147         if cols_to_output_tensors is not None:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py in get_dense_tensor(self, transformation_cache, state_manager)
   3275     sparse_tensors = self.categorical_column.get_sparse_tensors(
   3276         transformation_cache, state_manager)
-> 3277     return self._get_dense_tensor_internal(sparse_tensors, state_manager)
   3278 
   3279   @deprecation.deprecated(_FEATURE_COLUMN_DEPRECATION_DATE,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py in _get_dense_tensor_internal(self, sparse_tensors, state_manager)
   3228         self, name='embedding_weights')
   3229     return self._get_dense_tensor_internal_helper(sparse_tensors,
-> 3230                                                   embedding_weights)
   3231 
   3232   def _old_get_dense_tensor_internal(self, sparse_tensors, weight_collections,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py in _get_dense_tensor_internal_helper(self, sparse_tensors, embedding_weights)
   3205         to_restore = to_restore._get_variable_list()  # pylint: disable=protected-access
   3206       checkpoint_utils.init_from_checkpoint(self.ckpt_to_load_from, {
-> 3207           self.tensor_name_in_ckpt: to_restore
   3208       })
   3209 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_utils.py in init_from_checkpoint(ckpt_dir_or_file, assignment_map)
    290   else:
    291     distribution_strategy_context.get_replica_context().merge_call(
--> 292         init_from_checkpoint_fn)
    293 
    294 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in merge_call(self, merge_fn, args, kwargs)
   2418     merge_fn = autograph.tf_convert(
   2419         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)
-> 2420     return self._merge_call(merge_fn, args, kwargs)
   2421 
   2422   def _merge_call(self, merge_fn, args, kwargs):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in _merge_call(self, merge_fn, args, kwargs)
   2425         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access
   2426     try:
-> 2427       return merge_fn(self._strategy, *args, **kwargs)
   2428     finally:
   2429       _pop_per_thread_mode()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    280   def wrapper(*args, **kwargs):
    281     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.UNSPECIFIED):
--> 282       return func(*args, **kwargs)
    283 
    284   if inspect.isfunction(func) or inspect.ismethod(func):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_utils.py in <lambda>(_)
    285   """"""
    286   init_from_checkpoint_fn = lambda _: _init_from_checkpoint(
--> 287       ckpt_dir_or_file, assignment_map)
    288   if distribution_strategy_context.get_cross_replica_context():
    289     init_from_checkpoint_fn(None)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_utils.py in _init_from_checkpoint(ckpt_dir_or_file, assignment_map)
    296   """"""See `init_from_checkpoint` for documentation.""""""
    297   ckpt_file = _get_checkpoint_filename(ckpt_dir_or_file)
--> 298   reader = load_checkpoint(ckpt_dir_or_file)
    299   variable_map = reader.get_variable_to_shape_map()
    300   for tensor_name_in_ckpt, current_var_or_name in sorted(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_utils.py in load_checkpoint(ckpt_dir_or_file)
     65     raise ValueError(""Couldn't find 'checkpoint' file or checkpoints in ""
     66                      ""given directory %s"" % ckpt_dir_or_file)
---> 67   return py_checkpoint_reader.NewCheckpointReader(filename)
     68 
     69 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py in NewCheckpointReader(filepattern)
     93   """"""
     94   try:
---> 95     return CheckpointReader(compat.as_bytes(filepattern))
     96   # TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the
     97   # issue with throwing python exceptions from C++.

ValueError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ckpt/mock_embd_ckpt: Not found: ckpt; No such file or directory
```"
40742,compilation of rule '//tensorflow/python:bfloat16_lib' failed when building TF2.2 from source,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): r2.2.0
- Python version: 3.7.7
- Bazel version (if compiling from source):2.0.0
- GCC/Compiler version (if compiling from source):7.5.0
- CUDA/cuDNN version:10.2
- GPU model and memory: 12

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


I receive an error when build TF2.2 from source. Here's the error message:

> tensorflow/python/lib/core/bfloat16.cc:610:60: note:   no known conversion for argument 2 from <unresolved overloaded function type> to PyUFuncGenericFunction {aka void (*)(char**, const long int*, const long int*, void*)}
> tensorflow/python/lib/core/bfloat16.cc:655:36: error: no match for call to (tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>) (const char [14], <unresolved overloaded function type>, const std::array<int, 3>&)
>                        compare_types)) {
>                                     ^
> tensorflow/python/lib/core/bfloat16.cc:610:60: note: candidate: tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>
>                              const std::array<int, 3>& types) {
>                                                             ^
> tensorflow/python/lib/core/bfloat16.cc:610:60: note:   no known conversion for argument 2 from <unresolved overloaded function type> to PyUFuncGenericFunction {aka void (*)(char**, const long int*, const long int*, void*)}
> Target //tensorflow/tools/pip_package:build_pip_package failed to build
> Use --verbose_failures to see the command lines of failed build steps.
> ERROR: /home/aptx4869/github/tensorflow/tensorflow/python/tools/BUILD:281:1 C++ compilation of rule '//tensorflow/python:bfloat16_lib' failed (Exit 1)
> INFO: Elapsed time: 20.016s, Critical Path: 7.56s
> INFO: 0 processes.
> FAILED: Build did NOT complete successfully

I've taken advice from [this issue](https://github.com/tensorflow/tensorflow/issues/40688?notification_referrer_id=MDE4Ok5vdGlmaWNhdGlvblRocmVhZDk0OTk2NDQwMToxMDE4NDE1Mw%3D%3D#issuecomment-648539630) to downgrade numpy to 1.18.5 but it does not work for me."
40740,"First example in keras guide ""customizing_what_happens_in_fit"" does not work","Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit#a_first_simple_example

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit#a_first_simple_example

## Description of issue (what needs changing):
The First Example doesn't seem to actually call **train_step()**

### Clear description
I have run this example using a debugger, and it does not actually get called
I have tested this with version 2.2.0

### Correct links
I have not been able to find anything that explains how this is supposed to work.

### Parameters defined
N/A

### Returns defined

N/A

### Raises listed and defined

Are the errors defined? For example,
N/A

Is there a usage example?

N/A

### Request visuals, if applicable

N/A
### Submit a pull request?

I can't tell if this should work on not.
"
40738,Convergence issue across Keras 2.2.4 with TF 1.14.0 and Keras 2.3.1 with TF 2.2.0,"**System information**
- I am using the Keras functional API directly (not through tf.keras) 
- OS Platform and Distribution: Ubuntu 19.10 with Kernel 5.3.0-59-generic
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device: It is on PC (HP laptop)
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.7 (default, May  7 2020, 21:25:33)
- Bazel version (if compiling from source): Not compiling from source
- GCC/Compiler version (if compiling from source): Not compiling from source but GCC 7.3.0
- CUDA/cuDNN version: Not using GPU
- GPU model and memory: Not using GPU

**Describe the current behavior**
I have a code that converges on an older version of Keras (2.2.4) while it does not converge on a more recent version (2.3.1).

**Describe the expected behavior**
Convergence is expected to be the same (or at least nearly the same). I expect the validation loss to be approximately the same across different versions of Keras and Tensorflow with the same parameters, model, data, etc.

**Standalone code to reproduce the issue**
https://drive.google.com/file/d/1P6SrCS8HFw2fPYvwrmEuK9tyf6-e5Biv/view?usp=sharing

**PS:**
- I downgraded the Tensorflow on Keras 2.3.1 to TF 1.14.0 so that it would be the same as what it is on my older Keras but did not help with the converges but helped with the speed of training (most probably has to do something with the Eager execution).
- I also tried increasing the epoch, despite the fact that it gets slowly close to the desired loss, still does not get to the same expected loss

In my opinion, there is either a difference in default values across versions. Looking at the API of the methods/functions that I have used from Keras library I do not notice any difference between the default values so it must be something more serious going on."
40735,"NCCL is not supported when using virtual GPUs, fallingback to reduction to one device","Hello,

I tried to run colab notebook present here: https://www.tensorflow.org/guide/gpu.

When I try to use virtual GPU I get NCCL not supported error. can you help on how do I test virtual GPU's in colab?"
40729,Unexpected difference in scatter_nd_update variants,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 (subsystem on Windows)
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.6
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**

This problem (?) was observed for a [unit-test in the RL framework Tensorforce](https://github.com/tensorforce/tensorforce/blob/tf2/test/test_saving.py#L226) when using `tf.saved_model`. When using `variable.scatter_nd_update(indices, updates)`, I get the exception below. When instead using `value = tf.tensor_scatter_nd_update(variable, indices, updates); variable.assign(value)`, everything works well. The assignment happens [here](https://github.com/tensorforce/tensorforce/blob/tf2/tensorforce/core/models/tensorforce.py#L1012).

**Describe the expected behavior**

I would expect that both functions use the same implementation of the `scatter_nd_update` functionality, so I don't understand why one works and the other doesn't.

**Other info / logs**

```
Traceback (most recent call last):
  File ""python3.6/site-packages/tensorflow/python/framework/importer.py"", line 497, in _import_graph_def_internal
    graph._c_graph, serialized, options)  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: The inner -2 dimensions of input.shape=[] must match the inner 1 dimensions of updates.shape=[?,1]: Shapes must be equal rank, but are 0 and 1 for '{{node agent/ResourceScatterNdUpdate}} = ResourceScatterNdUpdate[T=DT_BOOL, Tindices=DT_INT64, _output_shapes=[], use_locking=true](agent_resourcescatterndupdate_ref:0, agent/stack_1:0, args_0:0)' with input shapes: [], [?,2], [?,1].
 
During handling of the above exception, another exception occurred:
 
Traceback (most recent call last):
  Tensorforce/test/test_saving.py"", line 227, in test_explicit
    agent = tf.saved_model.load(export_dir=os.path.join(self.__class__.directory, 'agent-1'))
  File ""python3.6/site-packages/tensorflow/python/saved_model/load.py"", line 578, in load
    return load_internal(export_dir, tags)
  File ""python3.6/site-packages/tensorflow/python/saved_model/load.py"", line 604, in load_internal
    export_dir)
  File ""python3.6/site-packages/tensorflow/python/saved_model/load.py"", line 116, in __init__
    meta_graph.graph_def.library))
  File ""python3.6/site-packages/tensorflow/python/saved_model/function_deserialization.py"", line 311, in load_function_def_library
    func_graph = function_def_lib.function_def_to_graph(copy)
  File ""python3.6/site-packages/tensorflow/python/framework/function_def_to_graph.py"", line 63, in function_def_to_graph
    importer.import_graph_def_for_function(graph_def, name="""")
  File ""python3.6/site-packages/tensorflow/python/framework/importer.py"", line 412, in import_graph_def_for_function
    graph_def, validate_colocation_constraints=False, name=name)
  File ""python3.6/site-packages/tensorflow/python/framework/importer.py"", line 501, in _import_graph_def_internal
    raise ValueError(str(e))
ValueError: The inner -2 dimensions of input.shape=[] must match the inner 1 dimensions of updates.shape=[?,1]: Shapes must be equal rank, but are 0 and 1 for '{{node agent/ResourceScatterNdUpdate}} = ResourceScatterNdUpdate[T=DT_BOOL, Tindices=DT_INT64, _output_shapes=[], use_locking=true](agent_resourcescatterndupdate_ref:0, agent/stack_1:0, args_0:0)' with input shapes: [], [?,2], [?,1].
```
"
40727,tf.nn.ctc_beam_search_decoder does not pick path with highest probability at next time step,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Colab Env (Linux Ubuntu 18.04)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
Binary (I think)
- TensorFlow version (use command below):
v2.2.0-0-g2b96f3662b 2.2.0
- Python version:
3.6.9
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
N/A
- GPU model and memory:
None

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

The built-in CTC beam search decoder sometimes chooses a less probable path to keep in the beam by default than it could've when expanding a given step. In the Colab example provided below, I give a concrete example of when the path (0,) is retained in the beam instead of (0, 1, 0) despite the latter having a greater log-probability.

**Describe the expected behavior**

(0, 1, 0) should remain in the beam; (0,) should not.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/1i9gvj0VN2gMNloohbHW6ad3Ti7eiQQCM?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

When I was comparing against a simple python version [based off this Medium article](https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7), I noticed that whenever the results diverged, the root problem was always that a path that should've been kept in the beam wasn't. I suspect top-k sorting might be mucking up somewhere.

Thanks,
Sean
"
40725,Incorrect documentation for model_from_config ,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/models/model_from_config

## Description of issue (what needs changing):

tf.keras.models.model_from_config function can create only layers, not the complete model as it is described in documentation. Correct usage is mentioned at https://www.tensorflow.org/guide/keras/save_and_serialize, but not described in the main documenation for tf.keras.Model class.

> Calling config = model.get_config() will return a Python dict containing the configuration of the model. The same model can then be reconstructed via Sequential.from_config(config) (for a Sequential model) or Model.from_config(config) (for a Functional API model).

### Clear description
The behavior of tf.keras.models.model_from_config does not correspond to the documentation.
Moreover, it is even more confusing when compared with similar methods, like

`tf.keras.models.model_from_json(model.to_json())`

> <tensorflow.python.keras.engine.training.Model at 0x7fa2e443aa20>

`tf.keras.models.model_from_yaml(model.to_yaml())`

> <tensorflow.python.keras.engine.training.Model at 0x7fa2e443ca40>

while model_from_config 

`tf.keras.models.model_from_config(model.get_config())`

> > ---------------------------------------------------------------------------
> KeyError                                  Traceback (most recent call last)
> <ipython-input-99-f3b4bb685ac8> in <module>
> ----> 1 tf.keras.models.model_from_config(model.get_config())
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/model_config.py in model_from_config(config, custom_objects)
>      53                     '`Sequential.from_config(config)`?')
>      54   from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top
> ---> 55   return deserialize(config, custom_objects=custom_objects)
>      56 
>      57 
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)
>      99   globs['SequenceFeatures'] = sfc.SequenceFeatures
>     100 
> --> 101   layer_class_name = config['class_name']
>     102   if layer_class_name in _DESERIALIZATION_TABLE:
>     103     config['class_name'] = _DESERIALIZATION_TABLE[layer_class_name]
> 
> KeyError: 'class_name'
> 

### Correct usage

`tf.keras.Model().from_config(model.get_config())`

> <tensorflow.python.keras.engine.training.Model at 0x7fa2e4480080>"
40724,Invalid test case from test_zero_padding_2d in convolutional_test.py,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04

**Describe the current behavior**
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/convolutional_test.py#L654 
They try to test on different data_format configurations, ie. `channels_first`, `channels_last`. But for the code in the abovementioned link, it's meaningless, it always takes the last inputs. We should construct the inputs separately under different conditions. Even though it didn't cause any error but it should be fixed.

"
40722,Segmentation fault interpreter->SetNumThreads CPP,"@tensorflow/micro

**System information**
Hardware : Freescale i.MX6 Quad/DualLite
Processor: ARMv7 Processor rev 10 (v71)
OS Platform and Distribution: Yocto built Linux distribution (kernel 4.9.4+)
The tf-lite library was built with common options and using default makefile: https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/lite/tools/make/Makefile
API : CPP

**Describe the problem**
Cross compiling the minimal TF Lite interpreter cpp code where I added the line to set the number of threads to use results in a segmentation error when running the program.

The relevant code : 
```
int main(int argc, char* argv[]) {
  if (argc != 2) {
    fprintf(stderr, ""minimal <tflite model>\n"");
    return 1;
  }
  const char* filename = argv[1];
  int startt, endd;
  startt = clock();

  // Load model
  // Load model
  std::unique_ptr<tflite::FlatBufferModel> model =
      tflite::FlatBufferModel::BuildFromFile(filename);
  TFLITE_MINIMAL_CHECK(model != nullptr);

  // Build the interpreter
  tflite::ops::builtin::BuiltinOpResolver resolver;
  InterpreterBuilder builder(*model, resolver);
  std::unique_ptr<Interpreter> interpreter;
  std::cout << ""allocating one number of threads"" << std::endl;
  int numthreads=1;
  interpreter->SetNumThreads(numthreads);
  std::cout << ""threads allocated"" << std::endl;

  builder(&interpreter);
  TFLITE_MINIMAL_CHECK(interpreter != nullptr);
  endd = clock();

  // Allocate tensor buffers.
  TFLITE_MINIMAL_CHECK(interpreter->AllocateTensors() == kTfLiteOk);
  printf(""=== Pre-invoke Interpreter State ===\n"");
  tflite::PrintInterpreterState(interpreter.get());

  double time_taken = double(endd-startt)/double(CLOCKS_PER_SEC);
  std::cout << ""4 threads should be selected"" << std::endl;
  std::cout << ""Time taken to load in the model in tflite using CPP API :"" << fixed << time_taken << std::setprecision(5);
  std::cout << "" sec "" << std::endl;
}
```

The model I've been using is a custom ENet I trained in TensorFlow and converted to TFLite using both TFLite_builtin_ops and TF_OPS, though I believe the problem has nothing to do with the model itself.

**Please provide the exact sequence of commands/steps when you ran into the problem**
Running gdb and checking the stacktrace results in the following:
![image](https://user-images.githubusercontent.com/29673343/85434212-fee63900-b585-11ea-860f-b3af1b4748bc.png)

I also cross compiled a standard cpp program using multiple threads which runs just fine. So that excludes problems concerning firmware. For the record, the multithreading program I got running is the following : 
```
#include <iostream>
#include <cstdlib>
#include <pthread.h>

using namespace std;

#define NUM_THREADS 4

void *PrintHello(void *threadid) {
   long tid;
   tid = (long)threadid;
   cout << ""Hello World! Thread ID, "" << tid << endl;
   pthread_exit(NULL);
}

int main () {
   pthread_t threads[NUM_THREADS];
   int rc;
   int i;

   for( i = 0; i < NUM_THREADS; i++ ) {
      cout << ""main() : creating thread, "" << i << endl;
      rc = pthread_create(&threads[i], NULL, PrintHello, (void *)i);

      if (rc) {
         cout << ""Error:unable to create thread,"" << rc << endl;
         exit(-1);
      }
   }
   pthread_exit(NULL);
}
```

How do I go about this problem? What is causing this? "
40721,Import .tflite model into Tensorflow graph,"**System information**
- TensorFlow version (you are using): 2.2.0
- Are you willing to contribute it (Yes/No): No (Don't have expertise to do it..)



**Describe the feature and the current behavior/state.**
I'd like to be able to import a .tflite model as a 'node' within a tensorflow graph. This would allow people to download published .tflite models, add pre/post processing nodes to the graph, then re-export the graph to .tflite again. This should allow the user to adapt published models to their use case, moving certain common pre/post processing actions on-GPU or other compute device.

To my knowledge, it is not currently possible to 're-import' a .tflite model into a tensorflow graph.

**Will this change the current api? How?**
Yes, a function will need to be added to tf.Graph to support importation of .tflite files. I could also see a function taking a tf.lite.Interpreter object which has the .tflite model in question loaded.

Concrete suggestions:
* `tf.graph_util.import_tflite(model_path=None)`
* `tf.graph_util.import_tflite(interpreter=None)`

**Who will benefit with this feature?**
All tensorflow-lite users will likely benefit. Folks publishing models will find their models will be easier to use and so more folks will download them. Folks trying to use published models will find they can add additional pre/post processing on-GPU or other compute device, making the published models more easily accessible. In some cases, this can skip re-training complex networks when versions which already work well have been published, but with perhaps not the right expected input dimensions, or not the right output format.

**Any Other info.**
None at this time."
40720,TF Unit test flaky in haswell/broadwell machines,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2
- Python version:  3.7
- Bazel version (if compiling from source):3.1
- GCC/Compiler version (if compiling from source):7.5
- CUDA/cuDNN version:
- GPU model and memory:
-CPUModel : Haswell/Broadwell


**Describe the current behavior**
   _**//tensorflow/core/kernels:sparse_matmul_op_test**_ 
     Is flaky on haswell/broadwell machines (-march=haswell -mtue=broadwell) and fails often (not always). The failure is in vectorization when setting the parameters for the op.

**Describe the expected behavior**

**Standalone code to reproduce the issue**
      //tensorflow/core/kernels:sparse_matmul_op_test
  build and run on broadwell platform. 


**Other info / logs** I
"
40719,"""Cannot find bazel"" return 0 in configure.py","Hello!
In file configure.py inside a function check_bazel_version when bazel is not exists this function returns 0.

Here is a part of code:
  if which('bazel') is None:
    print('Cannot find bazel. Please install bazel.')
    sys.exit(0)

Should be sys.exit(1)? It's an error. "
40717,"Writing custom py_function inside custom layer , gradient backpropagation","Hi , 

I'm writing a custom py_function inside a custom layer. But I get error during gradient backpropagation. I'm using tensorflow 1.1.4 with eager execution enabled. While debugging I reduced the complexity of code, and now 'm just trying 1-d DCT of input. I still get the error. 

Here is my code : 


from scipy.special import expit
from scipy.fftpack import dct, idct
import time

def fdct (a): 
    return dct(a.T, norm='ortho').T

def fdct_top (inp): 
    return tf.convert_to_tensor(np.array([fdct(in_) for in_ in list(inp.numpy())]))
    

def fidct (a): 
    return idct(a.T, norm='ortho').T

def fidct_top (inp): 
    return tf.convert_to_tensor(np.array([fidct(in_) for in_ in list(inp.numpy())]))


    
class MyDenseLayer(tf.keras.layers.Layer):
  def __init__(self, y_mat):
    super(MyDenseLayer, self).__init__()
    self.w_mat = y_mat
    
  def build(self, input_shape):
    self.w = tf.Variable (initial_value = self.w_mat, trainable = True)
  
  def call(self, input):
    dct_i = tf.py_function (fdct_top, (input,), 'float32')
    dct_i.set_shape(tf.TensorShape((None, 10)))
    
    dcts_q = tf.multiply(dct_i, 1/self.w)    
    print(dcts_q)
    z_floored_NOT_differentiable = tf.floor(dcts_q)
    z_floored_differentiable = (dcts_q - (tf.stop_gradient(dcts_q) - z_floored_NOT_differentiable))
    print(z_floored_differentiable)
    dcts_deg = tf.multiply(z_floored_differentiable, tf.cast(self.w, 'float32'))
    
    dcts_deg = tf.py_function (fidct_top, (dcts_deg,), 'float32')
    dcts_deg.set_shape(tf.TensorShape((None, 10)))
    
    return dcts_deg

img_inputs1 = keras.Input(shape=(10,))
q_mat = 5*np.ones((10)).astype(np.float32)
mul_layer = MyDenseLayer (q_mat)
outputs = mul_layer (img_inputs1)
model = keras.Model(inputs=[img_inputs1], outputs=outputs)
model.summary()

x = 10*np.random.rand(100,10).astype(np.float32)
y = x 

optimizer = tf.keras.optimizers.RMSprop(0.1)

model.compile(loss=tf.keras.losses.MSE,
                optimizer=optimizer,
                 )

history = model.fit(x, y, epochs = 50 )



InvalidArgumentError: Input to reshape is a tensor with 10 values, but the requested shape has 320
	 [[{{node training_1/RMSprop/gradients/Mul_3_grad/Reshape}}]] [Op:StatefulPartitionedCall]







"
40716,TFLite generation issue with lrn,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source): 2.1.0

**Infos**

Tflite return a type issue when i use the code below but it doesn't when just switching the lrn and multiply declaration order in the code

**Custom code (test_tflite.py)**

```python
import os
import numpy
import tensorflow.compat.v1 as tf
from tensorflow.python.tools import freeze_graph

tf.disable_v2_behavior()

if __name__ == '__main__':
    data = tf.placeholder(dtype=tf.float32, shape=[2,2,16,16], name=""input"")
    #output size: h,w,d,b = 2,16,16,2
    random_front_0 = tf.nn.local_response_normalization(
        data,
        depth_radius=2,
        bias=1.0,
        alpha=1.0,
        beta=0.5,
        name='random_front_0'
    )
    #output size: h,w,d,b = 2,16,16,2
    random_back_0 = tf.multiply(
        data,
        tf.Variable(numpy.random.rand(1).astype(dtype=numpy.float32)),
        name='random_back_0'
    )
    output = tf.add(
        random_front_0,
        random_back_0,
        name='output'
    )

    #output size: h,w,d,b = 2,16,16,2
    global_init = tf.global_variables_initializer()
    if len(tf.global_variables()) > 0:
        saver = tf.train.Saver()
    with tf.Session() as sess:
        sess.run(global_init)
        tf.train.write_graph(sess.graph, ""./"", 'model.pbtxt', as_text=True)
        save_path = saver.save(sess, './model.ckpt')
        print('Model saved in file: {}'.format(save_path))
        # Look here for more details https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph_test.py
        freeze_graph.freeze_graph(
           os.path.join(""./"", 'model.pbtxt'), # GraphDef
           '',
           False, # is the GraphDef in binary format
           os.path.join(""./"", 'model.ckpt'), # checkpoint name
           'output', # output node name
           '', '',
           os.path.join(""./"", 'model.frozen.pb'), # output frozen path graph
           True, # clear devices info from meta-graph
           '', '', '')
        input_arrays = [""input""]
        output_arrays = [""output""]
        converter = tf.lite.TFLiteConverter.from_frozen_graph('./model.frozen.pb', input_arrays, output_arrays)
        def representative_dataset_gen():
            for _ in range(1000):
                yield [numpy.array(numpy.random.randint(0, 255, size=(2, 2, 16, 16)),dtype=numpy.float32)]
        converter.representative_dataset = representative_dataset_gen
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        tflite_model = converter.convert()
        tflite_model_path = './model.tflite'
        open(tflite_model_path, 'wb').write(tflite_model)
    interpreter = tf.lite.Interpreter(model_path=str(tflite_model_path))
    assert(interpreter is not None)
    interpreter.allocate_tensors()
```

**The output**

```
Traceback (most recent call last):
  File ""test_tflite.py"", line 64, in <module>
    interpreter.allocate_tensors()
  File ""lib/python2.7/site-packages/tensorflow_core/lite/python/interpreter.py"", line 247, in allocate_tensors
    return self._interpreter.AllocateTensors()
  File ""lib/python2.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py"", line 110, in AllocateTensors
    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
RuntimeError: tensorflow/lite/kernels/local_response_norm.cc:47 input->type != output->type (9 != 1)Node number 1 (LOCAL_RESPONSE_NORMALIZATION) failed to prepare.
```

**Model.tflite graph**

![model tflite](https://user-images.githubusercontent.com/29231663/85408924-735cb000-b565-11ea-8a92-6a5e6cee8e20.png)

**Custom code (with switched layers)**
```python
import os
import numpy
import tensorflow.compat.v1 as tf
from tensorflow.python.tools import freeze_graph

tf.disable_v2_behavior()

if __name__ == '__main__':
    data = tf.placeholder(dtype=tf.float32, shape=[2,2,16,16], name=""input"")
    #output size: h,w,d,b = 2,16,16,2
    random_back_0 = tf.multiply(
        data,
        tf.Variable(numpy.random.rand(1).astype(dtype=numpy.float32)),
        name='random_back_0'
    )
    #output size: h,w,d,b = 2,16,16,2
    random_front_0 = tf.nn.local_response_normalization(
        data,
        depth_radius=2,
        bias=1.0,
        alpha=1.0,
        beta=0.5,
        name='random_front_0'
    )
    output = tf.add(
        random_front_0,
        random_back_0,
        name='output'
    )

    #output size: h,w,d,b = 2,16,16,2
    global_init = tf.global_variables_initializer()
    if len(tf.global_variables()) > 0:
        saver = tf.train.Saver()
    with tf.Session() as sess:
        sess.run(global_init)
        tf.train.write_graph(sess.graph, ""./"", 'model.pbtxt', as_text=True)
        save_path = saver.save(sess, './model.ckpt')
        print('Model saved in file: {}'.format(save_path))
        # Look here for more details https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph_test.py
        freeze_graph.freeze_graph(
           os.path.join(""./"", 'model.pbtxt'), # GraphDef
           '',
           False, # is the GraphDef in binary format
           os.path.join(""./"", 'model.ckpt'), # checkpoint name
           'output', # output node name
           '', '',
           os.path.join(""./"", 'model.frozen.pb'), # output frozen path graph
           True, # clear devices info from meta-graph
           '', '', '')
        input_arrays = [""input""]
        output_arrays = [""output""]
        converter = tf.lite.TFLiteConverter.from_frozen_graph('./model.frozen.pb', input_arrays, output_arrays)
        def representative_dataset_gen():
            for _ in range(1000):
                yield [numpy.array(numpy.random.randint(0, 255, size=(2, 2, 16, 16)),dtype=numpy.float32)]
        converter.representative_dataset = representative_dataset_gen
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        tflite_model = converter.convert()
        tflite_model_path = './model.tflite'
        open(tflite_model_path, 'wb').write(tflite_model)
    interpreter = tf.lite.Interpreter(model_path=str(tflite_model_path))
    assert(interpreter is not None)
    interpreter.allocate_tensors()
```

**Output**

No output, work fine

**Model.tflite graph**

![model tflite(1)](https://user-images.githubusercontent.com/29231663/85409979-d0a53100-b566-11ea-8940-04b6367b01cc.png)
"
40715,BERT has a invaild variable,"tensorflow 2.2.0
tensorflow_hub 0.8.0


my code is `bert_url = r""https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/2""

 bert = hub.KerasLayer(bert_url, trainable=True)

 print(bert.variables[-1])`
and the result is '**<tf.Variable 'Variable:0' shape=() dtype=bool, numpy=False>**'
my another task is limited by the variable, how to remove it?"
40714,ValueError: return statements are not supported within a TensorFlow loop.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.2.0
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

When using return statements within for loops TensorFlow raises the error aforementioned in the issue title. 

**Describe the expected behavior**

A workaround. As this behavior is unknown to me. 

**Standalone code to reproduce the issue**

[Colab Notebook](https://colab.research.google.com/gist/sayakpaul/a069acdb369b25f48dd3844b4f701855/scratchpad.ipynb)

**Other info / logs** 

**Update**
When retrieving the dataset just register here: http://www.fki.inf.unibe.ch/databases/iam-handwriting-database. It won't take more than 40 seconds. Once registered, one can update username and the password in the `wget` fields. 
"
40713,graph.o: In function `entry':,"Hi,

I am running into this strange issue. So I am able to compile using a specific TensorFlow library which is the open baselines and whenever I create a model with stable-baselines I keep getting this error when I go to compile. 

I am not a C++ or C wizard so this has proven to be very difficult to figure out for me. Any insight would be much appreciated.

Been trying to resolve this for 14 days now.

```
graph/graph.o: In function `entry':
__compute_module:(.text+0xafe): undefined reference to `__multi3'
__compute_module:(.text+0xcfa): undefined reference to `__multi3'
__compute_module:(.text+0xe90): undefined reference to `__multi3'
__compute_module:(.text+0x1000): undefined reference to `__multi3'
```
"
40712,How to run TF lite model on Nvidia GPU (NNAPI or GPU delegate)?,"I found that TF lite targeted major mobile GPUs including Adreno, Mali, and PowerVR from closed issue (https://github.com/tensorflow/tensorflow/issues/34536).

1. I wonder if... I can run TF lite model on the gpu, Nvidia T4.

2. I wonder if... ""TF lite model is optimized to mobile gpus"" means the case of using NNAPI.
I want to check if the sentence above means that ... the gpus that I can run TF lite model using NNAPI is limited to mobile GPUs. But, it's possible to infer TF lite model on other gpus like Nvidia gpu using GPU delegate.

Thank you!"
40711,Question: About Intra-threadpool core affinity,"When we use the intra-threadpool, which I believe is based on pthread,it seems we didn't find some where the code would try to set the CPU hard affinity
https://github.com/tensorflow/tensorflow/blob/e5023a1738cce7efcdf9d87863b85c80ab2f8c9e/tensorflow/core/common_runtime/local_device.cc#L114-L159
by calling the functions like `pthread_setaffinity_np` and `pthread_getaffinity_np` 
Is anyone knowing the reason behind?
"
40709,What exactly does `tf.signal.fft` compute?,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/signal/fft

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/signal/fft

## Description of issue (what needs changing):
The description is simply ""Fast Fourier transform."" which isn't fully-specified. What is the exact function computed? Is there a normalization term of 1/sqrt(N) or 1/N? Or is the normalization constant entirely in the inverse FFT (which has equally underspecified documentation)?

### Clear description
A mathematical formula that specifies what `tf.signal.fft` implements would be nice. Likewise with the other FFT methods, the inverse FFT methods, and STFT methods."
40708,looping over tf.range in tf.function is slower than looping over range,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
colab tensorflow 2


`v2.2.0-0-g2b96f3662b 2.2.0`
tested on both CPU and GPU (GPU is much worse!)

**Describe the current behavior**

when timing a simple tf.function that uses a loop, `tf.range` is much slower than using `range`.
BUT `tf.range` is recommended in the docs, moreover is says that looping over non-tensor will be rolled during tracing (which does not happen. normal `range` is being traced as a loop)

```
@tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.float32)])
def test(x):
  for i in tf.range(100):
    x = x * tf.constant(1.1)
  return x
```

```
%%timeit
test(tf.range(1000, dtype='float32'))
```
prints `100 loops, best of 3: 2.12 ms per loop`
prints `10 loops, best of 3: 70.2 ms per loop` on GPU!
while using `range` or `np.arange` is about 300 micro seconds in both CPU and GPU

**Describe the expected behavior**

1 there is a documentation issue where it currently always recommends `tf.range`.
2 the documentation should specify when python loops are not rolled
3 tf.range performance should be the same as range when used in a traced loop
(also note the `np.arange` is faster than `tf.range` and comparable to `range`)"
40707,TF 2 Keras | DenseFeatures layer not referring to data set fields by names,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Colab default
- TensorFlow version (use command below): 2.2
- Python version: 3.7
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**:
While using **tf.keras.layers.DenseFeatures** as input layer, TF doesn't give any error in case the input dataset is missing any field with the required field names as given in DenseFeatures. However this works absolutely fine when directly using the **tf.keras.Input()** - gives error **""KeyError: fieldname""**

**Describe the expected behavior**
**tf.keras.layers.DenseFeatures** should work absolutely like **tf.keras.Input()**

**Standalone code to reproduce the issue**
Use colab notebook - https://colab.research.google.com/drive/1luzdzGEdJqaUjmYGbGGPIx7DFSAHebnL?usp=sharing

1. **dummy_model_1( Correct behavior )** in the code uses only tf.keras.input( ) as inputs to TF Keras model and gives error if dataset misses required fields:

Here **reviews** was not passed as a field in the input dataset. -> So TF raised error

```
def dummy_model_1(params):
    METRICS = [
            keras.metrics.RootMeanSquaredError(name='RMSE')
    ]

    B = tf.keras.Input((), dtype = tf.string, name = 'condition')
    C = tf.keras.Input((), dtype = tf.string, name = 'reviews')

    model = tf.keras.Model([B, C], [B, C])

    #Set optimizer
    opt = tf.keras.optimizers.Adam(lr= params['lr'], beta_1=params['beta_1'], 
                                        beta_2=params['beta_2'], epsilon=params['epsilon'])

    #Compile model
    model.compile(loss='mean_squared_error',  optimizer=opt, metrics = METRICS)

    #Print Summary
    print(model.summary())
    return model

KeyError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *
        outputs = self.distribute_strategy.run(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **
        return self(x, training=False)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__
        outputs = call_fn(cast_inputs, *args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:719 call
        convert_kwargs_to_constants=base_layer_utils.call_context().saving)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:826 _run_internal_graph
        inputs = self._flatten_to_reference_inputs(inputs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:926 _flatten_to_reference_inputs
        return [tensors[inp._keras_history.layer.name] for inp in ref_inputs]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:926 <listcomp>
        return [tensors[inp._keras_history.layer.name] for inp in ref_inputs]

    KeyError: 'reviews'
```

2. **dummy_model_2( Wrong behavior )** in the code uses tf.keras.DenseFeatures( ) and tf.keras.Input( ) as inputs to TF Keras model and **DOESNT** gives error if dataset misses required fields. In fact I am not sure how it maps data from dataset to the model inputs:

Here **reviews** & **drugsName** both were passed as incorrect fieldnames and don't exist in the input dataset. -> **TF did not give any error**. It should have given error for both the fields.

It seems that in this case, TF just picks up values from dataset as per the index and not actually from the fieldnames.

```
def dummy_model_2(params):
    METRICS = [
            # keras.metrics.BinaryAccuracy(name='accuracy'),
            keras.metrics.RootMeanSquaredError(name='RMSE')
    ]

    A = tf.keras.layers.DenseFeatures(feature_columns=f)({'drugsName' : tf.keras.Input(name='drugsName', shape=(1,), dtype=tf.string)})
    B = tf.keras.Input((), dtype = tf.string, name = 'condition')
    C = tf.keras.Input((), dtype = tf.string, name = 'reviews')

    model = tf.keras.Model([{'drugsName' : tf.keras.Input(name='drugsName', shape=(1,), dtype=tf.string)}, B, C], [B, C])

    #Set optimizer
    opt = tf.keras.optimizers.Adam(lr= params['lr'], beta_1=params['beta_1'], 
                                        beta_2=params['beta_2'], epsilon=params['epsilon'])

    #Compile model
    model.compile(loss='mean_squared_error',  optimizer=opt, metrics = METRICS)

    #Print Summary
    print(model.summary())
    return model
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40706,How to use Tensorflow Lite GPU support for python code,"<em>I want to run tflite model on GPU using python code. But it seems that the code does not use GPU (There's no increase in GPU resource usage.). Is it possible to give an GPU-related option in ""tf.lite.Interpreter(model_path, option)""? </em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04
- Python version:  3.6
- CUDA/cuDNN version: 10.1 
- GPU model and memory: 2080 ti

**Describe the current behavior**
tflite model with python code runs on cpu.

**Describe the expected behavior**
tflite model with python code runs on gpu.

"
40704,Didn't find op for builtin opcode 'LOGISTIC' version '1',"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: Mac OS 10.16
- TensorFlow installed from  source at  2020-06-22  ( git clone.. )
- Target platform :  Arm Mbed OS

**Describe the problem**

Run-time error on FRDM-K66F board:
```
Didn't find op for builtin opcode 'LOGISTIC' version '1'
Failed to get registration from op code LOGISTIC
```
I looked at the TFLite source code, at it uses LOGISTIC version=0 :

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/kernels/logistic.cc#L124

**Please provide the exact sequence of commands/steps when you ran into the problem**
Compiled code as described here:

https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/micro_speech#deploy-to-nxp-frdm-k66f

Instead original model.cc I use my own model.cc which uses LOGISTIC op code.
Compiled, deployed to board and got the run-time error on FRDM-K66F board:
```
Didn't find op for builtin opcode 'LOGISTIC' version '1'
Failed to get registration from op code LOGISTIC
```

"
40703,[Regression] on_train_batch_begin callbacks with no batch number and size,"Yep this should work in TF2.1 as well, here's a full example (had to fix the metric code a bit):

```python
import tensorflow as tf

class Count(tf.keras.metrics.Metric):
  def __init__(self, name=None, dtype=None, **kwargs):
    super(Count, self).__init__(name, dtype, **kwargs)
    self.count = tf.Variable(0)

  def update_state(self, y_true, y_pred, sample_weight=None):
    first_tensor = tf.nest.flatten(y_true)[0]
    batch_size = tf.shape(first_tensor)[0]
    self.count.assign_add(batch_size)

  def result(self):
    return tf.identity(self.count)


class PrintInfo(tf.keras.callbacks.Callback):
  def on_train_batch_end(self, batch, logs):
    print('Batch number: {}'.format(batch))
    print('Samples seen this epoch: {}'.format(logs['counter']))

model = tf.keras.Sequential([tf.keras.layers.Dense(1)])
model.compile(optimizer='sgd', loss='mse', metrics=[Count(name='counter')])
x, y = tf.ones((10, 10)), tf.ones((10, 1))
model.fit(x, y, batch_size=2, callbacks=[PrintInfo()], verbose=2)
```

_Originally posted by @omalleyt12 in https://github.com/tensorflow/tensorflow/issues/39314#issuecomment-630325421_

I would like to use the same method, but with `on_train_batch_begin`, and it doesn't work. Actually the logs remain empty even after using the new metric. How can I use the batch size in a callback, with `on_train_batch_begin`?"
40702,Session crashes when I use TFLiteConverter with tf.lite.OpsSet.TFLITE_BUILTINS_INT8 option,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Colaboratory (Ubuntu 18.04.2 LTS)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary, nightly
- TensorFlow version (use command below): '2.3.0-dev20200622'
- Python version: Python 3.6.7
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: CUDA v10.0.130, cuDNN 7.6.0
- GPU model and memory: K80

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

1. AttributeError: module 'tensorflow' has no attribute 'GIT_VERSION'
2. v1.12.1-34793-g072cf7ee4b 2.3.0-dev20200622

**Describe the current behavior**

I'm trying to convert and quantize a mask_rcnn_inceptionv2 model from the model zoo for use on a Coral USB Accelerator and the Colab runtime crashes. 

**Describe the expected behavior**

Successful conversion w/o any crashes.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf
import tarfile
import pathlib

model_name = ""mask_rcnn_inception_v2_coco_2018_01_28""
base_url = 'http://download.tensorflow.org/models/object_detection/'
model_file = model_name + '.tar.gz'
model_dir = tf.keras.utils.get_file(fname=model_name, origin=base_url + model_file, untar=True)
model_dir = pathlib.Path(model_dir)/""saved_model""
print('Saved to {}'.format(model_dir))

export_dir = ""/root/.keras/datasets/mask_rcnn_inception_v2_coco_2018_01_28/saved_model""
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
converter.experimental_new_converter=True
converter.optimizations = [tf.lite.Optimize.DEFAULT]
def representative_dataset_gen():
  for _ in range(num_calibration_steps):
    yield [input]
converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_output_type = tf.int8 
tflite_quant_model = converter.convert() # crashes on this line
open(""converted_model_quant.tflite"", ""wb"").write(tflite_quant_model)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```

Jun 23, 2020, 7:09:41 AM | INFO | Discarding 6 buffered messages for 5081aeef-6fb9-46a7-a45d-3af457c9a931:aed26b5d8fdf4925f295f4d907ca617f
-- | -- | --
Jun 23, 2020, 7:09:41 AM | INFO | Adapting to protocol v5.1 for kernel 5081aeef-6fb9-46a7-a45d-3af457c9a931
Jun 23, 2020, 7:09:39 AM | INFO | Starting buffering for 5081aeef-6fb9-46a7-a45d-3af457c9a931:aed26b5d8fdf4925f295f4d907ca617f
Jun 23, 2020, 7:09:39 AM | WARNING | zmq message arrived on closed channel
Jun 23, 2020, 7:09:11 AM | WARNING | tf.TensorArrayWriteV3 {device = """"}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.TensorArrayV3 {clear_after_read = true, device = """", dtype = i32, dynamic_size = false, element_shape = #tf.shape<*>, identical_element_shapes = true, tensor_array_name = """"}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.TensorArrayV3 {clear_after_read = true, device = """", dtype = f32, dynamic_size = false, element_shape = #tf.shape<*>, identical_element_shapes = true, tensor_array_name = """"}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.TensorArraySizeV3 {device = """"}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.TensorArrayScatterV3 {device = """"}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.TensorArrayReadV3 {device = """"}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.TensorArrayGatherV3 {device = """", element_shape = #tf.shape<?x?x3>}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.TensorArrayGatherV3 {device = """", element_shape = #tf.shape<>}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.TensorArrayGatherV3 {device = """", element_shape = #tf.shape<3>}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.TensorArrayGatherV3 {device = """", element_shape = #tf.shape<100x4>}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.TensorArrayGatherV3 {device = """", element_shape = #tf.shape<100>}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.Size {device = """"}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.NonMaxSuppressionV2 {T = f32, T_threshold = f32, device = """"}
Jun 23, 2020, 7:09:11 AM | WARNING | tf.CropAndResize {T = f32, device = """", extrapolation_value = 0.000000e+00 : f32, method = ""bilinear""}
Jun 23, 2020, 7:09:11 AM | WARNING | error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
Jun 23, 2020, 7:09:10 AM | WARNING | loc(callsite(""BatchMultiClassNonMaxSuppression_1/map/while/TensorArrayWrite_2/TensorArrayWriteV3@_functionalize_body_0"" at ""BatchMultiClassNonMaxSuppression_1/map/while/LoopCond"")): error: 'tf.TensorArrayWriteV3' op is neither a custom op nor a flex op
Jun 23, 2020, 7:09:10 AM | WARNING | loc(callsite(""BatchMultiClassNonMaxSuppression_1/map/while/TensorArrayWrite_1/TensorArrayWriteV3@_functionalize_body_0"" at ""BatchMultiClassNonMaxSuppression_1/map/while/LoopCond"")): error: 'tf.TensorArrayWriteV3' op is neither a custom op nor a flex op
Jun 23, 2020, 7:09:10 AM | WARNING | loc(callsite(""BatchMultiClassNonMaxSuppression_1/map/while/TensorArrayWrite_4/TensorArrayWriteV3@_functionalize_body_0"" at ""BatchMultiClassNonMaxSuppression_1/map/while/LoopCond"")): error: 'tf.TensorArrayWriteV3' op is neither a custom op nor a flex op
Jun 23, 2020, 7:09:10 AM | WARNING | loc(callsite(""BatchMultiClassNonMaxSuppression_1/map/while/TensorArrayWrite/TensorArrayWriteV3@_functionalize_body_0"" at ""BatchMultiClassNonMaxSuppression_1/map/while/LoopCond"")): error: 'tf.TensorArrayWriteV3' op is neither a custom op nor a flex op
Jun 23, 2020, 7:09:10 AM | WARNING | loc(callsite(""BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/SortByField/Size@_functionalize_body_0"" at ""BatchMultiClassNonMaxSuppression_1/map/while/LoopCond"")): error: 'tf.Size' op is neither a custom op nor a flex op
...
...
...
loc(callsite(""BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/non_max_suppression_70/NonMaxSuppressionV2@_functionalize_body_0"" at ""BatchMultiClassNonMaxSuppression_1/map/while/LoopCond"")): error: 'tf.NonMaxSuppressionV2' op is neither a custom op nor a flex op
Jun 23, 2020, 7:09:10 AM | WARNING | : error: 'tf.NonMaxSuppressionV2' op is neither a custom op nor a flex op
Jun 23, 2020, 7:09:10 AM | WARNING | loc(callsite(""BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/non_max_suppression_7/NonMaxSuppressionV2@_functionalize_body_0"" at ""BatchMultiClassNonMaxSuppression_1/map/while/LoopCond""))
...
...
...
```
"
40699,Quuantization.keras.quantize_model failed for subclasses model,"We are using a subclassed mode:
class MyNet(tf.keras.Model):

When trying to do 
model = MyNet()
model = tfmot.quantization.keras.quantize_model(model)

We get:
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py"", line 134, in quantize_model
    '`to_quantize` can only either be a tf.keras Sequential or '
**ValueError: `to_quantize` can only either be a tf.keras Sequential or Functional model**

So does quantization does not works on subclasses network ?
If so how can I get it to run on quantization only edge devices ?"
40698,Can i change channel count in tf.keras.preprocessing.image.ImageDataGenerator or tf.keras.preprocessing.image.DirectoryIterator?,"In Xception Pretrained model, i'm trying to use 6 channel as an input(299, 299, 6).

I'm using ImageDataGenerator and DirectoryIterator to load and preprocess data like this.

```
 image_data_generator_train = ImageDataGenerator(
                preprocessing_function = myFunc        
                validation_split=val_ratio,
    )
```

```
train_data = DirectoryIterator(
                directory=imagenet_train,
                image_data_generator=image_data_generator_train,          
                target_size=input_shape,
                classes=train_classes,
                class_mode='sparse',
                batch_size=train_batch_size,
                subset = 'training',
                shuffle=True,
                seed=2030,
                interpolation='bilinear'
)
```

and in myFunc, i'm trying to return 6 channel(299, 299, 6) but it occurs error because preprocessing_function's input and output should be same shape.
so i want to make input 6 channels, like concatenate input with channel like 
tf.concat([img, img], axis = 2) to make shape (299, 299,6)
can i do this in directoryiterator or imagedatagenerator?
"
40692,Conv1DTranspose documentation inconsistent with code and unclear,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:

[https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1DTranspose](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1DTranspose)

## Description of issue (what needs changing):
The documentation claims that padding options {""valid"" and ""same""} are supported, but when following the code path to deconv_output_length at line 140 [here](https://github.com/tensorflow/tensorflow/blob/0c227aed65e62f741a88c9915923d262710fc8c9/tensorflow/python/keras/utils/conv_utils.py#L140) there is the option for {""full""} as well.

Additionally, the equation provided for calculating output shape merely says ""padding"" for a variable which is represented as a string in the API. This makes for a guessing game of how to achieve the desired output shape.

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links
[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/convolutional.py#L16](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/convolutional.py#L16l)
Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
40688,C++ compilation of rule '//tensorflow/python:bfloat16_lib' failed,"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04 -- building inside `Dockerfile` with `FROM nvidia/cuda:10.1-cudnn7-devel-ubuntu18.04`
- TensorFlow installed from: source
- TensorFlow version: 2.2.0
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?: No
- Bazel version: 2.0.0 (extracted from _TF_MAX_BAZEL)
- GCC/Compiler version: 7.4.0
- CUDA/cuDNN version: 10.1 / 7 
- GPU model and memory: tested on Titan XP and RTX 2070 8GB 


**Describe the problem**

Build fails with
```ERROR: /usr/local/src/tensorflow/tensorflow/python/BUILD:437:1: C++ compilation of rule '//tensorflow/python:bfloat16_lib' failed (Exit 1)
ESC[0mESC[91mtensorflow/python/lib/core/bfloat16.cc: In function 'bool tensorflow::{anonymous}::Initialize()':
tensorflow/python/lib/core/bfloat16.cc:636:36: error: no match for call to '(tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>) (const c
har [6], <unresolved overloaded function type>, const std::array<int, 3>&)'
                       compare_types)) {
                                    ^
tensorflow/python/lib/core/bfloat16.cc:610:60: note: candidate: tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>
                             const std::array<int, 3>& types) {
                                                            ^
tensorflow/python/lib/core/bfloat16.cc:610:60: note:   no known conversion for argument 2 from '<unresolved overloaded function type>' to 'PyUFuncGenericFunction {aka void (*)(char**, const long int
*, const long int*, void*)}'
tensorflow/python/lib/core/bfloat16.cc:640:36: error: no match for call to '(tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>) (const c
har [10], <unresolved overloaded function type>, const std::array<int, 3>&)'
                       compare_types)) {
                                    ^
tensorflow/python/lib/core/bfloat16.cc:610:60: note: candidate: tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>
                             const std::array<int, 3>& types) {
                                                            ^
tensorflow/python/lib/core/bfloat16.cc:610:60: note:   no known conversion for argument 2 from '<unresolved overloaded function type>' to 'PyUFuncGenericFunction {aka void (*)(char**, const long int
*, const long int*, void*)}'
tensorflow/python/lib/core/bfloat16.cc:643:77: error: no match for call to '(tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>) (const c
har [5], <unresolved overloaded function type>, const std::array<int, 3>&)'
   if (!register_ufunc(""less"", CompareUFunc<Bfloat16LtFunctor>, compare_types)) {

                                                                            ^
tensorflow/python/lib/core/bfloat16.cc:610:60: note: candidate: tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>
                             const std::array<int, 3>& types) {
                                                            ^
tensorflow/python/lib/core/bfloat16.cc:610:60: note:   no known conversion for argument 2 from '<unresolved overloaded function type>' to 'PyUFuncGenericFunction {aka void (*)(char**, const long int*, const long int*, void*)}'
tensorflow/python/lib/core/bfloat16.cc:647:36: error: no match for call to '(tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>) (const char [8], <unresolved overloaded function type>, const std::array<int, 3>&)'
                       compare_types)) {
                                    ^
tensorflow/python/lib/core/bfloat16.cc:610:60: note: candidate: tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>
                             const std::array<int, 3>& types) {
                                                            ^
tensorflow/python/lib/core/bfloat16.cc:610:60: note:   no known conversion for argument 2 from '<unresolved overloaded function type>' to 'PyUFuncGenericFunction {aka void (*)(char**, const long int*, const long int*, void*)}'
tensorflow/python/lib/core/bfloat16.cc:651:36: error: no match for call to '(tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>) (const char [11], <unresolved overloaded function type>, const std::array<int, 3>&)'
                       compare_types)) {
                                    ^
tensorflow/python/lib/core/bfloat16.cc:610:60: note: candidate: tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>
                             const std::array<int, 3>& types) {
                                                            ^
tensorflow/python/lib/core/bfloat16.cc:610:60: note:   no known conversion for argument 2 from '<unresolved overloaded function type>' to 'PyUFuncGenericFunction {aka void (*)(char**, const long int*, const long int*, void*)}'
tensorflow/python/lib/core/bfloat16.cc:655:36: error: no match for call to '(tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>) (const char [14], <unresolved overloaded function type>, const std::array<int, 3>&)'
                       compare_types)) {
                                    ^
tensorflow/python/lib/core/bfloat16.cc:610:60: note: candidate: tensorflow::{anonymous}::Initialize()::<lambda(const char*, PyUFuncGenericFunction, const std::array<int, 3>&)>
                             const std::array<int, 3>& types) {
                                                            ^
tensorflow/python/lib/core/bfloat16.cc:610:60: note:   no known conversion for argument 2 from '<unresolved overloaded function type>' to 'PyUFuncGenericFunction {aka void (*)(char**, const long int*, const long int*, void*)}'
ESC[0mESC[91mTarget //tensorflow/tools/pip_package:build_pip_package failed to build
ESC[0mESC[91mERROR: /usr/local/src/tensorflow/tensorflow/tools/pip_package/BUILD:62:1 C++ compilation of rule '//tensorflow/python:bfloat16_lib' failed (Exit 1)
ESC[0mESC[91mINFO: Elapsed time: 1828.057s, Critical Path: 881.14s
INFO: 13824 processes: 13824 local.
ESC[0mESC[91mFAILED: Build did NOT complete successfully
ESC[0mESC[91mFAILED: Build did NOT complete successfully
ESC[0mESC[91mCommand exited with non-zero status 1
```


**Provide the exact sequence of commands / steps that you executed before running into the problem**

Reproducible with the following `Dockerfile`

```
FROM nvidia/cuda:10.1-cudnn7-devel-ubuntu18.04

# Install system packages
ENV DEBIAN_FRONTEND noninteractive
RUN apt-get update -y \
  && apt-get install -y --no-install-recommends apt-utils \
  && apt-get install -y \
    build-essential \
    checkinstall \
    cmake \
    curl \
    g++ \
    gcc \
    git \
    locales \
    perl \
    pkg-config \
    protobuf-compiler \
    python3-dev \
    rsync \
    software-properties-common \
    unzip \
    wget \
    zip \
    zlib1g-dev \
  && apt-get clean

# UTF-8
RUN localedef -i en_US -c -f UTF-8 -A /usr/share/locale/locale.alias en_US.UTF-8
ENV LANG en_US.utf8

# Setup pip
RUN wget -q -O /tmp/get-pip.py --no-check-certificate https://bootstrap.pypa.io/get-pip.py \
  && python3 /tmp/get-pip.py \
  && pip3 install -U pip \
  && rm /tmp/get-pip.py
# Some TF tools expect a ""python"" binary
RUN ln -s $(which python3) /usr/local/bin/python

# /etc/ld.so.conf.d/nvidia.conf point to /usr/local/nvidia which seems to be missing, point to the cuda directory install for libraries
RUN cd /usr/local && ln -s cuda nvidia
ARG CTO_CUDA_VERSION=""10.1""
ARG CTO_CUDA_PRIMEVERSION=""10.0""
ARG CTO_CUDA_APT=""cuda-npp-${CTO_CUDA_VERSION} cuda-cublas-${CTO_CUDA_PRIMEVERSION} cuda-cufft-${CTO_CUDA_VERSION} cuda-libraries-${CTO_CUDA_VERSION} cuda-npp-dev-${CTO_CUDA_VERSION} cuda-cublas-dev-${CTO_CUDA_PRIMEVERSION} cuda-cufft-dev-${CTO_CUDA_VERSION} cuda-libraries-dev-${CTO_CUDA_VERSION}""
RUN apt-get install -y --no-install-recommends \
  time ${CTO_CUDA_APT} \
  && apt-get clean

ENV LD_LIBRARY_PATH=""$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64""

# Install Python tools 
RUN pip3 install -U \
  mock \
  numpy \
  setuptools \
  six \
  wheel \
  && pip3 install 'future>=0.17.1' \
  && pip3 install -U keras_applications --no-deps \
  && pip3 install -U keras_preprocessing --no-deps \
  && rm -rf /root/.cache/pip

## Download & Building TensorFlow from source
ARG LATEST_BAZELISK=1.5.0
ARG CTO_TENSORFLOW_VERSION=""2.2.0""
RUN curl -s -Lo /usr/local/bin/bazel https://github.com/bazelbuild/bazelisk/releases/download/v${LATEST_BAZELISK}/bazelisk-linux-amd64 \
  && chmod +x /usr/local/bin/bazel \
  && mkdir -p /usr/local/src \
  && cd /usr/local/src \
  && wget -q --no-check-certificate https://github.com/tensorflow/tensorflow/archive/v${CTO_TENSORFLOW_VERSION}.tar.gz \
  && tar xfz v${CTO_TENSORFLOW_VERSION}.tar.gz \
  && mv tensorflow-${CTO_TENSORFLOW_VERSION} tensorflow \
  && rm v${CTO_TENSORFLOW_VERSION}.tar.gz \
  && cd /usr/local/src/tensorflow \
  && fgrep _TF_MAX_BAZEL configure.py | grep '=' | perl -ne 'print $1 if (m%\=\s+.([\d\.]+).$+%)' > .bazelversion
RUN cd /usr/local/src/tensorflow \
  && TF_CUDA_CLANG=0 TF_CUDA_VERSION=${CTO_CUDA_VERSION} TF_CUDNN_VERSION=7 TF_DOWNLOAD_CLANG=0 TF_DOWNLOAD_MKL=0 TF_ENABLE_XLA=0 TF_NEED_AWS=0 TF_NEED_COMPUTECPP=0 TF_NEED_CUDA=1 TF_NEED_GCP=0 TF_NEED_GDR=0 TF_NEED_HDFS=0 TF_NEED_JEMALLOC=1 TF_NEED_KAFKA=0 TF_NEED_MKL=0 TF_NEED_MPI=0 TF_NEED_OPENCL=0 TF_NEED_OPENCL_SYCL=0 TF_NEED_ROCM=0 TF_NEED_S3=0 TF_NEED_TENSORRT=0 TF_NEED_VERBS=0 TF_SET_ANDROID_WORKSPACE=0 TF_CUDA_COMPUTE_CAPABILITIES=""5.3,6.0,6.1,6.2,7.0,7.2,7.5"" GCC_HOST_COMPILER_PATH=$(which gcc) CC_OPT_FLAGS=""-march=native"" PYTHON_BIN_PATH=$(which python) PYTHON_LIB_PATH=""$(python -c 'import site; print(site.getsitepackages()[0])')"" ./configure
RUN cd /usr/local/src/tensorflow \
  && time bazel build --verbose_failures --config=opt --config=v2 --config=cuda //tensorflow/tools/pip_package:build_pip_package \
  && time ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg \
  && time pip3 install /tmp/tensorflow_pkg/tensorflow-*.whl

CMD bash
```

Built using `docker build --tag cto:test .`

Note tested with CUDA 10.1, 10.0 and 10.2.
Also occurs with TF 1.15.3



**Any other info / logs**
I can provide the full build log if requested (91MB)

```Step 18/20 : RUN cd /usr/local/src/tensorflow   && TF_CUDA_CLANG=0 TF_CUDA_VERSION=${CTO_CUDA_VERSION} TF_CUDNN_VERSION=7 TF_DOWNLOAD_CLANG=0 TF_DOWNLOAD_MKL=0 TF_ENABLE_XLA=0 TF_NEED_AWS=0 TF_NEED_COMPUTECPP=0 TF_NEED_CUDA=1 TF_NEED_GCP=0 TF_NEED_GDR=0 TF_NEED_HDFS=0 TF_NEED_JEMALLOC=1 TF_NEED_KAFKA=0 TF_NEED_MKL=0 TF_NEED_MPI=0 TF_NEED_OPENCL=0 TF_NEED_OPENCL_SYCL=0 TF_NEED_ROCM=0 TF_NEED_S3=0 TF_NEED_TENSORRT=0 TF_NEED_VERBS=0 TF_SET_ANDROID_WORKSPACE=0 TF_CUDA_COMPUTE_CAPABILITIES=""5.3,6.0,6.1,6.2,7.0,7.2,7.5"" GCC_HOST_COMPILER_PATH=$(which gcc) CC_OPT_FLAGS=""-march=native"" PYTHON_BIN_PATH=$(which python) PYTHON_LIB_PATH=""$(python -c 'import site; print(site.getsitepackages()[0])')"" ./configure
 ---> Running in 9690386205a5
2020/06/22 14:11:17 Downloading https://releases.bazel.build/2.0.0/release/bazel-2.0.0-linux-x86_64...
Extracting Bazel installation...
You have bazel 2.0.0 installed.
Found CUDA 10.1 in:
    /usr/local/cuda-10.1/lib64
    /usr/local/cuda-10.1/include
Found cuDNN 7 in:
    /usr/lib/x86_64-linux-gnu
    /usr/include


Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
        --config=ngraph         # Build with Intel nGraph support.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
        --config=v2             # Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=noaws          # Disable AWS S3 filesystem support.
        --config=nogcp          # Disable GCP support.
        --config=nohdfs         # Disable HDFS support.
        --config=nonccl         # Disable NVIDIA NCCL support.
Configuration finished
Removing intermediate container 9690386205a5
 ---> 8910acc4d9c5
Step 19/20 : RUN cd /usr/local/src/tensorflow   && time bazel build --verbose_failures --config=opt --config=v2 --config=cuda //tensorflow/tools/pip_package:build_pip_package   && time ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg   && time pip3 install /tmp/tensorflow_pkg/tensorflow-*.whl
 ---> Running in 3b0267b1209d
ESC[91mStarting local Bazel server and connecting to it...
ESC[0mESC[91mWARNING: The following configs were expanded more than once: [v2, cuda, using_cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
ESC[0mESC[91mINFO: Options provided by the client:
  Inherited 'common' options: --isatty=0 --terminal_columns=80
ESC[0mESC[91mINFO: Reading rc options for 'build' from /usr/local/src/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /usr/local/src/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from /usr/local/src/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.6/dist-packages --python_path=/usr/local/bin/python --action_env TF_CUDA_VERSION=10.1 --action_env TF_CUDNN_VERSION=7 --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-10.1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=5.3,6.0,6.1,6.2,7.0,7.2,7.5 --action_env LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-7 --config=cuda --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file /usr/local/src/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
ESC[0mESC[91mINFO: Found applicable config definition build:cuda in file /usr/local/src/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /usr/local/src/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:opt in file /usr/local/src/tensorflow/.tf_configure.bazelrc: --copt=-march=native --host_copt=-march=native --define with_default_optimizations=true
INFO: Found applicable config definition build:v2 in file /usr/local/src/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:cuda in file /usr/local/src/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /usr/local/src/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:linux in file /usr/local/src/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /usr/local/src/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
ESC[0mESC[91mLoading: 
ESC[0mESC[91mLoading: 0 packages loaded
ESC[0mESC[91mLoading: 0 packages loaded
ESC[0mESC[91mLoading: 0 packages loaded
ESC[0mESC[91mDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
ESC[0mESC[91mDEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at /root/.cache/bazel/_bazel_root/bbcc73fcc5c2b01ab08b6bcf7c29e42e/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):
 - /root/.cache/bazel/_bazel_root/bbcc73fcc5c2b01ab08b6bcf7c29e42e/external/bazel_toolchains/repositories/repositories.bzl:37:9
 - /usr/local/src/tensorflow/WORKSPACE:37:1
ESC[0mESC[91mLoading: 0 packages loaded
ESC[0mESC[91mLoading: 0 packages loaded
ESC[0mESC[91mLoading: 0 packages loaded
ESC[0mESC[91mLoading: 0 packages loaded
    currently loading: tensorflow/tools/pip_package
ESC[0mESC[91mDEBUG: /root/.cache/bazel/_bazel_root/bbcc73fcc5c2b01ab08b6bcf7c29e42e/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:5: 
[...]```


"
40687,tf.keras.activations.relu doesn't support fp16 through mixed precision for threshold greater than 0,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2
- Python version: 3.6
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA




**Describe the current behavior**
tf.keras.activations.relu doesn't support fp16 for threshold greater than 0. The documentation says it should honor the input dtype but defaults to float32 through floatx
**Describe the expected behavior**
Should cast to input dtype instead of floatx


Addressing issue in pr #40685
"
40686,saved_model_cli convert tensorrt adds unknown inputs to serving signature,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.4 
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7


**Describe the current behavior**
```
saved_model_cli convert \
    --dir /tmp/bert \
    --output_dir /tmp/bert-fp16 \
    --tag_set serve \
    tensorrt --precision_mode FP16
```
results in the 100s additional inputs in the converted model `serving_default` signature.  

```
signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['input_mask'] tensor_info:
        dtype: DT_INT32
        shape: (-1, -1)
        name: serving_default_input_mask:0
    inputs['input_type_ids'] tensor_info:
        dtype: DT_INT32
        shape: (-1, -1)
        name: serving_default_input_type_ids:0
    inputs['input_word_ids'] tensor_info:
        dtype: DT_INT32
        shape: (-1, -1)
        name: serving_default_input_word_ids:0
    inputs['unknown'] tensor_info:
        dtype: DT_RESOURCE
        shape: ()
        name: serving_default_unknown:0
    inputs['unknown_0'] tensor_info:
        dtype: DT_RESOURCE
        shape: ()
        name: serving_default_unknown_0:0
    inputs['unknown_1'] tensor_info:
        dtype: DT_RESOURCE
        shape: ()
        name: serving_default_unknown_1:0
    inputs['unknown_10'] tensor_info:
        dtype: DT_RESOURCE
        shape: ()
        name: serving_default_unknown_10:0
    inputs['unknown_100'] tensor_info:
        dtype: DT_RESOURCE
        shape: ()
        name: serving_default_unknown_100:0
    inputs['unknown_101'] tensor_info:
        dtype: DT_RESOURCE
        shape: ()
        name: serving_default_unknown_101:0
    inputs['unknown_102'] tensor_info:
        dtype: DT_RESOURCE
        shape: ()
        name: serving_default_unknown_102:0
...
```

**Describe the expected behavior**
Converted signature corresponds to the original SavedModel

```
signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['input_mask'] tensor_info:
        dtype: DT_INT32
        shape: (-1, -1)
        name: serving_default_input_mask:0
    inputs['input_type_ids'] tensor_info:
        dtype: DT_INT32
        shape: (-1, -1)
        name: serving_default_input_type_ids:0
    inputs['input_word_ids'] tensor_info:
        dtype: DT_INT32
        shape: (-1, -1)
        name: serving_default_input_word_ids:0
  The given SavedModel SignatureDef contains the following output(s):
...
```
**Standalone code to reproduce the issue**
Try converting BERT from TF Hub
https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2"
40683,Tensorflow will not recognize GPU,"An truing to get TensorFlow to recognize that there is a GPU installed on the PC.  
Windows10 Pro 64bit version
Nvidia GTX1660 TI with latest drivers 
Tensorflow - 2.3.0-dev20200615
CUDA v10.0
cudnn 7.6.5.32

`print(device_lib.list_local_devices())`
```
print(device_lib.list_local_devices())
[name: ""/device:CPU:0""
device_type: ""CPU""
memory_limit: 268435456
locality {
}
incarnation: 4283633287383166880
, name: ""/device:XLA_CPU:0""
device_type: ""XLA_CPU""
memory_limit: 17179869184
locality {
}
incarnation: 5791820499534504026
physical_device_desc: ""device: XLA_CPU device""
, name: ""/device:XLA_GPU:0""
device_type: ""XLA_GPU""
memory_limit: 17179869184
locality {
}
incarnation: 15245658627817172966
physical_device_desc: ""device: XLA_GPU device""
]
```
so system sees that there isa GPU installed, however 

```
print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
Num GPUs Available:  0
```
Trying to get a model to train using the GPU to complete faster - my current training takes 5 hours per epoch.....please help as its for a college project and i really need the speed of the GPU to help.
"
40681,"TFLite Int8 Quantization silently failing, resulting in np.float32 input dtypes in c++ library","Earlier reported on stackoverflow without feedback

[https://stackoverflow.com/questions/59253566/quantized-input-and-output-with-tflite-in-tensorflow-2-0-0](https://stackoverflow.com/questions/59253566/quantized-input-and-output-with-tflite-in-tensorflow-2-0-0)

There appears to be an issue where a fully int8 quantized model still is detected by the c++ TFLite library interpreter to be a Float32 type.  This has a downstream issue when creating quantized models for microcontrollers, as the floating point data types are not fully supported.

It is documented [that an error should be thrown](https://www.tensorflow.org/lite/performance/post_training_integer_quant) when quantization fails, yet quantizing to uint8, for example using the following python completes without an error
```python
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

model_quant_int8_tflite = converter.convert()
quantized_size_int8 = open(MODEL_QUANT_INT8_TFLITE, 'wb').write(model_quant_int8_tflite)
```

Inspecting the resultant TFLite model with a simple iterative printing loop, 
```python
print(interpreter.get_input_details())
print(interpreter.get_output_details())

for l in interpreter.get_tensor_details():
  print(f'Name: {l[""name""]}')
  print(f' Index: {l[""index""]}')
  print(f' Shape: {l[""shape""]}')
  print(f' DType: {l[""dtype""]}')
```
shows that the layers are correctly converted to int8 quantization, however the input layer still has a dtype of numpy.float32
```
[{'name': 'conv2d_input', 'index': 23, 'shape': array([ 1, 49, 40,  1], dtype=int32), 'shape_signature': array([ 1, 49, 40,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
[{'name': 'Identity', 'index': 24, 'shape': array([ 1, 14], dtype=int32), 'shape_signature': array([ 1, 14], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
Name: conv2d_input_int8
 Index: 0
 Shape: [ 1 49 40  1]
 DType: <class 'numpy.int8'>
Name: sequential/dense/BiasAdd/ReadVariableOp
 Index: 1
 Shape: [64]
 DType: <class 'numpy.int32'>
Name: sequential/dense_1/BiasAdd/ReadVariableOp
 Index: 2
 Shape: [14]
 DType: <class 'numpy.int32'>
Name: sequential/flatten/Const
 Index: 3
 Shape: [2]
 DType: <class 'numpy.int32'>
Name: sequential/batch_normalization/FusedBatchNormV3;sequential/conv2d/BiasAdd/ReadVariableOp;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D/ReadVariableOp;sequential/conv2d/Conv2D
 Index: 4
 Shape: [24]
 DType: <class 'numpy.int32'>
Name: sequential/batch_normalization_1/FusedBatchNormV3;sequential/conv2d_1/BiasAdd/ReadVariableOp;sequential/conv2d_1/BiasAdd;sequential/batch_normalization_2/FusedBatchNormV3;sequential/conv2d_2/BiasAdd/ReadVariableOp;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D/ReadVariableOp;sequential/conv2d_2/Conv2D;sequential/conv2d_1/Conv2D/ReadVariableOp;sequential/conv2d_1/Conv2D
 Index: 5
 Shape: [48]
 DType: <class 'numpy.int32'>
Name: sequential/activation_2/Relu;sequential/batch_normalization_2/FusedBatchNormV3;sequential/conv2d_2/BiasAdd/ReadVariableOp;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D/ReadVariableOp;sequential/conv2d_2/Conv2D
 Index: 6
 Shape: [48]
 DType: <class 'numpy.int32'>
Name: sequential/dense/MatMul
 Index: 7
 Shape: [ 64 384]
 DType: <class 'numpy.int8'>
Name: sequential/dense_1/MatMul
 Index: 8
 Shape: [14 64]
 DType: <class 'numpy.int8'>
Name: sequential/batch_normalization/FusedBatchNormV3;sequential/conv2d/BiasAdd/ReadVariableOp;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D/ReadVariableOp;sequential/conv2d/Conv2D1
 Index: 9
 Shape: [24  3  3  1]
 DType: <class 'numpy.int8'>
Name: sequential/batch_normalization_1/FusedBatchNormV3;sequential/conv2d_1/BiasAdd/ReadVariableOp;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D/ReadVariableOp;sequential/conv2d_1/Conv2D
 Index: 10
 Shape: [48  3  3 24]
 DType: <class 'numpy.int8'>
Name: sequential/batch_normalization_2/FusedBatchNormV3;sequential/conv2d_2/BiasAdd/ReadVariableOp;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D/ReadVariableOp;sequential/conv2d_2/Conv2D
 Index: 11
 Shape: [48  3  3 48]
 DType: <class 'numpy.int8'>
Name: sequential/batch_normalization/FusedBatchNormV3;sequential/conv2d/BiasAdd/ReadVariableOp;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D/ReadVariableOp;sequential/conv2d/Conv2D2
 Index: 12
 Shape: [ 1 49 40 24]
 DType: <class 'numpy.int8'>
Name: sequential/max_pooling2d/MaxPool
 Index: 13
 Shape: [ 1 12 20 24]
 DType: <class 'numpy.int8'>
Name: sequential/activation/Relu
 Index: 14
 Shape: [ 1 12 20 24]
 DType: <class 'numpy.int8'>
Name: sequential/batch_normalization_1/FusedBatchNormV3;sequential/conv2d_1/BiasAdd/ReadVariableOp;sequential/conv2d_1/BiasAdd;sequential/batch_normalization_2/FusedBatchNormV3;sequential/conv2d_2/BiasAdd/ReadVariableOp;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D/ReadVariableOp;sequential/conv2d_2/Conv2D;sequential/conv2d_1/Conv2D/ReadVariableOp;sequential/conv2d_1/Conv2D1
 Index: 15
 Shape: [ 1 12 20 48]
 DType: <class 'numpy.int8'>
Name: sequential/max_pooling2d_1/MaxPool
 Index: 16
 Shape: [ 1  3 10 48]
 DType: <class 'numpy.int8'>
Name: sequential/activation_1/Relu
 Index: 17
 Shape: [ 1  3 10 48]
 DType: <class 'numpy.int8'>
Name: sequential/activation_2/Relu;sequential/batch_normalization_2/FusedBatchNormV3;sequential/conv2d_2/BiasAdd/ReadVariableOp;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D/ReadVariableOp;sequential/conv2d_2/Conv2D1
 Index: 18
 Shape: [ 1  1  8 48]
 DType: <class 'numpy.int8'>
Name: sequential/flatten/Reshape
 Index: 19
 Shape: [  1 384]
 DType: <class 'numpy.int8'>
Name: sequential/activation_3/Relu;sequential/dense/BiasAdd
 Index: 20
 Shape: [ 1 64]
 DType: <class 'numpy.int8'>
Name: sequential/dense_1/BiasAdd
 Index: 21
 Shape: [ 1 14]
 DType: <class 'numpy.int8'>
Name: Identity_int8
 Index: 22
 Shape: [ 1 14]
 DType: <class 'numpy.int8'>
Name: conv2d_input
 Index: 23
 Shape: [ 1 49 40  1]
 DType: <class 'numpy.float32'>
Name: Identity
 Index: 24
 Shape: [ 1 14]
 DType: <class 'numpy.float32'>
```

This results in the interpreter failing while validating the input tensor, as the model_input->type != kTfLiteUInt8.
```c++
  // Get information about the memory area to use for the model's input.
  model_input = interpreter->input(0);
  if ((model_input->dims->size != 4) || (model_input->dims->data[0] != 1) ||
      (model_input->dims->data[1] != kFeatureSliceCount) ||
      (model_input->dims->data[2] != kFeatureSliceSize) ||
      (model_input->type != kTfLiteUInt8)) {
    error_reporter->Report(""Bad input tensor parameters in model"");
    return;
  }
```
May we please get a developer to comment on the likely causes of failed int8 quantization?  "
40680,Segmentation fault when running TFLite's benchmark_model,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Darwin Kernel Version 19.5.0(for model conversion, Linux 4.9.140-tegra for running the benchmark tool)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Installed TFLite benchmark_model tool using the instructions given here: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark.
- TensorFlow version (use command below): N/A
- Python version: N/A
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I converted emotion_ferplus (https://github.com/onnx/models/tree/master/vision/body_analysis/emotion_ferplus) ONNX model to TF using onnx-tensorflow(https://github.com/onnx/onnx-tensorflow) and then converted the TF model to TFLite using tflite_convert.
```
$ onnx-tf convert -i model.onnx -o emotion.pb
$ tflite_convert --enable_v1_converter --graph_def_file=emotion.pb --output_file=emotion.tflite --output_format=TFLITE --input_shape=1,1,64,64 --input_arrays=Input3 --output_arrays=Plus692_Output_0 --inference_type=FLOAT --input_data_type=FLOAT
```
Then I ran benchmark_model tool on the tflite model I got from the previous step.
```
onnxruntime@onnxruntime-desktop:~/Documents/tensorflow$ bazel-bin/tensorflow/lite/tools/benchmark/benchmark_model --graph=emotion.tflite --num_runs=10 --num_threads=4
STARTING!
Duplicate flags: num_threads
Min num runs: [10]
Min runs duration (seconds): [1]
Max runs duration (seconds): [150]
Inter-run delay (seconds): [-1]
Num threads: [0]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [emotion.tflite]
Input layers: []
Input shapes: []
Input value ranges: []
Input layer values files: []
Allow fp16 : [0]
Require full delegation : [0]
Enable op profiling: [0]
Max profiling buffer entries: [1024]
CSV File to export profiling data to: []
Enable platform-wide tracing: [0]
#threads used for CPU inference: [0]
Max number of delegated partitions : [0]
Min nodes per partition : [0]
External delegate path : []
External delegate options : []
Use gpu : [0]
Use xnnpack : [0]
Loaded model ../models/tflite/emotion.tflite
The input model file size (MB): 35.0461
Initialized session in 1.645ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
Segmentation fault (core dumped)

```

**Describe the expected behavior**
benchmark tool should run without crashing and give model performance metrics like the following:
```
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
count=10 first=101249 curr=46906 min=46491 max=101249 avg=52839.8 std=16163

Running benchmark for at least 10 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
count=22 first=46543 curr=46554 min=46473 max=49668 avg=46957.8 std=627

Inference timings in us: Init: 218485, First inference: 101249, Warmup (avg): 52839.8, Inference (avg): 46957.8
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Peak memory footprint (MB): init=1.23047 overall=28.8906
```

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40679,"Python 3.6? 3.8? Catalina install, R error 951, 951, 2290, 2649","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): nope
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina 10.15.5 on MacBook Pro (Retina, 13-inch, Early 2015) 2.7 GHz Dual-Core Intel Core i5 8 GB 1867 MHz DDR3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version:  3.8.3 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Below is the full code. When I run the 489 line the following error appears.
I have installed Python from terminal using  your guide [here](https://www.tensorflow.org/install/pip). I have installed KERAS for R and it installed python 3.6 in its own bin, all the files are there. 

I'm a bit confused as I'm not sure which version I should use here and where. I would start with a fresh laptop install if needed to make this work. I have similar issues on Windows tho (another issue already discussed).

Any idea? Error message below here

Epoch 1/50
7/7 [==============================] - ETA: 0s - loss: 0.5326 - categorical_accuracy: 0.7778
 Error in py_call_impl(callable, dots$args, dots$keywords) : 
  ValueError: in user code:

    /Users/axeldrioli/Library/r-miniconda/envs/r-reticulate/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:941 test_function  *
        outputs = self.distribute_strategy.run(
    /Users/axeldrioli/Library/r-miniconda/envs/r-reticulate/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /Users/axeldrioli/Library/r-miniconda/envs/r-reticulate/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /Users/axeldrioli/Library/r-miniconda/envs/r-reticulate/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /Users/axeldrioli/Library/r-miniconda/envs/r-reticulate/lib/python3.6/site-packages/tensorflow/python/keras/e 
**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
---
  title: ""Detection, Extraction and Classification of Bird and Bat Vocalizations in R""
author: ""Francois Fabianek, Jean Marchal""
date: ""2018 October 30th""
output:
  rmarkdown::html_vignette:
  fig_caption: yes
number_sections: yes
toc: yes
toc_depth: 4
rmarkdown::pdf_document:
  fig_caption: yes
number_sections: yes
toc: yes
toc_depth: 4
vignette: >
  %\VignetteIndexEntry{Tutorial: Detection, Extraction and Classification of Bird and Bat Vocalizations in R} 
%\VignetteEncoding{UTF-8}
%\VignetteEngine{knitr::knitr} 
---
  
  _______
_______

# Load the necessary packages

Make sure you have the latest version of the packages:
  
  ```{r install_packages, message=FALSE, eval=FALSE}
install.packages(""bioacoustics"")
# The bioacoustics package may also be installed from GitHub using devtools as follows:
devtools::install_github(""wavx/bioacoustics"", build_vignettes = TRUE)
install.packages(""warbleR"")
install.packages(""dplyr"")
install.packages(""magrittr"")
install.packages(""randomForest"")
```

```{r load_packages, message=FALSE, eval=FALSE}
# Load the packages
library(warbleR)
library(bioacoustics)
library(dplyr)
library(tools)
library(randomForest)
library(magrittr)
```


___________________

# Load audio files

We can use the `quer_xc()` function from **warbleR** to download bird vocalizations from Xeno-Canto: <https://www.xeno-canto.org/>
  
  We are going to choose calls from *Catharus bicknelli*, songs from *Passerella iliaca* and *Setophaga magnolia* recorded in the United States and Canada.

We will filter only ""A"" quality recordings, then, pick up only the first nine, and merge all the metadata into a single ""df"" data frame. This data frame will be used to download MP3 files in your working directory directly from Xeno-Canto with the `quer_xc()` function:
  
  ```{r xeno1, message=FALSE, eval=FALSE}
df1 = quer_xc(qword ='Catharus bicknelli type:call cnt:""United States""', download = FALSE)
df1 = df1[df1$Vocalization_type==""call"",]
df1 = df1[df1$Quality==""A"",]
df1 = df1[1:9,]

df2 = quer_xc(qword ='Setophaga magnolia type:song cnt:""Canada""', download = FALSE)
df2 = df2[df2$Quality==""A"",]
df2 = df2[1:9,]

df3 = quer_xc(qword ='Passerella iliaca type:song cnt:""Canada""', download = FALSE)
df3 = df3[df3$Vocalization_type==""song"",]
df3 = df3[df3$Quality %in% c(""A"", ""B""),]
df3 = df3[1:9,]
df3 <- df3 %>%
  select(-(""Other_species8""))
df3
df = rbind(df1,df2,df3)
rm(df1,df2,df3)
```

```{r xeno4, eval=FALSE}
# Visualize your data frame
View(df)
# We will work in the R temp directory
wd <- tempdir()
# Create a data directory if it does not exist
data_dir <- file.path(wd, ""data"")
if(!dir.exists(data_dir))
  dir.create(data_dir)
# Download the MP3 files into your data directory
quer_xc(X = df, download = TRUE, path = data_dir)


```

Now that we have recordings stored in the data directory, we can read one of them to look at its structure and content.

```{r read_audio, eval=TRUE}

CATBIC <- read_audio(file.path(data_dir, ""Catharus-bicknelli-54866.mp3""))
CATBIC

```

We can see that the MP3 file has been converted into a Wave object with 7551360 samples, a duration of 157.32 seconds, a sampling rate of 48000 Hz, a bit depth of 16 bits, and that it contains one channel (mono, stereo being two channels).

Remember that you just have to divide the number of samples by the sampling rate to retrieve the duration (s) of an audio file.

___________________

# Extract GUANO metadata

[GUANO](https://guano-md.org/) stands for the ""Grand Unified Acoustic Notation Ontology"" and means to be a universal, extensible, open metadata format for bat (ultrasonic) and non-bat (audible, infrasonic) acoustic recordings [more here](https://github.com/riggsd/guano-r). GUANO format is now embeded directly in the WAV files generated from most Pettersson, Wildlife Acoustics, Titley Scientific acoustic recorders. It is possible to extract the metadata and GUANO embedded in the WAV file by using the `metadata()` function.

```{r metadata,eval=FALSE}
metadata(CATBIC)
```
<br>


Now that we have explored a WAV file, we will use the Fast Fourrier Transform (FFT) to compute a frequency-time representation of the recording, called a spectrogram. A spectrogram being the representation of the spectrum of frequencies in a recording as they vary through time. This representation, although not optimal, is still commonly used to detect animal vocalizations and extract acoustic features useful for classification with the purpose of animal identification.
___________________

# Plot audio files

There are several options to display animal vocalizations in audio files with R. You can use both `spectro()` or `fspec()` functions to generate spectrograms with **bioacoustics**. `fspec()` generates only a matrix of the spectrogram, and thus has to be used with the `image()` function to display the spectrogram. It is also possible to use the `spectro()` function in **Seewave**.  

Next, we will search manually and display an audio event (here, a bird vocalization) from a recording of *Catharus bicknelli*. To display a Region Of Interest (ROI) of the recording we will use temporal and frequency filters. Lets start with a temporal slice from 1 to 10 secs and a FFT size of 512 sample

```{r spectro0, eval=FALSE}
# Set plot margins to 0
par(mar = c(0, 0, 0, 0), oma = c(0, 0, 0, 0))
# Display with spectro()
ticks <- c(from = 1000, to = 20000, by = 1000) # frequency tick marks from 1 to 
# 20 kHz, and steps at each 1 kHz
temp_slice <- c(from = 1, to = 10) # in seconds
spectro(CATBIC, tlim = temp_slice, FFT_size = 512, ticks_y = ticks)
```  

Lets display spectrograms with various time / frequency limits (with `tlim=` and `flim=` arguments). You can also play with other arguments in `spectro()` and `fspec()` functions such as the percent of overlap between two FFTs (with `FFT_overlap=`) and various FFT resolutions (with `FFT_size=`). Note that the arguments are briefly explained in the documentation of each function:  
  
```{r help, eval=FALSE}
# Access the arguments of the spectro function
?spectro
?fspec
```

First, lets shorten the temporal axis from 2 to 3.5 secs to work on a shorter time window and compare the outputs from `spectro()` and `fspec()`  functions. Note that spectrograms can also be generated automatically while using the detection functions from **bioacoustics**. We will explore that in details in section 4.1.

```{r spectro1, eval=FALSE}
# Set plot margins to 0
par(mar = c(0, 0, 0, 0), oma = c(0, 0, 0, 0))
# Display the spectrogram with spectro()
ticks <- c(from = 1000, to = 20000, by = 1000) # frequency tick marks from 1 to 
# 20 kHz, 1 kHz steps
temp_slice <- c(from = 2, to = 3.5) # in seconds
spectro(CATBIC, tlim = temp_slice, FFT_size = 512, ticks_y = ticks)
# fspec() gives you the spectrogram matrix with energy values (dB)
spec_mx <- fspec(CATBIC, tlim = temp_slice, FFT_size = 512, rotate = TRUE)
# You can display the spectrogram with image()
image(spec_mx, xaxt = ""n"", yaxt = ""n"") 
```

The tick marks on the (frequency) y-axis were defined in the `spectro()` function starting from 1 to 20 kHz with an interval at each 1 kHz. The FFT size was 512 samples with an overlap between two FFT windows set by default at 0.875. Now try these settings: FTT size = 256, 1024 and 2048; FFT overlap = 0.3, 0.6, 0.9...

Another interesting thing to perform with the fspec outputs, is to implement your own set of filters. Lets try to reduce the background noise from a spectrogram with a narrower time and frequency bandwidth:

```{r filter, eval=FALSE}
temp_slice <- c(from = 2.5, to = 3.5)
freq_slice <- c(from = 1500, to = 20000)
spec_o <- fspec(CATBIC, tlim = temp_slice, flim = freq_slice, FFT_size = 512, rotate = TRUE)
## min and max (range) dB intensity
range(spec_o) # -120 (min) to 0 dB (max)
# Note that the tolerance of your recorders depends on the number of bits. 
# 16-bit recorders offer only around -96 dB tolerance and sound pressure above
# this level is clipped to 0 dB.
## Let's try a filter by mean + sd intensity
spec_f <- fspec(CATBIC, tlim = temp_slice, flim = freq_slice, FFT_size = 512, rotate = TRUE)
spec_f[spec_f < mean(spec_f) + sd(spec_f)] <- -120
# Works well with high intensity audio events, but leads to
# false negatives (missed events) otherwise.
par(mar = c(0, 0, 0, 0), oma = c(0, 0, 0, 0))
image(spec_o, xaxt=""n"", yaxt=""n"")
image(spec_f, xaxt=""n"", yaxt=""n"")
```

___________________

# The use of filters to detect and extract audio events

The functions used to detect and extract audio events in a recording also rely on ""generic"" filters based on frequency and duration, along with other ""specific"" filters. Let's take a quick look at the generic filters available in the `threshold_detection()` and `blob_detection()` functions:

  * High Pass (HPF) and Low Pass filters (LPF) can be employed to reduce the amount of unwanted noise in the recording or to track particular audio events within a narrower frequency bandwidth than the recording sampling rate. Frequencies below the HPF and above the LPF cutoff are greatly attenuated. These frequency filters can be set using the `HPF=` and `LPF=` arguments in the `threshold_detection()` and `blob_detection()` functions.
  * Minimum and maximum duration of an audio event, and a minimum time between two audio events also help reduce the amount of unwanted noise, or track a particular audio event within a narrower temporal window. These temporal filters can be set using the `min_dur=`, `max_dur=`, and `TBE=` arguments in both `threshold_detection()` and `blob_detection()` functions.
  * Other set of filters are specific to each detection function and will be defined while working with these functions on bird vocalizations.

___________________

## Detect and extract audio events in a recording

### Threshold detection

Let's start with the `threshold_detection()` function on a recording containing calls from *Catharus bicknelli*. This function is an amplitude threshold detector that picks up audio events above the Signal to Noise Ratio (SNR). It combines several algorithms for detection, filtering and audio feature extraction. We will play with the arguments of this function to understand their implication in the detection and extraction of audio events (here, calls of *Catharus bicknelli*).  

```{r threshold_help, eval=FALSE}
# Access the arguments of the threshold_detection function
?threshold_detection
```

```{r threshold1, eval=FALSE}
# Set each argument according to the targeted audio events
TD <- threshold_detection(
  CATBIC, # Either a path to an audio file (see ?read_audio), or a Wave object
  threshold = 12, # 12 dB SNR sensitivity for the detection algorithm
  time_exp = 1, # Time expansion factor of 1. Only needed for bat recordings.
  min_dur = 140, # Minimum duration threshold of 140 milliseconds (ms)
  max_dur = 440, # Maximum duration threshold of 440 ms
  min_TBE = 10, # Minimum time window between two audio events of 10 milliseconds
  max_TBE = 5000, # Maximum time window between two audio events, here 5 seconds
  EDG = 0.996, # Temporal masking with Exponential Decay Gain from 0 to 1
  LPF = 10000, # Low-Pass Filter of 10 kHz
  HPF = 1000, # High-Pass Filter of 1 kHz
  FFT_size = 256, # Size of the Fast Fourrier Transform (FFT) window
  FFT_overlap = 0.875, # Percentage of overlap between two FFT windows
  
  start_thr = 25, # 25 dB threshold at the start of the audio event
  end_thr = 30, # 30 dB threshold at the end of the audio event
  SNR_thr = 10, # 10 dB SNR threshold at which the extraction of the audio event stops
  angle_thr = 45, # 45 of angle at which the extraction of the audio event stops
  duration_thr = 440, # Noise estimation is resumed after 440 ms
  NWS = 1000, # Time window length of 1 s used for background noise estimation
  KPE = 1e-05, # Process Error parameter of the Kalman filter (for smoothing)
  KME = 1e-04, # Measurement Error parameter of the Kalman filter (for smoothing)
  settings = FALSE, #  Save on a list the above parameters set with this function
  acoustic_feat = TRUE, # Extracts the acoustic and signal quality parameters 
  metadata = FALSE, # Extracts on a list the metadata embedded with the Wave file
  spectro_dir = file.path(tempdir(), ""Spectros""), # Directory where to save the spectrograms
  time_scale = 1, # Time resolution of 2 ms for spectrogram display
  ticks = TRUE # Tick marks and their intervals are drawn on the y-axis (frequencies) 
) 
# Get the number of extracted audio events
nrow(TD$data$event_data)
```

Let the HTML page open with the 57 spectrograms (each representing an extracted audio event). These settings will be our benchmark for the number of audio events that can be extracted with the `threshold_detection()` function. In the following exercise, you will try to reach or beat this number by exploring different combinations of parameters for each argument of the function.

```{r threshold2, eval=FALSE}
# Let's try various settings, starting with 1024 FFT size instead of 256.
TD <- threshold_detection(
  CATBIC, threshold = 12, time_exp = 1, min_dur = 140, max_dur = 440, 
  min_TBE = 10, max_TBE = 5000, EDG = 0.996, LPF = 10000, HPF = 1000, 
  FFT_size = 1024, FFT_overlap = 0.875, start_thr = 25, end_thr = 30, 
  SNR_thr = 10, angle_thr = 45, duration_thr = 440, NWS = 1000, 
  KPE = 1e-05, KME = 1e-04, settings = FALSE, acoustic_feat = TRUE,
  metadata = FALSE, spectro_dir = file.path(tempdir(), ""Spectros""), time_scale = 1, 
  ticks = c(1000, 10000, 1000) # Tick marks from 1 to 10 kHz with 1 kHz interval
) 
# Take a look at the spectrograms and compare them with the previous extraction.
nrow(TD$data$event_data) # Only three audio events!
```

We will play with various detection thresholds: end_thr, SNR_thr, angle_thr, KPE and KME parameters. Try to reach 66 spectrograms extracted with a contour (*i.e.*, Kalman curve) that best matches the audio event (answer below). The FFT size will be set at 256 samples.

```{r threshold3, eval=FALSE}
CATBIC <- read_audio(file.path(data_dir, ""Catharus-bicknelli-54866.mp3""))
TD <- threshold_detection(
  CATBIC, threshold = 12, time_exp = 1, min_dur = 140, max_dur = 440, min_TBE = 10, 
  max_TBE = Inf, EDG = 0.996, LPF = 10000, HPF = 1000, FFT_size = 256, FFT_overlap = 0.875, 
  start_thr = 22, end_thr = 30, SNR_thr = 10, angle_thr = 125, duration_thr = 440, NWS = 1000,
  KPE = 1e-05, KME = 1e-05, settings = FALSE, acoustic_feat = TRUE, metadata = FALSE
)
```

Lets take a look at the extracted audio features. Note that all the features are described and explained in the package vignette (`vignette(""bioacoustics"")`).

```{r features1, eval=FALSE}
# Acoustic features are stored in a data frame called event_data,
# stored by order of detection.
View(TD$data$event_data) # Contains the filename and the time of detection in the 
                         # recording, and 26 extracted features.
```

The location (in number of samples) of the audio event in the recording is saved in a list. 

```{r features2, eval=FALSE}
# Start and end of the 5th extracted audio event (in samples)
c(TD$data$event_start[[5]], TD$data$event_end[[5]])
# Remember you just have to divide by the sample rate to retrieve the time (s)
c(TD$data$event_start[[5]], TD$data$event_end[[5]]) / slot(CATBIC, ""samp.rate"")
```

The amplitude (dB) and frequency (Hz) tracks (or bins) are also saved in a list. These can be used to build your own acoustic features.

```{r features3, eval=FALSE}
par(mar = c(1,1, 1, 1), oma = c(1, 1, 1, 1))
# Amplitude track of the 5th audio event
plot(TD$data$amp_track[[5]], type = ""l"")
# Frequency track of the 5th audio event
plot(TD$data$freq_track[[5]], type = ""l"")
```

The whole energy and frequency content can also be used to classify audio events instead of using acoustic features that may result in a loss of information. We will get there soon, but first, lets discover another detection function, here applied on echolocation calls of bats.


### Blob detection

### The `blob_detection()` function will be used on a recording containing 10 bat echolocation calls from the *Myotis* genus. This function combines several image processing, filtering and image feature extraction. A blur and contrast boost is applied after mean background subtraction to increase the SNR of the audio event. The blob detection algorithm is applied on the processed spectrogram to detect the ROI (i.e., each preprocessed audio event). The blob detector simultaneously labels the connected FFT values and their contours in the spectrogram. Labelling is done in a single pass over the spectrogram, while contour points are revisited more than once and up to four times (see [Chang et al., 2004](https://www.iis.sinica.edu.tw/papers/fchang/1362-F.pdf)). We will play with the arguments of this function to extract bat echolocation calls.

```{r blob0, eval=FALSE}
### Access the arguments of the blob_detection function
?blob_detection
```

```{r blob1, eval=FALSE}
# Use the bat recording stored in the package
data(myotis)
# Set each argument according to the targeted audio events
BD <- blob_detection(
  myotis, # Either a path to an audio file (see ?read_audio), or a Wave object
  time_exp = 10, # Time expansion factor of 10 for time expanded recordings.
  min_dur = 1.5, # Minimum duration threshold of 1.5 milliseconds (ms)
  max_dur = 80, # Maximum duration threshold of 80 ms
  min_area = 40, # minimum number of 40 pixels in the blob
  min_TBE = 20, # Minimum time window between two audio events of 20 milliseconds
  EDG = 0.996, # Temporal masking with Exponential Decay Gain from 0 to 1
  LPF = slot(myotis, ""samp.rate"") * 10 / 2, # Low-Pass Filter at the Nyquist frequency
  HPF = 16000, # High-Pass Filter of 16 kHz
  FFT_size = 256, # Size of the Fast Fourrier Transform (FFT) window
  FFT_overlap = 0.875, # Percentage of overlap between two FFT windows
  blur = 2, # Gaussian smoothing function with a factor of 2 for blurring the spectrogram
  bg_substract = 20, # Foreground extraction with a mean filter applied on the spectrogram
  contrast_boost = 20, # Edge contrast enhancement filter of the spectrogram contour
  settings = FALSE, #  Save on a list the above parameters set with this function
  acoustic_feat = TRUE, # Extracts the acoustic and signal quality parameters 
  metadata = FALSE, # Extracts on a list the metadata embedded with the Wave file
  spectro_dir = file.path(tempdir(), ""Spectros""), # HTML page with spectrograms by order of detection 
  time_scale = 0.1, # Time resolution of 2 ms for spectrogram display
  ticks = TRUE # Tick marks and their intervals are drawn on y-axis (frequencies)
) 
# Get the number of extracted audio events
nrow(BD$data$event_data)
```

Do not close the HTML page and tune the FFT size at 512. Lets play with the blur, contrast boost and background subtraction parameters to retrieve a number of 10 extracted echolocation calls.

```{r blob2, eval=FALSE}
# Lets try various settings, starting with 512 FFT size instead of 256
BD <- blob_detection(
  myotis, time_exp = 10, FFT_size = 512, settings = FALSE, acoustic_feat = TRUE,
  metadata = FALSE, spectro_dir = file.path(tempdir(), ""Spectros""), time_scale = 0.1, ticks = TRUE
) 
# Take a look at the spectrograms and compare them with the previous extraction.
nrow(BD$data$event_data) # Only 6 audio events!
```

Lets take a look at the extracted audio features. All the features are described and explained in the package vignette.

```{r blobfeat1, eval=FALSE}
# Acoustic features
head(BD$data)
```

This data frame is, for now, the only available set of acoustic features with the `blob_detection()` function. However, it combines well with the `fspec()` to make image analysis.

Now that we have played with both detection functions with bird and bat vocalizations, lets go back to birds to explore batch analysis (*i.e.*, with several recordings) and audio event classification.

___________________

## Batch analysis and classification

In this section, we will learn how to analyze several recordings at the same time and train a simple classifier (with training set) that will be used to classify new data (*i.e.*, the test set).

We will work with 27 recordings of *Catharus-bicknelli* (*n* = 9), *Passerella iliaca* (*n* = 9), and *Setophaga-magnolia* (*n* = 9). We will split the extracted audio events in a 70 % training set (called ""Train"") and 30 % test set (called ""Test"").

Our target audio events are calls of *Catharus-bicknelli*. We will use the threshold detector previously configured for this species (see section 4.1.1).

```{r classification1, eval=FALSE}
# Get the filepath for each MP3 file
files <- dir(data_dir, recursive = TRUE, full.names = TRUE, pattern = ""[.]mp3$"")
# Detect and extract audio events
TDs <- setNames(
  lapply(
    files,
    threshold_detection,
    threshold = 12, min_dur = 140, max_dur = 440, min_TBE = 50, max_TBE = Inf,
    LPF = 8000, HPF = 1500, FFT_size = 256, start_thr = 30, end_thr = 20, 
    SNR_thr = 10, angle_thr = 125, duration_thr = 400, spectro_dir = NULL,
    NWS = 2000, KPE = 0.00001, time_scale = 2, EDG = 0.996
  ),
  basename(file_path_sans_ext(files))
)
# Keep only files with data in it
TDs <- TDs[lapply(TDs, function(x) length(x$data)) > 0]
# Keep the extracted feature and merge in a single data frame for further analysis
Event_data <- do.call(""rbind"", c(lapply(TDs, function(x) x$data$event_data), list(stringsAsFactors = FALSE)))
nrow(Event_data) # 355 audio events extracted
# Compute the number of extracted CATBIC calls
sum(startsWith(Event_data$filename, ""Cat""))
# Add a ""Class"" column: ""CATBIC"" vs. other species of birds ""OTHERS""
classes <- as.factor(ifelse(startsWith(Event_data$filename, ""Cat""), ""CATBIC"", ""OTHERS""))
Event_data <- cbind(data.frame(Class = classes), Event_data)
# Get rid of the filename and time in the recording
Event_data$filename <- Event_data$starting_time <- NULL
```

We now have the necessary dataset to train a classifier: we will train a Random Forest on the training set and validate the results on the test set.

```{r classification2, eval=FALSE}
# Split the data in 60% Training / 40% Test sets
train <- sample(1:nrow(Event_data), round(nrow(Event_data) * .6))
Train <- Event_data[train,]
test <- setdiff(1:nrow(Event_data), train)
Test <- Event_data[test,]
# Train a random forest classifier
set.seed(666)
rf <- randomForest(Class ~ duration + freq_max_amp + freq_max + freq_min +
                     bandwidth + freq_start + freq_center + freq_end +
                     freq_knee + fc + freq_bw_knee_fc + bin_max_amp + 
                     pc_freq_max_amp + pc_freq_max + pc_freq_min +
                     pc_knee + temp_bw_knee_fc + slope + kalman_slope +
                     curve_neg + curve_pos_start + curve_pos_end + 
                     mid_offset + smoothness + snr + hd + smoothness,
                   data = Train, importance = FALSE, proximity = FALSE,
                   replace = TRUE, ntree = 4000, mtry = 4)
# Look at the confusion matrix of the training set
rf$confusion # looks good, but...
# Let's make predictions with our classifier on a test set
table(Test[,1], predict(rf, Test[,-1], type = ""response"")) # not bad!
# To look at the predictions 
head(predict(rf, Test[,-1], type = ""prob""))
```

We are now able to use this simple, but proven robust, classifier to detect new calls of your target species.


___________________

# Deep learning classification with the R interface to Keras

We will use Keras in R which requires to install several packages in [Python](https://www.python.org/downloads/)
Guidelines to install Keras properly in R are available [here](https://keras.rstudio.com/)

Lets now explore a ConvNet approach available on Keras. We will follow the approach of [Hatami et al. (2017)](https://arxiv.org/pdf/1710.00886.pdf) to analyze time series as images with 2D ConvNets. The difference is that we will only perform max pooling at the last layer before activation and add batch normalization with dropouts at each layer.

```{r keras1, eval=FALSE}
devtools::install_github(""rstudio/keras"")
# Run if keras is installed on your machine
library(keras)
# Build the training set
Y_train <- to_categorical(as.integer(Train[,1]) - 1) # One hot encoding
# X as matrix
X_train <- as.matrix(Train[,-1])
# Build the test set
Y_test <- to_categorical(as.integer(Test[,1]) - 1)
Y_test <- Y_test[,-1]
X_test <- as.matrix(Test[,-1])
# Build the sequential model
mod0 <- keras_model_sequential()
mod0 %>%
  # Input shape layer = c(samples, rows, cols, channels)
  layer_reshape(input_shape=ncol(X_train),target_shape=c(1,1,ncol(X_train))) %>% 
  # First conv 2d layer with 128 neurons, kernel size of 8 x 8 and stride of 1 x 1
  layer_conv_2d(128, c(8,8), c(1,1), padding='same') %>%
  layer_batch_normalization() %>%
  layer_activation(""relu"") %>%
  layer_dropout(0.2) %>%
  # Second conv 2d layer with 256 neurons, kernel size of 5 x 5 and stride of 1 x 1
  layer_conv_2d(256, c(5,5), c(1,1), padding='same') %>%
  layer_batch_normalization() %>%
  layer_activation(""relu"") %>%
  layer_dropout(0.2) %>%
  # Third conv 2d layer with 128 neurons, kernel size of 3 x 3 and stride of 1 x 1
  layer_conv_2d(128, c(3,3), c(1,1), padding='same') %>%
  layer_batch_normalization() %>%
  layer_activation(""relu"") %>%
  layer_dropout(0.2) %>%
  # Average pooling layer
  layer_global_average_pooling_2d() %>%
  # Activation output layer with 2 classes
  layer_dense(units = ncol(Y_train),  activation='softmax')
# Model compile
mod0 %>% compile(loss = 'categorical_crossentropy',
                 optimizer = ""adam"",
                 metrics = ""categorical_accuracy"")
# Add a callback to reduce the learning rate when reaching the plateau
reduce_lr <- callback_reduce_lr_on_plateau(monitor = 'loss', factor = 0.5,
                                           patience = 50, min_lr = 0.0001)
# Start learning
mod0 %>% fit(X_train, Y_train, batch_size = 32, epochs = 50,
             validation_data = list(X_test, Y_test),
             verbose = 1, callbacks = reduce_lr)
# Score on the test set
score <- mod0 %>% evaluate(X_test, Y_test, batch_size = 32)
score
```

Lets work a bit with the output to build a confusion matrix and use the predict function on the test set.

```{r keras2, eval=FALSE}
# Look at predictions and build a confusion matrix
Pred <- as.factor(predict_classes(mod0, X_test, batch_size = 32, verbose = 1))
table(Y_test[,2], Pred)
# To look at the prediction values 
Prob <- round(predict_proba(mod0, X_test, batch_size = 32, verbose = 1), 2)
```


We obtained a val_loss < 0.2 and val_categorical_accuracy > 0.94 which is acceptable, but not better than the simplest RF approach we used in section 3.2.
Using only 26 acoustic features as model inputs instead of the whole spectrogram content (energy and frequency distribution, and harmonics) probably reduced the performances of the CNN model.

This tutorial is now complete. Comments and feedback are welcome:
  
  Francois: francois.fabianek@wavx.ca  
Jean: jean.marchal@wavx.ca  
[www.wavx.ca](https://www.wavx.ca)


_______
_______

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40677,Unsupported ops when converting keyword spotting model,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Darwin Kernel Version 19.5.0
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 1.15.2


**Command used to run the converter or code if youre using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
tflite_convert --enable_v1_converter --graph_def_file=tf5/DS_CNN_L.pb --output_file=tflite/DS_CNN_L.tflite --output_format=TFLITE --input_shape=1 --input_arrays=wav_data --output_arrays=labels_softmax --inference_type=FLOAT --input_data_type=STRING
```

**The output from the converter invocation**

```
2020-06-22 19:10:58.286058: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-22 19:10:58.298962: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f998703d820 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-22 19:10:58.298980: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-22 19:10:58.334024: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-06-22 19:10:58.334124: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-22 19:10:58.366223: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize
2020-06-22 19:10:58.366256: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 125 nodes (-57), 125 edges (-57), time = 15.329ms.
2020-06-22 19:10:58.366261: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 125 nodes (0), 125 edges (0), time = 6.637ms.
Traceback (most recent call last):
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/bin/tflite_convert"", line 11, in <module>
    sys.exit(main())
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 515, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 511, in run_main
    _convert_tf1_model(tflite_flags)
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 199, in _convert_tf1_model
    output_data = converter.convert()
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 983, in convert
    **converter_kwargs)
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 449, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 200, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-06-22 19:11:00.826624: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeWav
2020-06-22 19:11:00.826669: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: AudioSpectrogram
2020-06-22 19:11:00.826680: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Mfcc
2020-06-22 19:11:00.828343: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 98 operators, 181 arrays (0 quantized)
2020-06-22 19:11:00.829492: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 98 operators, 181 arrays (0 quantized)
2020-06-22 19:11:00.833039: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 19 operators, 46 arrays (0 quantized)
2020-06-22 19:11:00.833242: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 19 operators, 46 arrays (0 quantized)
2020-06-22 19:11:00.833372: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 19 operators, 46 arrays (0 quantized)
2020-06-22 19:11:00.833621: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.
2020-06-22 19:11:00.833699: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 410704
2020-06-22 19:11:00.834066: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: AVERAGE_POOL_2D, CONV_2D, DEPTHWISE_CONV_2D, FULLY_CONNECTED, RESHAPE, SOFTMAX, SQUEEZE. Here is a list of operators for which you will need custom implementations: AudioSpectrogram, DecodeWav, Mfcc.
Traceback (most recent call last):
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/bin/toco_from_protos"", line 11, in <module>
    sys.exit(main())
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/prroy/Documents/MachineLearning/onnx_projects/onnxrt_env/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: AVERAGE_POOL_2D, CONV_2D, DEPTHWISE_CONV_2D, FULLY_CONNECTED, RESHAPE, SOFTMAX, SQUEEZE. Here is a list of operators for which you will need custom implementations: AudioSpectrogram, DecodeWav, Mfcc.
```

**Also, please include a link to the saved model or GraphDef**

```
https://github.com/ARM-software/ML-KWS-for-MCU/tree/master/Pretrained_models/DS_CNN
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40676,quantization not yet supported for op %,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):tf-nightly2.3
- TensorFlow version (or github SHA if from source):


**Command used to run the converter or code if youre using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
```
conventer=tf.lite.TFLiteConverter.from_keras_model(inference)
conventer.optimizations = [tf.lite.Optimize.DEFAULT]
conventer.representative_dataset = representative_data_gen
conventer.experimental_new_converter=True
conventer.target_spec.supported_ops=[tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
conventer.inference_input_type = tf.uint8  # or tf.uint8
conventer.inference_output_type = tf.uint8  # or tf.uint8
tflitemodel=conventer.convert()
open(""./centernet.tflite"",""wb"").write(tflitemodel)


**The output from the converter invocation**
quantization not yet supported for op % 
```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)
post-traiing quantization for uint8 model 

**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**
got an error:quantization not yet supported for op %
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40673,@Lu1352 Can you please open a new issue with a simple standalone code to reproduce the error? Thanks!,"@Lu1352 Can you please open a new issue with a simple standalone code to reproduce the error? Thanks!

_Originally posted by @jvishnuvardhan in https://github.com/tensorflow/tensorflow/issues/35750#issuecomment-642966950_

Here you go:
```
#!/usr/bin/python3
import tensorflow as tf
import numpy as np
import os

(train_images, train_answers), (test_images, test_answers) = tf.keras.datasets.mnist.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0

modelfile=""saved.model""
if os.path.exists(modelfile):
   model = tf.keras.models.load_model(modelfile)
else:
   model = tf.keras.models.Sequential([
     tf.keras.layers.Flatten(input_shape=(28, 28)),
     tf.keras.layers.Dense(128, activation='relu'),
     tf.keras.layers.Dropout(0.2),
     tf.keras.layers.Dense(10)
   ])
   loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
   model.compile(optimizer='adam', loss=loss_fn)
   model.fit(train_images, train_answers, epochs=1)
   model.save(modelfile)
model.summary()
```

Run it twice to reproduce the error:
```
Traceback (most recent call last):
  File ""./bug.py"", line 11, in <module>
    model = tf.keras.models.load_model(modelfile)
  File ""/home/dbw/.local/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py"", line 146, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ""/home/dbw/.local/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 244, in load_model_from_hdf5
    sample_weight_mode=sample_weight_mode)
  File ""/home/dbw/.local/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/dbw/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 300, in compile
    self.loss, self.output_names)
  File ""/home/dbw/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py"", line 1094, in prepare_loss_functions
    generic_utils.check_for_unexpected_keys('loss', loss, output_names)
  File ""/home/dbw/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 592, in check_for_unexpected_keys
    expected_values))
ValueError: Unknown entries in loss dictionary: ['class_name', 'config']. Only expected following keys: ['dense_1']
```"
40672,Optimizing scatter_nd_* for complex tensors,"**System information**
- TensorFlow version (you are using): 2.2
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

Currently, as noted in #40605 , the `scatter_nd_*` functions are extremely slow.

However, this is even more extreme when used on complex tensors. This [colab notebook](https://colab.research.google.com/drive/1omAKl8vcqd2TBVbXEnVGvey8Urmcp-kH?usp=sharing) illustrates this fact.

A simple hack consisting in treating separately real and imaginary parts makes us gain a factor 20 on computation time.

I guess at least this hack could be implemented at the python level of the op, a part on which I am definitely willing to contribute.

**Will this change the current api? How?**

No

**Who will benefit with this feature?**

Everyone using complex tensors, so I would say people working in sound processing and MRI, but this is surely not exhaustive.

**Any Other info.**

I don't know if this is due to eager execution or not. I don't necessarily know how to best profile these kind of issues in graph mode.

I think even if this is eager-related it still deserves a fix."
40671,"[TF 1.15] unexpected segment faults for seemingly ""reasonable and correct"" codes","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos7  (but libtensorflow.so is built in official docker image tensorflow/serving:1.15.0-devel-gpu)
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.15.0
- Python version: 3
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version: 10.0
- GPU model and memory: 1080Ti 11178MiB

**Describe the current behavior**
It is by-product of tensorflow serving. In official docker image (tensorflow/serving:1.15.0-devel-gpu) , we build tensorflow serving 1.15 based on tensorflow 1.15. Everything is OK for tensorflow serving mode, and it has been deployed in our product environment. However, we meet the bottleneck of inter-process for current tensorflow serving, hence we consider using direct local GPU infer.  

Luckily tensorflow is already included in tensorflow serving.  In tensorflow folder we build tensorflow_cc. using following command:

```shell
cd ./tensorflow
export  TF_NEED_CUDA=1
export  TF_NEED_S3=1
export  TF_CUDA_COMPUTE_CAPABILITIES=""3.5,5.2,6.1""
export  TF_NEED_GCP=1
export  TF_NEED_JEMALLOC=0
export  TF_NEED_HDFS=0
export  TF_NEED_OPENCL=0
export  TF_NEED_MKL=0
export  TF_NEED_VERBS=0
export  TF_NEED_MPI=0
export  TF_DOWNLOAD_MKL=0
export  TF_NEED_GDR=0
export  TF_ENABLE_XLA=0
export  TF_CUDA_CLANG=0
export  TF_NEED_OPENCL_SYCL=0
export  GCC_HOST_COMPILER_PATH=/usr/bin/gcc
export  PYTHON_BIN_PATH=/usr/bin/python
export  PYTHON_LIB_PATH=/usr/lib/python2.7/site-packages/
export  CC_OPT_FLAGS=""-march=native""
bazel build -c opt --config=cuda --copt=-mavx --verbose_failures tensorflow:libtensorflow_cc.so
```

Build is OK as:
```
INFO: From Compiling external/snappy/snappy-sinksource.cc:    
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
INFO: From Compiling external/snappy/snappy-stubs-internal.cc:                                            
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
INFO: From Compiling external/snappy/snappy.cc:                                   
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++                                                                                             
Target //tensorflow:libtensorflow_cc.so up-to-date:                             
  bazel-bin/tensorflow/libtensorflow_cc.so                                               
INFO: Elapsed time: 1258.352s, Critical Path: 455.73s                                                                                                                  
INFO: 7436 processes: 7436 local.                                                                                                                                                
INFO: Build completed successfully, 11163 total actions  
```

Then I import following files into my project:
```
  libtensorflow_cc.so
  libtensorflow_framework.so.1 so
  c_api.h
  tf_atrrtype.h
  tf_datatype.h
  tf_status.h
tf_tensor.h
```
My code calls only C api of tensorflow (which is tested in old cpu tensorflow 1.13 version, and main code logic is OK), and main code is below:
```
// init session
    TF_Session * sess;
    TF_SessionOptions* sess_opts = TF_NewSessionOptions();
    if(proto_len > 0)
    {
        TF_SetConfig(sess_opts,(void*)options_proto, proto_len, status);

        if(TF_GetCode(status) != TF_OK)
        {
            TF_DeleteSessionOptions(sess_opts);
            return NULL;
        }
    }
    sess = TF_NewSession(graph, sess_opts, status);

// session infer (most crashes occurs here)
TF_SessionRun(...)
```

SPECIAL NOTE: due to environment and other dependencies issues, my personal project  has to be built in local GPU centos (default glibc is old 2.17). In order to exclude the difference of gcc and glibc,   I build my project by using the same gcc 5.4.0 (the same as tensorflow/serving:1.15.0-devel-gpu) and the same glibc 2.23 (the same as tensorflow/serving:1.15.0-devel-gpu). Here is change of cmakelist.txt:
```
set(third_links ${third_links}
    -Wl,--rpath=/myf12/Code/glibc-2.23/install/lib
    -Wl,--dynamic-linker=/myf12/Code/glibc-2.23/install/lib/ld-2.23.so
    -lrt
    )
list(INSERT third_links 0 ""-L /myf12/Code/glibc-2.23/install/lib/"") 
```
where third_links will be used as
```
target_link_libraries(xxx	${third_links} )
```
Build is ok and here is ldd info:
```
ldd bin.debug/fst
        linux-vdso.so.1 =>  (0x00007ffc51718000)
        libdl.so.2 => /myf12/Code/glibc-2.23/install/lib/libdl.so.2 (0x00007f2c4f224000)
        libtensorflow_cc_v1.15_avx.so => /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so (0x00007f2c11963000)
        librt.so.1 => /myf12/Code/glibc-2.23/install/lib/librt.so.1 (0x00007f2c1175b000)
        libjemalloc.so.2 => /mnt/lustre/cm/shared/global/src/misc/jemalloc/5.2.1/lib/libjemalloc.so.2 (0x00007f2c112cc000)
        libpthread.so.0 => /myf12/Code/glibc-2.23/install/lib/libpthread.so.0 (0x00007f2c110af000)
        libstdc++.so.6 => /mnt/lustre/cm/shared/global/src/dev/gcc/5.4.0/lib64/libstdc++.so.6 (0x00007f2c10d34000)
        libm.so.6 => /myf12/Code/glibc-2.23/install/lib/libm.so.6 (0x00007f2c10a2e000)
        libgcc_s.so.1 => /mnt/lustre/cm/shared/global/src/dev/gcc/5.4.0/lib64/libgcc_s.so.1 (0x00007f2c10817000)
        libc.so.6 => /myf12/Code/glibc-2.23/install/lib/libc.so.6 (0x00007f2c10476000)
        /myf12/Code/glibc-2.23/install/lib/ld-2.23.so => /lib64/ld-linux-x86-64.so.2 (0x00007f2c4f42a000)
        libcusparse.so.10.0 => /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libcusparse.so.10.0 (0x00007f2c0ca0c000)
        libcusolver.so.10.0 => /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libcusolver.so.10.0 (0x00007f2c04325000)
        libnvinfer.so.5 => /mnt/lustre/cm/shared/global/src/machinelearning/tensorrt/TensorRT-5.0.2.6/lib/libnvinfer.so.5 (0x00007f2bfcec8000)
        libnvinfer_plugin.so.5 => /mnt/lustre/cm/shared/global/src/machinelearning/tensorrt/TensorRT-5.0.2.6/lib/libnvinfer_plugin.so.5 (0x00007f2bfc995000)
        libcublas.so.10.0 => /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libcublas.so.10.0 (0x00007f2bf83ff000)
        libcudnn.so.7 => /mnt/lustre/cm/shared/global/src/dev/cudnn/7.5.1/lib64/libcudnn.so.7 (0x00007f2be2de0000)
        libcufft.so.10.0 => /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libcufft.so.10.0 (0x00007f2bdc92b000)
        libcurand.so.10.0 => /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libcurand.so.10.0 (0x00007f2bd87c4000)
        libcudart.so.10.0 => /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libcudart.so.10.0 (0x00007f2bd854a000)
        libgomp.so.1 => /mnt/lustre/cm/shared/global/src/dev/gcc/5.4.0/lib64/libgomp.so.1 (0x00007f2bd8327000)
        libnvToolsExt.so.1 => /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libnvToolsExt.so.1 (0x00007f2bd811e000)

```

Program crashes due to segment fault as below:
```
2020-06-22 12:03:56.005532: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.                       
2020-06-22 12:03:56.007051: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0                                                                 
2020-06-22 12:03:56.650162: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:                               
2020-06-22 12:03:56.650296: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0                                                                                        
2020-06-22 12:03:56.650307: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N                                                                                        
2020-06-22 12:03:56.652890: F external/org_tensorflow/tensorflow/core/common_runtime/device.cc:28] Check failed: DeviceNameUtils::ParseFullName(name(), &parsed_name_) Invalid device name:
```

core dump is
```
#0  0x00007f0482651298 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54
#1  0x00007f048265271a in __GI_abort () at abort.c:89
#2  0x00007f048e307a34 in tensorflow::internal::LogMessageFatal::~LogMessageFatal() () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#3  0x00007f048dc2921f in tensorflow::Device::Device(tensorflow::Env*, tensorflow::DeviceAttributes const&) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#4  0x00007f048dc62e64 in tensorflow::LocalDevice::LocalDevice(tensorflow::SessionOptions const&, tensorflow::DeviceAttributes const&) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#5  0x00007f048d4d9166 in tensorflow::BaseGPUDevice::BaseGPUDevice(tensorflow::SessionOptions const&, std::string const&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality const&, tensorflow::gtl::IntType<tensorflow::TfGpuId_tag_, int>, std::string const&, tensorflow::Allocator*, tensorflow::Allocator*, bool, int) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#6  0x00007f048d4e40c8 in tensorflow::GPUDeviceFactory::CreateGPUDevice(tensorflow::SessionOptions const&, std::string const&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality const&, tensorflow::gtl::IntType<tensorflow::TfGpuId_tag_, int>, std::string const&, tensorflow::Allocator*, tensorflow::Allocator*) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#7  0x00007f048d4dcc9e in tensorflow::BaseGPUDeviceFactory::CreateGPUDevice(tensorflow::SessionOptions const&, std::string const&, tensorflow::gtl::IntType<tensorflow::TfGpuId_tag_, int>, long long, tensorflow::DeviceLocality const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#8  0x00007f048d4e1f2a in tensorflow::BaseGPUDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::string const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#9  0x00007f048dc299c9 in tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&, std::string const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#10 0x00007f048c709161 in tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#11 0x00007f048dca7380 in tensorflow::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
```

Then I fix ""bug"" in following line https://github.com/tensorflow/tensorflow/blob/590d6eef7e91a6a7392c8ffffb7b58f2e0c8bc6b/tensorflow/core/common_runtime/gpu/gpu_device.cc#L1265
from
```
const string device_name =
      strings::StrCat(name_prefix, ""/device:GPU:"", tf_gpu_id.value());
```
 into
```
const string device_name = name_prefix + ""/device:GPU:"" + std::to_string(tf_gpu_id.value());
```

Previous crash is avoided (see new log ""Created TensorFlow device"" ) and rerun again. It crashes again in ""InferStatically"":
```
2020-06-22 12:08:22.185006: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.                       
2020-06-22 12:08:22.186563: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1768] Adding visible gpu devices: 0                                                                 
2020-06-22 12:08:23.047640: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:                                
2020-06-22 12:08:23.047693: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0                                                                                        
2020-06-22 12:08:23.047705: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N                                                                                        
2020-06-22 12:08:23.050308: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8164 MB memory) ->
 physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)                                                                                                    
                                                                                                                                                                                                           
                                                                                                                                                                                                           
^[[A^[[ASegmentation fault (core dumped)    

#0  0x00007fa69ce6ce96 in std::_Hashtable<tensorflow::NodeDef const*, std::pair<tensorflow::NodeDef const* const, tensorflow::grappler::NodeState>, std::allocator<std::pair<tensorflow::NodeDef const* cons
t, tensorflow::grappler::NodeState> >, std::__detail::_Select1st, std::equal_to<tensorflow::NodeDef const*>, std::hash<tensorflow::NodeDef const*>, std::__detail::_Mod_range_hashing, std::__detail::_Defau
lt_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_M_find_before_node(unsigned long, tensorflow::NodeDef const* const&, unsigned long) const [clo
ne .isra.856] () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so

#1  0x00007fa69ce76041 in tensorflow::grappler::VirtualScheduler::GetNodeStateOrCreateIt(tensorflow::NodeDef const*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so         
#2  0x00007fa69ce78d9b in tensorflow::grappler::VirtualScheduler::Init(tensorflow::grappler::GrapplerItem const*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so            
#3  0x00007fa69ce569df in tensorflow::grappler::AnalyticalCostEstimator::PredictCosts(tensorflow::GraphDef const&, tensorflow::RunMetadata*, tensorflow::grappler::Costs*) const ()                        
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#4  0x00007fa69ce4f37f in tensorflow::grappler::VirtualCluster::Run(tensorflow::grappler::GrapplerItem const&, tensorflow::RunMetadata*) ()                                                                
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#5  0x00007fa69cdddb5a in tensorflow::grappler::GraphMemory::InferStatically(std::unordered_map<std::string, tensorflow::DeviceProperties, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, tensorflow::DeviceProperties> > > const&) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so                                                     
#6  0x00007fa69cdce427 in tensorflow::grappler::(anonymous namespace)::IdentifySwappingCandidates(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> >*, std::unordered_map<tensorflow::NodeDef*, tensorflow::grappler::(anonymous namespace)::SwapInfo, std::hash<tensorflow::NodeDef*>, std::equal_to<tensorflow::NodeDef*>, std::allocator<std::pair<tensorflow::NodeDef* const, tensorflow::grappler::(anonymous namespace)::SwapInfo> > >*) [clone .constprop.1020] ()                      
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#7  0x00007fa69cdd091d in tensorflow::grappler::(anonymous namespace)::SwappingPass(tensorflow::RewriterConfig_MemOptType, tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> >*) [clone .constprop.1019] ()                                                                         
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#8  0x00007fa69cdd3a97 in tensorflow::grappler::MemoryOptimizer::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()                             
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#9  0x00007fa69cd01e5a in tensorflow::grappler::MetaOptimizer::RunOptimizer(tensorflow::grappler::GraphOptimizer*, tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, tensorflow::GraphDef*, tensorflow::grappler::MetaOptimizer::GraphOptimizationResult*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so                                                            
#10 0x00007fa69cd03431 in tensorflow::grappler::MetaOptimizer::OptimizeGraph(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()                          
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#11 0x00007fa69cd04c64 in tensorflow::grappler::MetaOptimizer::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()                               
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#12 0x00007fa69cd070af in tensorflow::grappler::RunMetaOptimizer(tensorflow::grappler::GrapplerItem const&, tensorflow::ConfigProto const&, tensorflow::DeviceBase*, tensorflow::grappler::Cluster*, tensorflow::GraphDef*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#13 0x00007fa69ccf5fa8 in tensorflow::GraphExecutionState::OptimizeGraph(tensorflow::BuildGraphOptions const&, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> >*, std::unique_ptr<tensorflow::FunctionLibraryDefinition, std::default_delete<tensorflow::FunctionLibraryDefinition> >*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so                       
#14 0x00007fa69ccf8361 in tensorflow::GraphExecutionState::BuildGraph(tensorflow::BuildGraphOptions const&, std::unique_ptr<tensorflow::ClientGraph, std::default_delete<tensorflow::ClientGraph> >*) ()   
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#15 0x00007fa69bd9e46a in tensorflow::DirectSession::CreateGraphs(tensorflow::BuildGraphOptions const&, std::unordered_map<std::string, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> >, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> > > > >*, std::unique_ptr<tensorflow::FunctionLibraryDefinition, std::default_delete<tensorflow::FunctionLibraryDefinition> >*, tensorflow::DirectSession::RunStateArgs*, absl::InlinedVector<tensorflow::DataType, 4ul, std::allocator<tensorflow::DataType> >*, absl::InlinedVector<tensorflow::DataType, 4ul, std::allocator<tensorflow::DataType> >*, long long*) ()                                                                        
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#16 0x00007fa69bd9f9de in tensorflow::DirectSession::CreateExecutors(tensorflow::CallableOptions const&, std::unique_ptr<tensorflow::DirectSession::ExecutorsAndKeys, std::default_delete<tensorflow::DirectSession::ExecutorsAndKeys> >*, std::unique_ptr<tensorflow::DirectSession::FunctionInfo, std::default_delete<tensorflow::DirectSession::FunctionInfo> >*, tensorflow::DirectSession::RunStateArgs*) ()      
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#17 0x00007fa69bda1d64 in tensorflow::DirectSession::GetOrCreateExecutors(absl::Span<std::string const>, absl::Span<std::string const>, absl::Span<std::string const>, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so                                                                          
#18 0x00007fa69bda3648 in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> >
> const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so                                                                                                 
#19 0x00007fa696f70911 in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, TF_Tensor**, std::vector<std::string, std::allocator<std::string> > const&, TF_Buffer*, TF_Status*) [clone .constprop.628] ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#20 0x00007fa696f71179 in TF_SessionRun () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so 
```

Then I fix ""bug"" in following line https://github.com/tensorflow/tensorflow/blob/590d6eef7e91a6a7392c8ffffb7b58f2e0c8bc6b/tensorflow/core/grappler/costs/graph_properties.cc#L2140
from
```
fed_ports[tensor_id.node()].insert(tensor_id.index());
```
 into:
```
      if (fed_ports.find(tensor_id.node()) == fed_ports.end())
      {
         std::unordered_set<int> ports = {tensor_id.index()};
         fed_ports[tensor_id.node()] = ports;
      }
      else
      {
         fed_ports[tensor_id.node()].insert(tensor_id.index());
      }
```

This crash is fixed  and rerun again. It crashes again in ""GetNodeStateOrCreateIt"" .
```
#0  0x00007f348a9f4e46 in std::_Hashtable<tensorflow::NodeDef const*, std::pair<tensorflow::NodeDef const* const, tensorflow::grappler::NodeState>, std::allocator<std::pair<tensorflow::NodeDef const* const, tensorflow::grappler::NodeState> >, std::__detail::_Select1st, std::equal_to<tensorflow::NodeDef const*>, std::hash<tensorflow::NodeDef const*>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_M_find_before_node(unsigned long, tensorflow::NodeDef const* const&, unsigned long) const [clone .isra.856] ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#1  0x00007f348a9fe1f5 in tensorflow::grappler::VirtualScheduler::GetNodeStateOrCreateIt(tensorflow::NodeDef const*) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#2  0x00007f348aa00e5d in tensorflow::grappler::VirtualScheduler::Init(tensorflow::grappler::GrapplerItem const*) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#3  0x00007f348a9de98f in tensorflow::grappler::AnalyticalCostEstimator::PredictCosts(tensorflow::GraphDef const&, tensorflow::RunMetadata*, tensorflow::grappler::Costs*) const ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#4  0x00007f348a9d732f in tensorflow::grappler::VirtualCluster::Run(tensorflow::grappler::GrapplerItem const&, tensorflow::RunMetadata*) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#5  0x00007f348a965b0a in tensorflow::grappler::GraphMemory::InferStatically(std::unordered_map<std::string, tensorflow::DeviceProperties, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, tensorflow::DeviceProperties> > > const&) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so

```

After quickly fixing 2 bugs, it is unexpected and impossible for me to see theses ""obvious bugs"" in tensorflow release 1.15.  I strongly suspect it relates to some build configuration or running configuration. 

Can you help check it? Thanks. 
"
40670,Initialization of rmsprop optimizer in tensorflow,"In tensorflow RMSPROP optimizer can be used with tf.compat.v1.train.RMSPropOptimizer function as follows.

tf.compat.v1.train.RMSPropOptimizer(
    learning_rate, decay=0.9, momentum=0.0, epsilon=1e-10, use_locking=False,
    centered=False, name='RMSProp'
)
But it doesn't convey how to initialize moving average of the squared gradient for each weight.  Can anyone tell me how does tensorflow initialize it?"
40669,Windowing on multiple timeseries,"Usecase:
I have 360 day history of 1000 company stocks. My requirement is to create overlapping windows of the timeseries data for every company stock.

Current Solution (none TF one):
Currently I have implemented this by grouping the data on 'company' and applying a function that creates multi-step input and multistep output using pd.shift() function. Looking to upgrade the code using Tensorflow2.2 preprocessing functions.

Partial solutions tried:
I have tried the ""window"" function of the tf.data.Dataset that comprises of a single company's history. And I have tried the group_by_reducer function to group the data using 'company' as key. But could not figure a complete solution that can replace my current solution.

Please let me know if any code snippets are required. Appreciate any help or pointers on this.

Regards,
Jo
"
40668,ImportError: No module named '_pywrap_tensorflow',"I installed tensorflow in VS Code on Python 3.7.7 (32-bit) using the code :
 ```pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.0-py3-none-any.whl```
It successfully got installed at first, but when i tried to run a small code to check if it works it gave me error. I have referred to the earlier mentions of this issue and i have Microsoft Visual C++ 2015 already installed. 
Here is the code i tried to run -
```#This file has been made to practice tensors/numpy/pandas
import tensorflow as tf
import numpy as np
r0t = tf.constant(4)
print(r0t)```

**Here the error i'm facing -**

```PS D:\programs\Python> python tensor.py
Traceback (most recent call last):
  File ""C:\Users\Harshit Paliwal\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""C:\Users\Harshit Paliwal\AppData\Local\Programs\Python\Python37-32\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Harshit Paliwal\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Harshit Paliwal\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Users\Harshit Paliwal\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ModuleNotFoundError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""tensor.py"", line 2, in <module>
    import tensorflow as tf
  File ""C:\Users\Harshit Paliwal\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\Harshit Paliwal\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\__init__.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Harshit Paliwal\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""C:\Users\Harshit Paliwal\AppData\Local\Programs\Python\Python37-32\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Harshit Paliwal\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Harshit Paliwal\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Users\Harshit Paliwal\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ModuleNotFoundError: No module named '_pywrap_tensorflow'


Failed to load the native TensorFlow runtime.

See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
PS `D:\programs\Python>```
I also reffered to the GitHub link given in the last 4th line but the page is no more available.
Please provide me with a working solution to this problem.
Thanks
"
40667,having impport error ..tensorflow and tflearn,"having impport error ..tensorflow and tflearn

AttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'

i  am experiencing same import error in tflearn as well as tensorflow ..when i comment out import tensorflow same error is been reported as shown below ...
also thse libraries where working just fine a couple of days before ...i had imported them without showing errors .
i have just added python socketio and flask packages in virtual env
using python 3.6.10
tflearn :0.3
tensorflow :1.14
![Screenshot (65)](https://user-images.githubusercontent.com/65727171/85283770-890d9f00-b4ab-11ea-9d42-2094a54d75a7.png)
![Screenshot (64)](https://user-images.githubusercontent.com/65727171/85283781-8dd25300-b4ab-11ea-91d2-69381ab042b5.png)

_Originally posted by @BV-SS in https://github.com/tensorflow/tensorflow/issues/38589#issuecomment-647464978_"
40666,Very strange Reshape layer behavier in Keras,"
**System information**
- win10
- TensorFlow installed from pip
- TensorFlow version (use command below): 1.15.0, cpu version
- Python version: 3.6
- Keras: 2.2.4


**Describe the current behavior**
while I create a net,like this:

```
print(priorbox3.shape) #got (?, 38, 38, 3, 8)
priorbox3_reshape = Reshape((38*38*3, 4))(priorbox3)
print(priorbox3_reshape.shape) #(?, 4332, 4)
```

It runs successfully, but in fact 38 * 38 * 3 * 8 != 4332 * 4!

 if I set Reshape((38 * 38 * 3, 8)), I will get a mismatch error.

You can download the code and run:

```
python libfacemodel.py
```

[code.zip](https://github.com/tensorflow/tensorflow/files/4812938/code.zip)

"
40665,Cross-compile TFLite aarch64 with TF ops,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0
- Python version: Python3
- Installed using virtualenv? pip? conda?: -
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: 10.1/7
- GPU model and memory: -



I'm trying to cross-compile TFLite model with TF ops with tensorflow/lite/delegates/flex:delegate dep, and it failed on @icu//:icuuc

Build:
`bazel build -c opt --config=elinux_aarch64 --config=noaws --config=nogcp --config=nohdfs --config=nonccl --config=monolithic //tensorflow/lite/examples/myexample:myexample`

My .tf_configure.bazelrc:
```
build --action_env PYTHON_BIN_PATH=""/usr/bin/python3""
build --action_env PYTHON_LIB_PATH=""/usr/lib/python3/dist-packages""
build --python_path=""/usr/bin/python3""
#build --config=xla
build --config=tensorrt
build --action_env TF_CUDA_VERSION=""10.1""
build --action_env TF_CUDNN_VERSION=""7""
build --action_env CUDA_TOOLKIT_PATH=""/usr/local/cuda-10.1""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""3.5,7.0""
build --action_env LD_LIBRARY_PATH=""/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64/stubs:/usr/include/x64_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64""
build --action_env GCC_HOST_COMPILER_PATH=""/usr/bin/x86_64-linux-gnu-gcc-7""
#build --config=cuda
build:opt --copt=-march=native
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_env=LD_LIBRARY_PATH
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu,-v1only
build --action_env TF_CONFIGURE_IOS=""0""
```

Error:
```
ERROR: /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/icu/BUILD.bazel:33:1: C++ compilation of rule '@icu//:icuuc' failed (Exit 1)
external/icu/icu4c/source/common/brkiter.cpp:55:1: error: no declaration matches 'icu_60::BreakIterator* icu_60::BreakIterator::buildInstance(const icu_60::Locale&, const char*, UErrorCode&)'
 BreakIterator::buildInstance(const Locale& loc, const char *type, UErrorCode &status)
 ^~~~~~~~~~~~~
In file included from external/icu/icu4c/source/common/unicode/rbbi.h:28,
                 from external/icu/icu4c/source/common/brkiter.cpp:27:
/usr/include/unicode/brkiter.h:619:27: note: candidate is: 'static icu_60::BreakIterator* icu_60::BreakIterator::buildInstance(const icu_60::Locale&, const char*, int32_t, UErrorCode&)'
     static BreakIterator* buildInstance(const Locale& loc, const char *type, int32_t kind, UErrorCode& status);
                           ^~~~~~~~~~~~~
/usr/include/unicode/brkiter.h:102:20: note: 'class icu_60::BreakIterator' defined here
 class U_COMMON_API BreakIterator : public UObject {
                    ^~~~~~~~~~~~~
external/icu/icu4c/source/common/brkiter.cpp: In static member function 'static icu_60::BreakIterator* icu_60::BreakIterator::makeInstance(const icu_60::Locale&, int32_t, UErrorCode&)':
external/icu/icu4c/source/common/brkiter.cpp:415:70: error: no matching function for call to 'icu_60::BreakIterator::buildInstance(const icu_60::Locale&, const char [9], UErrorCode&)'
         result = BreakIterator::buildInstance(loc, ""grapheme"", status);
                                                                      ^
In file included from external/icu/icu4c/source/common/unicode/rbbi.h:28,
                 from external/icu/icu4c/source/common/brkiter.cpp:27:
/usr/include/unicode/brkiter.h:619:27: note: candidate: 'static icu_60::BreakIterator* icu_60::BreakIterator::buildInstance(const icu_60::Locale&, const char*, int32_t, UErrorCode&)'
     static BreakIterator* buildInstance(const Locale& loc, const char *type, int32_t kind, UErrorCode& status);
                           ^~~~~~~~~~~~~
/usr/include/unicode/brkiter.h:619:27: note:   candidate expects 4 arguments, 3 provided
external/icu/icu4c/source/common/brkiter.cpp:418:66: error: no matching function for call to 'icu_60::BreakIterator::buildInstance(const icu_60::Locale&, const char [5], UErrorCode&)'
         result = BreakIterator::buildInstance(loc, ""word"", status);
                                                                  ^
In file included from external/icu/icu4c/source/common/unicode/rbbi.h:28,
                 from external/icu/icu4c/source/common/brkiter.cpp:27:
/usr/include/unicode/brkiter.h:619:27: note: candidate: 'static icu_60::BreakIterator* icu_60::BreakIterator::buildInstance(const icu_60::Locale&, const char*, int32_t, UErrorCode&)'
     static BreakIterator* buildInstance(const Locale& loc, const char *type, int32_t kind, UErrorCode& status);
                           ^~~~~~~~~~~~~
/usr/include/unicode/brkiter.h:619:27: note:   candidate expects 4 arguments, 3 provided
external/icu/icu4c/source/common/brkiter.cpp:431:66: error: no matching function for call to 'icu_60::BreakIterator::buildInstance(const icu_60::Locale&, char [32], UErrorCode&)'
         result = BreakIterator::buildInstance(loc, lbType, status);
                                                                  ^
In file included from external/icu/icu4c/source/common/unicode/rbbi.h:28,
                 from external/icu/icu4c/source/common/brkiter.cpp:27:
/usr/include/unicode/brkiter.h:619:27: note: candidate: 'static icu_60::BreakIterator* icu_60::BreakIterator::buildInstance(const icu_60::Locale&, const char*, int32_t, UErrorCode&)'
     static BreakIterator* buildInstance(const Locale& loc, const char *type, int32_t kind, UErrorCode& status);
                           ^~~~~~~~~~~~~
/usr/include/unicode/brkiter.h:619:27: note:   candidate expects 4 arguments, 3 provided
external/icu/icu4c/source/common/brkiter.cpp:434:70: error: no matching function for call to 'icu_60::BreakIterator::buildInstance(const icu_60::Locale&, const char [9], UErrorCode&)'
         result = BreakIterator::buildInstance(loc, ""sentence"", status);
                                                                      ^
In file included from external/icu/icu4c/source/common/unicode/rbbi.h:28,
                 from external/icu/icu4c/source/common/brkiter.cpp:27:
/usr/include/unicode/brkiter.h:619:27: note: candidate: 'static icu_60::BreakIterator* icu_60::BreakIterator::buildInstance(const icu_60::Locale&, const char*, int32_t, UErrorCode&)'
     static BreakIterator* buildInstance(const Locale& loc, const char *type, int32_t kind, UErrorCode& status);
                           ^~~~~~~~~~~~~
/usr/include/unicode/brkiter.h:619:27: note:   candidate expects 4 arguments, 3 provided
external/icu/icu4c/source/common/brkiter.cpp:451:67: error: no matching function for call to 'icu_60::BreakIterator::buildInstance(const icu_60::Locale&, const char [6], UErrorCode&)'
         result = BreakIterator::buildInstance(loc, ""title"", status);
                                                                   ^
In file included from external/icu/icu4c/source/common/unicode/rbbi.h:28,
                 from external/icu/icu4c/source/common/brkiter.cpp:27:
/usr/include/unicode/brkiter.h:619:27: note: candidate: 'static icu_60::BreakIterator* icu_60::BreakIterator::buildInstance(const icu_60::Locale&, const char*, int32_t, UErrorCode&)'
     static BreakIterator* buildInstance(const Locale& loc, const char *type, int32_t kind, UErrorCode& status);
                           ^~~~~~~~~~~~~
/usr/include/unicode/brkiter.h:619:27: note:   candidate expects 4 arguments, 3 provided
Target //tensorflow/lite/examples/myexample:myexample failed to build

```"
40664,Tensorflow import issues,"i can't import tensorflow in python
because it says 'ModuleNotFoundError: No module named 'tensorflow.contrib''
tensorflow version is 2.x
what should i do?
windows 8.1
complete nooob to ml and ai
(i am new to github)"
40663,Coral edge TPU Classification coordinates ,"Hi,
I am running my object classification using Raspberry pi 4, model B, coral edge TPU. I am using this command to classify the image. 

    model.classify_with_image(frame, threshold=args[confidence])

It works perfectly but It does not give me coordinates like 

    model.detect_with_image() 

Is there any way I can get the coordinates?

From the official documentation: 

    detection: 
    detect_with_image(img, threshold=0.1, top_k=3, keep_aspect_ratio=False, relative_coord=True, resample=0)
    classification: 
    classify_with_image(img, threshold=0.1, top_k=3, resample=0)

"
40662,build,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
40661,"build failed with build_all_android.sh as ""make: *** No rule to make target '/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX1', needed by '/home/jason/workspace/algo/tf/tensorflow/tensorflow/contrib/makefile/gen/obj/android_armeabi-v7a/tensorflow/core/kernels/cast_op_impl_bool.o'.  Stop. make: *** Waiting for unfinished jobs....","Hi Guys,
I need to generate tensorflow static library for 32bit or 64 bit Arm for qsee platform. This is my first time to use tensorflow. I am trying to use ""./tensorflow/contrib/makefile/build_all_android.sh "" to generate such static library. Unfortunetly, it build failed.

Below are the information I am using, and problem are also described. Do you have any idea about it. Appreciated very much ^ ^.

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.1 LTS
- TensorFlow installed from (source or binary): source
- TensorFlow version: r1.5
- Python version: Python 2.7.17
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source): android-ndk-r12b


**Describe the problem**
Can not build successful with script build_all_android.sh

**Provide the exact sequence of commands / steps that you executed before running into the problem**
build command used: ./tensorflow/contrib/makefile/build_all_android.sh 


**Any other info / logs**
**make: *** No rule to make target '/home/jason/workspace/algo/tf/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX1', needed by '/home/jason/workspace/algo/tf/tensorflow/tensorflow/contrib/makefile/gen/obj/android_armeabi-v7a/tensorflow/core/kernels/cast_op_impl_bool.o'.  Stop.
make: *** Waiting for unfinished jobs....**

"
40660,Getting Error while tranning rasa model.(rasa train),"Traceback (most recent call last):
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\AKSHU\Anaconda3\envs\rasa\Scripts\rasa.exe\__main__.py"", line 7, in <module>
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\site-packages\rasa\__main__.py"", line 82, in main
    set_log_level(log_level)
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\site-packages\rasa\utils\common.py"", line 71, in set_log_level
    update_tensorflow_log_level()
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\site-packages\rasa\utils\common.py"", line 112, in update_tensorflow_log_level
    import tensorflow as tf
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""c:\users\akshu\anaconda3\envs\rasa\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
40659,[TF 2.2] Elapsed time of ConcreteFunction becomes shorter when printing loss,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
    - Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
    - Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
    - No
- TensorFlow installed from (source or binary):
    - Source
- TensorFlow version (use command below):
    - v2.2.0-0-g2b96f3662b (2.2.0)
- Python version:
    - 3.8.3
- Bazel version (if compiling from source):
    - 2.0.0
- GCC/Compiler version (if compiling from source):
    - 7.5.0
- CUDA/cuDNN version:
    - 10.0 / 7.6
- GPU model and memory:
    - NVIDIA Titan XP (11.9GB)

**Describe the current behavior**

I want to measure forward computation + backward computation time in `tf.function`
with a custom training loop.
Thus I wrapped `tf.function` scope to contain
- model forward
- tape.gradient

(I know that it is much more efficient if I include `apply_gradient` into `tf.function` scope,
but I didn't for my estimation).
If I print loss right after the function call, the estimated time becomes significantly different
(much shorter when w/ print loss, much longer when w/o print loss)

**Describe the expected behavior**

elapsed time should not be shorter when we print loss
(longer could be ok if `tf.function` runs asynchronously. printing loss will synchronize device execution)
(I think it runs asynchronously because if I print loss before applying gradients, throughput goes down and profiled trace shows that `ResourceApplyMomentum` operations are not overlapped with backpropagation)

**Standalone code to reproduce the issue**

Simplest version to reproduce
```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import time
import numpy as np

import tensorflow as tf
from tensorflow.python import keras
from tensorflow.python.eager import def_function
from tensorflow.python.keras import applications
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import random_seed
from tensorflow.python.ops import random_ops
from tensorflow.python.ops import losses
from tensorflow.python.eager.backprop import GradientTape

def main():
  model = applications.resnet.ResNet50(True, None)
  bs = 64

  @def_function.function
  def tf_function_scope(x, y_):
    with GradientTape() as tape:
      y = model(x)
      loss = losses.losses_impl.sparse_softmax_cross_entropy(y_, logits=y)
    grads = tape.gradient(loss, model.trainable_variables)
    return loss, grads

  # Train
  optimizer = keras.optimizer_v2.gradient_descent.SGD(0.01)
  for step in range(20):
    fake_x = random_ops.random_uniform([bs, 224, 224, 3], dtype=dtypes.float32)
    fake_y = random_ops.random_uniform([bs,],
                                       minval=0,
                                       maxval=1000,
                                       dtype=dtypes.int64)
    start = time.time()

    loss, grads = tf_function_scope(fake_x, fake_y)
    tf_func_end = time.time()

    print(loss)  # on / off makes different (tf_func_end - start) result
    print((tf_func_end - start) * 1000)

    optimizer.apply_gradients(zip(grads, model.trainable_variables))
    end = time.time()

    print('step %d, took %.3f ms (before apply_gradients: %f), throghput: %f' % \
          (step, (end-start)*1000, (tf_func_end - start)*1000, bs / (end - start)))

if __name__ == '__main__':
  os.environ['CUDA_VISIBLE_DEVICES'] = '0'
  main()
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

1. Without print loss
```
2020-06-22 08:42:40.022588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-22 08:42:40.123857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-06-22 08:42:40.124190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-06-22 08:42:40.126113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-06-22 08:42:40.127874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-06-22 08:42:40.128249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-06-22 08:42:40.130484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-06-22 08:42:40.132267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-06-22 08:42:40.137410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-22 08:42:40.148777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-22 08:42:40.190909: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2099905000 Hz
2020-06-22 08:42:40.197116: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b7233c1450 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-22 08:42:40.197192: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-22 08:42:40.393986: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b72342ab40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-22 08:42:40.394053: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2020-06-22 08:42:40.397195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-06-22 08:42:40.397284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-06-22 08:42:40.397334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-06-22 08:42:40.397374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-06-22 08:42:40.397414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-06-22 08:42:40.397443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-06-22 08:42:40.397472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-06-22 08:42:40.397502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-22 08:42:40.402115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-22 08:42:40.402174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-06-22 08:42:40.405355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-22 08:42:40.405380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-06-22 08:42:40.405407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-06-22 08:42:40.412971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11318 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-06-22 08:42:46.001636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-06-22 08:42:46.209792: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
tf function time: 4361.180067062378
step 0, took 4409.801 ms (before apply_gradients: 4361.180067), throghput: 14.513127
tf function time: 122.9701042175293
step 1, took 160.225 ms (before apply_gradients: 122.970104), throghput: 399.438503
tf function time: 292.9036617279053
step 2, took 329.290 ms (before apply_gradients: 292.903662), throghput: 194.357749
tf function time: 293.7884330749512
step 3, took 329.407 ms (before apply_gradients: 293.788433), throghput: 194.288679
tf function time: 296.1745262145996
step 4, took 331.075 ms (before apply_gradients: 296.174526), throghput: 193.309700
tf function time: 295.7441806793213
step 5, took 328.914 ms (before apply_gradients: 295.744181), throghput: 194.579640
tf function time: 297.3062992095947
step 6, took 328.839 ms (before apply_gradients: 297.306299), throghput: 194.624079
tf function time: 300.38952827453613
step 7, took 336.697 ms (before apply_gradients: 300.389528), throghput: 190.081826
tf function time: 295.8531379699707
step 8, took 333.771 ms (before apply_gradients: 295.853138), throghput: 191.748377
tf function time: 293.9162254333496
step 9, took 330.256 ms (before apply_gradients: 293.916225), throghput: 193.788929
tf function time: 295.107364654541
step 10, took 328.889 ms (before apply_gradients: 295.107365), throghput: 194.594592
tf function time: 296.8401908874512
step 11, took 328.850 ms (before apply_gradients: 296.840191), throghput: 194.617871
tf function time: 298.9656925201416
step 12, took 330.844 ms (before apply_gradients: 298.965693), throghput: 193.444828
tf function time: 300.534725189209
step 13, took 337.954 ms (before apply_gradients: 300.534725), throghput: 189.374994
tf function time: 295.2277660369873
step 14, took 335.415 ms (before apply_gradients: 295.227766), throghput: 190.808195
tf function time: 291.32676124572754
step 15, took 334.997 ms (before apply_gradients: 291.326761), throghput: 191.046658
tf function time: 287.0829105377197
step 16, took 333.483 ms (before apply_gradients: 287.082911), throghput: 191.914116
tf function time: 284.6190929412842
step 17, took 327.860 ms (before apply_gradients: 284.619093), throghput: 195.205059
tf function time: 288.6462211608887
step 18, took 329.876 ms (before apply_gradients: 288.646221), throghput: 194.012187
tf function time: 291.00489616394043
step 19, took 328.769 ms (before apply_gradients: 291.004896), throghput: 194.665292

```

2. with print loss

```
2020-06-22 08:43:03.438864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-22 08:43:03.560570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-06-22 08:43:03.561008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-06-22 08:43:03.563477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-06-22 08:43:03.565449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-06-22 08:43:03.565884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-06-22 08:43:03.568719: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-06-22 08:43:03.570816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-06-22 08:43:03.575264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-22 08:43:03.588127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-22 08:43:03.622770: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2099905000 Hz
2020-06-22 08:43:03.628790: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5632029c85b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-22 08:43:03.628829: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-22 08:43:03.814060: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563202a31ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-22 08:43:03.814126: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2020-06-22 08:43:03.822679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-06-22 08:43:03.822786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-06-22 08:43:03.822813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-06-22 08:43:03.822833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-06-22 08:43:03.822864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-06-22 08:43:03.822883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-06-22 08:43:03.822903: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-06-22 08:43:03.822934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-22 08:43:03.826928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-22 08:43:03.826991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-06-22 08:43:03.830583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-22 08:43:03.830633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-06-22 08:43:03.830665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-06-22 08:43:03.835490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11318 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-06-22 08:43:09.605652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-06-22 08:43:09.814419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
loss: tf.Tensor(6.9077563, shape=(), dtype=float32)
tf function time: 4659.780740737915
step 0, took 4717.544 ms (before apply_gradients: 4659.780741), throghput: 13.566382
loss: tf.Tensor(6.907754, shape=(), dtype=float32)
tf function time: 123.58546257019043
step 1, took 376.163 ms (before apply_gradients: 123.585463), throghput: 170.138898
loss: tf.Tensor(6.9077573, shape=(), dtype=float32)
tf function time: 123.61717224121094
step 2, took 368.745 ms (before apply_gradients: 123.617172), throghput: 173.561522
loss: tf.Tensor(6.9077635, shape=(), dtype=float32)
tf function time: 123.36468696594238
step 3, took 367.381 ms (before apply_gradients: 123.364687), throghput: 174.205911
loss: tf.Tensor(6.907756, shape=(), dtype=float32)
tf function time: 122.72977828979492
step 4, took 375.007 ms (before apply_gradients: 122.729778), throghput: 170.663412
loss: tf.Tensor(6.9077506, shape=(), dtype=float32)
tf function time: 123.32725524902344
step 5, took 377.959 ms (before apply_gradients: 123.327255), throghput: 169.330637
loss: tf.Tensor(6.907758, shape=(), dtype=float32)
tf function time: 123.4426498413086
step 6, took 377.844 ms (before apply_gradients: 123.442650), throghput: 169.382137
loss: tf.Tensor(6.907757, shape=(), dtype=float32)
tf function time: 126.03235244750977
step 7, took 374.068 ms (before apply_gradients: 126.032352), throghput: 171.091986
loss: tf.Tensor(6.9077587, shape=(), dtype=float32)
tf function time: 130.0036907196045
step 8, took 373.924 ms (before apply_gradients: 130.003691), throghput: 171.157768
loss: tf.Tensor(6.907766, shape=(), dtype=float32)
tf function time: 122.81250953674316
step 9, took 367.702 ms (before apply_gradients: 122.812510), throghput: 174.053986
loss: tf.Tensor(6.907754, shape=(), dtype=float32)
tf function time: 122.46370315551758
step 10, took 367.749 ms (before apply_gradients: 122.463703), throghput: 174.031643
loss: tf.Tensor(6.9077454, shape=(), dtype=float32)
tf function time: 123.29578399658203
step 11, took 366.575 ms (before apply_gradients: 123.295784), throghput: 174.589101
loss: tf.Tensor(6.9077616, shape=(), dtype=float32)
tf function time: 123.33488464355469
step 12, took 366.533 ms (before apply_gradients: 123.334885), throghput: 174.609088
loss: tf.Tensor(6.9077625, shape=(), dtype=float32)
tf function time: 123.26574325561523
step 13, took 368.901 ms (before apply_gradients: 123.265743), throghput: 173.488161
loss: tf.Tensor(6.907754, shape=(), dtype=float32)
tf function time: 123.28004837036133
step 14, took 378.585 ms (before apply_gradients: 123.280048), throghput: 169.050499
loss: tf.Tensor(6.9077578, shape=(), dtype=float32)
tf function time: 123.01921844482422
step 15, took 367.751 ms (before apply_gradients: 123.019218), throghput: 174.030853
loss: tf.Tensor(6.907749, shape=(), dtype=float32)
tf function time: 122.85351753234863
step 16, took 370.019 ms (before apply_gradients: 122.853518), throghput: 172.964222
loss: tf.Tensor(6.9077587, shape=(), dtype=float32)
tf function time: 123.2306957244873
step 17, took 367.553 ms (before apply_gradients: 123.230696), throghput: 174.124776
loss: tf.Tensor(6.9077473, shape=(), dtype=float32)
tf function time: 122.7264404296875
step 18, took 369.329 ms (before apply_gradients: 122.726440), throghput: 173.287243
loss: tf.Tensor(6.9077606, shape=(), dtype=float32)
tf function time: 123.77810478210449
step 19, took 370.604 ms (before apply_gradients: 123.778105), throghput: 172.691160

```

3. hybrid (print loss when step >= 10)

```
2020-06-22 08:45:28.959617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-22 08:45:29.091472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-06-22 08:45:29.091790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-06-22 08:45:29.093565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-06-22 08:45:29.095172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-06-22 08:45:29.095532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-06-22 08:45:29.097694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-06-22 08:45:29.099348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-06-22 08:45:29.104566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-22 08:45:29.111665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-22 08:45:29.150924: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2099905000 Hz
2020-06-22 08:45:29.157422: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559b110449d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-22 08:45:29.157478: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-22 08:45:29.406413: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559b110ae0b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-22 08:45:29.406485: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2020-06-22 08:45:29.413518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-06-22 08:45:29.413695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-06-22 08:45:29.413772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-06-22 08:45:29.413815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-06-22 08:45:29.413858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-06-22 08:45:29.413901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-06-22 08:45:29.413944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-06-22 08:45:29.413988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-22 08:45:29.421650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-22 08:45:29.421769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-06-22 08:45:29.424724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-22 08:45:29.424749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-06-22 08:45:29.424774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-06-22 08:45:29.428730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11318 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-06-22 08:45:34.957824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-06-22 08:45:35.250004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
tf function time: 4716.739177703857
step 0, took 4782.601 ms (before apply_gradients: 4716.739178), throghput: 13.381840
tf function time: 120.75352668762207
step 1, took 162.472 ms (before apply_gradients: 120.753527), throghput: 393.912849
tf function time: 288.3281707763672
step 2, took 331.619 ms (before apply_gradients: 288.328171), throghput: 192.992408
tf function time: 286.7617607116699
step 3, took 327.575 ms (before apply_gradients: 286.761761), throghput: 195.374982
tf function time: 288.7263298034668
step 4, took 332.976 ms (before apply_gradients: 288.726330), throghput: 192.206123
tf function time: 285.6485843658447
step 5, took 330.235 ms (before apply_gradients: 285.648584), throghput: 193.801241
tf function time: 285.5794429779053
step 6, took 328.592 ms (before apply_gradients: 285.579443), throghput: 194.770378
tf function time: 286.8924140930176
step 7, took 330.659 ms (before apply_gradients: 286.892414), throghput: 193.552647
tf function time: 287.52660751342773
step 8, took 333.751 ms (before apply_gradients: 287.526608), throghput: 191.759609
tf function time: 282.52458572387695
step 9, took 325.800 ms (before apply_gradients: 282.524586), throghput: 196.439568
loss: tf.Tensor(6.907755, shape=(), dtype=float32)
tf function time: 286.6995334625244
step 10, took 533.805 ms (before apply_gradients: 286.699533), throghput: 119.893993
loss: tf.Tensor(6.9077554, shape=(), dtype=float32)
tf function time: 120.00322341918945
step 11, took 362.584 ms (before apply_gradients: 120.003223), throghput: 176.510883
loss: tf.Tensor(6.907754, shape=(), dtype=float32)
tf function time: 120.20373344421387
step 12, took 364.925 ms (before apply_gradients: 120.203733), throghput: 175.378661
loss: tf.Tensor(6.90776, shape=(), dtype=float32)
tf function time: 120.89180946350098
step 13, took 367.710 ms (before apply_gradients: 120.891809), throghput: 174.050262
loss: tf.Tensor(6.907758, shape=(), dtype=float32)
tf function time: 121.07729911804199
step 14, took 375.999 ms (before apply_gradients: 121.077299), throghput: 170.213015
loss: tf.Tensor(6.907757, shape=(), dtype=float32)
tf function time: 121.16265296936035
step 15, took 371.518 ms (before apply_gradients: 121.162653), throghput: 172.266043
loss: tf.Tensor(6.907759, shape=(), dtype=float32)
tf function time: 121.36077880859375
step 16, took 371.042 ms (before apply_gradients: 121.360779), throghput: 172.487427
loss: tf.Tensor(6.9077525, shape=(), dtype=float32)
tf function time: 120.78547477722168
step 17, took 364.453 ms (before apply_gradients: 120.785475), throghput: 175.605711
loss: tf.Tensor(6.907755, shape=(), dtype=float32)
tf function time: 120.941162109375
step 18, took 375.551 ms (before apply_gradients: 120.941162), throghput: 170.416059
loss: tf.Tensor(6.9077535, shape=(), dtype=float32)
tf function time: 120.76926231384277
step 19, took 362.911 ms (before apply_gradients: 120.769262), throghput: 176.351553
```"
40658,tf2.2-tensorrt error,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- OS Platform and Distribution: DOCKER IMAGE:tensorflow/tensorflow:2.2.0-gpu
- GPU model and memory:Tesla K40m, 12GB

**Standalone code to reproduce the issue**
I want to use tensorrt api in tensorflow to speed up model inference.
## I simply created a model in savedmodel format with the following code
import tensorflow as tf
import numpy as np

model = tf.keras.applications.ResNet50(
    include_top=True,
    weights=None,
    input_shape=(300, 300, 3),
    classes=30
)

model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy)

data = np.random.normal(size=(3, 300, 300,3)).astype(np.float32)

model.predict(data)

model.save('original_saved_model')

## I am going to use the following code for inferred acceleration
import numpy as np
import tensorflow as tf

from absl import app
from absl import flags

FLAGS = flags.FLAGS
flags.DEFINE_enum('mode', 'FP16', ['FP16', 'FP32'], 'FP16 or FP32')
flags.DEFINE_string('original_model_dir', None, 'Original saved model dir')
flags.DEFINE_string('output_dir', None, 'Output model dir')

flags.mark_flags_as_required(['mode', 'original_model_dir', 'output_dir'])


def my_input_fn():
    for _ in range(2):
        # input1 = tf.random.normal(shape=(3, 300, 300, 3))
        input1 = np.random.normal(size=(1, 3, 300, 300, 3)).astype(np.float32)
        yield input1


def main(argv):
    del argv
    params = tf.experimental.tensorrt.ConversionParams(
        precision_mode=FLAGS.mode,
        max_batch_size=10,
        maximum_cached_engines=16)
    converter = tf.experimental.tensorrt.Converter(
        input_saved_model_dir=FLAGS.original_model_dir, conversion_params=params)
    converter.convert()
    converter.build(input_fn=my_input_fn)
    converter.save(FLAGS.output_dir)


if __name__ == '__main__':
    app.run(main)

## But something wrong
#### I simply thought change code `if not first_input` to `if first_input is not None` may ok. Maybe i am too naive.
## The running log below
root@f973fbbb7e16:/niuyifeng/remote# python tensorrt_use_pre_engine.py --original_model_dir=original_saved_model/ --output_dir=use_pre_engine
/usr/local/lib/python3.6/dist-packages/absl/flags/_validators.py:359: UserWarning: Flag --mode has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!
  'command line!' % flag_name)
2020-06-22 08:41:09.212475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
INFO:tensorflow:Linked TensorRT version: (6, 0, 1)
I0622 08:41:09.212588 139998758545216 trt_convert.py:264] Linked TensorRT version: (6, 0, 1)
INFO:tensorflow:Loaded TensorRT version: (6, 0, 1)
I0622 08:41:09.212863 139998758545216 trt_convert.py:265] Loaded TensorRT version: (6, 0, 1)
2020-06-22 08:41:09.534433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-22 08:41:09.541097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: Tesla K40m computeCapability: 3.5
coreClock: 0.745GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
2020-06-22 08:41:09.541222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-22 08:41:09.541262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-22 08:41:09.543652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-22 08:41:09.543997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-22 08:41:09.546345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-22 08:41:09.547615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-22 08:41:09.547674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-22 08:41:09.549420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-22 08:41:09.549693: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-06-22 08:41:09.560237: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2100000000 Hz
2020-06-22 08:41:09.563950: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5258000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-22 08:41:09.563997: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-22 08:41:09.646046: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8e78220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-22 08:41:09.646096: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K40m, Compute Capability 3.5
2020-06-22 08:41:09.648938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: Tesla K40m computeCapability: 3.5
coreClock: 0.745GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
2020-06-22 08:41:09.649015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-22 08:41:09.649044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-22 08:41:09.649082: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-22 08:41:09.649108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-22 08:41:09.649134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-22 08:41:09.649160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-22 08:41:09.649185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-22 08:41:09.653889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-22 08:41:09.653937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-22 08:41:09.946823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-22 08:41:09.946877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-06-22 08:41:09.946895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-06-22 08:41:09.953775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10650 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:3b:00.0, compute capability: 3.5)
2020-06-22 08:41:17.862854: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-06-22 08:41:17.862987: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-22 08:41:17.865596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: Tesla K40m computeCapability: 3.5
coreClock: 0.745GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
2020-06-22 08:41:17.865680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-22 08:41:17.865701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-22 08:41:17.865729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-22 08:41:17.865760: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-22 08:41:17.865791: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-22 08:41:17.865906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-22 08:41:17.865925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-22 08:41:17.869346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-22 08:41:17.869396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-22 08:41:17.869412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-06-22 08:41:17.869473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-06-22 08:41:17.874638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10650 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:3b:00.0, compute capability: 3.5)
2020-06-22 08:41:17.938253: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-22 08:41:17.938355: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 1201 nodes (878), 1861 edges (1538), time = 32.534ms.
2020-06-22 08:41:17.938368: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.703ms.
2020-06-22 08:41:20.273359: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-06-22 08:41:20.273507: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-22 08:41:20.276428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: Tesla K40m computeCapability: 3.5
coreClock: 0.745GHz coreCount: 15 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 268.58GiB/s
2020-06-22 08:41:20.276638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-22 08:41:20.276660: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-22 08:41:20.276682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-22 08:41:20.276703: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-22 08:41:20.276848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-22 08:41:20.276865: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-22 08:41:20.276880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-22 08:41:20.281167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-22 08:41:20.281210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-22 08:41:20.281226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-06-22 08:41:20.281256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-06-22 08:41:20.286624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10650 MB memory) -> physical GPU (device: 0, name: Tesla K40m, pci bus id: 0000:3b:00.0, compute capability: 3.5)
2020-06-22 08:41:21.637672: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:460] There are 6 ops of 3 different types in the graph that are not converted to TensorRT: Identity, NoOp, Placeholder, (For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops).
2020-06-22 08:41:21.720564: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:643] Number of TensorRT candidate segments: 1
2020-06-22 08:41:21.909022: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:745] Replaced segment 0 consisting of 505 nodes by TRTEngineOp_0.
2020-06-22 08:41:22.604272: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: tf_graph
2020-06-22 08:41:22.604326: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 881 nodes (-320), 1221 edges (-640), time = 410.577ms.
2020-06-22 08:41:22.604400: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   layout: Graph size after: 885 nodes (4), 1225 edges (4), time = 252.41ms.
2020-06-22 08:41:22.604411: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 883 nodes (-2), 1223 edges (-2), time = 124.309ms.
2020-06-22 08:41:22.604420: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   TensorRTOptimizer: Graph size after: 379 nodes (-504), 380 edges (-843), time = 621.076ms.
2020-06-22 08:41:22.604445: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 325 nodes (-54), 326 edges (-54), time = 11.802ms.
2020-06-22 08:41:22.604474: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: TRTEngineOp_0_native_segment
2020-06-22 08:41:22.604490: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 507 nodes (0), 522 edges (0), time = 75.445ms.
2020-06-22 08:41:22.604514: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   layout: Graph size after: 507 nodes (0), 522 edges (0), time = 168.448ms.
2020-06-22 08:41:22.604546: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 507 nodes (0), 522 edges (0), time = 80.639ms.
2020-06-22 08:41:22.604560: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   TensorRTOptimizer: Graph size after: 507 nodes (0), 522 edges (0), time = 22.492ms.
2020-06-22 08:41:22.604569: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 507 nodes (0), 522 edges (0), time = 77.95ms.
2020-06-22 08:41:25.885707: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:982] Building a new TensorRT engine for TRTEngineOp_0 with input shapes: [[3,300,300,3]]
2020-06-22 08:41:25.885767: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1153] Linked TensorRT version: 6.0.1
2020-06-22 08:41:25.885966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-06-22 08:41:25.885989: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1154] Loaded TensorRT version: 6.0.1
2020-06-22 08:41:25.888300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
2020-06-22 08:41:26.226543: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Calling isShapeTensor before the entire network is constructed may result in an inaccurate result.
2020-06-22 08:41:26.227079: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Half2 support requested on hardware without native FP16 support, performance will be negatively affected.
Traceback (most recent call last):
  File ""tensorrt_use_pre_engine.py"", line 48, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""tensorrt_use_pre_engine.py"", line 43, in main
    converter.build(input_fn=my_input_fn)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/compiler/tensorrt/trt_convert.py"", line 1172, in build
    if not first_input:
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()

"
40656,Tensorflow creating too many threads,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): via pip
- TensorFlow version (use command below): v1.12.1-26458-gc251e83 2.2.0-rc0
- Python version: 3.7.3
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.2
- GPU model and memory: 2x V100 (32GB) or 4x V100 (32GB)

**Describe the current behavior**

I am trying to run a simple model through some custom cross-validation code using Distributed Training and python multiproccessing to speed up execution. I get nearly through the first fold of CV when the command ""watch -n1 nvidia-smi"" (used to monitor GPU usage) starts giving an error of ""fork failed: Resource temporary unavailable"", i.e. the maximum number of threads has been reached. This is when the code hangs. I use this via LSF, so after some time where I notice that no progress has been made, I kill off the job myself, at which time, I get an error saying ""Runtime error: can't start new thread""

**Describe the expected behavior**

All folds of the CV code are finshed and some metrics are calculated.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

I have ~100K image files, and their name gives their respective label. I first load them all to get them into cache:

```
def load_file(path):

    arr = np.load(path)['arr_0'][0:None:resolution, 0:None:resolution, :fields]
    for field in range(arr.shape[-1]):

        scaler = StandardScaler()
        scaler.fit(arr[:, :, field])
        arr[:, :, field] = scaler.transform(arr[:, :, field])
    
    name = path.replace("".npz"", """").split(""/"")[-1]

    if ""no"" in name:
        cat, start_lat, end_lat, start_lon, end_lon, date = name.split(""_"")
        label = 0
    else:
        cat, press, wind, start_lat, end_lat, start_lon, end_lon, date = name.split(""_"")
        cat = int(cat)
        if cat < 1:
            label = 0
        else:
            label = 1
            
    return arr, label

pool = mp.Pool(int(mp.cpu_count()))
res = list(tqdm.tqdm(pool.imap(load_file, cat1_files), total=len(cat1_files)))
res = list(tqdm.tqdm(pool.imap(load_file, cat2_files), total=len(cat2_files)))
res = list(tqdm.tqdm(pool.imap(load_file, cat3_files), total=len(cat3_files)))
res = list(tqdm.tqdm(pool.imap(load_file, cat4_files), total=len(cat4_files)))
res = list(tqdm.tqdm(pool.imap(load_file, cat5_files), total=len(cat5_files)))
res = list(tqdm.tqdm(pool.imap(load_file, no_files), total=len(no_files)))
```

I then create a Generator to load the data in the model. The previously opened pool is used here as well to speed up loading of files:

```
class DataGenerator(tf.keras.utils.Sequence):
    
    def __init__(self, paths, batch_size=32, dim=(86, 128, 5), shuffle=True, data_aug=True):
        self.dim = dim
        self.batch_size = batch_size
        self.paths = paths
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        'Denotes the number of batches per epoch'
        return int(np.floor(len(self.paths) / self.batch_size))

    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]

        # Find list of IDs
        paths_temp = [self.paths[k] for k in indexes]

        # Generate data
        X, y = self.__data_generation(paths_temp)

        return X, y

    def on_epoch_end(self):
        self.indexes = np.arange(len(self.paths))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)
            
    def __data_generation(self, paths_temp):
        
        X = np.zeros((self.batch_size, self.dim[0], self.dim[1], self.dim[2]), dtype=""float32"")
        y = np.zeros(self.batch_size)
        pool_res = list(pool.imap(load_file, paths_temp))
        
        for i in range(len(pool_res)):
            X[i], y[i] = pool_res[i]
            
        return X, y
```

The penultimate step is to create a function that instantiates a new model. This is a fairly simple CNN classifier:

```
def create_model(shape):
    
    mirrored_strategy = tf.distribute.MirroredStrategy()
    with mirrored_strategy.scope():

        model = models.Sequential() 

        model.add(layers.Conv2D(8, (2, 2), padding=""same"", strides=(1, 1), input_shape=(shape))) 
        model.add(layers.ReLU())
        model.add(layers.MaxPooling2D((2, 2), strides=1)) 
        model.add(layers.Conv2D(16, (1, 1), strides=(1, 1))) 
        model.add(layers.ReLU())
        model.add(layers.MaxPooling2D((2, 2), strides=1))
        model.add(layers.Conv2D(32, (2, 2), strides=(1, 1))) 
        model.add(layers.ReLU())
        model.add(layers.MaxPooling2D((2, 2), strides=1))
        model.add(layers.Conv2D(64, (2, 2), strides=(1, 1))) 
        model.add(layers.ReLU())
        model.add(layers.MaxPooling2D((2, 2), strides=1))
        model.add(layers.Conv2D(128, (2, 2), strides=(1, 1))) 
        model.add(layers.ReLU())
        model.add(layers.MaxPooling2D((2, 2), strides=1))
        model.add(layers.Conv2D(256, (2, 2), strides=(1, 1))) 
        model.add(layers.ReLU())
        model.add(layers.MaxPooling2D((2, 2), strides=1))

        model.add(layers.Flatten()) 
        model.add(layers.Dense(128))
        model.add(layers.ReLU())
        model.add(layers.Dense(64))
        model.add(layers.ReLU())
        model.add(layers.Dense(32))
        model.add(layers.ReLU())
        model.add(layers.Dense(1, activation='sigmoid')) 

        METRICS = [
              tf.keras.metrics.TruePositives(name='tp'),
              tf.keras.metrics.FalsePositives(name='fp'),
              tf.keras.metrics.TrueNegatives(name='tn'),
              tf.keras.metrics.FalseNegatives(name='fn'), 
              tf.keras.metrics.BinaryAccuracy(name='accuracy'),
              tf.keras.metrics.Precision(name='precision'),
              tf.keras.metrics.Recall(name='recall'),
              tf.keras.metrics.AUC(name='auc'),
        ]

    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=METRICS) 
    
    return model
```

Finally, the Cross-Validation code, which trains a model on each fold and saves the model:

```
train_fold_paths = []
val_fold_paths = []

for fold in range(k):
    
    cat1_fold = cat1_train_files[int(fold/k*len(cat1_train_files)) : int((fold+1)/k*len(cat1_train_files))]
    cat2_fold = cat2_train_files[int(fold/k*len(cat2_train_files)) : int((fold+1)/k*len(cat2_train_files))]
    cat3_fold = cat3_train_files[int(fold/k*len(cat3_train_files)) : int((fold+1)/k*len(cat3_train_files))]
    cat4_fold = cat4_train_files[int(fold/k*len(cat4_train_files)) : int((fold+1)/k*len(cat4_train_files))]
    cat5_fold = cat5_train_files[int(fold/k*len(cat5_train_files)) : int((fold+1)/k*len(cat5_train_files))]  
    yes_fold = cat1_fold + cat2_fold + cat3_fold + cat4_fold + cat5_fold
    no_fold = no_train_files[int(fold/k*len(no_train_files)) : int((fold+1)/k*len(no_train_files))]
    
    fold_data = yes_fold + no_fold
    
    val_fold_paths.append(fold_data)
    
    fold_data = no_fold + yes_fold
    train_fold_paths.append(fold_data)

history_folds = []
model_folds = []

for i_fold in range(k):
    
    train_folds = list(np.arange(i_fold, k-1+i_fold)%k)

    train_paths = []
    for fold_index in train_folds:
        if train_paths != None:
            train_paths += train_fold_paths[fold_index]
        else:
            train_paths = train_fold_paths[fold_index]
            
    val_paths = val_fold_paths[(k+i_fold-1)%k]
    
    dummy_file, _ = load_file(cat1_files[0])
    
    params_train = {'dim': dummy_file.shape, 'batch_size': batch_size, 'shuffle': True, 'data_aug': False}
    params_val = {'dim': dummy_file.shape, 'batch_size': batch_size, 'shuffle': False, 'data_aug': False}

    training_generator = DataGenerator(train_paths, **params_train)
    validation_generator = DataGenerator(val_paths, **params_val)
    
    model = create_model(dummy_file.shape)

    print(""Training Fold "" + str(i_fold+1))
    print(""Training Fold "" + str(i_fold+1), file=console_out)
        
    history = model.fit_generator(generator=training_generator, validation_data=validation_generator, use_multiprocessing=True, workers=int(0.5*mp.cpu_count()), 
                                  verbose=1, epochs=epochs, max_queue_size = int(len(train_paths)/batch_size))
    
    history_folds.append(history)
        
    model.save(fold_model_name + str(i_fold+1))
    tf.keras.backend.clear_session()
    
    tf.keras.experimental.terminate_keras_multiprocessing_pools(grace_period=0.1, use_sigkill=True)

```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Output of ""ulimit -a"":

```
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 3090396
max locked memory       (kbytes, -l) unlimited
max memory size         (kbytes, -m) unlimited
open files                      (-n) 48000
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 2097151
cpu time               (seconds, -t) unlimited
max user processes              (-u) 4096
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited

```

Part of Stacktrace:

```
Exception in thread Thread-31178:
Traceback (most recent call last):
  File ""/apps/contrib/jaspy/miniconda_envs/jaspy3.7/m3-4.6.14/lib/python3.7/threading.py"", line 917, in _bootstrap_inner
    self.run()
  File ""/apps/contrib/jaspy/miniconda_envs/jaspy3.7/m3-4.6.14/lib/python3.7/threading.py"", line 865, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/users/dgalea/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py"", line 843, in _run
    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:
  File ""/home/users/dgalea/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py"", line 732, in <lambda>
    self.executor_fn = lambda _: get_pool_class(False)(workers)
  File ""/apps/contrib/jaspy/miniconda_envs/jaspy3.7/m3-4.6.14/lib/python3.7/multiprocessing/dummy/__init__.py"", line 124, in Pool
    return ThreadPool(processes, initializer, initargs)
  File ""/apps/contrib/jaspy/miniconda_envs/jaspy3.7/m3-4.6.14/lib/python3.7/multiprocessing/pool.py"", line 802, in __init__
    Pool.__init__(self, processes, initializer, initargs)
  File ""/apps/contrib/jaspy/miniconda_envs/jaspy3.7/m3-4.6.14/lib/python3.7/multiprocessing/pool.py"", line 176, in __init__
    self._repopulate_pool()
  File ""/apps/contrib/jaspy/miniconda_envs/jaspy3.7/m3-4.6.14/lib/python3.7/multiprocessing/pool.py"", line 241, in _repopulate_pool
    w.start()
  File ""/apps/contrib/jaspy/miniconda_envs/jaspy3.7/m3-4.6.14/lib/python3.7/multiprocessing/dummy/__init__.py"", line 51, in start
    threading.Thread.start(self)
  File ""/apps/contrib/jaspy/miniconda_envs/jaspy3.7/m3-4.6.14/lib/python3.7/threading.py"", line 847, in start
    _start_new_thread(self._bootstrap, ())
RuntimeError: can't start new thread

```"
40655,the memory couldn't be released after training,"
hi,dear
help wanted,
when I see the memory after a training in While
confused me that the memory can't be released in time sleep
the codes down for reference
```
import tensorflow as tf
import numpy as np
import time
def train_func():
    model = tf.keras.Sequential() #
    model.add(tf.keras.layers.Dense(512,activation='relu',input_shape=(784,)))
    model.add(tf.keras.layers.Dense(256,activation='relu'))
    model.add(tf.keras.layers.Dense(10,activation='softmax'))
    model.summary()


    X_train=np.random.randn(10000,784)
    y_train=np.random.randint(0,10,size=10000)

    y_train=tf.keras.utils.to_categorical(y_train,10)
    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
    model.fit(X_train,y_train,batch_size=64,epochs=1)
    
while True:
    train_func()
    print(""training over !!!"")
    time.sleep(1000)
```

the memory 
```
10000/10000 [==============================] - 1s 59us/sample - loss: 2.3762 - acc: 0.1027
training over !!!
```
![image](https://user-images.githubusercontent.com/35590066/85261428-b99b0c00-b49e-11ea-8d13-10974796160b.png)

SO how to release the memory ?

thx

"
40653,Incorrect error message for valid input of tf.math.segment_*,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary):  binary
- TensorFlow version (use command below):  v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
When passing a 0D tensor for `data` and an empty array for `segment_ids`, `tf.math.segment_*` (e.g., `tf.math.segment_mean`) throws an error saying  
- In command line: `InvalidArgumentError: segment_ids should be the same size as dimension 0 of input.`  
- In Colab: crash due to core dumped at 'F tensorflow/core/framework/tensor_shape.cc:435] Check failed: d < dims() (0 vs. 0)'

For a 0D tensor `data`,  the first dimension of `segment_ids` does not exist, so shouldn't an empty array be the valid input? 
Also, the same input behaves differently in Colab and command line. This is also strange behavior.

**Describe the expected behavior**
If the input above is valid, I would expect no error thrown. If invalid, I would expect a more straightforward error message and an update in the documentation so that it specifies `data` tensor should not be scalar.  

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf
import numpy as np

tf.math.segment_mean(np.uint16(10), np.array([]).astype('int64'), name=None)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40652,Gradient with respect to input returns None using GradientTape().,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow version (use command below): 2.2.0

**Describe the current behavior**
I am trying to calculate gradient for a KL divergence scalar loss value wrt input. 
Implementation has been with two approaches and returns [None] in both cases.

1. Differentiate wrt to a tensor. Output: None
2. Differentiate wrt to a Variable. Output: None

The following works with TensorFlow 1.x which used tf.gradients() however, GradientTape() is returning None and it very frustrating now. As I have been trying to overcome this for the last 3 weeks. Please provide some support. 

The colab link is provided below.

**Describe the expected behavior**
Gradient matrix should contain values and until that I can't work on building my model.

**Standalone code to reproduce the issue**
Updated link: 
[https://colab.research.google.com/drive/1hwFX3VMzKtfRjqd5-EG-0WePvtCbmChM?usp=sharing](url)
**Other info/logs** 

The below code is taken from this source: 
[https://gist.github.com/divamgupta/c778c17459c1f162e789560d5e0b2f0b]

Also followed a similar issue on this link: [https://github.com/tensorflow/tensorflow/issues/36596](url) . But it doesn't help me to solve my problem.

Any help is highly appreciated. Thanks for your time"
40651,Keras Model produces nan on fit,"**System information**
- Google Colab Python 3


**Bug Description**
I have a confusing problem. Before I call `.fit()` my model can produce output from inputs (see below).

```python

>>> print(f0.predict(x))
>>> print(f1.predict([x, x]))

[[16.913166 ]
 [ 6.2363415]
 [10.625664 ]
 ...
 [13.86934  ]
 [15.4675865]
 [16.353233 ]]
[[-0.94484174]
 [-1.0965291 ]
 [-0.829823  ]
 ...
 [-1.0362396 ]
 [-0.18886864]
 [-0.3576672 ]]
```

But after calling fit all I get are nans
```python
>>> print(f0.predict(x))
>>> print(f1.predict([x, x]))

[[16.913166 ]
 [ 6.2363415]
 [10.625664 ]
 ...
 [13.86934  ]
 [15.4675865]
 [16.353233 ]]
[[nan]
 [nan]
 [nan]
 ...
 [nan]
 [nan]
 [nan]]
```

Here is the code for generating the model. Error is _not_ dependent on the data as I can reproduce this with any sklearn dataset as an input.

```python
def create_base_model(p, units=20):
    # Specs
    input_layer = k.layers.Input((p,))

    penultimate_layer = k.layers.Dense(units, activation='elu')(input_layer)
    penultimate_layer = k.layers.Dense(p)(penultimate_layer)

    training_output = k.layers.Dense(1)(penultimate_layer)

    # Models
    boost_model = k.Model(inputs=input_layer, outputs=penultimate_layer)
    training_model = k.Model(inputs=input_layer, outputs=training_output)

    # Compile and export
    training_model.compile(optimizer='sgd', loss='mse')
    return training_model, boost_model


def create_staged_model(p: int, model: k.Model, units=20):
    # Freeze prior model
    for layer_i in model.layers:
        layer_i.trainable = False

    # Specs
    input_layer = k.layers.Input((p,))

    penultimate_layer = k.layers.concatenate([model.output, input_layer], axis=-1)
    penultimate_layer = k.layers.Dense(units, activation='elu')(penultimate_layer)
    penultimate_layer = k.layers.Dense(p)(penultimate_layer)

    training_output = k.layers.Dense(1)(penultimate_layer)

    # Models
    boost_model = k.Model(inputs=[model.input, input_layer], outputs=penultimate_layer)
    training_model = k.Model(inputs=[model.input, input_layer], outputs=training_output)

    # Compile and export
    training_model.compile(optimizer='sgd', loss='mse')
    return training_model, boost_model


fit_kwargs = dict(
    epochs=50, 
    validation_split=0.1, 
    callbacks=[
        k.callbacks.ReduceLROnPlateau(factor=.5, patience=5, min_lr=1e-6),
        k.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
    ]
)


f0, _ = create_base_model(p)
f0.fit(x, y, **fit_kwargs)  # Works fine

f1, _ = create_staged_model(p, model0)
f1.fit([x, x], y, **fit_kwargs)  # Breaks on fit
```

Note that this nan issue occurs immediately
```
Epoch 1/50
282/282 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan - lr: 0.0100
Epoch 2/50
282/282 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan - lr: 0.0100
Epoch 3/50
282/282 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan - lr: 0.0100
Epoch 4/50
282/282 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan - lr: 0.0100
Epoch 5/50
282/282 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan - lr: 0.0100
Epoch 6/50
282/282 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan - lr: 0.0050
Epoch 7/50
282/282 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan - lr: 0.0050
Epoch 8/50
282/282 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan - lr: 0.0050
Epoch 9/50
282/282 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan - lr: 0.0050
```
"
40649,AttributeError: 'StringIntLabelMapItem' object has no attribute 'keypoints',"I'm following the tutorial (https://www.youtube.com/watch?v=HjiBbChYRDw) and got into a problem of getting the category index from the labelmap.

PATH_TO_LABELS = 'training/labelmap.pbtxt'
![keypoints](https://user-images.githubusercontent.com/60057917/85229903-28d11b80-b41f-11ea-8579-82c6da4bbf7a.JPG)
"
40648,Inconsistant tf.name_scope behaviour with Custom model in TF2.X.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Google Colab Environment**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**
- TensorFlow installed from (source or binary): **Binary (Colab Pre-Installed)**
- TensorFlow version (use command below): **2.3.0-nightly**
- Python version: **3.6.9**
- Bazel version (if compiling from source): **N/A**
- GCC/Compiler version (if compiling from source): **N/A**
- CUDA/cuDNN version: **N/A (Colab CPU Environment used)**
- GPU model and memory: **N/A**

**Describe the current behavior**
I am trying to use tf.name_scope inside a custom model which is inherited from tf.keras.Model and it has custom layers which are inherited from tf.keras.layers.Layer.

**Describe the expected behavior**
I expect the scope_name that is added with the help of tf.name_scope as a prefix to the weights name. E.g. weight ""conv1/conv2d_35/kernel:0"" should be named as ""Conv_Block/conv1/conv2d_35/kernel:0"" when used with tf.name_scope(""Conv_Block).

**Standalone code to reproduce the issue**

```
class Config:
    weight_decay = 0.0005
    weight_init_seed = 42
    bnorm_momentum = 0.9

config = Config()

class ConvLayer(tf.keras.layers.Layer):
    def __init__(self, name, filters, k_size=(3, 3), strides=1, padding='same', use_bnorm=True):
        super(ConvLayer, self).__init__(name=name, trainable=True, dtype=tf.float32)        

        self.use_bnorm = use_bnorm

        self.weight_decay = config.weight_decay
        self.k_reg = tf.keras.regularizers.l2(self.weight_decay)
        self.k_init = tf.keras.initializers.GlorotNormal(seed=config.weight_init_seed)
        self.b_init = tf.zeros_initializer()

        self.conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=k_size, strides=strides, padding=padding, activation=None, use_bias=not self.use_bnorm, kernel_initializer=self.k_init, bias_initializer=self.b_init, kernel_regularizer=self.k_reg)
        if self.use_bnorm:
            self.bn = tf.keras.layers.BatchNormalization(momentum=config.bnorm_momentum)
        self.mx_pool = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=2, padding=padding)

        self.act = tf.nn.relu

    def call(self, x, training=False):
        if self.use_bnorm:
            return self.act(self.mx_pool(self.bn(self.conv(x), training=training)))
        else:
            return self.act(self.mx_pool(self.conv(x)))


class DenseLayer(tf.keras.layers.Layer):
    def __init__(self, name, units, use_bnorm=True, use_act=True):
        super(DenseLayer, self).__init__(name=name)
        self.use_bnorm = use_bnorm
        self.use_act = use_act
        
        self.weight_decay = config.weight_decay
        self.k_reg = tf.keras.regularizers.l2(self.weight_decay)
        self.k_init = tf.keras.initializers.GlorotNormal(seed=config.weight_init_seed)
        self.b_init = tf.zeros_initializer()

        self.fc = tf.keras.layers.Dense(units=units, activation=None, use_bias=not self.use_bnorm, kernel_initializer=self.k_init, bias_initializer=self.b_init, kernel_regularizer=self.k_reg)
        if self.use_bnorm:
            self.bn = tf.keras.layers.BatchNormalization(momentum=config.bnorm_momentum)
        
        if self.use_act:
            self.act = tf.nn.relu

    def call(self, x, training=False):
        if self.use_bnorm:
            op = self.bn(self.fc(x), training=training)
        else:
            op = self.fc(x)

        if self.use_act:
            return self.act(op)
        else:
            return op


class ClassifierModel(tf.keras.Model):
    def __init__(self, num_classes=2):
        super(ClassifierModel, self).__init__(name='ClassifierModel')
        self.num_classes = num_classes
        
        # input will be of shape : [None, 128, 128, 3]

        with tf.name_scope(""Conv_Block""):
            self.conv1 = ConvLayer('conv1', 32, (3, 3), 1, 'same', True)
            # [64 x 64 x 32]
            
            self.conv2 = ConvLayer('conv2', 48, (3, 3), 1, 'same', True)
            # [32 x 32 x 48]
            
            self.conv3 = ConvLayer('conv3', 72, (3, 3), 1, 'same', True)
            # [16 x 16 x 72]

            self.conv4 = ConvLayer('conv4', 96, (3, 3), 1, 'same', True)
            # [8 x 8 x 96]

            self.conv5 = ConvLayer('conv5', 128, (3, 3), 1, 'same', True)
            # [4 x 4 x 128]

            self.gap = tf.keras.layers.GlobalAveragePooling2D()
            self.mx_pool = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=2, padding='same')

        with tf.name_scope(""Dense_Block""):
            self.fc1 = DenseLayer('fc1', 64, True)
            # [64]

            self.fc2 = DenseLayer('fc2', 2, False, False)
            # [2]
    
    def call(self, x, training=False):
        # x         : [B, 128, 128, 3]
        # training  : True / False - used for batch norm.
        
        layer_1 = self.conv1(x, training=training)
        layer_1 = self.mx_pool(layer_1)

        layer_2 = self.conv2(layer_1, training=training)
        layer_2 = self.mx_pool(layer_2)

        layer_3 = self.conv3(layer_2, training=training)
        layer_3 = self.mx_pool(layer_3)

        layer_4 = self.conv4(layer_3, training=training)
        layer_4 = self.mx_pool(layer_4)

        layer_5 = self.conv5(layer_4, training=training)
        layer_5 = self.mx_pool(layer_5)

        gap = self.gap(layer_5)

        fc1 = self.fc1(gap, training=training)

        logits = self.fc2(fc1, training=None)
        outputs = tf.nn.softmax(logits)

        return logits, outputs


clf = ClassifierModel()
clf.build(input_shape=tf.TensorShape([None, 128, 128, 3]))

for v in clf.trainable_variables:
    print(v.name, ""\t\t"", v.shape)
```

Generated output is as below:
```
conv1/conv2d_35/kernel:0 		 (3, 3, 3, 32)
conv1/batch_normalization_41/gamma:0 		 (32,)
conv1/batch_normalization_41/beta:0 		 (32,)
conv2/conv2d_36/kernel:0 		 (3, 3, 32, 48)
conv2/batch_normalization_42/gamma:0 		 (48,)
conv2/batch_normalization_42/beta:0 		 (48,)
conv3/conv2d_37/kernel:0 		 (3, 3, 48, 72)
conv3/batch_normalization_43/gamma:0 		 (72,)
conv3/batch_normalization_43/beta:0 		 (72,)
conv4/conv2d_38/kernel:0 		 (3, 3, 72, 96)
conv4/batch_normalization_44/gamma:0 		 (96,)
conv4/batch_normalization_44/beta:0 		 (96,)
conv5/conv2d_39/kernel:0 		 (3, 3, 96, 128)
conv5/batch_normalization_45/gamma:0 		 (128,)
conv5/batch_normalization_45/beta:0 		 (128,)
fc1/dense_12/kernel:0 		 (128, 64)
fc1/batch_normalization_46/gamma:0 		 (64,)
fc1/batch_normalization_46/beta:0 		 (64,)
fc2/dense_13/kernel:0 		 (64, 2)
fc2/dense_13/bias:0 		 (2,)
```
Output should be as below:
```
Conv_Block/conv1/conv2d_35/kernel:0 		 (3, 3, 3, 32)
Conv_Block/conv1/batch_normalization_41/gamma:0 		 (32,)
Conv_Block/conv1/batch_normalization_41/beta:0 		 (32,)
Conv_Block/conv2/conv2d_36/kernel:0 		 (3, 3, 32, 48)
Conv_Block/conv2/batch_normalization_42/gamma:0 		 (48,)
Conv_Block/conv2/batch_normalization_42/beta:0 		 (48,)
Conv_Block/conv3/conv2d_37/kernel:0 		 (3, 3, 48, 72)
Conv_Block/conv3/batch_normalization_43/gamma:0 		 (72,)
Conv_Block/conv3/batch_normalization_43/beta:0 		 (72,)
Conv_Block/conv4/conv2d_38/kernel:0 		 (3, 3, 72, 96)
Conv_Block/conv4/batch_normalization_44/gamma:0 		 (96,)
Conv_Block/conv4/batch_normalization_44/beta:0 		 (96,)
Conv_Block/conv5/conv2d_39/kernel:0 		 (3, 3, 96, 128)
Conv_Block/conv5/batch_normalization_45/gamma:0 		 (128,)
Conv_Block/conv5/batch_normalization_45/beta:0 		 (128,)
Dense_Block/fc1/dense_12/kernel:0 		 (128, 64)
Dense_Block/fc1/batch_normalization_46/gamma:0 		 (64,)
Dense_Block/fc1/batch_normalization_46/beta:0 		 (64,)
Dense_Block/fc2/dense_13/kernel:0 		 (64, 2)
Dense_Block/fc2/dense_13/bias:0 		 (2,)
```

**Colab Notebook link:**  https://colab.research.google.com/drive/1MxMsIYVy7vGiY6jctw5OVkHUPGabHu9Z?usp=sharing

**Other info / logs** 
The same issue is reproduced in my local machine where Python 3.6.10 is installed with TensorFlow 2.1.0."
40647,"Describe Conv1D kernel_size as height, not length?","For a 1D convolution, is the use of the word, ""length,"" somewhat misleading? Wouldn't height be more appropriate?

> https://github.com/tensorflow/tensorflow/blob/54b51b10585e2e05124c708f8c5b2d41d3a728bb/tensorflow/python/keras/layers/convolutional.py#L425

![image](https://user-images.githubusercontent.com/16389820/85224546-2f1cb480-b399-11ea-95fe-5e6d6ba6fad8.png)
"
40646,Failed to get convolution algorithm,"

**System information**

- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from: Conda  using ``` condo install tensorflow-gpu```
- TensorFlow version: tensorflow-gpu 2.2.0
- IDE: PyCharm
- Python version: 3.7.7
- CUDA/cuDNN version: 10.1/ 7.6.5
- GPU model and memory: Nvidia GeForce 940 MX. Compute Capability 5.0


**Describe the current behavior**

I get the following error when I run  ```model.fit()``` in PyCharm:

  ...: history = model.fit(
  ...:     train_data_gen,
  ...:     epochs=epochs,
  ...:     validation_data=val_data_gen,)
Epoch 1/80
2020-06-21 14:35:26.768642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-21 14:35:26.940647: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-21 14:35:28.215703: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2020-06-21 14:35:28.224418: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
Traceback (most recent call last):
  File ""/home/adisha512/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-8-0cb462f62c0c>"", line 4, in <module>
    validation_data=val_data_gen,)
  File ""/home/adisha512/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/home/adisha512/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 848, in fit
    tmp_logs = train_function(iterator)
  File ""/home/adisha512/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/home/adisha512/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/adisha512/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/home/adisha512/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1665, in _filtered_call
    self.captured_inputs)
  File ""/home/adisha512/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/adisha512/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 598, in call
    ctx=ctx)
  File ""/home/adisha512/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node sequential/conv2d/Conv2D (defined at <ipython-input-8-0cb462f62c0c>:4) ]] [Op:__inference_train_function_1350]
Function call stack:
train_function

I tried going through some articles but couldn't get the solution.

Also, When I create the model, then this is what I get in the console:

2020-06-21 14:29:33.299080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-21 14:29:33.336130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-21 14:29:33.337117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce 940MX computeCapability: 5.0
coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 37.33GiB/s
2020-06-21 14:29:33.354558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-21 14:29:33.384143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-21 14:29:33.398202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-21 14:29:33.405597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-21 14:29:33.411914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-21 14:29:33.416370: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-21 14:29:33.428501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-21 14:29:33.428926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-21 14:29:33.430408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-21 14:29:33.431523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-21 14:29:33.432550: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-06-21 14:29:33.446572: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2699905000 Hz
2020-06-21 14:29:33.446977: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f691c002e50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-21 14:29:33.447022: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-21 14:29:33.447375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-21 14:29:33.448181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce 940MX computeCapability: 5.0
coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 37.33GiB/s
2020-06-21 14:29:33.448268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-21 14:29:33.448301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-21 14:29:33.448329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-21 14:29:33.448356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-21 14:29:33.448383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-21 14:29:33.448410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-21 14:29:33.448438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-21 14:29:33.448603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-21 14:29:33.449537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-21 14:29:33.450258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-21 14:29:33.450395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-21 14:29:33.497965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-21 14:29:33.497998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-06-21 14:29:33.498009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-06-21 14:29:33.498209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-21 14:29:33.498590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-21 14:29:33.498928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-21 14:29:33.499229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1538 MB memory) -> physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0)
2020-06-21 14:29:33.501220: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555cf5679cb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-21 14:29:33.501249: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce 940MX, Compute Capability 5.0


"
40645,i can not run examples with downloadPredictFloat16ModelFile,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://github.com/tensorflow/examples/tree/master/lite/examples/style_transfer/android

## Description of issue (what needs changing):
i follow the description

then run this project

log
```
> Task :app:downloadPredictFloat16ModelFile
Unable to get progress logger. Download progress will not be displayed.

> Task :app:downloadPredictFloat16ModelFile FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':app:downloadPredictFloat16ModelFile'.
> org.apache.http.conn.HttpHostConnectException: Connect to tfhub.dev:443 [tfhub.dev/172.217.27.142] failed: Connection timed out: connect

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.

* Get more help at https://help.gradle.org

Deprecated Gradle features were used in this build, making it incompatible with Gradle 7.0.
Use '--warning-mode all' to show the individual deprecation warnings.
See https://docs.gradle.org/6.1.1/userguide/command_line_interface.html#sec:command_line_warnings

BUILD FAILED in 24s
7 actionable tasks: 1 executed, 6 up-to-date

```

"
40642,keras.callbacks.ModelCheckPoint has a problem when filepath of working directory is long,"**System information**
- 
- OS Platform and Distribution: Windows 10
- TensorFlow version: 2.1.0
- Python version: 3.7.4

**Issue**
If the filepath to the current working directory is long, then keras.callbacks.ModelCheckPoint fails when creating a checkpoint. It raises a `NotFoundError`.

Two forms of the messages that I've encountered are:

> NotFoundError: Failed to create a directory: issues_with_mixed_slashes\too_damn_buggy\checkpoint_1/variables; No such file or directory

OR

> NotFoundError: Failed to create a NewWriteableFile: issues_with_mixed_slashes\too_damn_buggy\checkpoint_1\variables\variables_temp_af3a37dbc2fc491b87d8afc1eab1ef3a/part-00000-of-00001.data-00000-of-00001.tempstate5339521814986627484 : The system cannot find the path specified.
> ; No such process [Op:SaveV2]

Some working directories produce the first kind and some others produce the second kind.

**Standalone code to reproduce the issue**
```
import tensorflow as tf
import os
import numpy as np

n=10
x = np.random.random((n,1))
y = np.random.random((n,1))

# set `new_cwdir` to a really long path for the two commented out lines below.
# os.mkdir(new_cwdir)
# os.chdir(new_cwdir)

all_callbacks=[]
checkpoint_filepath = ""issues_with_mixed_slashes\\too_damn_buggy\\checkpoint_{epoch}""
all_callbacks.append(
    tf.keras.callbacks.ModelCheckpoint(
        filepath=checkpoint_filepath, monitor='loss', verbose=1))

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(1, input_shape=x.shape[-1:]))
model.add(tf.keras.layers.Dense(1))

epochs = 2
model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanAbsoluteError())
history = model.fit(x=x, y=y, epochs=epochs, callbacks=all_callbacks)
```
If you set the working directory to something closer to the root directory, the problem will not occur.

**More info** 
I suspect that the mixing of `/` and `\`  when TensorFlow tries to create a new directory is (or is part of) the cause."
40640,"""Could not find a version that satisfies the requirement tensorflow==1.15.3""","**System information**
- windows 10
- TensorFlow not installed because doing so doesn't work
- TensorFlow version: 1.15.3




**Describe the problem**
see the title; that happens when I try to pip install.

this is all related to #40459 and the rest of the relevant info is findable there.
"
40639,C++ compilation of rule '//tensorflow/core/kernels:softsign_op' ,"Under Windows-10 I have tried to build [TensorFlow 2.2 from the source](https://www.tensorflow.org/install/source_windows) and it ends with the following error

```
ERROR: C:/tensorflow/tensorflow/core/kernels/BUILD:4748:1: C++ compilation of rule '//tensorflow/core/kernels:softsign_op' failed (Exit 2)
C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_search.h(14): fatal error C1083: Cannot open include file: 'stddef.h': No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 9402.886s, Critical Path: 4760.75s
INFO: 6735 processes: 6735 local.
FAILED: Build did NOT complete successfully
```"
40638,Keras layer weights/sublayers getting deleted when creating a model with them. model.summary() / plot_model still shows those weights as part of graph though,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google colab enviroment

- TensorFlow installed from (source or binary): Google colab default 
- Python version: Python 3, Google colab default 

- CUDA/cuDNN version:   Google colab default  
- GPU model and memory:  Tested on both Google colab p-100 GPU and CPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

>2020-06-20 21:44:17.003371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
v2.2.0-0-g2b96f3662b 2.2.0

**Describe the current behavior**

I created a new model using two layers from and old model. However, now all of the layers/weights from the old model are Not showing up in the new model. 

`model.summary()` and 

```
tf.keras.utils.plot_model(
    model, to_file='model.png', show_shapes=False, show_layer_names=True,
    rankdir='TB', expand_nested=False, dpi=96
)
```

still has those weights, so I think they're a part of the graph.  But when I print them out, those weights/layers are missing altogether 


**Describe the expected behavior**

All weights from component layers to should be in the model. 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Here is a Colabnotebook with a minimal example that reproduced the issue. 

https://colab.research.google.com/drive/1n3_XNhdgH6Qo7GT-M570lIKWAoU3TML5?usp=sharing

And here is the code

```
!pip install transformers --q
%tensorflow_version 2.x

from transformers import TFBertModel, AutoModel, TFRobertaModel, AutoTokenizer
import tensorflow as tf
import tensorflow_addons as tfa

tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

from tensorflow import keras
from tensorflow.keras import layers
from copy import deepcopy

logger = tf.get_logger()
logger.info(tf.__version__)


def get_mini_models():
    tempModel = TFRobertaModel.from_pretrained('bert-base-uncased', from_pt=True)

    layer9 = deepcopy(tempModel.layers[0].encoder.layer[8])
    layer10 = deepcopy(tempModel.layers[0].encoder.layer[9])

    inputHiddenVals = tf.keras.Input(shape=[None, None], dtype=tf.float32, name='input_Q',
                                    batch_size=None) 

    hidden1 = layer9((inputHiddenVals, None, None))
    hidden2 = layer10((hidden1[0], None, None))
    modelNew = tf.keras.Model(inputs=inputHiddenVals, outputs=hidden2)

    del tempModel

    return modelNew

@tf.function
def loss_fn(_, probs):
    bs = tf.shape(probs)[0]
    labels = tf.eye(bs, bs)
    return tf.losses.categorical_crossentropy(labels,
                                              probs,
                                              from_logits=True)

model = get_mini_models()
model.compile(loss=loss_fn,
                optimizer=tfa.optimizers.AdamW(weight_decay=1e-4, learning_rate=1e-5, 
                                                epsilon=1e-06))

# Get model and layers directly to compare
tempModel = TFRobertaModel.from_pretrained('bert-base-uncased', from_pt=True)
layer9 = deepcopy(tempModel.layers[0].encoder.layer[8])
layer10 = deepcopy(tempModel.layers[0].encoder.layer[9])

# Only one layer, and that layer also has missing weights. 
for i, var in enumerate(model.weights):
    print(model.weights[i].name)

# Full weights for one layer 
for i, var in enumerate(layer9.weights):
    print(layer9.weights[i].name)

# Test what correct output should be 

tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
inputt = tokenizer.encode('This is a sentence', return_tensors='tf')
outt = tempModel(inputt)[0]

# Test model output. Not the same. 

model(outt)

# Model summary somehow lists the weights 
model.summary()

# Model diagram shows the correct connections between all the layers. 

tf.keras.utils.plot_model(
    model, to_file='model.png', show_shapes=False, show_layer_names=True,
    rankdir='TB', expand_nested=False, dpi=96
)

```

Edit: I also tried making the layers from scratch, and setting the weights directly, and got the same result. Here's a colab notebook that does this. https://colab.research.google.com/drive/1EC_fObSp9lUsj_PFaYgFtRI93ErPYmU9?usp=sharing

And here's the code 

```
!pip install transformers --q
%tensorflow_version 2.x

from transformers import TFBertModel, AutoModel, TFRobertaModel, AutoTokenizer

import tensorflow as tf
import tensorflow_addons as tfa

tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import (Dense,
                                     Dropout)
import numpy as np
import os

logger = tf.get_logger()
logger.info(tf.__version__)

class TFBertSelfAttention2(tf.keras.layers.Layer):
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        if config.hidden_size % config.num_attention_heads != 0:
            raise ValueError(
                ""The hidden size (%d) is not a multiple of the number of attention ""
                ""heads (%d)"" % (config.hidden_size, config.num_attention_heads)
            )

        self.num_attention_heads = config.num_attention_heads
        assert config.hidden_size % config.num_attention_heads == 0
        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)
        self.all_head_size = self.num_attention_heads * self.attention_head_size

        self.query = tf.keras.layers.Dense(
            self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=""query_2""
        )
        self.key = tf.keras.layers.Dense(
            self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=""key_2""
        )
        self.value = tf.keras.layers.Dense(
            self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=""value_2""
        )

        self.dropout = tf.keras.layers.Dropout(config.attention_probs_dropout_prob)

    def transpose_for_scores(self, x, batch_size):
        x = tf.reshape(x, (batch_size, -1, self.num_attention_heads, self.attention_head_size))
        return tf.transpose(x, perm=[0, 2, 1, 3])

    def call(self, inputs, training=False):
        hidden_states, attention_mask, head_mask, output_attentions = inputs

        batch_size = shape_list(hidden_states)[0]
        mixed_query_layer = self.query(hidden_states)
        mixed_key_layer = self.key(hidden_states)
        mixed_value_layer = self.value(hidden_states)

        query_layer = self.transpose_for_scores(mixed_query_layer, batch_size)
        key_layer = self.transpose_for_scores(mixed_key_layer, batch_size)
        value_layer = self.transpose_for_scores(mixed_value_layer, batch_size)

        # Take the dot product between ""query"" and ""key"" to get the raw attention scores.
        attention_scores = tf.matmul(
            query_layer, key_layer, transpose_b=True
        )  # (batch size, num_heads, seq_len_q, seq_len_k)
        dk = tf.cast(shape_list(key_layer)[-1], tf.float32)  # scale attention_scores
        attention_scores = attention_scores / tf.math.sqrt(dk)

        if attention_mask is not None:
            # Apply the attention mask is (precomputed for all layers in TFBertModel call() function)
            attention_scores = attention_scores + attention_mask

        # Normalize the attention scores to probabilities.
        attention_probs = tf.nn.softmax(attention_scores, axis=-1)

        # This is actually dropping out entire tokens to attend to, which might
        # seem a bit unusual, but is taken from the original Transformer paper.
        attention_probs = self.dropout(attention_probs, training=training)

        # Mask heads if we want to
        if head_mask is not None:
            attention_probs = attention_probs * head_mask

        context_layer = tf.matmul(attention_probs, value_layer)

        context_layer = tf.transpose(context_layer, perm=[0, 2, 1, 3])
        context_layer = tf.reshape(
            context_layer, (batch_size, -1, self.all_head_size)
        )  # (batch_size, seq_len_q, all_head_size)

        outputs = (
            (context_layer, attention_probs) if cast_bool_to_primitive(output_attentions) is True else (context_layer,)
        )

        return outputs


class TFBertSelfOutput2(tf.keras.layers.Layer):
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        self.dense = tf.keras.layers.Dense(
            config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=""dense2""
        )
        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=""LayerNorm2"")
        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)

    def call(self, inputs, training=False):
        hidden_states, input_tensor = inputs

        hidden_states = self.dense(hidden_states)
        hidden_states = self.dropout(hidden_states, training=training)
        hidden_states = self.LayerNorm(hidden_states + input_tensor)
        return hidden_states


class TFBertAttention2(tf.keras.layers.Layer):
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        self.self_attention = TFBertSelfAttention2(config, name=""self2"")
        self.dense_output = TFBertSelfOutput2(config, name=""output2"")

    def prune_heads(self, heads):
        raise NotImplementedError

    def call(self, inputs, training=False):
        input_tensor, attention_mask, head_mask, output_attentions = inputs

        self_outputs = self.self_attention(
            [input_tensor, attention_mask, head_mask, output_attentions], training=training
        )
        attention_output = self.dense_output([self_outputs[0], input_tensor], training=training)
        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them
        return outputs


class TFBertIntermediate2(tf.keras.layers.Layer):
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        self.dense = tf.keras.layers.Dense(
            config.intermediate_size, kernel_initializer=get_initializer(config.initializer_range), name=""dense2""
        )
        if isinstance(config.hidden_act, str):
            self.intermediate_act_fn = ACT2FN[config.hidden_act]
        else:
            self.intermediate_act_fn = config.hidden_act

    def call(self, hidden_states):
        hidden_states = self.dense(hidden_states)
        hidden_states = self.intermediate_act_fn(hidden_states)
        return hidden_states


class TFBertOutput2(tf.keras.layers.Layer):
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        self.dense = tf.keras.layers.Dense(
            config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=""dense2""
        )
        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=""LayerNorm2"")
        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)

    def call(self, inputs, training=False):
        hidden_states, input_tensor = inputs

        hidden_states = self.dense(hidden_states)
        hidden_states = self.dropout(hidden_states, training=training)
        hidden_states = self.LayerNorm(hidden_states + input_tensor)
        return hidden_states


class TFBertLayer2(tf.keras.layers.Layer):
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        self.attention = TFBertAttention2(config, name=""attention2"")
        self.intermediate = TFBertIntermediate2(config, name=""intermediate2"")
        self.bert_output = TFBertOutput2(config, name=""output2"")

    def call(self, inputs, training=False):
        hidden_states, attention_mask, head_mask, output_attentions = inputs

        attention_outputs = self.attention(
            [hidden_states, attention_mask, head_mask, output_attentions], training=training
        )
        attention_output = attention_outputs[0]
        intermediate_output = self.intermediate(attention_output)
        layer_output = self.bert_output([intermediate_output, attention_output], training=training)
        outputs = (layer_output,) + attention_outputs[1:]  # add attentions if we output them
        return outputs


class TFBertSelfAttention(tf.keras.layers.Layer):
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        if config.hidden_size % config.num_attention_heads != 0:
            raise ValueError(
                ""The hidden size (%d) is not a multiple of the number of attention ""
                ""heads (%d)"" % (config.hidden_size, config.num_attention_heads)
            )

        self.num_attention_heads = config.num_attention_heads
        assert config.hidden_size % config.num_attention_heads == 0
        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)
        self.all_head_size = self.num_attention_heads * self.attention_head_size

        self.query = tf.keras.layers.Dense(
            self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=""query_""
        )
        self.key = tf.keras.layers.Dense(
            self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=""key_""
        )
        self.value = tf.keras.layers.Dense(
            self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=""value_""
        )

        self.dropout = tf.keras.layers.Dropout(config.attention_probs_dropout_prob)

    def transpose_for_scores(self, x, batch_size):
        x = tf.reshape(x, (batch_size, -1, self.num_attention_heads, self.attention_head_size))
        return tf.transpose(x, perm=[0, 2, 1, 3])

    def call(self, inputs, training=False):
        hidden_states, attention_mask, head_mask, output_attentions = inputs

        batch_size = shape_list(hidden_states)[0]
        mixed_query_layer = self.query(hidden_states)
        mixed_key_layer = self.key(hidden_states)
        mixed_value_layer = self.value(hidden_states)

        query_layer = self.transpose_for_scores(mixed_query_layer, batch_size)
        key_layer = self.transpose_for_scores(mixed_key_layer, batch_size)
        value_layer = self.transpose_for_scores(mixed_value_layer, batch_size)

        # Take the dot product between ""query"" and ""key"" to get the raw attention scores.
        attention_scores = tf.matmul(
            query_layer, key_layer, transpose_b=True
        )  # (batch size, num_heads, seq_len_q, seq_len_k)
        dk = tf.cast(shape_list(key_layer)[-1], tf.float32)  # scale attention_scores
        attention_scores = attention_scores / tf.math.sqrt(dk)

        if attention_mask is not None:
            # Apply the attention mask is (precomputed for all layers in TFBertModel call() function)
            attention_scores = attention_scores + attention_mask

        # Normalize the attention scores to probabilities.
        attention_probs = tf.nn.softmax(attention_scores, axis=-1)

        # This is actually dropping out entire tokens to attend to, which might
        # seem a bit unusual, but is taken from the original Transformer paper.
        attention_probs = self.dropout(attention_probs, training=training)

        # Mask heads if we want to
        if head_mask is not None:
            attention_probs = attention_probs * head_mask

        context_layer = tf.matmul(attention_probs, value_layer)

        context_layer = tf.transpose(context_layer, perm=[0, 2, 1, 3])
        context_layer = tf.reshape(
            context_layer, (batch_size, -1, self.all_head_size)
        )  # (batch_size, seq_len_q, all_head_size)

        outputs = (
            (context_layer, attention_probs) if cast_bool_to_primitive(output_attentions) is True else (context_layer,)
        )

        return outputs


class TFBertSelfOutput(tf.keras.layers.Layer):
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        self.dense = tf.keras.layers.Dense(
            config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=""dense""
        )
        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=""LayerNorm"")
        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)

    def call(self, inputs, training=False):
        hidden_states, input_tensor = inputs

        hidden_states = self.dense(hidden_states)
        hidden_states = self.dropout(hidden_states, training=training)
        hidden_states = self.LayerNorm(hidden_states + input_tensor)
        return hidden_states


class TFBertAttention(tf.keras.layers.Layer):
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        self.self_attention = TFBertSelfAttention(config, name=""self"")
        self.dense_output = TFBertSelfOutput(config, name=""output"")

    def prune_heads(self, heads):
        raise NotImplementedError

    def call(self, inputs, training=False):
        input_tensor, attention_mask, head_mask, output_attentions = inputs

        self_outputs = self.self_attention(
            [input_tensor, attention_mask, head_mask, output_attentions], training=training
        )
        attention_output = self.dense_output([self_outputs[0], input_tensor], training=training)
        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them
        return outputs


class TFBertIntermediate(tf.keras.layers.Layer):
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        self.dense = tf.keras.layers.Dense(
            config.intermediate_size, kernel_initializer=get_initializer(config.initializer_range), name=""dense""
        )
        if isinstance(config.hidden_act, str):
            self.intermediate_act_fn = ACT2FN[config.hidden_act]
        else:
            self.intermediate_act_fn = config.hidden_act

    def call(self, hidden_states):
        hidden_states = self.dense(hidden_states)
        hidden_states = self.intermediate_act_fn(hidden_states)
        return hidden_states


class TFBertOutput(tf.keras.layers.Layer):
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        self.dense = tf.keras.layers.Dense(
            config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=""dense""
        )
        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=""LayerNorm"")
        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)

    def call(self, inputs, training=False):
        hidden_states, input_tensor = inputs

        hidden_states = self.dense(hidden_states)
        hidden_states = self.dropout(hidden_states, training=training)
        hidden_states = self.LayerNorm(hidden_states + input_tensor)
        return hidden_states


class TFBertLayer(tf.keras.layers.Layer):
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        self.attention = TFBertAttention(config, name=""attention"")
        self.intermediate = TFBertIntermediate(config, name=""intermediate"")
        self.bert_output = TFBertOutput(config, name=""output"")

    def call(self, inputs, training=False):
        hidden_states, attention_mask, head_mask, output_attentions = inputs

        attention_outputs = self.attention(
            [hidden_states, attention_mask, head_mask, output_attentions], training=training
        )
        attention_output = attention_outputs[0]
        intermediate_output = self.intermediate(attention_output)
        layer_output = self.bert_output([intermediate_output, attention_output], training=training)
        outputs = (layer_output,) + attention_outputs[1:]  # add attentions if we output them
        return outputs

configBase = {
  ""attention_probs_dropout_prob"": 0.1,
  ""bos_token_id"": 0,
  ""eos_token_id"": 2,
  ""hidden_act"": ""gelu"",
  ""hidden_dropout_prob"": 0.1,
  ""hidden_size"": 768,
  ""initializer_range"": 0.02,
  ""intermediate_size"": 3072,
  ""layer_norm_eps"": 1e-05,
  ""max_position_embeddings"": 514,
  ""model_type"": ""roberta"",
  ""num_attention_heads"": 12,
  ""num_hidden_layers"": 12,
  ""pad_token_id"": 1,
  ""type_vocab_size"": 1,
  ""vocab_size"": 50265
}

class AttrDict(dict):
    def __init__(self, *args, **kwargs):
        super(AttrDict, self).__init__(*args, **kwargs)
        self.__dict__ = self

config = AttrDict(configBase)

def get_initializer(initializer_range=0.02):
    """"""Creates a `tf.initializers.truncated_normal` with the given range.
    Args:
        initializer_range: float, initializer range for stddev.
    Returns:
        TruncatedNormal initializer with stddev = `initializer_range`.
    """"""
    return tf.keras.initializers.TruncatedNormal(stddev=initializer_range)


def gelu(x):
    """""" Gaussian Error Linear Unit.
    Original Implementation of the gelu activation function in Google Bert repo when initially created.
        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):
        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))
        Also see https://arxiv.org/abs/1606.08415
    """"""
    cdf = 0.5 * (1.0 + tf.math.erf(x / tf.math.sqrt(2.0)))
    return x * cdf

ACT2FN = {
    ""gelu"": tf.keras.layers.Activation(gelu),
}

def shape_list(x):
    """"""Deal with dynamic shape in tensorflow cleanly.""""""
    static = x.shape.as_list()
    dynamic = tf.shape(x)
    return [dynamic[i] if s is None else s for i, s in enumerate(static)]

def cast_bool_to_primitive(bool_variable, default_tensor_to_true=False):
    """"""Function arguments can be inserted as boolean tensor
        and bool variables to cope with keras serialization
        we need to cast `output_attentions` to correct bool
        if it is a tensor
    Args:
        default_tensor_to_true: bool, if tensor should default to True
        in case tensor has no numpy attribute
    """"""
    # if bool variable is tensor and has numpy value
    if tf.is_tensor(bool_variable):
        if hasattr(bool_variable, ""numpy""):
            return bool(bool_variable.numpy())
        elif default_tensor_to_true:
            return True

    # else variable is bool
    return bool_variable

def get_2_transformerLayerP(numb):
    tokenizer = AutoTokenizer.from_pretrained('allenai/biomed_roberta_base')
    inputt = tokenizer.encode('This is a sentence', return_tensors='tf')
    tempModel = TFRobertaModel.from_pretrained('allenai/biomed_roberta_base', from_pt=True)
    outt = tempModel(inputt)[0]

    t_layer11 = TFBertLayer(config, name=""layer_._{}"".format(11+numb))
    t_layer12 = TFBertLayer2(config, name=""layer_._{}"".format(12+numb))

    t_layer11((outt, None, None, None))
    t_layer12((outt, None, None, None))

    t_layer11.set_weights( tempModel.layers[0].encoder.layer[10].get_weights() )
    t_layer12.set_weights( tempModel.layers[0].encoder.layer[11].get_weights() )

    t_layer12.intermediate.intermediate_act_fn = tf.keras.activations.tanh

    del tokenizer
    del tempModel

    return t_layer11, t_layer12

def get_mini_models():
    P_trans11, P_trans12 = get_2_transformerLayerP(6)

    inputHiddenVals = tf.keras.Input(shape=[None, None], dtype=tf.float32, name='input_Q',
                                    batch_size=None) 

    P_outputs = P_trans11((inputHiddenVals, None, None, None))[0]
    P_outputsFinal = P_trans12((P_outputs, None, None, None))[0]
    modelNew = tf.keras.Model(inputs=inputHiddenVals, outputs=P_outputsFinal)

    return modelNew

@tf.function
def loss_fn(_, probs):

    bs = tf.shape(probs)[0]
    labels = tf.eye(bs, bs)
    return tf.losses.categorical_crossentropy(labels,
                                              probs,
                                              from_logits=True)

model = get_mini_models()
model.compile(loss=loss_fn,
                optimizer=tfa.optimizers.AdamW(weight_decay=1e-4, learning_rate=1e-5, 
                                                epsilon=1e-06))

for i, var in enumerate(model.trainable_weights):
    print(model.trainable_weights[i].name)

```"
40637,UnidentifiedImageError when I try to train my model,"UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x63a807fb0>

Using Keras library
OS: macOS Catalina
Python version: 3.7.6
Pillow version: PIL 7.1.2
Keras version: 2.3.1

```
classifier.fit_generator(training_set,
steps_per_epoch = 914,
epochs = 25,
validation_data = test_set,
validation_steps = 237)
```
![83977734-8134f300-a920-11ea-980d-6309847697c8](https://user-images.githubusercontent.com/59297399/85206340-fea82c80-b33e-11ea-8277-6708e7f6b554.png)
"
40635,Loss function not accessible when overriding optimizer_v2.OptimizerV2,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
n/a
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
TensorFlow version: 2.1.0
- Python version:
Python 3.6.10 |Anaconda, Inc.| (default, Mar 23 2020, 17:58:33) [MSC v.1916 64 bit (AMD64)]
- Bazel version (if compiling from source):
n/a
- GCC/Compiler version (if compiling from source):
n/a
- CUDA/cuDNN version:
- GPU model and memory:
n/a

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)

== check for virtualenv =========================================
False


== tensorflow import ============================================
Traceback (most recent call last):

  File ""<string>"", line 1, in <module>

ModuleNotFoundError: No module named 'tensorflow'


== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tf_env_collect.sh: line 145: nvidia-smi: command not found

== cuda libs  ===================================================

== tensorflow installed from info ==================

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 8, 2, 'final', 0)


== bazel version  ===============================================



You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
v2.1.0-rc2-17-ge5bf8de410 2.1.0

**Describe the current behavior**

There is no access to the loss function within the methods that are allowed to be overridden in the optimizer_v2.OptimizerV2 class, i.e _resource_apply_dense(). The result is that weights do not change within during training. I have tried overriding _compute_gradients(),but it is never called. 

As can be seen from the output at the last line, the weights do not change.

**Describe the expected behavior**

I want to be able to change the weights based upon the loss. In this case to change them randomly if the loss has not decreased. However, to do this one of the methods I am allowed to override should be passed the loss function.


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/github/ruperty/colab/blob/master/optimizer_test.ipynb

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40634,Looping over tf.data.Dataset very slow compared to that of Numpy Array,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A. Can be replicated in Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): N/A
- TensorFlow version (use command below): 2.2 and tf-nightly
- Python version: 3.6.7 (Google Colab)
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**: `For-Loop` over samples of a `tf.data.Dataset` is much slower (almost 500 times) than looping over the corresponding `numpy array`.

**Describe the expected behavior**: Looping over `tf.data.Dataset` shouldn't take so long.

**Standalone code to reproduce the issue**: This is the [Colab link](https://colab.research.google.com/gist/rakeshmothukuru1/c411d6de49f6cfb3d610d05c54a6d172/so_62453823.ipynb) to reproduce the issue.

```
import numpy as np
import tensorflow as tf
import time

print(tf.__version__)

a = np.ones(100000, dtype=np.float32)

start_time = time.time()
for x in a:
    pass
print(time.time() - start_time)

start_time = time.time()
for x in tf.data.Dataset.from_tensor_slices(a):
    pass
print(time.time() - start_time)
```"
40633,SparseTensor from dense conversion error when dtype tf.string,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): conda/binary
- TensorFlow version (use command below): unknown 2.1.0
- Python version: 3.7.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.2/7.6.5
- GPU model and memory: GTX 1070 8GB

**Describe the current behavior**
Fails to convert the Tensor to a SparseTensor representation

**Describe the expected behavior**
b should contain the SparseTensor representation of a

**Standalone code to reproduce the issue**

a = tf.constant(list(""ababa""))
print(a)
b = tf.sparse.from_dense(a)
print(b)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Traceback (most recent call last):
  File ""test.py"", line 264, in <module>
    b = tf.sparse.from_dense(a)
  File ""/home/alex/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/sparse_ops.py"", line 121, in from_dense
    math_ops.not_equal(tensor, array_ops.constant(0, tensor.dtype)))
  File ""/home/alex/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py"", line 258, in constant
    allow_broadcast=True)
  File ""/home/alex/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py"", line 266, in _constant_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/home/alex/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py"", line 96, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
TypeError: Cannot convert 0 to EagerTensor of dtype string
"
40632,Concatenating weights in Keras custom layer using `add_weight` fails while computing gradients,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A. It can be reproduced in Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): N/A
- TensorFlow version (use command below): 2.2.0 and tf-nightly
- Python version: 3.6.7 (Google Colab)
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**: While writing a `custom layer`, I need to have multiple `weight` matrices `concatenated` together. If I do this in the `build function` using `tf.concatenate`, I get the error `ValueError: No gradients provided for any variable:...`, however, if I make a `list of weights` in `build` and `concatenate` them in `call` it works.

**Describe the expected behavior**: It should work with `tf.concatenate` as well.

**Standalone code to reproduce the issue**: This is the [Colab link](https://colab.research.google.com/gist/rakeshmothukuru1/90bcb59075b6b5e60d00ffb060270a29/so_62425584.ipynb) to reproduce the issue.

Providing the code below as well.

```
import tensorflow as tf
import numpy as np
from tensorflow.keras.optimizers import Adam

print(tf.__version__)

class MultiInputLinear(tf.keras.layers.Layer):
    def __init__(self, output_dim=32, n_inputs=2):
        super(MultiInputLinear, self).__init__()
        self.output_dim = output_dim
        self.n_inputs = n_inputs


    def build(self, input_shapes):
        self.input_dim = input_shapes[0][1]

        self.W = tf.concat(
            [
                self.add_weight(
                    name=f'W_{i}',
                    shape=(self.input_dim, self.output_dim),
                    initializer='random_normal',
                    trainable=True
                ) for i in range(self.n_inputs)
            ], axis=0
        )

    def call(self, inputs):  
        supports = tf.concat(inputs, axis=-1)        
        return tf.matmul(supports, self.W)

N = 100
A = [np.random.normal(size=(N, N)) for _ in range(2)]
y = np.random.binomial(1, .1, size=(N, 32))

A_in = [tf.keras.layers.Input(batch_size=N, shape=(N, )) for _ in range(2)]
Y = MultiInputLinear(y.shape[1], 2)(A_in)

model = tf.keras.models.Model(inputs=A_in, outputs=Y)
model.compile(loss='categorical_crossentropy', optimizer=Adam())

model.fit(A, y, batch_size=N)
```
**Working Code** :

```
import tensorflow as tf
import numpy as np
from tensorflow.keras.optimizers import Adam

class MultiInputLinear(tf.keras.layers.Layer):
    def __init__(self, output_dim=32, n_inputs=2):
        super(MultiInputLinear, self).__init__()
        self.output_dim = output_dim
        self.n_inputs = n_inputs


    def build(self, input_shapes):
        self.input_dim = input_shapes[0][1]

        self.W_list = [
                self.add_weight(
                    name=f'W_{i}',
                    shape=(self.input_dim, self.output_dim),
                    initializer='random_normal',
                    trainable=True
                ) for i in range(self.n_inputs)
            ]

    def call(self, inputs):  
        supports = tf.concat(inputs, axis=-1)
        W = tf.concat(self.W_list, axis=0)

        return tf.matmul(supports, W)

N = 100
A = [np.random.normal(size=(N, N)) for _ in range(2)]
y = np.random.binomial(1, .1, size=(N, 32))

A_in = [tf.keras.layers.Input(batch_size=N, shape=(N, )) for _ in range(2)]
Y = MultiInputLinear(y.shape[1], 2)(A_in)

model = tf.keras.models.Model(inputs=A_in, outputs=Y)
model.compile(loss='categorical_crossentropy', optimizer=Adam())

model.fit(A, y, batch_size=N)
```

**Other info / logs** :     `ValueError: No gradients provided for any variable: ['multi_input_linear_4/W_0:0', 'multi_input_linear_4/W_1:0'].`
"
40631,"@tf.function decorated functions cannot access class varaiables, tf.print() doesn't work","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.10
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: Training on CPU

**Describe the current behavior**

I am trying to create a Q Learning algorithm using TF2. I have this class variable called memory that keeps increasing in size as training goes on. Inside the @tf.function decorated weight update function, when I print the size of memory, it seems to be always 1 (doesn't seem to increase). Here are the different configurations with which I tried this code,

1. With **tf.compat.v1.disable_eager_execution()** and **@tf.function** decorator
    - The tf.print() call inside this decorated function doesn't work, so I am not sure if this is actually training the model or not
2. With only **@tf.function** decorator,
    - The tf.print() call inside the decorated function works, but the class variable size is always constant (1).
3. With only **tf.compat.v1.disable_eager_execution()**,
    - The code raises this error `TypeError: 'Tensor' object does not support item assignment`
    - I tried to convert the Tensor into a numpy array, but it raises this error `'Tensor' object has no attribute 'numpy'`
4. With neither **tf.compat.v1.disable_eager_execution()** nor **@tf.function** decorator,
    - The code works as expected but is extremely slow (because of the eager execution I presume)

**Describe the expected behavior**


1. The **@tf.function** decorator to be able to handle class variables that change during runtime.
2. The **tf.print()** calls to work even when **tf.compat.v1.disable_eager_execution()** is called

As listed above, **method 1** seems to work as there are no errors, but there is no way for me to check whether my model is actually training or not as the `tf.print()` call doesn't seem to work. Ideally, I want method 1 to work as this is the fastest form of execution that matches the speeds of a similar implementation in TF1.1

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
from tensorflow import keras
import numpy as np
import random
import tqdm
import yfinance as yf


# tf.compat.v1.disable_eager_execution()
ticker = ""AAPL""
df_full = yf.Ticker(""{}"".format(ticker)).history(""max"").reset_index()
df = df_full.copy()[""Close""]
data = df.copy()


class DQN:
    def __init__(self, data, lookBack=30,
                 gamma=0.95, epsilon=0.5,
                 epsilonMin=0.01, epsilonDecay=0.8,
                 learningRate=0.001, money=10000):
        # NOT IMPORTANT
        self.lookBack = lookBack
        self.initialMoney = money
        self.actionSize = 3

        self.data = data
        self.gamma = gamma
        self.epsilon = epsilon
        self.epsilonMin = epsilonMin
        self.epsilonDecay = epsilonDecay
        self.learningRate = learningRate

        self.memory = []

    def buildModel(self):
        keras.backend.clear_session()
        model = keras.models.Sequential()
        model.add(keras.layers.Dense(256, input_shape=[self.lookBack],
                                     activation=""relu""))
        model.add(keras.layers.Dense(self.actionSize))

        self.optimizer = keras.optimizers.RMSprop(lr=self.learningRate,
                                                  epsilon=0.1,
                                                  rho=0.99)
        self.lossFunc = keras.losses.mean_squared_error
        model.compile(loss=""mse"", optimizer=self.optimizer)
        self.model = model

    def getAction(self, state):
        # NOT IMPORTANT
        if random.random() <= self.epsilon:
            return random.randrange(self.actionSize)
        else:
            return np.argmax(self.model.predict(state)[0])

    def createDataset(self):
        # NOT IMPORTANT
        tmp = self.data.copy()
        tmp = tmp.diff(1).dropna().values
        shape = tmp.shape[:-1] + (tmp.shape[-1] - self.lookBack + 1,
                                  self.lookBack)
        strides = tmp.strides + (tmp.strides[-1],)
        self.dataset = np.lib.stride_tricks.as_strided(tmp, shape=shape,
                                                       strides=strides)

    def getReward(self, action, currentPrice):
        # NOT IMPORTANT
        return 0

    # @tf.function
    def updateWeights(self):
        # IMPORTANT
        tf.print(len(self.memory))
        if len(self.memory) >= self.batchSize:
            endIndex = len(self.memory)
            startIndex = endIndex - self.batchSize
            batchData = []
            for i in range(startIndex, endIndex):
                batchData.append(self.memory[i])
            X = np.zeros((self.batchSize, self.lookBack))
            Y = np.zeros((self.batchSize, self.actionSize))
            states = np.array([item[0] for item in batchData])
            newStates = np.array([item[3] for item in batchData])
            Q = self.model(states)
            QNext = self.model(newStates)
            for i in range(len(batchData)):
                state, action, reward, nextState = batchData[i]
                target = Q[i]
                target[action] = reward
                target[action] += self.gamma * np.max(QNext[i])

                X[i] = state
                Y[i] = target
            self.model.train_on_batch(X, Y)
            if self.epsilon > self.epsilonMin:
                self.epsilon *= self.epsilonDecay

    def train(self, epochs=200, logFreq=1):
        # IMPORTANT
        for epoch in range(epochs):
            self.profit = 0
            self.money = self.initialMoney
            for timeStep in tqdm.tqdm(range(self.lookBack, len(self.data)-1)):
                currentPrice = data[timeStep]
                currentState = self.dataset[timeStep-self.lookBack]
                nextState = self.dataset[timeStep-self.lookBack+1]

                action = self.getAction(currentState.reshape(1, -1))

                reward = self.getReward(action, currentPrice)

                self.memory.append((currentState, action, reward, nextState))

                self.updateWeights()


test = DQN(data)
test.createDataset()
test.buildModel()
test.train(100)
```

The important functions are marked as so. Please take a look at those functions, all others are just helper functions for reproducibility.

**Other info / logs** 

1. Entire traceback for **method 3**, 

```
/Users/aakashsasikumar/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.
  warnings.warn(msg)
WARNING:tensorflow:From /Users/aakashsasikumar/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
  0%|                                                                                                                        | 0/9933 [00:00<?, ?it/s]2020-06-20 12:13:31.271860: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-20 12:13:31.286799: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa9662abf90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-20 12:13:31.286826: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  0%|                                                                                                                        | 0/9933 [00:00<?, ?it/s]
Traceback (most recent call last):
  File ""/Users/aakashsasikumar/Documents/Code/Python/StockMate/Misc/Benchmarks/QLearningAgentTF2.py"", line 122, in <module>
    test.train(100)
  File ""/Users/aakashsasikumar/Documents/Code/Python/StockMate/Misc/Benchmarks/QLearningAgentTF2.py"", line 116, in train
    self.updateWeights()
  File ""/Users/aakashsasikumar/Documents/Code/Python/StockMate/Misc/Benchmarks/QLearningAgentTF2.py"", line 91, in updateWeights
    target[action] = reward
TypeError: 'Tensor' object does not support item assignmenttext
```
2. Entire traceback for **method 3** when I try converting the tf.Tensor into a numpy array,
```text
/Users/aakashsasikumar/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.
  warnings.warn(msg)
WARNING:tensorflow:From /Users/aakashsasikumar/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
  0%|                                                                                                                        | 0/9933 [00:00<?, ?it/s]2020-06-20 12:15:24.714805: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-20 12:15:24.728233: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbdd92625a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-20 12:15:24.728260: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  0%|                                                                                                                        | 0/9933 [00:00<?, ?it/s]
Traceback (most recent call last):
  File ""/Users/aakashsasikumar/Documents/Code/Python/StockMate/Misc/Benchmarks/QLearningAgentTF2.py"", line 122, in <module>
    test.train(100)
  File ""/Users/aakashsasikumar/Documents/Code/Python/StockMate/Misc/Benchmarks/QLearningAgentTF2.py"", line 116, in train
    self.updateWeights()
  File ""/Users/aakashsasikumar/Documents/Code/Python/StockMate/Misc/Benchmarks/QLearningAgentTF2.py"", line 90, in updateWeights
    target = Q[i].numpy()
AttributeError: 'Tensor' object has no attribute 'numpy'
```
"
40630,"In model.fit, have each metric given a new line in display. ","

**Describe the feature and the current behavior/state.**

Instead of having each metric on one line in the display for model.fit, have each metric on a new line.

**Who will benefit with this feature?**

Those who are trying to monitor a ton of metrics. In my particular case, I am trying to track down the cause of exploding gradients, so I'm monitoring the norm of each trainable_weight. This makes for a very long line to side-scroll through. 

"
40629,python sequence example context_features  Unsupported FixedLenSequenceFeature,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):   tf 2.2
- Are you willing to contribute it (Yes/No):


**Describe the feature and the current behavior/state.**

   */miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/parsing_ops.py:548 parse_sequence_example  **
        context_features, [VarLenFeature, FixedLenFeature, RaggedFeature])
    /data1/arc_seven/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/parsing_config.py:461 from_features
        (type(feature).__name__, feature))

    ValueError: Unsupported FixedLenSequenceFeature FixedLenSequenceFeature(shape=(), dtype=tf.float32, allow_missing=-1, default_value=None).



**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
40628,Please enable ImageDataGenerator for tpu accelerator ,"please enable ImageDataGenerator for tpu because create TFRecordDataset is the complex and worst method I ever have seen my entire deep-learning experience . or make a function that converts ImageDataGenerator to TFRecordDataset. 

If converts ImageDataGenerator to TFRecordDataset gives me a reference.

Thank you"
40627,I want to implement the beam search,"i am using this code : https://www.tensorflow.org/tutorials/text/nmt_with_attention

I want to implement the beam search to this code in order to generate more than one sentence, but i don't know how can i do it. Can you please help me ?
"
40623,ALBERT from TF Hub doesn't work with GradientTape,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 9.12
- TensorFlow installed from (source or binary): Automatic installation for GCP deep learning vm
- TensorFlow version (use command below): 2.1.0
- Tensorflow Hub version: 0.8.0
- Python version: 3.7.6
- CUDA/cuDNN version: 10.1
- GPU model and memory: Nvidia V100

**Describe the current behavior**
I get an error when trying to run ALBERT from TF-Hub inside a `tf.GradientTape()` context. The error occurs at the ""forward pass"" before calling `tape.gradient()` . The error does not occur when the model call is placed outside of the `tf.GradientTape()` context. 

**Describe the expected behavior**
No such error should occur and the model should run and gradients should be calculated properly. 

**Standalone code to reproduce the issue**
```
import tensorflow as tf
import tensorflow_hub as hub
from tensorflow import keras
import numpy as np

def get_model():
    global max_seq_length
    global batch_size
    input_word_ids = keras.layers.Input(batch_shape=(batch_size, max_seq_length, ), 
                                           dtype=tf.int32,
                                           name=""input_word_ids"")
    input_mask = keras.layers.Input(batch_shape=(batch_size, max_seq_length, ), 
                                       dtype=tf.int32,
                                       name=""input_mask"")
    segment_ids = keras.layers.Input(batch_shape=(batch_size, max_seq_length, ), 
                                        dtype=tf.int32,
                                        name=""segment_ids"")
    albert_layer = hub.KerasLayer(""https://tfhub.dev/tensorflow/albert_en_base/1"",
                                  trainable=True,
                                  name='albert_layer')
    pooled_output, sequence_output = albert_layer([input_word_ids, input_mask, segment_ids])
    output = keras.layers.Dense(2)(sequence_output)

    model = keras.Model(inputs=(input_word_ids, input_mask, segment_ids),
                        outputs=output)
    print(model.summary())
    return model


batch_size = 4
max_seq_length = 16
model = get_model()

input_ids = 5 * np.ones((4, 16), dtype=np.int32)
input_mask = np.ones((4, 16), dtype=np.int32)
segment_ids = np.zeros((4, 16), dtype=np.int32)

with tf.GradientTape(persistent=True) as tape:
    logits = model({
                  'input_word_ids' : input_ids,
                  'input_mask' : input_mask,
                  'segment_ids' : segment_ids
    })
    print(logits)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
Traceback (most recent call last):
  File ""albert_gradient_tape_test.py"", line 42, in <module>
    'segment_ids' : segment_ids
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 822, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 717, in call
    convert_kwargs_to_constants=base_layer_utils.call_context().saving)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 891, in _run_internal_graph
    output_tensors = layer(computed_tensors, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 822, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py"", line 218, in call
    lambda: f(training=False))
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/smart_cond.py"", line 56, in smart_cond
    return false_fn()
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py"", line 218, in <lambda>
    lambda: f(training=False))
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 438, in _call_attribute
    return instance.__call__(*args, **kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 606, in _call
    results = self._stateful_fn(*args, **kwds)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2362, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/function_deserialization.py"", line 241, in restored_function_body
    return _call_concrete_function(function, inputs)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/function_deserialization.py"", line 72, in _call_concrete_function
    result = function._call_flat(tensor_inputs, function._captured_inputs)  # pylint: disable=protected-access
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 99, in _call_flat
    cancellation_manager)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1697, in _call_flat
    forward_function, args_with_tangents = forward_backward.forward()
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1423, in forward
    self._inference_args, self._input_tangents)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1185, in forward
    self._forward_and_backward_functions(inference_args, input_tangents))
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1379, in _forward_and_backward_functions
    outputs, inference_args, input_tangents)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 882, in _build_functions_for_outputs
    output)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/default_gradient.py"", line 45, in shape_and_dtype
    ""of a variable without handle data:\n%s"" % str(t))
ValueError: Internal error: Tried to take gradients (or similar) of a variable without handle data:
Tensor(""StatefulPartitionedCall:949"", shape=(), dtype=resource)
```
"
40622,tf.tpu.experimental.initialize_tpu_system fails to work on nightly builds,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colaboratory (Linux)
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf-nightly_v2.3.0.dev20200619
- Python version: v3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A
- TPU: Google Colab runtime with TPU accelerator

**Describe the current behavior**
`tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)` raises an unexpected error. The stack trace containing this error is provided underneath. 

The sample notebook that was being used to train an `EfficientNetB0` model with `TPUStrategy` containing the error message is provided [here](https://colab.research.google.com/drive/1twKOkGxWO8NpYIE_SZ2qroVNEyGCxQrS?usp=sharing). 

**Describe the expected behavior**
A ResNet50 model (as EfficientNetB0 is only present in TF-nightly) with similar code is able to run successfully with TPUStrategy and there are no such errors reported while calling `tf.tpu.experimental.initialize_tpu_system`.  A notebook with the corresponding training code for TFv2.2 can be found [here](https://colab.research.google.com/drive/1BPsM3Gh1d6-nXY0urp0AFuSm2WKlYorv?usp=sharing).

**Standalone code to reproduce the issue**
Just calling `tf.tpu.experimental.initialize_tpu_system` using the standard mechanism on a Colab runtime with TPU should suffice.

```python
tpu_url = 'grpc://' + os.environ['COLAB_TPU_ADDR']
tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_url)

tf.config.experimental_connect_to_cluster(tpu_cluster_resolver)
tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)

strategy = tf.distribute.experimental.TPUStrategy(tpu_cluster_resolver)
```

**Other info / logs** 

```python
Running on TPU  ['10.57.138.26:8470']
INFO:tensorflow:Initializing the TPU system: grpc://10.57.138.26:8470

INFO:tensorflow:Initializing the TPU system: grpc://10.57.138.26:8470

INFO:tensorflow:Clearing out eager caches

INFO:tensorflow:Clearing out eager caches

---------------------------------------------------------------------------

InvalidArgumentError                      Traceback (most recent call last)

<ipython-input-4-a42f01f7e70e> in <module>()
      6 
      7 tf.config.experimental_connect_to_cluster(tpu)
----> 8 tf.tpu.experimental.initialize_tpu_system(tpu)
      9 tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)

3 frames

/usr/local/lib/python3.6/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py in initialize_tpu_system(cluster_resolver)
    101     context.context()._clear_caches()  # pylint: disable=protected-access
    102 
--> 103     serialized_topology = output.numpy()
    104 
    105     # TODO(b/134094971): Remove this when lazy tensor copy in multi-device

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in numpy(self)
   1061     """"""
   1062     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.
-> 1063     maybe_arr = self._numpy()  # pylint: disable=protected-access
   1064     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr
   1065 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _numpy(self)
   1029       return self._numpy_internal()
   1030     except core._NotOkStatusException as e:  # pylint: disable=protected-access
-> 1031       six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access
   1032 
   1033   @property

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}
```

Typically, this bug is prevalent only on nightly builds (master branch) and not on TF v2.2 release.

/cc: @tanzhenyu "
40620,random in tf.data.Dataset.map is not random if not coming from tensorflow,"**System information**
== check os platform ===============================================
os: Linux
os kernel version: #53~18.04.1-Ubuntu SMP Thu Jun 4 14:58:26 UTC 2020
os release version: 5.3.0-59-generic
os platform: Linux-5.3.0-59-generic-x86_64-with-Ubuntu-18.04-bionic
linux distribution: ('Ubuntu', '18.04', 'bionic')
linux os distribution: ('Ubuntu', '18.04', 'bionic')
mac version: ('', ('', '', ''), '')

== check python ===================================================
python version: 3.6.9
python branch: 
python build version: ('default', 'Apr 18 2020 01:56:04')
python compiler version: GCC 8.4.0
python implementation: CPython

== compiler =====================================================
c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

== check pips ===================================================
numpy                   1.18.4
protobuf                3.12.2
tensorflow              2.1.1
tensorflow-addons       0.10.0
tensorflow-estimator    2.1.0

== tensorflow import ============================================
tf.version.VERSION = 2.1.1
tf.version.GIT_VERSION = v2.1.0-33-g3ffdb91
tf.version.COMPILER_VERSION = 7.3.1 20180303


**Standalone code to reproduce the issue**

```python
import tensorflow as tf
import numpy as np
import random as rd

dataset = (
    tf.data.Dataset.from_tensor_slices((np.arange(5)))
    .map(lambda annotation: (rd.random(), np.random.rand(), tf.random.uniform([])))
)

for el in dataset:
    print(el)
```

**Describe the current behavior**
The value for every element of the dataset is the same for python or numpy based random, but not for tensorflow based random.

**Describe the expected behavior**
The value for tf, np, python (...)-based randomness is a new random value for every dataset element.
Or a warning / error to avoid falling into this trap and debugging.
"
40617,keras.models.clone_model ignores input_tensors for functional models,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.7
- CUDA/cuDNN version: 10.1
- GPU model and memory:

**Describe the current behavior**
For functional models `tensorflow.keras.models.clone_model` ignores input_tensors if they are InputLayer objects. It keeps the original input tensors and does not build the model ""on top of new inputs tensors"".

**Describe the expected behavior**
The cloned model should be built on provided ""input tensors or InputLayer objects"" as stated in the documentation and as it is for sequential models.
This would allow to change the input shape and dtype or clone a model on top of a model.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf

# Build a sequential and functional model
original_input = tf.keras.Input(shape=(1,), dtype=tf.float32)
sequential_model = tf.keras.Sequential([
    original_input,
    # tf.keras.layers.Lambda(lambda x: x),
])
functional_model = tf.keras.Model(sequential_model.inputs, sequential_model.outputs)

# Predict some data
print(""sequential_model:"", sequential_model.predict([[1.5]]))
print(""functional_model:"", functional_model.predict([[1.5]]))

# Clone the model
cloned_sequential_model = tf.keras.models.clone_model(sequential_model)
cloned_functional_model = tf.keras.models.clone_model(functional_model)
assert id(cloned_sequential_model.input) != id(original_input)  # OK
assert id(cloned_functional_model.input) != id(original_input)  # OK

# Clone the model and make the input expect a different shape and dtype
new_input = tf.keras.Input(shape=(None,), dtype=tf.uint8)
cloned_sequential_model = tf.keras.models.clone_model(sequential_model, input_tensors=[new_input])
cloned_functional_model = tf.keras.models.clone_model(functional_model, input_tensors=[new_input])

assert id(cloned_sequential_model.input) == id(new_input) # OK
assert id(cloned_functional_model.input) == id(new_input) # FAILS (expected to pass)
assert id(cloned_functional_model.input) != id(original_input)  # FAILS (expected to pass)

print(""cloned_sequential_model.inputs:"", cloned_sequential_model.inputs)
print(""cloned_functional_model.inputs:"", cloned_functional_model.inputs)

assert(cloned_sequential_model.predict([[1.5]]) == cloned_functional_model.predict([[1.5]])) # FAILS (expected to pass)
print(""cloned_sequential_model:"", cloned_sequential_model.predict([[1.5]]))
print(""cloned_functional_model:"", cloned_functional_model.predict([[1.5]]))

## Chain example
x = tf.keras.Input(shape=(1,), dtype=tf.float32)
y = tf.keras.layers.Lambda(lambda x: -x)(x)
other_model = tf.keras.Model(x, y)

chained_models = tf.keras.models.clone_model(functional_model, other_model.outputs)
assert chained_models.predict([[1]]) == [[-1]] # FAILS (expected to pass)
print(""chained_models:"", chained_models.predict([[1]]))

```
"
40616,RuntimeError: Mmap of '/home/pi/object-detector/model' failed.,"Hi, 
I am using Raspberry pi 4 Model B, armv7l, with Raspbian stretch. I am having one 'mobilenet_v2_1.0_224_quant_edgetpu.tflite' model which I want to run with the google coral edge TPU. When I am trying to run the model it fails. 
I have used 658 images of two classes. I have also used same images for the training and validation. 
What can be the reason (not enough memory, TPU is damaged, the model is not prepared properly )?  How can I get to know the edge TPU is working or not? How can I fix it? 

Her is the traceback call: 

     pi@raspberrypi:~/object-detector $ python3 detect_object_video_edge.py --model  
    /home/pi/object-mask-detector/model --labels /home/pi/object-detector/model/object_labels.txt
    [INFO] parsing class labels...
    [INFO] loading Coral model...
    Traceback (most recent call last):
      File ""detect_object_video_edge.py"", line 29, in <module>
        model = DetectionEngine(args[""model""])
      File ""/usr/lib/python3/dist-packages/edgetpu/detection/engine.py"", line 73, in __init__
        super().__init__(model_path)
      File ""/usr/lib/python3/dist-packages/edgetpu/basic/basic_engine.py"", line 92, in __init__
        self._engine = BasicEnginePythonWrapper.CreateFromFile(model_path)
    RuntimeError: Mmap of '/home/pi/object-detector/model' failed.
"
40615, C++ interface session->Close() does not reclaim memory resources,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Utuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.5
- Python version:
- Bazel version (if compiling from source):0.24.1
- GCC/Compiler version (if compiling from source):5.5.0
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

When I have executed session->closing(), the memory is not completely released.
I found that after the destruction of the session object, only a part of the memory was released, not completely released.

In my scenario, the complete memory is 4.28G, after executing session->Close() and destructuring the object, the memory is 3G.

**Describe the expected behavior**

Theoreticallyafter executed session->Close() will Close the session to release the resources associated with.

**Standalone code to reproduce the issue**

int main() {
  {
    tensorflow::SessionOptions sess_options_;
    sess_options_.config.set_use_per_session_threads(true);
    sess_options_.config.set_intra_op_parallelism_threads(1);
    sess_options_.config.set_inter_op_parallelism_threads(1);

    std::unique_ptr<tensorflow::Session> sess_;
    sess_.reset(tensorflow::NewSession(sess_options_));

    tensorflow::GraphDef graph_def;
    auto default_env = tensorflow::Env::Default();
    tensorflow::Status s = tensorflow::ReadBinaryProto(default_env, 
      pd_path, &graph_def);

    sess_->Create(graph_def);

    std::vector<tensorflow::Tensor> output;
    std::vector<std::pair<std::string, tensorflow::Tensor>> tf_input;

    tf_input.emplace_back(...);
    auto status = sess_->Run(tf_input,
                             std::vector<std::string>{""output_node""}, {},
                             &output);
    sess_->Close();
  }
}"
40614,"If TMP is not set, then the build system defaults to the wrong path","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.3.1611 (Core)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): source
- TensorFlow version: v2.2.0
- Python version: 3.5.1
- Installed using virtualenv? pip? conda?: no, compiling from source
- Bazel version (if compiling from source): 2.0.0 (it claimed that Tensorflow did not support anything higher)
- GCC/Compiler version (if compiling from source): 8.2.0
- CUDA/cuDNN version: 10.1
- GPU model and memory: Tesla P100, 16280MiB



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
When building Tensorflow from source when the `TMP` environment variable is not set, then following warning is shown:

```
Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\Windows\Temp' as default
```

Naturally, I would expect it to default to something. However, I'm on a _Linux_ computer, not a _Windows_ computer. On Linux, it should default to something sensible (e.g. `/tmp`, or the current directory), instead of `C:\Windows\Temp` - which clearly isn't going to work - as on Linux this is not a valid file/directory path.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\Windows\Temp' as default
```"
40613,TFLite GPU Delegate with OpenCL backend produces wrong result,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Oneplus 6 (Snapdragon 845)
- TensorFlow installed from (source or binary): source (tag v2.1.1) and binary
- TensorFlow version (use command below): v2.1.1
- Python version: python 3.6.9
- Bazel version (if compiling from source): bazel 0.29.1
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
- CUDA/cuDNN version: 
from `nvidia-smi`:
NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2
from `nvcc --version`:
Cuda compilation tools, release 10.1, V10.1.243
no `cuDNN`
- GPU model and memory:
RTX 2080 Ti 11G memory

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
Build environment information:
[tf_env_bulid.txt](https://github.com/tensorflow/tensorflow/files/4803097/tf_env_bulid.txt)

Execution evironment information:
[tf_env_exec.txt](https://github.com/tensorflow/tensorflow/files/4803099/tf_env_exec.txt)


You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
```
v2.1.0-33-g3ffdb91 2.1.1
```

**Describe the current behavior**
I used YOLOv3 (COCO dataset) TFLite model to detect obejcts,
while TFLite OpenCL GPU Delegate produces error result compared to TFLite CPU backend.

TFLite CPU:
<img src=""https://user-images.githubusercontent.com/3896992/85111276-aee63a00-b246-11ea-8723-f75cbf048fa4.jpg"" width=""250"">


TFLite OpenCL GPU Delegate:
<img src=""https://user-images.githubusercontent.com/3896992/85111294-b279c100-b246-11ea-84a3-3af63af3b977.jpg"" width=""250"">

Note the tie on Zidane is not detected with OpenCL GPU delegate.

At first, the detection problem is encountered on Oneplus 6T.
To ensure the problem is only with OpenCL GPU delegate and not with OpenGLES GPU delegate, I built both OpenCL and OpenGLES GPU delegate on Linux to double check the result.
Linux OpenCL:
<img src=""https://user-images.githubusercontent.com/3896992/85112848-e48c2280-b248-11ea-831d-7f19c68b1f66.jpg"" width=""400"">

Linux OpenGLES:
<img src=""https://user-images.githubusercontent.com/3896992/85113251-9297cc80-b249-11ea-80ba-4e6610fad545.jpg"" width=""400"">

**Describe the expected behavior**
TFLite OpenCL GPU Delegate output same result as TFLite CPU backend.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

One can use https://github.com/zldrobit/onnx_tflite_yolov3/tree/reproduce-opencl to reproduce
 result from CPU, OpenCL and OpenGLES GPU delegate, with argument `--delegate """"`, 
 `--delegate ""libtensorflowlite_gpu_delegate.so""` and `--delegate ""libtensorflowlite_gpu_gl.so""` respectively.
The model can be downloaded from https://drive.google.com/file/d/1iATViInSaPZWV7zH_YMAwMQK5XNDpdGl/view?usp=sharing
A pre-bulit docker can be downloaded by
```
docker pull zldrobit/cudagl:opencl
```
Clone the git repo, download the model to `weights/yolov3_coco.fp32.tflite`, and run `python3 tflite_detect.py`. The results will be generated in the `output` folder.

PS: I am unable to provide a Colab notebook, due to the configuration diffculty of OpenCL and OpenGL on Colab environment. `*.so` are based on Tensorflow tag v2.1.1, and I only add initilization code and clean code (Once I have time, I will publish this build process ASAP).

PPS: I cannot run the OpenGLES GPU delegate on Oneplus 6T, the most critical error message may be
```
E/libEGL: call to OpenGL ES API with no current context (logged once per thread)

```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40612,Correct data type for tf serving warmup file: tf_serving_warmup_requests,"```
""""""Generate Warmup requests.""""""
import tensorflow as tf
import requests
import base64
import numpy as np
import requests
from PIL import Image

from tensorflow.python.framework import tensor_util
from tensorflow_serving.apis import predict_pb2
from tensorflow_serving.apis import prediction_log_pb2

im_path = '/home/n/Documents/mask_rcnn/dataset/val/00.jpg'
img = np.array(Image.open(im_path))
x = np.array(Image.open(im_path))
image_data = x.tolist()
NUM_RECORDS = 2


def main():
    """"""Generate TFRecords for warming up.""""""
    with tf.io.TFRecordWriter(""tf_serving_warmup_requests"") as writer:
        predict_request = predict_pb2.PredictRequest()

        predict_request.model_spec.name = 'a_model'

        predict_request.model_spec.signature_name = 'serving_default'

        predict_request.inputs['image:0'].CopyFrom(
            tensor_util.make_tensor_proto(image_data))

        log = prediction_log_pb2.PredictionLog(
            predict_log=prediction_log_pb2.PredictLog(request=predict_request))

        for r in range(NUM_RECORDS):
            writer.write(log.SerializeToString())


if __name__ == ""__main__"":
    main()
```

This is file which generates tf_serving_warmup_requests,
however im getting an error from the server:

```
2020-06-19 13:16:46.659681: E tensorflow_serving/util/retrier.cc:37] Loading servable: {name: a version: 1} failed: Invalid argument: Expects arg[0] to be float but half is provided

```

Could you help to set correct format for data input ?"
40611,[TF: 2.2] failing to load .pb protobuf properly,"**System information**:

- OS Platform and Distribution: Linux Ubuntu 18.04

- TensorFlow installed source: source

- TensorFlow version: 2.2.0 stable

- Python version: python3

- Bazel version: using Bazelisk with Bazel 2.0.0 version as required from tf-2.2.0

- GCC/Compiler version (if compiling from source): GCC-8

- CUDA/cuDNN version: No CUDA (for the moment)

- Tensorflow compilation: `bazel --host_jvm_args=-Xmx30G build --jobs=8 --config=v2 --config=opt --copt=-O3 --copt=-m64 --copt=-march=native --verbose_failures //tensorflow:install_headers //tensorflow:tensorflow //tensorflow:tensorflow_cc //tensorflow:tensorflow_framework //tensorflow/tools/lib_package:libtensorflow`


**What I have done**:

I'm trying to load a protobuf graph saved with a python script to inference with C++ APIs.

The python script is:

```
#!/usr/bin/env python3

from __future__ import print_function
import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
import os, sys

tf.keras.backend.clear_session()

physical_devices = tf.config.experimental.list_physical_devices('GPU')
for dev in physical_devices:
  try:
    tf.config.experimental.set_memory_growth(dev, True)
    print(dev, ""SET MEMORY GROWTH"")
    #tf.config.set_logical_device_configuration(dev, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])
    print(tf.config.get_logical_device_configuration(dev))
  except:
    print(""Device config error"")
    sys.exit(1)


batch_size = 512
num_classes = 10
epochs = 50
data_augmentation = True

# The data, split between train and test sets:
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

# Convert class vectors to binary class matrices.
y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_test = tf.keras.utils.to_categorical(y_test, num_classes)

model = Sequential()
model.add(Conv2D(32, (3, 3), padding='same',
                 input_shape=x_train.shape[1:]))
model.add(Activation('relu'))
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), padding='same'))
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(1024))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(1024))
model.add(Activation('relu'))
model.add(Dropout(0.25))
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes))
model.add(Activation('softmax'))

# initiate RMSprop optimizer
opt = tf.keras.optimizers.Adam(learning_rate=0.001)

# Let's train the model using RMSprop
model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

print(model.summary())

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255.
x_test /= 255.

print(x_train.shape[0])

if not data_augmentation:
    print('Not using data augmentation.')
    model.fit(x_train, y_train,
              steps_per_epoch=((x_train.shape[0] // batch_size)),
              batch_size=batch_size,
              epochs=epochs,
              validation_data=(x_test, y_test),
              validation_steps=((x_test.shape[0] // batch_size)),
              shuffle=True)
else:
    print('Using real-time data augmentation.')
    # This will do preprocessing and realtime data augmentation:
    datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        zca_epsilon=1e-06,  # epsilon for ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        # randomly shift images horizontally (fraction of total width)
        width_shift_range=0.1,
        # randomly shift images vertically (fraction of total height)
        height_shift_range=0.1,
        shear_range=0.,  # set range for random shear
        zoom_range=0.,  # set range for random zoom
        channel_shift_range=0.,  # set range for random channel shifts
        # set mode for filling points outside the input boundaries
        fill_mode='nearest',
        cval=0.,  # value used for fill_mode = ""constant""
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False,  # randomly flip images
        # set rescaling factor (applied before any other transformation)
        rescale=None,
        # set function that will be applied on each input
        preprocessing_function=None,
        # image data format, either ""channels_first"" or ""channels_last""
        data_format=None,
        # fraction of images reserved for validation (strictly between 0 and 1)
        validation_split=0.0)

    # Compute quantities required for feature-wise normalization
    # (std, mean, and principal components if ZCA whitening is applied).
    datagen.fit(x_train)

    # Fit the model on the batches generated by datagen.flow().
    model.fit(datagen.flow(x_train, y_train,
                            batch_size=batch_size),
                        steps_per_epoch=((x_train.shape[0] // batch_size)),
                        epochs=epochs,
                        validation_steps=((x_test.shape[0] // batch_size)),
                        validation_data=(x_test, y_test),
                        shuffle=True)
print(""fitted"")

model.save(save_format='tf', filepath='../../graphs/test0', include_optimizer=True)
print(""saved"")

model1 = tf.keras.models.load_model('../../graphs/test0')
print(model1.summary())

print(""Done"")
```

The C++ code is:

```
#include <stdlib.h>

#include <fstream>
#include <iostream>
#include <string>
#include <vector>

#include ""class_name.h""
#include ""tensorflow/cc/ops/const_op.h""
#include ""tensorflow/cc/ops/standard_ops.h""
#include ""tensorflow/core/framework/tensor.h""
#include ""tensorflow/core/graph/default_device.h""
#include ""tensorflow/core/graph/graph_def_builder.h""
#include ""tensorflow/core/lib/core/errors.h""
#include ""tensorflow/core/lib/core/stringpiece.h""
#include ""tensorflow/core/lib/core/threadpool.h""
#include ""tensorflow/core/lib/io/path.h""
#include ""tensorflow/core/lib/strings/stringprintf.h""
#include ""tensorflow/core/platform/env.h""
#include ""tensorflow/core/platform/init_main.h""
#include ""tensorflow/core/platform/logging.h""
#include ""tensorflow/core/platform/types.h""
#include ""tensorflow/core/public/session.h""
#include ""tensorflow/core/util/command_line_flags.h""

using namespace tensorflow;
using tensorflow::Flag;
using tensorflow::Status;
using tensorflow::string;
using tensorflow::Tensor;

//Read the image file, apply appropriate decoding depending on type of image
int TensorFromFile(string filename, const int i_height, const int i_width, std::vector<Tensor>* o_tensors) {
  tensorflow::Status status;
  auto root = tensorflow::Scope::NewRootScope();
  using namespace ::tensorflow::ops;
  std::unique_ptr<tensorflow::Session> session(tensorflow::NewSession({}));
  tensorflow::GraphDef graph;

  auto reader = tensorflow::ops::ReadFile(root.WithOpName(""img_reader""), filename);
  const int channels = 1;
  tensorflow::Output imgreader;

  if (tensorflow::str_util::EndsWith(filename, "".png"")) {
    imgreader = DecodePng(root.WithOpName(""png_reader""), reader, DecodePng::Channels(channels));
  } else if (tensorflow::str_util::EndsWith(filename, "".gif"")) {
    imgreader = DecodeGif(root.WithOpName(""gif_reader""), reader);
  } else {
    imgreader = DecodeJpeg(root.WithOpName(""jpeg_reader""), reader, DecodeJpeg::Channels(channels));
  }

  auto f_caster = Cast(root.WithOpName(""float_caster""), imgreader, tensorflow::DT_FLOAT);
  ExpandDims(root.WithOpName(""output""), f_caster, 0);

  status = root.ToGraphDef(&graph);
  if (!status.ok()) {
    LOG(ERROR) << status.ToString();
    return -1;
  }

  status = session->Create(graph);
  if (!status.ok()) {
    LOG(ERROR) << status.ToString();
    return -1;
  }

  status = session->Run({}, {""output""}, {}, o_tensors);
  if (!status.ok()) {
    LOG(ERROR) << status.ToString();
    return -1;
  }

  return 0;
}

int main(int argc, char* argv[]) {
  using namespace ::tensorflow::ops;
  tensorflow::Status status;

  std::string delimiter = ""."";
  std::string ofilename;
  std::vector<Tensor> inputs;
  std::vector<Tensor> outputs;

  std::string graph_path = ""../../graphs/test0"";
  std::string image_path = ""../../graphs/test0.png"";

  std::string mdlpath(graph_path);
  std::string imgpath(image_path);
  int32 inputdim = 32;

  std::unique_ptr<tensorflow::Session> session(tensorflow::NewSession({}));
  tensorflow::GraphDef graph;

  LOG(INFO) << ""OK"";

  //read model file
  status = ReadBinaryProto(Env::Default(), mdlpath, &graph);
  if (!status.ok()) {
    std::cout << status.ToString() << ""\n"";
    return -1;
  }

  LOG(INFO) << ""STATUS: "" << status.ToString();
  LOG(INFO) << ""OK"";

  //add graph to scope
  status = session->Create(graph);
  if (!status.ok()) {
    std::cout << status.ToString() << ""\n"";
    return -1;
  }

  LOG(INFO) << status.ToString();
  LOG(INFO) << ""OK"";

  //Read input image, assuming to be a sqaure image
  if (TensorFromFile(imgpath, inputdim, inputdim, &inputs)) {
    LOG(ERROR) << ""Image reading failed""
               << ""\n"";
    return -1;
  }

  LOG(INFO) << ""OK L1"";

  std::cout << ""input dimension of the image: "" << inputs[0].DebugString() << std::endl;
  std::cout << ""v: "" << graph.version() << std::endl;
  std::cout << ""ns: "" << graph.node_size() << std::endl << std::endl;
  auto shape = graph.node().Get(0).attr().at(""shape"").shape();
  for (int i = 0; i < shape.dim_size(); i++) {
      std::cout << shape.dim(i).size()<<std::endl;
  }

  //get the appropriate input and out layer names from the graph/mode to execute
  auto inputlayer = graph.node(0).name();
  LOG(INFO) << ""OK A1"";
  auto outputlayer = graph.node(graph.node_size() - 1).name();
  LOG(INFO) << ""OK A2"";

  status = session->Run({{inputlayer, inputs[0]}}, {outputlayer}, {}, &outputs);
  if (!status.ok()) {
    LOG(ERROR) << status.ToString();
    return -1;
  }

  std::cout << ""Output dimension of the image"" << outputs[0].DebugString() << std::endl;

  //create filename
  ofilename.append(imgpath.substr(0, imgpath.find(delimiter)));
  ofilename.append(""_mask.png"");

  std::cout << ""output filename: "" << ofilename << std::endl;

  //Now write this to a image file
  //if (TensorToFile(ofilename, outputs, threshold)) return -1;

  session->Close();

  return 0;
}
```

And then I execute:

`LD_LIBRARY_PATH=""/opt/tf_cpp/lib"" ./test`

With output:

```
2020-06-19 14:13:51.120484: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3399905000 Hz
2020-06-19 14:13:51.120742: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561cd4f5fe20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-19 14:13:51.120755: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-19 14:13:51.120974: I /home/niccolo/Documents/CodeBlocks/Prova/main.cpp:95] OK
2020-06-19 14:13:51.121005: I /home/niccolo/Documents/CodeBlocks/Prova/main.cpp:104] STATUS: OK
2020-06-19 14:13:51.121010: I /home/niccolo/Documents/CodeBlocks/Prova/main.cpp:105] OK
2020-06-19 14:13:51.121016: I /home/niccolo/Documents/CodeBlocks/Prova/main.cpp:114] OK
2020-06-19 14:13:51.121020: I /home/niccolo/Documents/CodeBlocks/Prova/main.cpp:115] OK
2020-06-19 14:13:51.123531: I /home/niccolo/Documents/CodeBlocks/Prova/main.cpp:124] OK L1
input dimension of the image: Tensor<type: float shape: [1,32,32,1] values: [[[169][131][100]]]...>
v: 0
ns: 0

[libprotobuf FATAL /opt/tpt/tf_cpp/include/src/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: (index) < (current_size_): 
Aborted (core dumped)
```

I followed these guides and tutorials:

- https://medium.com/@hamedmp/exporting-trained-tensorflow-models-to-c-the-right-way-cf24b609d183

- https://medium.com/analytics-vidhya/deploying-tensorflow-2-1-as-c-c-executable-1d090845055c

- https://medium.com/@dibyajyoti_20397/building-an-inference-module-in-tensorflow-c-api-5cac2096c0ec

(I didn't find a good complete guide)

What could cause that error?

Thx in advance"
40609,Test set is empty for imdb.load_data() with low maxlen value,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): custom
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6

**Describe the current behavior**
With the current imdb.load_data(), the following results are seen for different values of maxlen.

```
load_data                          (len(x_train), len(x_test))
------------------------------------------------------------ 
imdb.load_data(maxlen=50)    -->    (1035, 0)
imdb.load_data(maxlen=100)   -->    (5736, 0)
imdb.load_data(maxlen=200)   -->    (25000, 3913)
imdb.load_data()             -->    (25000, 25000)
```

<b>Analysis:</b> We can observe that when maxlen is low, the number of test samples can be 0. This is because the train and test data is concatenated, then the samples with length > maxlen are removed, and the first 25,000 are considered as training data.   

**Describe the expected behavior**

The number of test samples should not be zero.

<b>Fix:</b>This can be fixed when data can be filtered first to remove the ones with length > maxlen, and then concatenate to process further. The following are the results after the fix.

```
load_data                              (len(x_train), len(x_test))
------------------------------------------------------------ 
imdb.load_data(maxlen=50)    -->    (477, 558)
imdb.load_data(maxlen=100)   -->    (2773, 2963)
imdb.load_data(maxlen=200)   -->    (14244, 14669)
imdb.load_data()             -->    (25000, 25000)
```

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
from tensorflow.keras.datasets import imdb
(x_train, _), (x_test, _) = imdb.load_data(maxlen=50)
print((len(x_train), len(x_test)))  # This gives (1035, 0)

(x_train, _), (x_test, _) = imdb.load_data(maxlen=100)
print((len(x_train), len(x_test)))  # This gives (5736, 0)

(x_train, _), (x_test, _) = imdb.load_data(maxlen=200)
print((len(x_train), len(x_test)))  # This gives (25000, 3913)
```"
40608,tensorflow.keras.layer.add() causes exception in to_json(),"
**System information**
- custom code (below)
- OS: Windows 10
- Tensorflow installed from binary
- Tensorflow version v2.2.0-rc4-8-g2b96f3662b 2.2.0. 
- Keras version 2.3.0-tf
- Python version 3.6
- Run from CPU

**Describe the current behavior**
to_json() causes exception in nest.pack_sequence_as()

**Describe the expected behavior**
to_json() should work!

**Standalone code to reproduce the issue**
""""""
        Keras/Tensorflow bug.
  Exception in to_json()/.../nest.pack_sequence_as().
  Change ""KL.add"" to ""tf.add_n"" and there is no problem

  Using Tensorflow 2.2.0
        Keras 2.3.0-tf
"""""" 
import tensorflow.keras.layers as KL
import tensorflow.keras.models as KM
import tensorflow as tf

Input=KL.Input(batch_shape=[2,2])
sk=[]
o1=KL.Dense(17,name='d1')(Input)
sk.append(o1)
o2=KL.Dense(17,name='d2')(o1)
sk.append(o2)
x1 = KL.add(sk,name='a1')
o3=KL.Dense(17,name='d3')(o2)
sk.append(o3)
x2 = KL.add(sk,name='a2')

m=KM.Model(inputs=[Input],outputs=[x1,x2])
m.summary()
junk = m.to_json()
"
40607,tflite model failed to prepare in inference ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.14
- Python version: 3.7
- Bazel version (if compiling from source):  0.28.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10
- GPU model and memory: P100 16VRAM

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
After obtaining a .pb model with export_tflite_ssd_graph.py im using TOCO to create a detect.tflite model. I cant run inference with this model or compile it for the TPU.

Im getting this error when running inference with detect.tflite 

> Traceback (most recent call last):
  File ""test_tflite.py"", line 33, in <module>
    main()
  File ""test_tflite.py"", line 21, in main
    interpreter.allocate_tensors() 
  File ""/usr/local/lib/python3.5/dist-packages/tflite_runtime/interpreter.py"", line 242, in allocate_tensors
    return self._interpreter.AllocateTensors()
  File ""/usr/local/lib/python3.5/dist-packages/tflite_runtime/interpreter_wrapper.py"", line 110, in AllocateTensors
    return _interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
RuntimeError: tensorflow/lite/kernels/kernel_util.cc:129 std::abs(input_product_scale - bias_scale) <= 1e-6 * std::min(input_product_scale, bias_scale) was not true.Node number 108 (CONV_2D) failed to prepare.

I suspect it involves using SIGMOID as a score converter. When i use SOFTMAX the model works fine.

I understand the difference between the two, but i suspect that the post-processing-op is not capable of handling num_classes > 2 when using sigmoid. 


**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40606,sparse_softmax_cross_entropy_with_logits wrong answer under XLA,"Related to [https://github.com/tensorflow/probability/issues/975](https://github.com/tensorflow/probability/issues/975)

## System spec

TF version: 2.3.0-dev20200618 (`tf-nightly`)
OS: Linux Mint 19.3, CUDA-10.1.

## Current behaviour

Under XLA compilation, `tf.nn.sparse_softmax_cross_entropy_with_logits ` returns `nan` if one or more `logits` are `-inf`.  In regular graph mode, `-0.0` is returned.

## Expected behaviour
The log_prob function above should return the cross entropy of obtaining labels `k` from logits `logits`, and be non-`nan` (`-inf` is okay) for valid values of the function parameters.  

**NB** expected behaviour occurs under TF2.2.0 (stock Colab).  Only the current dev build is affected. 

## Minimal working example

 [colab here](https://colab.research.google.com/drive/1OUwqDF_KU0aUo-NHq-HKtxUgYv0Szy-u?usp=sharing)
```python
probs = tf.constant([0, 1, 1], dtype=tf.int32)
logits = tf.math.log(probs)

@tf.function(autograph=False, experimental_compile=True)
def log_prob(k):                                                                                   
    lp = -tf.nn.sparse_softmax_cross_entropy_with_logits(labels=k, logits=logits)                                   
    return lp  
print(log_prob(1))  # Expected: -0.6931472, Actual: nan
```

"
40605,Dynamical Tensor (and EagerTensor) slice assignment,"**System information**
- TensorFlow version (you are using): 2.2
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

I would like to have slice assignment for Tensor objects in TensorFlow.
The code I would like to write is:

```python
import tensorflow as tf

a = tf.constant([1, 2, 4, 5, 7, 3, 2, 6,])
indices = tf.constant([3, 4], dtype=tf.int32)

a[indices] += 1
```

Of course it's a simplistic example and doesn't cover everything I want to do (I would use it in more complex functions not with constants), and I am happy to make it more complex if necessary.

Currently this code gives the error:
```
TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4], dtype=int32)>
```

**Will this change the current api? How?**

I guess this is a change of API since it introduces a new functionality.

**Who will benefit with this feature?**

A lot of people have been asking for this feature for example in this GitHub issues:
- https://github.com/tensorflow/tensorflow/issues/14132#issuecomment-483002522
- https://github.com/tensorflow/tensorflow/issues/33131

These issues have unfortunately been closed because some workarounds for specific use-cases have been found (ones where the slicing is fixed and you can use [masking](https://github.com/tensorflow/tensorflow/issues/14132#issuecomment-483002522) or [TensorArrays](https://github.com/tensorflow/tensorflow/issues/14132#issuecomment-487643287)).
Some other issues deal with `Variable`s which is not what I am talking about here. [Some workarounds do exist](https://stackoverflow.com/a/62202181/4332585) involving `Variable` but they seem hacky.

I will personally benefit from it, in the multiple places where I now use `tensor_scatter_nd_add` or `tensor_scatter_nd_update`, which is solution that always works but is very difficult to write and very slow:

- [for a wavelet-based neural network, called MWCNN](https://github.com/zaccharieramzi/tf-mwcnn/blob/master/mwcnn.py#L106-L110);
- [for non-uniform fast fourier transform](https://github.com/zaccharieramzi/tfkbnufft/blob/master/tfkbnufft/nufft/interp_functions.py#L151);
- [for sensitivity map extraction when doing MRI reconstruction with TensorFlow neural networks](https://github.com/zaccharieramzi/fastmri-reproducible-benchmark/blob/master/fastmri_recon/data/utils/multicoil/smap_extract.py#L27-L35).

**Any Other info.**

The `tensor_scatter_nd_*` alternative might seem like a viable solution, but it suffers from 2 drawbacks that I consider huge:
- It is very difficult to write. It is actually so difficult, I decided to make a package that would alleviate this difficulty by having the different slicing possibilities unit tested: [tf-slice-assign](https://github.com/zaccharieramzi/tf-slice-assign).
- It is very slow. I made a [benchmark notebook](https://colab.research.google.com/drive/1gEjha7h1mhQkFwULS9MAU0bWQfzfEALY?usp=sharing) vs `pytorch` for slice assignment add. You can see that on GPU, using `tensor_scatter_nd_add` is 10 times slower than slice assignment in `pytorch` and 20 times slower on CPU. For a practical example, it means that my `tfkbnufft` (for non-uniform fast fourier transform) package is 30 times slower than its [torch counterpart](https://github.com/mmuckley/torchkbnufft#computation-speed) which I translated. This currently removes the possibility of training neural networks using the non-uniform fourier transform in TensorFlow."
40604,Keras Checkpoint Callback's `mode` argument needs clearer documentation,"In the documentation for the ModelCheckpoint class, the argument `mode` is described as such:
> ... In `auto` mode, the direction is automatically inferred from the name of the monitored quantity.

Such a description leads to an overestimation of this module's inference capabilities! In my case, I was training a model with `monitor='val_auc'` and `mode='auto'`, believing that TF was setting smartly setting mode as `'max'` as one typically wants to maximize the AUC just like accuracy.
However, I quickly realized that the model was only checkpointing when the AUC was decreasing. I looked through the source code to find out why:
https://github.com/tensorflow/tensorflow/blob/c159f1599548428660c80dada924d69f269384a3/tensorflow/python/keras/callbacks.py#L1195
The algorithm sets mode as `'max'` only when the given metric string contained `'acc'` or when it started with `'fmeasure'` - everything else is set to `'min'`, including for `'val_auc'`.

In my opinion, this inference logic is extremely arbitrary. The string check of `'acc'`or `'fmeasure'` should be either directly mentioned in the documentation, or replaced all-together with a more capable algorithm. Another suggestion is to have a default optimization direction for each metric class and the ModelCheckpoint class can simply refer to that when `mode` is not set. Additionally, one could get rid of `'auto'` as an option since the optimization direction for every metric is clear and obvious from the practitioner's point of view."
40603,cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): tensorflow-gpu 2.0.0 from pip
- TensorFlow version (use command below): tensorflow-gpu 2.0.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: 1650, 4 gb

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

when using tf.test.is_gpu_available()
it shows error like this 
cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.

**Describe the expected behavior**
True

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40600,Non-GPU tensorflow:1.15.0 docker image fails when it can't find CUDA,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): *Official tensorflow docker image (`4.19.76-linuxkit`...?), running in Docker Desktop on Windows 10*
- TensorFlow installed from (source or binary): *docker image `tensorflow/tensorflow:1.15.0`*
- TensorFlow version: *1.15.0*
- Python version: *2.7.15+*
- Installed using virtualenv? pip? conda?: *docker*
- CUDA/cuDNN version: *none*
- GPU model and memory: *host has NVIDIA card, but not applicable to docker guest*

**Describe the problem**

I am attempting to run the CPU-version of tensorflow with the object_detection pets tutorial. I'm trying to do it using Docker Desktop for Windows, but using the CPU since nvidia-docker doesn't support windows. But when I run a simple example it gives me errors about failing to find CUDA. I'm not sure if these are fatal errors or ignorable warnings. The pets object detection job I'm trying to run stops shortly after these errors. I'm using the official tensorflow docker image `tensorflow/tensorflow:1.15.0`.

I've also honed down a minimal example:

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Dockerfile:
```
FROM tensorflow/tensorflow:1.15.0
COPY test-tf.py /tensorflow/test-tf.py
WORKDIR /tensorflow
```
test-tf.py:
```
#!/usr/bin/env python

import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
```
Steps:
1. `docker build --tag detect-tf-generic .`
2. `docker run --rm -it --privileged -p 6006:6006 detect-tf-generic`
3. `./test-tf.py`

Output:
```
WARNING:tensorflow:From ./test-tf.py:5: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-06-19 00:48:56.905823: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-06-19 00:48:56.905858: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)
2020-06-19 00:48:56.905987: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c0e8a9783c35): /proc/driver/nvidia/version does not exist
2020-06-19 00:48:56.906459: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-19 00:48:56.913014: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1992000000 Hz
2020-06-19 00:48:56.913329: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5583d4015850 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-19 00:48:56.913358: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
```
I can't tell if this is a fatal error that I need to fix or just a warning. As mentioned my object detection job completes early a few output lines after this. It doesn't seem like it should be looking for CUDA at all, but what do I know."
40595,tf.signal.rfft(2d/3d) documentation refers `Tcomplex` and `input` as arguments.,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/signal/rfft

https://www.tensorflow.org/api_docs/python/tf/signal/rfft2d

https://www.tensorflow.org/api_docs/python/tf/signal/rfft3d

## Description of issue (what needs changing):

### Clear description

In the `Args` section, there are inputs `input` and `Tcomplex`. `Treal` no longer exist, and `input` should be `input_tensor`.

Running code

~~~python
tf.signal.rfft(1, Tcomplex=tf.complex64)
~~~

got exception:

~~~python
TypeError: _rfft() got an unexpected keyword argument 'Tcomplex'
~~~

### Parameters defined

Yes

### Returns defined

Yes

### Raises listed and defined

No

## System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.2.0-rc3
- **Python version**: 3.8.2


## Related Issue:
#39520"
40594,tf.signal.irfft(2d/3d) documentation refers `input` and `Treal` as arguments.,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/signal/irfft

https://www.tensorflow.org/api_docs/python/tf/signal/irfft2d

https://www.tensorflow.org/api_docs/python/tf/signal/irfft3d

## Description of issue (what needs changing):

### Clear description

In the `Args` section, there are inputs `input` and `Treal`. `Treal` no longer exist, and `input` should be `input_tensor`.

Running code:

~~~python
tf.signal.irfft(1, Treal=tf.float32) 
~~~

got exception:

~~~python
TypeError: _irfft() got an unexpected keyword argument 'Treal'
~~~

And if run code:

~~~python
tf.signal.irfft(input=1)
~~~

got exception:

~~~python
TypeError: _irfft() got an unexpected keyword argument 'input'
~~~

### Parameters defined

Yes

### Returns defined

Yes

### Raises listed and defined

No

## System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.2.0-rc3
- **Python version**: 3.8.2
"
40593,Unclear rank/dimension dependency of `weights` in  `sigmoid_cross_entropy` documentation,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/compat/v1/losses/sigmoid_cross_entropy

## Description of issue (what needs changing):

### Clear description

Unclear rank dependency of input `weights`. According to the document, `weights` could have the same rank as `labels`, and must be broadcastable to `labels`, but it is unclear what `labels` is. 

### Parameters defined

Yes

### Returns defined

Yes

### Raises listed and defined

Yes


## System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.2.0-rc3
- **Python version**: 3.8.2"
40592,`tf.nn.swish` documentation refers `name` as an argument,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/nn/swish

## Description of issue (what needs changing):

### Clear description

In the ""Args"" section, there is an input ` name`, but it is not in the signature, and the function doesn't accept the argument.

Running code:

~~~python
tf.nn.swish(1, name=None)
~~~

got exception:

~~~python
TypeError: swish() got an unexpected keyword argument 'name'
~~~

### Parameters defined

Yes

### Returns defined

Yes

### Raises listed and defined

No

## System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.2.0-rc3
- **Python version**: 3.8.2
"
40591,"bazel mirror tar gz 404 warning, and build fails","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version: 2.2.0, installed by mediapipe
- Python version: 3.8.3
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 3.3.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

Trying to build a mediapipe target:
```bash
bazel run mediapipe/examples/desktop/multi_hand_tracking:multi_hand_tracking_cpu 
```

I get:

 ```
Loading: 
Loading: 0 packages loaded  
WARNING: Download from https://mirror.bazel.build/github.com/tensorflow/tensorflow/archive/7c09d15f9fcc14343343c247ebf5b8e0afe3e4aa.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found     
WARNING: Download from http://mirror.tensorflow.org/github.com/bazelbuild/rules_closure/archive/cf1e44edb908e9616030cc83d085989b8e6cd6df.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found   

Analyzing: target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_tracking_cpu (0 packages loaded, 0 targets configured)  
INFO: Repository local_execution_config_python instantiated at:  
no stack (--record_rule_instantiation_callstack not enabled)     
Repository rule local_python_configure defined at:        
C:/users/amit/_bazel_amit/j6xr7hh5/external/org_tensorflow/third_party/py/python_configure.bzl:275:41: in                                                                                                                                  
ERROR: An error occurred during the fetch of repository 'local_execution_config_python':          Traceback (most recent call last):                     
File ""C:/users/amit/_bazel_amit/j6xr7hh5/external/org_tensorflow/third_party/py/python_configure.bzl"", 
line 208                                                                                              
get_python_bin(repository_ctx)                                                              
File ""C:/users/amit/_bazel_amit/j6xr7hh5/external/org_tensorflow/third_party/remote_config/common.bzl"", line 44, in 
get_python_bin                                                                                                    
which(repository_ctx, ""python"")           
File ""C:/users/amit/_bazel_amit/j6xr7hh5/external/org_tensorflow/third_party/remote_config/common.bzl"", line 27, in which  execute(repository_ctx, <1 more arguments>)            
File ""C:/users/amit/_bazel_amit/j6xr7hh5/external/org_tensorflow/third_party/remote_config/common.bzl"", line 208, in execute 
                                  fail(<1 more arguments>)`
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
conda create --name=test python=3
conda activate test
git clone https://github.com/google/mediapipe.git
cd mediapipe
bazel run mediapipe/examples/desktop/multi_hand_tracking:multi_hand_tracking_cpu
```"
40590,Cant install tensorflow with gpu ,"ImportError                               Traceback (most recent call last)
~\Anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59 

~\Anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~\Anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~\Anaconda3\envs\deeplearning\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

~\Anaconda3\envs\deeplearning\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-64156d691fe5> in <module>
----> 1 import tensorflow as tf

~\Anaconda3\envs\deeplearning\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\Anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\__init__.py in <module>
     48 import numpy as np
     49 
---> 50 from tensorflow.python import pywrap_tensorflow
     51 
     52 # Protocol buffers

~\Anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     67 for some common reasons and solutions.  Include the entire stack trace
     68 above this error message when asking for help."""""" % traceback.format_exc()
---> 69   raise ImportError(msg)
     70 
     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\mahmo\Anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\mahmo\Anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\mahmo\Anaconda3\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\mahmo\Anaconda3\envs\deeplearning\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\mahmo\Anaconda3\envs\deeplearning\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
"
40589,"AutoGraph ""could not transform"" warning when code contains a multi-line string with backslashes","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution: Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.3
- CUDA/cuDNN version: 10.1/7
- GPU model and memory: Nvidia GeForce RTX 2080Ti

**Describe the current behavior**
AutoGraph warning appears if a custom keras layer's `call` method code contains a multiline string joined by the backslash. If a multiline string is joined using brackets, however, no warning appears. Does not seem to influence calculations in any way, but a fun bug to encounter

```
WARNING:tensorflow:AutoGraph could not transform <bound method MyLayer.call of <__main__.MyLayer object at 0x0000XXXXXXXXXXXX>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x0000XXXXXXXXXXXX>, <gast.gast.Return object at 0x0000XXXXXXXXXXXX>]
WARNING: AutoGraph could not transform <bound method MyLayer.call of <__main__.MyLayer object at 0x0000XXXXXXXXXXXX>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x0000XXXXXXXXXXXX>, <gast.gast.Return object at 0x0000XXXXXXXXXXXX>]
```

**Describe the expected behavior**
No warnings appears

**Standalone code to reproduce the issue**
```
import tensorflow as tf
tf.autograph.set_verbosity(10, alsologtostdout = True)

from tensorflow.keras.layers import Layer, Input

class SlashPhobic(Layer):

    def call(self, inputs):
        s = ""foo"" \
            ""bar""
        print(s)
        return inputs

x = Input(shape = (1,))
y = SlashPhobic()(x)
```

Autograph log:

```
Converted call: <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>>
    args: (<tf.Tensor 'input_1:0' shape=(None, 1) dtype=float32>,)
    kwargs: {}

Not whitelisted: <method-wrapper '__call__' of method object at 0x0000XXXXXXXXXXXX>: default rule
Not whitelisted: <class '__main__.SlashPhobic'>: default rule
Not whitelisted: <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>>: default rule
Entity <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>> is not cached for key <code object call at 0x0000XXXXXXXXXXXX, file "".\phobic.py"", line 8> subkey (<tensorfl
ow.python.autograph.core.converter.ConversionOptions object at 0x0000XXXXXXXXXXXX>, frozenset())
Converting <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>>
Error transforming entity <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>>
Traceback (most recent call last):
  File ""D:\Miniconda3\lib\site-packages\tensorflow_core\python\autograph\impl\api.py"", line 526, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""D:\Miniconda3\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 326, in convert
    free_nonglobal_var_names)
  File ""D:\Miniconda3\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 240, in _convert_with_cache
    entity, program_ctx)
  File ""D:\Miniconda3\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 475, in convert_entity_to_ast
    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
  File ""D:\Miniconda3\lib\site-packages\tensorflow_core\python\autograph\impl\conversion.py"", line 634, in convert_func_to_ast
    node, source = parser.parse_entity(f, future_features=future_features)
  File ""D:\Miniconda3\lib\site-packages\tensorflow_core\python\autograph\pyct\parser.py"", line 207, in parse_entity
    return _attempt_to_parse_normal_source(source, future_features)
  File ""D:\Miniconda3\lib\site-packages\tensorflow_core\python\autograph\pyct\parser.py"", line 111, in _attempt_to_parse_normal_source
    return parse_str(source, preamble_len=len(future_features)), source
  File ""D:\Miniconda3\lib\site-packages\tensorflow_core\python\autograph\pyct\parser.py"", line 230, in parse_str
    raise ValueError('expected exactly one node node, found {}'.format(nodes))
ValueError: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x0000XXXXXXXXXXXX>, <gast.gast.Return object at 0x0000XXXXXXXXXXXX>]
WARNING:tensorflow:AutoGraph could not transform <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x0000XXXXXXXXXXXX>, <gast.gast.Return object at 0x0000XXXXXXXXXXXX>]
WARNING: AutoGraph could not transform <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x0000XXXXXXXXXXXX>, <gast.gast.Return object at 0x0000XXXXXXXXXXXX>]
```"
40588,Iterator.make_initializer returns None,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: 10.2 / 7.6
- GPU model and memory: GeForce RTX 2080 / 12 Gb


**Describe the current behavior**
I'm trying to run a code written in tensorflow 1.1 using tensorflow 2.2. I already run the `tf_upgrade_v2` which changed most of the unsupported things. However, while creating an iterator
```
train_data = tf.data.Dataset.from_generator(gen_function, gen_types, gen_shapes)
train_data = train_data.map(map_func=map_func, num_parallel_calls=self.num_threads)
# Prefetch data
train_data = train_data.prefetch(10)
# create a iterator of the correct shape and type
iterator = tf.compat.v1.data.Iterator.from_structure(tf.compat.v1.data.get_output_types(train_data), tf.compat.v1.data.get_output_shapes(train_data))
```
and when I initialize it:
```
train_init_op = iter.make_initializer(train_data)
```
The initalization operator `train_init_op` is `None`. and I got the following error when i run `sess.run(train_init_op)`
:
```
File ""/home/pvnieo/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 958, in run
    run_metadata_ptr)
  File ""/home/pvnieo/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1166, in _run
    self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)
  File ""/home/pvnieo/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 477, in __init__
    self._fetch_mapper = _FetchMapper.for_fetch(fetches)
  File ""/home/pvnieo/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 263, in for_fetch
    (fetch, type(fetch)))
TypeError: Fetch argument None has invalid type <class 'NoneType'>
```

How can I solve this issue?"
40586,Distributed training problem,"I am studying the principle of distributed training of TensorFlow, but I cannot find the source code related to gradient communication. I want to know where can I find the source code of uploaded gradient to PS."
40584,Tensorflow 2.2.0 and Tensorflow Probability 0.10.0 import error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.2.0
- Python version: 3.8.2
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):  3.1.0
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: n.a.
- GPU model and memory: n.a.



Tensorflow version 2.2.0 compiled from source following the steps detailed in the [official documentation](https://www.tensorflow.org/install/source#cpu-only_2) doesn't work with any version of Tensorflow Probability higher than 0.7.  
Tensorflow (CPU ONLY) is compiled using the Docker environment and works just fine by itself but when importing Tensorflow Probability I get the following error:  
~~~
>>> import tensorflow_probability as tfp
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/fabio/Downloads/tf-prob/.pyenv/lib64/python3.8/site-packages/tensorflow_probability/__init__.py"", line 76, in <module>
    from tensorflow_probability.python import *  # pylint: disable=wildcard-import
  File ""/home/fabio/Downloads/tf-prob/.pyenv/lib64/python3.8/site-packages/tensorflow_probability/python/__init__.py"", line 24, in <module>
    from tensorflow_probability.python import experimental
  File ""/home/fabio/Downloads/tf-prob/.pyenv/lib64/python3.8/site-packages/tensorflow_probability/python/experimental/__init__.py"", line 34, in <module>
    from tensorflow_probability.python.experimental import auto_batching
  File ""/home/fabio/Downloads/tf-prob/.pyenv/lib64/python3.8/site-packages/tensorflow_probability/python/experimental/auto_batching/__init__.py"", line 24, in <module>
    from tensorflow_probability.python.experimental.auto_batching import frontend
  File ""/home/fabio/Downloads/tf-prob/.pyenv/lib64/python3.8/site-packages/tensorflow_probability/python/experimental/auto_batching/frontend.py"", line 45, in <module>
    from tensorflow.python.autograph.core import naming
ImportError: cannot import name 'naming' from 'tensorflow.python.autograph.core' (/home/fabio/Downloads/tf-prob/.pyenv/lib64/python3.8/site-packages/tensorflow/python/autograph/core/__init__.py)
~~~
I am not sure if it is a bug in Tensorflow Probability or if there is something wrong with my build of Tensorflow."
40580,tf.image.flip_left_right and tf.image.flip_up_down incorrectly assumes rank-3 image and flips along the wrong axis,"## System information
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, see below
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.0
- Python version: 3.7

You can also obtain the TensorFlow version with:
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
`unknown 2.0.0`

## Describe the current behavior

**Setup:** Under some circumstances (in my case, when a `tf.Tensor` is inside a `tf.data.Dataset` and it is being conditionally transformed inside a `tf.data.Dataset.map()` call), the shape of a `Tensor` becomes unknown (this may be expected behavior still).

**Behavior**: When `tf.image.flip_left_right` is applied to this `tf.Tensor`, the function incorrectly assumes a rank-3 shape and flips the image along the wrong axis.

## Describe the expected behavior

When `tf.image.flip_left_right` is applied to the `tf.Tensor`, the function does not assume a rank-3 shape and flips the image along the correct axis.

## Standalone code to reproduce the issue

```py
import tensorflow as tf

def correct_image_flip_left_right(image):
    return tf.reverse(image, axis=[-2])

PATCH_TF = False  # Change this to True to fix the bug
if PATCH_TF:
    tf.image.flip_left_right = correct_image_flip_left_right

image_input = tf.convert_to_tensor([
    # batch: 0
    [
        # y: 0
        [[0, 1, 2], [3, 4, 5]],  # x=0,1 channels=0,1,2
        # y: 1
        [[6, 7, 8], [9, 10, 11]],  # x=0,1 channels=0,1,2
    ],
])

image_flipped_directly = tf.image.flip_left_right(image_input)

expected_output = tf.convert_to_tensor([
    # batch: 0
    [
        # y: 0
        [[3, 4, 5], [0, 1, 2]],  # x=0,1 channels=0,1,2
        # y: 1
        [[9, 10, 11], [6, 7, 8]],  # x=0,1 channels=0,1,2
    ],
])

tf.assert_equal(image_flipped_directly, expected_output)
print(""Directly calling tf.image.flip_left_right works as exected."")

def generator():  yield image_input

dataset = tf.data.Dataset.from_generator(generator, output_types=tf.int32)

def flip_it(image, do_flip: bool):
    if do_flip:
        return tf.image.flip_left_right(image)
    else:
        return image

dataset = dataset.map(lambda image: flip_it(image, tf.constant(True)))

image_flipped_via_dataset_map = next(iter(dataset))

print(""image_flipped_via_dataset_map:"")
print(image_flipped_via_dataset_map)
print(""expected_output:"")
print(expected_output)

tf.assert_equal(image_flipped_via_dataset_map, expected_output)
# This assertion fails even though it shouldn't unless PATCH_TF is True

print(""If you can see this message, image_flipped_via_dataset_map == expected_output"")
```

Output:
```
> python .\tf_image_flip.py
2020-06-18 17:10:08.875275: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
Directly calling tf.image.flip_left_right works as exected.
image_flipped_via_dataset_map:
tf.Tensor(
[[[[ 6  7  8]
   [ 9 10 11]]

  [[ 0  1  2]
   [ 3  4  5]]]], shape=(1, 2, 2, 3), dtype=int32)
expected_output:
tf.Tensor(
[[[[ 3  4  5]
   [ 0  1  2]]

  [[ 9 10 11]
   [ 6  7  8]]]], shape=(1, 2, 2, 3), dtype=int32)
Traceback (most recent call last):
  File "".\tf_image_flip.py"", line 54, in <module>
    tf.assert_equal(image_flipped_via_dataset_map, expected_output)
  File ""C:\Users\uib58003\AppData\Local\Continuum\miniconda3\lib\site-packages\tensorflow_core\python\ops\check_ops.py"", line 456, in assert_equal_v2
    return assert_equal(x=x, y=y, summarize=summarize, message=message, name=name)
  File ""C:\Users\uib58003\AppData\Local\Continuum\miniconda3\lib\site-packages\tensorflow_core\python\ops\check_ops.py"", line 546, in assert_equal
    (message or '', index_and_values_str, summary_msg)))
tensorflow.python.framework.errors_impl.InvalidArgumentError:
Condition x == y did not hold.
Indices of first 3 different values:
[[0 0 0 0]
 [0 0 0 1]
 [0 0 0 2]]
Corresponding x values:
[6 7 8]
Corresponding y values:
[3 4 5]
First 3 elements of x:
[6 7 8]
First 3 elements of y:
[3 4 5]
```

## Other info / logs

The bug is in `tensorflow_core.ops.image_ops_impl._flip`, called by `image_ops_impl.flip_left_right`:
https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/image_ops_impl.py#L537-L546

Tensorflow should not assume based on `shape.ndims is None` that the image is 3-dimensional and it should not call `fix_image_flip_shape` which further builds on this incorrect assumption:
https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/image_ops_impl.py#L315-L320

This causes the flipping to happen along the wrong axis.

The `flip_left_right` function should be implemented by `array_ops.reverse(image, axis=[-2])` which always flips along the correct axis for any number of ranks as long as the dimensions end in `..., HEIGHT, WIDTH, CHANNELS]`.

The same bug probably appears in `tf.image.flip_up_down` for the same reason based on looking at the source code, but I haven't tested this. That function should always apply `tf.reverse(image, axis=[-3])` for the same reason as before."
40577,tensor scatter nd add doesn't support complex64 in tf 2.3-dev,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.3-dev
- Python version: 3.6.8
- CUDA/cuDNN version: 10.1
- GPU model and memory: Quadro P5000, 16Gb


**Describe the current behavior**

When using `tf.tensor_scatter_nd_add` with complex data, I have the following error:

```
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-4-35a6b23ae93f> in <module>
----> 1 tf.tensor_scatter_nd_add(tf.transpose(to_update), arr_ind, updates)

~/workspace/tfkbnufft/venv/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py in tensor_scatter_add(tensor, indices, updates, name)
  10686       return _result
  10687     except _core._NotOkStatusException as e:
> 10688       _ops.raise_from_not_ok_status(e, name)
  10689     except _core._FallbackException:
  10690       pass

~/workspace/tfkbnufft/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6841   message = e.message + ("" name: "" + name if name is not None else """")
   6842   # pylint: disable=protected-access
-> 6843   six.raise_from(core._status_to_exception(e.code, message), None)
   6844   # pylint: enable=protected-access
   6845 

~/workspace/tfkbnufft/venv/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: Unsupported dtype: complex64 [Op:TensorScatterAdd]
```

**Describe the expected behavior**

`tf.tensor_scatter_nd_add` should work with complex data.

**Standalone code to reproduce the issue**

```python
import tensorflow as tf 
to_update = tf.ones([1, 640000], dtype=tf.complex64)
arr_ind = tf.range(324000)[:, None]
updates = tf.cast(tf.random.normal([324000, 1], dtype=tf.float32), tf.complex64)
tf.tensor_scatter_nd_add(tf.transpose(to_update), arr_ind, updates)
```

[Colab link](https://colab.research.google.com/drive/1omAKl8vcqd2TBVbXEnVGvey8Urmcp-kH?usp=sharing).

**Other info / logs** 

This problem only appears for tf-nightly and on GPU.
"
40576,Trying to dynamically change weighted connections between training examples,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
I would like to be able to change the routing of the weighted connections between training examples. I have developed the theory for a type of neural network that takes in as input a random vector of ints between 0 and 10 (and maps it to an image). then takes these ints and after adding 200 multiples of 10 for each dimension, i use this result as the index in tf.gather with the default weight matrix which is of shape (10,200). The reason we add multiples of 200 is because the first hidden layer will have 200 neurons and we want each possible number in the input to come with its own weighted connections. So between examples we will be loading different weighted connections into the weight matrix of the layer dependant on the input.

if two dimesnions happen to have the same numebr they will both load in the same connections in their respective dimensions. On top of this, to make each entry in the dimension unique we employ a circulant routing where the first neuron enters its entries in root position, while the next one rotates them by one, then the next one rotates them by 2 and so on. So a 2 in the nth position will have a different effect on the next layer from a 2 in the nth +1 position.

Additionally, Once the input layer is arranged dynamically we mirror the form within other layers that inherit from the input layer. So if there is a 3 in the nth position of the first layer. The next layer will have ""3"" weighted connections in its nth position. Note that these are not the same weighted connections that the first layer had , but a corresponding vector of weighted connections that go with it , but for the next layer. (we could not use the input into that layer to order its connections because tf._gather requires indices that are ints).

i would also like to somehow do this for convolutional layers too if the logic permits.

Here is some code that attempted to do all of this and a link to a colab file.


**Will this change the current api? How?**
I am not sure if it will because i have been trying to do it with no success

**Who will benefit with this feature?**

this is a new generative algorithm that will benefit the AI community in general.

**Any Other info.**
https://colab.research.google.com/drive/1mWAQH1jJMFJ0NTKrqLxzet47aUXm9wWz?usp=sharing"
40575,TF2.2.0 model.train&evaluate may have a display bug ,"Please make sure that this may be a bug. 
**System information**

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 
No. This is the code from (https://www.tensorflow.org/beta/tutorials/quickstart/beginner)

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab and mac OS Mojave  10.14.4

- TensorFlow version (use command below): pip install tensorflow==2.2.0

- Python version: 3.6.9 

**Describe the current behavior**
There is a difference of result between TF2.1.0 and TF2.20 version in model.train  & model.evaluate sections.  
In TF2.1.0, result of model.train show 60000/60000.it is normal.
But in TF2.2.0, this show 1875/1875  . Despite the same shape of train data.

In case of evaluate is same.
In TF2.1.0, result of model.evaluate show 10000/10000.
But in TF2.2.0, this show 313/313.

This is may be bug.But it's also may normal.
So please check the problem.

**Source code / logs**

```
#install Tensorflow in Colab
!pip install tensorflow==2.2.0
import tensorflow as tf
print(tf.__version__)

#RUN the code 
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
print(""fit"") 
model.fit(x_train, y_train, epochs=1)
print(""evaluate"")
model.evaluate(x_test,  y_test)
```

[out]
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
fit
1875/1875 [==============================] - 3s 2ms/step - loss: 0.2957 - accuracy: 0.9136
evaluate
313/313 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9594
[0.13421817123889923, 0.9593999981880188]



I uploaded to [Colab](https://colab.research.google.com/drive/1MxqnCskd43a9-cr3Gjv6Oaby04OzyDcc?usp=sharing )
This ipynb file uses the TF2.1.0 and TF2.2.0. You can see the bug on TF 2.2.0."
40574,LSTM example for GPU delegate ,"Hello, 
I am trying to run my model in android GPU using TF lite and gpu delegate.
But I faced this ""UNIDIRECTIONAL SEQUENCE LSTM: Operation is not supported"".
From the document ""https://www.tensorflow.org/lite/performance/gpu_advanced"", LSTM v2 is supported now. 
All examples in tensorflow git are not using this LSTM.
Is there any example for ""LSTM v2 (Basic LSTM only)"" ?
  "
40573,Keras Mixed Precision,"
**System information**
- Linux Ubuntu 18
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.14
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10.0
- GPU model and memory: 2080 Ti



**Describe the problem**
I am trying to run a simple cnn on Tensor Cores of 2080 Ti. Using the following
from tensorflow.keras.mixed_precision import experimental as mixed_precision
policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_policy(policy)
Running into this error
![Screenshot from 2020-06-16 16-03-04](https://user-images.githubusercontent.com/66824777/85017922-e93dd180-b189-11ea-90bd-759f2021b451.png)

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40572,Unable to create SavedModel from keras model,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.15.4
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 2.2.0rc3
- Python version: 3.7

**Describe the current behavior**

Running model.save(""model"") creates a standalone file named ""model""

**Describe the expected behavior**

Running model.save(""model"") creates a directory named model that contains assets, saved_model.pb, and variables

**Standalone code to reproduce the issue**
Link to model: https://www.dropbox.com/s/6ginejkhna1sic8/unet_70.h5?dl=0

```
import segmentation_models as sm
from keras.models import load_model
from tensorflow import keras
import tensorflow as tf


path_to_model = ""models/unet_70.h5""
loss = sm.losses.binary_focal_dice_loss
model = load_model(path_to_model, custom_objects={'binary_focal_loss_plus_dice_loss': loss})

model.save('model')

```
"
40571,The GPUs hang when split a log_prob and gradient computation across a number of GPU devices,"**System information**

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Red Hat - Enterprise Linux Server 7.5 (Maipo)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.2.0-0-g2b96f36 2.2.0
- Python version: 3.7.4
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: 10.1/7.6.4
- GPU model and memory: 4 x GPU NVIDIA V100 (Volta) with 16GB HBM2.

**Describe the current behavior**

Trying to demonstrate how to split a log_prob and gradient computation across a number of GPU devices, the GPUs hang. 

**Describe the expected behavior**


Run inference as expected in multi-GPU environment.

**Standalone code to reproduce the issue**

The attached files are based on the [notebook](https://colab.research.google.com/github/tensorflow/probability/blob/master/discussion/examples/cross_gpu_logprob.ipynb#scrollTo=b4RG2YJQdHGA) shared by @brianwa84 We have not setup logical GPUs as he did, but we have tried to use the 4 physical GPUs in the machine.  

This file hangs

```python 
#!/apps/PYTHON/3.7.4_ML/bin/python 

import sys
import numpy as np
import tensorflow as tf
import tensorflow_probability as tfp


def main():
    tfb, tfd = tfp.bijectors, tfp.distributions

    physical_gpus = tf.config.experimental.list_physical_devices('GPU')
    print(physical_gpus)

#    tf.config.experimental.set_virtual_device_configuration(
#        physical_gpus[0],
#        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)] * 2)
#    tf.config.experimental.set_virtual_device_configuration(
#        physical_gpus[1],
#        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)] * 2)
#    gpus = tf.config.list_logical_devices('GPU')
#    print(gpus)

#st = tf.distribute.MirroredStrategy(devices=tf.config.list_logical_devices('GPU'))
    st = tf.distribute.MirroredStrategy()
    print(st.extended.worker_devices)
    ndim = 3
    
    def model():
      Root = tfd.JointDistributionCoroutine.Root
      loc = yield Root(tfb.Shift(.5)(tfd.MultivariateNormalDiag(loc=tf.zeros([ndim]))))
      scale_tril = yield Root(tfb.FillScaleTriL()(tfd.MultivariateNormalDiag(loc=tf.zeros([ndim * (ndim + 1) // 2]))))
      yield tfd.MultivariateNormalTriL(loc=loc, scale_tril=scale_tril)
    
    dist = tfd.JointDistributionCoroutine(model)
    tf.random.set_seed(1)
    loc, scale_tril, _ = dist.sample(seed=2)
    
    samples = dist.sample(value=([loc] * 1024, scale_tril, None), seed=3)[2]
    samples = tf.round(samples * 1000) / 1000
    for dim in reversed(range(ndim)):
      samples = tf.gather(samples, tf.argsort(samples[:,dim]))
    
    print(samples)
    
    def dataset_fn(ctx):
      batch_size = ctx.get_per_replica_batch_size(len(samples))
      d = tf.data.Dataset.from_tensor_slices(samples).batch(batch_size)
      return d.shard(ctx.num_input_pipelines, ctx.input_pipeline_id)
    
    ds = st.experimental_distribute_datasets_from_function(dataset_fn)
    
    observations = next(iter(ds))
    print(observations)

    def log_prob_and_grad(loc, scale_tril, observations):
      ctx = tf.distribute.get_replica_context()
      with tf.GradientTape() as tape:
        tape.watch((loc, scale_tril))
        lp = tf.reduce_sum(dist.log_prob(loc, scale_tril, observations)) / len(samples)
      grad = tape.gradient(lp, (loc, scale_tril))
      return ctx.all_reduce('sum', lp), [ctx.all_reduce('sum', g) for g in grad]
    
    @tf.custom_gradient
    def target_log_prob(loc, scale_tril):
      lp, grads = st.experimental_run_v2(log_prob_and_grad, (loc, scale_tril, observations))
      return lp.values[0], lambda grad_lp: [grad_lp * g.values[0] for g in grads]
    
    singleton_vals = tfp.math.value_and_gradient(target_log_prob, (loc, scale_tril))
    
    kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob, step_size=.35, num_leapfrog_steps=2)
    kernel = tfp.mcmc.TransformedTransitionKernel(kernel, bijector=[tfb.Identity(), tfb.FillScaleTriL()])
    
    @tf.function(autograph=False)
    def sample_chain():
      return tfp.mcmc.sample_chain(
          num_results=200, num_burnin_steps=100,
          current_state=[tf.ones_like(loc), tf.linalg.eye(scale_tril.shape[-1])], 
          kernel=kernel, trace_fn=lambda _, kr: kr.inner_results.is_accepted)
    samps, is_accepted = sample_chain()
    
    print(f'accept rate: {np.mean(is_accepted)}')
    print(f'ess: {tfp.mcmc.effective_sample_size(samps)}')
    
    print(tf.reduce_mean(samps[0], axis=0))

if __name__ == ""__main__"":
    sys.exit(main())
```

In order to run previous file in a machine with multiple GPUs we use the following batch job 

```
#!/bin/bash 
#SBATCH --job-name='test2_cross_gpu' 
#SBATCH --qos=debug
# 
#SBATCH --nodes=1 
#SBATCH --ntasks=1 
#SBATCH --cpus-per-task=80 
#SBATCH --gres=gpu:2 
#SBATCH --time=00:05:00 
#------- I/O ------- 
#SBATCH -D . 
#SBATCH --output=test2_cross_gpu_%j.out 
#SBATCH --error=test2_cross_gpu_%j.err 
#------- modules ------- 
module purge 
module load gcc/8.3.0 cuda/10.1 cudnn/7.6.4 nccl/2.4.8 tensorrt/6.0.1 openmpi/4.0.1 atlas/3.10.3 scalapack/2.0.2 fftw/3.3.8 szip/2.1.1 ffmpeg/4.2.1 opencv/4.1.1 python/3.7.4_ML 
echo ""== Starting run at $(date)"" 
echo ""== Job ID: ${SLURM_JOBID}"" 
echo ""== Job NPROCS: ${SLURM_NPROCS}"" 
echo ""== Job NNODES: ${SLURM_NNODES}"" 
echo ""== Node list: ${SLURM_NODELIST}"" 
echo ""== Submit dir. : ${SLURM_SUBMIT_DIR}"" 
#------- srun ------ 
srun ./testHangs.py

echo ""Done""
```

This file works (second part of the notebook previously referred to)

```python
#!/apps/PYTHON/3.7.4_ML/bin/python 

import sys
import numpy as np
import tensorflow as tf
import tensorflow_probability as tfp


def main():
    tfb, tfd = tfp.bijectors, tfp.distributions

    physical_gpus = tf.config.experimental.list_physical_devices('GPU')
    print(physical_gpus)

#    tf.config.experimental.set_virtual_device_configuration(
#        physical_gpus[0],
#        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)] * 2)
#    tf.config.experimental.set_virtual_device_configuration(
#        physical_gpus[1],
#        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)] * 2)
#    gpus = tf.config.list_logical_devices('GPU')
#    print(gpus)

#st = tf.distribute.MirroredStrategy(devices=tf.config.list_logical_devices('GPU'))
    st = tf.distribute.MirroredStrategy()
    print(st.extended.worker_devices)
    ndim = 3
    
    def model():
      Root = tfd.JointDistributionCoroutine.Root
      loc = yield Root(tfb.Shift(.5)(tfd.MultivariateNormalDiag(loc=tf.zeros([ndim]))))
      scale_tril = yield Root(tfb.FillScaleTriL()(tfd.MultivariateNormalDiag(loc=tf.zeros([ndim * (ndim + 1) // 2]))))
      yield tfd.MultivariateNormalTriL(loc=loc, scale_tril=scale_tril)
    
    dist = tfd.JointDistributionCoroutine(model)
    tf.random.set_seed(1)
    loc, scale_tril, _ = dist.sample(seed=2)
    
    samples = dist.sample(value=([loc] * 1024, scale_tril, None), seed=3)[2]
    samples = tf.round(samples * 1000) / 1000
    for dim in reversed(range(ndim)):
      samples = tf.gather(samples, tf.argsort(samples[:,dim]))
    
    print(samples)
    
    batches_per_eval = 2
    
    def dataset_fn(ctx):
      batch_size = ctx.get_per_replica_batch_size(len(samples))
      d = tf.data.Dataset.from_tensor_slices(samples).batch(batch_size // batches_per_eval)
      return d.shard(ctx.num_input_pipelines, ctx.input_pipeline_id).prefetch(2)
    
    ds = st.experimental_distribute_datasets_from_function(dataset_fn)
    
    def log_prob_and_grad(loc, scale_tril, observations, prev_sum_lp, prev_sum_grads):
      with tf.GradientTape() as tape:
        tape.watch((loc, scale_tril))
        lp = tf.reduce_sum(dist.log_prob(loc, scale_tril, observations)) / len(samples)
      grad = tape.gradient(lp, (loc, scale_tril))
      return lp + prev_sum_lp, [g + pg for (g, pg) in zip(grad, prev_sum_grads)]

    @tf.custom_gradient
    def target_log_prob(loc, scale_tril):
      sum_lp = tf.zeros([])
      sum_grads = [tf.zeros_like(x) for x in (loc, scale_tril)]
      sum_lp, sum_grads = st.experimental_run_v2(
          lambda *x: tf.nest.map_structure(tf.identity, x), (sum_lp, sum_grads))
      def reduce_fn(state, observations):
        sum_lp, sum_grads = state
        return st.experimental_run_v2(
            log_prob_and_grad, (loc, scale_tril, observations, sum_lp, sum_grads))
      sum_lp, sum_grads = ds.reduce((sum_lp, sum_grads), reduce_fn)
      sum_lp = st.reduce('sum', sum_lp, None)
      sum_grads = [st.reduce('sum', sg, None) for sg in sum_grads]
      return sum_lp, lambda grad_lp: [grad_lp * sg for sg in sum_grads]
    
    multibatch_vals = tfp.math.value_and_gradient(target_log_prob, (loc, scale_tril))
    
    kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob, step_size=.35, num_leapfrog_steps=2)
    kernel = tfp.mcmc.TransformedTransitionKernel(kernel, bijector=[tfb.Identity(), tfb.FillScaleTriL()])
    
    @tf.function(autograph=False)
    def sample_chain():
      return tfp.mcmc.sample_chain(
          num_results=200, num_burnin_steps=100,
          current_state=[tf.ones_like(loc), tf.linalg.eye(scale_tril.shape[-1])], 
          kernel=kernel, trace_fn=lambda _, kr: kr.inner_results.is_accepted)
    samps, is_accepted = sample_chain()
    
    print(f'accept rate: {np.mean(is_accepted)}')
    print(f'ess: {tfp.mcmc.effective_sample_size(samps)}')
    
    print(tf.reduce_mean(samps[0], axis=0))

if __name__ == ""__main__"":
    sys.exit(main())
```
And the batch job 

```
#!/bin/bash 
#SBATCH --job-name='test2_cross_gpu' 
#SBATCH --qos=debug
# 
#SBATCH --nodes=1 
#SBATCH --ntasks=1 
#SBATCH --cpus-per-task=80 
#SBATCH --gres=gpu:2 
#SBATCH --time=00:05:00 
#------- I/O ------- 
#SBATCH -D . 
#SBATCH --output=test2_cross_gpu_%j.out 
#SBATCH --error=test2_cross_gpu_%j.err 
#------- modules ------- 
module purge 
module load gcc/8.3.0 cuda/10.1 cudnn/7.6.4 nccl/2.4.8 tensorrt/6.0.1 openmpi/4.0.1 atlas/3.10.3 scalapack/2.0.2 fftw/3.3.8 szip/2.1.1 ffmpeg/4.2.1 opencv/4.1.1 python/3.7.4_ML 
echo ""== Starting run at $(date)"" 
echo ""== Job ID: ${SLURM_JOBID}"" 
echo ""== Job NPROCS: ${SLURM_NPROCS}"" 
echo ""== Job NNODES: ${SLURM_NNODES}"" 
echo ""== Node list: ${SLURM_NODELIST}"" 
echo ""== Submit dir. : ${SLURM_SUBMIT_DIR}"" 
#------- srun ------ 
srun ./testWorks.py

echo ""Done""
```

**Other info / logs**

Doing ```strace -F -p [PID]``` we obtain 

```futex(0x4a896234, FUTEX_WAIT_PRIVATE, 1, NULL <unfinished ...> ```

Then ```gdb -p [PID]```
```
#0  syscall () at ../sysdeps/unix/sysv/linux/powerpc/syscall.S:29
#1  0x00007fff63fed144 in nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec) ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#2  0x00007fff63febd08 in nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*) ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#3  0x00007fff63fe7414 in nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*) ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#4  0x00007fff63fe7aec in nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*) ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#5  0x00007fff63fe7b44 in nsync::nsync_cv_wait(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*) ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#6  0x00007fff63fe59c4 in tensorflow::condition_variable::wait(tensorflow::mutex_lock&) ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007fff59ae1f88 in tensorflow::KernelAndDeviceFunc::Run(tensorflow::ScopedStepContainer*, tensorflow::EagerKernelArgs const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::CancellationManager*, absl::optional<tensorflow::EagerRemoteFunctionParams> const&) ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#8  0x00007fff59ae242c in tensorflow::KernelAndDeviceFunc::Run(tensorflow::EagerKernelArgs const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::CancellationManager*, absl::optional<tensorflow::EagerRemoteFunctionParams> const&) ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#9  0x00007fff59a9dcd4 in tensorflow::EagerKernelExecute(tensorflow::EagerContext*, absl::InlinedVector<tensorflow::TensorHandle*, 4ul, std::allocator<tensorflow::TensorHandle*> > const&, absl::optional<tensorflow::EagerRemoteFunctionParams> const&, std::unique_ptr<tensorflow::KernelAndDevice, tensorflow::core::RefCountDeleter> const&, tensorflow::GraphCollector*, tensorflow::CancellationManager*, absl::Span<tensorflow::TensorHandle*>) ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#10 0x00007fff59a9ef40 in tensorflow::ExecuteNode::Run() ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#11 0x00007fff59adb59c in tensorflow::EagerExecutor::SyncExecute(tensorflow::EagerNode*) ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#12 0x00007fff59a96e34 in tensorflow::(anonymous namespace)::EagerLocalExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#13 0x00007fff59a9b4c8 in tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) ()
   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
---Type <return> to continue, or q <return> to quit---
```"
40570,ValueError: Cannot set tensor: Got tensor of type STRING but expected type FLOAT32,"Hi, 
I am very new to Tensorflow. I am using TensorFlow 1.14.0, Anaconda Spyder 3.7 64 bit and windows 10 64 bit. In my DATASET I am having two folders with classification images (in png and jpeg format). 
I am trying to convert my Keras model.h5 into tflite model. For that, I am using the below-mentioned code. It gives me an error(full traceback can be found at the bottom): 
    ValueError: Cannot set tensor: Got tensor of type STRING but expected type FLOAT32 for input 185, name: mobilenetv2_1.00_224_input 

I have tried to convert images into float 32 using the TensorFlow image converter and NumPy but the same error. 

    import tensorflow as tf
    dataset_dir = ""C:\\Users\\Ravi\\dataset""

    IMAGE_SIZE = 224
    BATCH_SIZE = 64

    datagen = tf.keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255, 
        validation_split=0.2)

    train_generator = datagen.flow_from_directory(
    dataset_dir,
    target_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE, 
    subset='training')

    val_generator = datagen.flow_from_directory(
    dataset_dir,
    target_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE, 
    subset='validation')

    image_batch, label_batch = next(val_generator)
    image_batch.shape, label_batch.shape

    print (train_generator.class_indices)

    labels = '\n'.join(sorted(train_generator.class_indices.keys()))

    with open('Mask_labels.txt', 'w') as f:
      f.write(labels)
  
    IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)

    # Create the base model from the pre-trained MobileNet V2
    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                              include_top=False, 
                                              weights='imagenet')
    base_model.trainable = False
    model = tf.keras.Sequential([
      base_model,
      tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),
      tf.keras.layers.Dropout(0.2),
      tf.keras.layers.GlobalAveragePooling2D(),
      tf.keras.layers.Dense(units=2, activation='softmax')
    ])

    model.compile(optimizer=tf.keras.optimizers.Adam(), 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])

    print(model.summary())
    print('Number of trainable weights = {}'.format(len(model.trainable_weights)))

    history = model.fit_generator(train_generator, 
                    epochs=2, 
                    validation_data=val_generator)

    # A generator that provides a representative dataset
    def representative_data_gen():
      dataset_list = tf.data.Dataset.list_files(dataset_dir + '/*/*')
      for i in range(100):
        global image
        image = next(iter(dataset_list))
        image = tf.io.read_file(image)
        image = tf.io.decode_jpeg(image, channels=3)
        image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])
        #image = np.array(image, dtype=""float32"")
        image = tf.image.convert_image_dtype(image, tf.float32)
        #image = tf.expand_dims(image, 0)
        yield [image]
    
    saved_keras_model = 'model.h5'
    model.save(saved_keras_model)

    converter =  tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(""model.h5"")
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    # This ensures that if any ops can't be quantized, the converter throws an error
    #converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    # These set the input and output tensors to uint8
    converter.inference_input_type = tf.uint8
    converter.inference_output_type = tf.uint8
    # And this sets the representative dataset so we can quantize the activations
    converter.representative_dataset = representative_data_gen
    tflite_model = converter.convert()
 
    with open('mobilenet_v2_1.0_224_quant.tflite', 'wb') as f:
      f.write(tflite_model)


Traceback (most recent call last):

      File ""C:\Users\Ravi\train_the_model.py"", line 120, in <module>
        tflite_model = converter.convert()

      File ""C:\Users\Ravi\anaconda3\lib\site-packages\tensorflow\lite\python\lite.py"", line 908, in convert
    inference_output_type)

      File ""C:\Users\Ravi\anaconda3\lib\site-packages\tensorflow\lite\python\lite.py"", line 200, in _calibrate_quantize_model
    inference_output_type, allow_float)

      File ""C:\Users\Ravi\anaconda3\lib\site-packages\tensorflow\lite\python\optimize\calibrator.py"", line 75, in calibrate_and_quantize
    self._calibrator.FeedTensor(calibration_sample)

      File ""C:\Users\Ravi\anaconda3\lib\site-packages\tensorflow\lite\python\optimize\tensorflow_lite_wrap_calibration_wrapper.py"", line 112, in FeedTensor
    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_FeedTensor(self, input_value)

    ValueError: Cannot set tensor: Got tensor of type STRING but expected type FLOAT32 for input 185, name: mobilenetv2_1.00_224_input 





 "
40569,AttributeError: 'Tensor' object has no attribute 'numpy',"System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution: Windows 10
TensorFlow installed from (source or binary):
TensorFlow version: 2.0.0
Python version: 3.6
GPU model and memory: NVIDIA 4GB GTX970

My code is giving me the error 'AttributeError: 'Tensor' object has no attribute 'numpy'' in the bolded line, with the comments ""Error occurs here"".

I want to perform selective search on the feature mappings generated by the convolutional layers in my CNN model. However, it appears that cv2 functions do not accept tensors, and thus I wish to convert the tensors to numpy arrays. However, when I attempt to do the conversion using the numpy() or tf.py_function() functions, I will get the attribute error as shown above. 

Is this error occuring because I am calling numpy() within the model which is using @tf.function? Is there any other way to perform this operation?

Thank you.

Here is my code: 

```
class seq_model(object):
    def __init__(self):
        print(""Using SEQUENTIAL model"")

    def input(self):
        #Create CNN model
        input_size = (28, 28, 1)
        inputs = Input(shape = input_size)
        return inputs

    def selective_search(self, input_stack):
        cv2.setUseOptimized(True)
        cv2.setNumThreads(4)
        total_ROI = 0
        ROI_img_list = []
        select_search = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()

        input_shape = input_stack.get_shape().as_list()
        print(""input_shape = "", input_shape)
        no_of_channel = input_shape[3]
        for i in range(no_of_channel):
            if input_shape[0] == None:
                img_tensor = input_stack[-1,:,:,i]

                **img = img_tensor.numpy()** #Error occurs at this line

                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) #Ensure 3 channels
            select_search.setBaseImage(img)
            select_search.switchToSelectiveSearchQuality()
            rects = select_search.process()
            numShowRects = 100
            img_copy = img.copy()
            boundary_list = []
            for j, rect in enumerate(rects):
                if (j < numShowRects):
                    x, y, w, h = rect
                    cv2.rectangle(img_copy, (x,y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)
                    boundary = [x, x+w, y, y+h]
                    boundary_list.append(boundary)
                else:
                    break
            num_region = len(boundary_list)
            label = label_stack[i]
            for k in range(num_region):
                corner = boundary_list[k]
                x1 = corner[0]
                x2 = corner[1]
                y1 = corner[2]
                y2 = corner[3]
                ROI_img = img[y1:y2, x1:x2]
                ROI_img = cv2.cvtColor(ROI_img, cv2.COLOR_RGB2GRAY)
                ROI_img_reshaped = np.empty(CNN_input_shape)
                ROI_img_reshaped = cv2.resize(ROI_img, (y2-y1, x2-x1))
                ROI_img_list.append(ROI_img_reshaped)
            total_ROI += num_region #Obtain total number of ROI images
            ROI_stack = np.empty((total_ROI, 28, 28, 1))

        return ROI_stack

    def spatial_pyramid_pooling(self, input, levels):
        #Levels refers to the list of pooling regions to use. 
        #The length of the list is the number of pooling regions.
        #Each int in the list is the number of regions in that pool. 
        #For example [1,2,4] would be 3 regions with 1, 2x2 and 4x4 max pools, so 21 outputs per feature map
        input_shape = input.get_shape().as_list()
        pyramid = []
        outputs = []
        num_rows = input_shape[1]
        num_cols = input_shape[2]
        row_length = [K.cast(num_rows, 'float32') / i for i in levels] #Returns a Keras tensor of float32 type
        col_length = [K.cast(num_cols, 'float32') / i for i in levels]
        tf.print(row_length) #[4,8,16]
        tf.print(col_length) #[4,8,16]

        for pool_num, num_pool_regions in enumerate(levels): #pool_num is the index, num_pool_regions is the actual value
            for jy in range(num_pool_regions):
                for ix in range(num_pool_regions):
                    x1 = ix * col_length[pool_num]
                    x2 = ix * col_length[pool_num] + col_length[pool_num]
                    y1 = jy * row_length[pool_num]
                    y2 = jy * row_length[pool_num] + row_length[pool_num]

                    x1 = K.cast(K.round(x1), 'int32')
                    x2 = K.cast(K.round(x2), 'int32')
                    y1 = K.cast(K.round(y1), 'int32')
                    y2 = K.cast(K.round(y2), 'int32')

                    if input_shape[0] == None:
                        new_shape = [-1, y2 - y1, x2 - x1, input_shape[3]]

                    x_crop = input[:, y1:y2, x1:x2, :]
                    xm = Reshape(new_shape)(x_crop)
                    pooled_val = K.max(xm, axis = (1, 2)) #Obtain maximum value from cropped image
                    #print(""pooled_val = "", np.shape(pooled_val))
                    outputs.append(pooled_val)    

        outputs = concatenate(outputs, axis = 1)
        #print(""SHAPE = "", np.shape(outputs)) #(None, 112, 64)
        return outputs

    def conv_model(self, no_of_class = 10):
        kernel_size = (3,3)
        pad = 'same'
        activation = 'selu'
        kernel = 'lecun_normal'
        filters = 64

        self.initial_input = self.input()

        c1 = Conv2D(filters, kernel_size, padding = pad, activation = activation, kernel_initializer = kernel)(self.initial_input)
        b1 = BatchNormalization()(c1) 
        p1 = MaxPooling2D()(b1)

        c2 = Conv2D(filters, kernel_size, padding = pad, activation = activation, kernel_initializer = kernel)(p1)
        b2 = BatchNormalization()(c2) 

        roi = self.selective_search(b2)
        spp = self.spatial_pyramid_pooling(roi, levels = [3,2,1])

        f = Flatten()(spp)
        bf = BatchNormalization()(f)

        bf_shape = bf.get_shape().as_list()
        dense_num = bf_shape[1] #Changes the dense layer automatically

        d1 = Dense(dense_num, activation = 'selu', kernel_initializer = kernel)(bf)
        db1 = BatchNormalization()(d1)
        d2 = Dense(10, activation = 'softmax')(db1)

        model = Model(inputs = [self.initial_input], outputs = [d2])

        return model

get_model = seq_model()
model = get_model.conv_model()
print(model.summary())

```"
40568,Building Tensorflow for arm based linux systems.,"System information
- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.2.0
- Python version: 3.6
- Bazel Version: 2.0.0


**Describe the problem**
I want to build tensorflow shared library from source for arm based 32 bit linux platform but nowhere i find the build command in documentation.
Is it that some different toolchain is required for arm-linux-androideabi ?
What bazel command shall i try to build it ?
"
40567,d,d
40566,"Use loss_weight in Model.compile() to compute total loss, but in real the total loss is more than the sum of losses","I test for the using of the loss_weight in Model.compile() ,which can weight losses. but In my test, I find the total loss is more than sum of losses.
like { 'loss': 3.4932688, 'output_1_loss': 1.107162, 'output_2_loss': 1.107162, 'output_3_loss': 1.107162}, where I made loss_weight is [1,1,1]3.49 > 1.107*3
my version of tensorflow is 2.1.0
python is 3.6
"
40565,"Prediciting the model with features on TPU (AssertionError: Could not compute output Tensor(""dense_3/Identity:0"", shape=(None, 1), dtype=float32))","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Kaggle using TPU
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.2
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
After succesful Training , prediction of the model was not happening even if the dataset was right 
And throwing this error
`    AssertionError: Could not compute output Tensor(""dense_3/Identity:0"", shape=(None, 1), dtype=float32)
`
**Describe the expected behavior**
Model should sucessfully predict the dataset

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
[https://www.kaggle.com/prudhvi9999/image-and-metadata](url)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Logs are 
[logs.txt](https://github.com/tensorflow/tensorflow/files/4797768/logs.txt)

"
40563,New Model on Android not working,"I have make new model build with:
https://teachablemachine.withgoogle.com/

I download example SDK from:
https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android

I put my model with 2 files on assets directory:
1. model.tflite
2. model_label.txt

I make new class with extend to ""Classifier"". I replace this two methods:

```
  @Override
  protected String getModelPath() {
    return ""model.tflite"";
  }

  @Override
  protected String getLabelPath() {
    return ""model_label.txt"";
  }
```
And then run the project. And I dont see any effect. If I use mobilnet model is working.
I was test this model with tensorflow.js and using webcam, and its working, but why on android not working. I have miss it something? Pleaselet me know.

"
40561,MSVC 2017 NVIDIA CUDA 9.2.1.148 CUDNN 7.5.0.56 target //tensorflow:tensorflow_cc.dll fails to link,"

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10.0.18362
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version:r2.2
- Python version:3.6
- Installed using virtualenv? pip? conda?:NA
- Bazel version (if compiling from source): 2.0.0 via bazelisk
- GCC/Compiler version (if compiling from source):MSVC 2017 Microsoft (R) C/C++ Optimizing Compiler Version 19.16.27027.1 for x64
- CUDA/cuDNN version: 9.2.1.148/7.5.0.56
- GPU model and memory:GTX 1060 6Gb



**Describe the problem**

`r2.2` wont compile `tensorflow_cc.dll`

open  powershell
```
cd D:\github
mkdir attempt6
cd attempt6
git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
git checkout r2.2
cp .\..\..\*.ps1
. .\buildenv.ps1
. .\build-tf.ps1
```

where the contents of `buildenv.ps1` are

```
pushd 'C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Auxiliary\Build\'    
cmd /c ""vcvarsall.bat x64 & set"" |
foreach {
  if ($_ -match ""="") {
    $v = $_.split(""=""); set-item -force -path ""ENV:\$($v[0])""  -value ""$($v[1])""
  }
}
popd
write-host ""`nVisual Studio 2017 Command Prompt variables set."" -ForegroundColor Yellow
```

and `build-tf.ps1` are

```
$ENV:USE_BAZEL_VERSION=""2.0.0""
$ENV:PYTHON_BIN_PATH=""C:/Users/user/AppData/Local/Programs/Python/Python36/python.exe""
$ENV:PYTHON_LIB_PATH=""C:/Users/user/AppData/Local/Programs/Python/Python36/""
$ENV:Path += "";C:/msys64/usr/bin""
$ENV:Path += "";C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.2/bin""
$ENV:Path += "";C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.2/extras/CUPTI/libx64""
$ENV:Path += "";C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/cudnn-9.2-windows10-x64-v7.5.0.56/cuda/bin""
$ENV:BAZEL_SH = ""C:/msys64/usr/bin/bash.exe""
$ENV:CUDA_TOOLKIT_PATH=""C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.2/""
$ENV:TF_CUDA_VERSION=""9.2""
$ENV:CUDNN_INSTALL_PATH=""C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/cudnn-9.2-windows10-x64-v7.5.0.56/cuda""
$ENV:TF_CUDA_COMPUTE_CAPABILITIES=""6.0""
$ENV:TF_CUDNN_VERSION=""7""
$ENV:TF_NCCL_VERSION=""1""
$ENV:TF_CUDA_CLANG=""0""
$ENV:TF_NEED_CUDA=""1""
$ENV:TF_NEED_ROCM=""0""
$ENV:TF_NEED_OPENCL_SYCL=""0""


$params = ""configure.py"",""""
cmd /c ""ECHO Y"" | & python.exe @params 
bazel.exe build --copt=-nvcc_options=disable-warnings --test_tag_filters=-no_oss,-gpu,-benchmark-test,-nomac,-no_mac --announce_rc --test_timeout 300,450,1200,3600 --test_size_filters=small,medium --define=override_eigen_strong_inline=true  --repository_cache=D:/bazel-cache --jobs=12 //tensorflow:tensorflow_cc.dll
```
**Any other info / logs**


Would have expected a good result, only difference from recent build on AWS box with T4 hardware is CUDA 10.2 on AWS box and CUDA 9.2 on local box with GTX 1060 card

Error is

```
ERROR: D:/github/attempt6/tensorflow/tensorflow/BUILD:710:1: Linking of rule '//tensorflow:tensorflow_cc.dll' failed (Exit 1120)
LINK : warning LNK4044: unrecognized option '/Wl,-rpath,../local_config_cuda/cuda/lib64'; ignored
LINK : warning LNK4044: unrecognized option '/Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64'; ignored
   Creating library bazel-out/x64_windows-opt/bin/tensorflow/tensorflow_cc.dll.if.lib and object bazel-out/x64_windows-opt/bin/tensorflow/tensorflow_cc.dll.if.exp
bfc_allocator.lib(bfc_allocator.obj) : warning LNK4049: locally defined symbol ?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level) imported
graph_mgr.lib(graph_mgr.obj) : warning LNK4049: locally defined symbol ?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level) imported
batch_kernels.lo.lib(batch_kernels.obj) : warning LNK4049: locally defined symbol ?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level) imported
snapshot_util.lib(snapshot_util.obj) : warning LNK4049: locally defined symbol ?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level) imported
captured_function.lib(captured_function.obj) : warning LNK4049: locally defined symbol ?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level) imported
grpc_master_service.lo.lib(grpc_master_service.obj) : warning LNK4217: locally defined symbol ?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level) imported in function ""public: __cdecl tensorflow::profiler::TraceMe::TraceMe<class <lambda_ff01698cf6bea26b6df62d500bf7591b> >(class <lambda_ff01698cf6bea26b6df62d500bf7591b>,int)"" (??$?0V<lambda_ff01698cf6bea26b6df62d500bf7591b>@@@TraceMe@profiler@tensorflow@@QEAA@V<lambda_ff01698cf6bea26b6df62d500bf7591b>@@H@Z)
eager_service_impl.lib(eager_service_impl.obj) : warning LNK4049: locally defined symbol ?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level) imported
execute.lib(execute.obj) : warning LNK4049: locally defined symbol ?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level) imported
remote_tensor_handle_data.lib(remote_tensor_handle_data.obj) : warning LNK4049: locally defined symbol ?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level) imported
memory_optimizer.lib(memory_optimizer.obj) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported
pin_to_host_optimizer.lib(pin_to_host_optimizer.obj) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported
utils.lib(utils.obj) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported
collective_param_resolver_distributed.lib(collective_param_resolver_distributed.obj) : warning LNK4217: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported in function ""public: __cdecl tensorflow::CollGroupParams::CollGroupParams(void)"" (??0CollGroupParams@tensorflow@@QEAA@XZ)
batch_kernels.lo.lib(batch_kernels.obj) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported
captured_function.lib(captured_function.obj) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported
arithmetic_optimizer.lib(arithmetic_optimizer.obj) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported
tfprof_show.lib(tfprof_show.obj) : warning LNK4217: locally defined symbol TF_NewStatus imported in function ""protected: bool __cdecl tensorflow::tfprof::TFShow::LookUpCheckPoint(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class std::unique_ptr<class tensorflow::tfprof::TFProfTensor,struct std::default_delete<class tensorflow::tfprof::TFProfTensor> > *)"" (?LookUpCheckPoint@TFShow@tfprof@tensorflow@@IEAA_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@PEAV?$unique_ptr@VTFProfTensor@tfprof@tensorflow@@U?$default_delete@VTFProfTensor@tfprof@tensorflow@@@std@@@5@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4049: locally defined symbol TF_NewStatus imported
tfprof_show.lib(tfprof_show.obj) : warning LNK4217: locally defined symbol TF_DeleteStatus imported in function ""protected: bool __cdecl tensorflow::tfprof::TFShow::LookUpCheckPoint(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class std::unique_ptr<class tensorflow::tfprof::TFProfTensor,struct std::default_delete<class tensorflow::tfprof::TFProfTensor> > *)"" (?LookUpCheckPoint@TFShow@tfprof@tensorflow@@IEAA_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@PEAV?$unique_ptr@VTFProfTensor@tfprof@tensorflow@@U?$default_delete@VTFProfTensor@tfprof@tensorflow@@@std@@@5@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4049: locally defined symbol TF_DeleteStatus imported
tfprof_show.lib(tfprof_show.obj) : warning LNK4217: locally defined symbol TF_GetCode imported in function ""protected: bool __cdecl tensorflow::tfprof::TFShow::LookUpCheckPoint(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class std::unique_ptr<class tensorflow::tfprof::TFProfTensor,struct std::default_delete<class tensorflow::tfprof::TFProfTensor> > *)"" (?LookUpCheckPoint@TFShow@tfprof@tensorflow@@IEAA_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@PEAV?$unique_ptr@VTFProfTensor@tfprof@tensorflow@@U?$default_delete@VTFProfTensor@tfprof@tensorflow@@@std@@@5@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4049: locally defined symbol TF_GetCode imported
tf_tensor.lib(tf_tensor.obj) : warning LNK4049: locally defined symbol TF_GetCode imported
tfprof_show.lib(tfprof_show.obj) : warning LNK4217: locally defined symbol TF_Message imported in function ""protected: bool __cdecl tensorflow::tfprof::TFShow::LookUpCheckPoint(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class std::unique_ptr<class tensorflow::tfprof::TFProfTensor,struct std::default_delete<class tensorflow::tfprof::TFProfTensor> > *)"" (?LookUpCheckPoint@TFShow@tfprof@tensorflow@@IEAA_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@PEAV?$unique_ptr@VTFProfTensor@tfprof@tensorflow@@U?$default_delete@VTFProfTensor@tfprof@tensorflow@@@std@@@5@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4049: locally defined symbol TF_Message imported
utils.lib(utils.obj) : warning LNK4049: locally defined symbol ?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU) imported
arithmetic_optimizer.lib(arithmetic_optimizer.obj) : warning LNK4217: locally defined symbol ?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU) imported in function ""private: bool __cdecl tensorflow::grappler::`anonymous namespace'::ReorderCastLikeAndValuePreserving::NodeIsOnCpuOrGpu(class tensorflow::NodeDef const *)const "" (?NodeIsOnCpuOrGpu@ReorderCastLikeAndValuePreserving@?A0x41d86e96@grappler@tensorflow@@AEBA_NPEBVNodeDef@4@@Z)
auto_mixed_precision.lib(auto_mixed_precision.obj) : warning LNK4049: locally defined symbol ?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU) imported
memory_optimizer.lib(memory_optimizer.obj) : warning LNK4049: locally defined symbol ?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU) imported
pin_to_host_optimizer.lib(pin_to_host_optimizer.obj) : warning LNK4049: locally defined symbol ?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU) imported
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_DataTypeSize imported in function ""void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)"" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)
tf_tensor.lib(tf_tensor.obj) : warning LNK4049: locally defined symbol TF_DataTypeSize imported
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_SetStatus imported in function ""void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,unsigned __int64,unsigned __int64,struct TF_Status *)"" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@_K2PEAUTF_Status@@@Z)
tf_tensor.lib(tf_tensor.obj) : warning LNK4049: locally defined symbol TF_SetStatus imported
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_NewOpDefinitionBuilder imported in function ""public: bool __cdecl <lambda_e001034d847de908815119ad3d529795>::operator()(void)const "" (??R<lambda_e001034d847de908815119ad3d529795>@@QEBA_NXZ)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_RegisterOpDefinition imported in function ""public: bool __cdecl <lambda_e001034d847de908815119ad3d529795>::operator()(void)const "" (??R<lambda_e001034d847de908815119ad3d529795>@@QEBA_NXZ)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_OpDefinitionBuilderAddAttr imported in function ""public: bool __cdecl <lambda_e001034d847de908815119ad3d529795>::operator()(void)const "" (??R<lambda_e001034d847de908815119ad3d529795>@@QEBA_NXZ)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_OpDefinitionBuilderAddInput imported in function ""public: bool __cdecl <lambda_e001034d847de908815119ad3d529795>::operator()(void)const "" (??R<lambda_e001034d847de908815119ad3d529795>@@QEBA_NXZ)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_OpDefinitionBuilderAddOutput imported in function ""public: bool __cdecl <lambda_e001034d847de908815119ad3d529795>::operator()(void)const "" (??R<lambda_e001034d847de908815119ad3d529795>@@QEBA_NXZ)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_OpDefinitionBuilderSetShapeInferenceFunction imported in function ""public: bool __cdecl <lambda_e001034d847de908815119ad3d529795>::operator()(void)const "" (??R<lambda_e001034d847de908815119ad3d529795>@@QEBA_NXZ)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_NewShapeHandle imported in function ""void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)"" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_ShapeInferenceContextGetInput imported in function ""void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)"" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_ShapeInferenceContextSetOutput imported in function ""void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)"" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_ShapeInferenceContextVectorFromSize imported in function ""void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,unsigned __int64,unsigned __int64,struct TF_Status *)"" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@_K2PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_NewDimensionHandle imported in function ""void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,unsigned __int64,unsigned __int64,struct TF_Status *)"" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@_K2PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_ShapeInferenceContext_GetAttrType imported in function ""void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)"" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_ShapeInferenceContextRankKnown imported in function ""void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)"" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_ShapeInferenceContextWithRankAtLeast imported in function ""void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,unsigned __int64,unsigned __int64,struct TF_Status *)"" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@_K2PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_ShapeInferenceContextDim imported in function ""void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,unsigned __int64,unsigned __int64,struct TF_Status *)"" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@_K2PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_ShapeInferenceContextSubshape imported in function ""void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,unsigned __int64,unsigned __int64,struct TF_Status *)"" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@_K2PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_ShapeInferenceContextSetUnknownShape imported in function ""void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)"" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_DimensionHandleValueKnown imported in function ""void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,unsigned __int64,unsigned __int64,struct TF_Status *)"" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@_K2PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_DimensionHandleValue imported in function ""void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,unsigned __int64,unsigned __int64,struct TF_Status *)"" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@_K2PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_ShapeInferenceContextConcatenateShapes imported in function ""void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,unsigned __int64,unsigned __int64,struct TF_Status *)"" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@_K2PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_DeleteShapeHandle imported in function ""void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,unsigned __int64,unsigned __int64,struct TF_Status *)"" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@_K2PEAUTF_Status@@@Z)
bitcast_op_lib.lo.lib(bitcast.obj) : warning LNK4217: locally defined symbol TF_DeleteDimensionHandle imported in function ""void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,unsigned __int64,unsigned __int64,struct TF_Status *)"" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@_K2PEAUTF_Status@@@Z)
gpu_activation.lib(gpu_activation.obj) : error LNK2019: unresolved external symbol ""class stream_executor::gpu::GpuContext * __cdecl stream_executor::gpu::ExtractGpuContext(class stream_executor::gpu::GpuExecutor *)"" (?ExtractGpuContext@gpu@stream_executor@@YAPEAVGpuContext@12@PEAVGpuExecutor@12@@Z) referenced in function ""public: __cdecl stream_executor::gpu::ScopedActivateExecutorContext::ScopedActivateExecutorContext(class stream_executor::gpu::GpuExecutor *)"" (??0ScopedActivateExecutorContext@gpu@stream_executor@@QEAA@PEAVGpuExecutor@12@@Z)
gpu_activation.lib(gpu_activation.obj) : error LNK2019: unresolved external symbol ""class stream_executor::gpu::GpuExecutor * __cdecl stream_executor::gpu::ExtractGpuExecutor(class stream_executor::StreamExecutor *)"" (?ExtractGpuExecutor@gpu@stream_executor@@YAPEAVGpuExecutor@12@PEAVStreamExecutor@2@@Z) referenced in function ""public: __cdecl stream_executor::gpu::ScopedActivateExecutorContext::ScopedActivateExecutorContext(class stream_executor::StreamExecutor *)"" (??0ScopedActivateExecutorContext@gpu@stream_executor@@QEAA@PEAVStreamExecutor@2@@Z)
bazel-out/x64_windows-opt/bin/tensorflow/tensorflow_cc.dll : fatal error LNK1120: 2 unresolved externals
Target //tensorflow:tensorflow_cc.dll failed to build
INFO: Elapsed time: 2607.289s, Critical Path: 349.09s
INFO: 4393 processes: 4393 local.
```

note

```
gpu_activation.lib(gpu_activation.obj) : error LNK2019: unresolved external symbol ""class stream_executor::gpu::GpuContext * __cdecl stream_executor::gpu::ExtractGpuContext(class stream_executor::gpu::GpuExecutor *)"" (?ExtractGpuContext@gpu@stream_executor@@YAPEAVGpuContext@12@PEAVGpuExecutor@12@@Z) referenced in function ""public: __cdecl stream_executor::gpu::ScopedActivateExecutorContext::ScopedActivateExecutorContext(class stream_executor::gpu::GpuExecutor *)"" (??0ScopedActivateExecutorContext@gpu@stream_executor@@QEAA@PEAVGpuExecutor@12@@Z)
gpu_activation.lib(gpu_activation.obj) : error LNK2019: unresolved external symbol ""class stream_executor::gpu::GpuExecutor * __cdecl stream_executor::gpu::ExtractGpuExecutor(class stream_executor::StreamExecutor *)"" (?ExtractGpuExecutor@gpu@stream_executor@@YAPEAVGpuExecutor@12@PEAVStreamExecutor@2@@Z) referenced in function ""public: __cdecl stream_executor::gpu::ScopedActivateExecutorContext::ScopedActivateExecutorContext(class stream_executor::StreamExecutor *)"" (??0ScopedActivateExecutorContext@gpu@stream_executor@@QEAA@PEAVStreamExecutor@2@@Z)
bazel-out/x64_windows-opt/bin/tensorflow/tensorflow_cc.dll : fatal error LNK1120: 2 unresolved externals
```

Adding `*stream_executor*` to the appropriate `.lds` files might fix the problem"
40560,JAVA DataType support float16?,"use python to train a model has float16.but cant reference by java.DataType 19 is not recognized in Java 
https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/DataType"
40559,populateTypeInferenceInfo hits assertion when generating type inference interface for tf_ops,"mlir-tblgen: external/llvm-project/mlir/lib/TableGen/Type.cpp:22: mlir::tblgen::TypeConstraint::TypeConstraint(const llvm::Record*): Assertion `def->isSubClassOf(""TypeConstraint"") && ""must be subclass of TableGen 'TypeConstraint' class""' failed.


**System information**
- Linux Ubuntu 20.04
- TensorFlow installed from source
- TensorFlow version: Latest from source
- Python version: 3.8.2
- Installed using virtualenv? NO
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: 11.0
- GPU model and memory: GeForce RTX 2070 8G

bazel build --config=opt --config=noaws --config=nogcp //tensorflow/tools/pip_package:build_pip_package --verbose_failures

ERROR: /home/xxxxx/Downloads/tensorflow/tensorflow/compiler/mlir/tensorflow/BUILD:62:1: Generating code from table: ir/tf_ops.td //tensorflow/compiler/mlir/tensorflow:tensorflow_ops_inc_gen__gen_op_defs_genrule failed (Aborted): bash failed: error executing command 
  (cd /home/xxxx/.cache/bazel/_bazel_xxxxx/b7319a1803ca3236e14ad4085fc7b534/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda-11.0 \
    GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-9 \
    PATH=/home/xxxxx/anaconda3/condabin:/home/xxxxx/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=7.5 \
    TF_ENABLE_XLA=1 \
    TF_NEED_CUDA=1 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen -gen-op-defs tensorflow/compiler/mlir/tensorflow/ir/tf_ops.td -Ibazel-out/k8-opt/bin -I external/llvm-project/mlir/include -I external/org_tensorflow -I bazel-out/k8-opt/bin/external/llvm-project/mlir/include -I $(dirname tensorflow/compiler/mlir/tensorflow/ir/tf_ops.td) -o bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/ir/tf_ops.cc.inc')
Execution platform: @local_execution_config_platform//:platform
mlir-tblgen: external/llvm-project/mlir/lib/TableGen/Type.cpp:22: mlir::tblgen::TypeConstraint::TypeConstraint(const llvm::Record*): Assertion `def->isSubClassOf(""TypeConstraint"") && ""must be subclass of TableGen 'TypeConstraint' class""' failed.
PLEASE submit a bug report to  and include the crash backtrace.
Stack dump:
0.	Program arguments: bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen -gen-op-defs tensorflow/compiler/mlir/tensorflow/ir/tf_ops.td -Ibazel-out/k8-opt/bin -I external/llvm-project/mlir/include -I external/org_tensorflow -I bazel-out/k8-opt/bin/external/llvm-project/mlir/include -I tensorflow/compiler/mlir/tensorflow/ir -o bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/ir/tf_ops.cc.inc 
 #0 0x000055b79f119f53 llvm::sys::PrintStackTrace(llvm::raw_ostream&) (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0xe9f53)
 #1 0x000055b79f117f45 llvm::sys::RunSignalHandlers() (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0xe7f45)
 #2 0x000055b79f1184e5 SignalHandler(int) (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0xe84e5)
 #3 0x00007fdfd66ed3c0 __restore_rt (/usr/lib/x86_64-linux-gnu/libpthread.so.0+0x153c0)
 #4 0x00007fdfd633018b raise (/usr/lib/x86_64-linux-gnu/libc.so.6+0x4618b)
 #5 0x00007fdfd630f859 abort (/usr/lib/x86_64-linux-gnu/libc.so.6+0x25859)
 #6 0x00007fdfd630f729 (/usr/lib/x86_64-linux-gnu/libc.so.6+0x25729)
 #7 0x00007fdfd6320f36 (/usr/lib/x86_64-linux-gnu/libc.so.6+0x36f36)
 #8 0x000055b79f0c26bf mlir::tblgen::TypeConstraint::TypeConstraint(llvm::Record const*) (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0x926bf)
 #9 0x000055b79f0b2fda mlir::tblgen::Operator::getResultTypeConstraint(int) const (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0x82fda)
#10 0x000055b79f0b3f9c mlir::tblgen::Operator::populateTypeInferenceInfo(llvm::StringMap<int, llvm::MallocAllocator> const&)::'lambda'(int)::operator()(int) const (.isra.0) (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0x83f9c)
#11 0x000055b79f0b5693 mlir::tblgen::Operator::populateTypeInferenceInfo(llvm::StringMap<int, llvm::MallocAllocator> const&) (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0x85693)
#12 0x000055b79f0b6cd9 mlir::tblgen::Operator::populateOpStructure() (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0x86cd9)
#13 0x000055b79f0b75b1 mlir::tblgen::Operator::Operator(llvm::Record const&) (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0x875b1)
#14 0x000055b79f05ec60 emitOpList(std::vector<llvm::Record*, std::allocator<llvm::Record*> > const&, llvm::raw_ostream&)::'lambda'(llvm::Record*)::operator()(llvm::Record*) const (.isra.0) (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0x2ec60)
#15 0x000055b79f06f356 _ZNSt17_Function_handlerIFbRKN4llvm12RecordKeeperERNS0_11raw_ostreamEEUlS3_S5_E2_E9_M_invokeERKSt9_Any_dataS3_S5_ (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0x3f356)
#16 0x000055b79f0c5042 llvm::TableGenMain(char const*, bool (*)(llvm::raw_ostream&, llvm::RecordKeeper&)) (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0x95042)
#17 0x000055b79f04c6df main (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0x1c6df)
#18 0x00007fdfd63110b3 __libc_start_main (/usr/lib/x86_64-linux-gnu/libc.so.6+0x270b3)
#19 0x000055b79f04ef7e _start (bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen+0x1ef7e)
/bin/bash: line 1: 494760 Aborted                 (core dumped) bazel-out/host/bin/external/llvm-project/mlir/mlir-tblgen -gen-op-defs tensorflow/compiler/mlir/tensorflow/ir/tf_ops.td -Ibazel-out/k8-opt/bin -I external/llvm-project/mlir/include -I external/org_tensorflow -I bazel-out/k8-opt/bin/external/llvm-project/mlir/include -I $(dirname tensorflow/compiler/mlir/tensorflow/ir/tf_ops.td) -o bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/ir/tf_ops.cc.inc
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 23.476s, Critical Path: 16.84s
INFO: 414 processes: 414 local.
FAILED: Build did NOT complete successfully


"
40558,Segmentation fault (core dumped),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): pip install --upgrade tensorflow
- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5 1.14.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2
- GPU model and memory: GeForce RTX 2080, 12GB

**Describe the current behavior**
Hi, 
I installed tensorflow from source in python3 using cuda 10.2. But when I run my script, I got this error without any further details:
```
Segmentation fault (core dumped)
```
What is the cause of this issue?

Thank you in advance.
"
40556,Tensorflow Installation Issue tf_logging,"**System information**
- OS Platform: Windows 10
- TensorFlow installed from : conda install with Anaconda distribution
- TensorFlow version: 2.2.0
- Python version: 3.7.4

**Describe the problem**
At first I couldn't install tensorflow due to the folder google_pasta-0.2.0.dist-info not having a METADATA in it. I found somewhere online that by deleting the folder and using pip to reinstall it works. After that it had a METADATA and other files in it and I was able to install tensorflow and went to check if it worked in a Jupyter notebook however after running the program below I got the error described further below

**Provide the exact sequence of commands / steps that you executed before running into the problem**
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
print(sess.run(hello))

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-7-7380a45e29ab>"", line 1, in <module>
    import tensorflow as tf
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 75, in <module>
    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\framework_lib.py"", line 25, in <module>
    from tensorflow.python.framework.ops import Graph
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 42, in <module>
    from tensorflow.python.eager import core
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\core.py"", line 22, in <module>
    from tensorflow.python.framework import errors
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\errors.py"", line 22, in <module>
    from tensorflow.python.framework import errors_impl as _impl
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\errors_impl.py"", line 30, in <module>
    from tensorflow.python.util import deprecation
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\util\deprecation.py"", line 25, in <module>
    from tensorflow.python.platform import tf_logging as logging
ImportError: cannot import name 'tf_logging' from 'tensorflow.python.platform' (C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\platform\__init__.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1101, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
    return f(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File ""C:\ProgramData\Anaconda3\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\ProgramData\Anaconda3\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\ProgramData\Anaconda3\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\ProgramData\Anaconda3\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 10, in <module>
    from tensorflow.python.eager import core as _core
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\core.py"", line 22, in <module>
    from tensorflow.python.framework import errors
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\errors.py"", line 22, in <module>
    from tensorflow.python.framework import errors_impl as _impl
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\errors_impl.py"", line 30, in <module>
    from tensorflow.python.util import deprecation
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\util\deprecation.py"", line 25, in <module>
    from tensorflow.python.platform import tf_logging as logging
ImportError: cannot import name 'tf_logging' from 'tensorflow.python.platform' (C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\platform\__init__.py)"
40555,TFLite General OpenGL delegate ,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

**System information**
- TensorFlow version (you are using): 2.2/master on Ubuntu 18.04
- Are you willing to contribute it (Yes/No): Yes, I have a working version on TF 2.2.

**Describe the feature and the current behavior/state.**
Deprecated GL delegate runs in the GL context attached to the calling thread, instead of initializing an EGL/GLES context upon preparation.           

**Will this change the current api? How?**
This change would allow builds to macro out all references to EGL/GLES in the deprecated gl_delegate package.  A build target ~""libgeneral_opengl.so"" would be added to the lite/delegates/gpu BUILD file.  Users would provide paths to the relevant OpenGL headers (glew, glad, gl3w...) and link flags in the BUILD file.  The GL context would be initialized outside of the TFLite API. 

**Who will benefit with this feature?**
Anyone looking to integrate TFLite into their OpenGL render pipeline, without having to deal with GLES/Android dependencies.  Particularly useful for Linux users looking to build plugins for other engines e.g. Unreal or Unity.  

**Any Other info.**
Perfectly understandable if this change is undesired, since simple GPU acceleration for Android is the only reason the GL delegate exists.  Asking here before PRing so I don't waste time merging into master from my 2.2 based branch.   "
40553,tf.io.matching_files hangs given a certain pattern,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): No 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
`tf.io.matching_files` hangs and does not terminate when passing `/*` or `/?`  in the beginning of `pattern` argument.

**Describe the expected behavior**
As far as `/*` or `/?` is not placed in the beginning, the function terminates with a proper error handling. I would expect a similar behavior for my input below. 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf

tf.io.matching_files('/*name',name=None)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40551,Tensorflow Roadmap README link broken,"Link to 'Tensorflow Roadmap' in README is broken: https://www.tensorflow.org/community/roadmap

This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
40550,AttributeError: type object 'TFLiteConverterV2' has no attribute 'from_keras_model_file',"I am having one TensorFlow Keras model ""model.h5"". I want to generate tflite from it. I am using the below-mentioned code for that. I am using tensorflow version '2.0.0' on Anaconda Spyder 3.7, 64 bit, windows10. Later on I want to convert this model for the google coral edge tpu. 

    import tensorflow as tf
    import numpy as np
    from tensorflow import lite

    dataset_dir = ""C:\\Users\\Ravi\\dataset""
    IMAGE_SIZE = 224
    saved_keras_model = ""C:\\Users\\Ravi\\model.h5""

    def representative_data_gen():
      dataset_list = tf.data.Dataset.list_files(dataset_dir + '/*/*')
      for i in range(100):
        image = next(iter(dataset_list))
        image = tf.io.read_file(image)
        image = tf.io.decode_jpeg(image, channels=3)
        image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])
        image = tf.cast(image / 255., tf.float32)
        image = tf.expand_dims(image, 0)
        yield [image]

    converter =  lite.TFLiteConverter.from_keras_model_file(saved_keras_model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    # This ensures that if any ops can't be quantized, the converter throws an error
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    # These set the input and output tensors to uint8
    converter.inference_input_type = tf.uint8
    converter.inference_output_type = tf.uint8
    # And this sets the representative dataset so we can quantize the activations
    converter.representative_dataset = representative_data_gen
    tflite_model = converter.convert()

    with open('mobilenet_v2_1.0_224_quant.tflite', 'wb') as f:
          f.write(tflite_model)

I am getting this kind of error.

    Traceback (most recent call last):

     File ""C:\Users\Ravi\tflite_model.py"", line 28, in <module>
        converter =  lite.TFLiteConverter.from_keras_model_file(saved_keras_model)

    AttributeError: type object 'TFLiteConverterV2' has no attribute 'from_keras_model_file'

What can be the problem? How can I solve this issue?"
40549,Installed Tensorflow-directml show no module named tensorflow,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
 import tensorflow as tf
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 1903
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  pip install tensorflow-directml==0.0.1.dev0
- TensorFlow version (use command below):
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

So the long waited Directml was released today, but it seems that the package wasn't compiled yet
, I installed through pypi, obviously that size of wheel is 6.4 KB, which isn't right
, should be about 200 MB or so.

**Describe the expected behavior**

Any schedule on when the proper wheels will be released? 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40548,Make keras.callbacks.Callback and tensorflow.keras.callbacks.Callback mutually compatible,"`tensorflow.keras.callbacks.Callback` has private methods [`_implements_train_batch_hooks`](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/callbacks.py#L739) etc which are [called](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/callbacks.py#L328) e.g. when the callback is used with `tensorflow.keras.models.Model.fit`.

`keras.callbacks.Callback` provides no such methods and so using it with e.g. `tensorflow.keras.models.Model.fit` results in `AttributeError: 'SomeClassExtendingCallback' object has no attribute '_implements_train_batch_hooks'`.

If those two versions of Keras aim to be compatible, then this should be fixed."
40547,TF 2.2 GPU memory usage regression on model.predict() with big inputs,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: Ubuntu 16.04
- TensorFlow installed from: PyPI
- TensorFlow version : v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.1
- CUDA/cuDNN version: 10.1
- GPU model and memory: NVIDIA Tesla M60, 8GB

**Describe the current behavior**

I created a 3D Unet which takes 192x192x192 inputs and outputs a segmentation of the same size. I did not train the network but tried passing dummy inputs to `model.predict()` instead. I'm getting an OOM error when I limit the available GPU memory to 5GB on an input of size (70, 192, 192, 192, 1) (`batch_size=1`). I don't get the same error on TF 2.1 with the same input size. In order for the script to work on 2.2, I need to increase available memory to 5.7GB.
The exception is raised repeatably at batch 47 of 70.
I can't see anything related in v2.2 changelog, which leads me to believe that this is a regression.

**Describe the expected behavior**
For `batch_size=1`, I expect the inputs to be transferred to GPU memory one by one, and the outputs to be transferred back to RAM sequentially. There should not be significant GPU memory usage differences between predicting on 1000 inputs and 100 inputs. There probably should be a buffer such that the next batch of prediction is not held up by GPU-RAM I/O, but a difference of 700MB is suspicious.
I could work around this by splitting the prediction and then concatenating it like so:
```
MAX_INPUT_SIZE = 47
pred1 = model.predict(test_input[:MAX_INPUT_SIZE], batch_size=1)
pred2 = model.predict(test_input[MAX_INPUT_SIZE:], batch_size=1)
```
but this should probably be done by TF, not the user. Am I seeing a feature or a bug? 

**Standalone code to reproduce the issue**
```python
import numpy as np
from tensorflow.keras import Input
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv3D, BatchNormalization, Activation, Layer, MaxPool3D, Conv3DTranspose, Concatenate

import tensorflow as tf


def limit_gpu_memory_use(limit=None):
    gpus = tf.config.experimental.list_physical_devices(""GPU"")
    for gpu in gpus:
        if limit is None:
            tf.config.experimental.set_memory_growth(gpu, True)
        else:
            tf.config.experimental.set_virtual_device_configuration(
                gpu, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=limit)]
                )


def test_big_model():
    # TF 2.1: 5000, TF 2.2: 5700
    limit_gpu_memory_use(5000)
    model = build_model()
    test_input = np.ones(shape=(70, 192, 192, 192, 1), dtype=np.int16)
    model.predict(test_input, verbose=1, batch_size=1)


def build_model():
    depth = 4
    n_base_filters = 8
    actfun = ""relu""

    skip_layers = []
    inputs = Input(shape=(192, 192, 192, 1))
    x = Conv3D(
        filters=n_base_filters,
        kernel_size=(3, 3, 3),
        activation=actfun,
        padding=""same"",
    )(inputs)

    x = BatchNormalization()(x)
    x = Conv3D(
        filters=n_base_filters * 2,
        kernel_size=(3, 3, 3),
        activation=actfun,
        padding=""same"",
    )(x)

    skip_layers.append(x)

    for i in range(1, depth):
        x = create_downsampling_block(input_layer=x, num_filters=n_base_filters * 2 ** i, actfun=actfun)
        skip_layers.append(x)

    for i in range(depth - 1, 0, -1):
        x = create_upsampling_block(
            input_layer=x,
            skip_input_layer=skip_layers[i - 1],
            num_filters=n_base_filters * 2 ** (i + 1),
            actfun=actfun,
        )

    x = Conv3D(filters=1, kernel_size=(1, 1, 1))(x)
    out = Activation(""sigmoid"", dtype=""float32"")(x)

    return Model(inputs=inputs, outputs=out)


def create_downsampling_block(input_layer: Layer, num_filters: int, actfun: str) -> Layer:
    x = MaxPool3D(pool_size=(2, 2, 2))(input_layer)
    for i in [1, 2]:
        x = Conv3D(
            filters=num_filters * i,
            kernel_size=(3, 3, 3),
            activation=actfun,
            padding=""same"",
        )(x)
    return x


def create_upsampling_block(input_layer: Layer, skip_input_layer: Layer, num_filters: int, actfun: str) -> Layer:
    x = Conv3DTranspose(filters=num_filters, kernel_size=(2, 2, 2), strides=(2, 2, 2))(input_layer)
    x = Concatenate()([skip_input_layer, x])
    for _ in range(2):
        x = Conv3D(
            filters=num_filters // 2,
            kernel_size=(3, 3, 3),
            activation=actfun,
            padding=""same"",
        )(x)

    return x

test_big_model()
```

**Other info / logs** 
[traceback.log](https://github.com/tensorflow/tensorflow/files/4793605/traceback.log)
"
40546,`tf.saved_model.save` attempts to compile __call__ even if `signatures` is not `None`,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Microsoft Windows 10 Enterprise
- TensorFlow installed from (source or binary): official pipy wheel
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.6

**Describe the current behavior**
Consider a model whose `call` method can not be decorated by `tf.function`. We want to save some methods of the model (but not the call) using `tf.saved_model.save`. So we pass `signatures` argument to the  `tf.saved_model.save` where we list the methods we want to save. In TF2.0 and TF2.1 this worked. 
In TF2.2 it fails as tensorflow seems to try to decorate `call` by `tf.function` anyway.

**Describe the expected behavior**
Same behaviour as in TF2.0 and TF2.1. Passing `signatures` argument to `tf.saved_model.save` should prevent compilation of other methods.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf


class SomeClass:
    def __init__(self, x):
        self.x = x

    def __repr__(self):
        return f""SomeClass({self.x})""


class MyModel(tf.keras.Model):
    def build(self, input_shape):
        self.a = tf.Variable(1.0, name=""a"")

    def serve(self, x):
        return x + self.a

    def call(self, x):
        """"""This method can't be decorated by `tf.function` because it returns an object that is not a Tensor.
        It should not matter, because we do not want to save it.
        """"""
        x = tf.cast(x, tf.float32)
        return SomeClass(x + self.a)


model = MyModel()
print(""Call the model in order to build it: "", model(4))

signatures = {""my_stuff"": tf.function(model.serve, input_signature=[tf.TensorSpec([None], tf.float32)])}
tf.saved_model.save(model, export_dir="""", signatures=signatures)
```
This code works in TF2.0 and TF2.1 but not in TF2.2.

**Other info / logs** 
Here is the traceback in TF2.2
```
Call the model in order to build it:  SomeClass(5.0)
Traceback (most recent call last):
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 543, in make_tensor_proto
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 543, in <listcomp>
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\util\compat.py"", line 87, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got SomeClass(Tensor(""my_model/add:0"", shape=(), dtype=float32))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 937, in convert
    x = ops.convert_to_tensor_or_composite(x)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\framework\ops.py"", line 1464, in convert_to_tensor_or_composite
    value=value, dtype=dtype, name=name, as_ref=False)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\framework\ops.py"", line 1503, in internal_convert_to_tensor_or_composite
    accepted_result_types=(Tensor, composite_tensor.CompositeTensor))
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\framework\ops.py"", line 1341, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 321, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 262, in constant
    allow_broadcast=True)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 300, in _constant_impl
    allow_broadcast=allow_broadcast))
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 547, in make_tensor_proto
    ""supported type."" % (type(values), values))
TypeError: Failed to convert object of type <class '__main__.SomeClass'> to Tensor. Contents: SomeClass(Tensor(""my_model/add:0"", shape=(), dtype=float32)). Consider casting elements to a supported type.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""bordel.py"", line 31, in <module>
    tf.saved_model.save(model, export_dir="""", signatures=signatures)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\saved_model\save.py"", line 951, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\saved_model\save.py"", line 1012, in _build_meta_graph
    signature_serialization.validate_saveable_view(checkpoint_graph_view)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\saved_model\signature_serialization.py"", line 268, in validate_saveable_view
    saveable_view.root):
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\saved_model\save.py"", line 108, in list_dependencies
    extra_dependencies = self.list_extra_dependencies(obj)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\saved_model\save.py"", line 137, in list_extra_dependencies
    self._serialization_cache)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 2746, in _list_extra_dependencies_for_serialization
    .list_extra_dependencies_for_serialization(serialization_cache))
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\keras\saving\saved_model\base_serialization.py"", line 74, in list_extra_dependencies_for_serialization
    return self.objects_to_serialize(serialization_cache)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\keras\saving\saved_model\layer_serialization.py"", line 73, in objects_to_serialize
    serialization_cache).objects_to_serialize)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\keras\saving\saved_model\layer_serialization.py"", line 92, in _get_serialized_attributes
    serialization_cache)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\keras\saving\saved_model\model_serialization.py"", line 47, in _get_serialized_attributes_internal
    default_signature = save_impl.default_save_signature(self.obj)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\keras\saving\saved_model\save_impl.py"", line 203, in default_save_signature
    fn.get_concrete_function()
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\eager\def_function.py"", line 959, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\eager\def_function.py"", line 865, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\eager\def_function.py"", line 506, in _initialize
    *args, **kwds))
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\eager\function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\eager\function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\eager\function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 986, in func_graph_from_py_func
    expand_composites=True)
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\util\nest.py"", line 617, in map_structure
    structure[0], [func(*x) for x in entries],
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\util\nest.py"", line 617, in <listcomp>
    structure[0], [func(*x) for x in entries],
  File ""D:\git\workon_hrab2\venv_tf_22\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 943, in convert
    (str(python_func), type(x)))
TypeError: To be compatible with tf.contrib.eager.defun, Python functions must return zero or more Tensors; in compilation of <function trace_model_call.<locals>._wrapped_model at 0x00000278D27BE828>, found return
 value of type <class '__main__.SomeClass'>, which is not a Tensor.
```"
40544,Keras does not wait for multiprocessing pool to finish,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 2.X
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: 1060ti , 6 gb

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

Keras does not wait until the multiprocessing pool is done. I am using the pool function from the python built in multiprocessing library.

**Describe the expected behavior**

I want to do my multiprocessing pool, close it, and then use keras. 
"
40541,how to get image's shape using tf.data map,"my dataset is large and the image is irregular. I need to pad the image according to different width and length, but I can't get the image's shape using image.shape. The shape is [None, None, 3]."
40539,Feature request: facemesh example for tensorflow lite," Facemesh example for tensorflow lite

To get the result of facemesh we need first to detect face using blazefaceBut how to use the result of blazeface estimation as the input of facemesh model, it is not very clear.
Can we have a facemesh example for tensorflow lite ?"
40538,[TF2.2] Build libtensorflow_cc.so for C++ APIs,"**System information**:
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed source: source
- TensorFlow version: 2.2.0 stable
- Python version: python3
- Bazel version: using Bazelisk with Bazel 2.0.0 version as required from tf-2.2.0
- GCC/Compiler version (if compiling from source): GCC-8
- CUDA/cuDNN version: No CUDA (for the moment)

**What I have done**:
- Got tensorflow from github:
```
git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git
cd tensorflow
git checkout v2.2.0
```

- Installed and setted up Bazelisk:
( Using this guide: https://gist.github.com/philwo/f3a8144e46168f23e40f291ffe92e63c )
```
$ sudo curl -Lo /usr/local/bin/bazel https://github.com/bazelbuild/bazelisk/releases/download/v1.1.0/bazelisk-linux-amd64
$ sudo chmod +x /usr/local/bin/bazel
```

`$ grep -r _TF_MAX_BAZEL_VERSION .`
`./configure.py:_TF_MAX_BAZEL_VERSION = '2.0.0'`

```
$ echo '2.0.0' > .bazelversion
$ bazel version
```

- Start building tensorflow with Bazel:
```
$ ./configure

sudo bazel --host_jvm_args=-Xmx28G build --jobs=8 --config=monolithic --config=v2 --config=opt --verbose_failures //tensorflow:libtensorflow_cc.so

sudo bazel --host_jvm_args=-Xmx28G build --jobs=8 --config=monolithic --config=v2 --config=opt --verbose_failures //tensorflow:libtensorflow_framework.so
```

As mentioned here: https://itnext.io/how-to-use-your-c-muscle-using-tensorflow-2-0-and-xcode-without-using-bazel-builds-9dc82d5e7f80 I looked for `tensorflow/contrib/makefile/download_dependencies.sh` but there is no tensorflow/contrib, since v2.1.0.

- Copied libraries and headers:
```
# cp -rfvdp tensorflow/bazel-bin/tensorflow/*.so* /opt/tensorflow/lib
# sudo find . -name ""*.h*"" | sudo cpio -updm /opt/tpt/tensorflow/include/tensorflow
```
- Created first dummy example:
```
#include <stdlib.h>
#include <stdio.h>
#include ""tensorflow/c/c_api.h""

#include <tensorflow/core/platform/env.h>
#include <tensorflow/core/public/session.h>
#include <iostream>
using namespace std;
using namespace tensorflow;

int main() {return 0;}
```

- Trying to compile:
`gcc -O3 -o test -I /opt/tensorflow/include main.cpp -L /opt/tensorflow/lib -l tensorflow_cc`

- Error:
```
In file included from /opt/tpt/tensorflow_cpp/include/tensorflow/core/platform/types.h:22,
                 from /opt/tpt/tensorflow_cpp/include/tensorflow/core/platform/env_time.h:20,
                 from /opt/tpt/tensorflow_cpp/include/tensorflow/core/platform/env.h:26,
                 from main.cpp:5:
/opt/tpt/tensorflow_cpp/include/tensorflow/core/platform/tstring.h:29:10: fatal error: absl/strings/string_view.h: No such file or directory
 #include ""absl/strings/string_view.h""
          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
```"
40537,Tensorflow tf function with numpy hyper-parameters and numpy calls,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.2
- Python version: 3.6.8
- CUDA/cuDNN version: happens on CPU as well


**Describe the current behavior**

I am trying to build a `tf.function` which has numpy hyper-parameters and performs some numpy operations.
I currently am getting the following error:

```
NotImplementedError: in user code:

    <ipython-input-2-7da02a23bf62>:7 my_function  *
        range_array = np.arange(range_lim)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:749 __array__  **
        "" array."".format(self.name))

    NotImplementedError: Cannot convert a symbolic Tensor (strided_slice:0) to a numpy array.
```

**Describe the expected behavior**

I would like `tf.function` to be able to handle functions with numpy code in them.

**Standalone code to reproduce the issue**
My current minimal reproducible example is the following ([colab link](https://colab.research.google.com/drive/1VWkX7sQP4QKd52qb4S1pCZXAJPjuWYpk?usp=sharing)):

```python
import numpy as np
import tensorflow as tf

@tf.function
def my_function(params):
  np_array = params['np_array']
  my_list = []
  for i in range(2):
    range_lim = np_array[i]
    range_array = np.arange(range_lim)
    my_list.append(range_array)
  # then do other things

params = {'np_array': np.array([4, 5])}

my_function(params)
```

**Other info / logs**
When I look at the autograph generated code, using `print(tf.autograph.to_code(my_function.python_function))`, I see that the pure-numpy call `range_array = np.arange(range_lim)` is converted:

```python
range_array = ag__.converted_call(np.arange, (range_lim,), None, fscope)
```
I think this is where the bug is coming from: autograph is called on a line which shouldn't be transformed."
40536,Combining multiple savedmodels into one SavedModel,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below):
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

**Describe the expected behavior**
I was able to combine multiple tf estimator savedmodels (linear classifiers) into one and then serve that final model instead of serving multiple models. I assumed the same process would work for boosted trees saved models.

**Describe the current behavior**

But when it comes to boosted trees, i am experiencing the following error :

NotFoundError:  Resource localhost/boosted_trees/QuantileAccumulator/_load_2153_load_11463/N10tensorflow34BoostedTreesQuantileStreamResourceE does not exist.
	 [[node import/boosted_trees/BoostedTreesQuantileStreamResourceGetBucketBoundaries_1 (defined at <ipython-input-136-92a81f76cf4e>:2) ]] [Op:__inference_pruned_12525]

Function call stack:
pruned

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Model1, Model2 are my two loaded linear classifer estimators on the same feature set but for different cities; replacing them with boosted trees estimators yields the error 

# 
class CombinedModel(tf.Module):
    def __init__(self):
        self.model1 = model1
        self.model2 = model2
    @tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.float32),
                                 tf.TensorSpec(shape=[None], dtype=tf.float32),
                                 tf.TensorSpec(shape=[None], dtype=tf.string)])
    def __call__(self, feature1, feature2, city):
        input1 = {
            ""feature1"" : feature1,
            ""feature2"": feature2
        }
        print(type(allotment_eta))
        city_chennai = tf.constant([""chennai""])
        city_mumbai = tf.constant([""mumbai""])

        # IF CITY IS CHENNAI
        if tf.equal(city[0],city_chennai):
            inference_func = self.model1.signatures[""predict""]
            predictions = inference_func(**({""feature1"": feature1, ""feature2"": feature2}))        
            return predictions['probabilities']
        # ELSE CITY IS MUMBAI
        else :
            inference_func = self.model2.signatures[""predict""]
            predictions = inference_func(**({""feature1"": feature1, ""feature2"": feature2}))        
            return predictions['probabilities']


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40535,Combining multiple SavedModels into one SavedModel,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
I was able to combine multiple tf estimator savedmodels (linear classifiers) into one and then serve that final model instead of serving multiple models. But when it comes to boosted trees, i am experiencing an the following error :

NotFoundError:  Resource localhost/boosted_trees/QuantileAccumulator/_load_2153_load_11463/N10tensorflow34BoostedTreesQuantileStreamResourceE does not exist.
	 [[node import/boosted_trees/BoostedTreesQuantileStreamResourceGetBucketBoundaries_1 (defined at <ipython-input-136-92a81f76cf4e>:2) ]] [Op:__inference_pruned_12525]

Function call stack:
pruned
**Will this change the current api? How?**

**Who will benefit with this feature?**
Serving on port gives enables easier maintenance 
**Any Other info.**
"
40534,Need: Tensorflow for Unity plugin,"
**System information**
- TensorFlow version (you are using): 2.0.1

**Feature requested**
-Tensorflow for Unity plugin needed. 

For three reasons:

1.Although tensorflow lite can be used to build Android or IOS apps, developer prefer to use cross-platform IDEs so they only need to adapt and develop once.

2. Native Andoird (Android studio) or IOS (Xcode) are not really designed for 3D apps. For 3D developers, it is hard to create 3D scene and manipulate them in Android studio or Xcode. On the other hand, more and more AI  module in tensorflow can now show us 3d informaitons from 2D image (facemesh, hand pose, etc.), a 3d based IDE + tensorflow would be a better solution to use these 3d information in real productive apps.

3. There is no official release of Unity Tensorflow plugin, I tried some no-official ones, some of them can not use GPUs, some of them are full of bugs. Developers are strugglling finding a right version. If we have an official version, a large number of user would be increased.

"
40533,how to build no stripped tensorflow lite so,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): mac os
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.14
- Python version: 2.7
- Installed using virtualenv? pip? conda?:no
- Bazel version (if compiling from source): 0.25.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: no
- GPU model and memory: no



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

bazel build  --strip=never -c opt --fat_apk_cpu=arm64-v8a,armeabi-v7a \
  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \
  //tensorflow/lite/java:tensorflow-lite

i want build an no stripped so so that i can investigate the crash from user, even i add the '-strip=never', the so is also stripped

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
40532,segfault during tf.image.non_max_suppression_padded,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):  v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Segmentation fault occurs in c++ when passing a large value for `max_output_size`  and `True` for `pad_to_max_output_size`.

**Describe the expected behavior**
No segmentation fault. I would expect a proper error handling exception if necessary rather than a segfault.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf

boxes = [[4.0, 6.0, 3.0, 6.0],
       [2.0, 1.0, 5.0, 4.0],
       [9.0, 0.0, 9.0, 9.0]]
scores = [5.0, 6.0, 5.0]
max_output_size = 1000000000000

tf.image.non_max_suppression_padded(
   boxes, scores, max_output_size, iou_threshold=0.5,
    score_threshold=float('-inf'), pad_to_max_output_size=True, name=None)
)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40530,Attribute Error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.2.0
- Python version: 3.6.5
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: v11
- GPU model and memory: 

I am trying to run the following code
```
import tensorflow as tf
print(""Num GPUs Avaiable: "", len(tf.config.experimental.list_physical_devices('GPU')))
```

I get the error

> AttributeError: module 'tensorflow' has no attribute 'config'


I tried the following 

```
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
print(""Num GPUs Avaiable: "", len(tf.config.experimental.list_physical_devices('GPU')))

```
I got the error

> ModuleNotFoundError: No module named 'tensorflow.compat'


Edit1: After uninstalling and reinstalling tensorflow, now i'm getting the error:

> The Kernal appears to have died. It will restart automatically


I cannot understand what I'm doing wrong, I'm using jupyter notebook

for reference, if there is an issue with the versions
`pip list`  

> Package                            Version
> ---------------------------------- -------------------
> absl-py                            0.9.0
> alabaster                          0.7.12
> anaconda-client                    1.7.2
> anaconda-navigator                 1.9.12
> anaconda-project                   0.8.3
> argh                               0.26.2
> asn1crypto                         1.3.0
> astroid                            2.4.1
> astropy                            4.0.1.post1
> astunparse                         1.6.3
> atomicwrites                       1.4.0
> attrs                              19.3.0
> autopep8                           1.4.4
> Babel                              2.8.0
> backcall                           0.1.0
> backports.functools-lru-cache      1.6.1
> backports.shutil-get-terminal-size 1.0.0
> backports.tempfile                 1.0
> backports.weakref                  1.0.post1
> bcrypt                             3.1.7
> beautifulsoup4                     4.9.0
> bitarray                           1.2.2
> bkcharts                           0.2
> bleach                             1.5.0
> bokeh                              2.0.2
> boto                               2.49.0
> Bottleneck                         1.3.2
> cachetools                         4.1.0
> certifi                            2020.4.5.1
> cffi                               1.14.0
> chardet                            3.0.4
> click                              7.1.2
> cloudpickle                        1.4.1
> clyent                             1.2.2
> colorama                           0.4.3
> comtypes                           1.1.7
> conda                              4.8.3
> conda-build                        3.10.5
> conda-package-handling             1.7.0
> conda-verify                       3.4.2
> contextlib2                        0.6.0.post1
> contextvars                        2.4
> cryptography                       2.9.2
> cycler                             0.10.0
> Cython                             0.29.17
> cytoolz                            0.10.1
> dask                               2.17.2
> decorator                          4.4.2
> defusedxml                         0.6.0
> diff-match-patch                   20181111
> distributed                        2.17.0
> docutils                           0.16
> entrypoints                        0.3
> et-xmlfile                         1.0.1
> fastcache                          1.1.0
> filelock                           3.0.12
> flake8                             3.8.2
> Flask                              1.1.2
> fsspec                             0.7.4
> future                             0.18.2
> gast                               0.3.3
> gevent                             1.4.0
> glob2                              0.7
> google-auth                        1.16.1
> google-auth-oauthlib               0.4.1
> google-pasta                       0.2.0
> greenlet                           0.4.15
> grpcio                             1.29.0
> h5py                               2.10.0
> HeapDict                           1.0.1
> html5lib                           0.9999999
> hypothesis                         5.11.0
> idna                               2.9
> imageio                            2.8.0
> imagesize                          1.2.0
> immutables                         0.11
> importlib-metadata                 1.6.1
> intervaltree                       3.0.2
> ipykernel                          5.1.4
> ipython                            7.13.0
> ipython-genutils                   0.2.0
> ipywidgets                         7.5.1
> isort                              4.3.21
> itsdangerous                       1.1.0
> jdcal                              1.4.1
> jedi                               0.15.2
> Jinja2                             2.11.2
> joblib                             0.15.1
> json5                              0.9.5
> jsonschema                         3.2.0
> jupyter                            1.0.0
> jupyter-client                     6.1.3
> jupyter-console                    6.1.0
> jupyter-core                       4.6.3
> jupyterlab                         1.2.6
> jupyterlab-server                  1.1.4
> Keras-Preprocessing                1.1.2
> keyring                            21.1.1
> kiwisolver                         1.2.0
> lazy-object-proxy                  1.4.3
> libarchive-c                       2.9
> llvmlite                           0.32.1
> locket                             0.2.0
> lxml                               4.5.0
> Markdown                           3.2.2
> MarkupSafe                         1.1.1
> matplotlib                         3.1.3
> mccabe                             0.6.1
> menuinst                           1.4.16
> mistune                            0.8.4
> mkl-fft                            1.0.15
> mkl-random                         1.1.1
> mkl-service                        2.3.0
> mock                               4.0.2
> more-itertools                     8.3.0
> mpmath                             1.1.0
> msgpack                            1.0.0
> multipledispatch                   0.6.0
> navigator-updater                  0.2.1
> nbconvert                          5.6.1
> nbformat                           5.0.6
> networkx                           2.4
> nltk                               3.4.5
> nose                               1.3.7
> notebook                           6.0.3
> numba                              0.49.1
> numexpr                            2.7.1
> numpy                              1.18.5
> numpydoc                           0.9.2
> oauthlib                           3.1.0
> olefile                            0.46
> openpyxl                           3.0.3
> opt-einsum                         3.2.1
> packaging                          20.3
> pandas                             1.0.3
> pandocfilters                      1.4.2
> paramiko                           2.7.1
> parso                              0.5.2
> partd                              1.1.0
> path                               13.1.0
> pathlib2                           2.3.5
> pathtools                          0.1.2
> patsy                              0.5.1
> pep8                               1.7.1
> pexpect                            4.8.0
> pickleshare                        0.7.5
> Pillow                             7.1.2
> pip                                20.1.1
> pkginfo                            1.5.0.1
> pluggy                             0.13.1
> ply                                3.11
> prometheus-client                  0.7.1
> prompt-toolkit                     3.0.5
> protobuf                           3.12.2
> psutil                             5.7.0
> py                                 1.8.1
> pyasn1                             0.4.8
> pyasn1-modules                     0.2.8
> pycodestyle                        2.6.0
> pycosat                            0.6.3
> pycparser                          2.20
> pycrypto                           2.6.1
> pycurl                             7.43.0.5
> pydocstyle                         4.0.1
> pyflakes                           2.2.0
> Pygments                           2.6.1
> pylint                             2.5.2
> PyNaCl                             1.3.0
> pyodbc                             4.0.0-unsupported
> pyOpenSSL                          19.1.0
> pyparsing                          2.4.7
> pyreadline                         2.1
> pyrsistent                         0.16.0
> PySocks                            1.7.1
> pytest                             5.4.2
> pytest-arraydiff                   0.3
> pytest-astropy                     0.8.0
> pytest-astropy-header              0.1.2
> pytest-doctestplus                 0.7.0
> pytest-openfiles                   0.5.0
> pytest-remotedata                  0.3.2
> python-dateutil                    2.8.1
> python-jsonrpc-server              0.3.4
> python-language-server             0.31.9
> pytz                               2020.1
> PyWavelets                         1.1.1
> pywin32                            227
> pywin32-ctypes                     0.2.0
> pywinpty                           0.5.7
> PyYAML                             5.3.1
> pyzmq                              18.1.1
> QDarkStyle                         2.8.1
> QtAwesome                          0.7.0
> qtconsole                          4.7.4
> QtPy                               1.9.0
> requests                           2.23.0
> requests-oauthlib                  1.3.0
> rope                               0.17.0
> rsa                                4.0
> Rtree                              0.9.4
> ruamel-yaml                        0.15.87
> scikit-image                       0.16.2
> scikit-learn                       0.22.1
> scipy                              1.4.1
> seaborn                            0.10.1
> Send2Trash                         1.5.0
> setuptools                         47.1.1.post20200604
> simplegeneric                      0.8.1
> singledispatch                     3.4.0.3
> six                                1.15.0
> snowballstemmer                    2.0.0
> sortedcollections                  1.1.2
> sortedcontainers                   2.1.0
> soupsieve                          2.0.1
> Sphinx                             3.0.4
> sphinxcontrib-applehelp            1.0.2
> sphinxcontrib-devhelp              1.0.2
> sphinxcontrib-htmlhelp             1.0.3
> sphinxcontrib-jsmath               1.0.1
> sphinxcontrib-qthelp               1.0.3
> sphinxcontrib-serializinghtml      1.1.4
> sphinxcontrib-websupport           1.2.1
> spyder                             4.1.3
> spyder-kernels                     1.9.1
> SQLAlchemy                         1.3.17
> statsmodels                        0.11.1
> sympy                              1.5.1
> tables                             3.5.1
> tblib                              1.6.0
> tensorboard                        2.2.2
> tensorboard-plugin-wit             1.6.0.post3
> tensorflow                         2.2.0
> tensorflow-estimator               2.2.0
> termcolor                          1.1.0
> terminado                          0.8.3
> testpath                           0.4.4
> toml                               0.10.0
> toolz                              0.10.0
> tornado                            6.0.4
> tqdm                               4.46.0
> traitlets                          4.3.3
> typed-ast                          1.4.1
> typing-extensions                  3.7.4.1
> ujson                              1.35
> unicodecsv                         0.14.1
> urllib3                            1.25.8
> watchdog                           0.10.2
> wcwidth                            0.1.9
> webencodings                       0.5.1
> Werkzeug                           1.0.1
> wheel                              0.34.2
> widgetsnbextension                 3.5.1
> win-inet-pton                      1.1.0
> win-unicode-console                0.5
> wincertstore                       0.2
> wrapt                              1.12.1
> xlrd                               1.2.0
> XlsxWriter                         1.2.9
> xlwings                            0.19.4
> xlwt                               1.3.0
> xmltodict                          0.12.0
> yapf                               0.28.0
> zict                               2.0.0
> zipp                               3.1.0
> "
40527,Can't load tf 2.1 model trained on ai platform,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: Ubuntu 18.04 and MacOSX 10.15.5
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.1.0 and 2.2.0
- Python version: 3.7 and 3.6

**Describe the current behavior**
Can't load a model locally with tensorflow version 2.1. The model was trained on ai platform with [runtime version 2.1](https://cloud.google.com/ai-platform/training/docs/runtime-version-list#2.1) and saved using `tf.keras.callbacks.ModelCheckpoint(..., save_weights_only=False)`. It is possible to load the model locally with tensorflow version 2.2.
It is also possible to build the model locally and use `load_weights`.

```python
>>> import tensorflow as tf
>>> print(tf.__version__)
2.2.0
>>> tf.keras.models.load_model('/Users/fjp/projects/keras-job-dir/model_checkpoint/model.32-0.00/')
2020-06-17 00:59:39.651511: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-17 00:59:39.699145: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faa9f631160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-17 00:59:39.699171: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
<tensorflow.python.keras.engine.training.Model object at 0x12e9ceb10>
```

Using tf version 2.1 results in `KeyError: 0`:

```python
>>> import tensorflow as tf
>>> print(tf.__version__)
2.1.0
>>> tf.keras.models.load_model('/Users/fjp/projects/keras-job-dir/model_checkpoint/model.32-0.00/')
2020-06-17 01:30:15.614749: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-17 01:30:15.628231: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc502c878b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-17 01:30:15.628254: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/fjp/projects/venvtf/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 150, in load_model
    return saved_model_load.load(filepath, compile)
  File ""/Users/fjp/projects/venvtf/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 89, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""/Users/fjp/projects/venvtf/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 552, in load_internal
    export_dir)
  File ""/Users/fjp/projects/venvtf/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 118, in __init__
    super(KerasObjectLoader, self).__init__(*args, **kwargs)
  File ""/Users/fjp/projects/venvtf/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 121, in __init__
    self._load_all()
  File ""/Users/fjp/projects/venvtf/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 239, in _load_all
    node, setter = self._recreate(proto)
  File ""/Users/fjp/projects/venvtf/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 322, in _recreate
    return factory[kind]()
  File ""/Users/fjp/projects/venvtf/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 309, in <lambda>
    ""user_object"": lambda: self._recreate_user_object(proto.user_object),
  File ""/Users/fjp/projects/venvtf/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 328, in _recreate_user_object
    return self._recreate_base_user_object(proto)
  File ""/Users/fjp/projects/venvtf/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 216, in _recreate_base_user_object
    return revived_cls._init_from_metadata(metadata)  # pylint: disable=protected-access
  File ""/Users/fjp/projects/venvtf/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 297, in _init_from_metadata
    revived_obj = cls(**init_args)
  File ""/Users/fjp/projects/venvtf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_layer.py"", line 86, in __init__
    batch_size = batch_input_shape[0]
KeyError: 0
```



**Describe the expected behavior**
Loading a model trained on ai platform with runtime version 2.1 should be possible to load locally with tensorflow version 2.1 and its corresponding tf.keras version. tf version 2.2 shouldn't be required to load the model.

**Other info / logs** Include any logs or source code that would be helpful to
Here is the [link](https://drive.google.com/drive/folders/1CZwwfUV0uI3bGqi2b5NAUw5RlUoA_ZLV?usp=sharing) to the model trained on ai platform (runtime version 2.1). For me it is possible to load it locally with tensorflow 2.2 but not with 2.1. 



"
40525,SavedModel generates different probabilities than Estimator model It is exported from for RNNClassifier,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Catalina 10.15.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): b'v1.13.2-5-g04256c89d8' 1.13.2
- Python version: 3.6.10
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
For a tf.contrib.estimator.RNNClassifier estimator model, the estimator produces different probabilities when making predictions than the same model when exported to a SavedModel and making predictions (both using Serving and locally). When using the same code, except the estimator is changed to a DNNClassifier (and tf.contrib.feature_column.sequence_categorical_column_with_identity is changed to tf.feature_column.categorical_column_with_identity for feature_column), the SavedModel produces the same probabilities as expected. 

**Describe the expected behavior**
The SavedModel should generate the same probability as the estimator model it is generated from for any sample. 

**Standalone code to reproduce the issue**
Jupyter notebooks + small example datasets are provided in this repo: https://github.com/linbrian/tf_1.13_rnn_classifier_bug/tree/master


"
40524,"Building binaries for Arduino fails, fatal error: PDM.h","@tensorflow/micro

**System information**
- Ubuntu 20.04 x86_64
- TensorFlow installed from source:
- Tensorflow version : 389405a77946410400ed410246e4cc7257802dde
- Target platform: Arduino Nano 33

Documentation [here](https://www.tensorflow.org/lite/microcontrollers/library) under Build binaries heading suggest that a binary build can be initiated with a call as follows:

```
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=<target> <project_name>_bin
```
Therefore a simple call as follows should work or need specific architecture to run to success.
```
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=arduino micro_speech_bin
```

However, as the required `PDM.h` Arduino library is not in the source tree, when compiling micro_speech for Arduino, this fails with the error.

```
tensorflow/lite/micro/examples/micro_speech/arduino/audio_provider.cc:39:10: fatal error: PDM.h: No such file or directory
   39 | #include ""PDM.h""
      |          ^~~~~~~
```
Supported targets and target architectures are not documented anywhere I have found.

Furthermore, the `Makefile.inc` in the arduino folder `tensorflow/lite/micro/examples/micro_speech/arduino` contains a reference to 'sparkfun_edge' instead of 'arduino' the following:

```
ifeq ($(TARGET),$(filter $(TARGET),arduino))

MICRO_SPEECH_SRCS += \
	tensorflow/lite/micro/examples/micro_speech/sparkfun_edge/audio_provider.cc \
	tensorflow/lite/micro/examples/micro_speech/sparkfun_edge/command_responder.cc

endif

```"
40523,High memory use / leak in model.fit,"I have an issue with a high memory uses, from this simple code sample. (link [Test.py](https://gist.github.com/davsklaus/6764bb3cf90841ce57d3658f83e14fa7)

````
import tensorflow as tf
from tensorflow.keras import layers
import time, os, gc
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import SGD, Adam
import numpy as np

os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
print(tf.version.VERSION)

X = np.random.random((1119440, 100, 12)).astype(dtype=np.float32)
Y = np.random.random((1119440,)).astype(dtype=np.float32)
X_val = np.zeros( ( 300000, 100, 12), dtype=np.float32)
Y_val = np.zeros( (X_val.shape[0]), dtype=np.float32)

inputs = Input((100,12))
outputs = layers.Dense(1)(inputs)
model = Model(inputs=inputs, outputs=outputs, name='my_model')

model.compile(optimizer='SGD', loss = 'MSLE', metrics=['MSE'])
print(model.summary())

model.fit(X,Y, batch_size=32, verbose=1, shuffle=True, epochs=20, validation_data=(X_val,Y_val))

````
**For each epoch the the memory consumption inc with 1GB**, And after 20 epoch my system run out of memory.
I don't know if it a true memory leak, because gc.collect are able to collect a large portion of it.

I have localized the issue to be related to ""validation_data=(X_val,Y_val)"" 
The memory uses are stable if i replace the line with ""model.fit(X,Y, batch_size=32, verbose=1, shuffle=True, epochs=20)""

I can see there are reported other issues with use of generators, but in this case X_val and Y_val are simple numpy arrary.

Tested with this docker file  
    FROM tensorflow/tensorflow:2.2.0-jupyter 
    COPY test.py /tmp/test.py 
    CMD python3 /tmp/test.py 


Same result if I uses tensorflow/tensorflow:lastest

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 20.04):
- TensorFlow installed from (source or binary): docker tensorflow/tensorflow:2.2.0-jupyter
- TensorFlow version (use command below): 2.2.0
- Python version: 3
- Tested on a PC with 16GB of physical mem and 10GB of swap space 
"
40521,TensorFlowLiteSwift nightly build running 40 times slower than stable release build (on iPhone),"**System information**
   - Using TensorFlowLiteSwift iOS ObjectDetection example project
   - OS Platform and Distribution: iOS 13.5.1
   - Mobile device: iPhone 11 and other older iPhones
   - TensorFlow installed from binary
   - TensorFlow version: TensorFlowLiteSwift 0.0.1-nightly20200611

**Describe the current behavior**
   - With nightly build, we see 3330ms inference times

**Describe the expected behavior**
   - With stable release build, we see 80ms inference times

**Steps to reproduce the issue**
   1. Clone the TensorFlow Lite ObjectDetection iOS example repo
   2. Run and see inferences averaging 80ms on iPhone 11 (up to 250ms on older iPhones)
   3. Edit podfile, changing:
         pod 'TensorFlowLiteSwift'
      to
         pod 'TensorFlowLiteSwift', '-> 0.0.1-nightly'
   4. pod update
   5. Run and see inferences averaging 3330ms on iPhone 11 (up to 9000ms on older iPhones)
"
40519,Tensorflow lite v1 converter not correctly quantizing model (tf 2.2.0),"**System information**
- OS Platform and Distribution: Ubuntu 18.04.4 LTS
- TensorFlow installed using pip, version 2.2.0

**Python Code**

```
converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(
        ""mobilenet_v2_quantized/tflite_graph.pb"", ['normalized_input_image_tensor'],
        ['TFLite_Detection_PostProcess:0','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'],
        input_shapes={'normalized_input_image_tensor': [1, 300, 300, 3]})
converter.inference_type = tf.compat.v1.lite.constants.QUANTIZED_UINT8
converter.quantized_input_stats = {'normalized_input_image_tensor' : (128, 128)}
converter.change_concat_input_ranges = False
converter.allow_custom_ops = True
model = converter.convert()
open(""converted_model.tflite"", ""wb"").write(model)```
```

# Issue:

This code successfully produces a tflite flatbuffer, but the flatbuffer does not appear to be quantized correctly. When I attempt to compile the resulting model using Google's edgetpu_compiler tool, I encounter the following error:

```
Edge TPU Compiler version 2.1.302470888
Invalid model: converted_model.tflite
Model not quantized
```
The input model is SSD_mobilenet_v2_quantized, available [here](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz).
"
40518,Performance difference of TFlite in Android and iOS (model with quantization),"I've trained a model to detect custom objects to be used in mobile devices (Android and iOS), my code is based in the tensorflow's examples for [iOS](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/ios) and [Android](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android). During my tests in pyshical devices (iPad 6th gen and Xiaomi RedMi Note 7) I've been noticing a difference of performance on Android app and iOS app.

Some examples of performance (number of objects detected):
IMG - iOS - Android
img1 - 57 - 74
img2 - 9 - 33
img3 - 43 - 78
img4 - 17 - 25

The real number of objects is a bit more than Android's result.

I'm using the **ssd_mobilenet_v2_quantized_coco** from the [tensorflow model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) and **tensorflow-v1.14**.

I'm using [this class](https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/android/app/src/main/java/org/tensorflow/lite/examples/detection/tflite/TFLiteObjectDetectionAPIModel.java) in the Android version, and [this equivalent one](https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/ios/ObjectDetection/ModelDataHandler/ModelDataHandler.swift) in the iOS version, both without any modification from the ones provided by Tensorflow.

**My question is**: What should I investigate to know the reason of the performance difference and fix it? My model should give the same result for the customer in both mobile platforms.

If it's something unclear please let me know, any help would be great. Thanks!"
40517,for loop in map_fn within tf.function is very slow compared to using while_loop counterpart,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10 2004 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1, 7,6
- GPU model and memory: 1650Ti

**Describe the current behavior**

Code 1 runs much slow than Code 2 (71s seconds vs 11s), but from my understanding in Tensorflow documentation, Code 1 and Code 2 should be effectively the same (tf.function will turn the for loop into `while_loop` if the loop use Tensor but apparently not the case here). Moreover Code 2 will run much faster (~1s) on CPU (9750H, 1650Ti), not sure if that is expected tho. Code 3 using for loop and for loop to replace `map_fn` completed in 164s which is the slowest among the three which is expected.

*Update:* This behavior is not observed in tf2.1.0, code 1/2/3 completed in similar amount of time (11ish seconds)

**Describe the expected behavior**

Code 1 and Code 2 runs as fast as each other.

**Standalone code to reproduce the issue**

Code 1:
```python3
import time
import tensorflow as tf

@tf.function
def odeint_external(tensor):
    finished_user_t_ii = 0
    x = tensor[0]
    t = tensor[1]
    
    # array to store the result
    result = tf.TensorArray(dtype=tf.float32, size=t.shape[0])
    result = result.write(0, x)

    i = tf.constant(0, dtype=tf.int32)
    for _t in t[1:]:
        i = i+1
        result = result.write(i, tf.stack([tf.cos(_t), tf.sin(_t)]))

    return result.stack(), t


@tf.function
def parallelized_map_fn(tensor):
    return tf.map_fn(odeint_external, tensor)


# warm up
result = parallelized_map_fn((tf.random.normal((50, 2), 0, 1), tf.random.normal((50, 10000), 0, 1)))

start_t = time.time()
result = parallelized_map_fn((tf.random.normal((50, 2), 0, 1), tf.random.normal((50, 10000), 0, 1)))
print(time.time()-start_t)
```

Code 2:
```python3
import time
import tensorflow as tf

@tf.function
def odeint_external(tensor):
    finished_user_t_ii = 0
    x = tensor[0]
    t = tensor[1]
    
    # array to store the result
    result = tf.TensorArray(dtype=tf.float32, size=t.shape[0])
    result = result.write(0, x)

    i = tf.constant(1, dtype=tf.int32)
    cond = lambda i, _t, r: i < 9999
    body = lambda i, _t, r: (i+1, _t, r.write(i, tf.stack([tf.cos(_t[i]), tf.sin(_t[i])])))
    result = tf.while_loop(cond=cond, body=body, loop_vars=(i, t[1:], result))
    
    return result[2].stack(), t

@tf.function
def parallelized_map_fn(tensor):
    return tf.map_fn(odeint_external, tensor, parallel_iterations=1)

# warm up
result = parallelized_map_fn((tf.random.normal((50, 2), 0, 1), tf.random.normal((50, 10000), 0, 1)))

start_t = time.time()
result = parallelized_map_fn((tf.random.normal((50, 2), 0, 1), tf.random.normal((50, 10000), 0, 1)))
print(time.time()-start_t)
```

Code 3:
```python
import time
import tensorflow as tf

@tf.function
def odeint_external(tensor):
    finished_user_t_ii = 0
    x = tensor[0]
    t = tensor[1]
    
    # array to store the result
    result = tf.TensorArray(dtype=tf.float32, size=t.shape[0])
    result = result.write(0, x)

    i = tf.constant(0, dtype=tf.int32)
    for _t in t[1:]:
        i = i+1
        result = result.write(i, tf.stack([tf.cos(_t), tf.sin(_t)]))
    
    return result.stack(), t

x = tf.random.normal((50, 2), 0, 1)
t = tf.random.normal((50, 10000), 0, 1)

# warm up
result = [odeint_external((_x, _t)) for _x, _t in zip(x, t)]

start_t = time.time()
result = [odeint_external((_x, _t)) for _x, _t in zip(x, t)]
print(time.time()-start_t)
```

**Other info / logs** Include any logs or source code that would be helpful to
N/A"
40516,Tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.,"
**System information**
- Tf 2.2.0
- Windows10
- Python version: 5.7.6
- git version v2.2.0-rc4-8-g2b96f3662b



When I pass class_weight to model.fit() this error comes and when I do not pass it goes? any idea how to solve it?

`
Tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  indices[84] = 31 is not in [0, 31)
	 [[{{node GatherV2}}]]
	 [[IteratorGetNext]]
	 [[ReverseSequence_1/_502]]
  (1) Invalid argument:  indices[84] = 31 is not in [0, 31)
	 [[{{node GatherV2}}]]
	 [[IteratorGetNext]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_28314]

Function call stack:
train_function -> train_function
`

`       model_input = tf.keras.layers.Input(shape=(timesteps,), dtype='int32')
        self.createBertLayer()

        bert = self.bert_layer(model_input)


        self.d = tf.keras.layers.Dense(num_hiddens, activation=tf.nn.relu)(bert)
        h = tf.keras.layers.Dropout(0.5)(self.d)
        self.y1 = tf.keras.layers.Dense(classes, activation=tf.nn.softmax)(h)


        self.crf = CRF()
        output = self.crf(self.y1)

        model = Model(model_input, output)
        model.build(input_shape=(None, timesteps))
        self.bert_layer.apply_adapter_freeze()
        self.bert_layer.trainable = False

        model.compile(loss=self.crf.loss, optimizer=tf.keras.optimizers.Adam(0.001), metrics=[self.crf.accuracy])

        history = self.model.fit(
            training_set,
            training_label,
            class_weight=class_weights,
            epochs=n_epochs,
            # validation_data=(testing_set, one_hotted2),
            validation_split=0.1,
            verbose=1,
            batch_size=256
            # callbacks=[cp_callback]
        )
`

I checked class_weight keys and there was no problem with it."
40515,Keras callback stops receiving some params with tensorflow 2.2.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Fedora 31
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: Python 3.7.5
- CUDA/cuDNN version: No GPU
- GPU model and memory: No GPU

**Describe the current behavior**

When defining a custom Keras callback, the `set_params` method receives a subset of parameters in tensorflow 2.2.0 in comparison to what it used to receive in tensorflow 2.1.1.

In tensorflow 2.2.0, it receives:

```
{'verbose': 1, 'epochs': 2, 'steps': 1}
```

**Describe the expected behavior**

I would expect to get the same params as with tensorflow 2.1.1, which are:

```
{'batch_size': 4, 'epochs': 2, 'steps': None, 'samples': 4, 'verbose': 1, 'do_validation': False, 'metrics': ['loss']}
```

**Standalone code to reproduce the issue**

I used the following script to test the behavior with the two version of tensorflows and also trying with `keras` versus `tf.keras`:

```
import numpy as np
# import keras
import tensorflow.keras as keras

def build_xor_data():
    x_train = [np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=float)]
    y_train = [np.array([[0], [1], [1], [0]], dtype=float)]

    return x_train, y_train


def build_xor_model_keras():
    input_layer = keras.layers.Input(shape=(2,))
    hidden_layer = keras.layers.Dense(2, activation=""sigmoid"")(input_layer)
    output_layer = keras.layers.Dense(1, activation=""sigmoid"")(hidden_layer)
    model = keras.models.Model(inputs=input_layer, outputs=output_layer)
    model.compile(loss=""mse"", optimizer=""adam"")
    return model

x_train, y_train = build_xor_data()

model = build_xor_model_keras()

class DebugCallback(keras.callbacks.Callback):

    def set_params(self, params):
        print(""SET PARAMS"", locals())

print(""KERAS VERSION"", keras.__version__)
model.fit(x_train, y_train, batch_size=4, epochs=2, callbacks=[DebugCallback()])
```

I got the following outputs:

|          	| keras                                                                                                                  	| tf.keras                                                                                                            	|
|----------	|------------------------------------------------------------------------------------------------------------------------	|---------------------------------------------------------------------------------------------------------------------	|
| tf 2.1.1 	| {'batch_size': 4, 'epochs': 2, 'steps': None, 'samples': 4, 'verbose': 1, 'do_validation': False, 'metrics': ['loss']} 	| {'batch_size': 4, 'epochs': 2, 'steps': 1, 'samples': 4, 'verbose': 0, 'do_validation': False, 'metrics': ['loss']} 	|
| tf 2.2.0 	| {'batch_size': 4, 'epochs': 2, 'steps': None, 'samples': 4, 'verbose': 1, 'do_validation': False, 'metrics': ['loss']} 	| {'verbose': 1, 'epochs': 2, 'steps': 1}                                                                             	|

In tensorflow 2.2.0, we don't get anymore the following parameters:
* batch_size
* samples
* do_validation
* metrics

After reading the release note, section `Breaking changes` https://github.com/tensorflow/tensorflow/releases/tag/v2.2.0, I could expect to not receive `metrics` anymore. Are the other missing params also linked to that breaking change?"
40514,"TFBertForSequenceClassification: Non-deterministic when training on GPU, even with seeds fixed and TF_DETERMINISTIC_OPS=""1""","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): used on Google Colab
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.9
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: 10.1
- GPU model and memory: Tesla K80


**Describe the current behavior**
[Colab Link with a minimal example](https://colab.research.google.com/drive/1VSU8lYFD0E1HKZrIL1MvyIRwAktlSF_t#scrollTo=9NM47IRsy_v4)

Training a [transformers](huggingface/transformers/) `TFBertForSequenceClassification` model ([model code direkt link](https://github.com/huggingface/transformers/blob/3d495c61efbd2ca8a17827ff3103f7c820f0e9da/src/transformers/modeling_tf_bert.py#L910)) with keras/tf2.2.0 on the GPU is non-deterministic, even when setting all relevant random seeds and following the best practice guide in [these gputechconf slides](https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9911-determinism-in-deep-learning.pdf). 
As clearly documented in [this table](https://github.com/NVIDIA/tensorflow-determinism#confirmed-current-gpu-specific-sources-of-non-determinism-with-solutions), training on the GPU can be expected to be deterministic for TF 2.2.0 when setting environment variable `TF_DETERMINISTIC_OPS` to `""1""`. 
In spite of me setting this variable in my code (prior to importing tensorflow), this is not the case in my example.

Having seen previous issues (#38185) documented for `CrossEntropyLoss`, I also used the [suggested workaround for those](https://github.com/tensorflow/tensorflow/issues/38185#issuecomment-643014439). 
Nonetheless, my code remains non-deterministic on the GPU. 

The following table summarizes my results **after only training for five steps** , numbers were computed using [this function suggested to verify training reproducibility](https://github.com/NVIDIA/tensorflow-determinism/issues/2#issuecomment-548210203):

| | Device | Before training | After training |
| ------------- | ------------- | ------------- | ------------- |
| Run 1  | GPU | -641227.5609667897224  | -641237.442 **`5159916282`** |
| Run 2  | GPU | -641227.5609667897224  | -641237.442 **`3093758523`** |
| | |  | |
| Run 1 | CPU | -641227.5609667301178 | -641238.1506845243275 |
| Run 2 | CPU | -641227.5609667301178 | -641238.1506845243275 |


**Describe the expected behavior**
For TF 2.2.0, training on the GPU is expected to be deterministic when fixing random seeds and using: 
```python
os.environ[""TF_DETERMINISTIC_OPS""] = ""1""
```
Thus, my expectation is that the example code provided in my colab notebook should be deterministic on the colab GPU runtime as well.

**Standalone code to reproduce the issue**
Colab Link, reproducible on CPU runtime, non-deterministic on GPU runtime: https://colab.research.google.com/drive/1VSU8lYFD0E1HKZrIL1MvyIRwAktlSF_t#scrollTo=9NM47IRsy_v4

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.


"
40513,Docker images with tags '1.15.3' are missing on Docker Hub,"We would like to update our images to release 1.15.3 for the security fixes it contains. I'm not seeing any 1.15.3 images on dockerhub though.

https://hub.docker.com/r/tensorflow/tensorflow/tags?name=1.15.3"
40510,[RNN] LSTM and Bidir layers can't be converted in a TFLite model,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version (or github SHA if from source): 2.2.0


**Command used to run the converter or code if youre using the Python API**
If absolutely needed I will upload some code on a Colab, please request it.

```python
#representative dataset 
input_ds = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(X_train, dtype=np.float32))

def representative_data_gen():
      for input_value in input_ds.take(1000).batch(1):
            yield [input_value]

converter = tf.lite.TFLiteConverter.from_keras_model(m[""k_model""])
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
converter.representative_dataset = representative_data_gen

print(""quantization model conversion started"")
%time m[""k_model_tflite""] = converter.convert()
print(""quantization model conversion completed"")

tflite_model_file = 'current_converted_model.tflite'
f = open(tflite_model_file, 'wb')
f.write(m[""k_model_tflite""])
f.close()
print(""quantization model saved on file"")

```
output: 
```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
RuntimeError: Only models with a single subgraph are supported, model had 9 subgraphs

The above exception was the direct cause of the following exception:

SystemError                               Traceback (most recent call last)
c:\users\eric\virtualenvs\venvgpu\lib\site-packages\tensorflow\lite\python\optimize\calibrator.py in __init__(self, model_content)
     50       self._calibrator = (_calibration_wrapper.CalibrationWrapper
---> 51                           .CreateWrapperCPPFromBuffer(model_content))
     52     except Exception as e:

SystemError: <built-in function CalibrationWrapper_CreateWrapperCPPFromBuffer> returned a result with an error set

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<timed exec> in <module>

c:\users\eric\virtualenvs\venvgpu\lib\site-packages\tensorflow\lite\python\lite.py in convert(self)
    520     if self._is_calibration_quantize():
    521       result = self._calibrate_quantize_model(
--> 522           result, constants.FLOAT, constants.FLOAT)
    523 
    524     return result

c:\users\eric\virtualenvs\venvgpu\lib\site-packages\tensorflow\lite\python\lite.py in _calibrate_quantize_model(self, result, inference_input_type, inference_output_type)
    259                                 inference_output_type):
    260     allow_float = not self._is_int8_target_required()
--> 261     calibrate_quantize = _calibrator.Calibrator(result)
    262     if self._experimental_calibrate_only:
    263       return calibrate_quantize.calibrate(self.representative_dataset.input_gen)

c:\users\eric\virtualenvs\venvgpu\lib\site-packages\tensorflow\lite\python\optimize\calibrator.py in __init__(self, model_content)
     51                           .CreateWrapperCPPFromBuffer(model_content))
     52     except Exception as e:
---> 53       raise ValueError(""Failed to parse the model: %s."" % e)
     54     if not self._calibrator:
     55       raise ValueError(""Failed to parse the model."")

ValueError: Failed to parse the model: <built-in function CalibrationWrapper_CreateWrapperCPPFromBuffer> returned a result with an error set.

```
model is quite large and not included please indicated if is needed.

**Failure details**
When the Bidir and LSTM layers are removed the conversion works without error. 
When the Bidir and LSTM layers are present the above error is presented.

according to #36219 is seems that this type of error coudl be raised when using TFLite for microcontroller, this is not the intention here. Is there something to do to ensure that it is not the version for microcontroller which is used. 
For context, the target is the coral dev board (edge-tpu on linux platform).

**Any other info / logs**
model summary that I tried to convert.
```
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
inputs (InputLayer)             [(None, 250, 1)]     0                                            
__________________________________________________________________________________________________
bidirectional (Bidirectional)   (None, 250, 100)     20800       inputs[0][0]                     
__________________________________________________________________________________________________
flatten (Flatten)               (None, 25000)        0           bidirectional[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 250)          0           inputs[0][0]                     
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 25250)        0           flatten[0][0]                    
                                                                 flatten_1[0][0]                  
__________________________________________________________________________________________________
dense (Dense)                   (None, 2048)         51714048    concatenate[0][0]                
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1024)         2098176     dense[0][0]                      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 512)          524800      dense_1[0][0]                    
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 2048)         51714048    concatenate[0][0]                
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 256)          131328      dense_2[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1024)         2098176     dense_7[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 128)          32896       dense_3[0][0]                    
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 512)          524800      dense_8[0][0]                    
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 50)           6450        dense_4[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 256)          131328      dense_9[0][0]                    
__________________________________________________________________________________________________
reshape (Reshape)               (None, 50, 1)        0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 128)          32896       dense_10[0][0]                   
__________________________________________________________________________________________________
time_distributed (TimeDistribut (None, 50, 1)        2           reshape[0][0]                    
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 50)           6450        dense_11[0][0]                   
__________________________________________________________________________________________________
om (Reshape)                    (None, 50, 1)        0           time_distributed[0][0]           
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 50, 1)        0           dense_12[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 2)        0           om[0][0]                         
                                                                 reshape_1[0][0]                  
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 100)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 100)          10100       flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 100)          10100       dense_13[0][0]                   
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 50)           5050        dense_14[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 50)           2550        dense_15[0][0]                   
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 50, 1)        0           dense_16[0][0]                   
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 50, 1)        2           reshape_2[0][0]                  
__________________________________________________________________________________________________
of (Reshape)                    (None, 50, 1)        0           time_distributed_1[0][0]         
==================================================================================================
Total params: 109,064,000
Trainable params: 109,064,000
Non-trainable params: 0
```

"
40509,GatherV2 bug from pb->tflite,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.1
- Python version: 3.5
- Bazel version (if compiling from source): 0.16.0
- GCC/Compiler version (if compiling from source):7.4.0
- CUDA/cuDNN version: 10.2
- GPU model and memory: RTX 2080TI

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
v2.1.0-rc2-17-ge5bf8de 2.1.0

**Describe the current behavior**
![Screenshot from 2020-06-16 17-29-43](https://user-images.githubusercontent.com/17722852/84787868-26be2580-aff7-11ea-98b0-4b29c446c3ce.png)

I am trying to create a tflite from this pb, but it fails to convert this GatherV2 because
`2020-06-16 17:32:12.974945: F tensorflow/lite/toco/graph_transformations/resolve_constant_gather.cc:65] Check failed: stride * coords_shape.dims(0) == output_data.size() (131072 vs. 1310720)
`
The code is from resolve_constant_gather.cc
`  CHECK_EQ(stride * coords_shape.dims(0), output_data.size());
`
Is this desired? I think this is a bug.


**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40508,AttributeError: 'Tensor' object has no attribute 'numpy',"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.1.0
- Python version: 3.6
- GPU model and memory: NVIDIA 4GB gmx150

**currently my code giving me the error 'AttributeError: 'Tensor' object has no attribute 'numpy'' in line 11**

**i wanted to print the error in custom loss function**

**Here is my code**
import tensorflow as tf
import numpy as np
import keras.backend as K
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D, Input

def loss(yT, yP):
    err = yT - yP
    print(err.numpy())
    squaredError = tf.square(err)
    meanError = tf.reduce_mean(squaredError)
    return meanError

(xTrain, yTrain), (xTest, yTest) = mnist.load_data()
print(xTrain.shape, yTrain.shape, type(xTest))

xTrain, xTest = xTrain / 255, xTest / 255
yTrain, yTest = to_categorical(yTrain, num_classes=10), to_categorical(yTest, num_classes=10)

model = Sequential()
model.add(Flatten(input_shape=(28, 28)))
model.add(Dense(100, activation='relu'))
model.add(Dense(10, activation='softmax'))
model.summary()
model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])
model.fit(xTrain, yTrain, epochs=4, verbose=1)

Also tf.executing_eagerly is True
i don't know why this error is coming
"
40507,Conversion error when trying to convert model using BeamSearchDecoder from tensorflow-addons [RNN],"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MAC OS 10.15.5
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.2


**Command used to run the converter or code if youre using the Python API**

```
converter = tf.lite.TFLiteConverter.from_keras_model(inference_model)
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [
        tf.lite.OpsSet.TFLITE_BUILTINS,
        tf.lite.OpsSet.SELECT_TF_OPS
    ]
tflite_quantized_model = converter.convert()
```

**The output from the converter invocation**

```
2020-06-16 12:24:25.843841: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-06-16 12:24:25.843958: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-06-16 12:24:25.913996: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-06-16 12:24:25.914107: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 460 nodes (66), 546 edges (111), time = 11.364ms.
2020-06-16 12:24:25.914119: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 460 nodes (0), 546 edges (0), time = 9.66ms.
2020-06-16 12:24:25.914126: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: while_body_5784
2020-06-16 12:24:25.914133: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-06-16 12:24:25.914140: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-16 12:24:25.914151: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: TensorArrayV2Write_1_cond_true_6956
2020-06-16 12:24:25.914160: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-16 12:24:25.914166: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-16 12:24:25.914171: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: TensorArrayV2Write_2_cond_true_6974
2020-06-16 12:24:25.914177: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-16 12:24:25.914183: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-16 12:24:25.914193: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: while_cond_5783
2020-06-16 12:24:25.914199: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-16 12:24:25.914205: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-16 12:24:25.914210: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: TensorArrayV2Write_cond_true_6938
2020-06-16 12:24:25.914215: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-16 12:24:25.914228: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-16 12:24:25.914235: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: model_predictive_typing_addons_beam_search_decoder_decoder_while_body_6435
2020-06-16 12:24:25.914240: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 521 nodes (0), 597 edges (0), time = 4.097ms.
2020-06-16 12:24:25.914244: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 521 nodes (0), 597 edges (0), time = 4.171ms.
2020-06-16 12:24:25.914248: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: BeamSearchDecoderStep_cond_true_6915
2020-06-16 12:24:25.914253: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-16 12:24:25.914258: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-16 12:24:25.914264: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: BeamSearchDecoderStep_cond_false_6916
2020-06-16 12:24:25.914270: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-16 12:24:25.914276: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-16 12:24:25.914279: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: TensorArrayV2Write_2_cond_false_6975
2020-06-16 12:24:25.914283: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-16 12:24:25.914289: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-16 12:24:25.914294: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: TensorArrayV2Write_1_cond_false_6957
2020-06-16 12:24:25.914298: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-16 12:24:25.914302: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-16 12:24:25.914307: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: model_predictive_typing_addons_beam_search_decoder_decoder_while_cond_6434
2020-06-16 12:24:25.914313: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-16 12:24:25.914319: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-06-16 12:24:25.914323: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: TensorArrayV2Write_cond_false_6939
2020-06-16 12:24:25.914328: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-06-16 12:24:25.914333: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
Traceback (most recent call last):
  File ""lite_conversion.py"", line 60, in <module>
    main()
  File ""lite_conversion.py"", line 53, in main
    tflite_quantized_model = converter.convert()
  File ""/home/gc/miniconda3/envs/grammatica_tf2-gpu/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 459, in convert
    self._funcs[0], lower_control_flow=False))
  File ""/home/gc/miniconda3/envs/grammatica_tf2-gpu/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 706, in convert_variables_to_constants_v2_as_graph
    func, lower_control_flow, aggressive_inlining)
  File ""/home/gc/miniconda3/envs/grammatica_tf2-gpu/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 461, in _convert_variables_to_constants_v2_impl
    node_defs, tensor_data, name_to_node)
  File ""/home/gc/miniconda3/envs/grammatica_tf2-gpu/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 286, in _get_control_flow_function_data
    arg_types[idx] = get_resource_type(node.input[idx + 1])
  File ""/home/gc/miniconda3/envs/grammatica_tf2-gpu/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 259, in get_resource_type
    node_name = get_source_node_name_through_identities(node_name)
  File ""/home/gc/miniconda3/envs/grammatica_tf2-gpu/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 254, in get_source_node_name_through_identities
    while name_to_node[node_name].op == ""Identity"":
KeyError: 'beamsearchdecoderstep_cond_input_1_0'
```

**Any other info / logs**

I am trying to convert a Seq2Seq model to TF-Lite, however I am facing some issues with the BeamSearchDecoder from tensorflow-addons. My model works fine in Python and the source code looks like this: 

```
class MySeq2SeqModel(tf.keras.models.Model):
    def __init__(self, vocab_size: int, input_len: int, output_len: int,
                 batch_size,
                 rnn_units: int = 64, dense_units: int = 64, embedding_dim: int = 256, **kwargs):
        super(MySeq2SeqModel, self).__init__(**kwargs)

        # Base Attributes
        self.vocab_size = vocab_size
        self.input_len = input_len
        self.output_len = output_len
        self.rnn_units = rnn_units
        self.dense_units = dense_units
        self.embedding_dim = embedding_dim
        self.batch_size = batch_size

        # Beam search attributes
        self.beam_width = 3

        # Encoder
        self.encoder_embedding = layers.Embedding(vocab_size, embedding_dim, input_length=input_len)
        self.encoder_rnn = layers.LSTM(rnn_units, return_sequences=True, return_state=True)

        # Decoder
        self.decoder_embedding = layers.Embedding(vocab_size, embedding_dim, input_length=output_len)
        self.decoder_rnncell = tf.keras.layers.LSTMCell(rnn_units)

        # Attention
        self.attention_mechanism = tfa.seq2seq.LuongAttention(dense_units)
        self.rnn_cell = self.build_rnn_cell(batch_size=batch_size)

        # Output
        self.dense_layer = tf.keras.layers.Dense(vocab_size)

        self.inference_decoder = BeamSearchDecoder(cell=self.rnn_cell,
                                                   beam_width=self.beam_width,
                                                   output_layer=self.dense_layer,
                                                   # As tf.nn.embedding_lookup is not supported by tflite
                                                   embedding_fn=lambda ids: tf.gather(tf.identity(
                                                       self.decoder_embedding.variables[0]), ids),
                                                   coverage_penalty_weight=0.0, dynamic=False, parallel_iterations=1,
                                                   maximum_iterations=output_len
                                                   )

    def call(self, inputs, training=None, mask=None):
        # Encoder
        encoder = self.encoder_embedding(inputs[0])
        encoder_outputs, state_h, state_c = self.encoder_rnn(encoder)
        decoder_emb = self.decoder_embedding(inputs[1])

        tiled_a = tfa.seq2seq.tile_batch(encoder_outputs, multiplier=self.beam_width)
        tiled_a_tx = tfa.seq2seq.tile_batch(state_h, multiplier=self.beam_width)
        tiled_c_tx = tfa.seq2seq.tile_batch(state_c, multiplier=self.beam_width)
        start_tokens = tf.fill([1], START_ID)

        self.attention_mechanism.setup_memory(tiled_a)

        final_output, final_state, _ = self.inference_decoder(embedding=None,
                                                              start_tokens=start_tokens,
                                                              end_token=EOS_ID,
                                                              initial_state=self.build_decoder_initial_state(
                                                                  size=1 * self.beam_width,
                                                                  encoder_state=[tiled_a_tx, tiled_c_tx],
                                                                  Dtype=tf.float32))

        return final_output.predicted_ids

```
"
40506," from tensorflow.python.framework import versions   File ""C:\Users\Akanksha\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\versions.py"", line 24, in <module>__version__ = pywrap_tensorflow.__version__ AttributeError: module 'tensorflow.python.pywrap_tensorflow' has no attribute '__version__'","Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
40505,Want to contribute but build takes time,"I am new to TensorFlow's contribution community. I want to add some features and write test some scripts for it, but as it is taking so much time to build. I want to import TensorFlow from the source without re-building every time. 
Please let me know if it's possible or if there is another way of doing that."
40504,RuntimeError: tensorflow/lite/kernels/range.cc:39 (start > limit && delta < 0) || (start < limit && delta > 0) was not true.Node number 3 (RANGE) failed   to invoke. Node number 393 (WHILE) failed to invoke. current error :RuntimeError: tensorflow/lite/kernels/reshape.cc:55 stretch_dim != -1 (0 != -1)Node number 83 (RESHAPE) failed to prepare.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Command used to run the converter or code if youre using the Python API**
```
import numpy as np
import tensorflow as tf
from tensorflow_tts.processor import LJSpeechProcessor

# Load the TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=""fastspeech.tflite"")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print(""input_details: "", input_details)
print(""output_details"", output_details)

print(input_details[0])
print(input_details[1])
print(input_details[2])
# fastspeech inference
attention_mask = interpreter.tensor(interpreter.get_input_details()[0][""index""])()
speaker_id = interpreter.tensor(interpreter.get_input_details()[1][""index""])()
input_id = interpreter.tensor(interpreter.get_input_details()[2][""index""])()

input_id = tf.convert_to_tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]], tf.int32)
attention_mask = tf.convert_to_tensor([[True, True, True, True, True, True, True, True, True, True]], tf.bool)
speaker_id = tf.convert_to_tensor([0], tf.int32)

#out_p = interpreter.tensor(interpreter.get_output_details()[0][""index""])
interpreter.invoke()
interpreter.invoke()
interpreter.invoke()
print(""done"")
# The function `get_tensor()` returns a copy of the tensor data.
# Use `tensor()` in order to get a pointer to the tensor.
masked_mel_before = interpreter.get_tensor(output_details[2]['index'])
print(masked_mel_before)

```

**The output from the converter invocation**

```
input_details:  [{'name': 'attention_mask', 'index': 0, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.bool_'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'input_ids', 'index': 1, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'speaker_ids', 'index': 2, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
output_details [{'name': 'Identity', 'index': 585, 'shape': array([], dtype=int32), 'shape_signature': array([], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'Identity_1', 'index': 621, 'shape': array([], dtype=int32), 'shape_signature': array([], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'Identity_2', 'index': 537, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
{'name': 'attention_mask', 'index': 0, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.bool_'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}
{'name': 'input_ids', 'index': 1, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}
{'name': 'speaker_ids', 'index': 2, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}
2020-06-16 06:20:21.460754: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-06-16 06:20:21.460788: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2020-06-16 06:20:21.460819: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist
2020-06-16 06:20:21.461131: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-16 06:20:21.468935: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2593990000 Hz
2020-06-16 06:20:21.469795: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0cfc000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-16 06:20:21.469821: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""test_tflite.py"", line 28, in <module>
    interpreter.invoke()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py"", line 511, in invoke
    self._interpreter.Invoke()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py"", line 113, in Invoke
    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_Invoke(self)
RuntimeError: tensorflow/lite/kernels/range.cc:39 (start > limit && delta < 0) || (start < limit && delta > 0) was not true.Node number 3 (RANGE) failed to invoke.
Node number 393 (WHILE) failed to invoke.

```

**Also, please include a link to the saved model or GraphDef**

```
saved_model
https://drive.google.com/file/d/136KmfVwBT2htxPDZeYw4-TXmxPYe7Vsa/view?usp=sharing
fastspeech.tflite
https://drive.google.com/file/d/1QYyc5cUZbmbv7SwQMDTdM622ZiCFG2cp/view?usp=sharing
```

**Failure details**
conversion is successful, but there is runtime error,
state what is wrong:
interpreter.invoke() failing

**Any other info / logs**
pb conversion
```
import yaml
import numpy as np
import matplotlib.pyplot as plt

import yaml
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow_tts.configs import FastSpeechConfig
from tensorflow_tts.models import TFFastSpeech

with open('examples/fastspeech/conf/fastspeech.v3.yaml') as f:
    config = yaml.load(f, Loader=yaml.Loader)

config = FastSpeechConfig(**config[""fastspeech_params""])

fastspeech = TFFastSpeech(config=config, name=""fastspeech"")
fastspeech._build()

fastspeech.load_weights(""examples/fastspeech/pretrained/model-150000.h5"",by_name=True, skip_mismatch=True)
tf.saved_model.save(fastspeech, ""./test_saved"")
```
fastspeech model code

```
import numpy as np
import tensorflow as tf


def get_initializer(initializer_range=0.02):
    """"""Creates a `tf.initializers.truncated_normal` with the given range.

    Args:
        initializer_range: float, initializer range for stddev.

    Returns:
        TruncatedNormal initializer with stddev = `initializer_range`.

    """"""
    return tf.keras.initializers.TruncatedNormal(stddev=initializer_range)


def gelu(x):
    """"""Gaussian Error Linear unit.""""""
    cdf = 0.5 * (1.0 + tf.math.erf(x / tf.math.sqrt(2.0)))
    return x * cdf


def gelu_new(x):
    """"""Smoother gaussian Error Linear Unit.""""""
    cdf = 0.5 * (1.0 + tf.tanh((np.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3)))))
    return x * cdf


def swish(x):
    """"""Swish activation function.""""""
    return x * tf.sigmoid(x)


def mish(x):
    return x * tf.math.tanh(tf.math.softplus(x))


ACT2FN = {
    ""identity"": tf.keras.layers.Activation('linear'),
    ""tanh"": tf.keras.layers.Activation('tanh'),
    ""gelu"": tf.keras.layers.Activation(gelu),
    ""relu"": tf.keras.activations.relu,
    ""swish"": tf.keras.layers.Activation(swish),
    ""gelu_new"": tf.keras.layers.Activation(gelu_new),
    ""mish"": tf.keras.layers.Activation(mish)
}


class TFFastSpeechEmbeddings(tf.keras.layers.Layer):
    """"""Construct charactor/phoneme/positional/speaker embeddings.""""""

    def __init__(self, config, **kwargs):
        """"""Init variables.""""""
        super().__init__(**kwargs)
        self.vocab_size = config.vocab_size
        self.hidden_size = config.hidden_size
        self.initializer_range = config.initializer_range
        self.config = config

        self.position_embeddings = tf.keras.layers.Embedding(
            config.max_position_embeddings + 1,
            config.hidden_size,
            weights=[self._sincos_embedding()],
            name=""position_embeddings"",
            trainable=False,
        )

        if config.n_speakers > 1:
            self.encoder_speaker_embeddings = tf.keras.layers.Embedding(
                config.n_speakers,
                config.hidden_size,
                embeddings_initializer=get_initializer(self.initializer_range),
                name=""speaker_embeddings""
            )
            self.speaker_fc = tf.keras.layers.Dense(units=config.hidden_size, name='speaker_fc') 
    def build(self, input_shape):
        """"""Build shared charactor/phoneme embedding layers.""""""
        with tf.name_scope(""charactor_embeddings""):
            self.charactor_embeddings = self.add_weight(
                ""weight"",
                shape=[self.vocab_size, self.hidden_size],
                initializer=get_initializer(self.initializer_range),
            )
        super().build(input_shape)
    #@tf.function(experimental_relax_shapes=True)
    def call(self, inputs, training=False):
        """"""Get charactor embeddings of inputs.

        Args:
            1. charactor, Tensor (int32) shape [batch_size, length].
            2. speaker_id, Tensor (int32) shape [batch_size]
        Returns:
            Tensor (float32) shape [batch_size, length, embedding_size].

        """"""
        return self._embedding(inputs, training=training)
    def _embedding(self, inputs, training=False):
        """"""Applies embedding based on inputs tensor.""""""
        input_ids, speaker_ids = inputs

        input_shape = tf.shape(input_ids)
        seq_length = input_shape[1]

        position_ids = tf.range(1, seq_length + 1, dtype=tf.int32)[tf.newaxis, :]

        # create embeddings
        inputs_embeds = tf.gather(self.charactor_embeddings, input_ids)
        position_embeddings = self.position_embeddings(position_ids)

        # sum embedding
        embeddings = inputs_embeds + position_embeddings
        if self.config.n_speakers > 1:
            speaker_embeddings = self.encoder_speaker_embeddings(speaker_ids)
            speaker_features = tf.math.softplus(self.speaker_fc(speaker_embeddings))
            # extended speaker embeddings
            extended_speaker_features = speaker_features[:, tf.newaxis, :]
            embeddings += extended_speaker_features

        return embeddings
    def _sincos_embedding(self):
        position_enc = np.array([
            [pos / np.power(10000, 2.0 * (i // 2) / self.hidden_size) for i in range(self.hidden_size)]
            for pos in range(self.config.max_position_embeddings + 1)
        ])

        position_enc[:, 0::2] = np.sin(position_enc[:, 0::2])
        position_enc[:, 1::2] = np.cos(position_enc[:, 1::2])

        # pad embedding.
        position_enc[0] = 0.0

        return position_enc


class TFFastSpeechSelfAttention(tf.keras.layers.Layer):
    """"""Self attention module for fastspeech.""""""

    def __init__(self, config, **kwargs):
        """"""Init variables.""""""
        super().__init__(**kwargs)
        if config.hidden_size % config.num_attention_heads != 0:
            raise ValueError(
                ""The hidden size (%d) is not a multiple of the number of attention ""
                ""heads (%d)"" % (config.hidden_size, config.num_attention_heads)
            )
        self.output_attentions = config.output_attentions
        self.num_attention_heads = config.num_attention_heads
        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)
        self.all_head_size = self.num_attention_heads * self.attention_head_size

        self.query = tf.keras.layers.Dense(
            self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=""query""
        )
        self.key = tf.keras.layers.Dense(
            self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=""key""
        )
        self.value = tf.keras.layers.Dense(
            self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=""value""
        )

        self.dropout = tf.keras.layers.Dropout(config.attention_probs_dropout_prob)

    def transpose_for_scores(self, x, batch_size):
        """"""Transpose to calculate attention scores.""""""
        x = tf.reshape(x, (batch_size, -1, self.num_attention_heads, self.attention_head_size))
        return tf.transpose(x, perm=[0, 2, 1, 3])

    @tf.function(experimental_relax_shapes=True)
    def __call__(self, inputs, training=False):
        """"""Call logic.""""""
        hidden_states, attention_mask = inputs

        batch_size = tf.shape(hidden_states)[0]
        mixed_query_layer = self.query(hidden_states)
        mixed_key_layer = self.key(hidden_states)
        mixed_value_layer = self.value(hidden_states)

        query_layer = self.transpose_for_scores(mixed_query_layer, batch_size)
        key_layer = self.transpose_for_scores(mixed_key_layer, batch_size)
        value_layer = self.transpose_for_scores(mixed_value_layer, batch_size)

        attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)
        dk = tf.cast(tf.shape(key_layer)[-1], tf.float32)  # scale attention_scores
        attention_scores = attention_scores / tf.math.sqrt(dk)

        if attention_mask is not None:
            # extended_attention_masks for self attention encoder.
            extended_attention_mask = attention_mask[:, tf.newaxis, tf.newaxis, :]
            extended_attention_mask = tf.cast(extended_attention_mask, tf.float32)
            extended_attention_mask = (1.0 - extended_attention_mask) * -1e9
            attention_scores = attention_scores + extended_attention_mask

        # Normalize the attention scores to probabilities.
        attention_probs = tf.nn.softmax(attention_scores, axis=-1)
        attention_probs = self.dropout(attention_probs, training=training)

        context_layer = tf.matmul(attention_probs, value_layer)
        context_layer = tf.transpose(context_layer, perm=[0, 2, 1, 3])
        context_layer = tf.reshape(
            context_layer, (batch_size, -1, self.all_head_size)
        )

        outputs = (context_layer, attention_probs) if self.output_attentions else (context_layer,)
        return outputs


class TFFastSpeechSelfOutput(tf.keras.layers.Layer):
    """"""Fastspeech output of self attention module.""""""

    def __init__(self, config, **kwargs):
        """"""Init variables.""""""
        super().__init__(**kwargs)
        self.dense = tf.keras.layers.Dense(
            config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=""dense""
        )
        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=""LayerNorm"")
        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)

    @tf.function(experimental_relax_shapes=True)
    def __call__(self, inputs, training=False):
        """"""Call logic.""""""
        hidden_states, input_tensor = inputs

        hidden_states = self.dense(hidden_states)
        hidden_states = self.dropout(hidden_states, training=training)
        hidden_states = self.LayerNorm(hidden_states + input_tensor)
        return hidden_states


class TFFastSpeechAttention(tf.keras.layers.Layer):
    """"""Fastspeech attention module.""""""

    def __init__(self, config, **kwargs):
        """"""Init variables.""""""
        super().__init__(**kwargs)
        self.self_attention = TFFastSpeechSelfAttention(config, name=""self"")
        self.dense_output = TFFastSpeechSelfOutput(config, name=""output"")
    @tf.function(experimental_relax_shapes=True)
    def __call__(self, inputs, training=False):
        input_tensor, attention_mask = inputs

        self_outputs = self.self_attention([input_tensor, attention_mask], training=training)
        attention_output = self.dense_output([self_outputs[0], input_tensor], training=training)
        masked_attention_output = attention_output * tf.cast(tf.expand_dims(attention_mask, 2), dtype=tf.float32)
        outputs = (masked_attention_output,) + self_outputs[1:]  # add attentions if we output them
        return outputs


class TFFastSpeechIntermediate(tf.keras.layers.Layer):
    """"""Intermediate representation module.""""""

    def __init__(self, config, **kwargs):
        """"""Init variables.""""""
        super().__init__(**kwargs)
        self.conv1d_1 = tf.keras.layers.Conv1D(
            config.intermediate_size,
            kernel_size=config.intermediate_kernel_size,
            kernel_initializer=get_initializer(config.initializer_range),
            padding='same',
            name=""conv1d_1""
        )
        self.conv1d_2 = tf.keras.layers.Conv1D(
            config.hidden_size,
            kernel_size=config.intermediate_kernel_size,
            kernel_initializer=get_initializer(config.initializer_range),
            padding='same',
            name=""conv1d_2""
        )
        if isinstance(config.hidden_act, str):
            self.intermediate_act_fn = ACT2FN[config.hidden_act]
        else:
            self.intermediate_act_fn = config.hidden_act

    @tf.function(experimental_relax_shapes=True)
    def __call__(self, inputs, training=False):
        """"""Call logic.""""""
        hidden_states, attention_mask = inputs

        hidden_states = self.conv1d_1(hidden_states)
        hidden_states = self.intermediate_act_fn(hidden_states)
        hidden_states = self.conv1d_2(hidden_states)

        masked_hidden_states = hidden_states * tf.cast(tf.expand_dims(attention_mask, 2), dtype=tf.float32)
        return masked_hidden_states


class TFFastSpeechOutput(tf.keras.layers.Layer):
    """"""Output module.""""""

    def __init__(self, config, **kwargs):
        """"""Init variables.""""""
        super().__init__(**kwargs)
        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=""LayerNorm"")
        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)
    @tf.function(experimental_relax_shapes=True)
    def __call__(self, inputs, training=False):
        """"""Call logic.""""""
        hidden_states, input_tensor = inputs

        hidden_states = self.dropout(hidden_states, training=training)
        hidden_states = self.LayerNorm(hidden_states + input_tensor)
        return hidden_states


class TFFastSpeechLayer(tf.keras.layers.Layer):
    """"""Fastspeech module (FFT module on the paper).""""""

    def __init__(self, config, **kwargs):
        """"""Init variables.""""""
        super().__init__(**kwargs)
        self.attention = TFFastSpeechAttention(config, name=""attention"")
        self.intermediate = TFFastSpeechIntermediate(config, name=""intermediate"")
        self.bert_output = TFFastSpeechOutput(config, name=""output"")

    @tf.function(experimental_relax_shapes=True)
    def __call__(self, inputs, training=False):
        """"""Call logic.""""""
        hidden_states, attention_mask = inputs

        attention_outputs = self.attention([hidden_states, attention_mask], training=training)
        attention_output = attention_outputs[0]
        intermediate_output = self.intermediate([attention_output, attention_mask], training=training)
        layer_output = self.bert_output([intermediate_output, attention_output], training=training)
        masked_layer_output = layer_output * tf.cast(tf.expand_dims(attention_mask, 2), dtype=tf.float32)
        outputs = (masked_layer_output,) + attention_outputs[1:]  # add attentions if we output them
        return outputs


class TFFastSpeechEncoder(tf.keras.layers.Layer):
    """"""Fast Speech encoder module.""""""

    def __init__(self, config, **kwargs):
        """"""Init variables.""""""
        super().__init__(**kwargs)
        self.output_attentions = config.output_attentions
        self.output_hidden_states = config.output_hidden_states
        self.layer = [TFFastSpeechLayer(config, name=""layer_._{}"".format(i)) for i in range(config.num_hidden_layers)]
    
    @tf.function(experimental_relax_shapes=True)
    def __call__(self, inputs, training=False):
        """"""Call logic.""""""
        hidden_states, attention_mask = inputs

        all_hidden_states = ()
        all_attentions = ()
        for _, layer_module in enumerate(self.layer):
            if self.output_hidden_states:
                all_hidden_states = all_hidden_states + (hidden_states,)

            layer_outputs = layer_module([hidden_states, attention_mask], training=training)
            hidden_states = layer_outputs[0]

            if self.output_attentions:
                all_attentions = all_attentions + (layer_outputs[1],)

        # Add last layer
        if self.output_hidden_states:
            all_hidden_states = all_hidden_states + (hidden_states,)

        outputs = (hidden_states,)
        if self.output_hidden_states:
            outputs = outputs + (all_hidden_states,)
        if self.output_attentions:
            outputs = outputs + (all_attentions,)
        return outputs  # outputs, (hidden states), (attentions)


class TFFastSpeechDecoder(TFFastSpeechEncoder):
    """"""Fast Speech decoder module.""""""

    def __init__(self, config, **kwargs):
        super().__init__(config, **kwargs)
        self.config = config

        # create decoder positional embedding
        self.decoder_positional_embeddings = tf.keras.layers.Embedding(
            config.max_position_embeddings + 1,
            config.hidden_size,
            weights=[self._sincos_embedding()],
            name=""position_embeddings"",
            trainable=False
        )

        if config.n_speakers > 1:
            self.decoder_speaker_embeddings = tf.keras.layers.Embedding(
                config.n_speakers,
                config.hidden_size,
                embeddings_initializer=get_initializer(config.initializer_range),
                name=""speaker_embeddings""
            )
            self.speaker_fc = tf.keras.layers.Dense(units=config.hidden_size, name='speaker_fc')
    @tf.function(experimental_relax_shapes=True)
    def __call__(self, inputs, training=False):
        hidden_states, speaker_ids, encoder_mask, decoder_pos = inputs

        # calculate new hidden states.
        hidden_states = hidden_states + self.decoder_positional_embeddings(decoder_pos)

        if self.config.n_speakers > 1:
            speaker_embeddings = self.decoder_speaker_embeddings(speaker_ids)
            speaker_features = tf.math.softplus(self.speaker_fc(speaker_embeddings))
            # extended speaker embeddings
            extended_speaker_features = speaker_features[:, tf.newaxis, :]
            hidden_states += extended_speaker_features

        return super().call([hidden_states, encoder_mask], training=training)

    def _sincos_embedding(self):
        position_enc = np.array([
            [pos / np.power(10000, 2.0 * (i // 2) / self.config.hidden_size) for i in range(self.config.hidden_size)]
            for pos in range(self.config.max_position_embeddings + 1)
        ])

        position_enc[:, 0::2] = np.sin(position_enc[:, 0::2])
        position_enc[:, 1::2] = np.cos(position_enc[:, 1::2])

        # pad embedding.
        position_enc[0] = 0.0

        return position_enc


class TFTacotronPostnet(tf.keras.layers.Layer):
    """"""Tacotron-2 postnet.""""""

    def __init__(self, config, **kwargs):
        """"""Init variables.""""""
        super().__init__(**kwargs)
        self.conv_batch_norm = []
        for i in range(config.n_conv_postnet):
            conv = tf.keras.layers.Conv1D(
                filters=config.postnet_conv_filters if i < config.n_conv_postnet - 1 else config.num_mels,
                kernel_size=config.postnet_conv_kernel_sizes,
                padding='same',
                name='conv_._{}'.format(i)
            )
            batch_norm = tf.keras.layers.BatchNormalization(name='batch_norm_._{}'.format(i))
            self.conv_batch_norm.append((conv, batch_norm))
        self.dropout = tf.keras.layers.Dropout(rate=config.postnet_dropout_rate, name='dropout')
        self.activation = [tf.nn.tanh] * (config.n_conv_postnet - 1) + [tf.identity]

    @tf.function(experimental_relax_shapes=True)
    def __call__(self, inputs, training=False):
        """"""Call logic.""""""
        outputs, mask = inputs
        extended_mask = tf.cast(tf.expand_dims(mask, axis=2), tf.float32)
        for i, (conv, bn) in enumerate(self.conv_batch_norm):
            outputs = conv(outputs)
            outputs = bn(outputs)
            outputs = self.activation[i](outputs)
            outputs = self.dropout(outputs, training=training)
        return outputs * extended_mask


class TFFastSpeechDurationPredictor(tf.keras.layers.Layer):
    """"""FastSpeech duration predictor module.""""""

    def __init__(self, config, **kwargs):
        """"""Init variables.""""""
        super().__init__(**kwargs)
        self.conv_layers = []
        for i in range(config.num_duration_conv_layers):
            self.conv_layers.append(
                tf.keras.layers.Conv1D(
                    config.duration_predictor_filters,
                    config.duration_predictor_kernel_sizes,
                    padding='same',
                    name='conv_._{}'.format(i)
                )
            )
            self.conv_layers.append(
                tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=""LayerNorm_._{}"".format(i))
            )
            self.conv_layers.append(
                tf.keras.layers.Activation(tf.nn.relu6)
            )
            self.conv_layers.append(
                tf.keras.layers.Dropout(config.duration_predictor_dropout_probs)
            )
        self.conv_layers_sequence = tf.keras.Sequential(self.conv_layers)
        self.output_layer = tf.keras.layers.Dense(1)

    @tf.function(experimental_relax_shapes=True)
    def __call__(self, inputs, training=False):
        """"""Call logic.""""""
        encoder_hidden_states, attention_mask = inputs
        attention_mask = tf.cast(tf.expand_dims(attention_mask, 2), tf.float32)

        # mask encoder hidden states
        masked_encoder_hidden_states = encoder_hidden_states * attention_mask

        # pass though first layer
        outputs = self.conv_layers_sequence(masked_encoder_hidden_states)
        outputs = self.output_layer(outputs)
        masked_outputs = outputs * attention_mask
        return tf.squeeze(tf.nn.relu6(masked_outputs), -1)  # make sure positive value.


class TFFastSpeechLengthRegulator(tf.keras.layers.Layer):
    """"""FastSpeech lengthregulator module.""""""

    def __init__(self, config, **kwargs):
        """"""Init variables.""""""
        super().__init__(**kwargs)
        self.config = config
    @tf.function(experimental_relax_shapes=True)
    def __call__(self, inputs, training=False):
        """"""Call logic.

        Args:
            1. encoder_hidden_states, Tensor (float32) shape [batch_size, length, hidden_size]
            2. durations_gt, Tensor (float32/int32) shape [batch_size, length]
        """"""
        encoder_hidden_states, durations_gt = inputs
        outputs, encoder_masks = self._length_regulator(encoder_hidden_states, durations_gt)
        return outputs, encoder_masks

    def _length_regulator(self, encoder_hidden_states, durations_gt):
        """"""Length regulator logic.""""""
        sum_durations = tf.reduce_sum(durations_gt, axis=-1)  # [batch_size]
        max_durations = tf.reduce_max(sum_durations)

        input_shape = tf.shape(encoder_hidden_states)
        batch_size = input_shape[0]
        hidden_size = input_shape[-1]

        # initialize output hidden states and encoder masking.
        outputs = tf.zeros(shape=[0, max_durations, hidden_size], dtype=tf.float32)
        encoder_masks = tf.zeros(shape=[0, max_durations], dtype=tf.int32)

        def condition(i,
                      batch_size,
                      outputs,
                      encoder_masks,
                      encoder_hidden_states,
                      durations_gt,
                      max_durations):
            return tf.less(i, batch_size)

        def body(i,
                 batch_size,
                 outputs,
                 encoder_masks,
                 encoder_hidden_states,
                 durations_gt,
                 max_durations):
            repeats = durations_gt[i]
            real_length = tf.reduce_sum(repeats)
            pad_size = max_durations - real_length
            masks = tf.sequence_mask([real_length], max_durations, dtype=tf.int32)
            repeat_encoder_hidden_states = tf.repeat(
                encoder_hidden_states[i],
                repeats=repeats,
                axis=0
            )
            repeat_encoder_hidden_states = tf.expand_dims(
                tf.pad(
                    repeat_encoder_hidden_states, [[0, pad_size], [0, 0]]
                ),
                0)  # [1, max_durations, hidden_size]
            outputs = tf.concat([outputs, repeat_encoder_hidden_states], axis=0)
            encoder_masks = tf.concat([encoder_masks, masks], axis=0)
            return [i + 1, batch_size, outputs, encoder_masks,
                    encoder_hidden_states, durations_gt, max_durations]

        # initialize iteration i.
        i = tf.constant(0, dtype=tf.int32)
        _, _, outputs, encoder_masks, _, _, _, = tf.while_loop(
            condition,
            body,
            [i, batch_size, outputs, encoder_masks, encoder_hidden_states, durations_gt, max_durations],
            shape_invariants=[i.get_shape(),
                              batch_size.get_shape(),
                              tf.TensorShape([None, None, self.config.hidden_size]),
                              tf.TensorShape([None, None]),
                              encoder_hidden_states.get_shape(),
                              durations_gt.get_shape(),
                              max_durations.get_shape()]
        )

        return outputs, encoder_masks


class TFFastSpeech(tf.keras.Model):
    """"""TF Fastspeech module.""""""

    def __init__(self, config, **kwargs):
        """"""Init layers for fastspeech.""""""
        super().__init__(**kwargs)
        self.embeddings = TFFastSpeechEmbeddings(config, name='embeddings')
        self.encoder = TFFastSpeechEncoder(config, name='encoder')
        self.duration_predictor = TFFastSpeechDurationPredictor(config, name='duration_predictor')
        self.length_regulator = TFFastSpeechLengthRegulator(config, name='length_regulator')
        self.decoder = TFFastSpeechDecoder(config, name='decoder')
        self.mel_dense = tf.keras.layers.Dense(units=config.num_mels, name='mel_before')
        self.postnet = TFTacotronPostnet(config=config, name='postnet')

    def _build(self):
        """"""Dummy input for building model.""""""
        # fake inputs
        input_ids = tf.convert_to_tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]], tf.int32)
        attention_mask = tf.convert_to_tensor([[True, True, True, True, True, True, True, True, True, True]], tf.bool)
        speaker_ids = tf.convert_to_tensor([0], tf.int32)
        self(input_ids, attention_mask, speaker_ids)

    @tf.function(experimental_relax_shapes=True,
                 input_signature=[tf.TensorSpec(shape=[None, 10], dtype=tf.int32),
                                  tf.TensorSpec(shape=[None, 10], dtype=tf.bool),
                                  tf.TensorSpec(shape=[None, ], dtype=tf.int32)])
    def __call__(self,
             input_ids,
             attention_mask,
             speaker_ids,
             training=False):
        """"""Call logic.""""""
        embedding_output = self.embeddings([input_ids, speaker_ids], training=training)
        encoder_output = self.encoder([embedding_output, attention_mask], training=training)
        last_encoder_hidden_states = encoder_output[0]

        # duration predictor, here use last_encoder_hidden_states, u can use more hidden_states layers
        # rather than just use last_hidden_states of encoder for duration_predictor.
        duration_outputs = self.duration_predictor([last_encoder_hidden_states, attention_mask])  # [batch_size, length]
        speed_ratios = tf.convert_to_tensor(np.array([1.0]), dtype=tf.float32)

        duration_gts = tf.cast(tf.math.round(duration_outputs), tf.int32)

        length_regulator_outputs, encoder_masks = self.length_regulator([
            last_encoder_hidden_states, duration_gts], training=training)

        # create decoder positional embedding
        decoder_pos = tf.range(1, tf.shape(length_regulator_outputs)[1] + 1, dtype=tf.int32)
        masked_decoder_pos = tf.expand_dims(decoder_pos, 0) * encoder_masks

        decoder_output = self.decoder(
            [length_regulator_outputs, speaker_ids, encoder_masks, masked_decoder_pos], training=training)
        last_decoder_hidden_states = decoder_output[0]

        # here u can use sum or concat more than 1 hidden states layers from decoder.
        mel_before = self.mel_dense(last_decoder_hidden_states)
        mel_after = self.postnet([mel_before, encoder_masks], training=training) + mel_before
        outputs = (mel_before, mel_after, duration_outputs)
        #model10 = keras.models.Model(inputs=[input_ids,attention_mask,speaker_ids], output=outputs)
        return outputs

```"
40503,Android-PoseNet is not accurate when person is laying down,"I am running PoseNet on mobile and saw that when the person is laying down the model can't detect the legs of the person, does this is something that is happening only to me or is a general problem. If so is there any way I can improve the accuracy of PoseNet ?

- Running on mobile device: Xiaomi MI A2 (the speed was around 100ms, but I also tried on another device with Qualcomm 835 which had better speed but not improvement on accuracy)

-Also why its so unstable, I mean I stay in one place and points keep changing places 

-Can it work better on black and white frames ?"
40502,Tensorflow's FixedLengthRecordDataset reads binary file significantly slower than pure Python,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.6
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: CPU Only
- GPU model and memory: CPU Only

**Describe the current behavior**
I'm wondering why Tensorflow's FixedLengthRecordDataset is so slow when reading records from a binary file (without processing the records). My implementation in plain Python (see code below) appears to be two order of magnitude faster. 

**Describe the expected behavior**
I would expect that reading a file with FixedLengthRecordDataset would perform comparably or faster than the pure Python implementation. 

**Standalone code to reproduce the issue**
```
import time
import numpy as np
import tensorflow as tf

with open('some_file', 'wb') as f:
    f.write(np.ones(10000, dtype=np.int32).tobytes())


def time_tf():
    start_time = time.time()
    for record in tf.data.FixedLengthRecordDataset('some_file', record_bytes = 4):
        _ = record
    print(f'FixedLengthRecordDataset: {time.time() - start_time}')

def time_py():
    start_time = time.time()
    with open('some_file', 'rb') as f:
        b = f.read(4)
        while b:
            b = f.read(4)
    print(f'Plain Python: {time.time() - start_time}')

time_tf()
time_py()
```

```
FixedLengthRecordDataset: 0.6247196197509766
Plain Python: 0.001483917236328125
```

**Other info / logs** 
None, but happy to provide on request. 
"
40501,SavedModel does not work correctly with signatures that use structured inputs or outputs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-34056-gde8db50778 2.3.0-dev20200613
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
As described [here](https://www.tensorflow.org/guide/concrete_function#nested_arguments), support for structured/nested arguments is available in TF nightly builds and coming to 2.3. Getting concrete functions with structured inputs and outputs works as documented, but using these concrete functions as signatures in saved models leads to a various issues.

See the following code snippet for simple example cases.
```python
from collections import namedtuple
import tensorflow as tf

Pair = namedtuple('Pair', ('x', 'y'))

class TestModel(tf.keras.Model):
  @tf.function
  def test(self, inputs: Pair):
    # Unlike inputs, outputs would need to be manually flattened if nested.
    return Pair(inputs.x + inputs.y, inputs.x - inputs.y)

model = TestModel()
specs = Pair(tf.TensorSpec([], tf.int32), tf.TensorSpec([], tf.int32))
signatures = {'test': model.test.get_concrete_function(inputs=specs)}

tf.saved_model.save(model, 'test_model', signatures=signatures)
loaded_model = tf.saved_model.load('test_model')

# When using the original signature it works correctly.
# This produces a Pair with tensor values (5, 1).
inputs = Pair(tf.constant(3, tf.int32), tf.constant(2, tf.int32))
output_pair = signatures['test'](inputs)

# The same does not work when using the signature from the loaded model.
# It fails because inputs have been flattened. This is acceptable, but not documented.
loaded_model.signatures['test'](inputs)

# However, flattening the input data does not help.
# This fails too because the signature now requires keyword arguments.
loaded_model.signatures['test'](*tf.nest.flatten(inputs, expand_composites=True))

# This fails too because the keyword argument names are generated by TF.
loaded_model.signatures['test'](x=inputs.x, y=inputs.y)

# This works, but it's utterly confusing. Note the args 'inputs' and 'inputs_1'.
outputs = loaded_model.signatures['test'](inputs=inputs.x, inputs_1=inputs.y)

# Outputs are also flattened. However, we get a dict. This means we cannot
# do this to recover the structure as order is not necessarily preserved.
# For more complex nested structures this would be pretty much needed.
bad_output_pair = tf.nest.pack_sequence_as(specs, list(outputs.values()))

# Not only that, but key names are not even consistent with inputs.
# This fails because the 'output' key does not exist.
output_pair = Pair(outputs['output'], outputs['output_1'])

# This works, but it's again confusing and not self-consistent.
output_pair = Pair(outputs['output_0'], outputs['output_1'])
```

**Describe the expected behavior**
While it would be desirable to be able to use structured types directly, flattening them is a reasonable tradeoff for signatures in exported models.

However:
1. It should be properly documented.
2. It should make recovering arbitrarily nested structures easy.
3. It should be self-consistent.

If flattening inputs and outputs is required, then a much better approach would be to transform potentially nested structures into tuples of their flattened contents. These tuples could then be referred either by position or by their keyword argument.

For example:
```python
# This could work if it accepted flattened tuples by position.
flat_outputs = loaded_model.signatures['test'](tf.nest.flatten(inputs, True))

# This could work if it accepted flattened tuples by keyword argument,
# which would help with functions taking multiple structured input arguments.
flat_outputs = loaded_model.signatures['test'](inputs=tf.nest.flatten(inputs, True))

# flat_outputs can still be a dict if it maps to tuples of flattened tensors.
# This would work for arbitrarily complex nested structures,
# and would also remove the need to generate new output names.
output_pair = tf.nest.pack_sequence_as(specs, flat_outputs['output'])

# Returning the flattened tuple directly or a sequence of outputs instead of a dict
# would perhaps make more sense, but this would need to work with other use cases.
output_pair = tf.nest.pack_sequence_as(specs, flat_outputs[0])
```

These changes would make the behavior of loaded model signatures tf.nest-friendly.

It would also be best to make these changes before the feature goes public in the incoming TF 2.3 release, as otherwise developers might start writing code that depends on the current confusing and inconsistent keyword args behavior.

Edit: corrected the code example to correctly account for composite tensors on inputs, and to mention the additional issue from the first comment."
40500,"FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.   _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])","Hi, how to disable it?
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  not working

i'm using TS 1.14
keras
and imageai
full warning: 
`{ProjectPath}\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])`


"
40499,Tensorflow 2.0 converter.experimental_new_converter = True still giving 'str' object has no attribute 'call',"**System information**
- OS Platform and Distribution: Windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source): tensorflow 2.2.0


**Command used to run the converter or code if youre using the Python API**

```
converter = tf.lite.TFLiteConverter.from_keras_model(keras_file)
converter.experimental_new_converter = True
tflite_model = converter.convert()
open(""linear.tflite"", ""wb"").write(tflite_model)
```

**The output from the converter invocation**

```
AttributeError                            Traceback (most recent call last)
<ipython-input-12-b0b66b38a77c> in <module>
----> 1 converter = tf.lite.TFLiteConverter.from_keras_model(keras_file)
      2 converter.experimental_new_converter = True
      3 tflite_model = converter.convert()
      4 open(""linear.tflite"", ""wb"").write(tflite_model)

c:\python\python38\lib\site-packages\tensorflow\lite\python\lite.py in from_keras_model(cls, model)
    426     # to None.
    427     # Once we have better support for dynamic shapes, we can remove this.
--> 428     if not isinstance(model.call, _def_function.Function):
    429       # Pass `keep_original_batch_size=True` will ensure that we get an input
    430       # signature including the batch dimension specified by the user.

AttributeError: 'str' object has no attribute 'call'

```

(https://github.com/tensorflow/tensorflow/issues/32693)
I referred to this previous forum for the same error and saw one of the solutions was to use the 'experimental_new_converter = True' function but I'm still getting the same error. I would reopen the mentioned forum if I could but I'm not sure how."
40498,tf.GatherV2 is always not support ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04
- TensorFlow installed from (source or binary):pip
- TensorFlow version (or github SHA if from source):
2.2

**Provide the text output from tflite_convert**
tflite_convert   --from_keras_model
```
# Copy and paste here
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**
tf.gatherV2 op is neither a custom op nor a flex op
Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.

my use case is  tf.gather(params.index,batch_dims=1)"
40497,Undefined references when using TensorFlow Lite in Arduino Nano 33 BLE Sense + Platform IO,"@tensorflow/micro

**System information**
Ubunutu 20.04 on x86_64
TensorFlow from source 2.2.0
Target: Arduino Nano 33 BLE Sense

Hi,

I'm trying to get micro_speech running on a Arduino Nano 33 BLE Sense, using a model I've trained myself on Google Colab.  As Google Colab is currently using TensorFlow 2.2.0, this model is also 2.2.0.  Using the Arduino IDE 1.8.12 sample 'micro_speech', does work, and I can get inferences to occur, however this is a long way from TensorFlow 2.2.0.  In fact its many versions behind and as a result, I'm unable to get my model to run on this version.

In addition, this project is a stepping stone to another project which will swap out the model for other models, and introduce other libraries which introduce further development and debugging complexity.  For this reason, I've chosen to adopt the Platform IO + VSCode development environment.  With this combination I can debug the code, step by step, which is a feature not supported by the Microsoft VSCode Arduino extension or Arduino IDE itself.  I can also use unit testing technologies which aren't available elsewhere.

Unfortunately, my code is running into Undefined reference exceptions on build, in what is a fairly trivial port of the micro_speech application to the Platform IO code.  I get these same errors building the code using the local TensorFlow Arduino library zip which I built myself from the TensorFlow 2.2.0 master branch a couple of days ago.

May I please get some advice?
- Any ideas why Undefined references are appearing in local builds of [micro_speech](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/micro_speech), or my port of the [micro_speech](https://github.com/victorromeo/pio_micro_speech) product?  It was also reported in this issue [27629](https://github.com/tensorflow/tensorflow/issues/27629)
- Given the explosion of options, which development environment is the recommended approach for products which extend beyond 'hello-world' targeting micro-controllers? 
  - Arduino Online 
  - Arduino IDE with local TensorFlow Arduino library zip  
  - TensorFlow Lite + Bazel from command  line
  - Platform IO (IDE / VSCode / Atom)
  - Microsoft Arduino over VSCode
  - entirely manual arm-none-eabi-g++

```
> Executing task: platformio run --verbose <

Processing nano33ble (platform: nordicnrf52; board: nano33ble; framework: arduino; debug_tool: jlink; upload_protocol: jlink)
----------------------------------------------------------------
CONFIGURATION: https://docs.platformio.org/page/boards/nordicnrf52/nano33ble.html
PLATFORM: Nordic nRF52 4.2.1 > Arduino Nano 33 BLE
HARDWARE: NRF52840 64MHz, 256KB RAM, 960KB Flash
DEBUG: Current (jlink) External (cmsis-dap, jlink)
PACKAGES: 
 - framework-arduino-nrf52-mbedos 1.1.3 
 - tool-sreccat 1.164.0 (1.64) 
 - toolchain-gccarmnoneeabi 1.80201.181220 (8.2.1)
LDF: Library Dependency Finder -> http://bit.ly/configure-pio-ldf
LDF Modes: Finder ~ chain, Compatibility ~ soft
Framework incompatible library /home/ian/.platformio/packages/framework-arduino-nrf52-mbedos/libraries/mbed-memory-status
Found 7 compatible libraries
More details about ""Library Compatibility Mode"": https://docs.platformio.org/page/librarymanager/ldf.html#ldf-compat-mode
Scanning dependencies...
Dependency Graph
|-- <PDM> 1.0 (/home/ian/.platformio/packages/framework-arduino-nrf52-mbedos/libraries/PDM)
|-- <micro_features> (/home/ian/Documents/PlatformIO/Projects/Nano33Take01/lib/micro_features)
|   |-- <tensorflow> (/home/ian/Documents/PlatformIO/Projects/Nano33Take01/lib/tensorflow)
|-- <tensorflow> (/home/ian/Documents/PlatformIO/Projects/Nano33Take01/lib/tensorflow)
Building in release mode
arm-none-eabi-g++ -o .pio/build/nano33ble/firmware.elf -T linker_script.ld -DMBED_APP_SIZE=0xf0000 -DMBED_APP_START=0x10000 -DMBED_BOOT_STACK_SIZE=2048 -Wl,--gc-sections -Wl,--wrap,_calloc_r -Wl,--wrap,_free_r -Wl,--wrap,_malloc_r -Wl,--wrap,_memalign_r -Wl,--wrap,_realloc_r -Wl,--wrap,atexit -Wl,--wrap,exit -Wl,--wrap,main -Wl,-n -mcpu=cortex-m4 -mfloat-abi=softfp -mfpu=fpv4-sp-d16 -mthumb --specs=nano.specs --specs=nosys.specs -Wl,--as-needed .pio/build/nano33ble/src/audio_provider.cpp.o .pio/build/nano33ble/src/command_responder.cpp.o .pio/build/nano33ble/src/feature_provider.cpp.o .pio/build/nano33ble/src/main.cpp.o .pio/build/nano33ble/src/recognize_commands.cpp.o -L.pio/build/nano33ble -L/home/ian/.platformio/packages/framework-arduino-nrf52-mbedos/variants/ARDUINO_NANO33BLE -L/home/ian/.platformio/packages/framework-arduino-nrf52-mbedos/variants/ARDUINO_NANO33BLE/libs -Wl,--start-group -Wl,--whole-archive .pio/build/nano33ble/libe06/libPDM.a .pio/build/nano33ble/lib5e8/libtensorflow.a .pio/build/nano33ble/lib082/libmicro_features.a .pio/build/nano33ble/libFrameworkArduinoVariant.a .pio/build/nano33ble/libFrameworkArduino.a -lmbed -lcc_310_core -lcc_310_ext -lcc_310_trng -Wl,--no-whole-archive -lstdc++ -lsupc++ -lm -lc -lgcc -lnosys -Wl,--end-group
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/src/command_responder.cpp.o: in function `RespondToCommand(tflite::ErrorReporter*, long, char const*, unsigned char, bool)':
/home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/command_responder.cpp:48: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/src/feature_provider.cpp.o: in function `FeatureProvider::PopulateFeatureData(tflite::ErrorReporter*, long, long, int*)':
/home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/feature_provider.cpp:102: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/src/main.cpp.o: in function `tflite::MicroMutableOpResolver<4u>::GetOpDataParser(tflite::BuiltinOperator) const':
/home/ian/Documents/PlatformIO/Projects/Nano33Take01/lib/tensorflow/tensorflow/lite/micro/micro_mutable_op_resolver.h:62: undefined reference to `tflite::ParseOpData(tflite::Operator const*, tflite::BuiltinOperator, tflite::ErrorReporter*, tflite::BuiltinDataAllocator*, void**)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/src/main.cpp.o: in function `tflite::MicroMutableOpResolver<4u>::AddCustom(char const*, TfLiteRegistration*)':
/home/ian/Documents/PlatformIO/Projects/Nano33Take01/lib/tensorflow/tensorflow/lite/micro/micro_mutable_op_resolver.h:98: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/lib/tensorflow/tensorflow/lite/micro/micro_mutable_op_resolver.h:108: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/src/main.cpp.o: in function `tflite::MicroMutableOpResolver<4u>::AddBuiltin(tflite::BuiltinOperator, TfLiteRegistration*)':
/home/ian/Documents/PlatformIO/Projects/Nano33Take01/lib/tensorflow/tensorflow/lite/micro/micro_mutable_op_resolver.h:68: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/lib/tensorflow/tensorflow/lite/micro/micro_mutable_op_resolver.h:78: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/src/main.cpp.o: in function `setup':
/home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:75: undefined reference to `tflite::ops::micro::Register_DEPTHWISE_CONV_2D()'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:80: undefined reference to `tflite::ops::micro::Register_FULLY_CONNECTED()'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:85: undefined reference to `tflite::ops::micro::Register_SOFTMAX()'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:90: undefined reference to `tflite::ops::micro::Register_RESHAPE()'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:98: undefined reference to `tflite::MicroInterpreter::MicroInterpreter(tflite::Model const*, tflite::MicroOpResolver const&, unsigned char*, unsigned int, tflite::ErrorReporter*)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:102: undefined reference to `tflite::MicroInterpreter::AllocateTensors()'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:109: undefined reference to `tflite::MicroInterpreter::input(unsigned int)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:131: undefined reference to `tflite::MicroInterpreter::~MicroInterpreter()'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:59: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:114: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/src/main.cpp.o: in function `loop':
/home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:172: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:157: undefined reference to `tflite::MicroInterpreter::Invoke()'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/main.cpp:164: undefined reference to `tflite::MicroInterpreter::output(unsigned int)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/src/main.cpp.o:(.data._ZZ5setupE20micro_error_reporter+0x0): undefined reference to `vtable for tflite::MicroErrorReporter'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/src/recognize_commands.cpp.o: in function `RecognizeCommands::ProcessLatestResults(TfLiteTensor const*, long, char const**, unsigned char*, bool*)':
/home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/recognize_commands.cpp:46: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/recognize_commands.cpp:60: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/src/recognize_commands.cpp:74: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/src/recognize_commands.cpp.o: in function `PreviousResultsQueue::push_back(PreviousResultsQueue::Result const&)':
/home/ian/Documents/PlatformIO/Projects/Nano33Take01/include/recognize_commands.h:66: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/src/recognize_commands.cpp.o: in function `PreviousResultsQueue::pop_front()':
/home/ian/Documents/PlatformIO/Projects/Nano33Take01/include/recognize_commands.h:79: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/lib082/libmicro_features.a(micro_features_generator.cpp.o): in function `InitializeMicroFeatures(tflite::ErrorReporter*)':
/home/ian/Documents/PlatformIO/Projects/Nano33Take01/lib/micro_features/micro_features_generator.cpp:50: undefined reference to `FrontendPopulateState'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: /home/ian/Documents/PlatformIO/Projects/Nano33Take01/lib/micro_features/micro_features_generator.cpp:52: undefined reference to `tflite::ErrorReporter::Report(char const*, ...)'
/home/ian/.platformio/packages/toolchain-gccarmnoneeabi/bin/../lib/gcc/arm-none-eabi/8.2.1/../../../../arm-none-eabi/bin/ld: .pio/build/nano33ble/lib082/libmicro_features.a(micro_features_generator.cpp.o): in function `GenerateMicroFeatures(tflite::ErrorReporter*, short const*, int, int, signed char*, unsigned int*)':
/home/ian/Documents/PlatformIO/Projects/Nano33Take01/lib/micro_features/micro_features_generator.cpp:79: undefined reference to `FrontendProcessSamples'
collect2: error: ld returned 1 exit status
*** [.pio/build/nano33ble/firmware.elf] Error 1
================== [FAILED] Took 1.25 seconds ==================
The terminal process terminated with exit code: 1

Terminal will be reused by tasks, press any key to close it.
```"
40495,[batch AUC vs streaming AUC]: I want an implement a batch AUC method,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.4 and 2.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
Tensorflow only support streaming auc. If we want to monitoring the batch auc, we need to reset auc local variables or change the source code of `tensorflow.python.ops.metrics_impl`.

**Will this change the current api? How?**

It only add an optional arg named `batch=False` to current metrics.auc op like:

- tf.keras.metrics.AUC(_, batch=False)

- tf.compat.v1.metrics.auc(_, batch=False)

**Who will benefit with this feature?**
Developers want to monitoring the realtime batch_auc.  E.g:

- online training

- monitoring ordered training/eval data with diff distribution

- compute and log each batch auc


**Any Other info.**

I have implement a batch AUC method for myself and works fine. It changes the code of `tensorflow.python.ops.metrics_impl`. 

I also changed accuracy metric to enable the batch metric function.
"
40494,"tf-nightly build spits out thousands of lines about ""whitelisting"" during training","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2
- Python version: 3.6.2
- CUDA/cuDNN version: release 10.0, V10.0.130
- GPU model and memory: TITAN X

**Describe the current behavior**
I am attempting to train a model using the tf-nightly build using the tf.data.Dataset api. It works (and continues to train) but prints out thousands (if not hundreds of thousands) of lines about ""whitelisting"" parameters.

**Other info / logs**
This is an example of what it's printing out:

I0615 19:58:57.821352 140192954160896 ag_logging.py:140] Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_t
o_update_var at 0x7f80b7957620>: from cache
Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f80b7957620>: from cache
I0615 19:58:57.822939 140192954160896 ag_logging.py:140] Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_gr
ad_to_update_var at 0x7f80b7957620>
    args: (<tf.Variable 'conv4_block11_1_bn/gamma:0' shape=(256,) dtype=float32>, <tf.Tensor 'gradient_tape/resnet152v2/conv4_block
11_1_bn/FusedBatchNormGradV3:1' shape=(256,) dtype=float32>)
    kwargs: {}

Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f80b7957620>
    args: (<tf.Variable 'conv4_block11_1_bn/gamma:0' shape=(256,) dtype=float32>, <tf.Tensor 'gradient_tape/resnet152v2/conv4_block
11_1_bn/FusedBatchNormGradV3:1' shape=(256,) dtype=float32>)
    kwargs: {}

I0615 19:58:57.823056 140192954160896 ag_logging.py:140] Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_t
o_update_var at 0x7f80b7957620>: from cache
Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f80b7957620>: from cache
I0615 19:58:57.824649 140192954160896 ag_logging.py:140] Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_gr
ad_to_update_var at 0x7f80b7957620>
    args: (<tf.Variable 'conv4_block11_1_bn/beta:0' shape=(256,) dtype=float32>, <tf.Tensor 'gradient_tape/resnet152v2/conv4_block1
1_1_bn/FusedBatchNormGradV3:2' shape=(256,) dtype=float32>)
    kwargs: {}

Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f80b7957620>
    args: (<tf.Variable 'conv4_block11_1_bn/beta:0' shape=(256,) dtype=float32>, <tf.Tensor 'gradient_tape/resnet152v2/conv4_block1
1_1_bn/FusedBatchNormGradV3:2' shape=(256,) dtype=float32>)
    kwargs: {}

I0615 19:58:57.824765 140192954160896 ag_logging.py:140] Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_t
o_update_var at 0x7f80b7957620>: from cache
Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f80b7957620>: from cache
I0615 19:58:57.826352 140192954160896 ag_logging.py:140] Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_gr
ad_to_update_var at 0x7f80b7957620>
    args: (<tf.Variable 'conv4_block11_2_conv/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'gradient_tape/resnet152v
2/conv4_block11_2_conv/Conv2DBackpropFilter:0' shape=(3, 3, 256, 256) dtype=float32>)
    kwargs: {}

Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f80b7957620>
    args: (<tf.Variable 'conv4_block11_2_conv/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'gradient_tape/resnet152v
2/conv4_block11_2_conv/Conv2DBackpropFilter:0' shape=(3, 3, 256, 256) dtype=float32>)
    kwargs: {}
"
40492,Reduce size of published wheel files (_pywrap_tensorflow_internal.so),"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

**System information**
- TensorFlow version (you are using): 2.2.0
- Are you willing to contribute it (Yes/No): N/A

**Describe the feature and the current behavior/state.**
The size of the wheel files published for Tensorflow over the 2.x.x releases has increased dramatically and is reaching somewhat absurd levels. Taking for example the cp37 manylinux2010 wheel:

2.0.0: 84 MB
2.1.0: 422 MB
2.2.0: 516 MB

Presently, anyone depending on these wheels may have seen their download and build times quintuple over the 2.x.x lifespan, with resulting images etc also now significantly larger than before.

The increase in size appears to be dominated by a single 1.2 GB shared library file `_pywrap_tensorflow_internal.so`. Presumably this increase might relate to the switch from swig to pybind, with this .so file containing nearly half a million symbols. Many of these symbols are stacks of variations of parameters to single functions.

Obviously just asking for a file to be smaller isn't much help, but I would hope this can prompt some discussion about ways this can be remedied? Assuming it is related to the pybind switch, is there anything that can be learned from the prior swig architecture and applied in the current process?

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
All users who depend on the Python .whl files published to PyPI. Users with custom builds of Tensorflow will likely also have this large .so issue.

**Any Other info.**
There may already be an issue or discussion related to this, but GitHub search didn't reveal much."
40491,Minimum pooling operation. ,"
**System information**
- TensorFlow version (you are using): Latest as of 6/15/20
- Are you willing to contribute it (Yes/No): Yes.

**Describe the feature and the current behavior/state.**

Tensorflow/Keras has max pooling, and average pooling, but there is no minimum pooling. A minimum pooling operation feature would be great to have. 


**Will this change the current api? How?**

There could be a tf.nn.min_pool

**Who will benefit with this feature?**

Minimum pooling of embeddings can be powerful features, especially if those embeddings that are created with architectures which use a tanh activation (instead of rulu, sigmoid, etc.), since these embeddings would contain useful information in both the positive and negative direction of the embedding. 


"
40487,tfcompile for non-x86-64 CPU,"Are there possibilities to cross-compile with `tfcompile` for other architectures (aarch64, CortexM, etc..)?"
40486,tfcompile AOT with quantization,"Does the `tfcompile` have capability of quantization?
Is `tfcompile` able to process on input the quantized models?"
40485,d,d
40484,Bug in tf.strings.split vs tf.compat.v1.string_split,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installed from (source or binary): Colab
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.9

**Describe the current behavior**
tf.strings.split doesn't work as expected when the seperator is multiple characters.
**Describe the expected behavior**
tf.strings.split().to_sparse() should have the exact same behavior as tf.compat.v1.string_split()
yet when multiple characters are provided, tf.strings.split doesn't work

**Standalone code to reproduce the issue**
[github gist](https://gist.github.com/tommywei110/85328711e3cf1c0544fb4aca14bda37b)

`import tensorflow as tf`
`sentence = tf.constant([['cat goes meow'], ['dog?goes!woof']])`
`print(sentence)`
`v2 = tf.strings.split(sentence,' !?').to_sparse()`
`print(v2)`
`v1 = tf.compat.v1.string_split(tf.reshape(sentence, [-1]), ' !?')`
`print(v1)`
"
40482,Support for use of tensorflow_probability.distributions.Distribution instances in model.fit(...),"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): No (have yet to work out the best way to implement)



**Describe the feature and the current behavior/state.**

I have a model that I would like to train using the KL divergence between the model output and a tfp.distributions.Distribution instance. (Note: this model is using tensorflow_probability's probabilistic layers). As of right now, Distributions cannot be plumbed through the model.fit(...) pipeline due to incompatibilities with the DataAdapter classes, as:

1) They are not recognised by TensorLikeDataAdapter as a Tensor-like object (i.e. they fail the _is_tensor() check).

2) tf.keras.utils.Sequence instances that return distributions fail in convert_for_inspection (calling np.array(distribution,dtype='float64') fails as np sees distributions as sequences).

**Will this change the current api? How?**
Change to support this should have no effect on the API, but would expand functionality to users of tf and tfp.

**Who will benefit with this feature?**
Users who use both tf and tfp, and need to use distributions to train models.

**Any Other info.**
"
40481,How to use sliding_window_batch in TF 2.2.0,How to use tf.contrib.data.sliding_window_batch in tf 2.2.0
40478,Predcit function result is different from Training-Val using the same data,"Version:
Tensorflow 2.0.0 
Keras 2.3.1
Ubuntu 18

I use predict to check the model performance on val data but it is totally different from the training log file. **Predict and Val in the training use the same dataset.**

The top layers of my model:
`        
        model = Sequential()
        model.add(Embedding(input_dim = num_words,
                            output_dim=EMBEDDING_DIM,
                                    weights=[emb],  # remove this if you want to train your weight
                                    input_length=maxlen,
                                    trainable=train_embedding,
                                    mask_zero=True))
        ........
        .........
         model.add(Dropout(0.2))
        # Heuristic model: outputs 1-of-num_classes prediction
        model.add(BatchNormalization())

        model.add(Dense(dense_layer_size, activation=""relu""))

        model.add(Dense(1, activation=""sigmoid""))

        self.model = model

        self.model.compile(
            optimizer=""adam"",
            loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
            metrics=[
                  tf.keras.metrics.AUC(curve=""PR"", name=""PR""),
                      tf.keras.metrics.AUC(curve=""ROC"", name=""ROC""),
                    ""accuracy"",
                    tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),
                     tf.keras.metrics.binary_accuracy],
        )
`

Train code
`
self.model.fit_generator(train_generator, epochs=epochs, verbose=verbose,
                                     validation_data = validation_generator,
                                     shuffle=True, callbacks=[checkpoint], class_weight=class_weights)
`
Prediction and Compute AUC-PR code:

`

padded_x = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)

classlable, pro = model.predict(padded_x, batch_size)
pro = np.squeeze(pro)
y_test = np.squeeze(y_test)
from sklearn import metrics
precision, recall, thresholds = metrics.precision_recall_curve(y_test, pro)
pr = metrics.auc(recall, precision)
print(""PR {}"".format(pr))

`
Use Prediction compute PR-AUC:  0.2803784709997255
But  Val_PR: 0.4

I tried some solutions I found, use model.save.save or from keras.backend import manual_variable_initialization
manual_variable_initialization(True).
1. When I save the whole model weights, does the save function also save the Embedding layer?
2. I am doing binary-classification task, am I correctly using the metrics in model.compile  function?"
40477,Post-training full integer quantization produces model with float inputs/outputs,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Running from Colab notebook
- TensorFlow installed from (source or binary): Running from Colab notebook
- TensorFlow version (or github SHA if from source): v2.2.0-0-g2b96f3662b


**Command used to run the converter or code if youre using the Python API**
Colab notebook:
[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb)

**Failure details**
The conversion is successful, however the quantized model with float inputs/outputs (`/tmp/mnist_tflite_models/mnist_model_quant.tflite`) and the one with supposed int8 inputs/outputs (`/tmp/mnist_tflite_models/mnist_model_quant_io.tflite`) are identical. I've verified this by running 
```
diff mnist_model_quant.tflite mnist_model_quant_io.tflite
```
which resulted in an empty output (that is, the files are identical).

**Any other info / logs**
Here's what `mnist_model_quant_io.tflite` looks like when I open it with netron:
![netron](https://user-images.githubusercontent.com/30210403/84680403-f1500400-af32-11ea-980f-4a7b4b013dc9.png)
Rather than having a ""Quantize"" node right after the float input and a ""Dequantize"" node right before the float output, I would like to have int8 inputs/outputs directly. How to do that?

"
42806,Little bug? ,"I think it's a bug
![image](https://user-images.githubusercontent.com/7847271/84676251-f498bf00-af35-11ea-8bd4-845697e447e0.png)
"
40476,ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.   Failed to load the native TensorFlow runtime.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
Have I written custom code: No
OS Platform and Distribution: Windows 10 Pro updated
Mobile device: None
- TensorFlow version:**TensorFlow-2.2.0**
- Python version:** python .3.8.3**
- Installed using **pip**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**from keras.layers import Convolution2D**
I'm sure that TensorFlow is installed in my current environment. But still, the following error is shown up when I tried to run the above command.
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59 

~\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~\.anaconda\anaconda1\envs\deeplearning\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

~\.anaconda\anaconda1\envs\deeplearning\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-027d7fb732fd> in <module>
----> 1 from keras.layers import Convolution2D

~\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\keras\__init__.py in <module>
      1 from __future__ import absolute_import
      2 
----> 3 from . import utils
      4 from . import activations
      5 from . import applications

~\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\keras\utils\__init__.py in <module>
      4 from . import data_utils
      5 from . import io_utils
----> 6 from . import conv_utils
      7 from . import losses_utils
      8 from . import metrics_utils

~\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\keras\utils\conv_utils.py in <module>
      7 from six.moves import range
      8 import numpy as np
----> 9 from .. import backend as K
     10 
     11 

~\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\keras\backend\__init__.py in <module>
----> 1 from .load_backend import epsilon
      2 from .load_backend import set_epsilon
      3 from .load_backend import floatx
      4 from .load_backend import set_floatx
      5 from .load_backend import cast_to_floatx

~\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\keras\backend\load_backend.py in <module>
     88 elif _BACKEND == 'tensorflow':
     89     sys.stderr.write('Using TensorFlow backend.\n')
---> 90     from .tensorflow_backend import *
     91 else:
     92     # Try and load external backend.

~\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\keras\backend\tensorflow_backend.py in <module>
      3 from __future__ import print_function
      4 
----> 5 import tensorflow as tf
      6 from tensorflow.python.eager import context
      7 from tensorflow.python.framework import device as tfdev

~\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\tensorflow\python\__init__.py in <module>
     48 import numpy as np
     49 
---> 50 from tensorflow.python import pywrap_tensorflow
     51 
     52 # Protocol buffers

~\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     67 for some common reasons and solutions.  Include the entire stack trace
     68 above this error message when asking for help."""""" % traceback.format_exc()
---> 69   raise ImportError(msg)
     70 
     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\BASHEER\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\BASHEER\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\BASHEER\.anaconda\anaconda1\envs\deeplearning\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\BASHEER\.anaconda\anaconda1\envs\deeplearning\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\BASHEER\.anaconda\anaconda1\envs\deeplearning\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.


Failed to load the native TensorFlow runtime.


"
40472,ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.,"Good day, 

I am new to TensorFlow and I am trying to install the package (cpu_version) but I am failing to.
**Python version:** _Python 3.7, 64 bit (AMD64)] :: Anaconda, Inc. on win32_. 
I have been following the install steps as outlined here - [https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html](url) but when I get to the `import tensorflow as tf` part I am getting this error: 

_import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\User\Anaconda3\envs\tensorflow_cpu\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.
Failed to load the native TensorFlow runtime._

Please help :(
"
40471,Equal function forgets static shape in graph-mode in tensorflow 2.1 and 2.2,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Microsoft Windows 10 Enterprise
- TensorFlow installed from (source or binary): official pipy wheel
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.7.6

**Describe the current behavior**
In graph-mode when `x.shape == [None, 10, 1]`, `y.shape == [None, 1, 4]` then one would expect `(x==y).shape` to be `[None, 10, 4]`. This really works in tensorflow 2.0. In tensorflow 2.1 and 2.2 it is a completely undefined shape.

**Describe the expected behavior**
The same behaviour as in tensorflow 2.0.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf

@tf.function(input_signature=[tf.TensorSpec([None, 10, 1]), tf.TensorSpec([None, 1, 4])])
def fun(x, y):
    z = x == y
    tf.print(""z.shape ="", z.shape)
    return z

fun(tf.ones([5, 10, 1]), tf.ones([5, 1, 4]));
```
In tensorflow 2.0, this code prints `z.shape = TensorShape([None, 10, 4])`.
In tensorflow 2.2 and 2.1, this code prints `z.shape = TensorShape(None)`."
40470,Using own dataset in microspeech project doesn't work ,"@tensorflow/micro

**System information**

- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): currently working with Google Colab 
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source): Tensorflow 1.x
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Arduino Nano 33 BLE Sense

**Describe the problem**

Hello everyone, 

I just started to get into the world of machine learning and deep learning and I still need to learn a lot, but I hope that there might be someone who faced similar problems to the ones that I try to solve at the moment. 

A few weeks ago, I started working with the microspeech example for microcontrollers. My goal was (and still is) to get the project working with an own wake word. To save time, I decided to expand the speech commands dataset with a folder containing my own data. My wanted wake word is a german one (I'm not sure if this is an important information but I try to tell as much information as possible at the moment). 

At first, I only used samples of my own voice. To get more samples in a short time, I combined the original recordings with ones that were slightly manipulated. 
After that, I uploaded my data to Google Drive so that I could import it to Colab. I changed the 'wanted word' section and the 'data_dir' section according to my wanted word. 

Training seemed to work well and I changed the code in the microspeech project in the Arduino IDE and uploaded it to the Arduino. I expected the green LED to flash when I say the wake word and the blue one to do so if I say some other word of the dataset (as it is intended in the original project). But no matter what I said, only the blue one LED flashed. 

In a second step, I changed my dataset because I thought that it might be a problem that my dataset only consists of recordings of my own voice. So I collected new data with recordings from different people and tried everything that I did before with my new data. 
This time the arduino behaves a bit different as the green LED flashes randomly when nothing is said at all. And when I say my wake word, the blue LED is still flashing as it did before. 

As I said at the beginning, I'm new to this topic and so I only can imagine some possible causes for my issues (please feel free to correct me if some things don't make sense):

- I didn't collect enough samples of my wake word (at the moment there are 820 samples in the folder)
- there might be a problem that I only want to detect one word instead of two or more
- I forgot to change sth. in the Arduino project code or did sth. wrong
- it could be a problem that my dataset is a mix of English and German words 

**Please provide the exact sequence of commands/steps when you ran into the problem**

After training, I copy the code and paste it into the _micro_features_tiny_conv_micro_features_model_data.cpp_ and I also correct the data length parameter at the end of the source file. 

Then, I change _micro_features_micro_model_settings.cpp_ and _micro_features_micro_model_settings.h_ according to my wake word and the number of labels that I've got. 

Finally I go to the _arduino_command_responder.cpp_ and change the first if condition to **if(found_command[0] == 'h')**, as the wake word begins with an h. I erase the second if condition because I don't have a second wake word. 

Then I upload the project to the arduino. 

If there are any information missing please tell me and I will provide them.

Kind regards, 
eeesi"
40469,Tensorflow Lite subtraction in TOCO quantized model takes longer than all the convolutions in a MobileNet v3 model,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu/ARM
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: 

**Describe the current behavior**
Created MobileNet v3 model that includes subtraction and multiplication for normalization in the graph. Quantized the model with TOCO using post training quantization. Model was running very slow on ARM and x86. Profiling shows suctraction is responsible for 21% of the time
![image](https://user-images.githubusercontent.com/6794993/84648998-b2538b80-aefd-11ea-8407-36839ea175cf.png)

Using MLIR produces much more reasonable results
![image](https://user-images.githubusercontent.com/6794993/84649672-d499d900-aefe-11ea-9324-9cde5fd5c0ce.png)


**Describe the expected behavior**
Latency due to subtraction should be negligible

Can supply model and other info if necessary
"
40468,Gradient compression,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.2
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Feature: Gradient compression
Description: In distributed deep learning, communication of gradients often become a bottleneck. Gradient compression allows the gradients to be compressed so that the cost of communication is reduced. [Horovod](https://github.com/horovod/horovod) has a compression scheme built-in [here](https://github.com/horovod/horovod/blob/master/horovod/tensorflow/compression.py). The compression can speed up the distributed training (proved by various research). Building such a feature to Tensorflow would facilitate research as well as development.

**Will this change the current api? How?**


**Who will benefit with this feature?**
People who are interested in large scale distributed training. 

**Any Other info.**
"
40466,LoadSavedModel very slow in loading the net,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.5.2
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version: 10.1 / 7
- GPU model and memory: GeForce GTX 960M 2004MiB

**Describe the current behavior**
I am trying to load a keras SavedModel in C++ using the LoadSavedModel function and SavedModelBundleLite. 
The net is correctly loaded but it takes a lot of time (in my case around 70-90 seconds, which is too much in my opinion for such net, also because in python the laoding is much faster).

**Describe the expected behavior**
The time needed to load the net should be comparable with the python case.

**Standalone code to reproduce the issue**
PYTHON SIDE:
```
def create_model_vgg16(input_img_shape):
    base_model = keras.applications.VGG16(include_top=False, weights=""imagenet"", input_shape=input_img_shape)
    for layer in base_model.layers:
        layer.trainable = False
        
    model = keras.Sequential()

    model.add(keras.layers.Lambda(preprocess, name='preprocessing', input_shape=input_img_shape, output_shape=input_img_shape))
    for layer in base_model.layers[1:]:
        model.add(layer)
    model.add(keras.layers.Flatten())
    model.add(keras.layers.Dense(600, activation=""relu""))
    model.add(keras.layers.Dense(300, activation=""relu""))
    model.add(keras.layers.Dense(1, activation=""sigmoid""))
    
    return model

input_img_shape = (100,100,3)

model = create_model_vgg16(input_img_shape)

# ... training ...
model.save('saved_model/vgg_model') 
```

C++ SIDE

```
// loading the dnn model from file
  std::string modelfile_path = 
      std::string(common::kTrainingSamplesDirectory) + ""/../assets/"" + options_.modelfile_name;
      
  LOG(INFO) << ""ready to load the model"";

  auto status = 
      tf::LoadSavedModel(session_options_, run_options_, 
         modelfile_path, {tf::kSavedModelTagServe}, &model_);
  
  
  LOG(INFO) << ""after loading the model"";
  // this takes a lot

  if (!status.ok()) {
    LOG(ERROR) << ""Tracker Model not loaded successfully!"";
    return; 
  }
```

The output log :

```
2020-06-15 11:46:53.606488: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /home/hiro-robotics/Workspace/vs4_app_screwing/training_samples/../assets/vgg_model
2020-06-15 11:46:53.610125: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }
2020-06-15 11:46:53.610146: I tensorflow/cc/saved_model/loader.cc:295] Reading SavedModel debug info (if present) from: /home/hiro-robotics/Workspace/vs4_app_screwing/training_samples/../assets/vgg_model
2020-06-15 11:46:53.610211: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-15 11:46:53.624335: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2599990000 Hz
2020-06-15 11:46:53.624736: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb6f38aca80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-15 11:46:53.624750: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-15 11:46:53.626171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-15 11:46:53.635132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.0975GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s
2020-06-15 11:46:53.635491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-15 11:46:53.637397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-15 11:46:53.638597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-15 11:46:53.638994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-15 11:46:53.640652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-15 11:46:53.641880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-15 11:46:53.645200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-15 11:46:53.645773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-15 11:48:04.764783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-15 11:48:04.764807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-06-15 11:48:04.764813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-06-15 11:48:04.765615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 903 MB memory) -> physical GPU (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2020-06-15 11:48:04.767379: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb66fabe440 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-15 11:48:04.767394: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 960M, Compute Capability 5.0
2020-06-15 11:48:04.783707: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.
2020-06-15 11:48:04.928174: I tensorflow/cc/saved_model/loader.cc:183] Running initialization op on SavedModel bundle at path: /home/hiro-robotics/Workspace/vs4_app_screwing/training_samples/../assets/vgg_model
2020-06-15 11:48:04.941220: I tensorflow/cc/saved_model/loader.cc:364] SavedModel load for tags { serve }; Status: success: OK. Took 71334728 microseconds.
```

EDIT:
Actually I checked again the time needed in python and it is almost as slow as in C++. 
Then my problem is: why is it so slow? Should I expect that or there is something I can do to speed up the thing?

Thank you very much every hint is welcome"
40465,Tensorflow Java API reliability/stability guaranties,"Hello everyone

I want to use the TensorFlow Java API ( https://www.tensorflow.org/install/lang_java )

On the official page provided above it is stated that ""Caution: The TensorFlow Java API is not covered by the TensorFlow API stability guarantees.""

I have read the ""TensorFlow API stability guarantees"", googled little and still have the following questions:

1. If I will load the trained model with ""TensorFlow Java API""  and it will not complain, can I be sure that the inferred output is correct, meaning that I would get the same output if I would load the model in python?
2. When the 2.3 release expected to happen so TensorFlow Java API will support tensorflow 2?

Thanks
Harut"
40463,Add arm64 third-party CI,"**System information**
- TensorFlow version (you are using): 2.0+ and master branch
- Are you willing to contribute it (Yes/No): Yes


**Describe the feature and the current behavior/state.**
Currently, Tensorflow only has the official build CI on X86 and third-party build CIs on x86 and ppc64. There is no CI for arm64. Adding a arm64 CI can help community to discover arm64 problems easily.

OpenLab supports public CI system for opensource projects[1]. Now it supports arm64 arch and the tensorflow nightly build jobs for 2.0+ and master version have been added there as well[2]. It runs tensorflow build everyday at UTC-18.

Just like what tensorflow do currently, we can just easily add a new badge in the README.md file to link the Openlab arm64 third-party CI.

As you can see in the page[2], tensorflow 2.0, 2.1 and 2.2(master) build well on aarch64. But in some aws libs strongly based on x86 ARCH, so in master branch, I skip that part for build. You can see the build brief in [3], download the build whl packages there, and see the details logs in [4].

So adding the arm64 build CI is useful for the community.

1: https://openlabtesting.org
2: http://status.openlabtesting.org/builds?project=tensorflow%2Ftensorflow
3: http://status.openlabtesting.org/build/c816e5c9d6cc4519b933414fc6044d28
4: https://logs.openlabtesting.org/logs/periodic-18/github.com/tensorflow/tensorflow/master/tensorflow-arm64-build-daily-v2.1.0/c816e5c/

Additional context
Now the test is CPU only and is basing on Ubuntu 18.04 and python3.6. More can be added in the future.

And I'm from OpenLab commuinty. I'll keep looking after the tensorflow arm64 CI and try my best to fix the arm64 failure then.

Here is an example[1] we done in pytorch community. See 'Linux (aarch64) CPU' badge in the README.md. 
Also for another community[2], we done in greenplum-db community. See 'Zuul Regression Test On Arm' badge in the README.md

1: https://github.com/pytorch/pytorch/blob/master/README.md
2: https://github.com/greenplum-db/gpdb

**Will this change the current api? How?**
No
**Who will benefit with this feature?**
The arm64 users and developers

"
40462,passing labels=None to image_dataset_from_directory doesn't work,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS
- TensorFlow installed from (source or binary): tf-nightly
- TensorFlow version (use command below): v1.12.1-34068-g9a70ab8813 2.3.0-dev20200614
- Python version: 3.7.7

**Describe the current behavior**
Gives an error:
ValueError: `labels` argument should be a list/tuple of integer labels, of the same size as the number of image files in the target directory. If you wish to infer the labels from the subdirectory names in the target directory, pass `labels=""inferred""`. If you wish to get a dataset that only contains images (no labels), pass `labels=None`.

**Describe the expected behavior**
Should return a dataset hat only contains images (like the error message says)

**Standalone code to reproduce the issue**

```
import tensorflow as tf

train_images = tf.keras.preprocessing.image_dataset_from_directory(
    'images',
    labels=None,
)
```

**Other info / logs** 

```
Traceback (most recent call last):
  File ""train.py"", line 5, in <module>
    labels=None,
  File ""/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/preprocessing/image_dataset.py"", line 145, in image_dataset_from_directory
    '`labels` argument should be a list/tuple of integer labels, of '
ValueError: `labels` argument should be a list/tuple of integer labels, of the same size as the number of image files in the target directory. If you wish to infer the labels from the subdirectory names in the target directory, pass `labels=""inferred""`. If you wish to get a dataset that only contains images (no labels), pass `labels=None`.
```
"
40461,Tensorflow 2.2.0 import error - DLL load failed,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro [Version 10.0.19041.264]
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pip install
- TensorFlow version: 2.2.0
- Python version: 3.6.8 (issue also occurs with 3.7.7 and 3.8.3)
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**
I get the error that I'm missing some dynamic libraries when I try to import tensorflow after installing it. In the error message it is suggested that I download certain C++ dlls from visual studio. I did that and it still didn't work. I also downloaded visual studio code and the same problem persisted. Please note: the error message attached below also occurred with only tensorflow installed, with only tensorflow and tensorflow-gpu installed and finally, with all 3 (tensorflow, tensorflow-gpu, and tensorflow-cpu) installed.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
pip install tensorflow
pip install tensorflow-gpu
pip install tensorflow-cpu
python
>>import tensorflow


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

[tensorflow import error log.txt](https://github.com/tensorflow/tensorflow/files/4777264/tensorflow.import.error.log.txt)

"
40460,Can tf.keras.utils.normalize be verified by tf.norm?,"
I tried using `tf.keras.utils.normalize` to normalize the MNIST image dataset and then checking the normalized result with `tf.norm` on an arbitrary image (e.g. the 11th in the following sample) with:

```
(trainX, trainY), (testX, testY) = mnist.load_data()
print(trainX.shape)
print(np.amax(trainX[11]))  
trainX = tf.keras.utils.normalize(trainX,axis=1)
print(np.amax(trainX[11]))
print(tf.norm(trainX[11]))
```

but it gave me the following result:

```
(60000, 28, 28)
255
0.88178858555868
tf.Tensor(4.47213595499958, shape=(), dtype=float64)
```

I thought after normalization the max value of an arbitrary image should be `1` which is actually `0.88178858555868`. On the other hand, the norm of the normalized image should be `1` while it is `4.47213595499958`. Is my understanding wrong? Can anyone help me please?"
40459,ImportError: No module named '_pywrap_tensorflow_internal',"**System information**
- OS Platform and Distribution: Windows 10
- TensorFlow installed from (source or binary): i don't know which one; I'm fairly new to this. i installed via the command `pip install --user --upgrade tensorflow` iirc
- TensorFlow version: I am not sure; but its the version that pip currently installs i guess.
- Python version: 3.8.3
- Installed using virtualenv? pip? conda?: pip, as stated above.
- CUDA/cuDNN version: unsure how to find this.
- GPU model and memory: Nvidia GeForce gtx970, 3.5gb (if I'm not mistaken)



**Describe the problem**

I downloaded this repo and attempted to run ""test.py"" after installing all requirements successfully:
https://github.com/ialhashim/DenseDepth

i get an error message:
`ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'`



**Any other info / logs**
please see test.py from the above repository:
https://github.com/ialhashim/DenseDepth/blob/master/test.py

***here is my stack trace:***


Traceback (most recent call last):
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
  File ""C:\Program Files (x86)\Python38-32\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test.py"", line 8, in <module>
    from keras.models import load_model
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\keras\backend\__init__.py"", line 1, in <module>
    from .load_backend import epsilon
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\keras\backend\load_backend.py"", line 90, in <module>
    from .tensorflow_backend import *
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
  File ""C:\Program Files (x86)\Python38-32\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\aekna\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime."
40458,d,d
40457,TF 2.2.0: Error with model.fit; class_weight is only supported for Models with a single output.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Using custom loss function
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.8
- CUDA/cuDNN version: 10.1, 7.6
- GPU model and memory:  NVIDIA T4 Tensor Core GPU, AWS g4dn.xlarge 16GB

**Describe the current behavior**
- Error with `model.fit` function, when using `class_weight` as dictionary mapping class indices (integers) to a weight (float) values, for example {1.0: 0.6, 2.0, 0.4}.
- **Traceback**:
```
Traceback (most recent call last):
  File ""train.py"", line 117, in <module>
    main()
  File ""train.py"", line 112, in main
    use_multiprocessing=True
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 815, in fit
    model=self)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py"", line 1117, in __init__
    dataset = dataset.map(_make_class_weight_map_fn(class_weight))
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1621, in map
    return MapDataset(self, map_func, preserve_cardinality=True)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3981, in __init__
    use_legacy_function=use_legacy_function)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3221, in __init__
    self._function = wrapper_fn.get_concrete_function()
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2532, in get_concrete_function
    *args, **kwargs)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2496, in _get_concrete_function_garbage_collected
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3214, in wrapper_fn
    ret = _wrapper_helper(*args)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3156, in _wrapper_helper
    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 262, in wrapper
    return converted_call(f, args, kwargs, options=options)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 492, in converted_call
    return _call_unconverted(f, args, kwargs, options)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 346, in _call_unconverted
    return f(*args, **kwargs)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py"", line 1246, in _class_weights_map_fn
    ""`class_weight` is only supported for Models with a single output."")
ValueError: `class_weight` is only supported for Models with a single output.
```
- **My model input and output:**
    - Input: <tf.Tensor 'input.base_1.t1:0' shape=(None, 16) dtype=int32>
    - Output: <tf.Tensor 'output.base_1.t1/Identity:0' shape=(None, 25) dtype=float32>


**Describe the expected behavior**
- This was perfectly working with TF 2.1.0 and other previous versions. After upgrading to the 2.2.0 I'm getting this error and no changes was made to model architecture or any other parts of `model.fit` function.
"
40456,Model trained and saved on GPU fails at model open on CPU ,"Hi, this does not seem right. I have been training some models on TS-877 Ryzen-based NAS with 8 cores and 16 threads, and a GeForce GTX 1060 6GB graphics card, in a gpu-docker container Tensorflow:2.1.1-gpu-notebook (with CUDA version V10.1.243); then I have saved them as usual with `model.save()`. When I open them inside the container, everything works fine:

```
new_model.summary()
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_word_ids (InputLayer)  [(None, 192)]             0         
_________________________________________________________________
tf_distil_bert_model (TFDist multiple                  134734080 
_________________________________________________________________
tf_op_layer_strided_slice (T multiple                  0         
_________________________________________________________________
dense (Dense)                multiple                  769       
=================================================================
Total params: 134,734,849
Trainable params: 134,734,849
Non-trainable params: 0
_________________________________________________________________
```

**Describe the current behavior**
However, when I try to open this model in my computer, it fails tremendously, the summary shows all empty:
```
2020-06-14 21:38:07.495770: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-14 21:38:07.509869: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb6ff0417a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-14 21:38:07.509888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0
_________________________________________________________________
```

And trying to get any prediction yields all this:
```
2020-06-14 21:38:50.852268: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
Traceback (most recent call last):
  File ""open-model.py"", line 16, in <module>
    model.save(f'models/CPU_distilbert_batch16_epochs3_maxlen192') 
  File ""/Users/Margi7/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1052, in save
    signatures, options)
  File ""/Users/Margi7/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py"", line 138, in save_model
    signatures, options)
  File ""/Users/Margi7/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/Users/Margi7/anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 951, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/Users/Margi7/anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 1027, in _build_meta_graph
    options.namespace_whitelist)
  File ""/Users/Margi7/anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 629, in _fill_meta_graph_def
    signatures = _generate_signatures(signature_functions, resource_map)
  File ""/Users/Margi7/anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 497, in _generate_signatures
    function, mapped_inputs, resource_map)
  File ""/Users/Margi7/anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 449, in _call_function_with_mapped_captures
    resource_map)
  File ""/Users/Margi7/anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 372, in _map_captures_to_created_tensors
    ).format(interior))
AssertionError: Tried to export a function which references untracked object Tensor(""26682:0"", shape=(), dtype=resource).TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.
```
Which is really odd. How can I load and do inference, predictions on a CPU machine with a model trained on GPU on another machine?

**Describe the expected behavior**
I expected to be able to open the trained model and make predictions.

**System information where I try to OPEN the model**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No, I followed the examples of Tensorflow docs.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina 10.15.5 
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: Python 3.6.4
- CUDA/cuDNN version: no
- GPU model and memory: AMD Radeon Pro 580 (but not used)

**Standalone code to reproduce the issue**
```
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint

print(tf.version.VERSION)
print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))

model = tf.keras.models.load_model(f'models/distilbert_batch16_epochs3_maxlen192')
print(model.summary())

with tf.device('cpu:0'):
    model.save(f'models/CPU_distilbert_batch16_epochs3_maxlen192') 

with tf.device('cpu:0'):
    new_model = tf.keras.models.load_model(f'models/CPU_distilbert_batch16_epochs3_maxlen192')
print(new_model.summary())
```

I cannot upload the model itself because its more than 1 GB, but the summary is shown above.
"
40454,predict method of tf.estimator is very slow,"May be this is already known thing for others and this can be a duplicate issue. But could not find relevant information about this. Please let me know if there is way to deal with this. 

Thanks. 




<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40453,model.fit() is 10% slower over custom training loops when using TPUs,"I've created two training loops for training models on TPUs. One using the model.fit() method and one using a custom training loop based on information I've found in various notebooks.

The custom training loop consistently beats model.fit() by 10-15%.

Some overhead for using model.fit() over custom code is of course acceptable but 10-15% seem excessive. Maybe there's a bug somewhere?

Here are the relevant parts of my custom training loop:

```python
class LossAccObserver:
    def __init__(self):
        self.loss = metrics.SparseCategoricalCrossentropy()
        self.acc = metrics.SparseCategoricalAccuracy()
    def reset(self):
        self.loss.reset_states()
        self.acc.reset_states()
    def update(self, y, y_hat):
        self.loss.update_state(y, y_hat)
        self.acc.update_state(y, y_hat)

def compute_and_apply_gradients(model, x, y):
    with tf.GradientTape() as tape:
        y_hat = model(x, training = True)
        loss = model.compiled_loss(y, y_hat,
                                   regularization_losses = model.losses)
    vars = model.trainable_variables
    grads = tape.gradient(loss, vars)
    grads = [tf.clip_by_norm(g, 0.5) for g in grads]
    model.optimizer.apply_gradients(zip(grads, vars))
    return y_hat

@tf.function
def train_epoch(model, strategy, batch_size, dataset, obs):
    def step_fn(x, y):
        y_hat = compute_and_apply_gradients(model, x, y)
        obs.update(y, y_hat)
    for x, y in dataset:
        strategy.run(step_fn, args = (x, y))

@tf.function
def evaluate_epoch(model, strategy, dataset, obs):
    def step_fn(x, y):
        y_hat = model(x, training = False)
        obs.update(y, y_hat)
    for x, y in dataset:
        strategy.run(step_fn, args = (x, y))

def manual_training(model, strategy, train, valid, batch_size, epochs):
    with strategy.scope():
        train_obs = LossAccObserver()
        valid_obs = LossAccObserver()
    ...
    for i in range(epochs):
        ...
        train_epoch(model, strategy, batch_size, train, train_obs)
        evaluate_epoch(model, strategy, valid, valid_obs)
        ...
```
Here is my model.fit() training code:
```python
class MyModel(Model):
    def train_step(self, data):
        x, y = data
        y_hat = compute_and_apply_gradients(self, x, y)
        self.compiled_metrics.update_state(y, y_hat)
        return {m.name: m.result() for m in self.metrics}

def automatic_training(model, train, valid, batch_size, epochs):
    ...
    model.fit(x = train, validation_data = valid,
              epochs = epochs,
              verbose = 2)
```
"
40452,Error popping up,"Pl. pin-point the line in the code from which the error is coming?

class ReconstructingRegressor(keras.models.Model):
    def __init__(self, output_dim, **kwargs):
        super().__init__(**kwargs)
        self.flatten1 = keras.layers.Flatten(input_shape=[109,109])
        self.hidden = [keras.layers.Dense(30, activation=""relu"",
                                          kernel_initializer=""lecun_normal"")
                       for _ in range(5)]
        self.out = keras.layers.Dense(output_dim,activation=""softmax"")

    def build(self, batch_input_shape):
       
        n_inputs = batch_input_shape[-1]
        print(n_inputs)
        self.reconstruct = keras.layers.Dense(n_inputs)
        super().build(batch_input_shape)

    def call(self, inputs, training=None):
        Z=self.flatten1(inputs)
        
        for layer in self.hidden:
            Z = layer(Z)
         
        reconstruction = self.reconstruct(Z)
        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))
        self.add_loss(0.05 * recon_loss)
        #if training:
        #    result = self.reconstruction_mean(recon_loss)
        #    self.add_metric(result)
        return self.out(Z)
model = ReconstructingRegressor(10)
model.compile(loss=""sparse_categorical_crossentropy"", optimizer=keras.optimizers.SGD(), metrics=[""accuracy""])
history = model.fit(avast, housing_labels, epochs=100,validation_split=0.1) 



Error- InaccessibleTensorError: The tensor 'Tensor(""mul:0"", shape=(), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=build_graph, id=1629497199368); accessed from: FuncGraph(name=train_function, id=1629516591688)."
40448,tf_ops.cc takes 79s to compile / 4300+ lines long,"This is with TensorFlow at commit 80768cb23a3a4314c52af0b48a6bcf23ca541e19. The file 
tensorflow/compiler/mlir/tensorflow/ir/tf_ops.cc is about 4300 lines long and takes nearly 79s by itself to compile on a fast workstation (Intel Skylake-based Core i7 8700K 3.70GHz) with a typical bazel config below. It'll be great to split this file into two. 
```
bazel build --linkopt=""-fuse-ld=lld"" -j 11    //tensorflow/compiler/mlir:tf-opt
gcc (GCC) 9.3.1 20200408 (Red Hat 9.3.1-2)
On an Fedora Core 31 x86-64 Linux, Intel Core i7 8700K 3.70 GHz, 32 GB DDR4 RAM.
```

```
INFO: Analyzed target //tensorflow/compiler/mlir:tf-opt (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
Target //tensorflow/compiler/mlir:tf-opt up-to-date:
  bazel-bin/tensorflow/compiler/mlir/tf-opt
INFO: Elapsed time: 79.099s, Critical Path: 78.93s
INFO: 2 processes: 2 local.
INFO: Build completed successfully, 3 total actions
```

To reproduce, please change tf_ops.cc and rebuild tf-opt as shown above. The `linkopt` shouldn't make a difference here.
"
40447,[Using tf.function()] ValueError: Input 0 of layer dense is incompatible with the layer,"**Set up:** Using tensorflow 2.2.0 on python 3.7. 

**Background**: I'm just trying to get the **concrete function** of a simple `tf.keras.Model` to save it using SavedModel and use it later, yet there is no example of doing so in the documentation. Trying to perform this _simple task_ following the documentation gives the following problem: 

**Issue (possibly bug)**
I'm trying to run a very simple concrete function [based on the documentation](https://www.tensorflow.org/guide/concrete_function#accessing_concrete_function): 

```python
import tensorflow as tf

inputs = tf.keras.Input(shape=(3,))
x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)
outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs)

x = tf.constant([[1.0,2.0,3.0], [1.0,2.0,3.0]])
model.predict(x) 

# outputs: array([[0.19964378, 0.23859118, 0.17491119, 0.15458305, 0.23227075],
#       [0.19964378, 0.23859118, 0.17491119, 0.15458305, 0.23227075]],
#      dtype=float32)
# OK!
```

Now using tf.function: 
```python
@tf.function(input_signature=[tf.TensorSpec(shape=(None, 3), dtype=tf.float32)])
def predict(x):
  return model.predict(x)
p = predict.get_concrete_function()

# TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'
```

Without `None` : 

```python
@tf.function(input_signature=[tf.TensorSpec(shape=(3,), dtype=tf.float32)])
def predict(x):
  return model.predict(x)
p = predict.get_concrete_function()

# ValueError: Input 0 of layer dense is incompatible with the layer: 
# expected axis -1 of input shape to have value 3 but received input with shape [None, 1]
```

Finally, without declaring the input attribute on the `tf.function`:
```python
@tf.function
def predict(x):
  return model.predict(x)

p = predict.get_concrete_function(x=tf.TensorSpec(shape=(1,3,), dtype=tf.float32))
#  AttributeError: 'Tensor' object has no attribute 'numpy'
```
_(Among many other permutations, none o which works, because either it's a bug, or somehow you've made this thing unusably  complicated, or I'm missing something)_
"
40446, _load(spec) ImportError: DLL load failed while importing _pywrap_tensorflow_internal,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): calling HMR
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): https://files.pythonhosted.org/packages/af/50/d7da24189d95e2084bb1cc350a8e4acdf1b0c9b3d57def7a348f0d9cb062/tensorflow-2.2.0-cp37-cp37m-win_amd64.whl
- Python version: 3.7
- CUDA/cuDNN version: 10.1
- GPU model and memory: nvidia quadro fx 570
- CPU: Intel Xeon x5450


**Describe the current behavior**
""import tensorflow as tf"" fails 
**Describe the expected behavior**
""import tensorflow as tf"" doesn't fail 
**Standalone code to reproduce the issue**


**Other info / logs** 
$ python -m export --img_dir C:\Users\dell\Videos\temp\images_data --json_dir C:\Users\dell\Videos\temp\openpose_data --log_dir C:\Users\dell\Videos --output_path C:\Users\dell\Videos\temp\hmr_data.json
Traceback (most recent call last):
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Une routine dinitialisation dune bibliothque de liens dynamiques (DLL) a chou.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""D:\DEV\video2mocap\3rdparty\hmr\export.py"", line 32, in <module>
    import tensorflow as tf
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\dell\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Une routine dinitialisation dune bibliothque de liens dynamiques (DLL) a chou.


Failed to load the native TensorFlow runtime.


"
40445,Keras Reshae layer doesn't support in tf 2.2 ?,"
"
40444,Create a function to compute positive negative and neutral tweets. ,"
# Create a function to compute negative (-1), neutral (0) and positive (+1) analysis
def getAnalysis(score):
if score < 0:
  return 'Negative'
elif score == 0:
  return 'Neutral'
else:
  return 'Positive'
df['Analysis'] = df['Polarity'].apply(getAnalysis)
# Show the dataframe
df

This program doesn't creates analysis column."
40443,**stop_if_no_decrease_hook** did not work during training?,"```
    early_stopping_hook = tf.estimator.experimental.stop_if_no_decrease_hook(
                                deepfm_model,
                                metric_name='loss',
                                max_steps_without_decrease=13,
                                min_steps=5)
    training_hooks.append(early_stopping_hook)

    tf.estimator.train_and_evaluate(
        estimator=deepfm_model,
        train_spec=tf.estimator.TrainSpec(train_input_fn, hooks=training_hooks),
        eval_spec=tf.estimator.EvalSpec(eval_input_fn, steps=100)#, exporters=best_exporter)
    )
```

Using the code, as the params define, the evaluation should be processed every 13 training steps and the training process should be ended if the loss did not decrease. 

But it keep training and did not do evaluation every 13 training steps.

"
40442,image normalization preprocess in Tensorflow Lite iOS object detection examples,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iphoneX
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version:3.5
- Bazel version (if compiling from source):no
- GCC/Compiler version (if compiling from source):no
- CUDA/cuDNN version: not related, run on cpu 
- GPU model and memory:  not related, run on cpu 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

Hi, can anyone help to confirm which one is correct for the object detection model used in example(coco_mobilenet_ssd_v1)?

from the Tensorflow Lite IOS object_detection example, it use ""x / 255.0"" to normalize image for preprocess.

https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/ios/ObjectDetection/ModelDataHandler/ModelDataHandler.swift#L319

    // Not quantized, convert to floats
    let bytes = Array<UInt8>(unsafeData: byteData)!
    var floats = [Float]()
    for i in 0..<bytes.count {
      floats.append(Float(bytes[i]) / 255.0)
    }
    return Data(copyingBufferOf: floats)

while in the Tensorflow Lite Android object_detection example, it use ""(x -128.0) / 128.0"" 

https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/android/app/src/main/java/org/tensorflow/lite/examples/detection/tflite/TFLiteObjectDetectionAPIModel.java#L171

  // Float model
  private static final float IMAGE_MEAN = 128.0f;
  private static final float IMAGE_STD = 128.0f;
...
          imgData.putFloat((((pixelValue >> 16) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);
          imgData.putFloat((((pixelValue >> 8) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);
          imgData.putFloat(((pixelValue & 0xFF) - IMAGE_MEAN) / IMAGE_STD);

while from the ssd mobilenet v1 feature extractor , it use ""(2.0 / 255.0) * resized_inputs - 1.0"" which is different from the above two 

https://github.com/tensorflow/models/blob/master/research/object_detection/models/ssd_mobilenet_v1_feature_extractor.py#L78

350   def preprocess(self, resized_inputs):
351     """"""SSD preprocessing.
352 
353     Maps pixel values to the range [-1, 1]. The preprocessing assumes an input
354     value range of [0, 255].
355 
356     Args:
357       resized_inputs: a [batch, height, width, channels] float tensor
358         representing a batch of images.
359 
360     Returns:
361       preprocessed_inputs: a [batch, height, width, channels] float tensor
362         representing a batch of images.
363     """"""
364     return (2.0 / 255.0) * resized_inputs - 1.0


**Describe the expected behavior**

we got different accuracy when using a same model(ssd_mobilenet_v1) on PC vs. iOS when using tensorflow lite example code and pre trained model, for ssd_mobilenet_v1 how much accuracy loss on iOS is expected? 

Appreciate for any help, Thanks!
"
40441,0-th dimension of output tensor is None. Why not support batch?,"my out tensor has shape = [None, 16]. Why doesn't support batch?
```
preds = tf.concat(  # [bboxes, landms, landms_valid, conf]
            [bbox_regressions[0], landm_regressions[0],
             tf.ones_like(classifications[0, :, 0][..., tf.newaxis]),
             classifications[0, :, 1][..., tf.newaxis]], 1)
        priors = prior_box_tf((tf.shape(inputs)[1], tf.shape(inputs)[2]),
                              cfg['min_sizes'],  cfg['steps'], cfg['clip'])
        decode_preds = decode_tf(preds, priors, cfg['variances'])

        selected_indices = tf.image.non_max_suppression(
            boxes=decode_preds[:, :4],
            scores=decode_preds[:, -1],
            max_output_size=tf.shape(decode_preds)[0],
            iou_threshold=iou_th,
            score_threshold=score_th)

        out = tf.gather(decode_preds, selected_indices)

    return Model(inputs, out, name=name)
```
"
40440,add None 0-dimension to output tensor (tf2),"to get dynamic batch, i need to add None to below ouput tensor. 
```
out = tf.gather(decode_preds, selected_indices)
```
Can someone guide me?"
40439,tensorflow-gpu==1.13.1,"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow version: 1.13.1
- Python version: 3.6.9
- Installed using: Miniconda3, pip3
- GPU model and memory: Google Colab

**Description of the problem**
 In order to run this python script, TensorFlow-GPU and TensorBoard both version 1.13.1 are required. According to the log, the second code block does run successfully - however, in reality, there seems to be an installation issue since a ModuleNotFoundError is prompted.

Some general assistance and explanation would be extremely helpful - perhaps there exists a direct link that can be used for these installations instead?

**Sequence of commands executed before running into the problem**
```bash
!wget -c https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh
!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh
!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local
!conda install -q -y --prefix /usr/local python=3.6 ujson
import sys
sys.path.append('/usr/local/lib/python3.6/site-packages')
# test it
import ujson
```
```bash
!pip3 install tensorboard==1.13.1
!pip3 install tensorflow-gpu==1.13.1
```
**Unsuccessful command and traceback**
```bash
!conda create -y -n grover python=3.6 && source activate grover && pip3 install -r /content/drive/My\ Drive/CS/GPT-2/grover/requirements-gpu.txt
!python /content/drive/My\ Drive/CS/GPT-2/grover/download_model.py base
!PYTHONPATH=$(pwd) python /content/drive/My\ Drive/CS/GPT-2/grover/sample/contextual_generate.py -model_config_fn lm/configs/base.json -model_ckpt models/base/model.ckpt -metadata_fn sample/april2019_set_mini.jsonl -out_fn april2019_set_mini_out.jsonl
```
```
Traceback (most recent call last):
  File ""/content/drive/My Drive/CS/GPT-2/grover/sample/contextual_generate.py"", line 1, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
```
"
40438,"Building TF Lite C++ shared library for macOS, linux, iOS and Android","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave (10.14)
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.2
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.17)
- CUDA/cuDNN version: -
- GPU model and memory: -


I am trying to develop a C++ library on macOS and ubuntu to use in Android and iOS. Therefore, I am trying to build TFLite C++ shared library to link it my own C++ shared library using CMake. I have tried to build that using command `bazel build -c opt //tensorflow/lite:tensorflowlite` and got `libtensorflowlite.dylib` file as bazel-output. However CMake fails to link it and gives the following error:
```
Undefined symbols for architecture x86_64:
  ""tflite::FlatBufferModel::BuildFromFile(char const*, tflite::ErrorReporter*)"", referenced from:
      MyClass::MyClass(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int, int) in my_class.cpp.o
  ""tflite::FlatBufferModel::~FlatBufferModel()"", referenced from:
      std::__1::default_delete<tflite::FlatBufferModel>::operator()(tflite::FlatBufferModel*) const in my_class.cpp.o
  ""tflite::DefaultErrorReporter()"", referenced from:
      MyClass::MyClass(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int, int) in my_class.cpp.o
  ""tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()"", referenced from:
      MyClass::MyClass(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int, int) in my_class.cpp.o
  ""tflite::impl::Interpreter::AllocateTensors()"", referenced from:
      MyClass::MyClass(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int, int) in my_class.cpp.o
      MyClass::run_model(std::__1::vector<std::__1::vector<float, std::__1::allocator<float> >, std::__1::allocator<std::__1::vector<float, std::__1::allocator<float> > > > const&) in my_class.cpp.o
  ""tflite::impl::Interpreter::ResizeInputTensor(int, std::__1::vector<int, std::__1::allocator<int> > const&)"", referenced from:
      MyClass::run_model(std::__1::vector<std::__1::vector<float, std::__1::allocator<float> >, std::__1::allocator<std::__1::vector<float, std::__1::allocator<float> > > > const&) in my_class.cpp.o
  ""tflite::impl::Interpreter::Invoke()"", referenced from:
      MyClass::run_model(std::__1::vector<std::__1::vector<float, std::__1::allocator<float> >, std::__1::allocator<std::__1::vector<float, std::__1::allocator<float> > > > const&) in my_class.cpp.o
  ""tflite::impl::Interpreter::~Interpreter()"", referenced from:
      std::__1::default_delete<tflite::impl::Interpreter>::operator()(tflite::impl::Interpreter*) const in my_class.cpp.o
  ""tflite::impl::InterpreterBuilder::InterpreterBuilder(tflite::FlatBufferModel const&, tflite::OpResolver const&)"", referenced from:
      MyClass::MyClass(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int, int) in my_class.cpp.o
  ""tflite::impl::InterpreterBuilder::~InterpreterBuilder()"", referenced from:
      MyClass::MyClass(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int, int) in my_class.cpp.o
  ""tflite::impl::InterpreterBuilder::operator()(std::__1::unique_ptr<tflite::impl::Interpreter, std::__1::default_delete<tflite::impl::Interpreter> >*)"", referenced from:
      MyClass::MyClass(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int, int) in my_class.cpp.o
  ""vtable for tflite::MutableOpResolver"", referenced from:
      tflite::MutableOpResolver::~MutableOpResolver() in my_class.cpp.o
```
But, If I try to link shared tflite library(`libtensorflowlite.dylib`) with my static library, it builds without error.

I am fairly new to `bazel` and CMake, however I thought it is caused by building the `libtensorflowlite.dylib` with missing x86_64 architecture and tried below commands and got following errors.:
```
bazel build -c opt --config=ios_fat  //tensorflow/lite:tensorflowlite
ERROR: /Users/username/tensorflow/tensorflow/lite/kernels/internal/BUILD:687:1: C++ compilation of rule '//tensorflow/lite/kernels/internal:kernel_utils' failed (Exit 1)
clang: error: invalid version number in '-mmacosx-version-min=13.2'
```
and 
```
bazel build -c opt --cpu=x86_64  //tensorflow/lite:tensorflowlite
ERROR: /private/var/tmp/_bazel_username/ec3ee607500668f8e05b1977bf58c2f5/external/local_config_cc/BUILD:41:1: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'x86_64'
ERROR: Analysis of target '//tensorflow/lite:tensorflowlite' failed; build aborted: Analysis of target '@local_config_cc//:toolchain' failed
```

Finally, I thought it is related to #36178 , #39876 and #35386, but couldn't resolve it."
40437,Issue with tensorflow not being able to use my gpu after installing cuda and cuDNN,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): used sudo pip3 install tensorflow-gpu and sudo pip3 install tensorflow to install both versions.
- TensorFlow version (use command below): 2.2.0
- Python version: 3.8.2
- CUDA: release 10.1
- cuDNN version: 7.6.5 
- GPU model and memory: Geoforce GTX - 1050



**Current behavior**

running the following code (to verify if I have completed all the steps correctly of installing cuda and cuDNN) - 
`from tensorflow.python.client import device_lib`
`print(device_lib.list_local_devices())`

currently the following error occurs - 
W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory

**Expected behavior**
Due to the above error, I am not able to let tensorflow use my gpu for machine learning purposes. I would like to rectify this error

Kindly help me solve this problem, and let me know if any further details are required from my side.
"
40436,On the endianness of TensorProto::tensor_content,"This is a re-post from [tensorflow forums](https://groups.google.com/a/tensorflow.org/forum/?utm_medium=email&utm_source=footer#!topic/discuss/6ZaRNUF_--g).

I looked into the implementation of conversion from/to the protobuf type TensorProto, and feel confused on the endianness of the underlying storage.

In my understanding of the decoding process, it checks if TensorProto::tensor_content is empty ([code](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/core/framework/tensor.cc#L928-L931)). If not, it calls the template function Helper::Decode ([code](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/core/framework/tensor.cc#L169-L183)), and calls `base()` to cast the bytes data to desired type ([code](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/core/framework/tensor.cc#L176)).

I searched around the definition of `base()` and found that it simply calls `reinterpret_cast` ([code](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/core/framework/tensor.h#L86-L89)). The endianness of `reinterpret_cast` depends on the system architecture. So does tensorflow goes as it is, or did I miss anything?

**TL;DR** What is the endianness of the protobuf type `TensorProto::tensor_content`?"
40435,neural structured learning for NLP text classification,"I like the idea of neural structured learning, would like to use the adversarial concept on NLP. I'm using bidirection LSTM model to classify a text input and sequence of the words is important. I want it to be able to identify similarity of the sequence of text

can I used neural structured learning so that it can generate 'textual perturbation' for training purpose for the given sentence to increase the accuracy of prediction?

"
40434,zsdonghao / u-net-brain-tumor,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
40433,Please somebody help me......," I tried MUNIT-Tensorflow and I have this problem 

somebody help me please, 

environment = python 3.7 
tensorflow version = 1.4 


WARNING:tensorflow:From main.py:91: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From main.py:94: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-06-13 21:57:38.695873: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX AVX2
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-06-13 21:57:38.711357: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.
##### Information #####
 gan type :  lsgan
 dataset :  summer2winter
 max dataset number :  0
 batch_size :  1
 epoch :  10
 iteration per epoch :  100000
 style in test phase :  3

##### Generator #####
residual blocks :  4
 Style dimension :  8
 MLP dimension :  256
 Down sample :  2
 Up sample :  2

##### Discriminator #####
 Discriminator layer :  4
 Multi-scale Dis :  3
WARNING:tensorflow:From C:\Users\Lee Jong Ann\Desktop\study\Machine Learning\MUNIT-Tensorflow-master\MUNIT-Tensorflow-master\MUNIT.py:236: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From C:\Users\Lee Jong Ann\Desktop\study\Machine Learning\MUNIT-Tensorflow-master\MUNIT-Tensorflow-master\utils.py:19: The name tf.read_file is deprecated. Please use tf.io.read_file instead.

Traceback (most recent call last):
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 527, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1224, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1018, in _TensorTensorConversionFunction
    (dtype.name, t.dtype.name, str(t)))
ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: 'Tensor(""args_0:0"", shape=(), dtype=float32)'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""main.py"", line 138, in <module>
    main()
  File ""main.py"", line 98, in main
    gan.build_model()
  File ""C:\Users\Lee Jong Ann\Desktop\study\Machine Learning\MUNIT-Tensorflow-master\MUNIT-Tensorflow-master\MUNIT.py"", line 244, in build_model
    trainA = trainA.prefetch(self.batch_size).shuffle(self.dataset_num).map(Image_Data_Class.image_processing, num_parallel_calls=8).apply(batch_and_drop_remainder(self.batch_size)).repeat()
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1776, in map
    self, map_func, num_parallel_calls, preserve_cardinality=False))
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 3228, in __init__
    use_legacy_function=use_legacy_function)
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 2555, in __init__
    self._function = wrapper_fn._get_concrete_function_internal()
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1355, in _get_concrete_function_internal
    *args, **kwargs)
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1349, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1652, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1545, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 715, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 2549, in wrapper_fn
    ret = _wrapper_helper(*args)
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 2489, in _wrapper_helper
    ret = func(*nested_args)
  File ""C:\Users\Lee Jong Ann\Desktop\study\Machine Learning\MUNIT-Tensorflow-master\MUNIT-Tensorflow-master\utils.py"", line 19, in image_processing
    x = tf.read_file(filename)
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 625, in read_file
    ""ReadFile"", filename=filename, name=name)
  File ""C:\Users\Lee Jong Ann\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 550, in _apply_op_helper
    (prefix, dtypes.as_dtype(input_arg.type).name))
TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string."
40432,Slow computation when no gradients exist w.r.t a layer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): 2.2.0
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

I am trying to train a barebone Neural Machine Translation model with Luong attention (`dot` for calculating the alignment scores). I have gone for a custom training loop and I am getting the following warning which does make sense to me since gradients are not calculated for Embedding layers as far as I know:

![image](https://user-images.githubusercontent.com/22957388/84569556-35ad9980-ada5-11ea-9540-68137de72532.png)

It also slows the computation and one immediate workaround I could imagine was to wrap the single training step within a function and decorate with `tf.function`. But I really could not figure a way out. 

**Describe the expected behavior**

A workaround to enhance the computation or the overall training loop in general. 

**Standalone code to reproduce the issue**
[Colab Notebook](https://colab.research.google.com/drive/1GpMiXVonmQKQdiOTcDW9XgDnp9K0iL0b?usp=sharing)

"
40431,Please Remove Keyword check by append **kwargs in the tf.keras.Model,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): over 2.0 
- Are you willing to contribute it (Yes/No): Tes

**Describe the feature and the current behavior/state.**

```python
model(tensor, any_keyword=anyvalue_such_as_word)
# => TypeError: call() got an unexpected keyword argument 'any_keyword'
```
**Will this change the current api? How?**
Yes.
Append one ""**kwargs"" in this line 
https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/engine/network.py#L695

**Who will benefit with this feature?**
I don't know the benefit of this argument constraint.
And also, close the gap between the subclass model and the Functional API.
So this update will benefit the whole TF user, and developer.
**Any Other info.**
https://colab.research.google.com/gist/MokkeMeguru/887eb223d770551ecccb0f09c51fe2e4/please-remove-the-keyword-checker.ipynb"
40430,the document description  of tensorflow java api  is not detailed enough.,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
40429,Can't load subclassed model 's architecture from keras.layers.serialize(model),"According to the [guide](https://www.tensorflow.org/guide/keras/save_and_serialize#custom_objects), I defined a subclass model with get_config method:

```python
from tensorflow import keras
from tensorflow.keras import layers

class ThreeLayerMLP(keras.Model):
    def __init__(self, hidden_units):
        super().__init__()
        self.hidden_units = hidden_units
        self.dense_layers = [layers.Dense(u) for u in hidden_units]

    def call(self, inputs):
        x = inputs
        for layer in self.dense_layers:
            x = layer(x)
        return x

    def get_config(self):
        config = {""hidden_units"": self.hidden_units}
        return config

model = ThreeLayerMLP([64, 64, 10])
serialized_model = keras.layers.serialize(model)
new_model = keras.layers.deserialize(
    serialized_model, custom_objects={'ThreeLayerMLP': ThreeLayerMLP})
```

After serialized the model, I tried to load it but failed with errors:

```shell
Traceback (most recent call last):
  File ""demo14.py"", line 35, in <module>
    serialized_model, custom_objects={'ThreeLayerMLP': ThreeLayerMLP})
  File ""D:\Program Files\anaconda3\envs\tf2.2\lib\site-packages\tensorflow\python\keras\layers\serialization.py"", line 109, in deserialize
    printable_module_name='layer')
  File ""D:\Program Files\anaconda3\envs\tf2.2\lib\site-packages\tensorflow\python\keras\utils\generic_utils.py"", line 373, in deserialize_keras_object

    list(custom_objects.items())))
  File ""D:\Program Files\anaconda3\envs\tf2.2\lib\site-packages\tensorflow\python\keras\engine\network.py"", line 987, in from_config
    config, custom_objects)
  File ""D:\Program Files\anaconda3\envs\tf2.2\lib\site-packages\tensorflow\python\keras\engine\network.py"", line 2018, in reconstruct_from_config
    for layer_data in config['layers']:
KeyError: 'layers'
```

So I want to know how to safely load a subclassed model's architecture? Thanks~"
40428,Wrong batch size reported when using TPUStrategy,"In the summary, batch size is reported as 4 but I specified it as 32:
```python
from os import environ
from tensorflow.config import experimental_connect_to_cluster
from tensorflow.distribute.cluster_resolver import TPUClusterResolver
from tensorflow.distribute.experimental import TPUStrategy
from tensorflow.keras import Model
from tensorflow.keras.layers import *
from tensorflow.tpu.experimental import initialize_tpu_system
import tensorflow as tf

tpu_addr = environ.get('COLAB_TPU_ADDR')
resolver = TPUClusterResolver('grpc://' + tpu_addr)
experimental_connect_to_cluster(resolver)
initialize_tpu_system(resolver)
strategy = TPUStrategy(resolver)

with strategy.scope():
    source = Input(shape = (320,),
                   batch_size = 32,
                   dtype = tf.int32)
    embedding = Embedding(input_dim = 49, output_dim = 100)(source)
    lstm_1 = LSTM(700,
                  return_sequences = True,
                  dropout = 0.3)(embedding)
    y_pred = TimeDistributed(
        Dense(49, activation = 'softmax'))(lstm_1)
    m = Model(inputs = [source], outputs = [y_pred])
    m.compile(optimizer = 'rmsprop',
              loss = 'sparse_categorical_crossentropy',
              metrics = ['sparse_categorical_accuracy'])
    m.summary()
```
I suppose it is dividing the batch size I gave with the number of replicas available. But shouldn't that be transparent to the user? I want the code I write to work the same no matter what hw I have available (CPU, GPU or TPU). "
40427,when support tflite op: SparseFillEmptyRows,"why not support SparseFillEmptyRows in tflite, and when support?"
40426,Codelab: Recognize Flowers with TensorFlow Lite on Android - emulator crashes,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://codelabs.developers.google.com/codelabs/recognize-flowers-with-tensorflow-on-android/#7

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

Adding clear requirements for running the app on an emulator.

### Clear description

I was unable to get the app to fully run on an emulator in Android Studio. It loads once, then when I click 'Allow' on the camera permissions window, it crashes and cannot restart. 

I tried running both the app after following the codelab, and the prebuilt one in the finish directory (having moved the tf model file to its assets directory). I tried various emulator configurations in the AVD manager, including what was shown on screen. There may be some incompatible configuration in the emulator or another requirement that isn't being specified.




### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
40425,How to create data generator that outputs a dict?,"- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu16.04
- TensorFlow version (use command below): tensorflow1.15.2 eager mode
- Python version: 3.7
- CUDA/cuDNN version: 10.0
- GPU model and memory: 8G


How to create a tensorflow data generator that outputs a dict? This generator fetches data from disk (since my data can NOT be loaded to Memory once a time) and send it to my NN. (I am using tensorflow 1.15.2 in eager mode.)

Each term of my data is a array.
My training sample like this:
```
J_2d_0
(1, 25, 3)
J_2d_1
(1, 25, 3)
J_2d_2
(1, 25, 3)
J_2d_3
(1, 25, 3)
J_2d_4
(1, 25, 3)
J_2d_5
(1, 25, 3)
J_2d_6
(1, 25, 3)
J_2d_7
(1, 25, 3)
J_2d_8
(1, 25, 3)
J_2d_9
(1, 25, 3)
image_0
(1, 720, 720, 3)
image_1
(1, 720, 720, 3)
image_2
(1, 720, 720, 3)
image_3
(1, 720, 720, 3)
image_4
(1, 720, 720, 3)
image_5
(1, 720, 720, 3)
image_6
(1, 720, 720, 3)
image_7
(1, 720, 720, 3)
image_8
(1, 720, 720, 3)
image_9
(1, 720, 720, 3)
pose_0
(1, 24, 3, 3)
pose_1
(1, 24, 3, 3)
pose_2
(1, 24, 3, 3)
pose_3
(1, 24, 3, 3)
pose_4
(1, 24, 3, 3)
pose_5
(1, 24, 3, 3)
pose_6
(1, 24, 3, 3)
pose_7
(1, 24, 3, 3)
pose_8
(1, 24, 3, 3)
pose_9
(1, 24, 3, 3)
offset
(1, 27554, 3)
betas
(1, 1, 10)
trans_0
(1, 1, 3)
trans_1
(1, 1, 3)
trans_2
(1, 1, 3)
trans_3
(1, 1, 3)
trans_4
(1, 1, 3)
trans_5
(1, 1, 3)
trans_6
(1, 1, 3)
trans_7
(1, 1, 3)
trans_8
(1, 1, 3)
trans_9
(1, 1, 3)
```
I just learnt from 
https://stackoverflow.com/questions/51136862/creating-a-tensorflow-dataset-that-outputs-a-dict

```
def data_gen():
    begin_index = 10
    feeding_size = 1000
    for i in range(begin_index, begin_index + feeding_size):  # range(1): #range(len(gen)):
        print(""data_generator, yielding. %d"" %i)
        train_dat = pkl.load(open(
            'Training_pairs/shuffled_input_data/shuffle_input_dat270_510_%d.pkl' % i,
            ""rb""), encoding=""latin1"") 
        yield train_dat
```
To set the 'output_types' and 'output_shapes' in function  **tf.data.Dataset.from_generator** , I use one specific sample 'st_gt_dat': 
```

st_train_dat = pkl.load(open(
        'training_pairs/shuffled_input_data/shuffle_input_dat270_510_%d.pkl' % 10,
            ""rb""), encoding=""latin1"")  
```

```
 dataset = tf.data.Dataset.from_generator(
                data_gen,
                output_types={k: tf.float32 for k in st_train_dat},
                output_shapes={
                               'J_2d_0': (25, 3),
                               'J_2d_1': (25, 3),
                               'J_2d_2': (25, 3),
                               'J_2d_3': (25, 3),
                               'J_2d_4': (25, 3),
                               'J_2d_5': (25, 3),
                               'J_2d_6': (25, 3),
                               'J_2d_7': (25, 3),
                               'J_2d_8': (25, 3),
                               'J_2d_9': (25, 3),
                               'image_0': (720, 720, 3),
                               'image_1': (720, 720, 3),
                               'image_2': (720, 720, 3),
                               'image_3': (720, 720, 3),
                               'image_4': (720, 720, 3),
                               'image_5': (720, 720, 3),
                               'image_6': (720, 720, 3),
                               'image_7': (720, 720, 3),
                               'image_8': (720, 720, 3),
                               'image_9': (720, 720, 3),
                               'pose_0': (24, 3, 3),
                               'pose_1': (24, 3, 3),
                               'pose_2': (24, 3, 3),
                               'pose_3': (24, 3, 3),
                               'pose_4': (24, 3, 3),
                               'pose_5': (24, 3, 3),
                               'pose_6': (24, 3, 3),
                               'pose_7': (24, 3, 3),
                               'pose_8': (24, 3, 3),
                               'pose_9': (24, 3, 3),
                               'offset': (27554, 3),
                               'betas': (1, 10),
                               'trans_0': (1, 3),
                               'trans_1': (1, 3),
                               'trans_2': (1, 3),
                               'trans_3': (1, 3),
                               'trans_4': (1, 3),
                               'trans_5': (1, 3),
                               'trans_6': (1, 3),
                               'trans_7': (1, 3),
                               'trans_8': (1, 3),
                               'trans_9': (1, 3)}
            )
            iter = dataset.make_one_shot_iterator()
            next_elem = iter.get_next()
```

But I got error:
```
2020-06-13 12:26:09.452497: W tensorflow/core/framework/op_kernel.cc:1639] Invalid argument: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was {'J_2d_0': tf.float32, 'J_2d_1': tf.float32, 'J_2d_2': tf.float32, 'J_2d_3': tf.float32, 'J_2d_4': tf.float32, 'J_2d_5': tf.float32, 'J_2d_6': tf.float32, 'J_2d_7': tf.float32, 'J_2d_8': tf.float32, 'J_2d_9': tf.float32, 'image_0': tf.float32, 'image_1': tf.float32, 'image_2': tf.float32, 'image_3': tf.float32, 'image_4': tf.float32, 'image_5': tf.float32, 'image_6': tf.float32, 'image_7': tf.float32, 'image_8': tf.float32, 'image_9': tf.float32, 'pose_0': tf.float32, 'pose_1': tf.float32, 'pose_2': tf.float32, 'pose_3': tf.float32, 'pose_4': tf.float32, 'pose_5': tf.float32, 'pose_6': tf.float32, 'pose_7': tf.float32, 'pose_8': tf.float32, 'pose_9': tf.float32, 'offset': tf.float32, 'betas': tf.float32, 'trans_0': tf.float32, 'trans_1': tf.float32, 'trans_2': tf.float32, 'trans_3': tf.float32, 'trans_4': tf.float32, 'trans_5': tf.float32, 'trans_6': tf.float32, 'trans_7': tf.float32, 'trans_8': tf.float32, 'trans_9': tf.float32}, but the yielded element was {'J_2d_0': array([[[-0.09427154,  0.41095256,  1.12688104],
        [-0.07444732,  0.25008842,  1.02317508],
        [-0.21482247,  0.25017677,  1.02420145],
        [-0.26052661,  0.05423561,  1.06400284],
        [-0.26534972, -0.11140927,  1.05493748],
        [ 0.06103492,  0.24529497,  1.02426877],
        [ 0.12145394,  0.04935052,  0.96026634],
        [ 0.11658443, -0.12146067,  0.97616193],
        [-0.08933849, -0.14170642,  0.90027466],
        [-0.16977977, -0.14160274,  0.88860529],
        [-0.18017883, -0.42792061,  1.032287  ],
        [-0.22021453, -0.72938154,  1.01864192],
        [-0.00411502, -0.14650323,  0.87453262],
        [-0.01932905, -0.43304803,  1.02202842],
        [-0.0493427 , -0.70912272,  1.03996616],
        [-0.10472216,  0.42129188,  1.11642875],
        [-0.05930027,  0.42130201,  1.15048719],
        [-0.13954859,  0.40598681,  1.07391484],
        [-0.01432628,  0.4059807 ,  1.15703653],
        [-0.00895683, -0.76950105,  0.86484523],
        [ 0.02103647, -0.74940092,  1.0036266 ],
        [-0.06430062, -0.73434386,  0.88763042],
        [-0.25539206, -0.78477752,  0.89525851],
        [-0.28537308, -0.7794058 ,  0.89097358],
        [-0.21487881, -0.74964443,  0.92956732]]]), 'J_2d_1': array([[[-0.14470528,  0.40098775,  1.09027753],
        [-0.08938661,  0.25512539,  1.09985149],
        [-0.1898756 ,  0.25497139,  1.04048552],
        [-0.25517899,  0.05418177,  1.0721085 ],
        [-0.28041397, -0.10633208,  1.06210644],
        [ 0.02589675,  0.25526819,  1.08489046],
        [ 0.08125689,  0.03915851,  0.98820583],
        [ 0.05113377, -0.13659981,  1.00071059],
        [-0.11454961, -0.14654698,  0.8583964 ],
        [-0.18490882, -0.14161643,  0.89889107],
        [-0.2200103 , -0.42274546,  1.05879945],
        [-0.25524315, -0.70927703,  1.07121558],
        [-0.03920179, -0.14673024,  0.83556936],
        [-0.02928373, -0.43793617,  0.94163382],
        [-0.05420431, -0.6940558 ,  0.99540918],
        [-0.15488508,  0.42095556,  1.09184622],
        [-0.12452737,  0.42098428,  1.13112115],
        [-1.        ,  1.        ,  0.        ],
        [-0.04914441,  0.41088668,  1.09895583],
        [-0.07442048, -0.74964099,  0.92894744],
        [-0.03919271, -0.7493945 ,  0.94314416],
        [-0.05922171, -0.7042432 ,  0.86520933],
        [-0.35079933, -0.75939488,  0.91472051],
        [-0.35075437, -0.74451482,  0.92261895],
        [-0.22524563, -0.74429478,  1.00488518]]]), 'J_2d_2': array([[[-0.18007061,  0.40089064,  1.57988512],
        [-0.06942193,  0.26048028,  1.41631738],
        [-0.12455843,  0.2653055 ,  1.24171661],
        [-0.14980594,  0.06440445,  1.0687979 ],
        [-0.21493249, -0.09619188,  1.45641825],
        [-0.02414887,  0.26028943,  1.44538322],
        [-0.01417119,  0.04917884,  1.4911557 ],
        [-0.07438143, -0.14151838,  1.44140335],
        [-0.12463207, -0.14665676,  1.15797935],
        [-0.174891  , -0.14165133,  1.20497881],
        [-0.19992997, -0.41780427,  1.3514439 ],
        [-0.22037526, -0.69424658,  1.42331727],
        [-0.06435296, -0.15173715,  1.11622622],
        [-0.05439563, -0.42811827,  1.50000748],
        [-0.05932742, -0.71433716,  1.45640498],
        [-0.1798271 ,  0.42119778,  0.20291102],
        [-0.16965293,  0.42096863,  1.62150611],
        [-1.        ,  1.        ,  0.        ],
        [-0.08957527,  0.41106622,  1.63782675],
        [-0.15477217, -0.75457873,  1.3277638 ],
        [-0.12454928, -0.77448042,  1.21634246],
        [-0.04423719, -0.74935678,  1.35899541],
        [-0.3408351 , -0.72440123,  1.16838346],
        [-0.3358094 , -0.70921662,  1.2223608 ],
        [-0.21003629, -0.72430655,  1.45245355]]]), 'J_2d_3': array([[[-0.18008392,  0.38077087,  2.02785423],
        [-0.06454006,  0.28027766,  1.44454568],
        [-0.04927219,  0.29521328,  1.28410468],
        [ 0.06589895,  0.17465382,  0.31654373],
        [ 0.06635327,  0.14971188,  0.25575968],
        [-0.09464573,  0.26533813,  1.74140177],
        [-0.13451585,  0.05445549,  1.7655285 ],
        [-0.18508168, -0.11650477,  1.68718063],
        [-0.0944325 , -0.1215602 ,  1.36114065],
        [-0.08451241, -0.12145738,  1.00634772],
        [-0.13489544, -0.42298553,  1.7404709 ],
        [-0.16969479, -0.66922294,  1.65285767],
        [-0.09939567, -0.12655366,  1.40371122],
        [-0.08440387, -0.42815458,  1.65241455],
        [-0.08439801, -0.70905433,  1.77061931],
        [-1.        ,  1.        ,  0.        ],
        [-0.1751137 ,  0.41097099,  2.00782743],
        [-1.        ,  1.        ,  0.        ],
        [-0.12960182,  0.41097291,  1.945956  ],
        [-0.1899828 , -0.74443344,  1.84536047],
        [-0.15979638, -0.75455385,  1.68852475],
        [-0.05924096, -0.74434048,  1.85598338],
        [-0.23519866, -0.70409061,  1.27245307],
        [-0.23017727, -0.68417812,  1.14763897],
        [-0.14990367, -0.70405117,  1.17151459]]]), 'J_2d_4': array([[[-1.        ,  1.        ,  0.        ],
        [-0.05937093,  0.255393  ,  1.91558444],
        [ 0.03615684,  0.25536264,  1.74137026],
.........
```
It seems like we are using an array but the output_types is tf.float. How can I fix this?
```
                output_types={k: tf.float32 for k in st_train_dat},

```
Anyone can help?

Thanks in advance!

"
40424,How to bind the tensor data for some node?,"HI :
    I use some other distributed-train-framework got a model include meta_graph.pb and param data separate and the checkpoint format is different  from tensorflow,  In order to speed the online predict service, avoid build some tensor frequently, I want to bind some param data in some tensor-node, like bias and layer. Could you show me how to do this?
"
40423,CUDNN8 + CUDA 10.2 build?,"Hi,
similar to issue requesting a CUDA 11 build:
https://github.com/tensorflow/tensorflow/issues/40227
I think the most important of CUDA+CUDNN updates in relation to performance is CUDNN library updates..
seeing that CUDNN 8 ships with a library with CUDA 10.2 support and Tensorflow already supports CUDA 10.x, just asking if should be possible to integrate CUDNN 8 support faster than CUDA 11 and ship some nighlty build with CUDA 10.x+CUDNN 8 to test performance updates brought by this version..
thanks..

"
40422,AttributeError: module 'tensorflow' has no attribute 'compat',"---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-1-1e914dd8c3aa> in <module>
      1 get_ipython().run_line_magic('matplotlib', 'inline')
      2 import matplotlib.pyplot as plt
----> 3 import tensorflow as tf
      4 import numpy as np
      5 import pandas as pd

~\miniconda3\envs\tensorflow\lib\site-packages\tensorflow\__init__.py in <module>
     99 
    100 # We still need all the names that are toplevel on tensorflow_core
--> 101 from tensorflow_core import *
    102 
    103 # These should not be visible in the main tf module.

~\miniconda3\envs\tensorflow\lib\site-packages\tensorflow_core\__init__.py in <module>
     44 from . _api.v2 import autograph
     45 from . _api.v2 import bitwise
---> 46 from . _api.v2 import compat
     47 from . _api.v2 import config
     48 from . _api.v2 import data

~\miniconda3\envs\tensorflow\lib\site-packages\tensorflow_core\_api\v2\compat\__init__.py in <module>
     37 import sys as _sys
     38 
---> 39 from . import v1
     40 from . import v2
     41 from tensorflow.python.compat.compat import forward_compatibility_horizon

~\miniconda3\envs\tensorflow\lib\site-packages\tensorflow_core\_api\v2\compat\v1\__init__.py in <module>
     30 from . import autograph
     31 from . import bitwise
---> 32 from . import compat
     33 from . import config
     34 from . import data

~\miniconda3\envs\tensorflow\lib\site-packages\tensorflow_core\_api\v2\compat\v1\compat\__init__.py in <module>
     37 import sys as _sys
     38 
---> 39 from . import v1
     40 from . import v2
     41 from tensorflow.python.compat.compat import forward_compatibility_horizon

~\miniconda3\envs\tensorflow\lib\site-packages\tensorflow_core\_api\v2\compat\v1\compat\v1\__init__.py in <module>
     27 
     28 from . import compat
---> 29 from tensorflow._api.v2.compat.v1 import app
     30 from tensorflow._api.v2.compat.v1 import audio
     31 from tensorflow._api.v2.compat.v1 import autograph

~\miniconda3\envs\tensorflow\lib\site-packages\tensorflow_core\_api\v2\compat\__init__.py in <module>
     37 import sys as _sys
     38 
---> 39 from . import v1
     40 from . import v2
     41 from tensorflow.python.compat.compat import forward_compatibility_horizon

~\miniconda3\envs\tensorflow\lib\site-packages\tensorflow_core\_api\v2\compat\v1\__init__.py in <module>
     30 from . import autograph
     31 from . import bitwise
---> 32 from . import compat
     33 from . import config
     34 from . import data

~\miniconda3\envs\tensorflow\lib\site-packages\tensorflow_core\_api\v2\compat\v1\compat\__init__.py in <module>
     37 import sys as _sys
     38 
---> 39 from . import v1
     40 from . import v2
     41 from tensorflow.python.compat.compat import forward_compatibility_horizon

~\miniconda3\envs\tensorflow\lib\site-packages\tensorflow_core\_api\v2\compat\v1\compat\v1\__init__.py in <module>
    665 _current_module = _sys.modules[__name__]
    666 try:
--> 667   from tensorflow_estimator.python.estimator.api._v1 import estimator
    668   _current_module.__path__ = (
    669       [_module_util.get_parent_dir(estimator)] + _current_module.__path__)

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_estimator\__init__.py in <module>
      8 import sys as _sys
      9 
---> 10 from tensorflow_estimator._api.v1 import estimator
     11 
     12 del _print_function

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_estimator\_api\v1\estimator\__init__.py in <module>
      8 import sys as _sys
      9 
---> 10 from tensorflow_estimator._api.v1.estimator import experimental
     11 from tensorflow_estimator._api.v1.estimator import export
     12 from tensorflow_estimator._api.v1.estimator import inputs

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_estimator\_api\v1\estimator\experimental\__init__.py in <module>
      8 import sys as _sys
      9 
---> 10 from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder
     11 from tensorflow_estimator.python.estimator.canned.kmeans import KMeansClustering as KMeans
     12 from tensorflow_estimator.python.estimator.canned.linear import LinearSDCA

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_estimator\python\estimator\canned\dnn.py in <module>
     31 from tensorflow.python.keras.utils import losses_utils
     32 from tensorflow.python.util.tf_export import estimator_export
---> 33 from tensorflow_estimator.python.estimator import estimator
     34 from tensorflow_estimator.python.estimator.canned import head as head_lib
     35 from tensorflow_estimator.python.estimator.canned import optimizers

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_estimator\python\estimator\estimator.py in <module>
     51 from tensorflow_estimator.python.estimator import model_fn as model_fn_lib
     52 from tensorflow_estimator.python.estimator import run_config
---> 53 from tensorflow_estimator.python.estimator import util as estimator_util
     54 from tensorflow_estimator.python.estimator.export import export_lib
     55 from tensorflow_estimator.python.estimator.mode_keys import ModeKeys

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_estimator\python\estimator\util.py in <module>
     73 
     74 
---> 75 class _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook):
     76   """"""Creates a SessionRunHook that initializes the passed iterator.""""""
     77 

AttributeError: module 'tensorflow' has no attribute 'compat'"
40421,MirroredStrategy preventing use of cuDNN GRU implementation,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (18.04.3 LTS (Bionic Beaver))
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary (Python wheel)
- TensorFlow version (use command below): **2.2.0 and tf-nightly-gpu**
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: CUDA 10.1 / cuDNN 7
- GPU model and memory: Tesla T4 (15079MiB)

**Describe the current behavior**

The cuDNN implementation of GRU is not being used when the model is built and compiled within `tf.distribute.MirroredStrategy`. The same model built without a strategy does use the cuDNN GRU implementation.

**Describe the expected behavior**

I expect a GRU model built within a `tf.distribute.MirroredStrategy` scope to use the cuDNN GRU implementation, as it does when built without a strategy.

**Standalone code to reproduce the issue**

Please see this [Google Colab notebook](https://colab.research.google.com/gist/kaczmarj/ecda57beb73afb7e894193e541e6489a#file-mirroredstrategy_cudnn_gru-ipynb=). Please use the GPU runtime.

Here is the code that is in the notebook:

```python
import numpy as np
import tensorflow as tf

tfk = tf.keras
tfkl = tfk.layers

# The message that the cuDNN GRU implementation is used is printed at the debug level.
tf.get_logger().setLevel(""DEBUG"")

# Generate data.
x = np.random.rand(5000, 200, 750).astype(np.float32)
x += 0.01
x.clip(min=0, max=1, out=x)
y = np.random.randint(2, size=(5000, 1), dtype=np.int32)

def gru_cudnn(input_shape=(200, 750), dropout_rate=0.5):
    model = tfk.Sequential()
    model.add(tfkl.InputLayer(input_shape))
    model.add(tfkl.Masking(mask_value=0.0))
    model.add(tfkl.GRU(128))
    model.add(tfkl.Dropout(dropout_rate))
    model.add(tfkl.Dense(1))
    return model

# Train model (uses cuDNN implementation).
model = gru_cudnn()
model.compile(
    optimizer=tfk.optimizers.Adam(1e-3), 
    loss=tfk.losses.BinaryCrossentropy(from_logits=True))
# DEBUG:tensorflow:Layer gru will use cuDNN kernel when run on GPU.
model.fit(x, y)
# 157/157 [==============================] - 3s 20ms/step - loss: 0.8034

# Train using mirrored strategy, but using only one GPU.
strategy = tf.distribute.MirroredStrategy(devices=[""GPU:0""])
with strategy.scope():
    model = gru_cudnn()
    model.compile(
        optimizer=tfk.optimizers.Adam(1e-3), 
        loss=tfk.losses.BinaryCrossentropy(from_logits=True))
# DEBUG:tensorflow:Layer gru_1 will use cuDNN kernel when run on GPU.
model.fit(x, y)
# INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
# INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
# INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
# INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
# 157/157 [==============================] - 44s 279ms/step - loss: 0.8120
```"
40420,'tf.Dilation2D' op is neither a custom op nor a flex op,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): google colab, python 3.6
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source): 


**Provide the text output from tflite_convert**

```
INFO:tensorflow:Saver not created because there are no variables in the graph to restore

---------------------------------------------------------------------------

ConverterError                            Traceback (most recent call last)

<ipython-input-6-6ce9f2d0000a> in <module>()
      6                                        tf.lite.OpsSet.SELECT_TF_OPS]
      7 
----> 8 tflite_model = converter.convert()
      9 
     10 # Save the TF Lite model.

2 frames

/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    225       stdout = _try_convert_to_unicode(stdout)
    226       stderr = _try_convert_to_unicode(stderr)
--> 227       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    228   finally:
    229     # Must manually cleanup files.

ConverterError: See console for info.
2020-06-12 18:51:22.076900: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.
2020-06-12 18:51:22.076954: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.
2020-06-12 18:51:22.626844: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.
2020-06-12 18:51:22.954133: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-06-12 18:51:23.172150: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000134999 Hz
2020-06-12 18:51:23.172487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ef1c2b2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-12 18:51:23.172520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-12 18:51:23.180594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-12 18:51:23.271482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-12 18:51:23.271997: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ef1c2b100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-12 18:51:23.272026: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1
2020-06-12 18:51:23.272188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-12 18:51:23.272524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla P4 computeCapability: 6.1
coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s
2020-06-12 18:51:23.272923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-12 18:51:23.274901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-12 18:51:23.276599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-12 18:51:23.277233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-12 18:51:23.279053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-12 18:51:23.279837: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-12 18:51:23.283468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-12 18:51:23.283603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-12 18:51:23.284015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-12 18:51:23.285247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-06-12 18:51:23.288818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-12 18:51:23.293809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-12 18:51:23.293841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-06-12 18:51:23.293870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-06-12 18:51:23.297246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-12 18:51:23.297674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-12 18:51:23.298025: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-06-12 18:51:23.298071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5523 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)
2020-06-12 18:51:30.236028: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.
loc(""Dilation2D""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_1""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_2""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_3""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_4""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_5""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_6""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_7""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_8""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_9""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_10""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_11""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_12""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_13""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_14""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_15""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_16""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_17""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_18""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_19""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_20""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_21""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_22""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_23""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_24""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_25""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_26""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_27""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_28""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_29""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_30""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_31""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc(""Dilation2D_32""): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
error: failed while converting: 'main'
Ops that need custom implementation (enabled via setting the -emit-custom-ops flag): Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D
Traceback (most recent call last):
  File ""/usr/local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: <unknown>:0: error: loc(""Dilation2D""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_1""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_2""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_3""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_4""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_5""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_6""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_7""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_8""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_9""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_10""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_11""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_12""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_13""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_14""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_15""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_16""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_17""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_18""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_19""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_20""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_21""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_22""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_23""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_24""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_25""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_26""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_27""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_28""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_29""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_30""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_31""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""Dilation2D_32""): 'tf.Dilation2D' op is neither a custom op nor a flex op
<unknown>:0: error: failed while converting: 'main'
Ops that need custom implementation (enabled via setting the -emit-custom-ops flag): Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D
```

**Standalone code to reproduce the issue**
First download this saved model
https://drive.google.com/file/d/136KmfVwBT2htxPDZeYw4-TXmxPYe7Vsa/view?usp=sharing
Second run:
```
import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model('saved')
converter.target_spec.supported_types = [tf.float16]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]

tflite_model = converter.convert()
```

I am posting this to request the Dilation2D op for tflite. Thanks."
40419,"ValueError: we need atleast 1 value to plot word cloud,  got 0","
normal_words = ' '.join([text for text in combi['tidy_tweet'][combi['label'] == 0]]) wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(normal_words) plt.figure(figsize=(10, 7)) plt.imshow(wordcloud, interpolation=""bilinear"") plt.axis('off') plt.show()

ValueError: we need atleast 1 word to plot word cloud, got 0."
40418,Building Tensorflow from the source for the second time fails,"I am trying to build Tensorflow from the source (master branch) to get **AVX2** problem solved and get training faster, on my 
- **windows 10** machine 
-  intel(R) cpu Core i78650U 1.90GHz 2.11  which apparently doesn't have GPU support.
- **Python 3.7.4**.
First time I set my mavx2 and mavx flags when running configure.py and then I tried this command:
`bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda -k //tensorflow/tools/pip_package:build_pip_package`

It ran quite fast and built successfully though I could read in the log:

> cl : Command line warning D9002 : ignoring unknown option '-mavx'
> cl : Command line warning D9002 : ignoring unknown option '-mavx2'
> cl : Command line warning D9002 : ignoring unknown option '-mfma'
> cl : Command line warning D9002 : ignoring unknown option '-mfpmath=both'
> cl : Command line warning D9002 : ignoring unknown option '-msse4.2'
> cl : Command line warning D9002 : ignoring unknown option '-fno-strict-aliasing'
> cl : Command line warning D9002 : ignoring unknown option '-fexceptions' so these options aren't known

I made a wheel anyway and I could run the train command, however I am getting this warning:

>  This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX AVX2
> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.

and it doesn't run any faster.
I decided to manipulate the flags and run the bazel build again but now it fails! I cannot compile it anymore and I don't know if the previous build is failing this one or what?
How should I clean the previous build/installation? Should I checkout the code again?

And by the way what should I set my flags to, to get it right this time?

"
40417,ValueError: Unable to fit model on a built graph. ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab



**Hello, I am trying to build a model that relies on the concept of virtual adversarial training for text classification. The model involves the functional API of Keras and I have been to build a model graph. However, there is something wrong when I try to fit my training dataset on the model. Please suggest to me where I might be going wrong in the process.

Virtual Adversarial Training involves calculating KL DIvergence between two probability distribution. The shape of train data is displayed as well to get a better understanding about the problem. The code has been inspired from the following link but I have changed the domain to text preprocessing and is more advanced.

More information: 
Code: [https://gist.github.com/divamgupta/c778c17459c1f162e789560d5e0b2f0b]
Theory: [https://divamgupta.com/unsupervised-learning/semi-supervised-learning/2019/05/31/introduction-to-virtual-adversarial-training.html]

Google Colab link for below code: [https://colab.research.google.com/drive/1sdv-sGE80HwdPKkl_p3gakhkxgKO-zRv?usp=sharing]
**

**
CODE
**


`
import numpy as np
import random
import time
#------------------- Tensorflow
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Embedding, Dense, LSTM, Bidirectional

MAX_VOCAB_SIZE = len(word_index) + 1 # maximum no of unique words
MAX_DOC_LENGTH = 500 # maximum no of words in each sentence
EMBEDDING_DIM = 300 # Embeddings dimension from Glove directory

def compute_kld(p_logit, q_logit):
  p = tf.nn.softmax(p_logit)
  q = tf.nn.softmax(q_logit)
  kl_score = tf.reduce_sum( p * (tf.math.log(p+1e-16) - tf.math.log(q+1e-16)), axis = 1)
  return kl_score # lower kl means closer the distributions are

inputs = Input(shape=(MAX_DOC_LENGTH,), name=""Seq_Input"") # Text Sequence is the first input
#inputs = tf.Variable(tf.zeros(shape=(MAX_DOC_LENGTH,)))

def createEmbd(inputs): # Creates Embeddings for a sequence of words
  return layers.Embedding(input_dim=MAX_VOCAB_SIZE,
                    output_dim=EMBEDDING_DIM,
                    input_length = MAX_DOC_LENGTH,
                    trainable=True,
                    mask_zero=True,
                    name=""Keras_Embedding"")(inputs)

input_emb = createEmbd(inputs)
noise_emb = tf.random.uniform(shape=tf.shape(input_emb)) # Idea is to add noise to these embeddings
#noise_emb = tf.math.add(input_emb, noise_emb)
noise_emb = input_emb + noise_emb

input_h1 = layers.LSTM(units=128,name=""Input_h1"")(input_emb)
noise_h1 = layers.LSTM(units=128,name=""Noise_h1"")(noise_emb)

p_logit = layers.Dense(units=16, activation='relu', name=""p_logit"")(input_h1)
p_logit_r = layers.Dense(units=16, activation='relu', name=""p_logit_r"")(noise_h1)

with tf.GradientTape(watch_accessed_variables=False) as tape:
    tape.watch(noise_emb)
    kl_score = compute_kld(p_logit, p_logit_r)
    kl_score = tf.convert_to_tensor(kl_score, dtype=tf.float32)
grads = tape.gradient(kl_score, noise_emb) # Differentiate kl_score with respect to noise_embd

.#p_logit = tf.stop_gradient(p_logit)
.#p_logit_r = tf.stop_gradient(p_logit_r)

.# Due to some reason the first execution returned ""None"" for gradients so manually added the shape to be able to build the model
if grads is None:
  grads = tf.random.uniform(shape=tf.shape(noise_emb)) 

vadv_emb = tf.math.add(input_emb, grads)
vadv_h1 = layers.LSTM(units=128,name=""vadv_h1"")(vadv_emb)
q_logit = layers.Dense(units=16, activation='relu', name=""q_logit"")(vadv_h1)

vat_loss = compute_kld(p_logit, q_logit) # I need to add this vat loss(Scalar) to the final cost function

.# logits = layers.average([p_logit, p_logit_r, q_logit])
outputs = layers.Dense(units=1, activation='softmax', name=""output"")(p_logit)
model = keras.Model(inputs, outputs)

model.add_loss(vat_loss)

.# Not sure if this graph has any problem
keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)

model.summary()

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss= 'binary_crossentropy',metrics=['accuracy','precision'])

# Shuffle data random before splitting
indices = np.arange(sequences.shape[0])
random.Random(1).shuffle(indices)
data = sequences[indices]
labels = y[indices]

num_test_samples = int(0.2 * data.shape[0])
x_train = data[:-num_test_samples]
y_train = labels[:-num_test_samples]
x_test = data[-num_test_samples:]
y_test = labels[-num_test_samples:]
print(x_train.shape, y_train.shape)
print(x_train[0].shape, y_train[0].shape)

Output:
(400, 500) (400,)
(500,) ()
`
`train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset.take(1)
# output <TakeDataset shapes: ((500,), ()), types: (tf.int32, tf.int64)>

**model.fit(train_dataset,** epochs=2, batch_size=40)
#model.fit(x_train, y_train, epochs=2, validation_split=0.2, shuffle=True, batch_size=32)

`




**Any other info/logs**
Error: 
Epoch 1/2
WARNING:TensorFlow:Model was constructed with shape (None, 500) for input Tensor(""Seq_Input:0"", shape=(None, 500), dtype=float32), but it was called on an input with incompatible shape (500, 1).
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-113-cdea0e86cd74> in <module>()
----> 1 model.fit(train_dataset, epochs=2, batch_size=40)
      2 #model.fit(x_train, y_train, epochs=2, validation_split=0.2, shuffle=True, batch_size=32)

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step  **
        y, y_pred, sample_weight, regularization_losses=self.losses)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:213 __call__
        batch_dim = array_ops.shape(y_t)[0]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:984 _slice_helper
        name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1150 strided_slice
        shrink_axis_mask=shrink_axis_mask)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:10179 strided_slice
        shrink_axis_mask=shrink_axis_mask, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper
        attrs=attr_protos, op_def=op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal
        compute_device)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal
        op_def=op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1817 __init__
        control_input_ops, op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1657 _create_c_op
        raise ValueError(str(e))

    ValueError: slice index 0 of dimension 0 out of bounds. for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](Shape, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.**
"
40416,TFLite model not working with png images,"Hello,

I have trained a semantic segmentation model using VGG16 and unet. The model displayed good results before (irrelevant of image type). 

When I converted the model to tflite, I noticed that it does not work with png files. Here is an example : 

![image](https://user-images.githubusercontent.com/47783157/84525079-57424e80-acdb-11ea-9ac1-d1f1c2269b2f.png)

![image](https://user-images.githubusercontent.com/47783157/84525095-61fce380-acdb-11ea-9f92-f012c0c75ade.png)


When trying with a jpg however, the results seem fine compared to the original model. An example:

![image](https://user-images.githubusercontent.com/47783157/84525036-44c81500-acdb-11ea-9371-9015339cf568.png)<!-- .element height=""20%"" width=""20%"" -->

![image](https://user-images.githubusercontent.com/47783157/84525018-3e399d80-acdb-11ea-92ad-f65261f10e1a.png)

Hope someone have the answer because I do the same preprocessing to both images. And the original model as I said work fine with both types.



"
40415,AbstractRNNCell documentation,"# Documentation for state in AbstractRNNCell could be more clear.

In the documentation for the `AbstractRNNCell` it does not make it clear that the state is a tuple. https://www.tensorflow.org/api_docs/python/tf/keras/layers/AbstractRNNCell

This was a gotcha for me when I defined a custom RNN cell that had a single state. It kept adding an axis to that state whenever I performed an operation on it.

For example, the code within the call method the class implementing `AbstractRNNCell`
```logging.info(f'states: {states}')
logging.info(f'state_update: {state_update}')
new_states = tf.math.add(states, state_update)
logging.info(f'new_states: {new_states}')
```

leads to the confusing output

```06-12 12:28 root         INFO     states: (<tf.Tensor 'Placeholder_3:0' shape=(32, 4) dtype=float32>,)
06-12 12:28 root         INFO     state_update: Tensor(""add_1:0"", shape=(32, 4), dtype=float32)
06-12 12:28 root         INFO     new_states: Tensor(""Add_2:0"", shape=(1, 32, 4), dtype=float32)
```

Upon implementing the state as a tuple of length one, the issue was solved. I think this could be made more clear in the documentation.

Many thanks."
40414,Bug in tf.linalg.matmul on complex matrices,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**
- TensorFlow installed from (source or binary): **binary x64**
- TensorFlow version (use command below): **v2.2.0-rc4-8-g2b96f3662b 2.2.0**
- Python version: **python --version**
- CUDA/cuDNN version: **10.1**
- GPU model and memory: **2080 Ti, 1050 Ti**

**Describe the current behavior**
In `tf.linalg.matmul` setting `adjoint_a=True` throws an error. This worked fine in tf2.1, started erroring after upgrading to tf2.2. The minimal repro is below. 

**Standalone code to reproduce the issue**

```
import tensorflow as tf
a = tf.constant([[1,0],[0,1]], dtype=tf.complex64)
tf.linalg.matmul(a, a, adjoint_a=True)
```

**Other info / logs** 
```
Traceback (most recent call last):

  File ""<ipython-input-1-85e3daa5daeb>"", line 3, in <module>
    tf.linalg.matmul(a, a, adjoint_a=True)

  File ""C:\Users\qulab\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\util\dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)

  File ""C:\Users\qulab\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\ops\math_ops.py"", line 2984, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)

  File ""C:\Users\qulab\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\ops\gen_math_ops.py"", line 5577, in mat_mul
    _ops.raise_from_not_ok_status(e, name)

  File ""C:\Users\qulab\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\framework\ops.py"", line 6653, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)

  File ""<string>"", line 3, in raise_from

InternalError: Blas GEMM launch failed : a.shape=(2, 2), b.shape=(2, 2), m=2, n=2, k=2 [Op:MatMul]
```
"
40413,GPU sudden explosion during training.,"**System information**
- OS Platform and Distribution: Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7
- CUDA/cuDNN version: 10.0
- GPU model and memory: Nvidia 2080 8G

When I train the network,  for the first 25 samples of training, usage of memory and GPU were unchanged: 
![image](https://user-images.githubusercontent.com/55009565/84515230-c3827980-acfe-11ea-8241-9c96c3108e7e.png)
![image](https://user-images.githubusercontent.com/55009565/84515258-cd0be180-acfe-11ea-9fa0-400001686f1a.png)


But when it comes to 46-th sample, I got:
![image](https://user-images.githubusercontent.com/55009565/84515433-0b090580-acff-11ea-9edc-d93fc2398526.png)
And the usage of GPU and memory added:
![image](https://user-images.githubusercontent.com/55009565/84515495-1eb46c00-acff-11ea-9780-9413a69546dc.png)
![image](https://user-images.githubusercontent.com/55009565/84515535-31c73c00-acff-11ea-91a2-f207d6f6e472.png)


And when to comes to 96-th sample.

```
Limit:                  7012814029
InUse:                  4755516416
MaxInUse:               5347089664
NumAllocs:                  624595
MaxAllocSize:           2055250688

2020-06-12 22:52:55.958865: W tensorflow/core/common_runtime/bfc_allocator.cc:271] ****************__********************************************************************___***********
2020-06-12 22:52:55.959733: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at aggregate_ops.cc:70 : Resource exhausted: OOM when allocating tensor with shape[129675,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
Traceback (most recent call last):
  File ""/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py"", line 553, in _aggregate_grads
    return gen_math_ops.add_n(gradients)
  File ""/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 428, in add_n
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[129675,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:AddN]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/frank/PycharmProjects/reconstruction_NN/reconstruction_test.py"", line 634, in <module>
    train_model()
  File ""/home/frank/PycharmProjects/reconstruction_NN/reconstruction_test.py"", line 538, in train_model
    lo = m.train(train_dat, gt_dat, loss_dict)
  File ""/home/frank/PycharmProjects/reconstruction_NN/reconstruction_NN.py"", line 498, in train
    grad = gtape.gradient(loss_, self.trainable_variables)
  File ""/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py"", line 946, in gradient
    unconnected_gradients=unconnected_gradients)
  File ""/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py"", line 72, in imperative_grad
    compat.as_str(unconnected_gradients.value))
  File ""/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py"", line 126, in _gradient_function
    mock_op = _MockOp(attr_tuple, inputs, outputs, op_name)
SystemError: <class 'tensorflow.python.eager.backprop._MockOp'> returned a result with an error set

Process finished with exit code 1

```

It seems like something wrong with
![image](https://user-images.githubusercontent.com/55009565/84515981-c2058100-acff-11ea-98e6-4da5084f951a.png)

Anyone can help?
Thanks!

Best,
Frank








"
40412,tensorflow.keras slower than keras for repetitive calls to Model.predict(),"**System information**
- google colab notebook: [https://colab.research.google.com/drive/17PCkA9z5i8Yj9qd4QREYOSoaz8JFjk0C?usp=sharing](https://colab.research.google.com/drive/17PCkA9z5i8Yj9qd4QREYOSoaz8JFjk0C?usp=sharing)

**Describe the current behavior**
tensorflow.keras is significantly slower than keras when using repetitive calls to Model.predict().

**Describe the expected behavior**
Should be about the same no?
"
40411,Seq2Seq using copy mechanism(such as pointer-generator network),"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):tf 2.1
- Are you willing to contribute it (Yes/No):Yes



**Describe the feature and the current behavior/state.**
I am using the template in tutorial 'Machine translation using Seq2Seq with attention'. 
However, nowadays, copy mechanism(pointer-generator and copynet) is really important when we train seq2seq model.

Could you please provide an API that Machine translation using pointer-generator network?

**Will this change the current API? How?**  it may need a new API or old API with new parameters that can let us use pointer-generator.

**Who will benefit with this feature?**
The researcher who focus on machine translation and chatbot would be benefited with this feature

**Any Other info.**
"
40409,Tensorflow not working after installing tensorflow-gpu,"### System information

-   i used a stock example
-   OS Platform and Distribution: Windows 8, with JetBrains Pycharm
-   **TensorFlow installed from (source or binary)**: pip
-   **TensorFlow version: 2.0 upgraded to 2.2
-   **Python version**: 3.6
-   **CUDA/cuDNN version**: 11
-   **GPU model and memory**: NVIDIA Geforce 970
-   **Exact command to reproduce**:
```
from keras import backend as K
print(K.tensorflow_backend._get_available_gpus())
```

### Describe the problem
I wanted to start using Keras on my GPU as so far i only used the CPU, and it is rather slow.
However once i downloaded the tensorflow-gpu package the simple 
```
from keras import backend as K
```
produces the following error messages.
I tried upgrading my tensorflow installation from 2.0 to 2.2 but it did not help.
I am a bit helpless and would love to know how to continue.
I have CUDA installed.
Before i installed the tensorflow-gpu package, 
`from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())
`
printed my CPU correctly as a device. NOw it gives the same error message.
So i am assuming the problem is in the installatiuon of tensorflow.
Thank you so musch for your help!

### Source code / logs
`C:\Users\OM\PycharmProjects\intromljolo\venv\Scripts\python.exe C:/Users/OM/AppData/Roaming/JetBrains/PyCharmCE2020.1/scratches/scratch.py
Using TensorFlow backend.
Traceback (most recent call last):
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Anaconda3_64\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Anaconda3_64\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/OM/AppData/Roaming/JetBrains/PyCharmCE2020.1/scratches/scratch.py"", line 1, in <module>
    from keras import backend as K
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\keras\backend\__init__.py"", line 1, in <module>
    from .load_backend import epsilon
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\keras\backend\load_backend.py"", line 90, in <module>
    from .tensorflow_backend import *
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\OM\PycharmProjects\intromljolo\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Anaconda3_64\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Anaconda3_64\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

Process finished with exit code 1
`"
