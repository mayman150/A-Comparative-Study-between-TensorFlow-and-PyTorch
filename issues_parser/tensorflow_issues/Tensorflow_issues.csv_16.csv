Issue Number,Issue Title,Issue Body
47064,calling GradientTape.gradient inside its context warning even though tape recording is stopped,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 2.3
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
Running a function with a gradient tape that has a stopped recording, updating gradients, inside its context causes an unnecessary/misleading warning about performance.

**Describe the expected behavior**
There should be no warning about tons of extra memory & reduced performance.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1sasTq_SY7ylBETSQDmscIqYFkZpHDr9B?usp=sharing


edit: Closing this. It's a context manager, and it wasn't used like one here."
47062,tensorflow/cc/saved_model/README.md is broken,"## URL(s) with the issue:

- https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/saved_model/README.md
- https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/cc/saved_model/README.md

## Description of issue (what needs changing):
I would expect to see some documentation regarding the package. Instead, it says `<!--#include file=""../../python/saved_model/README.md""-->`.
"
47061,tf.function Out of Memory on non first call,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8.5
- Bazel version (if compiling from source): 4.0.0
- GCC/Compiler version (if compiling from source): gcc 9.3.0
- CUDA/cuDNN version: 11.1/8.0.5
- GPU model and memory: Nvidia Quadro RTX 6000 ~ 23.8G


**Describe the current behavior**
In a for loop of my python script, I call a @tf.function decorated function and the GPU allocator ran out of memory trying to allocate memory after hundreds of calls. The number of calls before the bug is variable.

**Describe the expected behavior**
I can't understand how the GPU can run hundreds times the function without memory issues and suddenly gets OOM. I would like to have better understanding, for example why GPU tries to allocate tensors on non-first call ? Have you any suggestions about how it can be solved ?

**Standalone code to reproduce the issue**
It's impossible here to provide a simple reproducer.  The problem is I can't understand how this bug may happen.

**Other info / logs**
Here is the traceback on Jupyter. Note that the parameter N_CRITICS is a tensorflow constant, so it can't be the cause of the problem.
```
---------------------------------------------------------------------------
ResourceExhaustedError                    Traceback (most recent call last)
<ipython-input-20-9b51c2da0088> in <module>
      5     tmp_record = {}
      6     for step in range(STEPS_PER_EPOCH):
----> 7         res = train_step(N_CRITICS)
      8 
      9         # sauvegarde des rÃ©sultats d'entrainement

/NAS/deathrow/vincent/anaconda3/envs/env_vincent_2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    785     tracing_count = self.experimental_get_tracing_count()
    786     with trace.Trace(self._name) as tm:
--> 787       result = self._call(*args, **kwds)
    788       compiler = ""xla"" if self._jit_compile else ""nonXla""
    789       new_tracing_count = self.experimental_get_tracing_count()

/NAS/deathrow/vincent/anaconda3/envs/env_vincent_2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    813       # In this case we have created variables on the first call, so we run the
    814       # defunned version which is guaranteed to never create variables.
--> 815       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
    816     elif self._stateful_fn is not None:
    817       # Release the lock early so that multiple threads can perform the call

/NAS/deathrow/vincent/anaconda3/envs/env_vincent_2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2969       (graph_function,
   2970        filtered_flat_args) = self._maybe_define_function(args, kwargs)
-> 2971     return graph_function._call_flat(
   2972         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
   2973 

/NAS/deathrow/vincent/anaconda3/envs/env_vincent_2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1945         and executing_eagerly):
   1946       # No tape is watching; skip to running the function.
-> 1947       return self._build_call_outputs(self._inference_function.call(
   1948           ctx, args, cancellation_manager=cancellation_manager))
   1949     forward_backward = self._select_forward_and_backward_functions(

/NAS/deathrow/vincent/anaconda3/envs/env_vincent_2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    554       with _InterpolateFunctionError(self):
    555         if cancellation_manager is None:
--> 556           outputs = execute.execute(
    557               str(self.signature.name),
    558               num_outputs=self._num_outputs,

/NAS/deathrow/vincent/anaconda3/envs/env_vincent_2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     57   try:
     58     ctx.ensure_initialized()
---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:

ResourceExhaustedError: 2 root error(s) found.
  (0) Resource exhausted:  OOM when allocating tensor with shape[1,64,93,111,93] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node while/body/_1/while/StatefulPartitionedCall/gradient_tape/sequential_33/sequential_31/conv3d_20/Conv3D_1/Conv3DBackpropInputV2}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[while/loop_body_control/_190/_23]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

  (1) Resource exhausted:  OOM when allocating tensor with shape[1,64,93,111,93] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node while/body/_1/while/StatefulPartitionedCall/gradient_tape/sequential_33/sequential_31/conv3d_20/Conv3D_1/Conv3DBackpropInputV2}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored. [Op:__inference_train_step_49710]

Function call stack:
train_step -> train_step
```
"
47059,Steps to build dynamic libraries of tflite for raspberry pi and aarch 64(armv8) boards,"I have downloaded tensorflow source github and try to create tensorflow lite library from tools/ make makefiles.
I have not found steps to build and generate dynamic tfLite library for these hardware devices. Could You provide me the steps to build dynamic .so for tfLite library
"
47058,CUDA_ERROR_NO_BINARY_FOR_GPU on A100 when compiled with CC 7.0,"**System information**
- Have I written custom code: No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7.4
- Bazel version (if compiling from source): 3.7.1
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: 10.1
- GPU model and memory: A100

**Describe the current behavior**

I'm compiling TF for our cluster with a CUDA 11 driver but 10.1 toolkit (there are reasons not to upgrade nvcc yet). Hence the maximum supported CUDA compute capability by nvcc is 7.0, but the A100 GPUs used have 8.0. This shouldn't be a problem as the CUDA driver can JIT compile the 7.0 PTX code for the A100.

However running the tests from the TensorFlow repo yields errors like: `tensorflow.python.framework.errors_impl.InternalError: Failed to load in-memory CUBIN: CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device [Op:Abs]`

Following the error message I come to `GpuExecutor::GetKernel` which has some logic whether to load a cubin or ptx binary, so my feeling is that that is faulty.

**Describe the expected behavior**

PTX code is loaded and kernel executed successfully

**Standalone code to reproduce the issue**

- `export TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.1,7.0`
- `bazel test --config=noaws --config=nogcp --config=nohdfs --compilation_mode=opt --config=opt --subcommands --verbose_failures --jobs=64 --copt=""-fPIC"" --distinct_host_configuration=false --config=mkl --test_output=errors --build_tests_only --local_test_jobs=1 --test_timeout=3600 --test_size_filters=small -- //tensorflow/core/kernels/mlir_generated:gpu_abs_test_gpu`

**Other info / logs**
Example error:

```
ERROR: testBroadcastWithBatchParamsAndBiggerEvent (__main__.CategoricalTest)
CategoricalTest.testBroadcastWithBatchParamsAndBiggerEvent
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/dev/shm/s3248973-EasyBuild/TensorFlow/2.4.1/fosscuda-2019b-Python-3.7.4/tmp9lUSI1-bazel-tf/fdff6046a749a079864ed2bee7e018bf/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/distributions/categorical_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/distributions/categorical_test.py"", line 296, in testBroadcastWithBatchParamsAndBiggerEvent
    ""norm_cdf"": norm.cdf(real_event_tf),
  File ""/dev/shm/s3248973-EasyBuild/TensorFlow/2.4.1/fosscuda-2019b-Python-3.7.4/tmp9lUSI1-bazel-tf/fdff6046a749a079864ed2bee7e018bf/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/distributions/categorical_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/distributions/distribution.py"", line 898, in cdf
    return self._call_cdf(value, name)
  File ""/dev/shm/s3248973-EasyBuild/TensorFlow/2.4.1/fosscuda-2019b-Python-3.7.4/tmp9lUSI1-bazel-tf/fdff6046a749a079864ed2bee7e018bf/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/distributions/categorical_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/distributions/distribution.py"", line 874, in _call_cdf
    return self._cdf(value, **kwargs)
  File ""/dev/shm/s3248973-EasyBuild/TensorFlow/2.4.1/fosscuda-2019b-Python-3.7.4/tmp9lUSI1-bazel-tf/fdff6046a749a079864ed2bee7e018bf/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/distributions/categorical_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/distributions/normal.py"", line 207, in _cdf
    return special_math.ndtr(self._z(x))
  File ""/dev/shm/s3248973-EasyBuild/TensorFlow/2.4.1/fosscuda-2019b-Python-3.7.4/tmp9lUSI1-bazel-tf/fdff6046a749a079864ed2bee7e018bf/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/distributions/categorical_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/distributions/special_math.py"", line 143, in ndtr
    return _ndtr(x)
  File ""/dev/shm/s3248973-EasyBuild/TensorFlow/2.4.1/fosscuda-2019b-Python-3.7.4/tmp9lUSI1-bazel-tf/fdff6046a749a079864ed2bee7e018bf/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/distributions/categorical_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/distributions/special_math.py"", line 151, in _ndtr
    z = math_ops.abs(w)
  File ""/dev/shm/s3248973-EasyBuild/TensorFlow/2.4.1/fosscuda-2019b-Python-3.7.4/tmp9lUSI1-bazel-tf/fdff6046a749a079864ed2bee7e018bf/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/distributions/categorical_test_gpu.runfiles/org_tensorflow/tensorflow/python/util/dispatch.py"", line 201, in wrapper
    return target(*args, **kwargs)
  File ""/dev/shm/s3248973-EasyBuild/TensorFlow/2.4.1/fosscuda-2019b-Python-3.7.4/tmp9lUSI1-bazel-tf/fdff6046a749a079864ed2bee7e018bf/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/distributions/categorical_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/math_ops.py"", line 401, in abs
    return gen_math_ops._abs(x, name=name)
  File ""/dev/shm/s3248973-EasyBuild/TensorFlow/2.4.1/fosscuda-2019b-Python-3.7.4/tmp9lUSI1-bazel-tf/fdff6046a749a079864ed2bee7e018bf/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/distributions/categorical_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py"", line 46, in _abs
    _ops.raise_from_not_ok_status(e, name)
  File ""/dev/shm/s3248973-EasyBuild/TensorFlow/2.4.1/fosscuda-2019b-Python-3.7.4/tmp9lUSI1-bazel-tf/fdff6046a749a079864ed2bee7e018bf/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/distributions/categorical_test_gpu.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 6862, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: Failed to load in-memory CUBIN: CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device [Op:Abs]
```
"
47057,Conv2D output shape becomes fully dynamic when only input batch size is dynamic in tf-nightly,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4.1 v.s. nightly

### 2. Code

nightly: https://colab.research.google.com/drive/1r-vzh6JCIc5A4K8aYEbMZANWVrtSkKrF?usp=sharing
2.4.1: https://colab.research.google.com/drive/1ODMv9joqc2ybsSdNHhGq1RWKXYsnFjd-?usp=sharing

### 3. Failure after conversion

Models are correct, but nightly has fully dynamic output shape and 2.4.1 has dynamic batch dim only.

Nightly
![image](https://user-images.githubusercontent.com/11615393/107465904-10ca1b80-6b18-11eb-9a96-9c7ba9254bcf.png)

2.4.1
![image](https://user-images.githubusercontent.com/11615393/107465944-1f183780-6b18-11eb-92ed-7befb0614e6b.png)

1 here means dynamic dim (netron cannot show it precisely). It does not really matter in my use case though. Just a regression issue."
47056,Why is snappy compression output buffer size so small?,"Hi @frankchn,
The snappy compression buffer size is hard coded to 262144 bytes:
https://github.com/tensorflow/tensorflow/blob/dec8e0b11f4f87693b67e125e67dfbc68d26c205/tensorflow/core/lib/io/snappy/snappy_compression_options.h#L30. This is a quite small number leading to high chance of hitting the error:
https://github.com/tensorflow/tensorflow/blob/516ae286f6cc796e646d14671d94959b129130a4/tensorflow/core/lib/io/snappy/snappy_inputstream.cc#L113

I wonder why it is set to thus small. 

Furthermore, `output_buffer_` is a fixed sized array https://github.com/tensorflow/tensorflow/blob/516ae286f6cc796e646d14671d94959b129130a4/tensorflow/core/lib/io/snappy/snappy_inputstream.h#L73

Why can't it be a vector so that we don't need the `output_buffer_size` at all? I'm happy to submit a PR to make the according change if needed.

Thanks.
"
47054,"tf.keras.initializers.zeros causes model.save to fail, while tf.keras.initializers.Zeros() works great","[Here](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/Zeros) it's written that `tf.keras.initializers.zeros` is a shortcut for `tf.keras.initializers.Zeros()`.
If it is a shortcut, then both should work same


While saving the model, if I use `tf.keras.initializers.zeros` , model save failes, but using `tf.keras.initializers.Zeros()` works great.

Same issue raised by someone at [Stackoverflow](https://stackoverflow.com/questions/57154799/keras-model-saving-erroring-typeerror-get-config-missing-1-required-position) 

[Colab](https://colab.research.google.com/drive/1E0P-aBU9B7RO_QUtDrlRDPcOWqd6UfkD?usp=sharing#scrollTo=weBjeZAFJOP4)

"
47053,Weight becomes untrainable after multiplying with constant ,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macos
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**: tensorflow 2.4
-   **Python version**: python 3.7

### Describe the problem
I want to mask the weights of my network (set them to zero and freeze them, i.e. no gradients). I tried creating a custom layer and multiply the weight matrices by a constant matrix, but this makes the weight matrices no longer trainable. Note that this approach used to work in tensorflow 1, and I can't figure out why it doesn't work anymore in tf2. I've attached an example in this [colab](https://colab.research.google.com/drive/1E1IdLuAFbQUKzrxoqN0XaZ79wb3au0nY?usp=sharing).
"
47051,java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model,"Please, in desperate need for help, has been trying to solve for 10 days. the tensorflow lite model I trained is here  [here](uhttps://drive.google.com/file/d/1fYay6FXNlAXi-migvGRtaeqNXB8gKZXk/view?usp=sharingrl). I ran python inference test and it worked. However, no way it is working on Android sample object detection app here https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android

by debugging the issue this  long modelHandle = createModelWithBuffer(this.modelByteBuffer, errorHandle); specifically this part in  NativeInterpreterWrapper.class
 NativeInterpreterWrapper(ByteBuffer buffer, Options options) {
        this.inferenceDurationNanoseconds = -1L;
        this.isMemoryAllocated = false;
        this.delegates = new ArrayList();
        this.ownedDelegates = new ArrayList();
        TensorFlowLite.init();
        if (buffer != null && (buffer instanceof MappedByteBuffer || buffer.isDirect() && buffer.order() == ByteOrder.nativeOrder())) {
            this.modelByteBuffer = buffer;
            long errorHandle = createErrorReporter(512);
            long modelHandle = createModelWithBuffer(this.modelByteBuffer, errorHandle);
            this.init(errorHandle, modelHandle, options);
        } else {
            throw new IllegalArgumentException(""Model ByteBuffer should be either a MappedByteBuffer of the model file, or a direct ByteBuffer using ByteOrder.nativeOrder() which contains bytes of model content."");
        }
    }

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform MACOS sieera 10.13
- Android studio 4
- I have tried every possible solution and updated the NDK
I used in the gradle

buildscript {
    repositories {
        google()
        jcenter()
        mavenLocal()
    }

aaptOptions {
        noCompress ""tflite""
        noCompress ""lite""
    }

  implementation 'org.tensorflow:tensorflow-lite-metadata:0.0.0-nightly'
    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'
also tried
 implementation 'org.tensorflow:tensorflow-lite-metadata:0.1.2-nightly'  and no difference

please help me I don't know if it is the file it self or the android libraries "
47050,ValueError: Cannot iterate over a shape with unknown rank,"### 1. System information

- OS Platform and Distribution: Ubuntu 20.04
- TensorFlow installation (pip package or built from source): pip (python 3.7)
- TensorFlow library (version, if pip package or github SHA, if built from source): tensorflow-2.4.1

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

```python
import sys
from pathlib import Path

import tensorflow as tf

# Specify the model.
saved_model_dir = Path('training/Model/admin/test2/1/exported-model/1/')

if saved_model_dir.exists():
    print(f'Converting model: {str(saved_model_dir)}')
else:
    print(f'Could not find model: {str(saved_model_dir)}')
    sys.exit(1)

# Convert the model.
converter = tf.compat.v1.lite.TFLiteConverter.from_saved_model(str(saved_model_dir))
tflite_model = converter.convert()

# Save the model.
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)

print('Ready.')
```

### 3. Failure after conversion

Error message:

```
Traceback (most recent call last):
  File ""convert-to-tflite.py"", line 17, in <module>
    tflite_model = converter.convert()
  File ""/home/thijs/.virtualenvs/tflite/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 1947, in convert
    return super(TFLiteConverter, self).convert()
  File ""/home/thijs/.virtualenvs/tflite/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 1304, in convert
    **converter_kwargs)
  File ""/home/thijs/.virtualenvs/tflite/lib/python3.7/site-packages/tensorflow/lite/python/convert.py"", line 606, in toco_convert_impl
    input_tensors, output_tensors, *args, **kwargs)
  File ""/home/thijs/.virtualenvs/tflite/lib/python3.7/site-packages/tensorflow/lite/python/convert.py"", line 497, in build_toco_convert_protos
    for dim in shape:
  File ""/home/thijs/.virtualenvs/tflite/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 861, in __iter__
    raise ValueError(""Cannot iterate over a shape with unknown rank."")
ValueError: Cannot iterate over a shape with unknown rank.
```

### 4. Any other info / logs

Startup log:

```
2021-02-09 20:09:36.646605: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/Qt/5.14.1/lib
2021-02-09 20:09:36.646636: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Converting model: training/Model/admin/test2/1/exported-model/1
2021-02-09 20:09:38.125156: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-09 20:09:38.125298: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/Qt/5.14.1/lib
2021-02-09 20:09:38.125310: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-02-09 20:09:38.125331: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (snowblower): /proc/driver/nvidia/version does not exist
2021-02-09 20:09:38.125557: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-09 20:09:38.125891: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
WARNING:tensorflow:From /home/thijs/.virtualenvs/tflite/lib/python3.7/site-packages/tensorflow/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.
2021-02-09 20:09:38.792020: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)
2021-02-09 20:09:38.858416: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3593310000 Hz
2021-02-09 20:09:38.954802: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-09 20:09:39.889489: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2021-02-09 20:09:39.889750: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2021-02-09 20:09:39.890025: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-09 20:09:39.953928: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize
  function_optimizer: function_optimizer did nothing. time = 0.004ms.
  function_optimizer: function_optimizer did nothing. time = 0ms.

WARNING:tensorflow:From /home/thijs/.virtualenvs/tflite/lib/python3.7/site-packages/tensorflow/lite/python/util.py:327: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /home/thijs/.virtualenvs/tflite/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py:856: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
2021-02-09 20:09:40.561332: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-09 20:09:41.338828: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-09 20:09:42.358175: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2021-02-09 20:09:42.358313: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2021-02-09 20:09:42.358532: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-09 20:09:42.426773: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize
  function_optimizer: function_optimizer did nothing. time = 0.004ms.
  function_optimizer: function_optimizer did nothing. time = 0ms.
```
"
47049,"""no checkpoint found"" tensorboard projector","I want to load a custom embedding file and a metadata file into tensorboard's projector plugin. I've been following this tutorial mostly: https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin. I get the ""no checkpoint found"" error in spite of the checkpoint files being present in the folder. I also have used tensorboard's inspect function on the log directory and tensorboard can't find any event files. Here's my code:

`import os
from tensorboard.plugins import projector
import pandas as pd
import tensorflow as tf

weights = pd.read_csv (""test/vectors_test.tsv"", sep = '\t')

log_dir = ""test/logs/""
weights = tf.Variable(weights)
checkpoint = tf.train.Checkpoint(embedding=weights)
checkpoint.save(os.path.join(log_dir, ""embedding.ckpt""))

# Set up config
config = projector.ProjectorConfig()
config.model_checkpoint_path = os.path.join(log_dir, ""embedding.ckpt"")
embedding = config.embeddings.add()
embedding.tensor_name = ""embedding/.ATTRIBUTES/VARIABLE_VALUE""
embedding.metadata_path = ""test/metadata_test.tsv""
projector.visualize_embeddings(log_dir, config)

%load_ext tensorboard

%tensorboard --logdir test/logs/ --host localhost --port=1003
%tensorboard --inspect --logdir test/logs
`"
47048,Allow cloning of tf.keras.Model subclass,"**System information**
- TensorFlow version (you are using): 2.4.1
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
As far as I know, there is no way to clone a class-based model currently. For functional models, we have `tf.keras.models.clone_model`, but this doesn't work for subclasses of `tf.keras.Model`. For example, if I define some model like so:
```python
class MySequentialModel(tf.keras.Model):
    def __init__(self, name=None, **kwargs):
        super().__init__(**kwargs)
        self.dense_1 = FlexibleDense(out_features=3)
        self.dense_2 = FlexibleDense(out_features=2)

    def call(self, x):
        x = self.dense_1(x)
        return self.dense_2(x)
```
Then train, save and load the model, when I try to clone it like this:
```model = tf.keras.models.clone_model(loaded_model)```
I get:
```ValueError: Expected `model` argument to be a functional `Model` instance, but got a subclass model instead.```
Is there another way to do this or am I missing something?
**Will this change the current api? How?**
Not really, you'd just be allowing an additional input type in the `tf.keras.models.clone_model` function.
**Who will benefit with this feature?**
People who want to clone class-based models."
47047,c_api_distributed_test creates huge amount of threads and segfaults,"**System information**
- Have I written custom code: no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7.4
- Bazel version (if compiling from source): 3.7.1
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: 10.1

**Describe the current behavior**

When running `bazel test` on a system with a large physical core count the test `//tensorflow/c/eager:c_api_distributed_test` finishes and then segfaults on exit.

When I manually set `OMP_NUM_THREADS=80` the test succeeds without a segfault but at around 85 it again crashes.

I'm unable to get a stacktrace neither through TensorFlow nor through gdb and even valgrind gives up with

> valgrind: the 'impossible' happened:
   Max number of threads is too low

It then prints the stacks of 500(!) threads. In GDB I was sometimes able to catch a part of the stack pointing to libiomp from the included llvm-OpenMP, but that was difficult and hard to reproduce. Usually the process would just be terminated even when in GDB.

Something I noticed: The ThreadPool(Device) creates a large amount of threads which don't terminate until program exit. I don't think this is intended and expect this to be the cause which triggers some limitation in the OpenMP runtime.

Also the crash does not happen when not all subtests are run (via the GTest filter), excluding any of the 5 (or 6?) makes the crash disappear

**Describe the expected behavior**

Threads exit when ThreadPool is destroyed and no crash happens.

**Standalone code to reproduce the issue**

- build with bazel
- `CUDA_VISIBLE_DEVICES=-1 gdb /dev/shm//tmpzWGWuq-bazel-tf/fdff6046a749a079864ed2bee7e018bf/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/c/eager/c_api_distributed_test`

**Other info / logs**
```
Executing tests from //tensorflow/c/eager:c_api_distributed_test
-----------------------------------------------------------------------------
2021-02-08 19:58:39.296267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
Running main() from test_main.cc
[==========] Running 6 tests from 1 test suite.
[----------] Global test environment set-up.
[----------] 6 tests from CAPI
[ RUN      ] CAPI.TestLocalFunctionWithPackedInput
2021-02-08 19:58:39.510017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-08 19:58:39.748990: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-02-08 19:58:39.749037: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: taurusi8028
2021-02-08 19:58:39.749045: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: taurusi8028
2021-02-08 19:58:39.749373: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3
2021-02-08 19:58:39.749416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3
2021-02-08 19:58:39.749430: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3
2021-02-08 19:58:39.749508: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:39.796167: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:59685, 1 -> localhost:50055, 2 -> localhost:31398}
2021-02-08 19:58:39.841581: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:50055
2021-02-08 19:58:39.841721: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:40.095546: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:59685, 1 -> localhost:50055, 2 -> localhost:31398}
2021-02-08 19:58:40.095796: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:31398
2021-02-08 19:58:40.095865: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:40.095922: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:40.258067: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:59685, 1 -> localhost:50055, 2 -> localhost:31398}
2021-02-08 19:58:40.406436: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:59685, 1 -> localhost:50055, 2 -> localhost:31398}
2021-02-08 19:58:40.406478: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:59685, 1 -> localhost:50055, 2 -> localhost:31398}
2021-02-08 19:58:40.406627: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:270] Creating async eager service context with rendezvous_id on host taurusi8028 /job:localhost/replica:0/task:1
2021-02-08 19:58:40.406634: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:270] Creating async eager service context with rendezvous_id on host taurusi8028 /job:localhost/replica:0/task:2
2021-02-08 19:58:40.406664: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:40.406670: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:40.408781: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:59685, 1 -> localhost:50055, 2 -> localhost:31398}
2021-02-08 19:58:40.409412: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:59685
2021-02-08 19:58:40.647385: I tensorflow/core/common_runtime/eager/kernel_and_device.cc:92] Ignoring error status when releasing multi-device function handle Unimplemented: Releasing a multi-device component 
handle on a remote device is not yet implemented.
[       OK ] CAPI.TestLocalFunctionWithPackedInput (1209 ms)
[ RUN      ] CAPI.TestRemoteFunctionWithPackedInput
2021-02-08 19:58:40.647938: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:40.673207: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:62634, 1 -> localhost:31692, 2 -> localhost:39353}
2021-02-08 19:58:40.673481: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:31692
2021-02-08 19:58:40.673544: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:40.775266: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:62634, 1 -> localhost:31692, 2 -> localhost:39353}
2021-02-08 19:58:40.778366: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:39353
2021-02-08 19:58:40.778517: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:40.778614: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:40.850707: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:62634, 1 -> localhost:31692, 2 -> localhost:39353}
2021-02-08 19:58:40.857370: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:62634, 1 -> localhost:31692, 2 -> localhost:39353}
2021-02-08 19:58:40.857557: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:62634, 1 -> localhost:31692, 2 -> localhost:39353}
2021-02-08 19:58:40.857947: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:270] Creating async eager service context with rendezvous_id on host taurusi8028 /job:localhost/replica:0/task:2
2021-02-08 19:58:40.857974: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:40.858061: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:270] Creating async eager service context with rendezvous_id on host taurusi8028 /job:localhost/replica:0/task:1
2021-02-08 19:58:40.858100: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:40.865056: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:62634, 1 -> localhost:31692, 2 -> localhost:39353}
2021-02-08 19:58:40.866478: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:62634
[       OK ] CAPI.TestRemoteFunctionWithPackedInput (367 ms)
[ RUN      ] CAPI.DistributedFunctionGraphPassOnlyOnce
2021-02-08 19:58:41.014661: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:41.024886: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:45659, 1 -> localhost:44179, 2 -> localhost:57750}
2021-02-08 19:58:41.025155: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:44179
2021-02-08 19:58:41.025233: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:41.101530: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:45659, 1 -> localhost:44179, 2 -> localhost:57750}
2021-02-08 19:58:41.103305: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:57750
2021-02-08 19:58:41.103445: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:41.103492: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:41.265757: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:45659, 1 -> localhost:44179, 2 -> localhost:57750}
2021-02-08 19:58:41.272939: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:45659, 1 -> localhost:44179, 2 -> localhost:57750}
2021-02-08 19:58:41.273025: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:45659, 1 -> localhost:44179, 2 -> localhost:57750}
2021-02-08 19:58:41.273080: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:270] Creating sync eager service context with rendezvous_id on host taurusi8028 /job:localhost/replica:0/task:1
2021-02-08 19:58:41.273111: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:41.273240: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:270] Creating sync eager service context with rendezvous_id on host taurusi8028 /job:localhost/replica:0/task:2
2021-02-08 19:58:41.273276: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:41.275488: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:45659, 1 -> localhost:44179, 2 -> localhost:57750}
2021-02-08 19:58:41.275920: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:45659
[       OK ] CAPI.DistributedFunctionGraphPassOnlyOnce (316 ms)
[ RUN      ] CAPI.DistributedFunctionNoError
2021-02-08 19:58:41.331075: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:41.405806: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:59564, 1 -> localhost:34434, 2 -> localhost:37620}
2021-02-08 19:58:41.406048: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:34434
2021-02-08 19:58:41.406115: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:41.445328: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:59564, 1 -> localhost:34434, 2 -> localhost:37620}
2021-02-08 19:58:41.446777: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:37620
2021-02-08 19:58:41.446932: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:41.447020: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:41.709247: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:59564, 1 -> localhost:34434, 2 -> localhost:37620}
2021-02-08 19:58:41.713390: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:59564, 1 -> localhost:34434, 2 -> localhost:37620}
2021-02-08 19:58:41.713392: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:59564, 1 -> localhost:34434, 2 -> localhost:37620}
2021-02-08 19:58:41.713504: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:270] Creating sync eager service context with rendezvous_id on host taurusi8028 /job:localhost/replica:0/task:2
2021-02-08 19:58:41.713531: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:41.713555: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:270] Creating sync eager service context with rendezvous_id on host taurusi8028 /job:localhost/replica:0/task:1
2021-02-08 19:58:41.713588: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:41.714723: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:59564, 1 -> localhost:34434, 2 -> localhost:37620}
2021-02-08 19:58:41.715081: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:59564
[       OK ] CAPI.DistributedFunctionNoError (448 ms)
[ RUN      ] CAPI.RemoteExecuteDeleteContextWithOutstandingRPC
2021-02-08 19:58:41.778430: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:41.843268: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:60792, 1 -> localhost:32251}
2021-02-08 19:58:41.843574: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:32251
2021-02-08 19:58:41.843637: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:41.843678: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:41.896621: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:60792, 1 -> localhost:32251}
2021-02-08 19:58:41.952439: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:60792, 1 -> localhost:32251}
2021-02-08 19:58:41.952676: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:270] Creating sync eager service context with rendezvous_id on host taurusi8028 /job:localhost/replica:0/task:1
2021-02-08 19:58:41.952707: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:41.953443: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:60792, 1 -> localhost:32251}
2021-02-08 19:58:41.953942: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:60792
[       OK ] CAPI.RemoteExecuteDeleteContextWithOutstandingRPC (178 ms)
[ RUN      ] CAPI.RemoteExecuteDeleteContextWithOutstandingRPCAsync
2021-02-08 19:58:41.956466: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:41.980731: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:63496, 1 -> localhost:32519}
2021-02-08 19:58:41.980969: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:32519
2021-02-08 19:58:41.981026: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 19:58:41.981060: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:42.347899: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:63496, 1 -> localhost:32519}
2021-02-08 19:58:42.350811: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:63496, 1 -> localhost:32519}
2021-02-08 19:58:42.350917: I tensorflow/core/distributed_runtime/eager/eager_service_impl.cc:270] Creating async eager service context with rendezvous_id on host taurusi8028 /job:localhost/replica:0/task:1
2021-02-08 19:58:42.350946: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-02-08 19:58:42.358578: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:63496, 1 -> localhost:32519}
2021-02-08 19:58:42.359091: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:63496
[       OK ] CAPI.RemoteExecuteDeleteContextWithOutstandingRPCAsync (403 ms)
[----------] 6 tests from CAPI (2921 ms total)

[----------] Global test environment tear-down
[==========] 6 tests from 1 test suite ran. (2921 ms total)
[  PASSED  ] 6 tests.

  YOU HAVE 1 DISABLED TEST

*** Received signal 11 ***
*** BEGIN MANGLED STACK TRACE ***

```

(yes the log ends here, no stack trace!)"
47044,Upload sdists to PyPI,"
I wanted to check if sdists can be uploaded on PyPi and also understand if there are any issues?
  
   
2017 : https://github.com/tensorflow/tensorflow/issues/7286 (not possible)
```
bazel build //tensorflow/tools/pip_package:build_pip_package     
bazel-bin/tensorflow/tools/pip_package/build_pip_package --src ""${srcdir}""    
cd ""${srcdir}"" && python3 ./setup.py sdist    
```
@perfinion  also mentioned that the above commands cannot create a true sdist since sdist has the compiled *.so files from bazel.
And we need to translate the bazel rules into python build rules so it can compile the libs.
"
47043,TF_SessionRun with multiple inputs gives Segmentation Fault,"System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux RHEL
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 2.4
Python version: 3.6
Bazel version (if compiling from source): 0.16.1
Exact command to reproduce: compile and execute my program


Problem description:
i have created a logistic regression model using tf.estimators.linearClassifier and exported the model to serve it using C API.

the saved_model cli command has the following output:
The given SavedModel SignatureDef contains the following input(s):
inputs['a'] tensor_info:
dtype: DT_INT64
shape: (-1, 1)
name: Placeholder:0
inputs['b'] tensor_info:
dtype: DT_INT64
shape: (-1, 1)
name: Placeholder_1:0
The given SavedModel SignatureDef contains the following output(s):
outputs['all_class_ids'] tensor_info:
dtype: DT_INT32
shape: (-1, 2)
name: head/predictions/Tile:0
outputs['all_classes'] tensor_info:
dtype: DT_STRING
shape: (-1, 2)
name: head/predictions/Tile_1:0
outputs['class_ids'] tensor_info:
dtype: DT_INT64
shape: (-1, 1)
name: head/predictions/ExpandDims:0
outputs['classes'] tensor_info:
dtype: DT_STRING
shape: (-1, 1)
name: head/predictions/str_classes:0
outputs['logistic'] tensor_info:
dtype: DT_FLOAT
shape: (-1, 1)
name: head/predictions/logistic:0
outputs['logits'] tensor_info:
dtype: DT_FLOAT
shape: (-1, 1)
name: linear/linear_model/linear/linear_model/linear/linear_model/weighted_sum:0
outputs['probabilities'] tensor_info:
dtype: DT_FLOAT
shape: (-1, 2)
name: head/predictions/probabilities:0
Method name is: tensorflow/serving/predict

it has two input tensors and 5 outputs, the following is the c code use to run this  model:

#include <stdlib.h>
#include <stdio.h>
#include ""tensorflow/c/c_api.h""

void NoOpDeallocator(void* data, size_t a, void* b) {}

int main()
{
    //********* Read model
    TF_Graph* Graph = TF_NewGraph();
    TF_Status* Status = TF_NewStatus();

    TF_SessionOptions* SessionOpts = TF_NewSessionOptions();
    TF_Buffer* RunOpts = NULL;

    const char* saved_model_dir = ""/nobackup/rajassub/scripts/C-Programs/tensorflow/logicalRegression/"";
    const char* tags = ""serve""; // default model serving tag; can change in future
    int ntags = 1;

    TF_Session* Session = TF_LoadSessionFromSavedModel(SessionOpts, RunOpts, saved_model_dir, &tags, ntags, Graph, NULL, Status);
    if(TF_GetCode(Status) == TF_OK)
    {
        printf(""TF_LoadSessionFromSavedModel OK\n"");
    }
    else
    {
        printf(""%s"",TF_Message(Status));
    }

    //****** Get input tensor
    //TODO : need to use saved_model_cli to read saved_model arch
    int NumInputs = 2;

    TF_Output* Input = (TF_Output*)malloc(sizeof(TF_Output) * NumInputs);

    TF_Output t0 = {TF_GraphOperationByName(Graph, ""Placeholder""), 0};
    if(t0.oper == NULL)
        printf(""ERROR: Failed TF_GraphOperationByName placeholder\n"");
    else
	printf(""TF_GraphOperationByName placeholder is OK\n"");
    
	
    TF_Output t1 = {TF_GraphOperationByName(Graph, ""Placeholder_1""), 0};
    if(t1.oper == NULL)
        printf(""ERROR: Failed TF_GraphOperationByName placeholder_1\n"");
    else
	printf(""TF_GraphOperationByName placeholder_1 is OK\n"");
	
    Input[0] = t0;
	Input[1] = t1;
    
    //********* Get Output tensor
    int NumOutputs = 5;
    TF_Output* Output = (TF_Output*)malloc(sizeof(TF_Output) * NumOutputs);

    TF_Output t2 = {TF_GraphOperationByName(Graph, ""head/predictions/ExpandDims""), 0};
    if(t2.oper == NULL)
        printf(""ERROR: Failed TF_GraphOperationByName linear/head/predictions/ExpandDims\n"");
    else	
	printf(""TF_GraphOperationByName linear/head/predictions/ExpandDims is OK\n"");
	
	TF_Output t3 = {TF_GraphOperationByName(Graph, ""head/predictions/str_classes""), 0};
    if(t3.oper == NULL)
        printf(""ERROR: Failed TF_GraphOperationByName head/predictions/str_classes\n"");
    else	
	printf(""TF_GraphOperationByName linear/head/predictions/str_classes is OK\n"");
	
    TF_Output t4 = {TF_GraphOperationByName(Graph, ""head/predictions/logistic""), 0};
    if(t4.oper == NULL)
        printf(""ERROR: Failed TF_GraphOperationByName linear/head/predictions/logistic\n"");
    else	
	printf(""TF_GraphOperationByName linear/head/predictions/logistic is OK\n"");
	
	TF_Output t5 = {TF_GraphOperationByName(Graph, ""linear/linear_model/linear/linear_model/linear/linear_model/weighted_sum""), 0};
    if(t5.oper == NULL)
        printf(""ERROR: Failed TF_GraphOperationByName linear/linear_model/weighted_sum\n"");
    else	
	printf(""TF_GraphOperationByName linear/linear_model/weighted_sum is OK\n"");
	
	TF_Output t6 = {TF_GraphOperationByName(Graph, ""head/predictions/probabilities""), 0};
    if(t6.oper == NULL)
        printf(""ERROR: Failed TF_GraphOperationByName linear/head/predictions/probabilities\n"");
    else	
	printf(""TF_GraphOperationByName linear/head/predictions/probabilities is OK\n"");
	
    Output[0] = t2;
	Output[1] = t3;
	Output[2] = t4;
	Output[3] = t5;
	Output[4] = t6;

    //********* Allocate data for inputs & outputs
    TF_Tensor** InputValues = (TF_Tensor**)malloc(sizeof(TF_Tensor*)*NumInputs);
    TF_Tensor** OutputValues = (TF_Tensor**)malloc(sizeof(TF_Tensor*)*NumOutputs);

    int ndims = 2;
    int64_t dims[] = {1,1};
    int64_t data1[] = {2};

    int ndata = sizeof(int64_t)*1 ;// This is tricky, it number of bytes not number of element

    TF_Tensor* int_tensor1 = TF_NewTensor(TF_FLOAT, dims, ndims, data1, ndata, &NoOpDeallocator, 0);
    if (int_tensor1 != NULL)
    {
        printf(""TF_NewTensor is OK for int_tensor1\n"");
    }
    else
	printf(""ERROR: Failed TF_NewTensor for int_tensor1\n"");
    
	int64_t data2[] = {3};
	TF_Tensor* int_tensor2 = TF_NewTensor(TF_FLOAT, dims, ndims, data2, ndata, &NoOpDeallocator, 0);
    if (int_tensor2 != NULL)
    {
        printf(""TF_NewTensor is OK for int_tensor2\n"");
    }
    else
	printf(""ERROR: Failed TF_NewTensor for int_tensor2\n"");
    InputValues[0] = int_tensor1;
	InputValues[1] = int_tensor2;
    
    // //Run the Session
    TF_SessionRun(Session, NULL, Input, InputValues, NumInputs, Output, OutputValues, NumOutputs, NULL, 0,NULL , Status);

    if(TF_GetCode(Status) == TF_OK)
    {
        printf(""Session is OK\n"");
    }
    else
    {
        printf(""%s"",TF_Message(Status));
    }

    // //Free memory
    TF_DeleteGraph(Graph);
    TF_DeleteSession(Session, Status);
    TF_DeleteSessionOptions(SessionOpts);
    TF_DeleteStatus(Status);


    void* buff = TF_TensorData(OutputValues[0]);
    float* offsets = buff;
    printf(""Result Tensor :\n"");
    printf(""%f\n"",offsets[0]);
    return 0; 
    
}


But it is crashing at Session run step, it would be really helpful if someone could identify where the issue is.

output obtained:
TF_LoadSessionFromSavedModel OK
TF_GraphOperationByName placeholder is OK
TF_GraphOperationByName placeholder_1 is OK
TF_GraphOperationByName linear/head/predictions/ExpandDims is OK
TF_GraphOperationByName linear/head/predictions/str_classes is OK
TF_GraphOperationByName linear/head/predictions/logistic is OK
TF_GraphOperationByName linear/linear_model/weighted_sum is OK
TF_GraphOperationByName linear/head/predictions/probabilities is OK
TF_NewTensor is OK for int_tensor1
TF_NewTensor is OK for int_tensor2
Segmentation fault (core dumped)

"
47042,Error when Building Tensorflow 2.4/2.4.1 for C++ with cuda support,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.4.0 / 2.4.1
- Python version: 3.8.6
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:11.0 /8.0.5.39
- GPU model and memory: Nvidia GTX 1070



**Describe the problem**

When building tenmsorflow for C++ with gpu support the build failed with the following error:
![grafik](https://user-images.githubusercontent.com/78606066/107390473-0730bb80-6af8-11eb-8454-3b651682eb16.png)


**Provide the exact sequence of commands / steps that you executed before running into the problem**

I first cloned the repository and switched to branch r2.4

after that i configured with configure.py.

![grafik](https://user-images.githubusercontent.com/78606066/107390779-537bfb80-6af8-11eb-8f62-bc4ca3d7b297.png)

then I started the build with bazel:

`bazel build --config=opt --config=cuda tensorflow:tensorflow.dll`

It ended up with the error above.

**Any other info / logs**


Building without cuda support works just fine

I dont know where the error is maybe its me maybe Tensorflow. I hope i can get some Help here. It would be great if the Tensorflow Site would have a proper instruction. I had to make a long journey to get to the point of where i am here with building. "
47041,TF 2.4.1 with python 3.8.7 (apple silicon with rosetta) terminated by SIGILL on import,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Big Sur 11.2
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8.7 (x86_64 through Rosetta)

**Describe the current behavior**
I am using a fish shell via Rosetta (`uname -m` gives me x86_64) and I could import TF without any problems.
After the 11.1 -> 11.2 Big Sur update, I can no longer import TensorFlow. I have no idea why.

**Describe the expected behavior**
no crash

**Standalone code to reproduce the issue**
just import tensorflow:

```bash
Python 3.8.7 (default, Feb  3 2021, 07:09:08)
[Clang 12.0.0 (clang-1200.0.32.29)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
fish: 'python' terminated by signal SIGILL (Illegal instruction)
```


"
47038,AttributeError: module 'tensorflow' has no attribute 'contrib' -->> alterative,"**I want alternative for the following code in TF2**

tf.contrib.cloud.configure_gcs(session, credentials=auth_info)


"
47037,shared_embeddings columns BUG: not updated when BP in Estimator which will cause lower metrics in model,"When using [share embedding column](https://www.tensorflow.org/api_docs/python/tf/feature_column/shared_embeddings) in premade Estimators, embedding table variables created in it will not be updated in training process.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Local run or distributed training have the same bug.
- TensorFlow installed from (source or binary):2.4.0
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:No cuda. 
- GPU model and memory:No GPU. CPU training.

**Describe the current behavior**

When using tf.feature_column.shared_embeddings in premade Estimator, embedding table variables create in it will not be included in traininng_variables. When I list all variables in checkpoint, Adagrad optimizer will not create any accumulator for shared embedding table variable which means  shared embedding table variable will not  be updated when BP. This bug will cause lower metrics such as AUC compared with old share embedding column in TF1.x with almost the same code.

**Describe the expected behavior**

 shared embedding table variable  should create accumulator in Adagrad or other optmizer.

The reason why this hadppen is that the way shared_embeddings column creates state is not like other feature column such as EmbeddingColumn which using tf.keras.layers.DenseFeatures._state_manager.create_variable, in create_variable function, it will use self._layer.add_weight so that variables can be included in keras.Model.trainable_variables. Finally I have to rewrite shared embedding column code using _state_manager and every thing will be OK.

**Standalone code to reproduce the issue**

```python

import tensorflow as tf
tf.compat.v1.disable_eager_execution()
import pandas as pd
import numpy as np
from tensorflow import feature_column

dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'
csv_file = 'datasets/petfinder-mini/petfinder-mini.csv'

tf.keras.utils.get_file('petfinder_mini.zip', dataset_url,
                        extract=True, cache_dir='.')
dataframe = pd.read_csv(csv_file)
dataframe['target'] = np.where(dataframe['AdoptionSpeed']==4, 0, 1)

# Drop un-used columns.
dataframe = dataframe.drop(columns=['AdoptionSpeed', 'Description'])

train = dataframe
train_y = dataframe.pop('target')

def input_fn(features, labels, training=True, batch_size=256):
    """"""An input function for training or evaluating""""""
    # Convert the inputs to a Dataset.
    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))

    # Shuffle and repeat if you are in training mode.
    if training:
        dataset = dataset.shuffle(1000).repeat()

    return dataset.batch(batch_size)

wide_columns = []
deep_columns = []
# numeric cols
for header in ['PhotoAmt', 'Fee', 'Age']:
  wide_columns.append(feature_column.numeric_column(header))

share_embedding_list = feature_column.shared_embeddings([feature_column.categorical_column_with_hash_bucket('Color1', 10), feature_column.categorical_column_with_hash_bucket('Color2', 10)], dimension=8)

deep_columns.extend(share_embedding_list)

classifier = tf.estimator.DNNLinearCombinedClassifier(
    model_dir='/tmp/model_test',
    linear_feature_columns=wide_columns,
    dnn_feature_columns=deep_columns,
    dnn_hidden_units=[30, 10])
# Train the Model.
classifier.train(
    input_fn=lambda: input_fn(train, train_y, training=True),
    steps=5000)
# Print all variables
save_path ='/tmp/model_test/model.ckpt-5000'
for var in tf.train.list_variables(save_path):
    print(var)

```

**Other info / logs** Include any logs or source code that would be helpful to

Output: 

**('Color1_Color2_shared_embedding', [10, 8])**
('dnn/hiddenlayer_0/bias', [30])
('dnn/hiddenlayer_0/kernel', [16, 30])
('dnn/hiddenlayer_1/bias', [10])
('dnn/hiddenlayer_1/kernel', [30, 10])
('dnn/logits/bias', [1])
('dnn/logits/kernel', [10, 1])
('global_step', [])
('linear/linear_model/Age/weights', [1, 1])
('linear/linear_model/Fee/weights', [1, 1])
('linear/linear_model/PhotoAmt/weights', [1, 1])
('linear/linear_model/bias_weights', [1])
('training/Adagrad/decay', [])
('training/Adagrad/dnn/hiddenlayer_0/bias/accumulator', [30])
('training/Adagrad/dnn/hiddenlayer_0/kernel/accumulator', [16, 30])
('training/Adagrad/dnn/hiddenlayer_1/bias/accumulator', [10])
('training/Adagrad/dnn/hiddenlayer_1/kernel/accumulator', [30, 10])
('training/Adagrad/dnn/logits/bias/accumulator', [1])
('training/Adagrad/dnn/logits/kernel/accumulator', [10, 1])
('training/Adagrad/learning_rate', [])
('training/Ftrl/beta', [])
('training/Ftrl/decay', [])
('training/Ftrl/iter', [])
('training/Ftrl/l1_regularization_strength', [])
('training/Ftrl/l2_regularization_strength', [])
('training/Ftrl/learning_rate', [])
('training/Ftrl/learning_rate_power', [])
('training/Ftrl/linear/linear_model/Age/weights/accumulator', [1, 1])
('training/Ftrl/linear/linear_model/Age/weights/linear', [1, 1])
('training/Ftrl/linear/linear_model/Fee/weights/accumulator', [1, 1])
('training/Ftrl/linear/linear_model/Fee/weights/linear', [1, 1])
('training/Ftrl/linear/linear_model/PhotoAmt/weights/accumulator', [1, 1])
('training/Ftrl/linear/linear_model/PhotoAmt/weights/linear', [1, 1])
('training/Ftrl/linear/linear_model/bias_weights/accumulator', [1])
('training/Ftrl/linear/linear_model/bias_weights/linear', [1])
"
47036,SIGSEGV - error when using large convolution - GPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04, Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): anaconda
- TensorFlow version (use command below): 2.2.0-rc3 and Colab Version
- Python version: 3.7 Colab
- CUDA/cuDNN version: 11.2, Colab
- GPU model and memory: 2080Ti, Colab


**Describe the expected behavior**

The script should generate a map of random values, smoothed with a Gauss filter. For the value sigma = 60 everything works fine, above this value the error ""Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)"" is returned. I got the same error on different workstations and also on colab. 

The problem only occurs when using the GPU.
**Standalone code to reproduce the issue**
```
import tensorflow as tf
from matplotlib import pyplot as plt

random_mask = tf.random.uniform((1, 400, 400, 1),
                                        minval=-1,
                                        maxval=1,
                                        dtype=tf.float32)

sigma = 61
sigmas_per_radius = 3
radius = tf.cast(sigma * sigmas_per_radius, tf.int32)

x = tf.cast(tf.range(-radius, radius + 1),dtype=tf.float32)

gauss_1d = tf.exp(-0.5 * tf.square(x / sigma))
gauss_1d = gauss_1d / tf.reduce_sum(gauss_1d)

kernel = tf.expand_dims(gauss_1d, 1) * gauss_1d
kernel = kernel[..., tf.newaxis, tf.newaxis]

point_wise_filter = tf.eye(1, batch_shape=[1, 1])

def_map = tf.nn.separable_conv2d(
    random_mask,
    kernel,
    point_wise_filter,
    strides=[1, 1, 1, 1],
    padding='SAME'
)

def_map = tf.squeeze(def_map)

plt.imshow(def_map.numpy())
plt.show()

```"
47035,Failing to Cross-Compile TensorFlow Lite C++ for Raspberry Pi,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.2 LTS
- TensorFlow installed from (source or binary): Attempting to build from source as per [here](https://www.tensorflow.org/lite/guide/build_rpi#cross-compile_for_raspberry_pi_with_make)
- TensorFlow version: TensorFlow Lite
- Python version: Python 3.8.5
- Installed using virtualenv? pip? conda?: No
- GCC/Compiler version (if compiling from source): 9.3.0


**Describe the problem**
Attempting to [cross-compile for Raspberry Pi with Make](https://www.tensorflow.org/lite/guide/build_rpi#cross-compile_for_raspberry_pi_with_make) for a Raspberry Pi 4. I tried building on my machine first, but that failed so I tried the Docker-based installation. This failed with the same error.

I haven't been able to find this in the issue tracker, appologies if I've missed something there. Many thanks in advance!

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Inside the Docker `tensorflow/tensorflow:devel` container:

```sh
# Step 1
git clone https://github.com/raspberrypi/tools.git rpi_tools

# Step 3 (step 2 skipped as per instructions)
cd tensorflow_src && ./tensorflow/lite/tools/make/download_dependencies.sh

# Step 4a
PATH=../rpi_tools/arm-bcm2708/arm-rpi-4.9.3-linux-gnueabihf/bin:$PATH \
  ./tensorflow/lite/tools/make/build_rpi_lib.sh
```

The final step failed with the log indicated below

**Any other info / logs**
It looks like the error might be:
```
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:17: error: 'is_trivially_copyable' is not a member of 'std'
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                 ^
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:57: error: expected primary-expression before '>' token
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                                                         ^
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:58: error: '::value' has not been declared
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
```
The full log (including the above extract) is:

<details>
<summary>Click here for full log</summary>

```
+ set -e
+++ dirname ./tensorflow/lite/tools/make/build_rpi_lib.sh
++ cd ./tensorflow/lite/tools/make
++ pwd
+ SCRIPT_DIR=/tensorflow_src/tensorflow/lite/tools/make
+ TENSORFLOW_DIR=/tensorflow_src/tensorflow/lite/tools/make/../../../..
++ free -m
++ awk '/^Mem/ {print $2}'
+ FREE_MEM=15803
+ [[ FREE_MEM -gt 2000 ]]
+ NO_JOB=4
+ make -j 4 TARGET=rpi -C /tensorflow_src/tensorflow/lite/tools/make/../../../.. -f tensorflow/lite/tools/make/Makefile
make: Entering directory '/tensorflow_src'
tensorflow/lite/tools/make/Makefile:358: warning: overriding recipe for target '/tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/lib/libtensorflow-lite.a'
tensorflow/lite/tools/make/Makefile:355: warning: ignoring old recipe for target '/tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/lib/libtensorflow-lite.a'
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/allocation.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/allocation.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/arena_planner.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/arena_planner.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/c/c_api.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/c/c_api.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/c/c_api_experimental.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/c/c_api_experimental.o
arm-linux-gnueabihf-gcc -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/c/common.c -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/c/common.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/core/api/error_reporter.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/core/api/error_reporter.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/core/api/flatbuffer_conversions.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/core/api/flatbuffer_conversions.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/core/api/op_resolver.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/core/api/op_resolver.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/core/api/tensor_utils.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/core/api/tensor_utils.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/core/subgraph.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/core/subgraph.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/create_op_resolver_with_builtin_ops.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/create_op_resolver_with_builtin_ops.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/delegates/interpreter_utils.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/delegates/interpreter_utils.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/experimental/resource/resource_variable.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/experimental/resource/resource_variable.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/experimental/resource/static_hashtable.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/experimental/resource/static_hashtable.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/external_cpu_backend_context.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/external_cpu_backend_context.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/graph_info.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/graph_info.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/interpreter.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/interpreter.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/interpreter_builder.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/interpreter_builder.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/kernels/activations.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/activations.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/kernels/add.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/add.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/kernels/add_n.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/add_n.o
In file included from ./tensorflow/lite/kernels/cpu_backend_gemm.h:23:0,
                 from ./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:45,
                 from tensorflow/lite/kernels/activations.cc:29:
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h: In static member function 'static void tflite::cpu_backend_gemm::detail::CustomGemvImpl<LhsScalar, RhsScalar, int, DstScalar, quantization_flavor>::Run(const tflite::cpu_backend_gemm::MatrixParams<LhsScalar>&, const LhsScalar*, const tflite::cpu_backend_gemm::MatrixParams<RhsScalar>&, const RhsScalar*, const tflite::cpu_backend_gemm::MatrixParams<DstScalar>&, DstScalar*, const tflite::cpu_backend_gemm::GemmParams<int, DstScalar, quantization_flavor>&, int, int)':
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:490:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:493:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:496:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:499:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:502:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:505:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
In file included from /tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/frontend.h:30:0,
                 from /tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/ruy.h:23,
                 from ./tensorflow/lite/kernels/cpu_backend_gemm_ruy.h:21,
                 from ./tensorflow/lite/kernels/cpu_backend_gemm.h:25,
                 from ./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:45,
                 from tensorflow/lite/kernels/activations.cc:29:
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h: In function 'void ruy::detail::FinalizeMulParams(const ruy::MulParams<AccumScalar, DstScalar>&, ruy::ChannelDimension, ruy::Ctx*, ruy::TrMulParams*)':
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:17: error: 'is_trivially_copyable' is not a member of 'std'
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                 ^
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:57: error: expected primary-expression before '>' token
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                                                         ^
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:58: error: '::value' has not been declared
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                                                          ^
In file included from ./tensorflow/lite/kernels/cpu_backend_gemm.h:23:0,
                 from ./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:45,
                 from ./tensorflow/lite/kernels/internal/optimized/integer_ops/add.h:26,
                 from tensorflow/lite/kernels/add.cc:15:
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h: In static member function 'static void tflite::cpu_backend_gemm::detail::CustomGemvImpl<LhsScalar, RhsScalar, int, DstScalar, quantization_flavor>::Run(const tflite::cpu_backend_gemm::MatrixParams<LhsScalar>&, const LhsScalar*, const tflite::cpu_backend_gemm::MatrixParams<RhsScalar>&, const RhsScalar*, const tflite::cpu_backend_gemm::MatrixParams<DstScalar>&, DstScalar*, const tflite::cpu_backend_gemm::GemmParams<int, DstScalar, quantization_flavor>&, int, int)':
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:490:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:493:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:496:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:499:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:502:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:505:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
In file included from /tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/frontend.h:30:0,
                 from /tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/ruy.h:23,
                 from ./tensorflow/lite/kernels/cpu_backend_gemm_ruy.h:21,
                 from ./tensorflow/lite/kernels/cpu_backend_gemm.h:25,
                 from ./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:45,
                 from ./tensorflow/lite/kernels/internal/optimized/integer_ops/add.h:26,
                 from tensorflow/lite/kernels/add.cc:15:
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h: In function 'void ruy::detail::FinalizeMulParams(const ruy::MulParams<AccumScalar, DstScalar>&, ruy::ChannelDimension, ruy::Ctx*, ruy::TrMulParams*)':
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:17: error: 'is_trivially_copyable' is not a member of 'std'
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                 ^
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:57: error: expected primary-expression before '>' token
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                                                         ^
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:58: error: '::value' has not been declared
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                                                          ^
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/kernels/arg_min_max.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/arg_min_max.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/kernels/assign_variable.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/assign_variable.o
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/../../../../../../ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/tensorflow_src/tensorflow/lite/tools/make/downloads/eigen -I/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/tensorflow_src/tensorflow/lite/tools/make/downloads/gemmlowp -I/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/tensorflow_src/tensorflow/lite/tools/make/downloads/neon_2_sse -I/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/kernels/audio_spectrogram.cc -o /tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/audio_spectrogram.o
In file included from ./tensorflow/lite/kernels/cpu_backend_gemm.h:23:0,
                 from ./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:45,
                 from tensorflow/lite/kernels/arg_min_max.cc:23:
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h: In static member function 'static void tflite::cpu_backend_gemm::detail::CustomGemvImpl<LhsScalar, RhsScalar, int, DstScalar, quantization_flavor>::Run(const tflite::cpu_backend_gemm::MatrixParams<LhsScalar>&, const LhsScalar*, const tflite::cpu_backend_gemm::MatrixParams<RhsScalar>&, const RhsScalar*, const tflite::cpu_backend_gemm::MatrixParams<DstScalar>&, DstScalar*, const tflite::cpu_backend_gemm::GemmParams<int, DstScalar, quantization_flavor>&, int, int)':
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:490:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:493:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:496:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:499:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:502:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:505:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
In file included from /tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/frontend.h:30:0,
                 from /tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/ruy.h:23,
                 from ./tensorflow/lite/kernels/cpu_backend_gemm_ruy.h:21,
                 from ./tensorflow/lite/kernels/cpu_backend_gemm.h:25,
                 from ./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:45,
                 from tensorflow/lite/kernels/arg_min_max.cc:23:
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h: In function 'void ruy::detail::FinalizeMulParams(const ruy::MulParams<AccumScalar, DstScalar>&, ruy::ChannelDimension, ruy::Ctx*, ruy::TrMulParams*)':
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:17: error: 'is_trivially_copyable' is not a member of 'std'
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                 ^
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:57: error: expected primary-expression before '>' token
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                                                         ^
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:58: error: '::value' has not been declared
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                                                          ^
In file included from ./tensorflow/lite/kernels/cpu_backend_gemm.h:23:0,
                 from ./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:45,
                 from tensorflow/lite/kernels/audio_spectrogram.cc:24:
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h: In static member function 'static void tflite::cpu_backend_gemm::detail::CustomGemvImpl<LhsScalar, RhsScalar, int, DstScalar, quantization_flavor>::Run(const tflite::cpu_backend_gemm::MatrixParams<LhsScalar>&, const LhsScalar*, const tflite::cpu_backend_gemm::MatrixParams<RhsScalar>&, const RhsScalar*, const tflite::cpu_backend_gemm::MatrixParams<DstScalar>&, DstScalar*, const tflite::cpu_backend_gemm::GemmParams<int, DstScalar, quantization_flavor>&, int, int)':
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:490:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:493:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:496:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:499:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:502:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:505:13: warning: attributes at the beginning of statement are ignored [-Wattributes]
             [[clang::fallthrough]];
             ^
In file included from /tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/frontend.h:30:0,
                 from /tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/ruy.h:23,
                 from ./tensorflow/lite/kernels/cpu_backend_gemm_ruy.h:21,
                 from ./tensorflow/lite/kernels/cpu_backend_gemm.h:25,
                 from ./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:45,
                 from tensorflow/lite/kernels/audio_spectrogram.cc:24:
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h: In function 'void ruy::detail::FinalizeMulParams(const ruy::MulParams<AccumScalar, DstScalar>&, ruy::ChannelDimension, ruy::Ctx*, ruy::TrMulParams*)':
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:17: error: 'is_trivially_copyable' is not a member of 'std'
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                 ^
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:57: error: expected primary-expression before '>' token
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                                                         ^
/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy/ruy/create_trmul_params.h:388:58: error: '::value' has not been declared
   static_assert(std::is_trivially_copyable<MulParamsType>::value, """");
                                                          ^
tensorflow/lite/tools/make/Makefile:334: recipe for target '/tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/add.o' failed
make: *** [/tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/add.o] Error 1
make: *** Waiting for unfinished jobs....
tensorflow/lite/tools/make/Makefile:334: recipe for target '/tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/activations.o' failed
make: *** [/tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/activations.o] Error 1
tensorflow/lite/tools/make/Makefile:334: recipe for target '/tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/arg_min_max.o' failed
make: *** [/tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/arg_min_max.o] Error 1
tensorflow/lite/tools/make/Makefile:334: recipe for target '/tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/audio_spectrogram.o' failed
make: *** [/tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/audio_spectrogram.o] Error 1
make: Leaving directory '/tensorflow_src'
```
</details>"
47034,Conv2D feeding into LSTM breaks model for inference,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.0
- Python version: 3.8


**Describe the current behavior**

Having a `Conv2D` layer with a `filter_size=(1, F)`, where `F` is the number of features, delivers inconsistent results while feeding a chunked stream to a model.

I identified this `Conv2D` layer as the breaking-point in my model for speech-recognition. The model works fine _without_ the `Conv2D` layer using chunking and non-chunking. However, if `Conv2D` is present, chunking is not working anymore.

**Describe the expected behavior**

The error between the chunked and non-chunked model output should _always_ be exactly `0.0` or at least *very* close.

**Standalone code to reproduce the issue**

The code below generates plot, as shown below, to illustrate the (potential) issue.

Essentially, it generates a toy-model which feeds inputs, taking the form `(batch, time, features, channels)` into the `Conv2D` layer and project this down to `(batch, time, 1, filters)`. Note the `tf.concat` before the `Conv2D` layer which artificially creates this input in the example. 

After the convolution we just drop the third axis and feed the result into the LSTM layers.

```python
import string

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers


def get_model(
    vocab_size: int,
    embedding_size: int,
    hidden_size: int,
    conv2d_kwargs: dict = None
):
    inputs = layers.Input(shape=(None,), dtype=tf.int32)

    embedding = layers.Embedding(
        vocab_size + 1,
        embedding_size,
        mask_zero=True
    )
    x = embedding(inputs)

    if conv2d_kwargs is not None:
        x = layers.Lambda(lambda l: tf.expand_dims(l, axis=-1))(x)
        x = layers.Lambda(lambda t: tf.concat([t, t, t], axis=-1))(x)
        x = layers.Conv2D(**conv2d_kwargs)(x)
        x = layers.Lambda(lambda l: tf.squeeze(l, axis=2))(x)

    lstm_out = layers.LSTM(hidden_size, return_sequences=True, return_state=True)(x)
    x = lstm_out[0]
    lstm_out = layers.LSTM(hidden_size, return_sequences=False, return_state=True)(x)
    x = lstm_out[0]
    outputs = layers.Dense(vocab_size, activation='softmax')(x)
    return keras.Model(inputs=inputs, outputs=outputs)


def infer(model, inputs, state=None):
    x = inputs
    new_states = list()

    # We're just interested in the output of the Conv2D layer and the succeeding LSTM-layer
    layers_of_interest = model.layers[:-2]

    for layer in layers_of_interest:
        if isinstance(layer, layers.LSTM):
            idx = len(new_states)
            outputs = layer(x, initial_state=state[idx] if state is not None else None)
            x, new_state = outputs[0], outputs[1:]
            new_states.append(new_state)
        else:
            x = layer(x)

    return x, new_states


def eval_plot(model, sample_text: str, char2idx: dict, chunk_size: int):

    enc_chunks = list()
    state_trained = None
    nb_chunks = int(np.ceil(len(sample_text) / chunk_size))
    for i in range(nb_chunks):
        s = i * chunk_size
        e = s + chunk_size
        text_chunk = sample_text[s:e]
        test_inputs = list(map(lambda c: char2idx[c], text_chunk))
        test_inputs = tf.constant([test_inputs], dtype=tf.int32)
        encoded, state_trained = infer(model, test_inputs, state=state_trained)
        enc_chunks.append(encoded)

    test_inputs = list(map(lambda c: char2idx[c], sample_text))
    test_inputs = tf.constant([test_inputs], dtype=tf.int32)
    enc_full, _ = infer(model, test_inputs)
    enc_full = enc_full.numpy()[0]

    chunks_concat = tf.concat(enc_chunks, axis=1).numpy()[0]
    diff = chunks_concat - enc_full
    rmspe = (np.sqrt(np.mean(np.square(diff / enc_full)))) * 100
    import matplotlib.pyplot as plt
    fix, axes = plt.subplots(1, 3, figsize=(16, 9), sharex='all', sharey='all')
    ax1, ax2, ax3 = axes
    ax1.matshow(chunks_concat.T)
    ax1.set_title('Chunked')
    ax2.matshow(enc_full.T)
    ax2.set_title('Full')
    ax3.matshow(diff.T)
    ax3.set_title(f'Diff (RMSPE: {rmspe:.8f})')
    for ax in axes:
        ax.set_xlabel('Time [T]')
    ax1.set_ylabel('Features [F]')
    plt.tight_layout()
    plt.show()
    return rmspe


def main():

    vocab = set(' ' + string.ascii_lowercase)
    vocab_size = len(vocab)
    idx2char = {(idx + 1): char for idx, char in enumerate(vocab)}
    char2idx = {char: idx for idx, char in idx2char.items()}

    units = 32
    embedding_size = 16
    filters = units * 2

    model_conv_params = dict(
        vocab_size=vocab_size,
        embedding_size=embedding_size,
        hidden_size=units,
        conv2d_kwargs=dict(filters=filters, kernel_size=(1, embedding_size), use_bias=False)
    )

    model_conv = get_model(**model_conv_params)

    sample_text = 'how are you buddy'

    for chunk_size in range(1, 11):
        print(f'Creating plots for chunk size {chunk_size}')
        rmspe = eval_plot(model_conv, sample_text, char2idx, chunk_size)
        print(f'  RMSPE: {rmspe:.4f}')

    print('All done')


if __name__ == '__main__':
    main()

```

### Toy-example plots

![image](https://user-images.githubusercontent.com/43335432/107357656-a93dad00-6ad2-11eb-9e15-5ce79c3a7f21.png)

![image](https://user-images.githubusercontent.com/43335432/107357740-bfe40400-6ad2-11eb-9897-a350652e3ba4.png)

### ""Real"" Model Plots

The following are plots from a speech recognition model which uses this simple `Conv2D` operation before it is send into LSTM layers. One plot is after 1000 steps of training, the other after 200. As you can see, **the MSE, computed for each frame in the last image, increases over time** (note the y-axis range). This model is ""broken"" **using chunking** and does not produce any meaningful output anymore after training it until early stopping. It does work *without* chunking though.

![image](https://user-images.githubusercontent.com/43335432/107615058-c9dd4280-6c4b-11eb-9b7b-2cf8169cfbf2.png)

![image](https://user-images.githubusercontent.com/43335432/107615064-ce096000-6c4b-11eb-8da7-519df0e33219.png)

On the other hand, using the same model but removing the `Conv2D` layer gives an MSE for each frame somewhere below `6e-14` which is (basically) zero:

![image](https://user-images.githubusercontent.com/43335432/107615288-293b5280-6c4c-11eb-837e-857c6773efb2.png)



"
47033,gradient computation fails in graph mode with numpy_function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary (conda-forge)
- TensorFlow version (use command below): 'v2.3.0-rc2-23-gb36436b087', 'v2.4.0-49-g85c8b2a817f'
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: Titan RTX 24GB

**Describe the current behavior**

I'm trying to use a function implemented in cython in a loss function. The (int64) output of this function is used as index for tf.gather. When computing the loss in eager execution mode gradients are computed fine, but when run in graph mode, an exception is raised.

**Describe the expected behavior**

I would expect the same result in graph execution mode.

**Standalone code to reproduce the issue**

A tiny sample where the cython function simply implements argmin:

```
import tensorflow as tf
import numpy as np
import assign

model = tf.keras.applications.ResNet50(False, weights=None, input_shape=(224, 224, 3))
data = tf.random.normal((8,224,224,3), 128, 64)

def f(x):
	y = model(x)
	idx = tf.numpy_function(assign.assign_objects_to_cells, (-y,), np.int64)
	#idx = tf.argmin(-y, -1)
	#idx = tf.numpy_function(np.argmin, (-y, -1), np.int64)
	values = tf.gather(y, idx, batch_dims=3)
	return tf.reduce_sum(values)


def grad(x):
	with tf.GradientTape() as tape:
		y = f(x)
	return tape.gradient(y, model.trainable_variables)
tf_grad = tf.function(grad)

print('eager execution')
g = grad(data)
print('graph execution')
g = tf_grad(data)
```

And the **assign.pyx**:

```
import numpy as np
cimport numpy as np
cimport cython

@cython.boundscheck(False) # turn off bounds-checking for entire function
@cython.wraparound(False)  # turn off negative index wrapping for entire function
cdef void _assign_objects_to_cells(float[:,:,:,:] error, np.int64_t[:,:,:] argmax) nogil:
	cdef int N = error.shape[0], H = error.shape[1], W = error.shape[2], C = error.shape[3]
	cdef int y, x, c, best_id
	cdef float best, e
	
	for n in range(N):
		for y in range(H):
			for x in range(W):
				best_id = 0
				best = error[n,y,x,0]
				for c in range(1, C):
					e = error[n,y,x,c]
					if e<best:
						best = e
						best_id = c
				argmax[n,y,x] = best_id

def assign_objects_to_cells(np.ndarray[np.float32_t, ndim=4] error not None):
	cdef int N = error.shape[0], H = error.shape[1], W = error.shape[2], C = error.shape[3]
	out = np.empty((N,H,W), np.int64)
	_assign_objects_to_cells(error, out)
	
	return out
```

**Other info / logs** 

Eager execution runs fine, but graph execution fails:

```
eager execution
graph execution
Traceback (most recent call last):

  File ""<ipython-input-1-eafa53e19dc9>"", line 25, in <module>
    g = tf_grad(data)

  File ""d:\conda\envs\tf2\lib\site-packages\tensorflow\python\eager\def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)

  File ""d:\conda\envs\tf2\lib\site-packages\tensorflow\python\eager\def_function.py"", line 823, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)

  File ""d:\conda\envs\tf2\lib\site-packages\tensorflow\python\eager\def_function.py"", line 697, in _initialize
    *args, **kwds))

  File ""d:\conda\envs\tf2\lib\site-packages\tensorflow\python\eager\function.py"", line 2855, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)

  File ""d:\conda\envs\tf2\lib\site-packages\tensorflow\python\eager\function.py"", line 3213, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)

  File ""d:\conda\envs\tf2\lib\site-packages\tensorflow\python\eager\function.py"", line 3075, in _create_graph_function
    capture_by_value=self._capture_by_value),

  File ""d:\conda\envs\tf2\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 986, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)

  File ""d:\conda\envs\tf2\lib\site-packages\tensorflow\python\eager\def_function.py"", line 600, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)

  File ""d:\conda\envs\tf2\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 973, in wrapper
    raise e.ag_error_metadata.to_exception(e)

TypeError: in user code:

    <ipython-input-1-eafa53e19dc9>:19 grad  *
        return tape.gradient(y, model.trainable_variables)
    d:\conda\envs\tf2\lib\site-packages\tensorflow\python\eager\backprop.py:1073 gradient  **
        unconnected_gradients=unconnected_gradients)
    d:\conda\envs\tf2\lib\site-packages\tensorflow\python\eager\imperative_grad.py:77 imperative_grad
        compat.as_str(unconnected_gradients.value))
    d:\conda\envs\tf2\lib\site-packages\tensorflow\python\eager\backprop.py:162 _gradient_function
        return grad_fn(mock_op, *out_grads)
    d:\conda\envs\tf2\lib\site-packages\tensorflow\python\ops\array_grad.py:678 _GatherV2Grad
        batch_dims, params_shape[axis])
    d:\conda\envs\tf2\lib\site-packages\tensorflow\python\ops\array_grad.py:603 _BatchGatherGrad
        indices = _GetBatchIndices(params_shape, indices, batch_dims)
    d:\conda\envs\tf2\lib\site-packages\tensorflow\python\ops\array_grad.py:582 _GetBatchIndices
        [1] * (dim - 1) + [dim_value] + [1] * (indices_ndims - dim), axis=0)

    TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'
```

Note, that both eager and graph modes work if I replace tf.numpy_function with tf.argmin and the results are the same (up to rounding errors). Graph execution also fails when using np.argmin.
"
47032,Setting class_weight in model.fit() with tf.data.Dataset causes error,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04  / Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0 / 2.4.1
- Python version: 3.6 / 3.7
- CUDA/cuDNN version: 10.1 / none
- GPU model and memory: RTX2080 / none

**Describe the current behavior**
When a tf.data.Dataset is used in model.fit(), setting class_weight causes an error.

**Describe the expected behavior**
No error occurs.

**Standalone code to reproduce the issue**
```
from tensorflow import keras
import tensorflow as tf
import numpy as np


def get_model():
    inputs = keras.layers.Input(shape=(10, 10, 3))
    x = keras.layers.Flatten()(inputs)
    outputs = keras.layers.Dense(5)(x)
    model = keras.Model(inputs, outputs)
    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))
    return model


def map_fun(_):
    dummy_image = np.zeros((10, 10, 3))  
    dummy_label = np.array([0, 0, 1, 0, 0]) 
    return dummy_image, dummy_label


if __name__ == '__main__':
    # dummy dataset
    dataset = tf.data.Dataset.from_tensor_slices([1, 2])  # values are ignored, dummy data generated in map()
    dataset = dataset.map(map_func=lambda x: tf.py_function(map_fun, [x], [tf.uint8, tf.uint8])).batch(2)

    # dummy model
    model = get_model()

    # call fit() without class weights - ok
    model.fit(dataset, epochs=1)

    # define class weights
    class_weight = {idx: weight for (idx, weight) in enumerate([1., 1., 1., 1., 1.])}

    # transform dataset to iterator, call fit() with class weights - ok
    model.fit(dataset.as_numpy_iterator(), class_weight=class_weight, epochs=1)

    # call fit() with class weights on tf.data.Dataset - error
    model.fit(dataset, class_weight=class_weight, epochs=1)
```

**Error message**
```
Traceback (most recent call last):
  File ""/data/sandbox/reproduce.py"", line 39, in <module>
    model.fit(dataset, class_weight=class_weight, epochs=1)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1063, in fit
    steps_per_execution=self._steps_per_execution)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py"", line 1122, in __init__
    dataset = dataset.map(_make_class_weight_map_fn(class_weight))
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1695, in map
    return MapDataset(self, map_func, preserve_cardinality=True)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 4045, in __init__
    use_legacy_function=use_legacy_function)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3371, in __init__
    self._function = wrapper_fn.get_concrete_function()
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2939, in get_concrete_function
    *args, **kwargs)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2906, in _get_concrete_function_garbage_collected
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3213, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3075, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 986, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3364, in wrapper_fn
    ret = _wrapper_helper(*args)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3299, in _wrapper_helper
    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 255, in wrapper
    return converted_call(f, args, kwargs, options=options)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 532, in converted_call
    return _call_unconverted(f, args, kwargs, options)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 339, in _call_unconverted
    return f(*args, **kwargs)
  File ""/data/sandbox/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py"", line 1314, in _class_weights_map_fn
    if y.shape.rank > 2:
TypeError: '>' not supported between instances of 'NoneType' and 'int'

Process finished with exit code 1
```"
47029,INFO:tensorflow:Saver not created because there are no variables in the graph to restore,"I am using
bert-tensorflow==1.0.1
tensorflow version = 2.4.1
keras - 2.4.3

Code
BERT_MODEL_HUB = ""https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1""

def create_tokenizer_from_hub_module():
""""""Get the vocab file and casing info from the Hub module.""""""
with tf.Graph().as_default():
bert_module = hub.Module(BERT_MODEL_HUB)
tokenization_info = bert_module(signature=""tokenization_info"", as_dict=True)
with tf.Session() as sess:
vocab_file, do_lower_case = sess.run([tokenization_info[""vocab_file""],
tokenization_info[""do_lower_case""]])

return bert.tokenization.FullTokenizer(
vocab_file=vocab_file, do_lower_case=do_lower_case)

tokenizer = create_tokenizer_from_hub_module()

After running above cell in Colab I'm getting the following msg

INFO:tensorflow:Saver not created because there are no variables in the graph to restore
INFO:tensorflow:Saver not created because there are no variables in the graph to restore"
47028,unable to run tensorflow - error ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
47027,post_training_integer_quantization issue,"I used a simple transfer learning code on my windows computer, downloading the cat-dog dataset.
The transfer learning and conversion to TFLite sections are OK, but I can't convert the input to int8 from float 32 following TF guidline.

**My Code;**
https://colab.research.google.com/drive/1hlTykr4-rUYqI-n10icVEywxUhyar364

**The Guide to do the conversion;**
https://www.tensorflow.org/lite/performance/post_training_integer_quant

**Issue**; ValueError: Unbatching a dataset is only supported for rank >= 1

Thanks in advance for your help,
MoZen
"
47026,"TPU, model.fit : 2GB of RAM limit. tf.version 2.4","**Describe the current behavior**

There is an error (""""Session crashed for unknown reason""""), when trying to use a dataset with the size more than 2GB of RAM.
Error is reproducible for different step size (256,1024,8192).

**Describe the expected behavior**

No error when feeding a dataset which is more than 2GB of RAM.

**Code to reproduce the issue**

To reproduce, just copy the following code to Colab with TPU enabled.

The bug can happen due to 2GB limit in protobuf (since tensorflow relies on it).
https://stackoverflow.com/questions/34128872/google-protobuf-maximum-size

```
import tensorflow as tf
import numpy as np

import distutils
if distutils.version.LooseVersion(tf.__version__) < '1.14':
    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')

import os

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
# This is the TPU initialization code that has to be at the beginning.
tf.tpu.experimental.initialize_tpu_system(resolver)
print(""All devices: "", tf.config.list_logical_devices('TPU'))

# optimizer = tf.tpu.CrossShardOptimizer(tf.train.GradientDescentOptimizer(0.01))

strategy = tf.distribute.TPUStrategy(resolver)

with strategy.scope():
  model = tf.keras.applications.VGG16(input_shape=(32,32,3),classes=10, weights=None)#  create_model()
  optimizer = tf.keras.optimizers.Adam()
  model.compile(
      optimizer=optimizer,
      loss='mse',
      metrics=['mse'])
  
  training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)
  training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
      'training_accuracy', dtype=tf.float32)


# 1024*192 * 32*32*3 * 4bytes = 2 415 919 104 bytes
# ~ 2GB. ""Session crashed for unknown reason""
X = np.zeros((1024*192, 32,32,3),dtype=np.float32)
y = np.ones((1024*192, 10),dtype=np.float32)

# ~ 1GB. Works
# X = np.zeros((1024*192//2, 32,32,3),dtype=np.float32)
# y = np.ones((1024*192//2, 10),dtype=np.float32)

model.fit(
    X,y,
    epochs=10,
    steps_per_epoch=1024, #batch size is 192 per TPU
)
```
```
print(tf.version.VERSION)
print(tf.version.GIT_VERSION)
2.4.1
v2.4.1-0-g85c8b2a817f
```

**Logs**
![106828116-a4958500-66dd-11eb-9ae6-06606e561bc4](https://user-images.githubusercontent.com/27484172/107322586-d735e800-6af8-11eb-9be7-5035a2bda197.png)"
47024,"Issue in converting input output from float 32 to int8(Convert using float fallback quantization),","Hi There, I have an issue in converting a model with float 32 input to int 8;
My code; https://colab.research.google.com/drive/1EGMqQlos_NovF3qakNVo0PLgvvZukLtB#scrollTo=TqOt6Sv7AsMi

Details:
I used standard transfer learning code;
https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb

 just instead of loading data from the website, I loaded data folders from my computer (instead of cat I wanna detect an invasive beetle!), then I  tried to convert the input of the model from float 32 to int 8 using the link below guideline;
https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb#scrollTo=FiwiWU3gHdkW

Specifically this cell from abovementioned quantization guidline generates the following issue;
def representative_data_gen():
  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):
    # Model has only one input so each data point has one element.
    yield [input_value]

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen

tflite_model_quant = converter.convert()

 I get the following issue;  ValueError: Unbatching a dataset is only supported for rank >= 1


-----------------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-167-9f553cafd0bd> in <module>
      8 converter.representative_dataset = representative_data_gen
      9 
---> 10 tflite_model_quant = converter.convert()

C:\ProgramData\Anaconda3\envs\TF2\lib\site-packages\tensorflow\lite\python\lite.py in convert(self)
    871           graph=frozen_func.graph)
    872 
--> 873     return super(TFLiteKerasModelConverterV2,
    874                  self).convert(graph_def, input_tensors, output_tensors)
    875 

C:\ProgramData\Anaconda3\envs\TF2\lib\site-packages\tensorflow\lite\python\lite.py in convert(self, graph_def, input_tensors, output_tensors)
    630     calibrate_and_quantize, flags = quant_mode.quantizer_flags()
    631     if calibrate_and_quantize:
--> 632       result = self._calibrate_quantize_model(result, **flags)
    633 
    634     flags_modify_model_io_type = quant_mode.flags_modify_model_io_type(

C:\ProgramData\Anaconda3\envs\TF2\lib\site-packages\tensorflow\lite\python\lite.py in _calibrate_quantize_model(self, result, inference_input_type, inference_output_type, activations_type, allow_float)
    457       return _mlir_quantize(calibrated)
    458     else:
--> 459       return calibrate_quantize.calibrate_and_quantize(
    460           self.representative_dataset.input_gen, inference_input_type,
    461           inference_output_type, allow_float, activations_type)

C:\ProgramData\Anaconda3\envs\TF2\lib\site-packages\tensorflow\lite\python\optimize\calibrator.py in calibrate_and_quantize(self, dataset_gen, input_type, output_type, allow_float, activations_type, resize_input)
     91     """"""
     92     initialized = False
---> 93     for sample in dataset_gen():
     94       if not initialized:
     95         initialized = True

<ipython-input-167-9f553cafd0bd> in representative_data_gen()
      1 def representative_data_gen():
----> 2   for input_value in tf.data.Dataset.from_tensor_slices(train_dataset).batch(1).take(20):
      3     # Model has only one input so each data point has one element.
      4     yield [input_value]
      5 

C:\ProgramData\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py in from_tensor_slices(tensors)
    689       Dataset: A `Dataset`.
    690     """"""
--> 691     return TensorSliceDataset(tensors)
    692 
    693   class _GeneratorState(object):

C:\ProgramData\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py in __init__(self, element)
   3155     element = structure.normalize_element(element)
   3156     batched_spec = structure.type_spec_from_value(element)
-> 3157     self._tensors = structure.to_batched_tensor_list(batched_spec, element)
   3158     self._structure = nest.map_structure(
   3159         lambda component_spec: component_spec._unbatch(), batched_spec)  # pylint: disable=protected-access

C:\ProgramData\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\data\util\structure.py in to_batched_tensor_list(element_spec, element)
    362   # pylint: disable=protected-access
    363   # pylint: disable=g-long-lambda
--> 364   return _to_tensor_list_helper(
    365       lambda state, spec, component: state + spec._to_batched_tensor_list(
    366           component), element_spec, element)

C:\ProgramData\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\data\util\structure.py in _to_tensor_list_helper(encode_fn, element_spec, element)
    337     return encode_fn(state, spec, component)
    338 
--> 339   return functools.reduce(
    340       reduce_fn, zip(nest.flatten(element_spec), nest.flatten(element)), [])
    341 

C:\ProgramData\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\data\util\structure.py in reduce_fn(state, value)
    335   def reduce_fn(state, value):
    336     spec, component = value
--> 337     return encode_fn(state, spec, component)
    338 
    339   return functools.reduce(

C:\ProgramData\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\data\util\structure.py in <lambda>(state, spec, component)
    363   # pylint: disable=g-long-lambda
    364   return _to_tensor_list_helper(
--> 365       lambda state, spec, component: state + spec._to_batched_tensor_list(
    366           component), element_spec, element)
    367 

C:\ProgramData\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py in _to_batched_tensor_list(self, value)
   3322   def _to_batched_tensor_list(self, value):
   3323     if self._dataset_shape.ndims == 0:
-> 3324       raise ValueError(""Unbatching a dataset is only supported for rank >= 1"")
   3325     return self._to_tensor_list(value)
   3326 

ValueError: Unbatching a dataset is only supported for rank >= 1
--------------------------------------"
47023,C++ compilation of rule '//tensorflow/core/kernels/image:extract_image_patches_op' failed,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): tensorflow-2.4.0.tar.gz
- TensorFlow version: 2.4.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 7.3.0
- CUDA/cuDNN version: no
- GPU model and memory: no

**Describe the problem**
[root@tf-build-asr tensorflow-2.4.0]# bazel build -c opt  //tensorflow:libtensorflow_cc.so
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=236
INFO: Reading rc options for 'build' from /opt/swan/tensorflow-2.4.0/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /opt/swan/tensorflow-2.4.0/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /opt/swan/tensorflow-2.4.0/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/python3/lib/python3.7/site-packages --python_path=/usr/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /opt/swan/tensorflow-2.4.0/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /opt/swan/tensorflow-2.4.0/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /opt/swan/tensorflow-2.4.0/.bazelrc: --define=with_xla_support=true
INFO: Found applicable config definition build:linux in file /opt/swan/tensorflow-2.4.0/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /opt/swan/tensorflow-2.4.0/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Analyzed target //tensorflow:libtensorflow_cc.so (0 packages loaded, 9 targets configured).
INFO: Found 1 target...
ERROR: /opt/swan/tensorflow-2.4.0/tensorflow/core/kernels/image/BUILD:229:18: C++ compilation of rule '//tensorflow/core/kernels/image:extract_image_patches_op' failed (Exit 1): gcc failed: error executing command /usr/local/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 142 argument(s) skipped)
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:117:0,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/kernels/image/extract_image_patches_op.h:19,
                 from tensorflow/core/kernels/image/extract_image_patches_op.cc:21:
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorImagePatch.h: In static member function 'static void Eigen::internal::EvalRange<Evaluator, StorageIndex, true>::run(Evaluator*, StorageIndex, StorageIndex) [with Evaluator = Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 4, 1, int>, 16, Eigen::MakePointer>, const Eigen::TensorReshapingOp<const Eigen::DSizes<int, 4>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 4, 1, int>, 16, Eigen::MakePointer> > > >, Eigen::ThreadPoolDevice>; StorageIndex = int]':
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorImagePatch.h:546:7: internal compiler error: in emit_move_insn, at expr.c:3698
       values[i] = coeff(index+i);
       ^~~~~~
0x899fba emit_move_insn(rtx_def*, rtx_def*)
	../.././gcc/expr.c:3697
0x88a34d store_bit_field_1
	../.././gcc/expmed.c:814
0x88a9b8 store_bit_field(rtx_def*, unsigned long, unsigned long, unsigned long, unsigned long, machine_mode, rtx_def*, bool)
	../.././gcc/expmed.c:1122
0x8a4a1e store_field
	../.././gcc/expr.c:6974
0x8a204b expand_assignment(tree_node*, tree_node*, bool)
	../.././gcc/expr.c:5209
0x7b3c01 expand_call_stmt
	../.././gcc/cfgexpand.c:2656
0x7b3c01 expand_gimple_stmt_1
	../.././gcc/cfgexpand.c:3571
0x7b3c01 expand_gimple_stmt
	../.././gcc/cfgexpand.c:3737
0x7b4ddf expand_gimple_basic_block
	../.././gcc/cfgexpand.c:5744
0x7b9f46 execute
	../.././gcc/cfgexpand.c:6357
Please submit a full bug report,
with preprocessed source if appropriate.
Please include the complete backtrace with any bug report.
See <https://gcc.gnu.org/bugs/> for instructions.
Target //tensorflow:libtensorflow_cc.so failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 931.265s, Critical Path: 45.73s
INFO: 945 processes: 6 internal, 939 local.
FAILED: Build did NOT complete successfully

**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel build -c opt  //tensorflow:libtensorflow_cc.so

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
47022,tf.strings.split cannot handle some characters,"**System information**
- OS Platform: Windows 10
- TensorFlow version: 2.3.2
- Python version: 3.8.5

**Issue**
This code:
````
print(tf.strings.split(tf.constant([""abc Ã  cc""])))
````
produces this:
````
<tf.RaggedTensor [[b'abc', b'\xc3']]>
````
Python split works just fine:
````
print(""abc Ã  cc"".split("" ""))
````
and prints:
````
['abc', 'Ã ', 'cc']
````
This is what I suspect is the problem: this code `""Ã "".encode() ` prints `b'\xc3\xa0'`. This byte literal `\xa0` is the nonbreaking space character (codepoint 160 in UTF-16 and UTF-32)."
47021,text_dataset_from_directory doesn't work if there isn't at least one subdirectory,"**System information**
- OS Platform: Windows 10
- TensorFlow version: 2.3.2
- Python version: 3.8.5

**Issue**
`tf.keras.preprocessing.text_dataset_from_directory` doesn't work if you have a directory structure like this:

data_dir/
--text_1.txt
--text_2.txt
--text_3.txt
````
ds = tf.keras.preprocessing.text_dataset_from_directory(
    data_dir, labels=[0,0,1], label_mode=""int"", 
    batch_size=NUM_FILES_PER_TENSOR, validation_split=None, 
    subset=None, shuffle=False, seed=seed
)
````
According to the documentation, the above should work since ""inferred"" is not passed to the `labels` argument. But instead you get this error:

````
ValueError: Expected the lengths of `labels` to match the number of files in the target directory. len(labels) is 3 while we found 0 files
````

But if you change the structure to this and run the exact same code, it works:

data_dir/
--dummy/
----text_1.txt
----text_2.txt
----text_3.txt

Even worse is that the labels you passed are simply ignored. It prints this message: `Found 3 files belonging to 1 classes`. It feels like the ""inferred"" option (which is the default) was properly implemented and the rest are broken."
47020,tf.nn.embedding_lookup outputs NaN,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
`tf.nn.embedding_lookup` outputs NaN if `params` is large value


**Describe the expected behavior**
Expect a grace exception message if the input is invalid instead of Nan as output

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.nn.embedding_lookup(params=np.array([1e+38, 1e+38],dtype=np.float32), ids=1, max_norm=10)
~~~

Output:
~~~python
<tf.Tensor: shape=(), dtype=float32, numpy=nan>
~~~"
47019,`tf.nn.log_poisson_loss` outputs NaN,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.nn.log_poisson_loss` outputs NaN if `log_input` and `targets` contain large values


**Describe the expected behavior**
Expect a grace exception message if the input is invalid instead of Nan as output

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.nn.log_poisson_loss(log_input=np.array([1e+38], dtype=np.float32), targets=np.array([1e+38], dtype=np.float32))
~~~
Output:
~~~python
<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>
~~~"
47016,Some Optimizers Don't Work on GPU With Embedding Layers,"**System information**
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.5 LTS
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
Python version: 3.7.9
CUDA/cuDNN version: CUDA Version: 11.0
GPU model and memory: Tesla T4, 15gb

**Describe the current behavior**
With some optimizers, I get this error consistently:Â 
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation .../ReadVariableOp: Could not satisfy explicit device specification '' because the node {{colocation_node .../ReadVariableOp}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, ... , /job:localhost/replica:0/task:0/device:GPU:0...]. 

Full error message is in this [gist](https://gist.github.com/iprovalo/7172d7b67535bc48e6ca7bae95a56ce1).

It looks like these three optimizers have an issue with embeddings:Â Adadelta,Â Adagrad, Ftrl

None of the other optimizers have this issue.Â  I tested all [eight](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) of them.

[Code](https://github.com/iprovalo/tf/blob/main/input_pipeline_stats_benchmark.py) to reproduce this.



**Describe the expected behavior**
All optimizers should work with Embeddings, or the documentation needs to reflect which ones are not compatible.

**Standalone code to reproduce the issue**
[Code](https://github.com/iprovalo/tf/blob/main/input_pipeline_stats_benchmark.py) to reproduce this.


**Other info / logs** Include any logs or source code that would be helpful to
log in the [gist](https://gist.github.com/iprovalo/7172d7b67535bc48e6ca7bae95a56ce1)
"
47013,Distributed mode is giving lower accuracy than standalone mode,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Laptop
- TensorFlow installed from (source or binary): No
- TensorFlow version (use command below):  2.4.1
- Python version: 3.8
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: ParameterServer Strategy

**The current behavior**

I wrote the below code in distributed mode using ParameterServer strategy and got an accuracy of 0.33 you can copy paste the code and execute the code it will work. However, in the standalone mode, it produces 100% accuracy. I believe there is some issue.

**The expected behavior**
The accuracy should be the same in standalone and distributed mode as the model and the data is the same.

**Standalone code to reproduce the issue**
```import multiprocessing
import os
import portpicker
import tensorflow as tf
import tensorflow.keras as keras
import tensorflow_hub as hub

print (tf.__version__)
#1. Define Workers
def create_in_process_cluster(num_workers, num_ps):
  """"""Creates and starts local servers and returns the cluster_resolver.""""""
  worker_ports = [portpicker.pick_unused_port() for _ in range(num_workers)]
  ps_ports = [portpicker.pick_unused_port() for _ in range(num_ps)]

  cluster_dict = {}
  cluster_dict[""worker""] = [""localhost:%s"" % port for port in worker_ports]
  if num_ps > 0:
    cluster_dict[""ps""] = [""localhost:%s"" % port for port in ps_ports]

  cluster_spec = tf.train.ClusterSpec(cluster_dict)

  # Workers need some inter_ops threads to work properly.
  worker_config = tf.compat.v1.ConfigProto()
  if multiprocessing.cpu_count() < num_workers + 1:
    worker_config.inter_op_parallelism_threads = num_workers + 1

  for i in range(num_workers):
    tf.distribute.Server(
        cluster_spec, job_name=""worker"", task_index=i, config=worker_config,
        protocol=""grpc"")

  for i in range(num_ps):
    tf.distribute.Server(
        cluster_spec, job_name=""ps"", task_index=i, protocol=""grpc"")

  cluster_resolver = tf.distribute.cluster_resolver.SimpleClusterResolver(
      cluster_spec, task_id=0, task_type=""worker"",rpc_layer=""grpc"")
  return cluster_resolver

NUM_WORKERS = 3
NUM_PS = 2
cluster_resolver = create_in_process_cluster(NUM_WORKERS, NUM_PS)

# Set the environment variable to allow reporting worker and ps failure to the
# coordinator. This is a workaround and won't be necessary in the future.
os.environ[""GRPC_FAIL_FAST""] = ""use_caller""

variable_partitioner = (
    tf.distribute.experimental.partitioners.FixedShardsPartitioner(
        num_shards=NUM_PS))

strategy = tf.distribute.experimental.ParameterServerStrategy(cluster_resolver)

word = ""Elephant""
sentence = ""I am a sentence for which I would like to get its embedding.""
paragraph = (
    ""Universal Sentence Encoder embeddings also support short paragraphs. ""
    ""There is no hard limit on how long the paragraph is. Roughly, the longer ""
    ""the more 'diluted' the embedding will be."")
messages = [word, sentence, paragraph, paragraph]
#labels=[""1"",""2"",""3""]
reviews = [[1,0,0],[0,1,0],[0,0,1],[0,0,1]]


encoder=hub.load(""https://tfhub.dev/google/universal-sentence-encoder/4"")

X_train=encoder(messages)

# from sentence_transformers import SentenceTransformer
#
# bertmodel = SentenceTransformer('stsb-roberta-large')
# X_train=bertmodel.encode(messages)

BUFFER_SIZE = len(X_train)
BATCH_SIZE_PER_REPLICA = 3
GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync
EPOCHS = 4


with strategy.scope():

    model = keras.Sequential()

    model.add(
        keras.layers.Dense(
            units=256,
            input_shape=(X_train.shape[1],),
            activation='relu'
        )
    )
    model.add(
        keras.layers.Dropout(rate=0.5)
    )

    model.add(
        keras.layers.Dense(
            units=128,
            activation='relu'
        )
    )
    model.add(
        keras.layers.Dropout(rate=0.5)
    )

    model.add(keras.layers.Dense(3, activation='softmax'))
    # model.compile(
    #     loss='categorical_crossentropy',
    #     optimizer=keras.optimizers.Adam(0.001),
    #     metrics=['accuracy']
    # )

    # history = model.fit(
    #     np.array(X_train), np.array(reviews),
    #     epochs=10,
    #     batch_size=16,
    #     verbose=1,
    #     shuffle=True
    # )
    optimizer=keras.optimizers.Adam(0.001)
    accuracy = keras.metrics.Accuracy()


def step_fn(x_train_slice):
    x_train, y_train = next(x_train_slice)
    with tf.GradientTape() as tape:

        pred=model(x_train,training=True)
        # tf.print(x_train)
        # tf.print(pred)
        # tf.print(y_train)

        per_example_loss = keras.losses.CategoricalCrossentropy(
            reduction=tf.keras.losses.Reduction.NONE)(y_train, pred)
        loss = tf.nn.compute_average_loss(per_example_loss)
        gradients = tape.gradient(loss, model.trainable_variables)

    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    # actual_pred = tf.cast(tf.greater(pred, 0.5), tf.int64)
    argmax_pred = tf.one_hot(tf.math.argmax(pred, axis=1), depth=pred.shape[1])
    tf.print(""train values are"",x_train)
    tf.print("" pred Values are : "", pred)
    tf.print("" ArgMAx Values are "",type(tf.math.argmax(pred,axis=0)))
    # tf.print("" actual_pred Values are : "", actual_pred)
    tf.print("" Labels  are : "", y_train)
    tf.print("" Labels Max Values are : "", tf.argmax(y_train))
    tf.print("" tf.math.argmax(pred, axis=1) "", tf.math.argmax(pred, axis=1))
    tf.print(""argmax_pred "",argmax_pred)
    accuracy.update_state(y_train, argmax_pred)
    tf.print(""Accuracy is : "",accuracy.result())

    return (loss,tf.math.argmax(pred,axis=0))

@tf.function
def distributed_train_step(per_worker_iterator):
    (losses,argmaxes) = strategy.run(step_fn,args=(per_worker_iterator,))
    strategy.reduce(tf.distribute.ReduceOp.SUM, losses, axis=None)
    return argmaxes


@tf.function
def per_worker_dataset_fn():
    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, reviews)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)
    print(train_dataset)
    tf.print(""train_dataset "",train_dataset)
    # test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)
    train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)
    # test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)
    return train_dist_dataset


coordinator = tf.distribute.experimental.coordinator.ClusterCoordinator(strategy)
per_worker_dataset = coordinator.create_per_worker_dataset(per_worker_dataset_fn)
per_worker_iterator = iter(per_worker_dataset)
num_epoches = 5
steps_per_epoch = 1
for i in range(num_epoches):
  accuracy.reset_states()
  for _ in range(steps_per_epoch):
    argmaxes=coordinator.schedule(distributed_train_step, args=(per_worker_iterator,))

    # Wait at epoch boundaries.
  coordinator.join()
  print(""argmaxes"", argmaxes.fetch())
  print (""Finished epoch %d, accuracy is %f."",(i,accuracy.result().numpy()))
```

**Other info / logs** Include any logs or source code that would be helpful to
Finished epoch %d, accuracy is %f. (4, 0.33333334)
"
47010,Construct sparse tensor using keras inputs (keras symbolic tensor),"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): r2.4
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
We want to construct sparse tensors using keras inputs (dens inputs, not sparse inputs). We pass dense_shape, values, and indices as dense inputs and will be using these three to construct a sparse tensor. Particularly, we dont want to use keras inputs with sparse flag on as keras models with sparse input can not be export for serving directly (see this [issue](https://github.com/tensorflow/tensorflow/issues/42018) ).

**Will this change the current api? How?**
No
**Who will benefit with this feature?**
Users need to build and serve models with sparse tensors
**Any Other info.**
#42018 "
47008,RNN + CUDA crashing with a generator,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home Edition
- TensorFlow installed from (source or binary): conda
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.5
- CUDA/cuDNN version: 10.1 and 7.6.5
- GPU model and memory: GeForce GTX 1650 4GB

**Describe the current behavior**

I have multiple .npy files that cannot be loaded into memory all at once. I created a generator that would shuffle the files, load them in batches and use them for training. It works well on CPU, but on GPU it gives an error:

> InternalError:    Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 2, 3, 1, 99, 103830, 0] 
	 [[{{node cond_40/then/_0/cond/CudnnRNNV3}}]]
	 [[sequential_1/gru_1/PartitionedCall]] [Op:__inference_train_function_9121]
Function call stack:
train_function -> train_function -> train_function

If I generate the data with next() function call, I can make training happen (obviously only on the current set of files generated). So the generator behaves properly and I can train on whatever's yielded out of it.. but not when I put the generator inside the fit method.

same happens on Google Colab.

I have looked into other issues that show a very similar error, however only one of them was related to generators: https://github.com/tensorflow/tensorflow/issues/44553 .Otherwise, the error does not happen to me.

**Describe the expected behavior**

I would like to be able to pass the generated dataset into the .fit method directly and train it.

**Standalone code to reproduce the issue**

the code for generator
```
no_of_files = len(x_tr_f)
file_batch = 5
loop_iterations = np.floor(no_of_files / file_batch)
init_alpha = 47.05906039370126
mask_value = -1.3371337

def tf_data_generator5(directory = [], batch_size = 5):
    i = 0
    x_t = os.listdir(directory[0])
    y_t = os.listdir(directory[1])
    x_t, y_t = shuffle(x_t, y_t)
    while True:
        if i*batch_size >= len(x_t):
            i = 0
            x_t, y_t = shuffle(x_t, y_t)
        file_chunk = x_t[i*batch_size:(i+1)*batch_size] 
        X_a = []
        Y_a = []
        for fname in file_chunk:
            x_info = np.load(directory[0]+fname)
            y_info = np.load(directory[1]+fname)
            X_a.append(x_info)
            Y_a.append(y_info)
        X_a = np.concatenate(X_a)
        Y_a = np.concatenate(Y_a)
       #just some masking stuff and weight generation, irrelevant to the problem
        tte_mean_train = np.nanmean(Y_a[:,:,0])
        mask_value = -1.3371337
        X_a,Y_a, W_a = nanmask_to_keras_mask(X_a,Y_a,mask_value,tte_mean_train)
        yield X_a,Y_a
        i = i + 1
```

Here I generate the data
```
generated_train_data = tf_data_generator2(['./data/x_train_m/', './data/y_train_m/'], batch_size = 5)
```

Here I define the model (using WTTE-RNN):
```
def base_model():
    model = Sequential()
    model.add(Masking(mask_value=mask_value,input_shape=(None, 2)))
    model.add(GRU(3,activation='tanh',return_sequences=True))
    return model
def wtte_rnn():
    model = base_model()
    model.add(TimeDistributed(Dense(2)))
    model.add(Lambda(wtte.output_lambda, 
                     arguments={""init_alpha"":init_alpha, 
                                ""max_beta_value"":4.0,
                                ""alpha_kernel_scalefactor"":0.5}))

    loss = wtte.loss(kind='discrete',reduce_loss=False).loss_function
    model.compile(loss=loss, optimizer=Adam(lr=.01,clipvalue=0.5),sample_weight_mode='temporal')
    return model
```

And finally I am trying to fit:

```
model = wtte_rnn()
model.summary()

K.set_value(model.optimizer.lr, 0.01)
model.fit(generated_train_data,
          epochs=100,
          steps_per_epoch=loop_iterations)
```

**Other info / logs**
```
InternalError                             Traceback (most recent call last)
<ipython-input-3-bcd428d0a8b2> in <module>
      3 
      4 K.set_value(model.optimizer.lr, 0.01)
----> 5 model.fit(generated_train_data,
      6           epochs=10,
      7           verbose=1,
C:\Anaconda3\envs\tf-gpu-test2\lib\site-packages\tensorflow\python\keras\engine\training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--> 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.
C:\Anaconda3\envs\tf-gpu-test2\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1096                 batch_size=batch_size):
   1097               callbacks.on_train_batch_begin(step)
-> 1098               tmp_logs = train_function(iterator)
   1099               if data_handler.should_sync:
   1100                 context.async_wait()
C:\Anaconda3\envs\tf-gpu-test2\lib\site-packages\tensorflow\python\eager\def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()
C:\Anaconda3\envs\tf-gpu-test2\lib\site-packages\tensorflow\python\eager\def_function.py in _call(self, *args, **kwds)
    838         # Lifting succeeded, so variables are initialized and we can run the
    839         # stateless function.
--> 840         return self._stateless_fn(*args, **kwds)
    841     else:
    842       canon_args, canon_kwds = \
C:\Anaconda3\envs\tf-gpu-test2\lib\site-packages\tensorflow\python\eager\function.py in __call__(self, *args, **kwargs)
   2827     with self._lock:
   2828       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2829     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2830 
   2831   @property
C:\Anaconda3\envs\tf-gpu-test2\lib\site-packages\tensorflow\python\eager\function.py in _filtered_call(self, args, kwargs, cancellation_manager)
   1841       `args` and `kwargs`.
   1842     """"""
-> 1843     return self._call_flat(
   1844         [t for t in nest.flatten((args, kwargs), expand_composites=True)
   1845          if isinstance(t, (ops.Tensor,
C:\Anaconda3\envs\tf-gpu-test2\lib\site-packages\tensorflow\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1921         and executing_eagerly):
   1922       # No tape is watching; skip to running the function.
-> 1923       return self._build_call_outputs(self._inference_function.call(
   1924           ctx, args, cancellation_manager=cancellation_manager))
   1925     forward_backward = self._select_forward_and_backward_functions(
C:\Anaconda3\envs\tf-gpu-test2\lib\site-packages\tensorflow\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    543       with _InterpolateFunctionError(self):
    544         if cancellation_manager is None:
--> 545           outputs = execute.execute(
    546               str(self.signature.name),
    547               num_outputs=self._num_outputs,
C:\Anaconda3\envs\tf-gpu-test2\lib\site-packages\tensorflow\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     57   try:
     58     ctx.ensure_initialized()
---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
InternalError:    Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 2, 3, 1, 99, 108196, 0] 
	 [[{{node cond_40/then/_0/cond/CudnnRNNV3}}]]
	 [[sequential/gru/PartitionedCall]] [Op:__inference_train_function_7361]
Function call stack:
train_function -> train_function -> train_function
```"
47007,[TF Lite] How to use XNNPACK delegate on Windows?,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 2.5 (nightly)
- Python version: 3.8
- Installed using virtualenv? pip? conda?: No
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): Visual C++ 2019
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the problem**
I was successfully building tensorflow lite on Windows, for CPU only, not with any delegate. I also verified that I was able to against `tensorflowlite_c.dll.if.lib` and to execute a tf lite model and produce the correct outputs.

Then I rebuilt tensorflow lite with the `xnnpack` delegate. The build was successful. However, now, when I try to build my test program and link against `tensorflowlite_c.dll.if.lib`, I now get:

![err1](https://user-images.githubusercontent.com/67419721/107218568-c80e4780-69dd-11eb-89f2-cebdc47dad81.PNG)

I tried to add `xnnpack_delegate.lib` to the list of library dependencies, only to get more linker errors:

![err2](https://user-images.githubusercontent.com/67419721/107218646-e2482580-69dd-11eb-960a-9ac33144f1e2.PNG)

I also tried linking against of libs, like `c_api.lo.lib` or `common.lo.lib`, but it made no difference. 
Anybody know which `.lib` files should I be linking against on Windows?

**Provide the exact sequence of commands / steps that you executed before running into the problem**

The command I used to build TF Lite with xnnpack delegate was:
```
bazel build -c opt --cxxopt=-std=c++14 --define tflite_with_xnnpack=true //tensorflow/lite/c:tensorflowlite_c.dll
```
When I ran the `configure.py` script, I left everything to default, with the only exception that I changed the `-c opt` flag from default `/arch:AVX` to `/arch:AVX512`. "
47004,Error in keras.tokenizer.texts_to_sequences,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.0
- Python version: 3.7.4
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Describe the current behavior**
When few texts are given to the keras.tokenizer.texts_to_sequences, it can produce the right sequences but when we have loarge number of texts, it produces wrong sequences.

**Describe the expected behavior**
Expect the same ""number of non zero values"" for few texts and large texts.

In example below, for ""few texts"", rows 0 and 5 have 2 and 4 non-zero values respectively, but for ""texts"" that we have many rows (as shown below) for these rows we have 1 and 3 non-zero values (the first 8 rows in ""texts"" are the same as in ""few texts""). These are just two rows. There are many rows like this.

**Standalone code to reproduce the issue**
[samples.txt](https://github.com/tensorflow/tensorflow/files/5942989/samples.txt)

```from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
import numpy as np
import pickle

few_texts=['product market',
           'business marketing',
           'entrepreneur business',
           'invest money',
           'money invest .',
           'business money investment investing',
           'strategies market .',
           'marketing investment . .']


tokenizer = Tokenizer(num_words=25)
tokenizer.fit_on_texts(few_texts)
sequences = tokenizer.texts_to_sequences(few_texts)
print('sequences:',sequences)
word_index = tokenizer.word_index
data = pad_sequences(sequences, maxlen=25, padding='post')
print('Shape of data tensor:', data.shape)
data
```
sequences: [[7, 3], [1, 4], [8, 1], [5, 2], [2, 5], [1, 2, 6, 9], [10, 3], [4, 6]]
Shape of data tensor: (8, 25)
array([[ 7,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 1,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 5,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 2,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 1,  2,  6,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0],
       [10,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 4,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0]])

```
with open(""samples.txt"", ""rb"") as fp:   
    seed = pickle.load(fp)
texts=seed
len(texts)
```
1000
```
texts[0],texts[1],texts[2],texts[3],texts[4],texts[5],texts[6],texts[7]
```
('product market',
 'business marketing',
 'entrepreneur business',
 'invest money',
 'money invest .',
 'business money investment investing',
 'strategies market .',
 'marketing investment . .')
```
tokenizer = Tokenizer(num_words=25)
tokenizer.fit_on_texts(texts)
sequences = tokenizer.texts_to_sequences(texts)
#print('sequences:',sequences)
word_index = tokenizer.word_index
#print('Found %s unique tokens.' % len(word_index))

data = pad_sequences(sequences, maxlen=25, padding='post')
#print(data)
print('Shape of data tensor:', data.shape)

data[0],data[5]
```
Shape of data tensor: (1000, 25)
(array([5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0]),
 array([ 1,  3, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0]))"
47002,Import tensorflow -> Illegal instruction,"System information |  Version
|----------------|---------|
OS Platform | Ubuntu 18.04 LTS
Device | Orange Pi 4
Python version | 3.6
Installed using | pip

Hi everyone!
Find only one work solution for me:
```
pip3 install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.8.0-py3-none-any.whl
<...>
Installing collected packages: tensorflow
Successfully installed tensorflow-1.8.0
```
And:
```
orangepi@orangepi4:~$ python3.6.9
>>> import tensorflow
Illegal instruction (core dumped)
```
I am installing version 1.5.0 and the problem persists
"
47001,Tensorflow 2.4.1running with cpu but not gpu,"Hi all,

I am trying to set up an environment on WSL2(windows 10) to run my deep learning project with Tensorflow on GPU.
Please see below for my system and related packages I have installed:
##
Main OS: Windows Pro, Insider Preview (21301.1010)
GPU : Nvidia 1060 3GB
CPU : I5-2500
##
Subsystem: Ubuntu20.04 LTS ( install from windows store)
Tensorflow: 2.4.1
Python: 3.8.5
CUDA and other necessary toolkits were installed as following url:
[Tensorflow gpu support guide](https://www.tensorflow.org/install/gpu), in the section of **Ubuntu 18.04 (CUDA 11.0)**.
_p.s. Although I am using Ubuntu20.04(WSL2), tensorflow was not able to detect my gpu when I installed CUDA toolkit for Ubuntu20.04. Therefore, I followed the guide of Ubuntu18.04 and it worked fine._
##

Everything worked fine at the beginning, all tests showing that tensorflow was able to detect my gpu device.
However, when I ran [Tensorflow sample code](https://www.tensorflow.org/tutorials/quickstart/beginner?hl=zh_tw), the message showed that tensorflow created a gpu device but running on cpu when code executed to model.fit

`2021-02-08 16:32:23.944331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-08 16:32:26.591081: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 16:32:26.599408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-08 16:32:26.902834: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2021-02-08 16:32:26.903131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 3GB computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 9 deviceMemorySize: 3.00GiB deviceMemoryBandwidth: 178.99GiB/s
2021-02-08 16:32:26.903196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-08 16:32:26.907413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-08 16:32:26.907593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-08 16:32:26.910460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-08 16:32:26.911433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-08 16:32:26.915959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-02-08 16:32:26.916820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-08 16:32:26.917147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-02-08 16:32:26.918042: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2021-02-08 16:32:26.918932: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2021-02-08 16:32:26.919158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-02-08 16:32:26.920533: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 16:32:26.921406: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2021-02-08 16:32:26.921676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 3GB computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 9 deviceMemorySize: 3.00GiB deviceMemoryBandwidth: 178.99GiB/s
2021-02-08 16:32:26.921762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-08 16:32:26.921851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-08 16:32:26.921914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-08 16:32:26.921976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-08 16:32:26.922038: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-08 16:32:26.922073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-02-08 16:32:26.922133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-08 16:32:26.922195: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-02-08 16:32:26.923004: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2021-02-08 16:32:26.923906: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2021-02-08 16:32:26.924155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-02-08 16:32:26.924245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-08 16:32:29.425230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-08 16:32:29.425326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-02-08 16:32:29.425343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-02-08 16:32:29.427287: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2021-02-08 16:32:29.427562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1489] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.
2021-02-08 16:32:29.428461: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2021-02-08 16:32:29.429563: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.`

### Created TensorFlow device successfully
**2021-02-08 16:32:29.429890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2074 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1)**

`2021-02-08 16:32:29.888992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-08 16:32:31.514620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-08 16:32:32.694044: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 188160000 exceeds 10% of free system memory.
2021-02-08 16:32:33.834778: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)`

### Model was running on cpu but not cpu
**2021-02-08 16:32:33.836445: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3292520000 Hz**

Is there anything I did not execute properly? I would like to utilize my gpu power on my deep learning project but tensorflow only work on my cpu but not gpu even it showed it created a tensorflow device.

Any comments and suggestion are appreciate. Thanks you all.
"
47000,tf.train.Server and mirrored strategy..,"Hello I am a new user of tensorflow.
I am implementing one reinforcement learning algorithm using tf2 ,I have it's implementation with tf1 there the authors have used tf.train.Server for the distributed learning I want to use tf.distribute.MirroredStrategy to do the distributed training. But I am not able to link these 2 methods the ""tf.train.Server"" and ""tf.distribute.MirroredStrategy"". can anyone help to understand the difference between these and how to go about it? Thanks you..

"
46999,How could I know the label is correctly read from image_dataset_from_directory?,"I'd save the directory structure as indicated in document, separate classes of images stored in corresponding folder with corresponding label as folder name.

However, I could not find a way to return the labels read from image_dataset_from_directory function, and I'm afraid the class name is not correctly read.

The performance of my training is that, after 10 training epochs the training and validate accuracy reached 0.99, but the model prediction would only predict one class.

How could I check the label read by this function?
"
46998,Documentation mistake in tf.keras.layers.MaxPool2D python section,"## URL(s) with the issue: 
https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D

## Description of issue (what needs changing):

A Documentation mistake in tf.keras.layers.MaxPool2D python section(example)

### Clear description

There is a documentation mistake in tf.keras.layers.MaxPool2D python section(example). 
In the description part of there are few examples given with their respective code snippets.
Under this text-""For example, for stride=(2,2) and padding=""valid"":"" in the code snippet of example instead of **strides=(2,2)**, **strides=(1,1)** is written.


<img width=""939"" alt=""Screenshot 2021-02-08 at 10 16 05 AM"" src=""https://user-images.githubusercontent.com/38719024/107178001-33b1de00-69f9-11eb-8c7a-6114457686c0.png"">
"
46996,tf.nn.local_response_normalization outputs NaN,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.nn.local_response_normalization` outputs NaN when `input` contains large value

**Describe the expected behavior**
Expect a grace exception message if the input is invalid instead of Nan as output

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
input=np.array([[[[-2e+38, 1, 1e+38,1, 1, 1, 1]]]])
tf.nn.local_response_normalization(input=input, alpha=1, beta=1)
~~~


Output:
~~~python
<tf.Tensor: shape=(1, 1, 1, 7), dtype=float32, numpy=array([[[[-0.,  0.,  0.,  0.,  0.,  0., nan]]]], dtype=float32)>
~~~

"
46995,`tf.nn.weighted_moments` outputs NaN when `axes=[]` and `x` is complex,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A
-

**Describe the current behavior**
`tf.nn.weighted_moments` outputs NaN when `axes=[]` and `x` is complex
**Describe the expected behavior**
expect no Nan in output

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.nn.weighted_moments(x=np.array([1e+38+0.j, 2e+38+0.j], dtype=np.complex64), frequency_weights=10, axes=[])
~~~

Output:
~~~python
(<tf.Tensor: shape=(2,), dtype=complex64, numpy=array([inf+nanj, inf+nanj], dtype=complex64)>, <tf.Tensor: shape=(2,), dtype=complex64, numpy=array([inf+nanj, inf+nanj], dtype=complex64)>)
~~~"
46994,tf.nn.avg_pool/1d/2d/3d outputs NaN if `ksize=0`,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A:



**Describe the current behavior**
The following APIs output NaN if `ksize=0`
- `tf.nn.avg_pool1d`
- `tf.nn.avg_pool2d`
- `tf.nn.avg_pool3d`
- `tf.nn.avg_pool`


**Describe the expected behavior**
Expect a grace exception message if the input is unexpected(e.g. `ksize=0`) other than a NaN as output

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.nn.avg_pool1d(input=np.ones((1, 1, 1)), ksize=0, strides=1, padding='SAME')
tf.nn.avg_pool2d(input=np.ones((1, 1, 1, 1)), ksize=0, strides=1, padding='SAME')
tf.nn.avg_pool3d(input=np.ones((1, 1, 1, 1, 1)), ksize=0, strides=1, padding='SAME')
tf.nn.avg_pool(input=np.ones((1, 1, 1)), ksize=0, strides=1, padding='SAME')
~~~

The output of `tf.nn.avg_pool1d`
~~~python
<tf.Tensor: shape=(1, 1, 1), dtype=float64, numpy=array([[[nan]]])>
~~~
"
46993,`tf.keras.layers.ELU` and  `tf.keras.layers.LeakyReLU` outputs nan if `alpha=None`,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
`tf.keras.layers.ELU` and  `tf.keras.layers.LeakyReLU` outputs nan if `alpha=None`


**Describe the expected behavior**
expect no nan as output


**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
layer = tf.keras.layers.ELU(alpha=None)
out=layer(np.array([-2, 6.]))
print(out)
~~~

Output:
~~~
tf.Tensor([nan  6.], shape=(2,), dtype=float32)
~~~


~~~python
import tensorflow as tf
import numpy as np
layer = tf.keras.layers.LeakyReLU(alpha=None)
out=layer(np.array([-2, 6]))
~~~
Output:
~~~
<tf.Tensor: shape=(2,), dtype=float32, numpy=array([nan,  6.], dtype=float32)>
~~~


Related: #13787"
46992,"Converting tf.argmax(predicted,axis=0) to numpy array to index the y_labels","I am new to Tensorflow and wrote the following distributed training code. The code works fine.

    import multiprocessing
    import os
    import portpicker
    import tensorflow as tf
    import tensorflow.keras as keras
    import tensorflow_hub as hub
    import tensorflow.python.keras.backend as K
    #1. Define Workers
    def create_in_process_cluster(num_workers, num_ps):
      """"""Creates and starts local servers and returns the cluster_resolver.""""""
      worker_ports = [portpicker.pick_unused_port() for _ in range(num_workers)]
      ps_ports = [portpicker.pick_unused_port() for _ in range(num_ps)]
    
      cluster_dict = {}
      cluster_dict[""worker""] = [""localhost:%s"" % port for port in worker_ports]
      if num_ps > 0:
        cluster_dict[""ps""] = [""localhost:%s"" % port for port in ps_ports]
    
      cluster_spec = tf.train.ClusterSpec(cluster_dict)
    
      # Workers need some inter_ops threads to work properly.
      worker_config = tf.compat.v1.ConfigProto()
      if multiprocessing.cpu_count() < num_workers + 1:
        worker_config.inter_op_parallelism_threads = num_workers + 1
    
      for i in range(num_workers):
        tf.distribute.Server(
            cluster_spec, job_name=""worker"", task_index=i, config=worker_config,
            protocol=""grpc"")
    
      for i in range(num_ps):
        tf.distribute.Server(
            cluster_spec, job_name=""ps"", task_index=i, protocol=""grpc"")
    
      cluster_resolver = tf.distribute.cluster_resolver.SimpleClusterResolver(
          cluster_spec, task_id=0, task_type=""worker"",rpc_layer=""grpc"")
      return cluster_resolver
    
    NUM_WORKERS = 3
    NUM_PS = 2
    cluster_resolver = create_in_process_cluster(NUM_WORKERS, NUM_PS)
    
    # Set the environment variable to allow reporting worker and ps failure to the
    # coordinator. This is a workaround and won't be necessary in the future.
    os.environ[""GRPC_FAIL_FAST""] = ""use_caller""
    
    variable_partitioner = (
        tf.distribute.experimental.partitioners.FixedShardsPartitioner(
            num_shards=NUM_PS))
    
    strategy = tf.distribute.experimental.ParameterServerStrategy(cluster_resolver)
    
    word = ""Elephant""
    sentence = ""I am a sentence for which I would like to get its embedding.""
    paragraph = (
        ""Universal Sentence Encoder embeddings also support short paragraphs. ""
        ""There is no hard limit on how long the paragraph is. Roughly, the longer ""
        ""the more 'diluted' the embedding will be."")
    messages = [word, sentence, paragraph]
    #labels=[""1"",""2"",""3""]
    reviews = [[1,0,0],[0,1,0],[0,0,1]]
    
    
    encoder=hub.load(""https://tfhub.dev/google/universal-sentence-encoder/4"")
    
    X_train=encoder(messages)
    
    BUFFER_SIZE = len(X_train)
    BATCH_SIZE_PER_REPLICA = 2
    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync
    EPOCHS = 4
    
    
    with strategy.scope():
    
        model = keras.Sequential()
    
        model.add(
            keras.layers.Dense(
                units=256,
                input_shape=(X_train.shape[1],),
                activation='relu'
            )
        )
        model.add(
            keras.layers.Dropout(rate=0.5)
        )
    
        model.add(
            keras.layers.Dense(
                units=128,
                activation='relu'
            )
        )
        model.add(
            keras.layers.Dropout(rate=0.5)
        )
    
        model.add(keras.layers.Dense(3, activation='softmax'))
        # model.compile(
        #     loss='categorical_crossentropy',
        #     optimizer=keras.optimizers.Adam(0.001),
        #     metrics=['accuracy']
        # )
    
        # history = model.fit(
        #     np.array(X_train), np.array(reviews),
        #     epochs=10,
        #     batch_size=16,
        #     verbose=1,
        #     shuffle=True
        # )
        optimizer=keras.optimizers.Adam(0.001)
        accuracy = keras.metrics.Accuracy()
    
    
    def step_fn(x_train_slice):
    
        x_train, y_train = next(x_train_slice)
        with tf.GradientTape() as tape:
            pred=model(x_train,training=True)
            # tf.print(x_train)
            # tf.print(pred)
            # tf.print(y_train)
    
            per_example_loss = keras.losses.CategoricalCrossentropy(
                reduction=tf.keras.losses.Reduction.NONE)(y_train, pred)
            loss = tf.nn.compute_average_loss(per_example_loss)
            gradients = tape.gradient(loss, model.trainable_variables)
    
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))
        actual_pred = tf.cast(tf.greater(pred, 0.5), tf.int64)
        tf.print(""train values are"",x_train)
        tf.print("" pred Values are : "", pred)
        tf.print("" ArgMAx Values are "",tf.math.argmax(pred,axis=0)) #problem
        tf.print("" actual_pred Values are : "", actual_pred)
        tf.print("" Labels  are : "", y_train)
        tf.print("" Labels Max Values are : "", tf.argmax(y_train))
        accuracy.update_state(y_train, actual_pred)
        tf.print(""Accuracy is : "",accuracy.result())
        return loss
    
    @tf.function
    def distributed_train_step(x_train_slice):
        losses = strategy.run(step_fn,args=(x_train_slice,))
        return strategy.reduce(tf.distribute.ReduceOp.SUM, losses, axis=None)
    
    
    @tf.function
    def per_worker_dataset_fn():
        train_dataset = tf.data.Dataset.from_tensor_slices((X_train, reviews)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)
        # test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)
        train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)
        # test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)
        return train_dist_dataset
    
    
    coordinator = tf.distribute.experimental.coordinator.ClusterCoordinator(strategy)
    per_worker_dataset = coordinator.create_per_worker_dataset(per_worker_dataset_fn)
    per_worker_iterator = iter(per_worker_dataset)
    num_epoches = 5
    steps_per_epoch = 1
    for i in range(num_epoches):
      accuracy.reset_states()
      for _ in range(steps_per_epoch):
        coordinator.schedule(distributed_train_step, args=(per_worker_iterator,))
        # Wait at epoch boundaries.
      coordinator.join()
      print (""Finished epoch %d, accuracy is %f."",(i,accuracy.result().numpy()))

The problem is, in the step_fn once I get the prediction values I would like to get the corresponding labels, for this I have used this line of code
`tf.print("" ArgMAx Values are "",tf.math.argmax(pred,axis=0)) #problem`

The argmax gives the array of indices for max probabilities. I would like to extract this as numpy array and index it to reviews array (One-Hot encoded values) to get the confusion matrix. 

But I'm not able to convert `tf.math.argmax(pred,axis=0)` tensor to numpy array. I tried many approaches like eval(K.get_session()) and so on but nothing worked. Any help is appreciated.

Thanks much"
46990,Yet Another -1073740791 (0xC0000409),"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: `pip freeze` gave me this:
```
tensorboard==2.4.1
tensorboard-plugin-wit==1.7.0
tensorflow==2.4.0
tensorflow-estimator==2.4.0
tensorflow-gpu==2.4.1
```
- Python version: 3.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: ```nvcc --version``` gave me this:
```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Thu_Jun_11_22:26:48_Pacific_Daylight_Time_2020
Cuda compilation tools, release 11.0, V11.0.194
Build cuda_11.0_bu.relgpu_drvr445TC445_37.28540450_0

```
As referenced here - 

*The main reason is cuda version information is not stored in ```cudnn.h``` anymore in CUDA 11.X. In CUDA 11.X, the version information seems to stored in  new ```cudnn_version.h``` file. So many build tools such as cmake depends on ```cudnn.h``` for CUDA version information cannot guess CUDA version anymore.*

_Originally posted by @hongsoog in https://github.com/tensorflow/tensorflow/issues/8264#issuecomment-723446642_

Am sure its cudnn 11.2 (The name of zip file)

- GPU model and memory:

GTX 1650 8 GB

**Describe the problem**

So I have been trying to accelerate my Deep Learning program using GPU since ages, for the first time I was able to find my GPU and after going through the whole process, I ran

```
import tensorflow as tf
print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
```
It found my GPU

Result - 
```
C:\Users\asus\Music_Classification\lib\site-packages\numpy\.libs\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll
C:\Users\asus\Music_Classification\lib\site-packages\numpy\.libs\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll
  warnings.warn(""loaded more than 1 DLL from .libs:""
2021-02-08 04:01:40.630572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-02-08 04:01:45.995174: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 04:01:45.997294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2021-02-08 04:01:46.037247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1650 computeCapability: 7.5
coreClock: 1.56GHz coreCount: 16 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 119.24GiB/s
2021-02-08 04:01:46.038203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-02-08 04:01:46.086937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-02-08 04:01:46.087068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-02-08 04:01:46.117926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-02-08 04:01:46.127343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-02-08 04:01:46.196088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-02-08 04:01:46.215917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
Num GPUs Available:  1
2021-02-08 04:01:46.219540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-02-08 04:01:46.220028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
```

**Question 1** - Funny enough it found 4gig of memory only, is this because of some Shared vs DEdicated memory?

I then went on to train my CNN model, and it gave me traceback:

```
Process finished with exit code -1073740791 (0xC0000409)
```

The whole error:
```
2021-02-08 04:05:05.982102: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-08 04:05:05.982898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2021-02-08 04:05:06.021203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1650 computeCapability: 7.5
coreClock: 1.56GHz coreCount: 16 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 119.24GiB/s
2021-02-08 04:05:06.021514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-02-08 04:05:06.029225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-02-08 04:05:06.029425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-02-08 04:05:06.034370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-02-08 04:05:06.036450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-02-08 04:05:06.047235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-02-08 04:05:06.050880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-02-08 04:05:06.051983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-02-08 04:05:06.052288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-02-08 04:05:06.060950: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-08 04:05:06.064289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1650 computeCapability: 7.5
coreClock: 1.56GHz coreCount: 16 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 119.24GiB/s
2021-02-08 04:05:06.064478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-02-08 04:05:06.064582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-02-08 04:05:06.064710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-02-08 04:05:06.064841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-02-08 04:05:06.064948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-02-08 04:05:06.065057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-02-08 04:05:06.065150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-02-08 04:05:06.065240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-02-08 04:05:06.065392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-02-08 04:05:07.277891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-08 04:05:07.278012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-02-08 04:05:07.278075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-02-08 04:05:07.279959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2903 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5)
2021-02-08 04:05:07.284087: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
  0%|          | 0/8091 [00:00<?, ?it/s]
C:/Users/asus/PycharmProjects/Auto_Caption_Generator/caption_generator_collab.py:139: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  for img in tqdm(os.listdir(directory)):
2021-02-08 04:05:09.583142: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-08 04:05:10.755831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll

Process finished with exit code -1073740791 (0xC0000409)
```

**Problem 2** Can someone please help me with this error.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Summed up above

**Any other info / logs**
Pip Freeze 
```
absl-py==0.11.0
appdirs==1.4.4
argon2-cffi==20.1.0
astunparse==1.6.3
async-generator==1.10
attrs==20.3.0
audioread==2.1.9
backcall==0.2.0
bleach==3.2.1
cachetools==4.2.0
certifi==2020.12.5
cffi==1.14.4
chardet==4.0.0
colorama==0.4.4
cycler==0.10.0
decorator==4.4.2
defusedxml==0.6.0
entrypoints==0.3
flatbuffers==1.12
gast==0.3.3
google-auth==1.24.0
google-auth-oauthlib==0.4.2
google-pasta==0.2.0
grpcio==1.32.0
h5py==2.10.0
idna==2.10
ipykernel==5.4.3
ipython==7.19.0
ipython-genutils==0.2.0
ipywidgets==7.6.3
jedi==0.18.0
Jinja2==2.11.2
joblib==1.0.0
jsonschema==3.2.0
jupyter==1.0.0
jupyter-client==6.1.11
jupyter-console==6.2.0
jupyter-core==4.7.0
jupyter-http-over-ws==0.0.8
jupyterlab-pygments==0.1.2
jupyterlab-widgets==1.0.0
Keras==2.4.3
Keras-Preprocessing==1.1.2
kiwisolver==1.3.1
librosa==0.8.0
llvmlite==0.35.0
Markdown==3.3.3
MarkupSafe==1.1.1
matplotlib==3.3.3
mistune==0.8.4
nbclient==0.5.1
nbconvert==6.0.7
nbformat==5.1.2
nest-asyncio==1.4.3
notebook==6.2.0
numba==0.52.0
numpy==1.19.5
oauthlib==3.1.0
opt-einsum==3.3.0
packaging==20.8
pandas==1.2.0
pandocfilters==1.4.3
parso==0.8.1
pickleshare==0.7.5
Pillow==8.0.1
pooch==1.3.0
prometheus-client==0.9.0
prompt-toolkit==3.0.10
protobuf==3.14.0
pyasn1==0.4.8
pyasn1-modules==0.2.8
pycparser==2.20
Pygments==2.7.4
pyparsing==2.4.7
PyQt5==5.15.2
PyQt5-sip==12.8.1
pyrsistent==0.17.3
python-dateutil==2.8.1
python-speech-features==0.6
pytz==2020.5
pywin32==300
pywinpty==0.5.7
PyYAML==5.3.1
pyzmq==21.0.1
qtconsole==5.0.1
QtPy==1.9.0
requests==2.25.1
requests-oauthlib==1.3.0
resampy==0.2.2
rsa==4.7
scikit-learn==0.24.0
scipy==1.6.0
Send2Trash==1.5.0
six==1.15.0
SoundFile==0.10.3.post1
tensorboard==2.4.1
tensorboard-plugin-wit==1.7.0
tensorflow==2.4.0
tensorflow-estimator==2.4.0
tensorflow-gpu==2.4.1
termcolor==1.1.0
terminado==0.9.2
testpath==0.4.4
threadpoolctl==2.1.0
tornado==6.1
tqdm==4.56.0
traitlets==5.0.5
typing-extensions==3.7.4.3
urllib3==1.26.2
wcwidth==0.2.5
webencodings==0.5.1
Werkzeug==1.0.1
widgetsnbextension==3.5.1
wrapt==1.12.1
```
"
46989,Failed to deploy custom Tensorflow lite select ops .aar to Android,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Huawei P30 Lite
- TensorFlow installed from (source or binary): Source
- TensorFlow version: master - 2.4.1+
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
- CUDA/cuDNN version:
- GPU model and memory:

I have followed the instructions here: https://www.tensorflow.org/lite/guide/build_android and here: https://www.tensorflow.org/lite/guide/reduce_binary_size to build custom versions of tensorflow-lite.aar and tensorflow-lite-select-tf-ops.aar. However, when I try to run the model on Android, I get this error:

```
java.lang.UnsatisfiedLinkError: Failed to load native TensorFlow Lite methods. Check that the correct native libraries are present, and, if using a custom native library, have been properly loaded via System.loadLibrary():
      java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""_ZN6tflite3ops6custom38Register_TFLITE_DETECTION_POST_PROCESSEv"" referenced by ""/data/app/com.example.myapplication-2NF_GHdjAnMJHFkmSCcPvw==/lib/arm64/libtensorflowlite_jni.so""...
        at org.tensorflow.lite.TensorFlowLite.init(TensorFlowLite.java:80)
        at com.example.myapplication.MainActivity.onCreate(MainActivity.java:26)
```

This appears to be happening before loading the model, it seems to be a linking issue, though I have just build the two .aar files from source.

Steps followed:

I'm using Docker to build the aar files. I downloaded the Docker file from [here](https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/tools/dockerfiles/tflite-android.Dockerfile) and ran:
`docker build . -t tflite-builder -f tflite-android.Dockerfile`
followed by:
`docker run -it -v ""local_dir"":/host_dir tflite-builder bash`

Inside the docker container, I ran:
`curl -o build_aar_with_docker.sh   https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/lite/tools/build_aar_with_docker.sh &&   chmod +x build_aar_with_docker.sh`

followed by:
`echo y | /bin/bash build_aar_with_docker.sh --input_models=/host_dir/my_model.tflite   --target_archs=arm64-v8a,armeabi-v7a   --checkpoint=master `

My model is defined (here)[https://github.com/barrypitman/tensorflow_LPRnet] and uses 1 custom op - ctc_beam_search_decoder. 

After several hours, the build finished with this message:
```
INFO: Analyzed target //tmp:tensorflow-lite-select-tf-ops (308 packages loaded, 33657 targets configured).
INFO: Found 1 target...
Target //tmp:tensorflow-lite-select-tf-ops up-to-date:
  bazel-bin/tmp/tensorflow-lite-select-tf-ops.aar
INFO: Elapsed time: 35622.438s, Critical Path: 3942.80s
INFO: 14237 processes: 861 internal, 13376 local.
INFO: Build completed successfully, 14237 total actions
Output can be found here:
tensorflow-lite.aar
tensorflow-lite-select-tf-ops.aar
```

I copied the tensorflow-lite.aar and tensorflow-lite-select-tf-ops.aar files into a sample Android application (attached), and I got the above-mentioned error:
```
java.lang.UnsatisfiedLinkError: Failed to load native TensorFlow Lite methods. Check that the correct native libraries are present, and, if using a custom native library, have been properly loaded via System.loadLibrary():
      java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""_ZN6tflite3ops6custom38Register_TFLITE_DETECTION_POST_PROCESSEv"" referenced by ""/data/app/com.example.myapplication-2NF_GHdjAnMJHFkmSCcPvw==/lib/arm64/libtensorflowlite_jni.so""...
```

I've tried generating the tensorflow-lite-select-tf-ops.aar file against the 2.4.0 and 2.4.1 branches, but I'm getting similar errors. This issue appears to be similar to [45153](https://github.com/tensorflow/tensorflow/issues/45153). 

I built the two .aar files against the following tensorflow commit:
```
root@8eb4e1fb67bf:/tensorflow_src# git rev-parse HEAD
6ac306c372287e522168da6931fd751203915d46
```

I've attached the two .aar files as well as the demo Android app. I haven't included the model, because the app is crashing before trying to load the model.
[tensorflow-lite-master-20210207-docker.zip](https://github.com/tensorflow/tensorflow/files/5939881/tensorflow-lite-master-20210207-docker.zip)
[AndroidHelloWorld.zip](https://github.com/tensorflow/tensorflow/files/5939884/AndroidHelloWorld.zip)


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
46987,how to find what tensorflow/keras release contains a specific bug fix,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

This is related to a known bug (see below in italics), but I'm trying to figure out how to install a version of tf/keras which has the fix.
**System information**
- OS Platform and Distribution -> Ubuntu 20.0.4
- TensorFlow installed from -> docker tensorflow-gpu 
- TensorFlow version: 2.5.0-dev20210204 from docker tensorflow/tensorflow:nightly-gpu
- Python version: 3.6.9 (default, Oct  8 2020, 12:12:24) \n[GCC 8.4.0]
- Installed usinga  Dockerfile to add some required Python libraries to tensorflow-gpu image
- CUDA/cuDNN version:Cuda compilation tools, release 11.0, V11.0.221
Build cuda_11.0_bu.TC445_37.28845127_0
- GPU model and memory: Nvidia RTX 2080 Ti

I'm training a large (millions of parameters) NN to analyze audio files (speech vs. music).  After 28/50 epochs I hit a known bug which is (to my knowledge) fixed already.  I'm not sure how to find out what tf/keras release the fix is in or if my docker image has the fix.  I'm using a docker image since it was recommended as the easiest way to get version compatibility between tf/keras and CUDA. 

This is the bug description and reference to the fix:

_Tensorflow 2.1 Error âwhen finalizing GeneratorDataset iteratorâ - a memory leak? #37515

URL: https://github.com/tensorflow/tensorflow/commit/e918c6e6fab5d0005fcde83d57e92b70343d3553
Fixing a memory leak in Keras.
Fixes: #37515
PiperOrigin-RevId: 302568217
Change-Id: I28d0eaf3602fea0461901680df24899f135ce649_

"
46986,Run MIRNet and get Segment Fault on Raspberry Pi Model 3B,"Run [MIRNet](https://github.com/sayakpaul/MIRNet-TFLite-TRT) and get Segment Fault on Raspberry Pi Model 3B.
The tflite model I used is from [dynamic_shape](https://github.com/sayakpaul/MIRNet-TFLite/releases/download/v0.1.0/dynamic_shape.zip) and named mirnet_dr.tflite.
Following is the error info from my binary built from [our repo](https://github.com/Duan-JM/edge-brain):
```
#0  0x003648dc in ruy::TrMul(ruy::Ctx*, ruy::TrMulParams*) ()
#1  0x0035fd84 in ruy::MulFrontEndFromTrMulParams(ruy::Ctx*, ruy::TrMulParams*) ()
#2  0x00095c84 in void ruy::MulFrontEnd<(ruy::Path)17, signed char, signed char, int, int>(ruy::Mat<signed char> const&, ruy::Mat<signed char> const&, ruy::MulParams<int, int> const&, ruy::Ctx*, ruy::Mat<int>*) ()
#3  0x00091918 in void ruy::Mul<(ruy::Path)17, signed char, signed char, int, int>(ruy::Matrix<signed char> const&, ruy::Matrix<signed char> const&, ruy::MulParams<int, int> const&, ruy::Context*, ruy::Matrix<int>*) ()
#4  0x0033ba00 in tflite::tensor_utils::NeonCpuBackendGemm(signed char const*, int const*, signed char const*, int, int, int, int, int*, tflite::CpuBackendContext*) ()
#5  0x0033ba88 in tflite::tensor_utils::NeonMatrixBatchVectorMultiplyAccumulate(signed char const*, int, int, signed char const*, float const*, int, int*, float*, tflite::CpuBackendContext*) ()
#6  0x000f0c74 in tflite::optimized_ops::HybridConv(tflite::ConvParams const&, float*, tflite::RuntimeShape const&, signed char const*, tflite::RuntimeShape const&, signed char const*, tflite::RuntimeShape const&, float const*, tflite::RuntimeShape const&, int*, tflite::RuntimeShape const&, float*, tflite::RuntimeShape const&, signed char*, tflite::CpuBackendContext*) ()
#7  0x001088c4 in TfLiteStatus tflite::ops::builtin::conv::EvalHybrid<(tflite::ops::builtin::conv::KernelType)2>(TfLiteContext*, TfLiteNode*, TfLiteConvParams*, tflite::ops::builtin::conv::OpData*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor*, TfLiteTensor*, TfLiteTensor*) ()
#8  0x000fe188 in TfLiteStatus tflite::ops::builtin::conv::EvalImpl<(tflite::ops::builtin::conv::KernelType)2, (TfLiteType)1>(TfLiteContext*, TfLiteNode*) ()
#9  0x000f68dc in TfLiteStatus tflite::ops::builtin::conv::Eval<(tflite::ops::builtin::conv::KernelType)2>(TfLiteContext*, TfLiteNode*) ()
#10 0x00391c6c in tflite::Subgraph::OpInvoke(TfLiteRegistration const&, TfLiteNode*) ()
#11 0x0038e940 in tflite::Subgraph::Invoke() ()
#12 0x0039e354 in tflite::Interpreter::Invoke() ()
#13 0x0001ff24 in mirnet::MIRNet::RunInference(cv::Mat const&, cv::Mat&) ()
#14 0x00020188 in mirnet::MIRNet::EnhanceImage(cv::Mat const&, cv::Mat&) ()
#15 0x0001c5d0 in main ()
```
BTW, it also was crash with minimal.cc examples from tflite repo, please take a check. 
Thanks."
46985,Stateful global metrics with multi-device distribution,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.4.1
- Are you willing to contribute it (Yes/No): Unsure



**Describe the feature and the current behavior/state.**
Assume you want to create a metric which is calculated over the full dataset (i.e. evaluating how good a model is at sorting via some regression problem). On a single GPU you could do this:
```python
import tensorflow as tf
from tensorflow.python.keras.backend import track_variable

class MyCustomGlobalMetric(tf.keras.metrics.Metric):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.y_true = tf.Variable(name='y_true', shape=tf.TensorShape(None), dtype=tf.dtypes.float32,
                                  initial_value=[0.],
                                  validate_shape=False, synchronization=tf.VariableSynchronization.ON_READ,
                                  aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)
        self.y_pred = tf.Variable(name='y_pred', shape=tf.TensorShape(None), dtype=tf.dtypes.float32,
                                  initial_value=[0.],
                                  validate_shape=False, synchronization=tf.VariableSynchronization.ON_READ,
                                  aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)
        self._non_trainable_weights.append(self.y_true)
        self._non_trainable_weights.append(self.y_pred)
        track_variable(self.y_true)
        track_variable(self.y_pred)
        self.was_called = self.add_weight('was_called', initializer=tf.keras.initializers.zeros, dtype=tf.dtypes.uint8,
                                          synchronization=tf.VariableSynchronization.ON_READ,
                                          aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)

    def update_state(self, y_true, y_pred, **kwargs):
        y_true = K.flatten(K.cast(y_true, self.y_true.dtype))
        y_pred = K.flatten(K.cast(y_pred, self.y_true.dtype))
        a = self.y_true.assign(tf.concat([self.y_true, y_true], axis=0))
        b = self.y_pred.assign(tf.concat([self.y_pred, y_pred], axis=0))
        c = self.was_called.assign(1)
        return tf.group(a, b, c)

    def result(self):
        return tf.cond(self.was_called >= 1, lambda: some_custom_metric(self.y_true[1:], self.y_pred[1:]), lambda: 0.)

    def reset_states(self):
        super().reset_states()
        self.y_true.assign(tf.constant([0.]))
        self.y_pred.assign(tf.constant([0.]))
        self.was_called.assign(0)
```
This will store all predictions and labels and calculates `some_custom_metric` for them. But this fails to calculate the correct metric when instantiated and used in a MirroredStrategy scope. Growing the variable shape is a hacky workaround to get this running, but there is no workaround in the first way. None of the `VariableAggregation` options actually make sense when you want to calculate the metric in a global sense on multiple devices.

I'd like to have the possibility to implement a stateful metric which allows me to store all predictions and labels, such that I can calculate some arbitrary metric over them, which should be consistent and correct even if I'm using a MirroredStrategy.

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
46984,STM32F746NG Hello World LCD Display not working correctly,"@tensorflow/micro

**System information**
- Host OSX10.15.7
- TensorFlow installed with homebrew
- Tensorflow version 2.4.1
- Target platform Arm Mbed OS

**Describe the problem**
After the hello world project has compiled, when I copy the mbed.bin file (177Kb) to the STM32F746NG  the LCD screen just goes white. The program is clearly running because if I run screen /dev/tty.usbmodem403 9600 is can see all the correct values scrolling down my terminal window. Also, the hardware is working correctly as if I install the MBED LCD demo https://ide.mbed.com/compiler/#nav:/DISCO-F746NG_LCDTS_demo it runs fine and both the screen display and the capacitative touch work correctly.


"
46983,Hard to use a lstm tflite model.,"I'm interested in lstm models, and I really need one tflite model(other framework like onnx or saved model for me is not acceptable now) include lstm node. But for days, I can ony find one float32 model from https://storage.googleapis.com/download.tensorflow.org/models/tflite/speech_asr_am_model.tflite and it's uint8 model from https://storage.googleapis.com/download.tensorflow.org/models/tflite/speech_asr_am_model_int8.tflite. Other old official models like tts and speakerid models are deprecated. But for my work, the shape info between layers are missing, and for me, it's impossible to infer these shapes before real work. Are there any tools to edit or infer the shape info and regenerate a new tflite model? Or is it just a wrong model? I have taken look at tfhub, tensorflow official website, and tracked with lots of discussions for lstm tflite using google search, but no more models found and not much useful information. And I found that others are also confused with lstm tflite like model convert issues. So what I needs are: 1. usable models. 2. tools like tflite editor or shape inferencer. 3. any update for lstm. 4. is lstm tflite supported or not. Really need help. Thanks."
46982,Unexpected TFDS Shuffling behavior,"dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])
dataset = dataset.shuffle(buffer_size=256)
dataset = dataset.take(1)
print(list(dataset.as_numpy_iterator()))
dataset = dataset.repeat(5)
print(list(dataset.as_numpy_iterator()))

>>> [2]
>>> [1, 2, 3, 3, 2]

Is this on purpose? I was expecting [2, 2, 2, 2, 2], as I would expect the dataset in memory to be replaced with the subset that I took in take(1), rather than now having (I assume) two datasets in memory, the subset dataset + the original dataset.

Thanks =) "
46980,Documentation about convolution padding computation is missing,"## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/nn/convolution?version=nightly

## Description of issue (what needs changing):

The documentation refers to an invalid link, https://tensorflow.org/api_guides/python/nn#Convolution, and the reference to that link is recently deleted in this commit:  https://github.com/tensorflow/tensorflow/commit/271df9ce498f630b6c417087f18b32f2f7446a83 (cc @MarkDaoust ). 

However, I think **the correct action to take is to make an alternative to the invalid link (rather than deleting it)**.

When the link existed in the past, it contains the formula of how padding is computed for convolution, which is obviously a necessary piece of information for users to know and must be in the documentation.


As a reference, I found some [incomplete third-party website](https://tensorflow.juejin.im/api_guides/python/nn.html) that contain the old version of this now-missing page:


![2021-02-06_23-50](https://user-images.githubusercontent.com/1381301/107140355-37990f80-68d6-11eb-9f2f-6c06d3503102.png)
"
46979,why tensorflow has so much ugly designed api?  be pythonic please...,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
46978,Confiuguration error ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Linux Ubuntu 18 with qemu and docker aarch64 image for jetson platform

- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.14.0
- Python version: 3
 
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): gcc (Ubuntu/Linaro 7.5.0-3ubuntu1~18.04) 7.5.0
- CUDA/cuDNN version: 10.2 8
- GPU model and memory: gtx 1070


Hi everyone I have a problem in the configuration phase. When asking for Cuda and cudnn library I get this error:
Traceback (most recent call last):
  File ""third_party/gpus/find_cuda_config.py"", line 497, in <module>
    main()
  File ""third_party/gpus/find_cuda_config.py"", line 489, in main
    for key, value in sorted(find_cuda_config().items()):
  File ""third_party/gpus/find_cuda_config.py"", line 468, in find_cuda_config
    result.update(_find_cudnn_config(cudnn_paths, cudnn_version))
  File ""third_party/gpus/find_cuda_config.py"", line 346, in _find_cudnn_config
    get_header_version)
  File ""third_party/gpus/find_cuda_config.py"", line 235, in _find_header
    required_version, get_version)
  File ""third_party/gpus/find_cuda_config.py"", line 224, in _find_versioned_file
    actual_version = get_version(file)
  File ""third_party/gpus/find_cuda_config.py"", line 342, in get_header_version
    return ""."".join(version)
  File ""third_party/gpus/find_cuda_config.py"", line 341, in <genexpr>
    for name in (""CUDNN_MAJOR"", ""CUDNN_MINOR"", ""CUDNN_PATCHLEVEL""))
  File ""third_party/gpus/find_cuda_config.py"", line 123, in _get_header_version
    for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
  File ""/usr/lib/python3.6/codecs.py"", line 321, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb7 in position 18: invalid start byte
Asking for detailed CUDA configuration...


**Provide the exact sequence of commands / steps that you executed before running into the problem**

Please specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]: /folder_shared/lib64,/usr/local/cuda-10.2/targets/aarch64-linux/include/,/usr/local/cuda-10.2/bin/,/usr/local/cuda-10.2/nvvm/libdevice,/usr/local/cuda-10.2/nvvmx/libdevice,/usr/local/cuda-10.2/nvvmx/libdevice/libdevice.10.bc,/usr/local/cuda-10.2,/usr/include,/folder_shared,/folder_shared/cudnn8/

"
46977,"Is there a error ""DCHECK((ref_.store(0), true));""  of RefCounted::Unref() function.","https://github.com/tensorflow/tensorflow/blob/3db52be7be81a87c623cdeb7f03d3767521c5246/tensorflow/core/lib/core/refcount.h#L103

`DCHECK((ref_.store(0), true));`  shoud convert the ref_'value  to 0. but after run `DCHECK((ref_.store(0), true));`, the ref_'value is still 1.

then, there is a test codeï¼
`#include<iostream>

#include ""tensorflow/core/lib/core/refcount.h""

#include ""tensorflow/core/platform/test.h""

namespace tensorflow {
namespace core {
namespace {
TEST(RefCountTest, UnRefTest) {
  std::atomic_int_fast32_t ref_(1);
  DCHECK((ref_.store(0), true));
  // CHECK(ref_.load() == 0);   //here's check could not passed.
  std::cout << ""ref_value: "" <<  ref_.load(std::memory_order_acquire);
}
}
}
}`

Result:
`Running main() from test_main.cc
   [==========] Running 1 test from 1 test suite.
  [----------] Global test environment set-up.
  [----------] 1 test from RefCountTest
  [ RUN      ] RefCountTest.UnRefTest
  ref_value: 1[       OK ] RefCountTest.UnRefTest (0 ms)
  [----------] 1 test from RefCountTest (0 ms total)
 
  [----------] Global test environment tear-down
  [==========] 1 test from 1 test suite ran. (0 ms total)
[  PASSED  ] 1 test.`
"
46976,Build with clang support is failing,"To reproduce, configure with clang enabled with cuda, i.e.

```
Do you wish to build TensorFlow with ROCm support? [y/N]: n
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: n
No CUDA support will be enabled for TensorFlow.

Do you wish to download a fresh release of clang? (Experimental) [y/N]: y
Clang will be downloaded and used to compile tensorflow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
Not configuring the WORKSPACE for Android builds.
```

Then star building
```
$ bazel build //tensorflow/tools/pip_package:build_pip_package
Starting local Bazel server and connecting to it...
ERROR: Config value 'download_clang' is not defined in any .rc file
```

The generated `.tf_configure.bazelrc` contains:

```
build --action_env PYTHON_BIN_PATH=""/usr/local/bin/python3""
build --action_env PYTHON_LIB_PATH=""/usr/lib/python3.9/site-packages""
build --python_path=""/usr/local/bin/python3""
build --config=xla
build --config=download_clang
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-Wno-sign-compare
build:opt --define with_default_optimizations=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-gpu
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only
build --action_env TF_CONFIGURE_IOS=""0""
```

I didn't find `download_clang` defined as a build config in .bazelrc, guess it might be the reason.

This happens on the master branch with latest commit 57bbc5e0d4b93483b8ae853352173516f1c08018"
46975,tensorflow not working with RTX 3070 cuda 11.1+cudnn 8.0 and 11.2+cudnn 8.1,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

I have first installed cuda 11.1 and cudnn 8.0 but i was getting error could not find file libcusolver.so.10 
to solve this i run command 
sudo ln -s /usr/local/cuda-11.1/lib64/libcusolver.so.11 /usr/local/cuda-11.1/lib64/libcusolver.so.10
error was resolved and showed message 
Successfully opened dynamic library libcusolver.so.10
but now i got another error shown below
I also tried cuda 11.2 and cudnn 8.1 there with the same error could not find file libcusolver.so.10  i am getting error could not find libcudnn.so.8

Please help me i just re installed multiple cuda versions cudnn versions and nvidia drivers but could not resolve the issue

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tensorflow-gpu 
- TensorFlow version (use command below): 2.4.1
- Python version:3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda 11.1 cudnn 8.0
- GPU model and memory: RTX 3070

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

2021-02-07 02:05:18.468688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
x_train shape: (60000, 28, 28, 1)
60000 train samples
10000 test samples
2021-02-07 02:05:19.608268: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-07 02:05:19.608796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-07 02:05:19.636743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-07 02:05:19.637151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: Graphics Device computeCapability: 8.6
coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2021-02-07 02:05:19.637166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-07 02:05:19.638801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-07 02:05:19.638838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-07 02:05:19.639414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-07 02:05:19.639618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-07 02:05:19.835524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-02-07 02:05:19.837327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-07 02:05:19.837692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-02-07 02:05:19.837958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-07 02:05:19.839606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-07 02:05:19.851728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-02-07 02:05:19.852873: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-07 02:05:19.854566: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-07 02:05:19.854939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-07 02:05:19.856558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: Graphics Device computeCapability: 8.6
coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2021-02-07 02:05:19.856623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-07 02:05:19.856695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-07 02:05:19.856746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-07 02:05:19.856795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-07 02:05:19.856844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-07 02:05:19.856893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-02-07 02:05:19.856942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-07 02:05:19.856991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-02-07 02:05:19.857186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-07 02:05:19.858869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-07 02:05:19.860412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-02-07 02:05:19.866190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-07 02:05:22.758155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-07 02:05:22.758203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-02-07 02:05:22.758221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-02-07 02:05:22.758447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-07 02:05:22.759222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-07 02:05:22.759935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-07 02:05:22.760605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6864 MB memory) -> physical GPU (device: 0, name: Graphics Device, pci bus id: 0000:01:00.0, compute capability: 8.6)
2021-02-07 02:05:22.990187: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-07 02:05:23.007092: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz
Epoch 1/12
2021-02-07 02:05:23.350598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-07 02:05:27.235033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-07 02:05:27.282436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-02-07 02:05:29.037626: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2021-02-07 02:05:29.061028: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
Traceback (most recent call last):
  File ""main.py"", line 63, in <module>
    validation_data=(x_test, y_test))
  File ""/home/mohsin/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File ""/home/mohsin/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""/home/mohsin/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 888, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/mohsin/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2943, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File ""/home/mohsin/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1919, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/mohsin/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 560, in call
    ctx=ctx)
  File ""/home/mohsin/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node sequential/conv2d/Conv2D (defined at main.py:63) ]] [Op:__inference_train_function_790]

Function call stack:
train_function


**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46972,How to build tensorflow when making small changes?,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.1
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version:
- GPU model and memory:



I know that I can build tensorflow using the following command:

`bazel build --config=opt -c opt -j 8 //tensorflow/tools/pip_package:build_pip_package`

But this command takes a lot of time and I need to make small changes in the code of tensorflow and check them immediately. How do you build tensorflow while contributing? There must be a faster way. 
  



"
46971,Tensorflow implementation in Julia,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.x
- Are you willing to contribute it (Yes/No):
Yes


**Describe the feature and the current behavior/state.**
Currently, there is no Tensorflow implementation in Julia. Since Julia is the next major upcoming scientific computation language and it is much faster than Python while maintaining similar intuitiveness, I believe that we should have a Julia-version of TF.

**Will this change the current api? How?**
This will not change existing features but will port them over to Julia as well.

**Who will benefit with this feature?**
The entire scientific community will be benefitted as more and more people will start shifting to Julia in the near future, as more and more packages are being developed for it.
**Any Other info.**
"
46970,ValueError: ssd_mobilenet_v2 is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow,"Hi Folks

From last few days I'm working on generating model file for Object Detection using Tensorflow 2.x. I have gone through so many blogs and github repos etc. etc.

With help of them I am able to generate xml -> csv file then test.record / train.record files.

Links which I had gone through are mentioned below
https://teyou21.medium.com/training-your-object-detection-model-on-tensorflow-part-2-e9e12714bdf
https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/
https://medium.com/@marklabinski/installing-tensorflow-object-detection-api-on-windows-10-7a4eb83e1e7b

Now I am at that step where I have to run command to train the record files using label text file.
python train.py --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_quantized_300x300_coco.config

But after running this command in PyCharm I am getting error

![ssd_mobilenet_v2](https://user-images.githubusercontent.com/34931349/107122123-d3695200-68bb-11eb-9ea4-80356801a16f.jpeg)

I searched a lot to solve this issue but not able to find any solution

Operating System: Windows 10 64 bit
Python version: 3.7
Tensorflow version : 2.4.1

Please help me if anyone has any solution for this.
"
46964,Move Tensorflow Lite packages off of Bintray / JCenter due to deprecation of Bintray,"Some Tensorflow packages are on Bintray at https://bintray.com/google/tensorflow, but according to https://jfrog.com/blog/into-the-sunset-bintray-jcenter-gocenter-and-chartcenter/, Bintray (and JCenter) will be unavailable on May 1, 2021. Does this affect Tensorflow's usage of Bintray?

Looking at older issues, I saw a comment https://github.com/tensorflow/tensorflow/issues/30348#issuecomment-533239346 that says that Tensorflow is ""no longer releasing TensorFlow Mobile Android artifacts on Maven"". If the deprecation of Bintray affects Tensorflow, then it would be great if the packages were made available on Maven Central "
46961,tf.data function mapping slower when using tf.GradientTape,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): conda binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: - 
- GPU model and memory: -

**Describe the current behavior**

Mapping a function to a `tf.data.Dataset` is slower, than computing the function directly with the tensor.

The example below is exaggerated, but it represents the issue I have, with less gradients but a more complex function.
Further more, the tf.data mapping uses more memory, which is my main concern.

**Describe the expected behavior**

I would expect both function are compiled and should result in similiar performance and memory usage.

**Standalone code to reproduce the issue**


```py
import tensorflow as tf

@tf.function
def func(r):
    with tf.GradientTape(persistent=True, watch_accessed_variables=False) as tape:
        tape.watch(r)
        out = []
        for idx in range(2000):
            out.append(r**idx)
    grad = []
    for layer in out:
        grad.append(tape.gradient(layer, r))
    return tf.stack(grad)

data = tf.random.normal((100000, 1000))
dataset = tf.data.Dataset.from_tensor_slices(data)
dataset = dataset.batch(2).map(func)

# Compile
iterator = iter(dataset)
_ = next(iterator)
_ = func(data[:2])

%timeit next(iterator)  # 57.5 ms Â± 265 Âµs per loop
%timeit func(data[:2])  # 30 ms Â± 34.9 Âµs per loop
```

Link to [Google Colab](https://colab.research.google.com/drive/1-4TrBifOZDEkdeXWwPAkfp7Q6KIRYHfV?usp=sharing)

"
46960,"TF_LITE_MICRO_EXPECT_NEAR(inf, inf) gives incorrect result for some platforms.","micro/kernels/exp_test.cc checks that two inf values are near eachother:
https://github.com/tensorflow/tensorflow/blob/ed22f400428a669c1c6e4553cd7f4900abeaf954/tensorflow/lite/micro/kernels/exp_test.cc#L67-L72

This works ok for all the CI targets, but broke the xtensa build:
```
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=xtensa OPTIMIZED_KERNEL_DIR=xtensa TARGET_ARCH=fusion_f1 XTENSA_CORE=F1_190305_swupgrade test_kernel_exp_test -j8
```
fails with:
```
Testing SingleDim
expected_output_data[i] (Inf) near output_data[i] (Inf) failed at tensorflow/lite/micro/kernels/exp_test.cc:54
0/1 tests passed
~~~SOME TESTS FAILED~~~
```

The underlying issue that the EXPECT_NEAR_MACRO is taking a difference of two infinities which at least with the xtensa toolchain can give a `nan`, which in turn results in the check failing, even though inf==inf is true:
https://github.com/tensorflow/tensorflow/blob/ed22f400428a669c1c6e4553cd7f4900abeaf954/tensorflow/lite/micro/testing/micro_test.h#L153-L165

"
46958,model train InvalidArgumentError:Input is empty,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4(latest)
- Python version:latest


**Describe the current behavior**
I am about to train the model using the model_main_tf2.py and it seems to show this error and stop. I have tried it on centernet_resnet50_v1_fpn_512x512 and ssd_mobilenet_v2_fpnlite_320x320 and it is the same for both. when I ran this on AWS it did not show any errors but it did not seem to generate any checkpoints either.
**Describe the expected behavior**
Expect it to run without showing any errors

I guess the error is in the tfrecord file but all the paths and the values have been verified.
the code for generating tfrecord
writer = tf.io.TFRecordWriter(outputPath)
        total = 0
        for k in keys:

            encoded = np.asarray(Image.open(k))
            h,w,ch=encoded.shape
            filename = k.split(os.path.sep)[-1]
            encoding = filename[filename.rfind(""."") + 1:]

            image = encoded.tostring() 
            xMins,xMaxs,yMins,yMaxs,textLabels,classes=[],[],[],[],[],[]
            for (label,(startX, startY, endX, endY)) in D[k]:
                endX,endY=endX-startX,endY-startY
                xMin = (startX+endX/2) / w
                xMax = endX / w
                yMin = (startY+endY/2) / h
                yMax = endY / h
                if xMin<0 or xMax<0 or yMin<0 or yMax<0 or xMin>1 or xMax>1 or yMin>1 or yMax>1:
                    continue
                xMins.append(xMin)
                xMaxs.append(xMax)
                yMins.append(yMin)
                yMaxs.append(yMax)
                textLabels.append(label.encode(""utf-8""))
                classes.append(CLASSES[label])

            total += 1

            classes=np.array(classes)            
            example = tf.train.Example(features=tf.train.Features(feature={
           'image/height': int64_feature(h),
           'image/width': int64_feature(w),
           'image/filename': bytes_feature(filename.encode('utf-8')),
           'image/source_id': bytes_feature(filename.encode('utf-8')),
           'image/image_raw': bytes_feature(image),
           'image/format': bytes_feature(encoding.encode('utf-8')),
           'image/object/bbox/xmin': float_list_feature(xMins),
           'image/object/bbox/xmax': float_list_feature(xMaxs),
           'image/object/bbox/ymin': float_list_feature(yMins),
           'image/object/bbox/ymax': float_list_feature(yMaxs),
           'image/object/class/text': bytes_list_feature(textLabels),
           'image/object/class/label': int64_list_feature(classes),
 }))

            writer.write(example.SerializeToString())

        writer.close()

**Other info / logs** 
2021-02-05 23:08:11.056603: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-02-05 23:08:11.056634: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-02-05 23:08:13.273009: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-05 23:08:13.273186: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-02-05 23:08:13.273204: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-02-05 23:08:13.273234: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kingsman-desktop): /proc/driver/nvidia/version does not exist
2021-02-05 23:08:13.274261: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
W0205 23:08:13.275029 140202867857216 cross_device_ops.py:1321] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
I0205 23:08:13.275206 140202867857216 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
INFO:tensorflow:Maybe overwriting train_steps: None
I0205 23:08:13.295096 140202867857216 config_util.py:552] Maybe overwriting train_steps: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0205 23:08:13.295231 140202867857216 config_util.py:552] Maybe overwriting use_bfloat16: False
WARNING:tensorflow:From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/model_lib_v2.py:523: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
W0205 23:08:13.363639 140202867857216 deprecation.py:339] From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/model_lib_v2.py:523: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
INFO:tensorflow:Reading unweighted datasets: ['/home/kingsman/deepl/records/train.tfrecord']
I0205 23:08:13.371121 140202867857216 dataset_builder.py:163] Reading unweighted datasets: ['/home/kingsman/deepl/records/train.tfrecord']
INFO:tensorflow:Reading record datasets for input file: ['/home/kingsman/deepl/records/train.tfrecord']
I0205 23:08:13.371364 140202867857216 dataset_builder.py:80] Reading record datasets for input file: ['/home/kingsman/deepl/records/train.tfrecord']
INFO:tensorflow:Number of filenames to read: 1
I0205 23:08:13.371473 140202867857216 dataset_builder.py:81] Number of filenames to read: 1
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0205 23:08:13.371576 140202867857216 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
W0205 23:08:13.373951 140202867857216 deprecation.py:339] From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
WARNING:tensorflow:From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0205 23:08:13.397681 140202867857216 deprecation.py:339] From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0205 23:08:20.996112 140202867857216 deprecation.py:339] From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
W0205 23:08:24.354368 140202867857216 deprecation.py:339] From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
WARNING:tensorflow:From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0205 23:08:26.214364 140202867857216 deprecation.py:339] From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2021-02-05 23:08:28.723569: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-05 23:08:28.745519: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3400075000 Hz
Traceback (most recent call last):
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/eager/context.py"", line 2113, in execution_mode
    yield
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 733, in _next_internal
    output_shapes=self._flat_output_shapes)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2579, in iterator_get_next
    _ops.raise_from_not_ok_status(e, name)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 6862, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input is empty.
	 [[{{node case/cond/else/_10/case/cond/cond_jpeg/else/_105/case/cond/cond_jpeg/decode_image/DecodeImage}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]] [Op:IteratorGetNext]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""object_detection/model_main_tf2.py"", line 113, in <module>
    tf.compat.v1.app.run()
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""object_detection/model_main_tf2.py"", line 110, in main
    record_summaries=FLAGS.record_summaries)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 566, in train_loop
    unpad_groundtruth_tensors)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 344, in load_fine_tune_checkpoint
    features, labels = iter(input_dataset).next()
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 628, in next
    return self.__next__()
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 632, in __next__
    return self.get_next()
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 663, in get_next
    self._iterators[i].get_next_as_list_static_shapes(new_name))
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 1619, in get_next_as_list_static_shapes
    return self._format_data_list_with_options(self._iterator.get_next())
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py"", line 585, in get_next
    result.append(self._device_iterators[i].get_next())
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 800, in get_next
    return self._next_internal()
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 739, in _next_internal
    return structure.from_compatible_tensor_list(self._element_spec, ret)
  File ""/usr/lib/python3.6/contextlib.py"", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/eager/context.py"", line 2116, in execution_mode
    executor_new.wait()
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/eager/executor.py"", line 69, in wait
    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input is empty.
	 [[{{node case/cond/else/_10/case/cond/cond_jpeg/else/_105/case/cond/cond_jpeg/decode_image/DecodeImage}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]]

"
46957,No registered kernels for SobolSample.,"I tested this on two similar machines (with slightly different versions, apparently)

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS
- TensorFlow installed from (source or binary): pip3 binary
- TensorFlow version (use command below): 2.3.0 and 2.3.1
- Python version: 3.6.8 and 3.8.0
- CUDA/cuDNN version: not relevant
- GPU model and memory: not relevant; but GTX1660Ti and RTX2080Ti

v2.3.0-54-gfcc4b966f1
v2.3.0-rc2-23-gb36436b087

**Describe the current behavior**
`tf.math.sobol_sample(4, 10)` produces following error:
```py
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py"", line 201, in wrapper
    return target(*args, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_ops.py"", line 4846, in sobol_sample
    return gen_math_ops.sobol_sample(dim, num_results, skip, dtype=dtype)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 9280, in sobol_sample
    return sobol_sample_eager_fallback(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 9312, in sobol_sample_eager_fallback
    _result = _execute.execute(b""SobolSample"", 1, inputs=_inputs_flat,
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.NotFoundError: Could not find device for node: {{node SobolSample}} = SobolSample[dtype=DT_FLOAT]
All kernels registered for op SobolSample:
  <no registered kernels>
 [Op:SobolSample]
```

**Describe the expected behavior**
I don't know why this kernel is not registered. It seems the code is there (although I can't validate the correctness of it):
https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/core/kernels/sobol_op.cc#L175

**Standalone code to reproduce the issue**
```py
import tensorflow as tf
tf.math.sobol_sample(4, 10)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46956,TensorFlow custom loss function error- ValueError: No gradients provided for any variable,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Anaconda
- TensorFlow version (use command below): 2.2 gpu
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 7.6.5
- GPU model and memory: NVIDIA Tesla v100

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I have written custom loss function which is Loss(pred,label)= { 0.0 if predâlabel<=0.1, 1.0 elsewhere.

Here is my code: 
'''
comparing_tensor = tf.convert_to_tensor([0.1, 0.1, 0.1])
def custom_loss(y_pred, y_true):
    loss_tensor = tf.raw_ops.Abs(x=y_pred - y_true) # get the abs diff between y_true and y_pred
    boolean_tensor = tf.raw_ops.Greater(x=loss_tensor, y=comparing_tensor) # get a boolean tensor based on Greater operation. Example: [True, False, True] 
    binary_tensor = tf.raw_ops.Cast(x=boolean_tensor, DstT=tf.float32) # convert boolean to bianry tensor Example: [1.0, 0.0, 1.0]
    mean_tensor= tf.raw_ops.Mean(input=binary_tensor, axis=-1) # get mean of binary tensor, 2/3=0.66 
    loss = tf.raw_ops.Reshape(tensor=mean_tensor, shape=(1,1), name=None) # reshape mean tensor to get desired shape
    return loss
'''


The error I am getting is :

ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'dense/kernel:0', 'dense/bias:0', 'x/kernel:0', 'x/bias:0'].
**Describe the expected behavior**
The error should not be there

**Standalone code to reproduce the issue**

Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46954,Makefile fails when setting CO_PROCESSOR=ethos-u,"@tensorflow/micro

make: *** No rule to make target 'tensorflow/lite/micro/tools/make/ext_libs/ethos-u.inc'.  Stop.

**System information**

- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 
- Tensorflow from most recent commit

**Describe the problem**

```
make: *** No rule to make target 'tensorflow/lite/micro/tools/make/ext_libs/ethos-u.inc'.  Stop.
```

**Please provide the exact sequence of commands/steps when you ran into the problem**

 ```
make -f tensorflow/lite/micro/tools/make/Makefile -j8 TARGET=cortex_m_generic TARGET_ARCH=cortex-m55 OPTIMIZED_KERNEL_DIR=cmsis-nn CO_PROCESSOR=ethos-u microlite
```"
46953,Problems with tf.keras.metrics.CategoricalAccuracy?,"Hi

As per the documentation in https://www.tensorflow.org/api_docs/python/tf/keras/metrics/CategoricalAccuracy , I am to understand that this metric is expecting y_true to be one hot encoded. Now, taking an example from the docs:

```
m = tf.keras.metrics.CategoricalAccuracy()
m.update_state([[0, 0, 1], [0, 1, 0]], [[0.1, 0.9, 0.8],[0.05, 0.95, 0]])
m.result().numpy() 
```
This gives me the desired result.
But when I DO NOT one hot encode the y_true data and just use the labels(something for which SparseCategoricalAccuracy is there).
Code shown below:
```
m = tf.keras.metrics.CategoricalAccuracy()
m.update_state([[2], [1]], [[0.1, 0.9, 0.8],[0.05, 0.95, 0]]) 
m.result().numpy()
```
Instead of raising an exception, it gives me a result.
Was this designed intentionally?
If no, can we do something about it cause it'd be really helpful to intimate the user about a possible miss(not one hot encoding the y_true labels) on their part."
46952,Bug reported: Tensorflow GPU version(Cuda) may cause thread blocking when calling scripts across languages.  C#.,"Actually I'm not sure whether it's a bug 'cause I've solved my problem, but i'll still trying to make a report.
1. Basically, I wrote a py script to generate a TFLite model.
2. Trying to run the test code, and worked good.
```python
import threading
from tensorflow import keras
import tensorflow as tf
import numpy as np
import sys
import time
import asyncio

def load_interpreter(model_dir:str):
    interpreter = tf.lite.Interpreter(model_path=model_dir)
    interpreter.allocate_tensors()
    return interpreter
def classify_single_image(img_dir:str, interpreter:tf.lite.Interpreter):
    start_time = time.time()
    img = keras.preprocessing.image.load_img(img_dir, target_size=(160, 160))
    img_array = keras.preprocessing.image.img_to_array(img)
    img_array = np.expand_dims(img_array, 0)
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    interpreter.set_tensor(input_details[0]['index'], img_array)
    interpreter.invoke()
    output_data = np.squeeze(interpreter.get_tensor(output_details[0]['index']))
    probs = tf.nn.softmax(output_data)
    probs = np.round(probs * 100, 2)
    elapsed_time = time.time()
    result = ""{}+{:.2f}"".format(probs, (elapsed_time - start_time) * 1000)
    print(result, flush=True)

interpreter = load_interpreter(""trash_model_lite.tflite"")
threading.Thread(classify_single_image(""1.jpg"", interpreter)).start()
threading.Thread(classify_single_image(""2.jpg"", interpreter)).start()
threading.Thread(classify_single_image(""3.jpg"", interpreter)).start()
threading.Thread(classify_single_image(""4.jpg"", interpreter)).start()
threading.Thread(classify_single_image(""5.jpg"", interpreter)).start()
# å¾æ¾ç¶ï¼å¦æç»§ç»­è¿æ ·å, interpreter ä¸æ¯çº¿ç¨å®å¨ç. éè¦å é. 
```
3. i'm tring to call it in my C# project just by openning python and let it to run the script
4. Problem is that C# cannot get any result, and i'll give the code in the end 'cause this is a tf bug report.
5. i'm trying to see where's the problem, just by print(""n"", flush=True) after every slice of code.
6. The result shows that the tensorflow module will ""BLOCK""(maybe not, but will stop here) the program such as:
```python
    print(""0"", flush=True) # will see 0 in the python console and C# console
    img_array = tf.expand_dims(img_array, 0)
    print(""1"", flush=True) # will see 1 printed in the python console but not in C# console
```
7. trying to avoid tensorflow will exam the hypothesis:
```python
    print(""0"", flush=True) # 0 in python and C#
    img_array = np.expand_dims(img_array, 0)
    print(""1"", flush=True) # 1 in python and C#
......
    probs = tf.nn.softmax(output_data) # still wrong
```
8. I suddenly understand that the tensorflow module might be made a mistake, so i'm tring to install cpu version and get the correct answer by only work with cpu.
```python
import os
os.environ[""CUDA_VISIBLE_DEVICES""]=""-1""
import tensorflow as tf
......
```
9. After delete the print code, i've got the almost same answer in both C# and python, and which is correct after deleting the empty line.
```python
[  0.   0.   0. 100.]+960.62
[9.997e+01 0.000e+00 0.000e+00 2.000e-02]+31.92
[  0. 100.   0.   0.]+35.90
[ 0.35  0.2  41.75 57.7 ]+32.91
[  0.   0. 100.   0.]+33.91
```
```C#
[  0.   0.   0. 100.]+382.50
[9.997e+01 0.000e+00 0.000e+00 2.000e-02]+31.99
[  0. 100.   0.   0.]+31.91
[ 0.35  0.2  41.75 57.7 ]+31.96
[  0.   0. 100.   0.]+32.90
```
10. If i delete the code which forbide the cuda, the C# program will still wrong. So the right thing is to just work on cpu, and i think this maybe a bug( or config problem maybe)

**THESE ARE MY SYSTEM CONFIG:**
OS: Windows 10 from Microsoft
Python: 3.8, download in python.org
Tensorflow: GPU==2.4.1, CPU==2.4.1( installed after the bug became) with tflite, download with pip
Keras: download with TF
IDE or Text Editor: VSCode, Visual Studio
Cuda: 11.0
Cuddn: the right version with cuda 11.0
GPU: Laptop gpu -- MX250
Bazel: No bazel.

Config with C#:
.Net: .Net 5 or .Net Core 3.1
Project: dotnet new Console
Nuget packages: None

C# code :
```C#
using System;
using System.Diagnostics;

namespace ConsoleApp1
{
    class Program
    {
        static void Main(string[] args)
        {
            string[] args_array = new string[2];
            string pyDir = ""test.py"";
            args_array[0] = """";
            args_array[1] = """";
            RunPythonScript(pyDir,"""", args_array);
        }
        public static void RunPythonScript(string sArgName, string args = """", params string[] teps)
        {
            Process p = new Process();
            p.StartInfo.FileName = @""C:/Program Files/Python38/python.exe"";
            string sArguments = sArgName;
            foreach (string sigstr in teps)
            {
                sArguments += "" "" + sigstr;
            }
            sArguments += "" "" + args;
            p.StartInfo.Arguments = sArguments;
            p.StartInfo.UseShellExecute = false;
            p.StartInfo.RedirectStandardOutput = true;
            p.StartInfo.RedirectStandardInput = true;
            p.StartInfo.RedirectStandardError = true;
            p.StartInfo.CreateNoWindow = true;
            p.OutputDataReceived += new DataReceivedEventHandler(p_OutputDataReceived);
            p.Start();
            p.BeginOutputReadLine();
            p.WaitForExit();
            Console.ReadLine();
        }
        static void p_OutputDataReceived(object sender, DataReceivedEventArgs e)
        {
            if (!string.IsNullOrEmpty(e.Data))
            {
                AppendText(e.Data + Environment.NewLine);
            }
        }
        public delegate void AppendTextCallback(string text);
        public static void AppendText(string text)
        {
            Console.WriteLine(text);
        }
    }
}

```
And i hope you could solve your problem like this. That's why i made this report. Have a good time! :) "
46951,Help understand outputs of Mask RCNN tflite model,"Hi, I could really do with some help in understanding the outputs of the tflite model of Mask RCNN.

I have converted the model to tflite using Tensorflow 2.3.

The model takes 3 inputs - the resized image, image meta and anchors

I have written the android equivalent code for the resized image - included padding and subtracted pixel means, as well as the image meta and anchors. The model is running but I can't seem to understand which output stands for what.

There are 7 outputs of the tflite model which have dimensions as follows:

[1][1][1]
[1][1000][81][4]
[1][1000][81]
[1][100][6]
[1][100][28][28][81]
[1][1][4]
[1][1][2]

I assume [1][100][28][28][81] is for the masks and I thought [1][100][6] would be the class ID, probability score and bounding boxes. However that doesn't seem to be consistent with the results. I can share the tflite model and the first few results of the outputs if that helps. Any help would be very much appreciated!"
46950,TensorFlow with DLPack invokes unexpected data transfers,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu-18.04
- TensorFlow installed from (source or binary): binary, TensorFlow official docker image 
- TensorFlow version (use command below): 2.4.1
- Python version: 3.6.9
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: CUDA 11.0
- GPU model and memory: Tesla V100

**Describe the current behavior**
TensorFlow with DLPack invokes unexpected data transfers. For instance, before prediction, TensorFlow transfers the data, allocated by CuPy and wrapped with DLPack to CPU, then transfers data back to GPU, and then starts prediction. This behavior makes DLPack meaningless.

**Describe the expected behavior**
TensorFlow shouldn't transfer the data, allocated by CuPy and wrapped with DLPack to CPU. Instead, it should take the data on GPU directly.

**Standalone code to reproduce the issue**
1. sample code (foo.py):
```python
import cupy as cp
import tensorflow as tf
from tensorflow.keras.layers import Input, Lambda
from tensorflow.keras.models import Model

n = 10000000

a = Input(shape=(n))
output = Lambda(lambda x: x ** 2)(a)
model = Model(a, output)

x = cp.arange(n, dtype=cp.float32).reshape(1, n)
dltensor = x.toDlpack()
x2 = tf.experimental.dlpack.from_dlpack(dltensor)

cp.cuda.nvtx.RangePush('model.predict')
y = model.predict(x2)
cp.cuda.nvtx.RangePop()
print('done')
```

2. pull TensorFlow image
```bash
$ docker pull tensorflow/tensorflow:latest-gpu
```

3. install CuPy
```bash
# after login the container
$ pip install cupy-cuda110
```

4. run:
```
$ nvprof -o output.nvprof python ./foo.py
# or use Nsight-Systems to record behavior
$ nsys profile -t cuda,nvtx python ./foo.py
```
**Other info / logs**
![tf2_with_dlpack](https://user-images.githubusercontent.com/5894445/107031704-96368e80-67ed-11eb-9092-11e669b3853b.png)

"
46949,How to use tflite on bert,"I have convert a trained bert model from .pb to .tfliteã
I have two tasks : 1) sentence pair classification 2) QA on squad2.0 format dataset which need to have more than one outputs.
I have find text classification demo code on normal text classification task, but what should i do to hire tflite on bert.
Wonder that whether tflite BERT needs input_ids, input_mask, input_type_ids, if they are needed, how to make that kind of input to tflite interpreter.
Thanks"
46948,keras LSTM model - a tf 1.15 equivalent that works with tflite,"Hello

**TLDR**: How to implement this model using `tf.lite.experimental.nn.TFLiteLSTMCell, tf.lite.experimental.nn.dynamic_rnn`instead `keras.layers.LSTM`?
![image](https://user-images.githubusercontent.com/26148975/107017531-eab71b00-67a7-11eb-9a92-b161b49f439b.png)

I have this network in keras:
```python
inputs = keras.Input(shape=(1, 52))
state_1_h = keras.Input(shape=(200,))
state_1_c = keras.Input(shape=(200,))
x1, state_1_h_out, state_1_c_out = layers.LSTM(200, return_sequences=True, input_shape=(sequence_length, 52),
                                               return_state=True)(inputs, initial_state=[state_1_h, state_1_c])
output = layers.Dense(13)(x1)

model = keras.Model([inputs, state_1_h, state_1_c],
                    [output, state_1_h_out, state_1_c_out])
```

I need to implement it in tensorflow 1.15, but in a way that will be compatible with tflite 1.15.
** It means that I cannot use `keras.layers.LSTM` because it is not compatible with tflite 1.15. **

Following this examples, I saw the tutorial: https://github.com/tensorflow/tensorflow/tree/r1.15/tensorflow/lite/experimental/examples/lstm
https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/lite/experimental/examples/lstm/TensorFlowLite_LSTM_Keras_Tutorial.ipynb 

Which explains how to implement LSTM in a way that is compatible with tflite 1.15. 
I understand I need to use the following layers: `tf.lite.experimental.nn.TFLiteLSTMCell, tf.lite.experimental.nn.dynamic_rnn`

The hard part is this line:
```python
x1, state_1_h_out, state_1_c_out = layers.LSTM(200, return_sequences=True, input_shape=(sequence_length, 52),
                                               return_state=True)(inputs, initial_state=[state_1_h, state_1_c])

```

How can I implement it? 

The [dynamic_rnn documentation](https://www.tensorflow.org/api_docs/python/tf/compat/v1/lite/experimental/nn/dynamic_rnn) explains how to provide initial state to the dynamic rnn. 

I try to use it in the `buildLstmLayer` function provided (that should implement LSTM): 

```python
def buildLstmLayer(inputs, num_layers, num_units):
  """"""Build the lstm layer.

  Args:
    inputs: The input data.
    num_layers: How many LSTM layers do we want.
    num_units: The unmber of hidden units in the LSTM cell.
  """"""
  lstm_cells = []
  for i in range(num_layers):
    lstm_cells.append(
        tf.lite.experimental.nn.TFLiteLSTMCell(
            num_units, forget_bias=0, name='rnn{}'.format(i)))
  lstm_layers = tf.keras.layers.StackedRNNCells(lstm_cells)
  # Assume the input is sized as [batch, time, input_size], then we're going
  # to transpose to be time-majored.
  transposed_inputs = tf.transpose(
      inputs, perm=[1, 0, 2])
  outputs, _ = tf.lite.experimental.nn.dynamic_rnn(
      lstm_layers,
      transposed_inputs,
      dtype='float32',
      time_major=True)
  unstacked_outputs = tf.unstack(outputs, axis=0)
  return unstacked_outputs[-1]
```

I try to take this code:
```python
  outputs, _ = tf.lite.experimental.nn.dynamic_rnn(
      lstm_layers,
      transposed_inputs,
      dtype='float32',
      time_major=True)
```
And add initial state.

This try
  ```python
outputs, _ = tf.lite.experimental.nn.dynamic_rnn(
      lstm_layers,
      transposed_inputs,
      dtype='float32',
      time_major=True,
      initial_state=[tf.compat.v1.placeholder(tf.float32, shape=(200)), tf.compat.v1.placeholder(tf.float32, shape=(200))])
```
returns error `ValueError: Shape must be rank 2 but is rank 1 for 'stacked_rnn_cells/concat' (op: 'ConcatV2') with input shapes: [?,28], [200], [].
`

This try:
```python
  outputs, _ = tf.lite.experimental.nn.dynamic_rnn(
      lstm_layers,
      transposed_inputs,
      dtype='float32',
      time_major=True,
      initial_state=[tf.compat.v1.placeholder(tf.float32, shape=(1, 200)), tf.compat.v1.placeholder(tf.float32, shape=(1, 200))])
```
returns error `ValueError: Dimensions must be equal, but are 228 and 92 for 'stacked_rnn_cells/MatMul' (op: 'MatMul') with input shapes: [1,228], [64,92].
`

How can I solve it?

Thank you"
46947,Mobilenet parameters: alpha & rho,"Hello, my name is Joy and I've been learning about PoseNet in order to use it in my health-related research work.
I was impressed how mobilenet enables to keep high accuracy while reducing CPU (or GPU/NPU) dependency by adapting few parameters where my questions sprouted.
I've noticed that in mobilenet official papers, there were two multipliers introduced: alpha and rho. I'll skip the explanation of both parameters. 
I wonder what is the each value of alpha and rho for the mobilenet for the newest pretrained PoseNet model. Also, I'm wondering if there is a guideline for parameters(especially alpha and rho) tuning, and how the values of both are set and validated before training the model.
Thank you."
46944,Unable to create functional model as slice from internal layer output if it is a Sequential model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Colab default
- TensorFlow version (use command below): v2.4.1-0-g85c8b2a817f 2.4.1
- Python version: 3 (Colab default)
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: No
- GPU model and memory: No

**Describe the current behavior**
I'm trying to create feature extractor for semantic segmentation model like here https://www.tensorflow.org/tutorials/images/segmentation
But my pretrained backbone built with combination of custom layers and sequential models (used as layer). Particularly it is BiT-S model from here https://github.com/google-research/big_transfer/blob/master/bit_tf2/models.py

During the feature extraction i got a `Graph disconnected` error every time i try to use Sequetial-layer output in new model.

**Describe the expected behavior**
There should be no error

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1hg4RJtux1md5zJErzG7RDCQg0ye5cmFi?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```python
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-5-6cce9314b5b2> in <module>()
----> 1 ext3_model = tf.keras.Model(inputs=funct_model.inputs, outputs=funct_model.get_layer(name='block2').output)

4 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    515     self._self_setattr_tracking = False  # pylint: disable=protected-access
    516     try:
--> 517       result = method(self, *args, **kwargs)
    518     finally:
    519       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in __init__(self, inputs, outputs, name, trainable, **kwargs)
    118     generic_utils.validate_kwargs(kwargs, {})
    119     super(Functional, self).__init__(name=name, trainable=trainable)
--> 120     self._init_graph_network(inputs, outputs)
    121 
    122   @trackable.no_automatic_dependency_tracking

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    515     self._self_setattr_tracking = False  # pylint: disable=protected-access
    516     try:
--> 517       result = method(self, *args, **kwargs)
    518     finally:
    519       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in _init_graph_network(self, inputs, outputs)
    202     # Keep track of the network's nodes and layers.
    203     nodes, nodes_by_depth, layers, _ = _map_graph_network(
--> 204         self.inputs, self.outputs)
    205     self._network_nodes = nodes
    206     self._nodes_by_depth = nodes_by_depth

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in _map_graph_network(inputs, outputs)
    988                              'The following previous layers '
    989                              'were accessed without issue: ' +
--> 990                              str(layers_with_complete_input))
    991         for x in nest.flatten(node.outputs):
    992           computable_tensors.add(id(x))

ValueError: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 10), dtype=tf.float32, name='conv2d_2_input'), name='conv2d_2_input', description=""created by layer 'conv2d_2_input'"") at layer ""conv2d_2"". The following previous layers were accessed without issue: []
```"
46943,Reagarding discripency in tensorboard validation accuracy and the one printed during training,"When I am running a random search for hyperparameter tunning. The accuracies appearing on print screen for training and validation sets are different which is not appearing in tensorboard. In tensorboard the validation accuracy always appears lesser than the print value.

![image](https://user-images.githubusercontent.com/37747800/106998754-040d9680-67ab-11eb-8833-0ed9b6b7bf4c.png)
![image](https://user-images.githubusercontent.com/37747800/106998902-40d98d80-67ab-11eb-9713-f9e4efba3a5a.png)

The accuracy appearing are different. Why?"
46941,tf.keras.backend.random_normal segfault ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.keras.backend.random_normal` crashes(segfault) when `dtype` is integer

**Describe the expected behavior**
expect an exception message if the file format is incorrect instead of crash

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.keras.backend.random_normal(shape=np.ones((1)), mean=np.ones((1)), dtype=20)
~~~
Output:
~~~
Segmentation fault (core dumped)
~~~"
46939,tf.nn.depth_to_space crash(aborts) with block_size is large,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.nn.depth_to_space` crash(aborts) with `block_size` is large

**Describe the expected behavior**
expect an exception message if the file format is incorrect instead of crash

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.nn.depth_to_space(input=np.ones((4, 1, 1, 1)), block_size=2147483647)
~~~

Output:
~~~python
2021-02-05 00:28:12.102761: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-02-05 00:28:12.108864: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -17179869180)
Aborted (core dumped)
~~~"
46938,`tf.random.learned_unigram_candidate_sampler` crashes(abort) when `range_max` is large,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.random.learned_unigram_candidate_sampler` crashes(abort) when `range_max` is large

**Describe the expected behavior**
expect an exception message if the file format is incorrect instead of crash


**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.random.learned_unigram_candidate_sampler(true_classes=np.ones((1,1)), num_true=1, num_sampled=1, unique=True, range_max=3118649543)
~~~

Output:
~~~python
2021-02-04 23:02:12.013481: F tensorflow/core/lib/random/weighted_picker.cc:27] Check failed: N >= 0 (-1176317753 vs. 0)
Aborted (core dumped)
~~~"
46937,Initialization of global pointer variable seems suspect with our current use of Renode.,"@tensorflow/micro

I hit this issue while working on https://github.com/tensorflow/tensorflow/pull/46904:

 * If I create a global pointer variable (explicitly initialized to nullptr) and check for the variable == nullptr in my factory function, the check always returns false.

AFAICT, this behavior is specific to our use of Renode. I have not been able to reproduce on Linux or with the Xtensa simulator.

I have a workaround that should allow #46904 to be merged and I will then update this issue with a cleaner way to reproduce this error."
46936,Cannot create mbed folder,"**System information**
- OS Platform and Distribution Windows 10
- Mobile device STM32F746

When I run the command:
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed TAGS=""CMSIS disco_f746ng"" generate_hello_world_mbed_project

I get the following error message:
/Makefile:61: *** The TAGS command line option is no longer supported in the TFLM Makefile..  

"
46935,Tensorflow GPU Not Recognizing GPUs,"**System information**
- Windows 10 Pro 19042.746
- TensorFlow installed from conda/pip
- TensorFlow version: 2.3.0
- TensorFlow GPU version: 2.3.0
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11.2 as of 2/4/2021
- GPU model and memory: TITAN RTX 303MiB / 24576MiB
- GPU model and memory: GeForce GTX 1070 Ti 1720MiB /  8192MiB


_tflow_select             2.3.0                       gpu
tensorboard               2.3.0              pyh4dce500_0
tensorboard-plugin-wit    1.6.0                      py_0
tensorflow                2.3.0           mkl_py38h8557ec7_0
tensorflow-base           2.3.0           eigen_py38h75a453f_0
tensorflow-estimator      2.3.0              pyheb71bc4_0
tensorflow-gpu            2.3.0                he13fc11_0


The GPUs are not displayed when querying with list_local_devices() and they are used when explicitly declaring them to be used in  with tf.device('GPU:1'). Yet, tensorflow does not complain when I reference the GPU devices, but the GPUs do not show any load whatsoever during LSTM evaluation.
```
>>> from tensorflow.python.client import device_lib
>>> print(device_lib.list_local_devices())
2021-02-04 11:37:27.094309: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[name: ""/device:CPU:0""
device_type: ""CPU""
memory_limit: 268435456
locality {
}
incarnation: 18092632807336689748
]
```
Did the following commands to verify:
```
>>> from tensorflow.python.client import device_lib
>>> print(device_lib.list_local_devices())
```
Output from nvidia-smi:

```
Thu Feb  4 11:38:59 2021
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 461.09       Driver Version: 461.09       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  TITAN RTX          WDDM  | 00000000:1B:00.0 Off |                  N/A |
| 41%   29C    P8    16W / 280W |    303MiB / 24576MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 107... WDDM  | 00000000:68:00.0  On |                  N/A |
|  0%   38C    P8    10W / 180W |   1720MiB /  8192MiB |      4%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
```"
46934,Cannot Install Tensorflow on any version of Python 3.8,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64-bit
- TensorFlow installed from (source or binary): Cannot Install
- TensorFlow version: NaN
- Python version: 3.8, 3.8.7, 3.9, 3.9.1 (All 64-bit)
- Installed using virtualenv? pip? conda?: pip via venv




**Describe the problem**
Cannot install tensorflow. tried on all the above mentioned python version. Yes it is a 64-bit installation. 
**Provide the exact sequence of commands / steps that you executed before running into the problem**
Tried:
pip install tensorflow
pip install --upgrade tensorflow
pip install --upgrade ALL_URLS_FOR_WINDOWS
py -m ALL_ABOVE_COMMANDS

"
46933,Ubuntu 20.10 and 3090 with CUDA 11.0 and cuDNN 8.0: ptxas fatal   : Value 'sm_86' is not defined for option 'gpu-name',"

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.10
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.4.1
- Python version: 3.8.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: 11.0.3/8.0.5.39
- GPU model and memory: GeForce RTX 3090 24GB



**Describe the problem**

I just set up a new deep learning station with Ubuntu 20.10 and a GeForce RTX 3090. I am receiving a very large number of warnings in the form of:

```
2021-02-04 08:52:12.943009: W tensorflow/stream_executor/gpu/asm_compiler.cc:235] Your CUDA software stack is old. We fallback to the NVIDIA driver for some compilation. Update your CUDA version to get the best performance. The ptxas error was: ptxas fatal   : Value 'sm_86' is not defined for option 'gpu-name'
```

I followed the instructions in:
* https://www.tensorflow.org/install/gpu
* https://www.tensorflow.org/install/source#gpu
(though the instructions are not updated since Ubuntu 18.04)

To build a setup with
* Tensorflow 2.4.1
* NVIDIA GPU driver: 460.32.03
* CUDA toolkit: 11.0.3
* cuDNN: 8.0.5.39


**Provide the exact sequence of commands / steps that you executed before running into the problem**
``` bash 
sudo apt -y install build-essential
sudo apt -y install gcc-8 g++-8 gcc-9 g++-9

sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 8 --slave /usr/bin/g++ g++ /usr/bin/g++-8
sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 9 --slave /usr/bin/g++ g++ /usr/bin/g++-9

sudo update-alternatives --config gcc # select gcc-8 option (1)
gcc --version # to check it is gcc 8

# Get CUDA Toolkit
# TF 2.4.0 compatibel with cuDNN 8.0 and CUDA 11.0
wget https://developer.download.nvidia.com/compute/cuda/11.0.3/local_installers/cuda_11.0.3_450.51.06_linux.run
sudo bash cuda_11.0.3_450.51.06_linux.run # Deslect CUDA driver and install
# Add the following to the bashrc file
export PATH=$PATH:/usr/local/cuda-11.0/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.0/lib64

# Get cuDNN package
tar -xvf cudnn-11.0-linux-x64-v8.0.5.39.tgz
sudo cp cuda/include/cudnn.h /usr/local/cuda/include
sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64
sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*
nvcc --version
nvidia-smi
python -c ""import tensorflow as tf; tf.config.list_physical_devices('GPU')""
```

"
46931,MultiWorkerMirroredStrategy() hanging,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**

I have access to two computers and below give the info for both. 

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Computer 1: Windows 10, Computer 2: Windows 10
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.4.1 on both machines
- Python version: 3.8.5 on both machines
- Installed using virtualenv? pip? conda?: For both:  Installed using pip install tensorflow-gpu after manually installing the appropriate Nvidia driver, coda toolkit, cudnn versions.
- CUDA/cuDNN version: CUDA 11.0 and cuDNN 8.0.4. Also both computers have an NVIDIA driver of 450x or higher
- GPU model and memory: Computer 1: NVIDIA Quadro P2000 (GPU memory of 36.8 GB), Computer 2: NVIDIA Quadro P5000 (GPU memory of 79.9 GB)

Note: the CUDA, cuDNN were installed on each machine manually, I am not using docker.

**Describe the problem**

In case this might be an issue/helps to know, I am on a Mac remoting into my work's computer (Computer 1) using Microsoft Remote Desktop. From Computer 1 (Windows OS), I am remoting into Computer 2 (Windows OS as well) using Remote Desktop Connection (the GUI for RDP -- so not using ssh). Both these computers have a GPU as specified above and want to use them to create a two node distributed training job using tensorflow's distribute.multiworkermirroredstrategy. I believe my issue is that I do not understand if the nodes can communicate with each other.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Below is my script ""worker.py""

```python
def create_model():
    model = Sequential()
    model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(T, D)))
    model.add(TimeDistributed(Dense(1, activation='relu')))
    return model


if __name__ == ""__main__"":

    random.set_seed(1)

    parser = argparse.ArgumentParser()

    # inputs for setting environment variable
    parser.add_argument('-node1', default=None, required=True, help='Node 1 IP and port')
    parser.add_argument('-node2', default=None, required=True, help='Node 2 IP and port')
    parser.add_argument('-type', default=None, required=True, help='Node type')
    parser.add_argument('-index', default=None, required=True, help='Node number', type=int)

    args = parser.parse_args()
    node_1 = args.node1
    node_2 = args.node2
    worker_type = args.type
    worker_index = args.index

    # set environment variable
    os.environ['TF_CONFIG'] = json.dumps({
        'cluster': {
            ""worker"": [node_1, node_2]
        },
        'task': {'type': worker_type, 'index': worker_index}
    })

    # load data
    with open('data/X.json', 'rb') as f:
        X = pickle.load(f)

    with open('data/y.json', 'rb') as f:
        y = pickle.load(f)

    # split data, set random state (for replicability)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
    _, T, D = X_train.shape

    # dynamic memory allocation
    # gpu = config.experimental.list_physical_devices('GPU')
    # config.experimental.set_memory_growth(gpu[0], True)

    # set training strategy
    strategy = distribute.MultiWorkerMirroredStrategy( )
    print(f""Number of devices: {strategy.num_replicas_in_sync}"")

    num_epochs = 10000
    batch_size_per_replica = 64
    batch_size = batch_size_per_replica * strategy.num_replicas_in_sync

    # create data structure
    train_data = data.Dataset.from_tensor_slices((X_train, y_train))
    val_data = data.Dataset.from_tensor_slices((X_test, y_test))

    train_data = train_data.batch(batch_size, drop_remainder=True)
    val_data = val_data.batch(batch_size, drop_remainder=True)

    # Disable AutoShard.
    # options = data.Options()
    # options.experimental_distribute.auto_shard_policy = data.experimental.AutoShardPolicy.OFF
    # train_data = train_data.with_options(options)
    # val_data = val_data.with_options(options)

    with strategy.scope():
        model = create_model()
        model.compile(
            loss='mse',
            optimizer='adam',
            metrics=[metrics.RootMeanSquaredError()],
        )

    # fit
    model.fit(
        train_data,
        epochs=num_epochs,
        validation_data=val_data,
        # callbacks=[cp_callback, es_callback, tbd_callback]
    )

    # save
    # model.save('model/model.h5')
```

From the documentation, I understand that this script has to be run on all machines (in my case 2) and set the TF_CONFIG environment variable correctly on both machines. And so I am doing:

Command line machine 1: python worker.py -node1 172.31.15.60:8081 -node2 172.31.15.132:8081 -type worker -index 0
 
Command line machine 2:  python worker.py -node1 172.31.15.60:8081 -node2 172.31.15.132:8081 -type worker -index 1

Once I run the above command I see the following on machine 1:

```
2021-02-04 10:24:32.161847: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-04 10:24:32.171344: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2021-02-04 10:24:32.206509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:65:00.0 name: Quadro P2000 computeCapability: 6.1
coreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 130.53GiB/s
2021-02-04 10:24:32.213804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-02-04 10:24:32.233653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-02-04 10:24:32.237158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-02-04 10:24:32.247535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-02-04 10:24:32.254801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-02-04 10:24:32.270340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-02-04 10:24:32.278635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-02-04 10:24:32.284876: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-02-04 10:24:32.288053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-02-04 10:24:32.291911: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-04 10:24:32.300368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:65:00.0 name: Quadro P2000 computeCapability: 6.1
coreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 130.53GiB/s
2021-02-04 10:24:32.305947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-02-04 10:24:32.309708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-02-04 10:24:32.312512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-02-04 10:24:32.315162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-02-04 10:24:32.317685: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-02-04 10:24:32.320235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-02-04 10:24:32.323467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-02-04 10:24:32.326515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-02-04 10:24:32.329607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-02-04 10:24:32.868210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-04 10:24:32.871587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0
2021-02-04 10:24:32.873963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N
2021-02-04 10:24:32.876398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3835 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:65:00.0, compute capability: 6.1)
2021-02-04 10:24:32.883411: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-04 10:24:32.889654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:65:00.0 name: Quadro P2000 computeCapability: 6.1
coreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 130.53GiB/s
2021-02-04 10:24:32.896221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-02-04 10:24:32.900555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-02-04 10:24:32.903795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-02-04 10:24:32.906767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-02-04 10:24:32.909681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-02-04 10:24:32.912606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-02-04 10:24:32.916783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-02-04 10:24:32.920150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-02-04 10:24:32.923249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-02-04 10:24:32.925742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-04 10:24:32.928836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0
2021-02-04 10:24:32.932095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N
2021-02-04 10:24:32.934222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:0 with 3835 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:65:00.0, compute capability: 6.1)
2021-02-04 10:24:32.939752: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-04 10:24:32.948503: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 ->  172.31.15.60:8081, 1 -> 172.31.15.132:8081}
2021-02-04 10:24:32.953737: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://172.31.15.60:8081
```

And see the same similar things on machine 2, essentially hanging at ""Started server with target: grpc://172.31.15.132:8081.""

I am not sure what the issue could be? Could it be related to the ports, I chose 8081? Is it installation-wise? I have tried many things suggested on GitHub and none seem to work. Could firewalls, very secure networks be causing this issue?

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Per one of the GitHub issues I added the environment variable GRPC_VERBOSITY=DEBUG on machine 1 and got back from the command line 
D0204 10:40:31.617000000  8780 external/com_github_grpc_grpc/src/core/ext/filters/client_channel/resolver/dns/native/dns_resolver.cc:314] Using native dns resolver
I0204 10:40:31.624000000  8780 external/com_github_grpc_grpc/src/cpp/server/server_builder.cc:332] Synchronous server. Num CQs: 1, Min pollers: 1, Max Pollers: 2, CQ timeout (msec): 10000

"
46930,Subgraph search & replace (graph surgery),"TensorFlow version (you are using): 2.4
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
I would like to be able to do subgraph search & replace of models, basically to replace some block of operators by others automatically.
Currently there is no way to iterate over the graph with a standard graph traversal, making it hard/impossible to perform automatic subgraph search & replace.

**Will this change the current api? How?**
Not necessarily, Pytorch is developping torch.fx for doing something similar (in 1.8 alpha)

**Who will benefit with this feature?**
Businesses wanting to write custom framework on top of tensorflow for automatic model modifications taylored to their needs.

**Any Other info.**
"
46929,Possible bug: tf2 raise `OverflowError: Python int too large to convert to C long` for `feature_column.crossed_column`,"**System information**
window 10 python 3.7.9 tf 2.3.x cpu/gpu, for tf-gpu, cuda 10.1 

**Describe the current behavior**
This is my code
```
import tensorflow as tf
from tensorflow.keras import layers
# import pandas as pd

data = {
    ""feat"": [0,1,2],
    ""gender"": [""f"", ""f"", ""m""]
}


feat_c = tf.feature_column.categorical_column_with_identity(
    ""feat"", 3
)

gender_c = tf.feature_column.categorical_column_with_vocabulary_list(
    ""gender"", ['f', 'm']
)

feat = tf.feature_column.indicator_column(feat_c)
gender = tf.feature_column.indicator_column(gender_c)

feat_gender_cross_c = tf.feature_column.crossed_column(
    [feat_c, gender_c], 5
)

feat_gender_cross = tf.feature_column.indicator_column(feat_gender_cross_c)

feature_columns = [feat_gender_cross]

dense = layers.DenseFeatures(feature_columns)
print(dense(data))
```  

Error msg from `dense(data)`:    
```
Traceback (most recent call last):
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\keras\feature_column\dense_features.py"", line 167, in call
    transformation_cache, self._state_manager, training=training)
TypeError: get_dense_tensor() got an unexpected keyword argument 'training'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 2353, in get
    self, state_manager, training=training)
TypeError: transform_feature() got an unexpected keyword argument 'training'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 2353, in get
    self, state_manager, training=training)
TypeError: transform_feature() got an unexpected keyword argument 'training'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""e:/test.py"", line 32, in <module>
    print(dense(data))
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 985, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\keras\feature_column\dense_features.py"", line 170, in call
    self._state_manager)
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 4158, in get_dense_tensor
    return transformation_cache.get(self, state_manager)
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 2355, in get
    transformed = column.transform_feature(self, state_manager)
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 4095, in transform_feature
    transformation_cache, state_manager)
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 3952, in get_sparse_tensors
    transformation_cache.get(self, state_manager), None)
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 2355, in get
    transformed = column.transform_feature(self, state_manager)
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 3913, in transform_feature
    hash_key=self.hash_key)
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\ops\sparse_ops.py"", line 677, in sparse_cross_hashed
    name=name)
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\ops\sparse_ops.py"", line 756, in _sparse_cross_internal
    name=name)
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\ops\gen_sparse_ops.py"", line 1068, in sparse_cross
    internal_type=internal_type, name=name, ctx=_ctx)
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\ops\gen_sparse_ops.py"", line 1146, in sparse_cross_eager_fallback
    attrs=_attrs, ctx=ctx, name=name)
  File ""D:\Python\Python37\lib\site-packages\tensorflow\python\eager\execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
OverflowError: Python int too large to convert to C long
```   


I test above code  with tf2.3.x -cpu/gpu tf2.4-cpu on windows (and window server), they all give me same error. But on linux, it runs well
"
46928,Cannot run LSTM in tensorflow lite 1.15 ,"Hello.

**TLDR**: Can someone show how to create LSTM, convert it to TFLite, and run it in android version 1.15?

I am trying to create a simple LSTM model and run in in android application with tensorflow v115.

** It is the same case when using GRU and SimpleRNN layers **

# Creating simple LSTM model
I am working in Python, trying two tensorflow and keras versions: LATEST (2.4.1 with built-in keras), and 1.1.5 (and I install keras version 2.2.4). 

I create this simple model:
```python
model = keras.Sequential()
model.add(layers.Embedding(input_dim=1000, output_dim=64))
model.add(layers.LSTM(128))
model.add(layers.Dense(10))
model.summary()
```

# Saving it 
I save it in both ""SavedModel"" and ""h5"" format:
```python
model.save(f'output_models/simple_lstm_saved_model_format_{tf.__version__}', save_format='tf')
model.save(f'output_models/simple_lstm_{tf.__version__}.h5', save_format='h5')
```

# Converting to TFLite
I try create & save the model in both v115 and v2 versions. 

Then, I try to convert it to TFLite in several methods.

In TF2: 
1. I try to convert from keras model:
```python
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open(f""output_models/simple_lstm_tf_v{tf.__version__}.tflite"", 'wb') as f:
    f.write(tflite_model)
```

2. I try to convert from saved model:
```python
converter_saved_model = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)
tflite_model_from_saved_model = converter_saved_model.convert()
with open(f""{saved_model_path}_converted_tf_v{tf.__version__}.tflite"", 'wb') as f:
    f.write(tflite_model_from_saved_model)
```

3. I try to convert from keras saved model (h5) - I try to use **both** tf.compat.v1.lite.TFLiteConverter and tf..lite.TFLiteConverter. 
```python
converter_h5 = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(h5_model_path)
# converter_h5 = tf.lite.TFLiteConverter.from_keras_model_file(h5_model_path) # option 2
tflite_model_from_h5 = converter_h5.convert()
with open(f{h5_model_path.replace('.h5','')}_converted_tf_v1_lite_from_keras_model_file_v{tf.__version__}.tflite"", 'wb') as f:
f.write(tflite_model_from_h5)
```

# Android Application
### build.gradle (Module: app)
When I want to use v2, I use:
```
    implementation 'org.tensorflow:tensorflow-lite-task-vision:0.0.0-nightly'
    implementation 'org.tensorflow:tensorflow-lite-task-text:0.0.0-nightly'
```
When I want to use v115, I use `implementation 'org.tensorflow:tensorflow-lite:1.15.0'`
in the build grade. 

Then, I follow common tflite loading code in android:

```java
private MappedByteBuffer loadModelFile(Activity activity) throws IOException {

        AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(getModelPath());
        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());
        FileChannel fileChannel = inputStream.getChannel();
        long startOffset = fileDescriptor.getStartOffset();
        long declaredLength = fileDescriptor.getDeclaredLength();
        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);
    }

    LoadLSTM(Activity activity) {
        try {
            tfliteModel = loadModelFile(activity);
        } catch (IOException e) {
            e.printStackTrace();
        }
        tflite = new Interpreter(tfliteModel, tfliteOptions);
        Log.d(TAG, ""*** Loaded model *** "" + getModelPath());
    }
```

When I use v2, the model is loaded.
When I use the v115, in ALL of the options i've tried, I receive errors as the following:
`A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x70 in tid 17686 (CameraBackgroun), pid 17643 (flitecamerademo)
`

I need a simple outcome - create LSTM and make it work in android v115. 

What am I missing? Thanks"
46927,PPO implementation does not converge,"I'm not sure whether the problem is implementation / tensorflow specific. Following this [repo](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail) as a reference, I re-implemented the same thing over and over for like 5 times in different ways. Every single time, I end up with the same results, despite the code is almost identical to the pytorch implementation. Here's a colab [notebook](https://colab.research.google.com/drive/1rvCYd9xJDQNAutpAHUBYc42ElHCXWNNd?usp=sharing) containing the full code. If anyone can help me fix the issue, I'd really be very grateful. 
"
46926,Output range changes when converted to TFLite,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installation (pip package or built from source): Pip package
- TensorFlow library (version, if pip package or github SHA, if built from source): TF 1.14

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

#### Code A: Tensorflow to TFLite conversion


```
def save(self):
        
        graph = tf.get_default_graph()
        with graph.as_default():
        if self.quant == True:
           tf.contrib.quantize.create_eval_graph()

        out_def = graph.as_graph_def()
        with tf.gfile.GFile(self.out_graph, 'wb') as f:
            f.write(out_def.SerializeToString())

def freeze(self):
        checkpoint = os.path.join(self.checkpoint_dir, 'Model%d' % self.trial)
        ckpt= tf.train.get_checkpoint_state(checkpoint)
        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)
        ckpt_path = os.path.join(checkpoint, ckpt_name)

        self.out_name = 'output'
        freeze_graph.freeze_graph(self.out_graph,'',True,ckpt_path, self.out_name, restore_op_name='save/restore_all', filename_tensor_name='save/Const:0' , initializer_nodes='', output_graph= self.fr_graph ,clear_devices=True)


def convert(self):
        print(self.fr_graph)
        converter= tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file= self.fr_graph, input_arrays= ['input'],\
                                                  input_shapes= {'input': self.input_shape}, output_arrays=[self.out_name])
        
        if self.quant == True:
            in_array = converter.get_input_arrays()
            converter.quantized_input_stats = {in_array[0] : (0, 1)}  # mean, std_dev (input range is [-1, 1])

            converter.inference_type = tf.uint8

            tflite_model = converter.convert()
            print('Save the model.')

            with open('int_qat_%d.tflite'%self.trial, 'wb') as f:
                f.write(tflite_model)

```

#### Option B:  TFLite inference code

```
def run_tflite(modelpath, labelpath, datapath, trial, height, weight):

    interpreter = tf.lite.Interpreter(model_path=modelpath)
    interpreter.allocate_tensors()

    # Get input and output tensors.
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    # Test the model on random input data.

    in_s = input_details[0]['shape']

    num = len(label_list)
    tf_img, label, num = load_and_slice_img(img_list,label_list, num, height, weight)
    output_data= []
    for i in range(num):
        input_= tf_img[i].reshape((1, height//2, weight//2, 3))

        interpreter.set_tensor(input_details[0]['index'], input_)
        interpreter.invoke()

        out_data = interpreter.get_tensor(output_details[0]['index'])

        output_data.append(out_data)
    output_data = np.array(output_data).reshape((num, height, weight, 3))

```

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

I am trying to quantize a SR model (EDSR), using Quantization Aware Training.

I am using same codes used in Jacob et al. (2017) to perform quantization (create_training_graph etc)

Fake Quantization (Stimulated) works rather well, but when I convert them using TFLiteconverter (from freeze_model), the result becomes very poor (PSNR below that of bicubic interpolation)

When I draw histogram with the output and HR image, the range of image has decreased about 20% (e.g 0-200 to 25-180). Histogram structure seems to be identical.


I tried to cross-check this using a simple model for MNIST, and found out following things
- Almost zero performance change when converted to TFLite file, both with QAT and Post Integer Quantization
- Output, before applying softmax function, changes dramatically between TFLite and Float (real float and fake/stimulated quantization one) models.


I used images in raw form, without normalizing to [0,1] to train the floating point models. When converting the float model, I used exact codes written in relevant document in tf==1.14 github. I also used same codes for inference in TFLite

I would like to reproduce the issue, but since it requires a lot of computation to train SR model, I did not upload the file initially. If required though, I will try to upload snippets of MNIST code (+ conversion code) that I have used to produce this error
**Update - I have uploaded some codes and pb/tflite file of the models I produced**

When I had a look into each nodes, the only difference between tflite and QAT(float) was a small change in min/max values for 'act_quant' stage, when activation function is not applied.


What might be the possible cause of this error (happens in both classification and SR model)? One easy thought is that the input image might have slightly changed after converting the format into float32 (from uint8) for inference in floating model.
Also, I think it might be the case that random bias has been added.

![KakaoTalk_20210204_233632390](https://user-images.githubusercontent.com/29692100/106907712-e8ba7100-6741-11eb-94b4-3ad0aff0ab5d.jpg)

Top Image- TFLite model after quantization (QAT)
Bottom Image - HR image


![KakaoTalk_20210204_233632390_01](https://user-images.githubusercontent.com/29692100/106907721-eb1ccb00-6741-11eb-8717-b1e5a1041913.jpg)

Histogram of above image for TFLite model after QAT


![KakaoTalk_20210204_233632390_02](https://user-images.githubusercontent.com/29692100/106907723-ebb56180-6741-11eb-864d-f2d46f27c66e.jpg)


Histogram of same image for floating point model


It is ok if there is no exact solution, but I would like to know possible cause of this phenomenon, so that I can try to debug it.


* I used non keras layers to create the model, and also manually recreated depth_to_space layer of EDSR, as it was not supported in the version of TFLite converter I used.


[Graphs.zip](https://github.com/tensorflow/tensorflow/files/5929670/Graphs.zip)
frozen graph (fake quant)  and corresponding tflite file (qat)
"
46925,TF.js Error: TensorList shape mismatch:  Shapes -1 and 3 must match,"I'm currently trying to convert to TF.js one of the Object Detection models from the TF2 OD ZOO, in particular SSD MobileNet V2 FPNLite 320x320.

When I convert the model pre-existing SavedModel from the saved_model folder I'm able to import it in my browser and launch it through executeAsync(). If I keep the original pipeline.config and try to create another SavedModel from the provided checkpoint using this line

```
python exporter_main_v2.py --input_type image_tensor \
    --pipeline_config_path ./pre-trained-models/ssd320/pipeline.config \
    --trained_checkpoint_dir ./pre-trained-models/ssd320/checkpoint_0 \
    --output_directory ./pre-trained-models/ssd320/exported_model
```

after I convert it to TF.js with the following line

```
tensorflowjs_converter \
    --input_format=tf_saved_model \
    --saved_model_tags=serve \
    ./pre-trained-models/ssd320/path-to-savedmodel-folder \
    ./pre-trained-models/tfjs_test
```

I encounter the following error when I try to launch the inference on my browser

```
util_base.js?a6b2:141 Uncaught (in promise) Error: TensorList shape mismatch:  Shapes -1 and 3 must match
    at Module.assert (util_base.js?a6b2:141)
    at assertShapesMatchAllowUndefinedSize (tensor_utils.js?74aa:24)
    at TensorList.setItem (tensor_list.js?41f7:182)
    at Module.executeOp (control_executor.js?de9e:188)
    at eval (operation_executor.js?be85:52)
    at executeOp (operation_executor.js?be85:94)
    at GraphExecutor.processStack (graph_executor.js?33ef:390)
    at GraphExecutor.executeWithControlFlow (graph_executor.js?33ef:350)
    at async GraphExecutor._executeAsync (graph_executor.js?33ef:285)
    at async GraphModel.executeAsync (graph_model.js?9724:316)
```

I'm currently working in Colab with the standard modules (TF 2.4.1, Python 3.6.9 and tensorflowjs 3.0.0) and didn't manage to find infos on similiar issues elsewhere.

I tried with SSD MobileNet v2 320x320 (no FPN here) and the outcome is the same. I'm starting to think that it may be connected to the use of exporter_main_v2.py but I wouldn't know how to convert the model without it.

Could you please help me figure out something more about the cause of this issue?"
46924,RuntimeError: Encountered unresolved custom op: TensorArrayV3.Node number 3 (TensorArrayV3) failed to prepare.,"I'm not so professional in python! I'm trying to convert frozen graph to tflite file in colab to start inference it using jetson nano. I get this error! 

converter.allow_custom_ops = True
converter.experimental_new_converter = True
converter.optimizations = [tf.lite.Optimize.DEFAULT]

tflite_model = converter.convert()
open('tflite_file', 'wb').write(tflite_model)

interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()"
46923,Training is different depending on loss function being decorate with tf.function or not,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

I am training with 4 different versions of a class weighted loss function and am getting very different results. These 4 differ only in from_logits and tf.function decorator. I can compare with the result from running model.fit with the standard categorical cross entropy loss function and explicit weights and see which ones are correct and get

1. from_logits = True, no tf.function decorator ---> wrong answer
2. from_logits = True, tf.function decorator ---> wrong answer
3. from_logits = False, no tf.function decorator ---> wrong answer
4. from_logits = False, tf.function decorator ---> correct answer

Incidentally, all the three incorrect answers are equal to each other. This is not related to the numerical stability issue related to use of from_logits as we can see the correct answer actually comes from the one that does not use logits. Furthermore, the standard categorical cross entropy loss function with class weights give the same answer irrespective of the from_logits flag.

**Describe the expected behavior**

All four loss functions should result in the same training.

**Standalone code to reproduce the issue**

https://colab.research.google.com/drive/1LrB6krDIowtzDfmstU-oGi6iHOoDYRYm?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46922,[quantization] Post-training quantization using TFLiteConverter isn't working in TF 2.3,"Hello there :wave: 

**System information**
- Have I written custom code: not one bit
- OS Platform and Distribution: Linux, Ubuntu 20.04
- TensorFlow installed from: pip
- TensorFlow version: 2.3.1
- Python version: 3.8.5
- CUDA/cuDNN version: CUDA 11.0, cuDNN 8.0.5
- GPU model and memory: GeForce RTX 2070 Max Q, 8Gb RAM


**Describe the current behavior**
There seems to be an issue in TF 2.3, where post-training quantization does not seem to actually work: quantized version are no smaller than fp16 counterpart using the conversion tutorial from the documentation (post-training). This seems to have been fixed in tf2.4 but I din't see any related issue or mention of a fix (I may have missed a few things :sweat_smile: ).

**Describe the expected behavior**
Using the same TFLite converter, the bare TFLite model should be strictly bigger than its FP16 counterpart, which in turn should be strictly bigger than its int8 counterpart.

**Standalone code to reproduce the issue**
The following code raises an error in TF2.3.1 but no longer in TF 2.4.* :
```
import sys
import tensorflow as tf
import numpy as np
from tensorflow.keras import layers, Sequential

_layers = [
    layers.Conv2D(8, 3, activation='relu', padding='same', input_shape=(224, 224, 3)),
    layers.GlobalAveragePooling2D(),
    layers.Flatten(),
    layers.Dense(10),
]
mock_model = Sequential(_layers)

def convert_to_fp16(tf_model):
    converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)

    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_types = [tf.float16]
    return converter.convert()


def quantize_model(tf_model, input_shape):
    converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)

    converter.optimizations = [tf.lite.Optimize.DEFAULT]

    # Float fallback for operators that do not have an integer implementation
    def representative_dataset():
        for _ in range(100):
            data = np.random.rand(1, *input_shape)
            yield [data.astype(np.float32)]

    converter.representative_dataset = representative_dataset
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8

    return converter.convert()


assert sys.getsizeof(convert_to_fp16(mock_model)) > sys.getsizeof(quantize_model(mock_model, (224, 224, 3)))
```

**Other info / logs** No error is actually thrown during the execution, but the behaviour is not as expected. The same test is passing between a bare tflite conversion (in fp32), and fp16 conversion, but fails between fp16 and int8.
"
46921,MeanIoU not ignoring background,"According to https://en.wikipedia.org/wiki/Jaccard_index and the MeanIoU documentation : https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/metrics.py#L2722-L2850
The IoU score is TP / (TP+FP+FN)

However the MeanIoU seems to calculate this per class not ignoring the background class.
Minimum working example.


```
import tensorflow as tf

m = tf.keras.metrics.MeanIoU(num_classes=2)
m.update_state([0, 0, 1, 1, 1], [0, 1, 0, 1, 1])

tp = m.total_cm[1,1]
tn = m.total_cm[0,0]
fn = m.total_cm[1,0]
fp = m.total_cm[0,1]

print(m.total_cm)
print(m.result())
print(tp/(tp+fp+fn))
```
Where tensorflow calculates the IoU to be (0.5 + 0.3333) / 2, however to my understanding the correct answer should be 0.5.

Is there a way to get the IoU scores mean for Classes that are not background? (Ignoring cm[0,0] in true positives)

Best regards"
46920,tf.abs() crashes when dtype=float32,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home 20H2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): using pip inside conda
- TensorFlow version (use command below): 2.5.0-dev20210203
- Python version: 3.8.5
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: 11.0 / 8
- GPU model and memory: RTX 1070 8GB

**Describe the current behavior**
tf.abs() works fine when provided with integer values but crashes when dtype=float32.
If run in Jupyter the cell will hang and never execute. If run in Anaconda prompt python will crash and kick you back out to conda.

**Describe the expected behavior**
Return absolute value

**Standalone code to reproduce the issue**
```
import tensorflow as tf
x = tf.constant([-2.25, 3.25])
tf.abs(x)
```
"
46919,"In tf.keras, can i use model(x).numpy() with disable_eager_execution()?","This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.

- Python version: 3.7
- TensorFlow version (use command below):2.2

**Describe the current behavior**
As is known to us, for predicting, there are two options to use the model. I can call `model.predict(x)` or I can call `model(x).numpy()`. `model(x)` is faster than `model.predict(x)`  for small amount of inputs in eager mode. Since i want to  deploy the model in production environmentï¼i should disable the eager mode with `tf.compat.v1.disable_eager_execution()`.For better performanceï¼i want to use `model(x).numpy()` to predict instead of  `model.predict(x)` for small amount of inputs ,but i found that i can't convert tensor to numpy with  `tf.compat.v1.disable_eager_execution()`
**Describe the expected behavior**
is there any solutions to use `model(x).numpy()` with `tf.compat.v1.disable_eager_execution()` for faster prediction"
46918,Model is working fine in CPU but in GPU it consumes all RAM. ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code:- Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4
- Python version: 3.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11.0
- GPU model and memory: Tesla K4, RAM=15GB


**Current behavior**
I am trying to run face identification using the face_identification library based on dlib and object detection using the mobilenet_ssd model. Both of them combined working fine in CPU on local machine and on AWS CPU but when we use GPU, RAM is used completely. The issue is with the object detection model. Before loading the model it uses 300MB RAM, but when it loads the pre-trained model, RAM is suddenly jumped to 15GB. Both models are working fine in the CPU. 

**Expected behavior**
It should run on GPU without RAM overflow.


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info/logs** 
Traceback (most recent call last):
  File ""StreamingService.py"", line 252, in <module>
    streamingService.start()
  File ""StreamingService.py"", line 104, in start
    verification_service.verify(studentExamId, studentId, verificationCode)
  File ""/home/ubuntu/screening-service-test/screening-service/computerVision/VerificationService.py"", line 84, in verify
    studentFaceEncoding  = self.getFaceEncoding(studentPicDict[key])
  File ""/home/ubuntu/screening-service-test/screening-service/computerVision/VerificationService.py"", line 20, in getFaceEncoding
    face_locations = face_recognition.face_locations(rgb_small_frame, model = ""cnn"")
  File ""/home/ubuntu/.local/lib/python3.8/site-packages/face_recognition/api.py"", line 119, in face_locations
    return [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, ""cnn"")]
  File ""/home/ubuntu/.local/lib/python3.8/site-packages/face_recognition/api.py"", line 103, in _raw_face_locations
    return cnn_face_detector(img, number_of_times_to_upsample)
RuntimeError: Error while calling cudnnFindConvolutionForwardAlgorithm( context(), descriptor(data), (const cudnnFilterDescriptor_t)filter_handle, (const cudnnConvolutionDescriptor_t)conv_handle, descriptor(dest_desc), num_possible_algorithms, &num_algorithms, perf_results.data()) in file /home/ubuntu/dlib/dlib/cuda/cudnn_dlibapi.cpp:820. code: 2, reason: CUDA Resources could not be allocated.
"
46917,TypeError: can't pickle _thread.RLock objects when using multiprocessing,"Information:

```
Tensorflow version 2.1.0
Python 3.7
```
The minimal example to reproduce the error:


```
import tensorflow as tf
from tensorflow import keras
import numpy as np


from multiprocessing import Pool
from multiprocessing.dummy import Pool as ThreadPool
from functools import partial

def simple_model():
    model = keras.models.Sequential([
        keras.layers.Dense(units = 10, input_shape = [1]),
        keras.layers.Dense(units = 1, activation = 'sigmoid')
    ])
    model.compile(optimizer = 'sgd', loss = 'mean_squared_error')
    return model

def clone_model(model):
    model_clone = tf.keras.models.clone_model(model)
    model_clone.set_weights(model.get_weights())
    return model_clone

def work(model, seq):
    return model.predict(seq)
    
def worker(model, n = 4):
    seqences = np.arange(0,100).reshape(n, -1)
    pool = Pool()
    # model_list = [clone_model(model) for _ in range(n)]
    # results = pool.map(work, zip(model_list,seqences))
    partial_work = partial(work, model=model)
    results = pool.map(partial_work, seqences)
    pool.close()
    pool.join()
    
    return np.reshape(results, (-1, ))



if __name__ == '__main__':
    model = simple_model()
    out = worker(model, n=4)
    print(out)
```


gives the following error trace:
```
Traceback (most recent call last):
  File ""c:/****/test4.py"", line 43, in <module>
    out = worker(model, n=4)
  File ""c:/****/test4.py"", line 33, in worker
    results = pool.map(partial_work, seqences)
  File ""C:\***\anaconda3\envs\tf-gpu\lib\multiprocessing\pool.py"", line 268, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File ""C:\***\anaconda3\envs\tf-gpu\lib\multiprocessing\pool.py"", line 657, in get
    raise self._value
  File ""C:\***\anaconda3\envs\tf-gpu\lib\multiprocessing\pool.py"", line 431, in _handle_tasks
    put(task)
  File ""C:\***\anaconda3\envs\tf-gpu\lib\multiprocessing\connection.py"", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File ""C:\***\anaconda3\envs\tf-gpu\lib\multiprocessing\reduction.py"", line 51, in dumps
    cls(buf, protocol).dump(obj)
TypeError: can't pickle _thread.RLock objects
```"
46916,window10 make file error,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): window10
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): 2.4.0
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): heimax we1

**Describe the problem**
Hello, I have problem build makefile in window10
I've download the migw to use ""make"".

in Powershell

```
PS C:\tensorflow> make -f tensorflow/lite/micro/tools/make/Makefile test_hello_world_test
process_begin: CreateProcess(NULL, uname -m, ...) failed.
-mì(ë) ììëì§ ìììµëë¤.
'tr'ì(ë) ë´ë¶ ëë ì¸ë¶ ëªë ¹, ì¤íí  ì ìë íë¡ê·¸ë¨, ëë
ë°°ì¹ íì¼ì´ ìëëë¤.
FIND: ë§¤ê° ë³ì íìì´ íë¦½ëë¤.
FIND: ë§¤ê° ë³ì íìì´ íë¦½ëë¤.
ëªë ¹ êµ¬ë¬¸ì´ ì¬ë°ë¥´ì§ ììµëë¤.
process_begin: CreateProcess(NULL, bash C:\tensorflow\tensorflow\lite\micro\tools\make\flatbuffers_download.sh tensorflow/lite/micro/tools/make/downloads, ...) failed.
tensorflow/lite/micro/tools/make/Makefile:521: *** Something went wrong with the flatbuffers download: .  ë©ì¶¤.

```

```
PS C:\tensorflow> make -f tensorflow/lite/micro/tools/make/Makefile TARGET=himax_we1_evb third_party_downloads
process_begin: CreateProcess(NULL, uname -m, ...) failed.
-mì(ë) ììëì§ ìììµëë¤.
'tr'ì(ë) ë´ë¶ ëë ì¸ë¶ ëªë ¹, ì¤íí  ì ìë íë¡ê·¸ë¨, ëë
ë°°ì¹ íì¼ì´ ìëëë¤.
FIND: ë§¤ê° ë³ì íìì´ íë¦½ëë¤.
FIND: ë§¤ê° ë³ì íìì´ íë¦½ëë¤.
ëªë ¹ êµ¬ë¬¸ì´ ì¬ë°ë¥´ì§ ììµëë¤.
process_begin: CreateProcess(NULL, bash C:\tensorflow\tensorflow\lite\micro\tools\make\flatbuffers_download.sh tensorflow/lite/micro/tools/make/downloads, ...) failed.
tensorflow/lite/micro/tools/make/Makefile:521: *** Something went wrong with the flatbuffers download: .  ë©ì¶¤.
```

I can't find the reason of this problem. I guess I have to change environment setting

"
46915,tf.nn.atrous_conv2d crashes(aborts) when rate is large value,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.nn.atrous_conv2d` crashes(aborts) when `rate` is large value

**Describe the expected behavior**
expect an exception message if the input unexpected instead of crash. 



**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.nn.atrous_conv2d(value=np.ones((1,1,1,5)), filters=np.ones((1,1,5,1)), rate=2147483647, padding='SAME')
~~~

~~~python
2021-02-04 04:47:25.891213: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -1)
Aborted (core dumped)
~~~"
46914,tf.keras.layers.UpSampling2D crashes(aborts) when size is large,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
`tf.keras.layers.UpSampling2D` crashes(aborts) when `size` is large
**Describe the expected behavior**
expect an exception message if the input unexpected instead of crash. 


**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.keras.layers.UpSampling2D(size=1610637938, data_format='channels_first', interpolation='bilinear')(np.ones((5,1,1,1)))
~~~
Output:
~~~python
2021-02-04 04:44:48.936606: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -5475971237085092396)
Aborted (core dumped)
~~~"
46913,tf.keras.layers.RepeatVector crashes(aborts) when n is large,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.keras.layers.RepeatVector` crashes(aborts) when `n` is large

**Describe the expected behavior**
expect an exception message if the input unexpected instead of crash. 

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.keras.layers.RepeatVector(n=9223372036854775807)(np.ones((3, 1)))
~~~

Output:
~~~python
2021-02-04 04:42:07.262027: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -1)
Aborted (core dumped)
~~~"
46912,`tf.sparse.eye` crashes(aborts) when num_rows contains large number,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
`tf.sparse.eye` crashes(aborts) when `num_rows` contains large number

**Describe the expected behavior**
expect an exception message if the input unexpected instead of crash. 


**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.sparse.eye(num_rows=9223372036854775807, num_columns=None)
~~~

Output
~~~python
2021-02-04 04:36:57.184236: F tensorflow/core/framework/tensor_shape.cc:345] Check failed: size >= 0 (-9223372036854775808 vs. 0)
Aborted (core dumped)
~~~"
46911,tf.keras.backend.tile crash(aborts) when n is large,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A




**Describe the current behavior**
`tf.keras.backend.tile` crash(aborts) when `n` is large

**Describe the expected behavior**
expect an exception message if the input unexpected instead of crash. 

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.keras.backend.tile(x=np.ones((1,1,1)), n=[100000000,100000000, 100000000])
~~~
Output
~~~python
2021-02-04 04:10:34.072054: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -1)
Aborted (core dumped)
~~~"
46910,tf.quantization.fake_quant_with_min_max_vars(_gradient) crash(abort),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
`tf.quantization.fake_quant_with_min_max_vars` and `tf.quantization.fake_quant_with_min_max_vars_gradient` crash(abort)


**Describe the expected behavior**
expect an exception message if the input unexpected instead of crash. 

**Standalone code to reproduce the issue**
~~~python
tf.quantization.fake_quant_with_min_max_vars_gradient(gradients=1, inputs=1, max=[1,1], min=[1,1])
tf.quantization.fake_quant_with_min_max_vars_gradient(gradients=[], inputs=[], max=[1,1], min=[1,1])
tf.quantization.fake_quant_with_min_max_vars(inputs=np.ones((1,1)), max=[1,1], min=[1,1])
~~~


Output
~~~python
2021-02-04 04:05:44.055418: F tensorflow/core/framework/tensor.cc:669] Check failed: 1 == NumElements() (1 vs. 2)Must have a one element tensor
Aborted (core dumped)
~~~"
46909,tf.summary.create_file_writer aborts ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.summary.create_file_writer` crash (abort)

**Describe the expected behavior**
expect an exception message if the input unexpected instead of crash. 

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.summary.create_file_writer(logdir='', flush_millis=np.ones((1,2)))
~~~

Output:
~~~python
2021-02-04 03:59:32.339427: F tensorflow/core/framework/tensor.cc:669] Check failed: 1 == NumElements() (1 vs. 2)Must have a one element tensor
Aborted (core dumped)
~~~
"
46908,tf.nn.softmax_cross_entropy_with_logits and tf.keras.backend.categorical_crossentropy crash(abort),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
`tf.nn.softmax_cross_entropy_with_logits` and `tf.keras.backend.categorical_crossentropy` crash(abort) when `axis` is large

**Describe the expected behavior**
expect an exception message if the input unexpected instead of crash. 

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.keras.backend.categorical_crossentropy(target=np.ones((1, 1, 1)), output=np.ones((1, 1, 1)), axis=9223372036854775807, from_logits=True)
~~~
Output
~~~python
2021-02-04 03:56:25.011064: F tensorflow/core/framework/tensor_shape.cc:345] Check failed: size >= 0 (-9223372036854775808 vs. 0)
Aborted (core dumped)
~~~

~~~python
import tensorflow as tf
import numpy as np
tf.nn.softmax_cross_entropy_with_logits(labels=1, logits=1, axis=9223372036854775807)
~~~
Output
~~~python
2021-02-04 03:55:56.843085: F tensorflow/core/framework/tensor_shape.cc:345] Check failed: size >= 0 (-9223372036854775808 vs. 0)
Aborted (core dumped)
~~~

"
46907,Tokenizer doesn't work with string tensors (AttributeError),"**System information**
- OS Platform: Windows 10
- TensorFlow version: 2.3.2
- Python version: 3.8.5
- CUDA version: 10.1.243

**Issue**
Tokenizer doesn't work with tensors (at least string tensors).

**Standalone code to reproduce**

Fails with a string tensor:

````
a = ['hello world', 'what is your name', 'start with a scene']

t = tf.constant(a, dtype=tf.string)
tokenizer = tf.keras.preprocessing.text.Tokenizer()
tokenizer.fit_on_texts(t)
````
Throws this error:

````
AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'lower'
````

Works fine with a regular python list:

````
a = ['hello world', 'what is your name', 'start with a scene']

tokenizer = tf.keras.preprocessing.text.Tokenizer()
tokenizer.fit_on_texts(a)
````
"
46905,libtensorflowlite_flex_jni.so not found when using tensorflow-lite.aar,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- Yes, I have overwritten the tensorflow lite Transpose method to accept tensors larger than 4D

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- macOS Catalina 10.15.7

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- Running an emulator in AndroidStudio 4.1.2, Pixel_3a_API_30_x86

- TensorFlow installed from (source or binary):
- Source

- TensorFlow version (use command below):  2.5.0 master branch HEAD (2/3/2021, commit 54bcf2919f7824995835726630064c383eb47149)
- with modified tensorflow/lite/kernels/transpose.cc, and registering function in tensorflow/lite/kernels/register.cc and builtin_op_kernels.h)
- Python version:3.7.5
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): Apple clang version 11.0.3 (clang-1103.0.32.29)
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I used that tensorflow code (with my custom transpose operation) to convert a pb file of the Glow model into a tflite file using the Python API.  I tested the model out in Python, and was able to load/invoke it just fine.

I built the tensorflow-lite.aar and tensorflow-lite-select-tf-ops.aar files with the current version of tensorflow (commands used to build below).  I try loading the model in Android using Java, and the Interpreter() constructor throws the following error:
E/AndroidRuntime: FATAL EXCEPTION: main
    Process: com.example.tflite_java, PID: 4451
    java.lang.UnsatisfiedLinkError: dlopen failed: library ""libtensorflowlite_flex_jni.so"" not found
        at java.lang.Runtime.loadLibrary0(Runtime.java:1087)
        at java.lang.Runtime.loadLibrary0(Runtime.java:1008)
        at java.lang.System.loadLibrary(System.java:1664)
        at org.tensorflow.lite.flex.FlexDelegate.<clinit>(FlexDelegate.java:61)
        at java.lang.Class.classForName(Native Method)
        at java.lang.Class.forName(Class.java:454)
        at java.lang.Class.forName(Class.java:379)
        at org.tensorflow.lite.NativeInterpreterWrapper.maybeCreateFlexDelegate(NativeInterpreterWrapper.java:511)
        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegates(NativeInterpreterWrapper.java:476)
        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:88)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:66)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:287)
        at com.example.tflite_java.MainActivity.loadModel(MainActivity.java:79)
        at com.example.tflite_java.MainActivity.onCreate(MainActivity.java:115)
        at android.app.Activity.performCreate(Activity.java:8000)
        at android.app.Activity.performCreate(Activity.java:7984)
        at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1309)
        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3422)
        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3601)
        at android.app.servertransaction.LaunchActivityItem.execute(LaunchActivityItem.java:85)
        at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:135)
        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:95)
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2066)
        at android.os.Handler.dispatchMessage(Handler.java:106)
        at android.os.Looper.loop(Looper.java:223)
        at android.app.ActivityThread.main(ActivityThread.java:7656)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:592)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:947)
I/Process: Sending signal. PID: 4451 SIG: 9

**Describe the expected behavior**
I expected to be able to load and utilize the model, not this error: java.lang.UnsatisfiedLinkError: dlopen failed: library ""libtensorflowlite_flex_jni.so"" not found

**Standalone code to reproduce the issue**
===========MainActivity.java=============
package com.example.tflite_java;

import android.content.res.AssetFileDescriptor;
import android.content.res.AssetManager;
import android.os.Bundle;
import androidx.appcompat.app.AppCompatActivity;
import org.tensorflow.lite.Interpreter;
import java.io.FileInputStream;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;

public class MainActivity extends AppCompatActivity {
    // Load tflite model from assets.
    public MappedByteBuffer loadModelFile(String modelPath) throws IOException, IOException {
        try (AssetFileDescriptor fileDescriptor = getAssets().openFd(modelPath);
            FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor())) {
            FileChannel fileChannel = inputStream.getChannel();
            long startOffset = fileDescriptor.getStartOffset();
            long declaredLength = fileDescriptor.getDeclaredLength();
            return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);
        }
    }

    // Load the tflite model
    public Interpreter loadModel(String modelFile) {
        Interpreter tflite;
        try {
            System.out.println(""Loading model from file "" + modelFile);
            ByteBuffer buffer = loadModelFile(modelFile);
            Interpreter.Options opt = new Interpreter.Options();
            opt.setNumThreads(1);
            tflite = new Interpreter(buffer, opt);
        } catch (IOException ex) {
            tflite = null;
            System.out.println(ex.getMessage());
        }
        return tflite;
    }

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        Interpreter interpreter = loadModel(""waterfall_glow_20210203_tfnightly.tflite"");
    }
}


**Other info / logs** 
Android ndk version android-ndk-r18b-darwin-x86_64.zip
Android sdk version 30.0.3
Build commands for tensorflow-lite and tensorflow-lite-select-tf-ops
bazel build --cxxopt='--std=c++14' -c opt --config=android_arm --config=monolithic //tensorflow/lite/java:tensorflow-lite-select-tf-ops
bazel build --cxxopt='--std=c++11' -c opt --fat_apk_cpu=x86,x86_64,arm64-v8a,armeabi-v7a //tensorflow/lite/java:tensorflow-lite"
46902,Cannot Compile TF-Nightly with CUDA 11.2 and CUDNN 8.1,"**System information**
- Windows 10
- TensorFlow installed from (source or binary): source
- TensorFlow version: tf-nightly
- Python version: 3.8.6
- Installed using virtualenv? pip? conda?: Built using instructions [here](https://www.tensorflow.org/install/source_windows)
- Bazel version (if compiling from source): Bazel 3.7.2
- GCC/Compiler version (if compiling from source): MSVC 14.28.29333
- CUDA/cuDNN version: 11.2 / 8.1
- GPU model and memory: Geforce RTX 3090 24GB

When trying to build TF-nightly with CUDA 11.2 and CUDNN 8.1, this error occurs:
`C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.28.29333\include\complex(354): error C2039: 'copysign': is not a member of ''global namespace''
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.28.29333\include\complex(354): error C3861: 'copysign': identifier not found
`

This causes the build to fail.

Steps to reproduce:
1) Uninstall all global CUDA instances.
2) Install CUDA 11.2
3) Install CUDNN 8.1 by dragging the files into the install directory of CUDA
4) Git clone tensorflow
5) Checkout tf-nightly branch
6) Set up Bazel, following [this](https://docs.bazel.build/versions/master/windows.html#build-c) guide (suggested by documentation)
7) Follow the rest of the guide [here](https://www.tensorflow.org/install/source_windows).
8) Execute bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package
9) Receive the error.

Traceback is attached.
[log.txt](https://github.com/tensorflow/tensorflow/files/5922256/log.txt)
"
46900,tf.strings.substr crashes(aborts) ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
`tf.strings.substr` crashes(aborts)  when `len(pos)` > `len(input)`

**Describe the expected behavior**
expect an exception message if the input unexpected instead of crash. 


**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
tf.strings.substr(input='abc', len=1, pos=[1,-1])
~~~

~~~python
import tensorflow as tf
tf.strings.substr(input='abc', len=1, pos=[1,2])
~~~


Output:
~~~python
2021-02-03 22:46:41.234297: F ./tensorflow/core/framework/tensor.h:806] Check failed: new_num_elements == NumElements() (2 vs. 1)
Aborted (core dumped)
~~~"
46899,tf.ragged.range and  tf.range crash (abort) when `start` is large,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.ragged.range` and  `tf.range`  crash (abort) when `start` is large

**Describe the expected behavior**
expect an exception message if the input unexpected instead of crash

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
tf.range(start=-1e+38, limit=1)
~~~
Output:
~~~python
2021-02-03 22:29:09.074233: F tensorflow/core/framework/tensor_shape.cc:345] Check failed: size >= 0 (-9223372036854775808 vs. 0)
Aborted (core dumped)
~~~




~~~python
import tensorflow as tf
tf.ragged.range(starts=1e+38)
~~~

Output:
~~~python
2021-02-03 22:28:53.789455: F tensorflow/core/framework/tensor_shape.cc:345] Check failed: size >= 0 (-9223372036854775808 vs. 0)
Aborted (core dumped)
~~~"
46898,`tf.random.fixed_unigram_candidate_sampler` crashes(abort) when `vocab_file` is invalid,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.random.fixed_unigram_candidate_sampler` crashes(abort) when `vocab_file` is invalid

**Describe the expected behavior**
expect an exception message if the file format is incorrect instead of crash


**Standalone code to reproduce the issue**
~~~python
tf.random.fixed_unigram_candidate_sampler(true_classes=np.ones((1,1)), num_true=1, num_sampled=1, unique=True, range_max=1, vocab_file='abc')
~~~
Output:
~~~python
2021-02-03 22:08:02.817419: F tensorflow/core/kernels/range_sampler.cc:246] Non-OK-status: LoadFromFile(env, vocab_file, distortion) status: Not found: abc; No such file or directory
Aborted (core dumped)
~~~

"
46897,tf.sparse.segment_sqrt_n/sum crashes(abort) when segment_ids is large uint,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.sparse.segment_sqrt_n` and `tf.sparse.segment_sum` crashes(abort) when `segment_ids` is large `uint`


**Describe the expected behavior**
expect no crash if the input is unexpected instead of crash

**Standalone code to reproduce the issue**
~~~python
tf.sparse.segment_sqrt_n(data=1.0, indices=[1], segment_ids=np.array([1205444461],dtype=np.uint32))
tf.sparse.segment_sum(data=1, indices=[1], segment_ids=np.array([1205444461], dtype=np.uint32))
~~~

Output:
~~~python
2021-02-03 21:19:17.206426: F tensorflow/core/framework/tensor_shape.cc:435] Check failed: d < dims() (0 vs. 0)
Aborted (core dumped)
~~~
"
46896,"Custom ""Best"" Metric Not Tracking Best Accuracy","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
-- custom code in which the bug manifests, but test code is slightly edited stock example code from Tensorflow docs.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
-- MacOS and Linux
- TensorFlow installed from (source or binary):
-- via pip
- TensorFlow version (use command below):
-- 2.4.0
- Python version:
-- 3.8.2


**Describe the current behavior**

I've created a custom metric which tracks the max achieved result of a metric during a training run (so for example it should reflect the best model's accuracy seen so far at any given point in time). When I apply this to the simple MNIST code from the docs where the accuracy continuously moves up at the epoch level, this custom metric does not exactly match the raw accuracy (though it roughly tracks with it).

**Describe the expected behavior**

The expected behaviour in this case would be for the custom metric to exactly match the accuracy since the accuracy improves monotonically at the epoch level. It seems like it's a bug that it does not. However, I admit that it could be a hole in my understanding of Tensorflow! Perhaps there's some kind of off-by-one error here in how I'm interpreting the metric's state maybe?

Another comment which may or may not be related: In working with multiple class instances of tensorflow metric objects in jupyter notebooks, I noticed that sometimes I had to be very liberal with my usage of reset_state even though I had separate class instances of the same metric. This makes me expect that at the root of both this and the bug I outline in this issue, that there's some kind of unintentionally shared state between multiple instances of the same metric class. If I can reproduce this someday again, I'll post in separate issue. I just wanted to include full context in case this provides clues that tie to other posted issues in tf's github repo.

**Standalone code to reproduce the issue**

reproducible in this collab notebook: https://colab.research.google.com/drive/1hBcLce9VWynZgTAbzhWzEfdO3VZq4-0W?usp=sharing
"
46891,tf.transpose crashes(abort) if `a` is complex,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.transpose` crashes(abort) if `a` is complex and `conjugate`=True


**Describe the expected behavior**
expect no crash

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
tf.transpose(conjugate=True, a=complex(1))
~~~

Output:
~~~python
2021-02-03 17:58:05.565680: F ./tensorflow/core/kernels/transpose_functor.h:169] Check failed: in.dims() >= 2 (0 vs. 2)
Aborted (core dumped)
~~~"
46890,tf.image.resize/resize_with_crop_or_pad/pad_to_bounding_box/extract_glimpse crash(abort),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
The following APIs crash(abortion) when the given size is large
- tf.image.resiz
- tf.image.resize_with_crop_or_pad
- tf.image.pad_to_bounding_box
- tf.image.extract_glimpse
- `tf.keras.backend.resize_images`

**Describe the expected behavior**
expect exception messages if the input is not expected instead of crash

**Standalone code to reproduce the issue**

### `tf.image.resize`
~~~python
import tensorflow as tf
import numpy as np
tf.image.resize(images=np.ones((5,5,5)), size=[2065374891,1145309325])
~~~
Output:
~~~python
2021-02-03 17:41:13.484992: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -6619278462293758741)
Aborted (core dumped)
~~~

### `tf.image.resize_with_crop_or_pad`
~~~python
import tensorflow as tf
import numpy as np
tf.image.resize_with_crop_or_pad(image=np.ones((1,1,1)), target_height=5191549470, target_width=5191549470)
~~~
Output:
~~~python
2021-02-03 17:42:15.468265: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -1)
Aborted (core dumped)
~~~

### `tf.image.pad_to_bounding_box`
~~~python
import tensorflow as tf
import numpy as np
tf.image.pad_to_bounding_box(image=np.ones((1,1,1)), target_height=5191549470, target_width=5191549470, offset_height=1, offset_width=1)
~~~
Output
~~~python
2021-02-03 17:42:52.556583: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -1)
Aborted (core dumped)
~~~

### `tf.image.extract_glimpse`
~~~python
import tensorflow as tf
import numpy as np
tf.image.extract_glimpse(input=np.ones((5,5,5,5)), size=[1574700351, 451745106], offsets=np.ones((5,2)))
~~~

Output:
~~~python
2021-02-03 17:43:30.140277: F tensorflow/core/framework/tensor_shape.cc:338] Check failed: 0 <= n (0 vs. -662664649191246466)
Aborted (core dumped)
~~~

### `tf.keras.backend.resize_image`
~~~python
import tensorflow as tf
import numpy as np
tf.keras.backend.resize_images(x=np.ones((1,5,3,15)), height_factor=5628955348197345288, width_factor=5628955348197345288, data_format='channels_last')
~~~

Output:
~~~python
2021-02-03 17:54:01.192819: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -5948468124908472256)
Aborted (core dumped)
~~~"
46889,tf.keras.backend.arange crash (abort) when start is large,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A
- 
**Describe the current behavior**
`tf.keras.backend.arange` crash (abort) when `start` is large
**Describe the expected behavior**
expect no crash

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
tf.keras.backend.arange(start=1e+38)
~~~

Output:
~~~python
2021-02-03 16:53:49.181545: F tensorflow/core/framework/tensor_shape.cc:187] Non-OK-status: InitDims(dim_sizes) status: Internal: Expected shape dimensions to be non-negative, got -9223372036854775808
Aborted (core dumped)
~~~"
46888,tf.math.segment_max/min/mean/sun/prod crashes(aborts) when segment_ids is large,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
tf.math.segment_max/min/mean/sun/prod crashes(aborts) when `segment_ids` is large

**Describe the expected behavior**
expect an exception message if the input is unexpected instead of crash

**Standalone code to reproduce the issue**
~~~python
tf.math.segment_max(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])
tf.math.segment_min(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])
tf.math.segment_mean(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])
tf.math.segment_sum(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])
tf.math.segment_prod(data=np.ones((1,10,1)), segment_ids=[1676240524292489355])
~~~

Output:
~~~python
2021-02-03 16:44:25.849065: F tensorflow/core/framework/tensor_shape.cc:405] Check failed: 0 <= new_num_elements (0 vs. -1684338830784658056)
Aborted (core dumped)
~~~

Related issue: #46696"
46887,`tf.math.floormod` crashes(floating point exception) when x is large,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A



**Describe the current behavior**
`tf.math.floormod` crashes(floating point exception) when `x` is large and `y` is negative

**Describe the expected behavior**
expect no crash

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.math.floormod(x=-9223372036854775808, y=[-1])
~~~

Output:
~~~python
Floating point exception (core dumped)
~~~"
46885,Tensorflow lite return zero in the third running time.,"hello everyone, I build a tensorflow lite 1.15.0(1.15.5) c++ lib for android.
In the first and second time, the  interpreter output is normal. but after it, interpreter return all zero.
I'm accept the camera video. 
![image](https://user-images.githubusercontent.com/29395068/106755884-9efe5780-6669-11eb-9274-25554774c53a.png)
![image](https://user-images.githubusercontent.com/29395068/106755895-a160b180-6669-11eb-8386-947e606e723f.png)
![image](https://user-images.githubusercontent.com/29395068/106755907-a45ba200-6669-11eb-8bd7-e3cf3667c5d6.png)

there is my code:
int init()
{
    std::unique_ptr<tflite::FlatBufferModel> model;
    model = tflite::FlatBufferModel::BuildFromBuffer(model_buffer,model_size);
    tflite::ops::builtin::BuiltinOpResolver resolver;
    tflite::InterpreterBuilder(*model, resolver)(&interpreter_);
    if (interpreter_->AllocateTensors() != kTfLiteOk) {
        return -1;
    }
    else
    {
        input_ = interpreter_->inputs()[0];
        return 0;
    }
}

int detect(android_camera_frame)
{
               /*
                  process image
             */
             memcpy(interpreter_->typed_tensor<float>(input_),detect_mat.data,256 * 256 * 3 * sizeof(float));
            TfLiteTensor *predict_tensor = interpreter_->tensor(interpreter_->outputs()[0]);
            float *detect_out_data = predict_tensor->data.f;

            for(int i = 0; i<20;i++)
            {
                printf(""detect_out_data(%d):%f\n"",i,detect_out_data[i]);
            }
}

**init** is a initialization function,only run once. and the frame of android camera is process by **detect** always.
In the result only first and second return is true;after that, result is all zero or nan....

there is my compile option:
bazel build //tensorflow/lite:libtensorflowlite.so --crosstool_top=//external:android/crosstool --cpu=arm64-v8a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cxxopt=""-std=c++11""

tensorflow vision is 1.15.0 and 1.15.5
"
46883,"give list of images instead of directory to ""flow_from_directory"" in keras image data generator.","<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.2.0
- Are you willing to contribute it (Yes/No): be an honor to.



**Describe the feature and the current behavior/state.** now, we just can pass directories of train, test and validation to the flow_from_directory for building the generator in keras. i want to give a list of image pathes with their label (like two lists) to build the generator.

**Will this change the current api? How?** no.

**Who will benefit with this feature?** me

**Any Other info.** thanks
"
46882,No UInt8 support for logistic operator in TFLu,"@tensorflow/micro

**Describe the problem**
I am working on running object detection demo with TFLu + ssd mobilenet v1 quantized model on i.mx8mp's Cortex-M7 core. The input tensor and output tensor's type for logistic operator is UInt8. But there is no UInt8 support in current code.

I create the following patch to fix the problem. Please give me some advice.
https://github.com/tensorflow/tensorflow/pull/46873

"
46879,Keras UpSampling2D layer is converted with a `shape` op that should be constant-folded away,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.15.6
- TensorFlow installation (pip package or built from source): PyPI pip package
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4.1

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

```
import tensorflow as tf

m = tf.keras.models.Sequential(
    [
        tf.keras.layers.Input((32, 32, 3)),
        tf.keras.layers.Conv2D(32, (3, 3)),
        tf.keras.layers.UpSampling2D((2, 2), interpolation=""nearest""),
    ]
)

converter = tf.lite.TFLiteConverter.from_keras_model(m)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
with open(""tmp-model.tflite"", ""wb"") as f:
    f.write(converter.convert())
```

### 3. Failure after conversion

The converted TFLite model looks like this:

![image](https://user-images.githubusercontent.com/7688302/106741589-cde9de80-6613-11eb-96c0-60dfd88c3d61.png)

Since the shape is statically known, I would expect the right-hand branch to be constant folded.

Possibly related to #25086."
46872,[BUG]ConvertGraphDefToGraph return an invalid tensorflow::Graph,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
> Binary
- TensorFlow version (use command below):
> 1.15 and 2.4.0
- Python version:
> 3.7.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

I want to use the C++ API to process my pbtxt model. After the GraphDef file is correctly loaded from the file, I continue to call tensorflow::ConvertGraphDefToGraph to convert my model into a tensorflow::Graph object. The call is successful, however, nodes on graph objects are invalid. For example, core dump occurs when in_edge is invoked.

For further verification, I register a pass optimizer for the POST_REWRITE_FOR_EXEC phase on the TF of version 2.4, which prints only the input graph,

> part of my pass

```C
    LOG(INFO) << ""------------------------------------Inputs------------------------------------"";
    const tensorflow::EdgeSet &in_edges = node->out_edges();
    for (auto edge : in_edges) {
      if (edge == nullptr) {
        LOG(INFO) << ""    nullptr"";
      } else {
        LOG(INFO) << ""    "" << edge->src()->DebugString();
      }
    }

    LOG(INFO) << ""------------------------------------Outputs------------------------------------"";
    const tensorflow::EdgeSet &out_edges = node->out_edges();
    for (auto edge : out_edges) {
      if (edge == nullptr) {
        LOG(INFO) << ""    nullptr"";
      } else {
        LOG(INFO) << ""    "" << edge->dst()->DebugString();
      }
    }
```

> python test code

```PYTHON
@tf.function
def f(a, b):
  return a + b

f(tf.constant(1), tf.constant(2))
```
> and the result

```
{name:'_SOURCE' id:0 source}
------------------------------------Inputs------------------------------------
    {name:'_SOURCE' id:0 source}
    {name:'_SOURCE' id:0 source}
    nullptr
------------------------------------Outputs------------------------------------
    {name:'a' id:2 op device:{/job:localhost/replica:0/task:0/device:CPU:0} def:{{{node a}} = _Arg[T=DT_INT32, _output_shapes=[[]], _user_specified_name=""a"", index=0, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()}}
    {name:'b' id:3 op device:{/job:localhost/replica:0/task:0/device:CPU:0} def:{{{node b}} = _Arg[T=DT_INT32, _output_shapes=[[]], _user_specified_name=""b"", index=1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()}}
    nullptr
{name:'b' id:3 op device:{/job:localhost/replica:0/task:0/device:CPU:0} def:{{{node b}} = _Arg[T=DT_INT32, _output_shapes=[[]], _user_specified_name=""b"", index=1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()}}
------------------------------------Inputs------------------------------------
    nullptr
------------------------------------Outputs------------------------------------
    nullptr
{name:'a' id:2 op device:{/job:localhost/replica:0/task:0/device:CPU:0} def:{{{node a}} = _Arg[T=DT_INT32, _output_shapes=[[]], _user_specified_name=""a"", index=0, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()}}
------------------------------------Inputs------------------------------------
    nullptr
------------------------------------Outputs------------------------------------
    nullptr
{name:'add' id:4 op device:{/job:localhost/replica:0/task:0/device:CPU:0} def:{{{node add}} = AddV2[T=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](a, b)}}
------------------------------------Inputs------------------------------------
    nullptr
------------------------------------Outputs------------------------------------
    nullptr
{name:'identity_RetVal' id:5 op device:{/job:localhost/replica:0/task:0/device:CPU:0} def:{{{node identity_RetVal}} = _Retval[T=DT_INT32, index=0, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](add)}}
------------------------------------Inputs------------------------------------
    nullptr
------------------------------------Outputs------------------------------------
    nullptr
{name:'_SINK' id:1 sink}
------------------------------------Inputs------------------------------------
    nullptr
------------------------------------Outputs------------------------------------
    nullptr
```

Obviously, the edges on the figure are completely disordered. For example, AddV2 has the nullptr edge* input in both the input and output.

I have also verified the ConvertGraphDefToGraph interface and the result is the same as that described above. I'm sure this function isn't working properly.

**Describe the expected behavior**

ConvertGraphDefToGraph should return a valid tensorflow::Graph object, including complete input and output edge information.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46871,RuntimeError: Unable to create link (name already exists),"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): kaggle kernel
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.4.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

This is my  Notebook:
[Kaggle Notebook](https://www.kaggle.com/shanmukh05/cassave-leaf-diseases-tpu-final/edit/run/53396178)
This is the main model I am using:
![error](https://user-images.githubusercontent.com/65073329/106710547-1e653a00-661c-11eb-856a-b8619f0d5a80.png)

**I am getting following error as mentioned in below link**
[Github Issue](https://github.com/tensorflow/tensorflow/issues/41021)
![error_1](https://user-images.githubusercontent.com/65073329/106710888-ab0ff800-661c-11eb-97cf-6102280e8009.png)

"
46870,Crash when Dense 2D without Bias on Android GPU Delegate,"**System information**
- Have I written custom code:Yes
- OS Platform and Distribution:Ubuntu 20.04 and Win10
- Mobile device: Huawei Honor V30 Pro (OXF-AN10)
- TensorFlow installed from: Pip
- TensorFlow version:2.4.1
- Python version:3.8
- CUDA/cuDNN version:11.0/8.0.5
- GPU model and memory:GTX 1080 ti

You can collect some of this information using our environment capture
v2.4.0-49-g85c8b2a817f 2.4.1

**Describe the current behavior**
A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x0

**Describe the expected behavior**
Work fine as run the model on mobile CPU

**Standalone code to reproduce the issue**

```
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow as tf

x = layers.Input(shape=(256,64,3))
y = layers.Dense(1,use_bias=False)(x) #here use_bias=False is the key point
y = layers.GlobalMaxPool2D()(y)

model = keras.Model(inputs=[x],outputs=[y])
model.summary()

converter = tf.lite.TFLiteConverter.from_keras_model(model)
model_input = model.inputs[0]
input_shape = model_input.shape
model_input.set_shape((1,*input_shape[1:]))

lite_model = converter.convert()
with open('issue_dense_2dMustBias_android_gpu.tflite', ""wb"") as fp:
    fp.write(lite_model)
```

[issue_dense_2dMustBias_android_gpu.zip](https://github.com/tensorflow/tensorflow/files/5916325/issue_dense_2dMustBias_android_gpu.zip)
"
46867,Shakespeare's style writing generation model cannot be exported with TensorFlow 2.3,"[text_generation.ipynb]: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb
[Colab notebook]: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb
## URL(s) with the issue:

- TensorFlow Tutorial: Text generation with an RNN (the one that produces Shakespeare's style writing using RNN).

    https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb

- Accompanying Colab.

    https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb

## Description of issue (what needs changing):

With TensorFlow 2.4, the notebook [text_generation.ipynb] above works as expected (without throwing any error), but this is not the case with TensorFlow 2.3.

A trivial solution is to upgrade to TensorFlow 2.4. However, this would require, when using pre-built TensorFlow, switching to CUDA 11 (cf. https://www.tensorflow.org/install/source#gpu). In a cloud environment I use from time to time, CUDA 11 is not yet supported; this is where my trouble comes from.

So the notebook better works well with TensorFlow 2.3 or higher.

### Clear description

To reproduce the issue:

1. Open the [Colab notebook].
1. Select Runtime > Change runtime type > GPU.
1. insert the line `!pip install 'tensorflow<2.4'` before the line `import tensorflow as tf`.
1. Select Runtime > Run all.

Environmental setup, text preprocessing, model building, and training run smoothly, but after the following cell in the ""Export the generator"" section, a `ValueError` is raised:

```
tf.saved_model.save(one_step_model, 'one_step')
one_step_reloaded = tf.saved_model.load('one_step')
```

```
WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f020a19e860>, because it is not built.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
INFO:tensorflow:Assets written to: one_step/assets
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-45-5089d08e324f> in <module>()
      1 tf.saved_model.save(one_step_model, 'one_step')
----> 2 one_step_reloaded = tf.saved_model.load('one_step')

9 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py in _add_saveable(saveables, seen_ops, saveable)
    329   if saveable.op in seen_ops:
    330     raise ValueError(""The same saveable will be restored with two names: %s"" %
--> 331                      saveable.name)
    332   saveables.append(saveable)
    333   seen_ops.add(saveable.op)

ValueError: The same saveable will be restored with two names: ids_from_chars/_table/.ATTRIBUTES/table
```

Just so you know, this notebook is not compatible with TensorFlow 2.2 for the very reason that `StringLookup` is not supported; running it with TensorFlow 2.2 raises an exception as follows:

```
ids_from_chars = preprocessing.StringLookup(
    vocabulary=list(vocab))
```

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-9-aea607cfc6f7> in <module>()
----> 1 ids_from_chars = preprocessing.StringLookup(
      2     vocabulary=list(vocab))

AttributeError: module 'tensorflow.keras.layers.experimental.preprocessing' has no attribute 'StringLookup'
```

So the `ValueError` in concern is an exception peculiar to TensorFlow 2.3. So far I have no idea why the notebook is not compatible with TensorFlow 2.3, and any help or a single hint will be very much appreciated."
46866,A mistake code on Model Maker Guide,"The image classification code on [official Model Maker Guide](https://tensorflow.google.cn/lite/guide/model_maker) may get a mistake on training data name.

![516441612286382_ pic_hd](https://user-images.githubusercontent.com/17171866/106685499-76437700-6603-11eb-83c3-6e4098e44183.jpg)

Mistake code in above red rectangle, I think should be replace with following code snippet.
```
model = image_classifier.create(train_data)
```
"
46863,[Keras Fit & Compile] Horovod worker desynchronization - Potentially deadlock training TF 2.4,"CC: @reedwm @pkanwar23 @sanjoy 
CC2: @romerojosh @tgaddair 
CC3: @nluehr @WhiteFangBuck

We unfortunately found quite a serious bug in TF2.4.X with Keras Models (Compile and Fit approach) combined with Mixed Precision Policy when using Horovod.

Models can ran into Deadlock or DeSynchronization (all reduce gradient of one step from worker A with gradient of another step of worker B) and stop training completely.

To make the matter worse, this issue increases in likelihood with the number of workers.

I have put together a simple repro case showing how workers can deadlock and basically stalls:

https://github.com/DEKHTIARJonathan/HVD_TF_Worker_Desync_BugReport

Small extract of the bug:
```bash
[2021-02-02 21:19:07.345988: W /tmp/pip-install-dxtho7yu/horovod_0bde588442554cf4b80c76441efc4e03/horovod/common/stall_inspector.cc:105] One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 10 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Missing ranks:
0: [cond_1/then/_10/cond_1/SGD/PartitionedCall/DistributedSGD_Allreduce/cond/then/_79/DistributedSGD_Allreduce/cond/HorovodAllreduce_grads_0]
```
As a note, this bug wasn't present in prior versions of TF.

Any help would be greatly appreciated.

Thanks a lot"
46860,[TFLM] keyword benchmark broken when using generated Makefile projects,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source):
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**
When building the keyword benchmark project like this:
make -f tensorflow/lite/micro/tools/make/Makefile  generate_keyword_benchmark_make_project

I get 2 errors. One is due to micro_benchmark.h not being copied into the generated project, the other is a duplicate object error for **g_keyword_scrambled_model_data**. That happens because keyword_scrambled_model_data.cc somehow appears twice in the generated Makefile :)

I will open a PR with a fix shortly.



**Please provide the exact sequence of commands/steps when you ran into the problem**

"
46859,Requesting MatrixDeterminant op in tflite,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.3+
- Are you willing to contribute it (Yes/No): I would need guidance / access to someone who knows the tflite codebase



**Describe the feature and the current behavior/state.**
I request that the operator MatrixDeterminant be added to the tensorflow-lite operators.  Currently, tensorflow/core/kernels/determinant_op.[cc/h] defines the standard tensorflow MatrixDeterminant operation, but there appears to be no such operation for tflite.

I am trying to convert the Glow model (https://github.com/openai/glow) to tflite, but I am running into the issue where I can't convert the trained pb file and invoke it because there is no MatrixDeterminant operation.

**Will this change the current api? How?**
It would add an operation for MatrixDeterminant to tflite's operators.

**Who will benefit with this feature?**
Anyone trying to convert a model containing the MatrixDeterminant operation to tflite.

**Any Other info.**
"
46858,InaccessibleTensorError in custom Model using add_loss and build,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10.0.18363
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: Python 3.8.5
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: CUDA 11.2, cuDNN 8.1.0.77
- GPU model and memory: NVIDIA GeForce GTX 1050 Ti 4096MiB

**Describe the current behavior**
When running the following code, which uses `add_loss()` and creates a layer in the `build()` method, I get an
`InaccessibleTensorError`

**Describe the expected behavior**
Execution without errors

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/16wFnwjWx9n0RKCuCqdTyjFPzfyqOQdyW?usp=sharing
```python
import tensorflow as tf
from tensorflow import keras

class MyModel(keras.models.Model):

    def build(self, batch_input_shape):
        self.output_layer = keras.layers.Dense(1)
        super().build(batch_input_shape)

    def call(self, inputs, training=None):
        self.add_loss(tf.reduce_mean(self.output_layer(inputs)))
        return self.output_layer(inputs)

model = MyModel()
model.compile(loss=""mse"", optimizer=""nadam"")

X = tf.random.uniform((100, 10))
y = tf.random.uniform((100, 1))
history = model.fit(X, y, epochs=2)
```

**Other info / logs** 
```
Epoch 1/2
---------------------------------------------------------------------------
InaccessibleTensorError                   Traceback (most recent call last)
<ipython-input-1-9f83c1e2ea49> in <module>
     17 X = tf.random.uniform((100, 10))
     18 y = tf.random.uniform((100, 1))
---> 19 history = model.fit(X, y, epochs=2)

d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1098                 _r=1):
   1099               callbacks.on_train_batch_begin(step)
-> 1100               tmp_logs = self.train_function(iterator)
   1101               if data_handler.should_sync:
   1102                 context.async_wait()

d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\eager\def_function.py in __call__(self, *args, **kwds)
    826     tracing_count = self.experimental_get_tracing_count()
    827     with trace.Trace(self._name) as tm:
--> 828       result = self._call(*args, **kwds)
    829       compiler = ""xla"" if self._experimental_compile else ""nonXla""
    830       new_tracing_count = self.experimental_get_tracing_count()

d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\eager\def_function.py in _call(self, *args, **kwds)
    869       # This is the first call of __call__, so we have to initialize.
    870       initializers = []
--> 871       self._initialize(args, kwds, add_initializers_to=initializers)
    872     finally:
    873       # At this point we know that the initialization is complete (or less

d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\eager\def_function.py in _initialize(self, args, kwds, add_initializers_to)
    723     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)
    724     self._concrete_stateful_fn = (
--> 725         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
    726             *args, **kwds))
    727 

d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\eager\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2967       args, kwargs = None, None
   2968     with self._lock:
-> 2969       graph_function, _ = self._maybe_define_function(args, kwargs)
   2970     return graph_function
   2971 

d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\eager\function.py in _maybe_define_function(self, args, kwargs)
   3359 
   3360           self._function_cache.missed.add(call_context_key)
-> 3361           graph_function = self._create_graph_function(args, kwargs)
   3362           self._function_cache.primary[cache_key] = graph_function
   3363 

d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3194     arg_names = base_arg_names + missing_arg_names
   3195     graph_function = ConcreteFunction(
-> 3196         func_graph_module.func_graph_from_py_func(
   3197             self._name,
   3198             self._python_function,

d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    988         _, original_func = tf_decorator.unwrap(python_func)
    989 
--> 990       func_outputs = python_func(*func_args, **func_kwargs)
    991 
    992       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\eager\def_function.py in wrapped_fn(*args, **kwds)
    632             xla_context.Exit()
    633         else:
--> 634           out = weak_wrapped_fn().__wrapped__(*args, **kwds)
    635         return out
    636 

d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\framework\func_graph.py in wrapper(*args, **kwargs)
    975           except Exception as e:  # pylint:disable=broad-except
    976             if hasattr(e, ""ag_error_metadata""):
--> 977               raise e.ag_error_metadata.to_exception(e)
    978             else:
    979               raise

InaccessibleTensorError: in user code:

    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\keras\engine\training.py:805 train_function  *
        return step_function(self, iterator)
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\keras\engine\training.py:795 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:3417 _call_for_each_replica
        return fn(*args, **kwargs)
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\keras\engine\training.py:788 run_step  **
        outputs = model.train_step(data)
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\keras\engine\training.py:755 train_step
        loss = self.compiled_loss(
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\keras\engine\compile_utils.py:229 __call__
        reg_loss = math_ops.add_n(regularization_losses)
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\util\dispatch.py:201 wrapper
        return target(*args, **kwargs)
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\ops\math_ops.py:3572 add_n
        return gen_math_ops.add_n(inputs, name=name)
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\ops\gen_math_ops.py:417 add_n
        _, _, _op, _outputs = _op_def_library._apply_op_helper(
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\framework\op_def_library.py:748 _apply_op_helper
        op = g._create_op_internal(op_type_name, inputs, dtypes=None,
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\framework\func_graph.py:588 _create_op_internal
        inp = self.capture(inp)
    d:\programs\miniconda3\envs\ml\lib\site-packages\tensorflow\python\framework\func_graph.py:633 capture
        raise errors.InaccessibleTensorError(

    InaccessibleTensorError: The tensor 'Tensor(""Mean:0"", shape=(), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=build_graph, id=2106957634048); accessed from: FuncGraph(name=train_function, id=2106954072704).
```
**Additional info**
When line 2709 in keras\engine\base_layer.py (`tf_utils.maybe_init_scope(self):`) is commented no errors are raised.
"
46857,LU solve output shape incorrect for wildcard batched inputs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab version
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): NA
- TensorFlow version (use command below): colab version
- Python version: colab version
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: colab version
- GPU model and memory: NA

**Describe the current behavior**
tf.linalg.lu_solve does not trace shapes properly:
if M is a tensor of shape (None, a, a) and RHS a tensor of shape (None, a, b), computing M^{-1}RHS returns a tensor of shape (None, a, None).
This is in contradiction with using tf.linalg.solve directly which is better behaved.

**Describe the expected behavior**
The shape tracing should happen properly.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1qkZfPVaLIjKyLwg-N-n4DBkvwZUrBCkW?usp=sharing

"
46855,"Training freezed at last batch of first epoch , not starting validation generator","[logs.txt](https://github.com/tensorflow/tensorflow/files/5911742/logs.txt)


Log file attached 

Code 

```
#!/usr/bin/env python
# coding: utf-8

# In[1]:


from PIL import Image
import os 
import cv2
import numpy as np
import time
from scipy import ndimage
import random
from model import Deeplabv3
import tensorflow as tf
# import numpy as np
# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))
import math
from tensorflow.python.keras.applications.imagenet_utils import preprocess_input
from keras.utils import to_categorical
from keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.callbacks import TensorBoard
import matplotlib.pyplot as plt


# In[2]:


pd_dir='../../../ssd_scratch/cvit/ritvik_agr/Combined_Dataset/'
#path to provided foreground images
fg_path_1 = pd_dir+'Training_set/Adobe-licensed images/fg/'
#path to provided alpha mattes
a_path_1 = pd_dir+'Training_set/Adobe-licensed images/alpha/'
#path to provided foreground images
fg_path_2 = pd_dir+'Training_set/Other/fg/'
#path to provided alpha mattes
a_path_2 = pd_dir+'Training_set/Other/alpha/'
bg_path_train = pd_dir+'train2014/'
bg_path_val=pd_dir+'VOCtrainval_11-May-2012/VOCdevkit/VOC2012/JPEGImages/'
val_path_a=pd_dir+'Test_set/Adobe-licensed_images/alpha/'
val_path_fg=pd_dir+'Test_set/Adobe-licensed_images/fg/'
batch_size_user=20
input_image_shape=512
#Path to folder where you want the composited images to go
# out_path = 'merged/'


# In[3]:


# def composite4(fg, bg, a, w, h):
#     bbox = fg.getbbox()
#     bg = bg.crop((0,0,w,h))
#     fg_list = fg.load()
#     bg_list = bg.load()
#     a_list = a.load()
#     for y in range(h):
#         for x in range (w):
#             alpha = a_list[x,y] / 255
#             t = fg_list[x,y][0]
#             t2 = bg_list[x,y][0]
#             if alpha >= 1:
#                 r = int(fg_list[x,y][0])
#                 g = int(fg_list[x,y][1])
#                 b = int(fg_list[x,y][2])
#                 bg_list[x,y] = (r, g, b, 255)
#             elif alpha > 0:
#                 r = int(alpha * fg_list[x,y][0] + (1-alpha) * bg_list[x,y][0])
#                 g = int(alpha * fg_list[x,y][1] + (1-alpha) * bg_list[x,y][1])
#                 b = int(alpha * fg_list[x,y][2] + (1-alpha) * bg_list[x,y][2])
#                 bg_list[x,y] = (r, g, b, 255)
#     return bg


# In[4]:


def generate_trimap(alpha):
   k_size = random.choice(range(2, 5))
   iterations = np.random.randint(5, 15)
   kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k_size, k_size))
   dilated = cv2.dilate(alpha, kernel, iterations=iterations)
   eroded = cv2.erode(alpha, kernel, iterations=iterations)
   trimap = 128*np.ones(alpha.shape, dtype=np.uint8)
   trimap[eroded >= 255] = 255
   trimap[dilated <= 0] = 0
   return trimap


# In[5]:


# def composited_image(im_name,bg_name):
#     if os.path.isfile(fg_path_1+im_name):
#         im = Image.open(fg_path_1 + im_name);
#         a = Image.open(a_path_1 + im_name);
#     elif os.path.isfile(fg_path_2+im_name):
#         im = Image.open(fg_path_2 + im_name);
#         a = Image.open(a_path_2 + im_name); 
#     else:
#         im = Image.open(val_path_fg + im_name);
#         a = Image.open(val_path_a + im_name); 
        
    
    
#     bbox = im.size
#     w = bbox[0]
#     h = bbox[1]
    
#     if im.mode != 'RGB' and im.mode != 'RGBA':
#         im = im.convert('RGB')
    
#     if os.path.isfile(bg_path_train+bg_name):
#         bg = Image.open(bg_path_train + bg_name);
#     else:
#         bg=Image.open(bg_path_val+bg_name)
        
#     if bg.mode != 'RGB':
#         bg = bg.convert('RGB')

#     bg_bbox = bg.size
#     bw = bg_bbox[0]
#     bh = bg_bbox[1]
#     wratio = w / bw
#     hratio = h / bh
#     ratio = wratio if wratio > hratio else hratio     
#     if ratio > 1:        
#         bg = bg.resize((math.ceil(bw*ratio),math.ceil(bh*ratio)), Image.BICUBIC)
#     out = composite4(im, bg, a, w, h)
#     return cv2.resize(np.array(out),(512,512)),cv2.resize(generate_trimap(np.array(a)),(512,512))


# In[6]:


def combined_img(im_name,bg_name):
    if os.path.isfile(fg_path_1+im_name):
        foreground = Image.open(fg_path_1 + im_name);
        alpha = cv2.imread(a_path_1 + im_name);
    elif os.path.isfile(fg_path_2+im_name):
        foreground = Image.open(fg_path_2 + im_name);
        alpha = cv2.imread(a_path_2 + im_name); 
    else:
        foreground = Image.open(val_path_fg + im_name);
        alpha = cv2.imread(val_path_a + im_name); 

    if foreground.mode != 'RGB':
        foreground = foreground.convert('RGB')
    
    if os.path.isfile(bg_path_train+bg_name):
        background = Image.open(bg_path_train + bg_name);
    else:
        background=Image.open(bg_path_val+bg_name)
        
    if background.mode != 'RGB':
        background = background.convert('RGB')
    
    foreground = np.array(foreground)
    background = np.array(background)

    background=cv2.resize(background,dsize=(foreground.shape[1],foreground.shape[0]))
    # Convert uint8 to float
    foreground = foreground.astype(float)
    background = background.astype(float)

    # Normalize the alpha mask to keep intensity between 0 and 1
    alpha = alpha.astype(float)/255

    # Multiply the foreground with the alpha matte
    foreground = cv2.multiply(alpha, foreground)

    # Multiply the background with ( 1 - alpha )
    background = cv2.multiply(1.0 - alpha, background)

    # Add the masked foreground and background.
    outImage = cv2.add(foreground, background)
    return cv2.resize(np.array(outImage),(512,512)),cv2.resize(generate_trimap(np.array(255*alpha)),(512,512))[:,:,0]


# In[7]:


def train_gen():
    with open(pd_dir+'Training_set/training_fg_names.txt') as f:
        fg_files = np.array(f.read().splitlines()).reshape((-1,1))
    with open(pd_dir+'Training_set/training_bg_names.txt') as f:
        bg_files = np.array(f.read().splitlines()).reshape((len(fg_files),-1))
    
    n=0
    x_img=[]
    y_img=[]
    while True:
        i=np.random.randint(0,431)
        j=np.random.randint(0,100)
        while bg_files[i,j]=='-1':
            i=np.random.randint(0,431)
            j=np.random.randint(0,100)
        x,y=combined_img(fg_files[i,0],bg_files[i,j])
        x_img.append(x)
        y=to_categorical(y//127,num_classes=3)
        y_img.append(y)
        bg_files[i,j]=-1        
        n+=1
        if n==batch_size_user:
            yield preprocess_input(np.array(x_img),mode='tf'),np.array(y_img)
            n=0
            x_img=[] 
            y_img=[]


# In[8]:


def val_gen():
    with open(pd_dir+'Test_set/test_fg_names.txt') as f:
        val_fg_files = np.array(f.read().splitlines()).reshape((-1,1))
    with open(pd_dir+'Test_set/test_bg_names.txt') as f:
        val_bg_files = np.array(f.read().splitlines()).reshape((len(val_fg_files),-1))
    n=0
    x_img=[]
    y_img=[]
    while True:
        i=np.random.randint(0,50)
        j=np.random.randint(0,20)
        while val_bg_files[i,j]=='-1':
            i=np.random.randint(0,50)
            j=np.random.randint(0,20)
        x,y=combined_img(val_fg_files[i,0],val_bg_files[i,j])
        x_img.append(x)
        y=to_categorical(y//127,num_classes=3)
        y_img.append(y)
        val_bg_files[i,j]=-1        
        n+=1
        if n==batch_size_user:
            yield preprocess_input(np.array(x_img),mode='tf'),np.array(y_img)
            n=0
            x_img=[] 
            y_img=[]


# In[ ]:





# In[9]:


model_1=Deeplabv3(backbone='xception')
model=Deeplabv3(backbone='xception',classes=3)
for l_tg,l_sr in zip(model.layers[:-2],model_1.layers[:-2]):
        l_tg.set_weights(l_sr.get_weights())
del model_1
for l in model.layers[:356]:
    l.trainable=False
checkpoint = ModelCheckpoint(""./best_model.h5"", monitor='val_loss', verbose = 1, save_best_only=True, mode = 'auto')
earlystop =  EarlyStopping(monitor='val_loss', min_delta=0.01, patience=5, verbose =1, mode=""auto"", restore_best_weights=True)
tb_callback=TensorBoard(log_dir=""logs_tb/{}"".format(int(time.time())),histogram_freq=1)
model.summary()


# In[11]:


model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True))


# In[14]:


model.fit(train_gen(),steps_per_epoch=43100//batch_size_user,validation_data=val_gen(),validation_steps=1000//batch_size_user,epochs=100,callbacks=[checkpoint, earlystop,tb_callback])


# In[ ]:



```



"
46854,Windows GUI application: ptxas.exe spawns a blank console window,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Professional
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 2.4.0
- Python version: N/A
- Bazel version (if compiling from source): Unknown
- GCC/Compiler version (if compiling from source): Visual Studio 2019
- CUDA/cuDNN version: 10.1
- GPU model and memory: GeForce GTX 1070

**Describe the current behavior**

When running our application that uses Tensorflow through a graphical interface, a command prompt window quickly appears and disappears the first time Tensorflow is used in the application.

**Describe the expected behavior**

No command prompt window should appear.

**Standalone code to reproduce the issue**

```c++
#include <windows.h>
#include <iostream>
#include <vector>

#include <tensorflow/c/c_api.h>

void deallocator(void* data, size_t, void*)
{
    delete[] static_cast<float*>(data);
}

// Standard ""console"" main: no problem
// int main() 

// Windows ""GUI"" main: problem occurs
int CALLBACK WinMain(_In_ HINSTANCE, _In_opt_ HINSTANCE, _In_ LPSTR, _In_ int)
{
    std::vector<unsigned char> config_opts =
    {
        0x32, 0xe, 0x9, 0x9a, 0x99, 0x99, 0x99, 0x99,
        0x99, 0xb9, 0x3f, 0x20, 0x1, 0x2a, 0x1, 0x30, 0x38, 0x1
    };

    TF_Status* status = TF_NewStatus();
    TF_Graph* graph = TF_NewGraph();
    TF_SessionOptions* options = TF_NewSessionOptions();
    TF_SetConfig(options, static_cast<const void*>(config_opts.data()), config_opts.size(), status);

    const char* const tag = ""serve"";
    TF_Session* session = TF_LoadSessionFromSavedModel(options, nullptr, ""model"", &tag, 1, graph, nullptr, status);

    TF_Output graph_input_tensor = { TF_GraphOperationByName(graph, ""input_tensor_name""), 0 };
    TF_Output graph_output_tensor = { TF_GraphOperationByName(graph, ""output_tensor_name""), 0 };

    const int64_t image_size = 256;
    const size_t image_area = image_size * image_size;
    int64_t input_dimensions[4] = { 1, image_size, image_size, 1 };
    const uint64_t buffer_size = sizeof(float) * image_area;

    void* buffer_data = new float[image_area];

    TF_Tensor* const input_tensor = TF_NewTensor(TF_FLOAT, input_dimensions, 4, buffer_data, buffer_size, &deallocator, nullptr);

    TF_Tensor* output_tensor = nullptr;
    TF_SessionRun(session, nullptr, &graph_input_tensor, &input_tensor, 1,
        &graph_output_tensor, &output_tensor, 1, nullptr, 0, nullptr, status);

    if (output_tensor) TF_DeleteTensor(output_tensor);
    if (input_tensor)  TF_DeleteTensor(input_tensor);
    if (session)       TF_DeleteSession(session, status);
    if (options)       TF_DeleteSessionOptions(options);
    if (graph)         TF_DeleteGraph(graph);
    if (status)        TF_DeleteStatus(status);

    return 0;
}
```

NB: To trigger the problem, you need the following pre-requisites:
 - a saved model folder (the one we use is proprietary, I cannot share it, but any model should do)
 - a Windows machine with a CUDA-capable GPU
 - the CUDA 10.x SDK installed on the machine

If you compile and run the code above, you should experience the issue. If you comment out the ``WinMain`` line and use the standard ``main`` entry point, the problem disappears.

I traced it down to Tensorflow spawning a sub-process to run ``ptxas.exe`` using the Windows API function ``CreateProcess``. This Windows API function [is called without specifying any ""process creation flag"" for the new process](https://github.com/tensorflow/tensorflow/blob/14cd0d3440908d4f8b4a9a557bfc88cf6ddaaeaf/tensorflow/core/platform/windows/subprocess.cc#L269). According to the [Windows API documentation](https://docs.microsoft.com/en-us/windows/win32/procthread/process-creation-flags), the flag ``CREATE_NO_WINDOW`` should be provided to avoid the sub-process creating any window (in this case, ``ptxas.exe`` opening a blank console window).

The different behavior of ``CreateProcess`` for GUI vs console applications doesn't seem to be documented (Edit: it is. The default behavior is to inherit the console of the parent process, but if the parent process has no console, a new one is created). But definitely the flag ``CREATE_NO_WINDOW``  should be passed, since the intent is just to run a console application in the background, not to open a new window for the user to interact with.

To be clear:
 - The problem won't occur if the main program is compiled as a console application, because ptxas.exe will then just reuse the console window of the main process.
 - The problem won't occur if the CUDA SDK is not installed on the machine, as ptxas.exe won't be found and won't be executed. I don't know if there are other instances where this program can end up in the system PATH, hence be found by Tensorflow.
 - AFAIK, the problem won't occur with CUDA 11 because from this version on, ptxas is a DLL and not an EXE.
 - The above is specific to ptxas.exe, but the root of the problem isn't. I don't know if Tensorflow uses CreateProcess for other purposes. If so, it will be affected in a similar manner."
46853,Cannot use load_model when using a layer with dynamic = True and saving to hdf5 format,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11.0
- GPU model and memory: NVIDIA Quadro RXT 6000, 24 GB NVRAM

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
When building a model (using the Function API), I need to use a layer in dynamic mode as far as I can tell, since the task is going to involve operations along an axis of variable size.
While the training works perfectly fine, and the saving of the model also does as far as I can tell (no error, at least), when loading the model back up using load_model fails with the error:
ValueError: You are trying to load a weight file containing [n] layers into a model with [n-1] layers.

Upon inspection of the load_weights_from_hdf5_group function, it appears that layers build with dynamic=True return an empty list with trying to get the weights, which results in such layers not being included in the following operations, ultimately resulting in the function failing. However, the layer itself is found and otherwise normal (e.g. its name gets found properly by the same function).

This affects both new models and ones saved before the update.

**Describe the expected behavior**
The model should load properly, as it did in previous versions (I have tested up to 2.3.1). 

**Standalone code to reproduce the issue**
I write two versions of the same little script, the only difference is the `dynamic` flag in the first Conv2D layer.
I originally discovered this when using a custom layer (where the need for the dynamic=True flag came in), but this also happens when using the Conv2D layer.
```
from tensorflow.keras.models import load_model, Model
from tensorflow.keras.layers import Conv2D, Input

# this works
inp = Input(shape=(64, None, 3))
conv = Conv2D(4, (3, 3), dynamic=False)
# dynamic = True apparently requires manual building, which might or might not be a separate issue
conv.build(inp.shape)
x = conv(inp)
x = Conv2D(4, (3, 3))(x)

mod1 = Model(inputs=inp, outputs=x)

mod1.save(""test.hdf5"")
load_model(""test.hdf5"")
print(""Succesfully loaded this model"")

# this fails:
inp = Input(shape=(64, None, 3))
conv = Conv2D(4, (3, 3), dynamic=True)
# dynamic = True apparently requires manual building, which might or might not be a separate issue
conv.build(inp.shape)
x = conv(inp)
x = Conv2D(4, (3, 3))(x)

mod1 = Model(inputs=inp, outputs=x)

mod1.save(""test.hdf5"")
load_model(""test.hdf5"")
print(""Succesfully loaded this model"")`

**Other info / logs** 
`Traceback (most recent call last):
  File ""C:/Users/killian/AppData/Roaming/JetBrains/PyCharmCE2020.1/scratches/scratch_7.py"", line 29, in <module>
    load_model(""test.hdf5"")
  File ""C:\Users\killian\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\keras\saving\save.py"", line 207, in load_model
    compile)
  File ""C:\Users\killian\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\keras\saving\hdf5_format.py"", line 187, in load_model_from_hdf5
    load_weights_from_hdf5_group(f['model_weights'], model.layers)
  File ""C:\Users\killian\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\keras\saving\hdf5_format.py"", line 691, in load_weights_from_hdf5_group
    ' layers.')
ValueError: You are trying to load a weight file containing 2 layers into a model with 1 layers.
`
"
46852,experimental apis in iOS pod is missing.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): v2.4
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
experimental apis  in iOS pod is missing.

**Will this change the current api? How?**
No

**Who will benefit with this feature?**

**Any Other info.**
"
46851,TF 2.5 nightly CUDA driver check failed ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.5.0-dev20210202
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?: Pip 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.0/8.0.4
- GPU model and memory: 2 x RTX 3090 w/ 24GB


**Describe the problem**
I have installed the tensorflow 2.5 nightly builds: 
```
pip install tf-nightly-gpu
pip install tf-nightly
```
into a virtual environment to try and address performance issues with using a dual RTX 3090 setup. When I try and execute the python script I get the following error from the CUDA driver: 
```
2021-02-02 09:48:40.071972: F tensorflow/stream_executor/cuda/cuda_driver.cc:1289] Check failed: context != nullptr success should entail non-null context
```

I assume this might be linked to the CUDA/cuDNN revision being used but I can't find any instructions as to the versions being of CUDA/cuDNN being expected. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
pip install tf-nightly-gpu
pip install tf-nightly

**run python script** 

```

N.B. the script is working as it executes under other versions of TF. 

"
46850,Issue is not managed well,"Friends, I opened this issue https://github.com/tensorflow/tensorflow/issues/46315 already 3 weeks ago and it look like it is not prioritized and no ETA.... And actually for me it looks like ""talking"" and not ""doing"" progress.
I would like to understand if it is regular situation when the updates from support side come a week after ?

Thanks
"
46849,the label_smoothing argument for CE loss in keras,"Recently, I find that only the loss function 

tf.keras.losses.categorical_crossentropy(y_true,y_pred,from_logits=True,label_smoothing=0.1)

has argument ""label_smoothing"", 

both function:  tf.keras.losses.sparse_categorical_crossentropy
and class:  tf.keras.losses.SparseCategoricalCrossentropy

do not have this parameter.

Why not add ""label_smoothing"" to this CE loss functions?"
46848,LinearRegression Example in ForwardAccumulator docstring has an error,"## URL(s) with the issue:

https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/eager/forwardprop.py#L234

## Description of issue (what needs changing):

I was trying to understand precisely how ForwardAccumulator.jvp works and was working through the example to which I have linked. From computing by hand what I believed to be the correct jvp formula, and comparing it to the linear regression code I found that in the line

  ...   loss = tf.reduce_sum((dense(x) - tf.constant([1., -1.])) ** 2.)

the target 
tf.constant([1., -1.]) 
which I would call 'y', should be reshaped, for example replaced by 
tf.constant([[1.], [-1.]]) 

The code as it stands introduces a multiplicative factor of n in the loss function where n is the number of samples. This same problem occurs in other places in this docstring. 

Would it be possible to include somewhere in this docstring a formula for the jacobian-vector-product?
"
46847,"Hi everyone, I want to look at the person_detect.tflite model you mentioned in Arduino IDE ESP32 person detection code, I want to look at the input layer of it, my beetle classifier has 96 by 96 and is grayscale so it is 1 x 96 x96 x1, but I am not sure if I can modify the person detection code to detect beetle or cat and dog TFlite converted to c model. Would you please provide the person_detect.tflite model available online? ","@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source):
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**

**Please provide the exact sequence of commands/steps when you ran into the problem**

"
46846,Creating custom model for object detection,How can I create a custom model from a directory containing some images????????????I dont want to download a pre trained model.I want to make my own model for object detection.How can I do that??????
46845,[docker]  ERROR executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc,"I have configured the `GPU` build from sources via `docker` as described in the docs:
```
docker pull tensorflow/tensorflow:devel-gpu
docker run --gpus all -it -w /tensorflow -v $PWD:/mnt -e HOST_PERMS=""$(id -u):$(id -g)"" tensorflow/tensorflow:devel-gpu bash
```
The `configure` selected options were:

```
Found possible Python library paths:
  /usr/lib/python3/dist-packages
  /usr/local/lib/python3.6/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]
Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as ""x.y"" or ""compute_xy"" to include both virtual and binary GPU code, or as ""sm_xy"" to only include the binary code.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 6.1 
Do you wish to build TensorFlow with ROCm support? [y/N]: N
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: core2
```

Please note that I have selected `core2` since my aim is to build a older arch cpu with GPUs support build. Then I run the build as 

```
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```

Using the build option `--verbose_failures` I get the following error logs:

```
ERROR: /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/com_google_protobuf/BUILD:110:11: C++ compilation of rule '@com_google_protobuf//:protobuf_lite' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/include/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64/stubs \
    PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/external/com_google_protobuf/_objs/protobuf_lite/statusor.d '-frandom-seed=bazel-out/host/bin/external/com_google_protobuf/_objs/protobuf_lite/statusor.o' -iquote external/com_google_protobuf -iquote bazel-out/host/bin/external/com_google_protobuf -isystem external/com_google_protobuf/src -isystem bazel-out/host/bin/external/com_google_protobuf/src -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIE -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 -w core2 -g0 '-std=c++14' -DHAVE_PTHREAD -DHAVE_ZLIB -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -Wno-write-strings -c external/com_google_protobuf/src/google/protobuf/stubs/statusor.cc -o bazel-out/host/bin/external/com_google_protobuf/_objs/protobuf_lite/statusor.o)
Execution platform: @local_execution_config_platform//:platform
x86_64-linux-gnu-gcc-7: error: core2: No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1.453s, Critical Path: 0.14s
INFO: 17 processes: 14 internal, 3 local.
FAILED: Build did NOT complete successfully
```

The whole log is available [here](https://gist.github.com/loretoparisi/d8d7b29010d72bedb37cc61f4f48b1d2)."
46844,gpt2 int8 quantization:  op_context.input->type == kTfLiteUInt8 || op_context.input->type == kTfLiteInt8 || op_context.input->type == kTfLiteInt16 || op_context.input->type == kTfLiteFloat16 was not true.Node number 15 (DEQUANTIZE) failed to prepare ,"TF: 2.4.1 
Huggingface/transformers: 4.2.2
Python: 3.8

**Describe the current behavior**
The int8 quantization during the exporting has no error or problem. But it would throw an error when it is invoked. 
```
RuntimeError: tensorflow/lite/kernels/dequantize.cc:61 op_context.input->type == kTfLiteUInt8 || op_context.input->type == kTfLiteInt8 || op_context.input->type == kTfLiteInt16 || op_context.input->type == kTfLiteFloat16 was not true.Node number 15 (DEQUANTIZE) failed to prepare.
```
Note if we only use `last_hidden_state` for tflite, this would have no problem. It seems like `tf.matmul` is a problem.

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import random

import numpy as np
import tensorflow as tf
from transformers import *

rng = random.Random()

gpt2_model = TFGPT2Model.from_pretrained('distilgpt2')


def get_tf_lm_head_tensor():
    gpt2_lm_pt_model = GPT2LMHeadModel.from_pretrained('distilgpt2')
    np_tensor = gpt2_lm_pt_model.lm_head.weight.detach().numpy()
    np_tensor = np.transpose(np_tensor)
    tf_lm_head_tensor = tf.convert_to_tensor(np_tensor)
    return tf_lm_head_tensor


tf_lm_head = get_tf_lm_head_tensor()

@tf.function(input_signature=[tf.TensorSpec(shape=(1, None), dtype=tf.int32, name=""input_ids"")])
def serving_func(input_ids):
    outputs = gpt2_model(input_ids, training=False)
    last_hidden_state = outputs[0][0][-1:, :]
    next_token_logits = tf.matmul(last_hidden_state, tf_lm_head)
    next_token = tf.math.argmax(next_token_logits, axis=-1, output_type=tf.int32)
    log_probs = tf.math.reduce_max(tf.nn.log_softmax(next_token_logits))
    return {""decoded_ids"": next_token, ""log_probs"": log_probs}


tensors = []
for example in range(100):
    values = [[rng.randint(0, 30000) for _ in range(8)]]
    tensors.append(np.array(values, dtype=np.int32))


def representative_dataset_gen():
    for ts in tensors:
        yield [ts]


converter = tf.lite.TFLiteConverter.from_concrete_functions([serving_func.get_concrete_function(
    tf.TensorSpec(shape=(1, None), dtype=tf.int32, name='input_ids'))])
# converter.experimental_new_converter = True
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS,
                                       tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
tflite_quant_model = converter.convert()
with open(""/tmp/model.tflite"", 'wb') as f:
    f.write(tflite_quant_model)

# invoke the model
import tensorflow as tf

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=""/tmp/model.tflite"")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

import numpy as np
# Test the TensorFlow Lite model on random input data.
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.int32)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46843,Distributed training using Parameterstrategy ,"Hi All,

I am new to Tensorflow and trying to implement distributed Tensorflow using ParameterStrategy based on the [Documentation][1]. So far I have the code below

  [1]: https://www.tensorflow.org/tutorials/distribute/parameter_server_training
```
import multiprocessing
import os
import portpicker
import tensorflow as tf
import tensorflow.keras as keras
import tensorflow.keras.layers.experimental.preprocessing as kpl
import tensorflow_hub as hub
import numpy as np
print(tf.__version__)

def create_in_process_cluster(num_workers, num_ps):
  """"""Creates and starts local servers and returns the cluster_resolver.""""""
  worker_ports = [portpicker.pick_unused_port() for _ in range(num_workers)]
  ps_ports = [portpicker.pick_unused_port() for _ in range(num_ps)]

  cluster_dict = {}
  cluster_dict[""worker""] = [""localhost:%s"" % port for port in worker_ports]
  if num_ps > 0:
    cluster_dict[""ps""] = [""localhost:%s"" % port for port in ps_ports]

  cluster_spec = tf.train.ClusterSpec(cluster_dict)

  # Workers need some inter_ops threads to work properly.
  worker_config = tf.compat.v1.ConfigProto()
  if multiprocessing.cpu_count() < num_workers + 1:
    worker_config.inter_op_parallelism_threads = num_workers + 1

  for i in range(num_workers):
    tf.distribute.Server(
        cluster_spec, job_name=""worker"", task_index=i, config=worker_config,
        protocol=""grpc"")

  for i in range(num_ps):
    tf.distribute.Server(
        cluster_spec, job_name=""ps"", task_index=i, protocol=""grpc"")

  cluster_resolver = tf.distribute.cluster_resolver.SimpleClusterResolver(
      cluster_spec, task_id=0, task_type=""worker"",rpc_layer=""grpc"")
  return cluster_resolver

# Set the environment variable to allow reporting worker and ps failure to the
# coordinator. This is a workaround and won't be necessary in the future.
os.environ[""GRPC_FAIL_FAST""] = ""use_caller""

NUM_WORKERS = 3
NUM_PS = 2
cluster_resolver = create_in_process_cluster(NUM_WORKERS, NUM_PS)

variable_partitioner = (
    tf.distribute.experimental.partitioners.FixedShardsPartitioner(
        num_shards=NUM_PS))

strategy = tf.distribute.experimental.ParameterServerStrategy(cluster_resolver)

word = ""Elephant""
sentence = ""I am a sentence for which I would like to get its embedding.""
paragraph = (
    ""Universal Sentence Encoder embeddings also support short paragraphs. ""
    ""There is no hard limit on how long the paragraph is. Roughly, the longer ""
    ""the more 'diluted' the embedding will be."")
messages = [word, sentence, paragraph]
labels=[""1"",""2"",""3""]
reviews = [[1,0,0],[0,1,0],[0,0,1]]

encoder=hub.load(""https://tfhub.dev/google/universal-sentence-encoder/4"")

X_train=encoder(messages)

with strategy.scope():
  feature_lookup_layer = kpl.StringLookup(vocabulary=messages)

  label_lookup_layer = kpl.StringLookup(vocabulary=labels,
                                        num_oov_indices=0,
                                        mask_token=None)

  raw_feature_input = keras.layers.Input(
      shape=(1,), dtype=tf.string, name=""feature"")
  feature_id_input = feature_lookup_layer(raw_feature_input)
  feature_preprocess_stage = keras.Model(
      {""features"": raw_feature_input}, feature_id_input)

  raw_label_input = keras.layers.Input(
      shape=(3,), dtype=tf.string, name=""label"")
  label_id_input = label_lookup_layer(raw_label_input)
  label_preprocess_stage = keras.Model({""label"": raw_label_input}, label_id_input)

examples = {""features"": [word,sentence,paragraph], ""label"": [[""1"",""0"",""0""],[""0"",""1"",""0""],[""0"",""0"",""1""]]}
print(examples)
def dataset_fn(_):
  raw_dataset = tf.data.Dataset.from_tensor_slices(examples)

  train_dataset = raw_dataset.map(
      lambda x: (
          {""features"": feature_preprocess_stage(x[""features""])},
          label_preprocess_stage(x[""label""])
      )).shuffle(200).batch(32).repeat()
  return train_dataset


# These variables created under the `strategy.scope` will be placed on parameter
# servers in a round-robin fashion.
with strategy.scope():
  # Create the model. The input needs to be compatible with KPLs.
  model_input = keras.layers.Input(
      shape=(3,), dtype=tf.int64, name=""model_input"")

  emb_layer = keras.layers.Embedding(
      input_dim=len(feature_lookup_layer.get_vocabulary()), output_dim=20)
  emb_output = tf.reduce_mean(emb_layer(model_input), axis=1)
  dense_output = keras.layers.Dense(units=1, activation=""sigmoid"")(emb_output)
  model = keras.Model({""features"": model_input}, dense_output)

  optimizer = keras.optimizers.RMSprop(learning_rate=0.1)
  accuracy = keras.metrics.Accuracy()


@tf.function
def step_fn(iterator):

  def replica_fn(batch_data, labels):
    with tf.GradientTape() as tape:
      pred = model(batch_data, training=True)
      per_example_loss = keras.losses.CategoricalCrossentropy(
              reduction=tf.keras.losses.Reduction.NONE)(labels, pred)
      loss = tf.nn.compute_average_loss(per_example_loss)
      gradients = tape.gradient(loss, model.trainable_variables)

    optimizer.apply_gradients(zip(gradients, model.trainable_variables))

    actual_pred = tf.cast(tf.greater(pred, 0.5), tf.int64)
    accuracy.update_state(labels, actual_pred)
    return loss

  batch_data, labels = next(iterator)
  losses = strategy.run(replica_fn, args=(batch_data, labels))
  return strategy.reduce(tf.distribute.ReduceOp.SUM, losses, axis=None)


coordinator = tf.distribute.experimental.coordinator.ClusterCoordinator(strategy)
@tf.function
def per_worker_dataset_fn():
  return strategy.distribute_datasets_from_function(dataset_fn)


per_worker_dataset = coordinator.create_per_worker_dataset(per_worker_dataset_fn)
per_worker_iterator = iter(per_worker_dataset)

num_epoches = 2
steps_per_epoch = 1
for i in range(num_epoches):
  accuracy.reset_states()
  for _ in range(steps_per_epoch):
    coordinator.schedule(step_fn, args=(per_worker_iterator,))
  # Wait at epoch boundaries.
  coordinator.join()
  print (""Finished epoch %d, accuracy is %f."" % (i, accuracy.result().numpy()))
```

In this example, I'm trying to convert the document example from binary classification to Categorical classification. But I'm getting the following error.

> ValueError: Input 0 of layer dense is incompatible with the layer: : expected min_ndim=2, found ndim=1. Full shape received: (None,)
 
I have Tensotflow `2.4.1` version  "
46840,TypeError: __array__() takes 1 positional argument but 2 were given,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code: yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOs Big Sur
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1
- Python version: 3.8.7

**Describe the current behavior**

I'm trying to assign the return value of `get_value()` to a numpy array within a method decorated using `tf.function`. It works only if I call the method directly. However, if I use the result of `tf.numpy_function()` (in `case3`), I get an error. 

**Describe the expected behavior**

I don't know, but the error is not doing any good explaining why this is happening

**Standalone code to reproduce the issue**
Please find the notebook [here](https://colab.research.google.com/drive/1npV2ZmDE-So0IlA63MpoKhIs7sL-N6Xu?usp=sharing) which contains the following:

    import numpy as np
    import tensorflow as tf
    
    
    class Foo:
        def __init__(self):
            self.storage = np.zeros((10, 3, 1))
    
        @staticmethod
        def get_value(): 
            return np.array([[1], [2], [3]])
    
        @tf.function
        def case1(self):  # works
            self.storage[0] = self.get_value()
    
        def case2(self):  # works
            self.storage[0] = tf.numpy_function(self.get_value, inp=[], Tout=tf.float32)
    
        @tf.function  # fails
        def case3(self):
            self.storage[0] = tf.numpy_function(self.get_value, inp=[], Tout=tf.float32)
    
    
    if __name__ == '__main__':
        foo = Foo()
        foo.case1()
        foo.case2()
        foo.case3()

Error:

    2021-02-01 23:11:35.422101: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
    2021-02-01 23:11:35.422548: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
    To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
    2021-02-01 23:11:35.439501: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
    Traceback (most recent call last):
      File ""/Users/emadboctor/Library/Application Support/JetBrains/PyCharm2020.3/scratches/scratch.py"", line 29, in <module>
        foo.case3()
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 828, in __call__
        result = self._call(*args, **kwds)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 871, in _call
        self._initialize(args, kwds, add_initializers_to=initializers)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 725, in _initialize
        self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2969, in _get_concrete_function_internal_garbage_collected
        graph_function, _ = self._maybe_define_function(args, kwargs)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3361, in _maybe_define_function
        graph_function = self._create_graph_function(args, kwargs)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3196, in _create_graph_function
        func_graph_module.func_graph_from_py_func(
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 990, in func_graph_from_py_func
        func_outputs = python_func(*func_args, **func_kwargs)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 634, in wrapped_fn
        out = weak_wrapped_fn().__wrapped__(*args, **kwds)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3887, in bound_method_wrapper
        return wrapped_fn(*args, **kwargs)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 977, in wrapper
        raise e.ag_error_metadata.to_exception(e)
    TypeError: in user code:
    
        /Users/emadboctor/Library/Application Support/JetBrains/PyCharm2020.3/scratches/scratch.py:22 case3  *
            self.storage[0] = tf.numpy_function(self.get_value, inp=[], Tout=tf.float32)
    
        TypeError: __array__() takes 1 positional argument but 2 were given

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46837,FATAL ERROR: tensorflow/core/framework/types.pb.h: No such file or directory,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes. Standard C++ program used to previously compile and run with TF 1.1 (CUDA - 9.2 and CUDNN 7.2 )
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6.9
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 7.5
- CUDA/cuDNN version: CUDA - 10.2/ CUDNN - 7.6
- GPU model and memory: Quadro P5200, 32 Gb RAM


**Describe the current behavior**
TF 2.3.0 successfully installs with bazel. However, while compiling a C++ program using gcc, I get the following error
_**/usr/local/include/tensorflow/tensorflow/core/framework/tensor_shape.h:22:10: fatal error: tensorflow/core/framework/types.pb.h: No such file or directory**_
I tried to locate the types.pb.h file and found the file in _/home/%username%/.cache/bazel/_bazel_%username%/3fa00a5b455754a3e6fd353fefb67596/execroot/org_tensorflow/bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/framework/types.pb.h_
Copying or including this folder/file did not help as additional dependencies were missing. 

**Standalone code to reproduce the issue**
Clone tensorflow from github and checkout v2.3.0. Run ./configure with following options (refer attachment)
Bazel build with the following options:
_bazel build -c opt \
            --copt=-mavx \
            --copt=-mavx2 \
            --copt=-mfma \
            --copt=-mfpmath=both \
            --copt=-msse4.2 \
            --config=cuda //tensorflow:libtensorflow_cc.so_
[TF_Config.txt](https://github.com/tensorflow/tensorflow/files/5906638/TF_Config.txt)

"
46835,"Bug or me? Using a generator with a dataset, impossible to correctly specify shapes","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10/Ubuntu 18.04/Macos
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below):v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: 3.8.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.1
- GPU model and memory: 1080TI 8gigs

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Creating a functional model with multiple outputs seems to work fine if all of the data is in memory or being sourced from files, but using a generator it seems to be impossible to properly define the shapes.  I've tried both the deprecated `output_*` options and the current `output_signature` options to no avail.  It is entirely possible it is just me, but if so, it is possible the the documentation might be a tad incorrect. :)

**Describe the expected behavior**
I would expect that the shape of the data can be properly defined and used for fitting!

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

This code will compile fine but fail to fit with an error concerning the data shape.  I've redefined the data to be any of a variety of shapes... As soon as I switch to multiple outputs, this fails.

```
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models

def generate_sample():
    x = list(""123456789"")
    y = list(""2345"")
    while 1:
        yield np.array(x).astype(np.float32),[np.array(y).astype(np.float32),np.array(y).astype(np.float32)]

dataset = tf.data.Dataset.from_generator(generate_sample,
            output_signature=(
                 tf.TensorSpec(shape=(9,), dtype=tf.float32),
                 tf.TensorSpec(shape=(2,4), dtype=tf.float32)

            ))

dataset = dataset.batch(batch_size=32)

inputs = keras.Input(shape=(next(generate_sample())[0].shape))
x = layers.Dense(512, activation = ""relu"")(inputs)
x_outputs = layers.Dense(4, activation=""relu"", name=""output"")(x)
y_outputs = layers.Dense(4, activation=""relu"", name=""output2"")(x)

model = keras.Model(inputs=inputs, outputs=[x_outputs,y_outputs])
model.compile(loss=""mse"", optimizer = ""adam"", metrics=['accuracy'])
history = model.fit(dataset, epochs=1, steps_per_epoch=10, validation_data=dataset, validation_steps=5)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-102-3dad39c1e2c1> in <module>
----> 1 history = model.fit(dataset, epochs=1, steps_per_epoch=10, validation_data=dataset, validation_steps=5)

~\anaconda3\envs\SEC595\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1098                 _r=1):
   1099               callbacks.on_train_batch_begin(step)
-> 1100               tmp_logs = self.train_function(iterator)
   1101               if data_handler.should_sync:
   1102                 context.async_wait()

~\anaconda3\envs\SEC595\lib\site-packages\tensorflow\python\eager\def_function.py in __call__(self, *args, **kwds)
    826     tracing_count = self.experimental_get_tracing_count()
    827     with trace.Trace(self._name) as tm:
--> 828       result = self._call(*args, **kwds)
    829       compiler = ""xla"" if self._experimental_compile else ""nonXla""
    830       new_tracing_count = self.experimental_get_tracing_count()

~\anaconda3\envs\SEC595\lib\site-packages\tensorflow\python\eager\def_function.py in _call(self, *args, **kwds)
    886         # Lifting succeeded, so variables are initialized and we can run the
    887         # stateless function.
--> 888         return self._stateless_fn(*args, **kwds)
    889     else:
    890       _, _, _, filtered_flat_args = \

~\anaconda3\envs\SEC595\lib\site-packages\tensorflow\python\eager\function.py in __call__(self, *args, **kwargs)
   2940       (graph_function,
   2941        filtered_flat_args) = self._maybe_define_function(args, kwargs)
-> 2942     return graph_function._call_flat(
   2943         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
   2944 

~\anaconda3\envs\SEC595\lib\site-packages\tensorflow\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1916         and executing_eagerly):
   1917       # No tape is watching; skip to running the function.
-> 1918       return self._build_call_outputs(self._inference_function.call(
   1919           ctx, args, cancellation_manager=cancellation_manager))
   1920     forward_backward = self._select_forward_and_backward_functions(

~\anaconda3\envs\SEC595\lib\site-packages\tensorflow\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    553       with _InterpolateFunctionError(self):
    554         if cancellation_manager is None:
--> 555           outputs = execute.execute(
    556               str(self.signature.name),
    557               num_outputs=self._num_outputs,

~\anaconda3\envs\SEC595\lib\site-packages\tensorflow\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     57   try:
     58     ctx.ensure_initialized()
---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:

InvalidArgumentError:  Incompatible shapes: [32,2,4] vs. [32,4]
	 [[node mean_squared_error/SquaredDifference (defined at <ipython-input-102-3dad39c1e2c1>:1) ]] [Op:__inference_train_function_12605]

Function call stack:
train_function
```"
46834,floating point exception in tf.nn.avg_pool3d and tf.nn.max_pool3dwhen ksize=0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
floating point exception in `tf.nn.avg_pool3d` and `tf.nn.max_pool3d` when `ksize`=0



**Describe the expected behavior**
expect no crash
**Standalone code to reproduce the issue**

The code crashes in nightly version too. Check out the [gist](https://colab.research.google.com/drive/10O4Qn2S4uW-40jLDHvlUBN_vlMsQkUo-?usp=sharing)
~~~python
tf.nn.avg_pool3d(input=tf.ones((1,1,1,1,1)), strides=1, ksize=0, padding='VALID')
~~~

~~~python
tf.nn.max_pool3d(input=tf.ones((1,1,1,1,1)), strides=1, ksize=0, padding='VALID')
~~~
Output:
~~~python
Floating point exception (core dumped)
~~~"
46833,backing_device changes depending on the tensor's dtype,"Hi!

I have noticed that `backing_device` changes depending on the Tensor's `dtype`:

```python
import tensorflow as tf
tensor_1 = tf.math.add(tf.zeros([2, 2]), [[1, 2], [3, 4]])
tensor_2 = tf.math.add(tf.zeros([2, 2], dtype=tf.dtypes.int32), [[1, 2], [3, 4]])
 
print(tensor_1.backing_device)
print(tensor_2.backing_device)
```
 

```
/job:localhost/replica:0/task:0/device:GPU:0
/job:localhost/replica:0/task:0/device:CPU:0
```

The behaviour above has some impact when interacting with other libraries. For instance, when exporting the Tensor via DLPack, some libraries (i.e. CUDA or JAX), do not support DLPack object hosted in CPU memory.

Hope it helps!
Miguel

**System information**
- TensorFlow version: 2.4.1
- Ubuntu 20.04
- Cuda 11.0
- Python 3.8
- Installed via pip.

**Describe the current behavior**
One tensor backing device is CPU, while the other is GPU.

**Describe the expected behavior**
Having GPU as backing device for both tensors.
"
46832,Error when converting a resnetv1_50 based model trained with Tensorflow.,"### 1. System information

- OS Platform and Distribution: Windows 10
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): Tensorflow 1.15

### 2. Code

```
from tensorflow import lite
## Training model code is omitted here ##

saver.save(sess, path_to_save, global_step=it)
        
# Converting a GraphDef from session.
converter = lite.TFLiteConverter.from_session(sess, list(batch.values()), posenet.output_tensors)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
converter.allow_custom_ops=True
tflite_model = converter.convert()
open(""./converted_model.tflite"", ""wb"").write(tflite_model)
```


#### Option B: Paste your code here or provide a link to a custom end-to-end colab

```
[Link to my notebook in drive](https://drive.google.com/file/d/1xnmr69QOCmUByZbDQNTBLBp0RQbbKYqb/view?usp=sharing)
```

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:
The conversion didn't work.

### 5. (optional) Any other info / logs
**These are my inputs:**
[<tf.Tensor 'fifo_queue_Dequeue:0' shape=(1, 200, 200, 3) dtype=float32>,
<tf.Tensor 'fifo_queue_Dequeue:1' shape=(1, 26, 26, 21) dtype=float32>,
<tf.Tensor 'fifo_queue_Dequeue:2' shape=(1, 26, 26, 21) dtype=float32>,
<tf.Tensor 'fifo_queue_Dequeue:3' shape=(1, 26, 26, 42) dtype=float32>,
<tf.Tensor 'fifo_queue_Dequeue:4' shape=(1, 26, 26, 42) dtype=float32>]

**These are my outputs:**
[<tf.Tensor 'pose/part_pred/block4/BiasAdd:0' shape=(1, 26, 26, 21) dtype=float32>,
<tf.Tensor 'pose/locref_pred/block4/BiasAdd:0' shape=(1, 26, 26, 42) dtype=float32>]


```
I'm showing the error output below, any help will be useful:
`---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-10-458b03f29263> in <module>
     30         converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
     31         converter.allow_custom_ops=True
---> 32         tflite_model = converter.convert()
     33 #         open(""./converted_model.tflite"", ""wb"").write(tflite_model)
     34 #         with open('model.tflite', 'wb') as f:

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\lite\python\lite.py in convert(self)
    981           input_tensors=self._input_tensors,
    982           output_tensors=self._output_tensors,
--> 983           **converter_kwargs)
    984     else:
    985       result = _toco_convert_graph_def(

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\lite\python\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    447       input_data.SerializeToString(),
    448       debug_info_str=debug_info_str,
--> 449       enable_mlir_converter=enable_mlir_converter)
    450   return data
    451 

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    198       stdout = _try_convert_to_unicode(stdout)
    199       stderr = _try_convert_to_unicode(stderr)
--> 200       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    201   finally:
    202     # Must manually cleanup files.

ConverterError: See console for info.
El sistema no puede encontrar la ruta especificada.
2021-02-01 17:29:45.263535: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_100.dll'; dlerror: cudart64_100.dll not found
2021-02-01 17:29:45.264019: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
c:\users\pipita\anaconda3\envs\aws_train\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
c:\users\pipita\anaconda3\envs\aws_train\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
c:\users\pipita\anaconda3\envs\aws_train\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
c:\users\pipita\anaconda3\envs\aws_train\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
c:\users\pipita\anaconda3\envs\aws_train\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
c:\users\pipita\anaconda3\envs\aws_train\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
2021-02-01 17:29:48.157783: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: FIFOQueueV2
2021-02-01 17:29:48.158185: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2021-02-01 17:29:48.290435: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: QueueDequeueV2
2021-02-01 17:29:48.322668: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 685 operators, 1055 arrays (0 quantized)
2021-02-01 17:29:48.343643: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 683 operators, 1054 arrays (0 quantized)
2021-02-01 17:29:48.367174: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 683 operators, 1054 arrays (0 quantized)
2021-02-01 17:29:48.582688: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 92 operators, 231 arrays (0 quantized)
2021-02-01 17:29:48.586252: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 92 operators, 231 arrays (0 quantized)
2021-02-01 17:29:48.588560: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 92 operators, 231 arrays (0 quantized)
2021-02-01 17:29:48.593331: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 10880000 bytes, theoretical optimal value: 7680000 bytes.
2021-02-01 17:29:48.594149: I tensorflow/lite/toco/toco_tooling.cc:439] Estimated count of arithmetic ops: 10608315996 ops, equivalently 5304157998 MACs
2021-02-01 17:29:48.594470: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 24644870`

```



"
46831,TF 2.4.1: Mirrored Strategy not providing performance boost RTX 3090 ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.0/8.0.4.30
- GPU model and memory: 2x RTX 3090/24GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

I have a dataset created from an image directory (tf.keras.preprocessing.image_dataset_from_directory()). I then use a mirrored strategy (tf.distribute.MirroredStrategy) to create and compile my model then I try training the model using model.fit(). The call to model.fit causes an error message to inform me that the dataset is unshardable. I am therefore not receiving a performance increase from the second RTX 3090 GPU that I have just installed in the machine. 


**Describe the expected behavior**

When I used this approach using Tensorflow 2.3.1 and 2 x RTX 2060s, I did not generate any error messages about sharding the dataset, the log printed that it was running with a mirrored strategy, and listed the GPUs being used, and there was a significant performance boost

**Standalone code snippet to reproduce the issue**

```

def get_compiled_model(num_classes, dim_x, dim_y, dim_z):

        data_augmentation = keras.Sequential(
          [
                layers.experimental.preprocessing.RandomFlip(""horizontal"", input_shape=(dim_x, dim_y, dim_z)),
                layers.experimental.preprocessing.RandomRotation(0.1),
                layers.experimental.preprocessing.RandomZoom(0.1),
          ]
        )


        model = Sequential([
          data_augmentation,
          layers.experimental.preprocessing.Rescaling(1./255),
          layers.Conv2D(2, 3, padding='same', activation='relu'),
          layers.MaxPooling2D(),
          #layers.Conv2D(32, 3, padding='same', activation='relu'),
          #layers.MaxPooling2D(),
          #layers.Conv2D(64, 3, padding='same', activation='relu'),
          #layers.MaxPooling2D(),
          layers.Dropout(0.2),
          layers.Flatten(),
          layers.Dense(6, activation='relu'),
          layers.Dropout(0.2),
          layers.Dense(num_classes)
        ])
        model.compile(
                #optimizer=tf.keras.optimizers.Adam(),
                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                optimizer=tf.keras.optimizers.Adam(),
                metrics=['accuracy'],
        )

        return model


## create data set 

        train_ds = tf.keras.preprocessing.image_dataset_from_directory(
          data_dir,
          validation_split=0.2,
          subset=""training"",
          seed=123,
          image_size=(50, 50),
          batch_size=2048,
          color_mode='grayscale'
        )
        val_ds = tf.keras.preprocessing.image_dataset_from_directory(
          data_dir,
          validation_split=0.2,
          subset=""validation"",
          seed=123,
          image_size=(50, 50),
          batch_size=2048,
          color_mode='grayscale'
        )


## create model with mirrored strategy 
        mirrored_strategy = tf.distribute.MirroredStrategy()

        with mirrored_strategy.scope():

                model = get_compiled_model(2, 50, 50, 1):


## train model 

        history = model.fit(
          train_ds,
          validation_data=val_ds,
          epochs=5000,
          initial_epoch=0,
        )

```
"
46829,Missing CI for OPTIMIZED_KERNEL_DIR=cmsis_nn with MVEI extension,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source):
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**
The CI script tensorflow/lite/micro/tools/ci_build/test_stm32f4.sh tests OPTIMIZED_KERNEL_DIR=cmsis_nn with DSP extension.
However there is no equivalent test for MVEI extension, i.e. Cortex-M55.

**Please provide the exact sequence of commands/steps when you ran into the problem**

"
46828,To save subclassed Keras model from_config method is mandatory,"## URL(s) with the issue:
https://www.tensorflow.org/guide/keras/save_and_serialize#custom_objects

## Description of issue (what needs changing):
The guide states that to save/load custom layer or a subclassed model, the get_config and optionally from_config methods should be overwritten. However, in the case of subclassed model the definition of from_config is needed and not optional.

### Clear description
Overwriting from_config is needed because the method of the base class Model calls Functional.from_config, which looks for the key 'layers' in the config and therefore raises an exception in case of a subclassed model. 

### Submit a pull request?
Submitted PR to update the guide.
https://github.com/keras-team/keras-io/pull/363
"
46827,tensorflow 2.4 ParameterServerStrategy + Estimator will be stuck,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
tf version: 2.4
cluster spec:
ParameterServerStrategyV2 is now connecting to cluster with cluster_spec: ClusterSpec({'chief': ['tensorflow-tess-search-rk2-mlp-339212-chief-0.mlp.svc:2222'], 'evaluator': ['tensorflow-tess-search-rk2-mlp-339212-evaluator-0.mlp.svc:2222'], 'ps': ['tensorflow-tess-search-rk2-mlp-339212-ps-0.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-1.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-2.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-3.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-4.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-5.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-6.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-7.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-8.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-9.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-10.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-11.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-12.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-13.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-14.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-ps-15.mlp.svc:2222'], 'worker': ['tensorflow-tess-search-rk2-mlp-339212-worker-0.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-1.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-2.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-3.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-4.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-5.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-6.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-7.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-8.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-9.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-10.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-11.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-12.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-13.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-14.mlp.svc:2222', 'tensorflow-tess-search-rk2-mlp-339212-worker-15.mlp.svc:2222']})
1ãtf.compat.v1.distribute.experimental.ParameterServerStrategy + Estimator :  Error reported to Coordinator: 'NoneType' object has no attribute 'extended'
example code:
strategy = tf.compat.v1.distribute.experimental.ParameterServerStrategy()
model_config = tf.estimator.RunConfig(
        train_distribute=strategy,
        eval_distribute=None,
        log_step_count_steps=config[""parameters""][""log_steps""],
        save_summary_steps=config[""parameters""][""save_summary_steps""],
        save_checkpoints_steps=config[""parameters""][""save_checkpoints_steps""],
        save_checkpoints_secs=None,
        keep_checkpoint_max=config[""parameters""][""keep_checkpoint_max""],
 )
estimator = tf.estimator.Estimator(
        model_fn=model_fn, model_dir=model_dir, params=config, config=model_config
)
![image](https://user-images.githubusercontent.com/13100437/106465747-5ada4e00-64d5-11eb-8ddc-11fb45695a88.png)

2ãtf.distribute.experimental.ParameterServerStrategy + Estimator: the training job will be stuck
example code:
os.environ[""GRPC_FAIL_FAST""] = ""use_caller""
cluster_resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()
 variable_partitioner = (
    tf.distribute.experimental.partitioners.FixedShardsPartitioner(
    num_shards=ps_number))
strategy = tf.distribute.experimental.ParameterServerStrategy(cluster_resolver=cluster_resolver,
    variable_partitioner=variable_partitioner)
model_config = tf.estimator.RunConfig(
        train_distribute=strategy,
        eval_distribute=None,
        log_step_count_steps=config[""parameters""][""log_steps""],
        save_summary_steps=config[""parameters""][""save_summary_steps""],
        save_checkpoints_steps=config[""parameters""][""save_checkpoints_steps""],
        save_checkpoints_secs=None,
        keep_checkpoint_max=config[""parameters""][""keep_checkpoint_max""],
    )
estimator = tf.estimator.Estimator(
        model_fn=model_fn, model_dir=model_dir, params=config, config=model_config
)
"
46826,Estimator: how to write asset files into the assets directory hermetically when save model,"System information

- python 3.6.8
- tensorflow-gpu 1.15.0

**Describe the problem**
I have an asset file which needs to be saved within the exported model. I use estimator to export model as follows:
```
predictor = tf.estimator.Estimator()
assets_extra = {'index.idx': '/local/path/to/index.idx'}
servable_model_path = predictor.export_savedmodel(
    model_path,
    export_input_fn,
    assets_extra,
    as_text=True)
```

The parameter `assets_extra` will copy the asset file `index.idx` to the export directory. And the expected result is that the tensor in the graph which contain the directory of `index.idx` should be binded to the path of `index.idx` within the export directory. Actually,  the directory of `index.idx` in the graph dosen't change, but still `/local/path/to/index.idx`. If I move the exported model to another machine which don't contain `/local/path/to/index.idx`, the model can't find the `index.idx`.

So how can I bind the tensor value to the path of `index.idx` within the export directory?"
46825,RaggedTensor not supported as model input in generator and sequence,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- tf-nightly 2.5.0 (2021020101)
- colab

**Describe the current behavior**
generators and sequences (objects that implement the keras.utils.Sequence interface) that return a RaggedTensor as model input trigger an exception

**Describe the expected behavior**
generators and sequences should support any CompositeTensor

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1Qxov6zoWEnVcGwAH67cWiqaIjGcUTwbk?usp=sharing

This notebook creates a model that uses ragged tensors and verifies that when a tensor is passed to ```model.fit``` the behaviour is as expected. It then attempts to return the save value from a generator. The generator works if the tensor is converted from ragged to dense (although that changes the computed value). Passing a ragged tensor directly to the tf.data.Dataset API also seems to work. 

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
InvalidArgumentError:  TypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was <tf.RaggedTensor [[[1, 2], [3, 4]], [[5, 6]]]>.
TypeError: int() argument must be a string, a bytes-like object or a number, not 'RaggedTensor'


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 912, in generator_py_func
    dtype=dtype.as_numpy_dtype))

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py"", line 209, in _convert
    result = np.asarray(value, dtype=dtype, order=""C"")

  File ""/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py"", line 83, in asarray
    return array(a, dtype, copy=False, order=order)

ValueError: setting an array element with a sequence.


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py"", line 249, in __call__
    ret = func(*args)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py"", line 625, in wrapper
    return func(*args, **kwargs)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 921, in generator_py_func
    sys.exc_info()[2])

  File ""/usr/local/lib/python3.6/dist-packages/six.py"", line 702, in reraise
    raise value.with_traceback(tb)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 912, in generator_py_func
    dtype=dtype.as_numpy_dtype))

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py"", line 209, in _convert
    result = np.asarray(value, dtype=dtype, order=""C"")

  File ""/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py"", line 83, in asarray
    return array(a, dtype, copy=False, order=order)

TypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was <tf.RaggedTensor [[[1, 2], [3, 4]], [[5, 6]]]>.


	 [[{{node PyFunc}}]]
	 [[IteratorGetNext]] [Op:__inference_train_function_1924]

Function call stack:
train_function
```"
46824,"On Windows, full-integer TFLite conversion is broken; `schema_py_generated.py` is empty","### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (20H2, build 19042)
- TensorFlow installation (pip package or built from source): `tensorflow_cpu` PyPI pip package
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4.1

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

```python
import tensorflow as tf
import tensorflow_model_optimization as tfmot


def make_qat_keras_model():
    model = tf.keras.models.Sequential(
        [
            tf.keras.layers.Input((224, 224, 3)),
            tf.keras.layers.Conv2D(32, (3, 3), padding=""same"", strides=2),
        ]
    )
    return tfmot.quantization.keras.quantize_model(model)


keras_model = make_qat_keras_model()
keras_model.summary()

with open(""converted_keras_model.tflite"", ""wb"") as f:
    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    # This code works if the following two lines are commented out
    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8
    f.write(converter.convert())
```

### 3. Failure after conversion

The above code yields the error:

```
Traceback (most recent call last):
  File "".\test_scipt.py"", line 23, in <module>
    f.write(converter.convert())
  File ""C:\Users\Adam\src\tmp-env\lib\site-packages\tensorflow\lite\python\lite.py"", line 873, in convert
    return super(TFLiteKerasModelConverterV2,
  File ""C:\Users\Adam\src\tmp-env\lib\site-packages\tensorflow\lite\python\lite.py"", line 637, in convert
    result = _modify_model_io_type(result, **flags_modify_model_io_type)
  File ""C:\Users\Adam\src\tmp-env\lib\site-packages\tensorflow\lite\python\util.py"", line 835, in modify_model_io_type
    model_object = _convert_model_from_bytearray_to_object(model)
  File ""C:\Users\Adam\src\tmp-env\lib\site-packages\tensorflow\lite\python\util.py"", line 572, in _convert_model_from_bytearray_to_object
    model_object = schema_fb.Model.GetRootAsModel(model_bytearray, 0)
AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model'
```

### Cause

The Python schema file generated as this Bazel output is just an empty file when built on Windows: https://github.com/tensorflow/tensorflow/blob/822ec5c902a7fbbb630a7ee76437abe4d8bfe13a/tensorflow/lite/python/BUILD#L11-L14

This can be verified by running `bazel build -c opt //tensorflow/lite/python:schema_py` and checking the output: `bazel-bin/external/org_tensorflow/tensorflow/lite/python/schema_py_generated.py` is empty.

Running the same build command on Linux/MacOS yields a thousands-of-LOC Python file.

The empty file issue can be further verified by unzipping the published [TensorFlow wheel](https://files.pythonhosted.org/packages/9c/3b/fb50a6d5bdaf189c6131d8db84acba2fc35d6e7d9bfd7991dd71eb304d92/tensorflow_cpu-2.4.1-cp38-cp38-win_amd64.whl) and noting that `tensorflow/lite/python/schema_py_generated.py` is an empty file.

Hence the Python attribute error.

### Related issues

* #38285"
46823,Running TensorFlow Profiler on CPU only machine but training on GPU machine?,"Can I trainng a model on GPU machine and generating the profile files, but use a CPU only machine to load the files and render the profile webpage correctly?"
46822,TFLite converter does not convert dilated conv to single conv op when spatial dimension is dynamic,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4 and nightly

### 2. Code

https://colab.research.google.com/drive/1U_rbD_tlvRmHjHXXFGMch_s_-2vl_cSf?usp=sharing

and visualize models with netron.

### 3. Failure after conversion

- Model converts successfully but the generated model does not have single dilated convolution op.

Although

https://github.com/tensorflow/tensorflow/blob/6b23dbc15988dd7bbfbdca7581f1cb2b85246e8c/tensorflow/compiler/mlir/lite/transforms/dilated_conv.h#L98-L102

says allow dynamic width and height, paddings in SpaceToBatchNDOp and crops in BatchToSpaceNDOp are not constant when input has dynamic spatial dim. Therefore,

https://github.com/tensorflow/tensorflow/blob/6b23dbc15988dd7bbfbdca7581f1cb2b85246e8c/tensorflow/compiler/mlir/lite/transforms/dilated_conv.h#L239-L253

fails to match this kind of pattern.

"
46821,ValueError: Failed to parse the model: pybind11::init(): factory function returned nullptr. when convert and quantize tf model,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: Yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**: source
-   **TensorFlow version (use command below)**: `import tensorflow.compat.v1 as tf tf.__version__  2.4.1`
-   **Python version**: Python 3.6.9
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

### Describe the problem
I am trying to covert a Feature Extraction model that used in deepSort tracking to a int8 quantized tflite model, I am following the post-training quantization but failed with an error.  Actually, no matter what content in representative_data_gen() function, the error is same as in Traceback below:
### Source code / logs
Here is the code that converting the frozen-graph to tflite:
    
        import tensorflow.compat.v1 as tf
        mnist = tf.keras.datasets.mnist
        (train_images, train_labels), (test_images, test_labels) = mnist.load_data()
        train_images = train_images.astype(np.float32) / 255.0

        def representative_data_gen():
            for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):
                yield [input_value]
        
        converter = tf.lite.TFLiteConverter.from_frozen_graph(""mars-small128.pb"",input_arrays=[""Cast""],output_arrays=[""features""],input_shapes={""Cast"":[1, 128, 64, 3]})
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
        converter.inference_input_type = tf.uint8
        converter.inference_output_type = tf.uint8
        converter.representative_dataset = representative_data_gen
        tflite_model = converter.convert()
        open(""converted_model.tflite"", ""wb"").write(tflite_model)
Traceback (most recent call last):
  File ""/home/dev/.local/lib/python3.6/site-packages/tensorflow/lite/python/optimize/calibrator.py"", line 58, in __init__
    _calibration_wrapper.CalibrationWrapper(model_content))
TypeError: pybind11::init(): factory function returned nullptr

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""detect.py"", line 219, in <module>
    main()
  File ""detect.py"", line 109, in main
    encoder = generate_detections.create_box_encoder(""mars-small128.pb"", batch_size = 32)
  File ""/home/dev/projects/coral/examples-camera/opencv/generate_detections.py"", line 191, in create_box_encoder
    image_encoder = ImageEncoder(model_filename, input_name, output_name)
  File ""/home/dev/projects/coral/examples-camera/opencv/generate_detections.py"", line 150, in __init__
    tflite_model = converter.convert()
  File ""/home/dev/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 1947, in convert
    return super(TFLiteConverter, self).convert()
  File ""/home/dev/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 1313, in convert
    result = self._calibrate_quantize_model(result, **flags)
  File ""/home/dev/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 449, in _calibrate_quantize_model
    calibrate_quantize = _calibrator.Calibrator(result)
  File ""/home/dev/.local/lib/python3.6/site-packages/tensorflow/lite/python/optimize/calibrator.py"", line 60, in __init__
    raise ValueError(""Failed to parse the model: %s."" % e)
ValueError: Failed to parse the model: pybind11::init(): factory function returned nullptr."
46820,ConvLSTM2D with CUDNN crashes,"System Information: Windows 10
tensorflow version: 2.5.0-dev20201217
python version: 3.7.9
cuda version : 10.2


On using the above model, python crashes after

`model = models.Sequential(
	[
		layers.Input(
			shape=(timesteps, width, height, channels)
		),
		layers.ConvLSTM2D(
			filters=32, kernel_size=(3, 3), padding=""same"", return_sequences=True, dropout=0.1, recurrent_dropout=0.1
		),
		layers.MaxPool3D(
			pool_size=(1, 2, 2), strides=(1, 2, 2), padding=""same""
		),
		layers.BatchNormalization(),
		layers.ConvLSTM2D(
			filters=16, kernel_size=(3, 3), padding=""same"", return_sequences=True, dropout=0.1, recurrent_dropout=0.1
		),
		layers.MaxPool3D(
			pool_size=(1, 2, 2), strides=(1, 2, 2), padding=""same""
		),
		layers.BatchNormalization(),
		layers.ConvLSTM2D(
			filters=8, kernel_size=(3, 3), padding=""same"", return_sequences=False, dropout=0.1, recurrent_dropout=0.1
		),
		layers.MaxPool2D(
			pool_size=(2, 2), strides=(2, 2), padding=""same""
		),
		layers.BatchNormalization(),
		layers.Flatten(),
		layers.Dense(192, activation='relu'),
		layers.Dense(action_num, activation='softmax')
	]
)
`
On using the above model, python crashes after

>2021-02-01 10:03:12.227916: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:127] None of the MLIR optimization passes are enabled (registered 2)
Epoch 1/300
2021-02-01 10:03:21.950076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-02-01 10:03:22.694349: I tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Loaded cuDNN version 8005
2021-02-01 10:03:23.281554: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0

>2021-02-01 10:03:23.769410: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0

>2021-02-01 10:03:23.867774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-02-01 10:03:24.624172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll

on further examining the system logs found the following

>Faulting application name: python.exe, version: 3.7.9150.1013, time stamp: 0x5f3ad38e
Faulting module name: _pywrap_tensorflow_internal.pyd, version: 0.0.0.0, time stamp: 0x5fdb260c
Exception code: 0xc00000fd
Fault offset: 0x00000000094ae988
Faulting process id: 0x35dc
Faulting application start time: 0x01d6f85196812501
Faulting application path: C:\Users\Scorp\AppData\Local\Programs\Python\Python37\python.exe
Faulting module path: C:\Users\Scorp\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd

keras config

{
    ""floatx"": ""float32"",
    ""epsilon"": 1e-07,
    ""backend"": ""tensorflow"",
    ""image_data_format"": ""channels_last""
}

PFA the code and files

https://github.com/sivi299/lstm"
46819,problematic args description table of aixs in tf.nn.softmax,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/nn/softmax#args

document version: 2.4.1

## Description of issue (what needs changing):

In the args description table, it says axis default to -1,
while the code below 'view alias' uses: axis=None.

and according to its equivalent code, axis deafaults to None in the function reduce_sum.

### so which one is right?

"
46818,tf.cond within vectorized_map results in unknown output shape,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab version
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Colab version
- TensorFlow version (use command below): v2.4.1-0-g85c8b2a817f 2.4.1
- Python version: Colab version
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
When using tf.cond from within tf.vectorized_map, the output shape is lost and the result has a None batch shape. This results in memory exploding at backpropagation time.

**Describe the expected behavior**
The output shape should be retained when the shapes of the two possible cond outputs are the same. 

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1ydXdSe0_jJqtJLYGXgkCxywjC9gFANwv?usp=sharing
"
46817,error trying to download tensorflow with pip,"
**System information**
-MacOs Big sur(11.1)
- TensorFlow installed from pip 
- Python version: Python 3.9.1
- pip version: 21.01


**Describe the problem**
when i want to download Tensor-flow with pip this error occurs. it says: 
ERROR: Could not find a version that satisfies the requirement tensorflow
ERROR: No matching distribution found for tensorflow
(attachment)

<img width=""569"" alt=""Bildschirmfoto 2021-01-31 um 17 09 14"" src=""https://user-images.githubusercontent.com/22261997/106390097-0ce71c80-63e7-11eb-971e-5b6472516600.png"">

"
46816,The chained `==` operator throws error when converting to TFLite from `tf.function`.,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.04 (Google Colab)**
- TensorFlow installation (pip package or built from source):  **pip package (Google Colab)**
- TensorFlow library (version, if pip package or github SHA, if built from source): **2.4.1 (Google Colab)**

### 2. Code

#### Option B: Paste your code here:
Consider the scenario, in which one would like to zero-out (or filter) a tensor, based on multiple equality checks:
```python
import tensorflow as tf

SHAPE = (10, )

@tf.function(
    input_signature=[tf.TensorSpec(shape=SHAPE, dtype=tf.int32)]
)
def my_function(inputs):
    
    # Let's say that we want to zero-out all values BUT 1 and 2 from our input tensor.

    filtered_inputs = tf.where(
        (inputs == 1) | (inputs == 2),
        inputs,
        0
    )
    return filtered_inputs
```

Let us call this function on a mock input:

```python
mock_inputs = tf.random.uniform(shape=SHAPE, minval=1, maxval=5, dtype=tf.int32)
my_function(mock_inputs)
```
It works (so far). Now let us convert this to Tensorflow Lite as per [official documentation](https://www.tensorflow.org/lite/convert#convert_concrete_functions_)

```python
concrete_func = my_function.get_concrete_function()
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = True
tflite_model = converter.convert()   # ERROR.
```
The above will fail with rather long error message that ends with
```python
<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
	tf.Equal {device = """", incompatible_shape_error = false}
```
Now, there is a workaround: one can use the `tf.math.equal` instead of the `==` operator:

```python
@tf.function(
    input_signature=[tf.TensorSpec(shape=SHAPE, dtype=tf.int32)]
)
def my_workaround_function(inputs):

    # Use Tensorflow ops instead of Python ops

    filtered_inputs = tf.where(
        (tf.math.equal(inputs, 1)) | (tf.math.equal(inputs, 2)),
        inputs,
        0
    )
    return filtered_inputs
```
And the above can be safely converted to TFLite:

```python
concrete_func = my_workaround_function.get_concrete_function()
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = True
tflite_model = converter.convert()  # OK. 
```

I am opening the issue as I am unsure if this is a intended or known behaviour. For example, some people might be stuck on this situation, without figuring out the workaround. Also: as per the [Tensorflow documentation](https://www.tensorflow.org/guide/function#autograph_transformations), the `tf.function` is intended to work with simple Python ops.

If this is somewhat intended, let me know and I will close the issue (though I would greatly appreciate some explanation if possible).
  
Best regards,
Sebastian

### 5. (optional) Any other info / logs

Here is a full error message:
```python
Exception: /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1750:0: error: 'tf.Equal' op is neither a custom op nor a flex op
/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201:0: note: called from
<ipython-input-54-3ccb02792638>:14:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:973:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:634:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:990:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:3206:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:3361:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:2969:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:726:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1750:0: error: 'tf.Equal' op is neither a custom op nor a flex op
/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201:0: note: called from
<ipython-input-54-3ccb02792638>:14:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:973:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:634:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:990:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:3206:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:3361:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:2969:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:726:0: note: called from
<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
	tf.Equal {device = """", incompatible_shape_error = false}


During handling of the above exception, another exception occurred:

ConverterError                            Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    214       return model_str
    215     except Exception as e:
--> 216       raise ConverterError(str(e))
    217 
    218   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:

ConverterError: /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1750:0: error: 'tf.Equal' op is neither a custom op nor a flex op
/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201:0: note: called from
<ipython-input-54-3ccb02792638>:14:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:973:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:634:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:990:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:3206:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:3361:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:2969:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:726:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1750:0: error: 'tf.Equal' op is neither a custom op nor a flex op
/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201:0: note: called from
<ipython-input-54-3ccb02792638>:14:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:973:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:634:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:990:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:3206:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:3361:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:2969:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:726:0: note: called from
<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
	tf.Equal {device = """", incompatible_shape_error = false}
```"
46815,Problem with jit compiler:,"When trying your example programm:
import tensorflow as tf
import tensorflow_probability as tfp

# Pretend to load synthetic data set.
features = tfp.distributions.Normal(loc=0., scale=1.).sample(int(100e3))
labels = tfp.distributions.Bernoulli(logits=1.618 * features).sample()

# Specify model.
model = tfp.glm.Bernoulli()

# Fit model given data.
coeffs, linear_response, is_converged, num_iter = tfp.glm.fit(
    model_matrix=features[:, tf.newaxis],
    response=tf.cast(labels, dtype=tf.float32),
    model=model)
# ==> coeffs is approximately [1.618] (We're golden!)

I get the following log message:
2021-01-31 13:51:01.420629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
Traceback (most recent call last):
  File ""D:/PyProjects/PILCO-master/other.py"", line 2, in <module>
    import tensorflow_probability as tfp
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\__init__.py"", line 20, in <module>
    from tensorflow_probability import substrates
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\substrates\__init__.py"", line 21, in <module>
    from tensorflow_probability.python.internal import all_util
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\python\__init__.py"", line 142, in <module>
    dir(globals()[pkg_name])  # Forces loading the package from its lazy loader.
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\python\internal\lazy_loader.py"", line 61, in __dir__
    module = self._load()
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\python\internal\lazy_loader.py"", line 44, in _load
    module = importlib.import_module(self.__name__)
  File ""C:\Users\Martin\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\python\experimental\__init__.py"", line 35, in <module>
    from tensorflow_probability.python.experimental import bijectors
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\python\experimental\bijectors\__init__.py"", line 17, in <module>
    from tensorflow_probability.python.bijectors.ldj_ratio import inverse_log_det_jacobian_ratio
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\python\bijectors\__init__.py"", line 23, in <module>
    from tensorflow_probability.python.bijectors.absolute_value import AbsoluteValue
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\python\bijectors\absolute_value.py"", line 23, in <module>
    from tensorflow_probability.python.bijectors import bijector
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\python\bijectors\bijector.py"", line 35, in <module>
    from tensorflow_probability.python.math import gradient
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\python\math\__init__.py"", line 30, in <module>
    from tensorflow_probability.python.math.generic import log1mexp
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\python\math\generic.py"", line 151, in <module>
    _kahan_reduction, _kahan_reduce_bwd, _kahan_reduce_tangents)
  File ""C:\Users\Martin\Anaconda3\lib\site-packages\tensorflow_probability\python\internal\variadic_reduce.py"", line 122, in make_variadic_reduce
    @tf.function(jit_compile=True)
TypeError: function() got an unexpected keyword argument 'jit_compile'
"
46813,suffering with the problem : tensorflow.python.framework.errors_impl.NotFoundError: NewRandomAccessFile failed to Create/Open: HelmetDetection/frozen_inference_graph.pb : The system cannot find the path specified. ; No such process,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
![issue1](https://user-images.githubusercontent.com/75311266/106377536-a8669600-63c3-11eb-865a-9fdfbb9b10f7.png)
![issue1](https://user-images.githubusercontent.com/75311266/106377540-b1effe00-63c3-11eb-9385-ec6b9997a32e.png)


- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46812,    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'.,"[](# -*- coding: utf-8 -*-
""""""Untitled42.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LJOb_cY2_aK9adr8i6jNn9QcFzwDZBS8
""""""

import numpy as np
import pandas as pd
import os
import random, re, math
import tensorflow as tf, tensorflow.keras.backend as K
import tensorflow_addons as tfa
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Model
from tensorflow.keras import optimizers
from tensorflow.keras.models import Sequential
import tensorflow.keras.layers as L
from tensorflow.keras.applications import ResNet152V2, InceptionResNetV2, InceptionV3, Xception, VGG19
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D,GlobalMaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler
from keras import regularizers

import matplotlib.pyplot as plt

!pip install efficientnet
import efficientnet.tfkeras as efn

from google.colab import files
files.upload()

from google.colab import files
files.upload()

! mkdir -p ~/.kaggle
! cp kaggle.json ~/.kaggle/
#change the permission
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d andrewmvd/ocular-disease-recognition-odir5k

from zipfile import ZipFile
file_name = ""ocular-disease-recognition-odir5k.zip""
with ZipFile(file_name, 'r') as zip:
  zip.extractall()
  print('done')

AUTO = tf.data.experimental.AUTOTUNE
try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
else:
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)

GCS_DS_PATH = '/content/ODIR-5K'

train = pd.read_csv('/content/new_df_oc (1).csv')
train_paths = train.filename.apply(lambda x: GCS_DS_PATH+ '/ODIR-5K/ODIR-5K/Training Images/' + x).values
train_labels = train.target.values

train_paths

train.head(10)

train=train.drop(columns=['D','C','A','M','G','O'],axis=1)

train=train[((train['N']== 1) | (train['H'] == 1))]

train

train,valid = train_test_split(train,test_size = 0.2,random_state = 42)

BATCH_SIZE = 8* strategy.num_replicas_in_sync
img_size = 512
EPOCHS = 1
SEED = 42

def decode_image(filename, label=None, image_size=(img_size,img_size)):
    bits = tf.io.read_file(filename)
    image = tf.image.decode_jpeg(bits, channels=3) 
    image = tf.image.resize(image, image_size)
    image = tf.cast(image, tf.float32)
    image = tf.image.per_image_standardization(image)
    if label is None:
        return image
    else:
        return image, label
    
def preprocess(df,test=False):
    paths = df.filename.apply(lambda x: GCS_DS_PATH + '/ODIR-5K/Training Images/' + x).values
    labels = df.loc[:, ['N', 'H']].values
    if test==False:
        return paths,labels
    else:
        return paths
    
def data_augment(image, label=None, seed=SEED):
    image = tf.image.random_flip_left_right(image, seed=seed)
    image = tf.image.random_flip_up_down(image, seed=seed)
           
    if label is None:
        return image
    else:
        return image, label

def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):
    rotation = math.pi * rotation / 180.
    shear = math.pi * shear / 180.

    c1 = tf.math.cos(rotation)
    s1 = tf.math.sin(rotation)
    one = tf.constant([1],dtype='float32')
    zero = tf.constant([0],dtype='float32')
    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )

    c2 = tf.math.cos(shear)
    s2 = tf.math.sin(shear)
    
    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    
    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )
    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )
    
    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))

def transform(image,label=None):
    DIM = img_size
    XDIM = DIM%2 
    
    rot = 15. * tf.random.normal([1],dtype='float32')
    shr = 5. * tf.random.normal([1],dtype='float32') 
    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.
    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.
    h_shift = 8. * tf.random.normal([1],dtype='float32') 
    w_shift = 8. * tf.random.normal([1],dtype='float32') 
  
    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) 

    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )
    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )
    z = tf.ones([DIM*DIM],dtype='int32')
    idx = tf.stack( [x,y,z] )
    
    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))
    idx2 = K.cast(idx2,dtype='int32')
    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)
              
    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )
    d = tf.gather_nd(image,tf.transpose(idx3))
    
    if label is None:
        return tf.reshape(d,[DIM,DIM,3])
    else:
        return tf.reshape(d,[DIM,DIM,3]),label

train_dataset = (tf.data.Dataset
    .from_tensor_slices(preprocess(train))
    .map(decode_image, num_parallel_calls=AUTO)
    #.map(data_augment, num_parallel_calls=AUTO)
    .map(transform,num_parallel_calls=AUTO)
    .shuffle(SEED)
    .batch(BATCH_SIZE)
    .repeat()
    .prefetch(AUTO))

test_dataset= (tf.data.Dataset
    .from_tensor_slices(preprocess(valid))
    .map(decode_image, num_parallel_calls=AUTO)
    .batch(BATCH_SIZE)
    .cache()
    .prefetch(AUTO))

LR_START = 0.00001
LR_MAX = 0.00005 * strategy.num_replicas_in_sync
LR_MIN = 0.00001
LR_RAMPUP_EPOCHS = 5
LR_SUSTAIN_EPOCHS = 0
LR_EXP_DECAY = .8

def lrfn(epoch):
    if epoch < LR_RAMPUP_EPOCHS:
        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START
    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:
        lr = LR_MAX
    else:
        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN
    return lr
    
lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)

rng = [i for i in range(EPOCHS)]
y = [lrfn(x) for x in rng]
plt.plot(rng, y)
print(""Learning rate schedule: {:.3g} to {:.3g} to {:.3g}"".format(y[0], max(y), y[-1]))

def categorical_focal_loss(gamma=2., alpha=.25):
    def categorical_focal_loss_fixed(y_true, y_pred):
        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)
        epsilon = K.epsilon()
        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)
        cross_entropy = -y_true * K.log(y_pred)
        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy
        return K.sum(loss, axis=1)
    return categorical_focal_loss_fixed

with strategy.scope():
    enet = efn.EfficientNetB7(input_shape=(img_size, img_size, 3),weights='noisy-student',include_top=False)

with strategy.scope():
    enet.trainable = True

with strategy.scope():
    ef7 =tf.keras.Sequential()
    ef7.add(enet)
    ef7.add(tf.keras.layers.MaxPooling2D())
    ef7.add(tf.keras.layers.Conv2D(2048,3,padding='same'))
    ef7.add(tf.keras.layers.BatchNormalization())
    ef7.add(tf.keras.layers.ReLU())
    ef7.add(tf.keras.layers.GlobalAveragePooling2D())
    ef7.add(tf.keras.layers.Flatten())

    ef7.add(tf.keras.layers.Dense(1024,activation='relu'))
    ef7.add(tf.keras.layers.BatchNormalization())
    ef7.add(tf.keras.layers.LeakyReLU())
    ef7.add(tf.keras.layers.Dropout(0.25))

    ef7.add(tf.keras.layers.Dense(512,activation='relu'))
    ef7.add(tf.keras.layers.BatchNormalization())
    ef7.add(tf.keras.layers.LeakyReLU())
    ef7.add(tf.keras.layers.Dropout(0.15))
    ef7.add(tf.keras.layers.Dense(2,activation='softmax'))
    ef7.compile(
                optimizer=tf.optimizers.Adam(lr=0.0001),
                loss=categorical_focal_loss(gamma=2., alpha=.25),
                metrics=['categorical_accuracy',
                        tf.keras.metrics.Recall(),
                        tf.keras.metrics.Precision(),   
                        tf.keras.metrics.AUC(),
                        tfa.metrics.F1Score(num_classes=2, average=""macro"")
                       ])

h7=ef7.fit(
    train_dataset,
    steps_per_epoch=train_labels.shape[0] // BATCH_SIZE,
    callbacks=[lr_callback],
    epochs=EPOCHS)

)




TypeError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *
        return step_function(self, iterator)
    <ipython-input-20-4c42ef206b9f>:6 categorical_focal_loss_fixed  *
        cross_entropy = -y_true * K.log(y_pred)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1180 binary_op_wrapper
        raise e
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1164 binary_op_wrapper
        return func(x, y, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1496 _mul_dispatch
        return multiply(x, y, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:518 multiply
        return gen_math_ops.mul(x, y, name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py:6078 mul
        ""Mul"", x=x, y=y, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper
        inferred_from[input_arg.type_attr]))

    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'.](url)


[Pls help me on this finding the solution of this error ](url)"
46811,"Encountered ""Segmentation fault (core dumped)"" when convert keras model to tflite model","Iâm trying to convert a pytorch model (SSD) to tflite model. The model transformation path is: pytorch mode >> onnx model >> keras model >> tflite mode. 

### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 16.04**
- TensorFlow installation (pip package or built from source): **pytorch1.6.0+cu101, onnx1.8.0, onnx2keras0.0.24, tensorflow2.3.0, cudatoolkit10.1, cudnn7.6.5** installed via ""**conda install**"" command


### 2. Code

pytorch source code in [pytorch-ssd](https://github.com/qfgaohao/pytorch-ssd) and my converting code as follows:


```
from vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite
import os
import torch
import onnx
import tensorflow as tf
from onnx2keras import onnx_to_keras
import numpy as np

os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""

torch_path = "" ... pretrained weights path ...""
tf_lite_path = "" ... output path ... ""

create_net = lambda num: create_mobilenetv2_ssd_lite(num, is_test=True, device='cpu')
net = create_net(21)

state_dict = torch.load(torch_path, map_location=torch.device('cpu'))
net.load_state_dict(state_dict, strict=True)

net.eval()
image_size = 300

input_np = np.random.uniform(0, 1, (1, 3, image_size, image_size))
input = torch.FloatTensor(input_np)

torch.onnx.export(
        model=net,
        args=input,
        f="" ... onnx output path ... "",
        export_params=True,
        do_constant_folding=False
        verbose=False,
        input_names=['input'],
        opset_version=10,
        output_names=['output'])

onnx_model = onnx.load(' .. onnx output path ... ')
keras_model = onnx_to_keras(onnx_model, ['input'])

print(""======1"")

converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
converter.experimental_new_converter = True
print(""======2"")

tflite_model = converter.convert() 
print(""======3"")
with open(tf_lite_path, 'wb') as f:
        f.write(tflite_model)
print(""=====4"")
```


""====1"" and ""====2"" are printed normally, but Segmentation fault occured before ""====3"". No error messages are shown before Segmentation fault occured. Some of the log information is as follows (Total log over 10,000 lines):

```
Tensor(""inputs/0:0"", shape=(None, 3000, 2), dtype=float32) Tensor(""inputs/1:0"", shape=(1, 3000, 2), dtype=float32)
INFO:tensorflow:Assets written to: /tmp/tmpt6z4tlht/assets
INFO:tensorflow:Assets written to: /tmp/tmpt6z4tlht/assets
Tensor(""functional_1/444/FusedBatchNormV3:0"", shape=(None, 16, 150, 150), dtype=float32) Tensor(""functional_1/446_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/469/BiasAdd:0"", shape=(None, 16), dtype=float32) Tensor(""functional_1/471_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/522/BiasAdd:0"", shape=(None, 96), dtype=float32) Tensor(""functional_1/524_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/558/BiasAdd:0"", shape=(None, 240), dtype=float32) Tensor(""functional_1/560_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/595/BiasAdd:0"", shape=(None, 240), dtype=float32) Tensor(""functional_1/597_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/615/FusedBatchNormV3:0"", shape=(None, 120, 19, 19), dtype=float32) Tensor(""functional_1/617_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/637/BiasAdd:0"", shape=(None, 120), dtype=float32) Tensor(""functional_1/639_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/653/FusedBatchNormV3:0"", shape=(None, 48, 19, 19), dtype=float32) Tensor(""functional_1/655_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/661/FusedBatchNormV3:0"", shape=(None, 144, 19, 19), dtype=float32) Tensor(""functional_1/663_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/683/BiasAdd:0"", shape=(None, 144), dtype=float32) Tensor(""functional_1/685_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/699/FusedBatchNormV3:0"", shape=(None, 48, 19, 19), dtype=float32) Tensor(""functional_1/701_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/746/FusedBatchNormV3:0"", shape=(None, 288, 19, 19), dtype=float32) Tensor(""functional_1/748_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/768/BiasAdd:0"", shape=(None, 288), dtype=float32) Tensor(""functional_1/770_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/784/FusedBatchNormV3:0"", shape=(None, 96, 10, 10), dtype=float32) Tensor(""functional_1/786_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/792/FusedBatchNormV3:0"", shape=(None, 576, 10, 10), dtype=float32) Tensor(""functional_1/794_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/814/BiasAdd:0"", shape=(None, 576), dtype=float32) Tensor(""functional_1/816_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/830/FusedBatchNormV3:0"", shape=(None, 96, 10, 10), dtype=float32) Tensor(""functional_1/832_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/839/FusedBatchNormV3:0"", shape=(None, 576, 10, 10), dtype=float32) Tensor(""functional_1/841_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/861/BiasAdd:0"", shape=(None, 576), dtype=float32) Tensor(""functional_1/863_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/877/FusedBatchNormV3:0"", shape=(None, 96, 10, 10), dtype=float32) Tensor(""functional_1/879_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/899/BiasAdd:0"", shape=(None, 576), dtype=float32) Tensor(""functional_1/901_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/914/FusedBatchNormV3:0"", shape=(None, 576, 10, 10), dtype=float32) Tensor(""functional_1/916_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/921/BiasAdd:0"", shape=(None, 1280, 10, 10), dtype=float32) Tensor(""functional_1/923_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/708/FusedBatchNormV3:0"", shape=(None, 288, 19, 19), dtype=float32) Tensor(""functional_1/710_const2/Const:0"", shape=(), dtype=float32)
Tensor(""functional_1/1115/mul:0"", shape=(None, 3000, 2), dtype=float32) Tensor(""functional_1/1117_const2/Const:0"", shape=(1, 3000, 2), dtype=float32)
2021-01-31 14:22:38.501393: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2021-01-31 14:22:38.501533: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2021-01-31 14:22:38.502841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:06:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.62GiB deviceMemoryBandwidth: 625.94GiB/s
2021-01-31 14:22:38.502879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-01-31 14:22:38.502931: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-01-31 14:22:38.502954: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-01-31 14:22:38.502973: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-01-31 14:22:38.502993: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-01-31 14:22:38.503024: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-01-31 14:22:38.503046: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-01-31 14:22:38.504682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-01-31 14:22:38.504715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-31 14:22:38.504725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-01-31 14:22:38.504733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-01-31 14:22:38.506316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21686 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:06:00.0, compute capability: 7.5)
2021-01-31 14:22:38.537184: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize
2021-01-31 14:22:38.537202: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.006ms.
2021-01-31 14:22:38.537219: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2021-01-31 14:22:40.299627: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.
2021-01-31 14:22:40.299667: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.
2021-01-31 14:22:40.546372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:06:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.62GiB deviceMemoryBandwidth: 625.94GiB/s
2021-01-31 14:22:40.546422: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-01-31 14:22:40.546476: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-01-31 14:22:40.546498: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-01-31 14:22:40.546519: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-01-31 14:22:40.546539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-01-31 14:22:40.546558: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-01-31 14:22:40.546579: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-01-31 14:22:40.548140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-01-31 14:22:40.548184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-31 14:22:40.548194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-01-31 14:22:40.548202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-01-31 14:22:40.549800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21686 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:06:00.0, compute capability: 7.5)
Segmentation fault (core dumped)
```
"
46810,StyleGAN2 is not converging in 4x RTX 3090,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): 2.4rc02
- TensorFlow version (use command below): 2.x
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.1
- GPU model and memory: 4x RTX 3090(24 GB)


**Describe the current behavior**
I have converted StyleGAN 2 official code(Written in Tensorflow 1.x) to TensorFlow 2.x. It is converging properly till some point, but then it started to decrease the quality. 

First I observed a mode collapsing then Eventually, the resulting images were a completely distorted type, kind of noise only. 
I'm using data having many categories.

Anyone knows why it is happing and the solution. Thanks in advance.
"
46809,[RNN] LSTM with TimeDistributed layer converts successfully but fails when invoking,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): tf-nightly

### 2. Code

https://colab.research.google.com/drive/1zgiZN6K1YsT70w-uWshBQA2ESuHSASn3?usp=sharing

### 3. Failure after conversion

- Model fails when invoking interpreter.
- When set `batch_size` to 1 during building model, everything works. See `with_converted_lstm.tflite` for example.
"
46808,Multi GPU training - works on Intel CPU but failed on AMD CPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A
- TensorFlow installed from (source or binary):binary and source with -march=native
- TensorFlow version (use command below):2.4
- Python version:3.6.9
- Bazel version (if compiling from source):3.1.0
- GCC/Compiler version (if compiling from source):7.5.0
- CUDA/cuDNN version:11.0/8.0.4
- GPU model and memory: 2x GTX1080  Titan/12GB

**Describe the current behavior**
With the standard tensorflow-gpu 2.4 distribution installed using
- pip3 install tensorflow-gpu==2.4""

When the same script is executed on the following two systems:
- System 1: Intel CPU i7 6850k / 2x Titan (Pascal) 12GB / Ubuntu 18.04
- System 2: AMD Threadripper 1950x / 2x Titan (Pascal) 12GB / Ubuntu 18.04

The script works on System 1 but stuck on System 2. The script is stuck on the following line with both GPU at 100% utilization:
```
model.fit(train_dataset, epochs=12, callbacks=callbacks)
```

**Describe the expected behavior**
The multi-gpu training should work on the systems with AMD cpus. System can run the same script successfully with only one GPU assigned to the runtime (export CUDA_VISIBLE_DEVICES=""0""). The problem might be CPU related. 

I have also tried Tensorflow compiled from source (version 2.4/GPU with -march=native) and the results are the same (stuck).

**Standalone code to reproduce the issue**
https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/keras.ipynb

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

System 1 (Intel CPU) runs the entire script successfully:
```
Epoch 1/12
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
  3/469 [..............................] - ETA: 2:40 - loss: 2.2512 - accuracy: 0.1276WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0065s vs `on_train_batch_begin` time: 0.0727s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0065s vs `on_train_batch_begin` time: 0.0727s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_train_batch_end` time: 0.0402s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_train_batch_end` time: 0.0402s). Check your callbacks.
```

System 2 (AMD Threadripper CPU) gets stuck on the model.fit line:
```
model.fit(train_dataset, epochs=12, callbacks=callbacks)
Epoch 1/12
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
```
"
46807,ImageDataGenerator - Caching not effective when using tf.data.Dataset.from_generator,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Manjaro Linux 20.2.1
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8.5
- CUDA/cuDNN version: 11.0


**Describe the current behavior**

When creating a dataset generator using ImageDataGenerator, as the documentation specifies it:
```
The data will be looped over (in batches).
```
The dataset generator is then used in `tf.data.Dataset.from_generator`, on which is then called `.cache()`: we have a problem here, since the `cache()` function caches the data, as the documentation specifies it:
```
The first time the dataset is iterated over, its elements will be cached either in the specified file or in memory.
Subsequent iterations will use the cached data.
```
The problem is that the dataset never ends since this is the way ImageDataGenerator works.

**Describe the expected behavior**

There should be a callback or something telling `tf.data.Dataset` that the dataset is OVER when getting the last batch each time, so that data can be cached properly."
46806,"edgetpu_compiler: ""Model not Quantized"" despite being quantized","### 1. System information

- OS Platform and Distribution: Google Colab; Ubuntu 20.04.1
- TensorFlow installation (pip package or built from source): `pip`
- TensorFlow library (version, if pip package or github SHA, if built from source): Tested on `1.15.5`, `2.3.0`, and `2.4.1`

### 2. Code

I have followed these guides to the letter:

- Creating a YOLOv3-tiny model, Converting it to Keras, then finally exporting as a tflite
    - https://github.com/goruck/edge-tpu-train
 - Training YOLO models
    - https://github.com/AlexeyAB/darknet#how-to-train-tiny-yolo-to-detect-your-custom-objects

It is as dead-stock a model as possible. I am trying to eliminate causes. I have also encountered the error while trying to convert EfficientDet-d0, YOLOv3, and YOLOv4-tiny.

1)  Reference [TensorFlow Model Colab](https://colab.research.google.com/drive/1p5TpbSZZgDVTTlrJPxfw-waAGH-HKFSy?usp=sharing): Download [this attached model](https://github.com/tensorflow/tensorflow/files/5898304/heehoo.zip). Simply drag and drop to `/content`, then run the notebook.

### 3. Failure after conversion
```
Edge TPU Compiler version 15.0.340273435
Invalid model: heehoo.tflite
Model not quantized
```

### 5. (optional) Any other info / logs
I encounter no errors during conversion from Keras to Tflite. I even verified the models using Netron, and there seems to be nothing wrong. All the layers seem to use `uint8`.

This is the worst warning I have seen, along with CUDA-related warnings:
`2021-01-31 00:15:49.647787: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.`
"
46805,Shuffle Buffer Filled,"When I run the model_main_tf2.py script to train a centernet_resnet50_v1_fpn_512x512 model with a dataset that is of the size 25GB in the tfrecord format.

Is the dataset the main reason for this issue?

the error is

2021-01-30 19:37:30.641972: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-01-30 19:37:30.642004: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-01-30 19:37:41.087656: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-30 19:37:41.087854: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-01-30 19:37:41.087870: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-01-30 19:37:41.087898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kingsman-desktop): /proc/driver/nvidia/version does not exist
2021-01-30 19:37:41.088899: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
W0130 19:37:41.089709 140284268705600 cross_device_ops.py:1321] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
I0130 19:37:41.089887 140284268705600 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
INFO:tensorflow:Maybe overwriting train_steps: None
I0130 19:37:41.093331 140284268705600 config_util.py:552] Maybe overwriting train_steps: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0130 19:37:41.093431 140284268705600 config_util.py:552] Maybe overwriting use_bfloat16: False
WARNING:tensorflow:From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/model_lib_v2.py:523: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
W0130 19:37:43.446819 140284268705600 deprecation.py:339] From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/model_lib_v2.py:523: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
INFO:tensorflow:Reading unweighted datasets: ['/home/kingsman/deepl/records/train.tfrecord']
I0130 19:37:43.468255 140284268705600 dataset_builder.py:163] Reading unweighted datasets: ['/home/kingsman/deepl/records/train.tfrecord']
INFO:tensorflow:Reading record datasets for input file: ['/home/kingsman/deepl/records/train.tfrecord']
I0130 19:37:43.468415 140284268705600 dataset_builder.py:80] Reading record datasets for input file: ['/home/kingsman/deepl/records/train.tfrecord']
INFO:tensorflow:Number of filenames to read: 1
I0130 19:37:43.468508 140284268705600 dataset_builder.py:81] Number of filenames to read: 1
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0130 19:37:43.468611 140284268705600 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
W0130 19:37:43.471664 140284268705600 deprecation.py:339] From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
WARNING:tensorflow:From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0130 19:37:43.492702 140284268705600 deprecation.py:339] From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0130 19:37:51.294010 140284268705600 deprecation.py:339] From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0130 19:37:54.907917 140284268705600 deprecation.py:339] From /home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2021-01-30 19:37:58.317565: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-01-30 19:37:58.341385: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3399920000 Hz
2021-01-30 19:38:09.704606: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 68 of 2048
2021-01-30 19:38:18.681284: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 162 of 2048
2021-01-30 19:38:28.579701: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 314 of 2048
2021-01-30 19:38:34.514916: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:230] Shuffle buffer filled.
Traceback (most recent call last):
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/eager/context.py"", line 2113, in execution_mode
    yield
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 733, in _next_internal
    output_shapes=self._flat_output_shapes)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2579, in iterator_get_next
    _ops.raise_from_not_ok_status(e, name)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 6862, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input is empty.
	 [[{{node case/cond/else/_10/case/cond/cond_jpeg/else/_105/case/cond/cond_jpeg/decode_image/DecodeImage}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]] [Op:IteratorGetNext]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""object_detection/model_main_tf2.py"", line 113, in <module>
    tf.compat.v1.app.run()
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""object_detection/model_main_tf2.py"", line 110, in main
    record_summaries=FLAGS.record_summaries)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 566, in train_loop
    unpad_groundtruth_tensors)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 344, in load_fine_tune_checkpoint
    features, labels = iter(input_dataset).next()
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 628, in next
    return self.__next__()
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 632, in __next__
    return self.get_next()
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 663, in get_next
    self._iterators[i].get_next_as_list_static_shapes(new_name))
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 1619, in get_next_as_list_static_shapes
    return self._format_data_list_with_options(self._iterator.get_next())
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py"", line 585, in get_next
    result.append(self._device_iterators[i].get_next())
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 800, in get_next
    return self._next_internal()
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 739, in _next_internal
    return structure.from_compatible_tensor_list(self._element_spec, ret)
  File ""/usr/lib/python3.6/contextlib.py"", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/eager/context.py"", line 2116, in execution_mode
    executor_new.wait()
  File ""/home/kingsman/.virtualenvs/deepl/lib/python3.6/site-packages/tensorflow/python/eager/executor.py"", line 69, in wait
    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input is empty.
	 [[{{node case/cond/else/_10/case/cond/cond_jpeg/else/_105/case/cond/cond_jpeg/decode_image/DecodeImage}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]]
"
46803,Expose TString related C API,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

**System information**
- TensorFlow v2.4.1:
- Are you willing to contribute it (Yes):

**Describe the feature and the current behavior/state.**
Since v2.4.0 removed string related APIs like `TF_StringEncode`, we can't operate string in other language binding. What we need are exposing thoses APIs: 
* TF_CAPI_EXPORT extern TF_TString* TF_StringInit();
* TF_CAPI_EXPORT extern void TF_StringCopy(TF_TString *dst, const char *src, size_t size);
* TF_CAPI_EXPORT extern const char* TF_StringGetDataPointer(TF_TString* tstr);
* TF_CAPI_EXPORT extern size_t TF_StringGetSize(TF_TString* tstr);
* TF_CAPI_EXPORT extern void TF_StringDealloc(TF_TString* tstr);

**Will this change the current api? How?**
No changing current api.

**Who will benefit with this feature?**
All other language bindings.

**Any Other info.**
I'm willing to PR these changes."
46801,thankyou,"thankyou all of you .
I have solved my error by just installing tensorflow==1.5
by the command ""pip install tensorflow==1.5"""
46800,GPU Underutilized,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.5 LTS
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: 3.7.9
- CUDA/cuDNN version: CUDA Version: 11.0 
- GPU model and memory: Tesla T4, 15gb

**Describe the current behavior**
Sample code on a 1-GPU is utilizing 20% GPU.  Increasing the number of GPU's lowers utilization per GPU and increases the training total time.  There are a lot of copying from H2D and back.  Some functions, like Identity (which maybe expected) are executed on CPU. 

1-GPU:
Epoch 2/2
1000/1000 [==============================] - 4s 4ms/step

8-GPU:
Epoch 2/2
1000/1000 [==============================] - 8s 8ms/step

**Describe the expected behavior**
GPU utilization should be much higher.  I am already using TF_GPU_THREAD_MODE=gpu_private option.  
The dataset is preprocessed and saved on to a snapshot, then loaded as a distributed dataset.  
The actual prod data is displaying similar characteristics to this sandbox test.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1C5gK_TshqO-fscJYIRDI6OX74b2l2Iw7

**Other info / logs** Include any logs or source code that would be helpful to
https://github.com/iprovalo/tf/blob/main/input_pipeline_stats_benchmark.py

"
46799,Failed when trying to install TensorFlow 2.x into my laptop. Ubuntu 18.04(Desktop). From source,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04(Desktop)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
- TensorFlow installed from (source or binary): Source code
- TensorFlow version: 2.2
- Python version: 3.7.5
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): clang 11.0.0
- CUDA/cuDNN version: CUDA 11.2 / cuDNN 8.0.4
- GPU model and memory: GTX 1050 ti / 4 GB



**Describe the problem**
Hey, guys. I'm trying to install TensorFlow into my laptop(Dell G3 3579) but failed. There is the error information list below(**Any other info / logs**).

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```bash
sudo bazel build --config=opt --config=v2  --config=cuda //tensorflow/tools/pip_package:build_pip_package
```

**Any other info / logs**
```bash
(base) river@river-G3-3579:~/Downloads/Ubuntu_installation_essential_components/tensorflow$ sudo bazel build --config=opt --config=v2  --config=cuda //tensorflow/tools/pip_package:build_pip_package
[sudo] password for river: 
Starting local Bazel server and connecting to it...
WARNING: The following configs were expanded more than once: [cuda_clang, using_cuda, v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=141
INFO: Reading rc options for 'build' from /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.7/site-packages --python_path=/usr/local/bin/python3 --config=xla --config=tensorrt --action_env TF_CUDA_VERSION=11.2 --action_env TF_CUDNN_VERSION=8 --action_env TF_TENSORRT_VERSION=7 --action_env TF_NCCL_VERSION=2.7 --action_env TF_CUDA_PATHS=/usr/local/cuda-11.2/,/usr/local/cuda-11.2/targets/x86_64-linux/include/,/usr/local/include/,/usr/local/lib/,/home/river/Documents/OS_unitility/TensorRT/include/,/home/river/Documents/OS_unitility/TensorRT/util --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.2 --action_env TF_CUDA_COMPUTE_CAPABILITIES=6.1 --action_env LD_LIBRARY_PATH=:/usr/local/jdk1.8/lib:/usr/local/jdk1.8/jre/lib:/usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/extras/Debugger/lib64:/usr/local/cuda-11.2/nvvm/lib64:/usr/local/cuda-11.2/nvvm-prev/lib64 --config=cuda_clang --action_env CLANG_CUDA_COMPILER_PATH=/usr/local/bin/clang --config=cuda_clang --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --define=with_xla_support=true
INFO: Found applicable config definition build:tensorrt in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --action_env TF_NEED_TENSORRT=1
INFO: Found applicable config definition build:cuda_clang in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_clang=true --define=using_clang=true --action_env TF_CUDA_CLANG=1
INFO: Found applicable config definition build:using_cuda in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1
INFO: Found applicable config definition build:cuda_clang in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_clang=true --define=using_clang=true --action_env TF_CUDA_CLANG=1
INFO: Found applicable config definition build:using_cuda in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1
INFO: Found applicable config definition build:opt in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.tf_configure.bazelrc: --copt=-Wno-sign-compare --host_copt=-Wno-sign-compare --define with_default_optimizations=true
INFO: Found applicable config definition build:v2 in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:cuda in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1
INFO: Found applicable config definition build:linux in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Repository local_config_cuda instantiated at:
  /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/WORKSPACE:15:10: in <toplevel>
  /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/tensorflow/workspace2.bzl:13:20: in workspace
  /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/tensorflow/workspace.bzl:95:19: in tf_repositories
Repository rule cuda_configure defined at:
  /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/third_party/gpus/cuda_configure.bzl:1424:33: in <toplevel>
ERROR: An error occurred during the fetch of repository 'local_config_cuda':
   Traceback (most recent call last):
	File ""/home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1394, column 38, in _cuda_autoconf_impl
		_create_local_cuda_repository(repository_ctx)
	File ""/home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/third_party/gpus/cuda_configure.bzl"", line 977, column 35, in _create_local_cuda_repository
		cuda_config = _get_cuda_config(repository_ctx, find_cuda_config_script)
	File ""/home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/third_party/gpus/cuda_configure.bzl"", line 666, column 30, in _get_cuda_config
		config = find_cuda_config(repository_ctx, find_cuda_config_script, [""cuda"", ""cudnn""])
	File ""/home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/third_party/gpus/cuda_configure.bzl"", line 643, column 41, in find_cuda_config
		exec_result = _exec_find_cuda_config(repository_ctx, script_path, cuda_libraries)
	File ""/home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/third_party/gpus/cuda_configure.bzl"", line 637, column 19, in _exec_find_cuda_config
		return execute(repository_ctx, [python_bin, ""-c"", decompress_and_execute_cmd])
	File ""/home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/third_party/remote_config/common.bzl"", line 219, column 13, in execute
		fail(
Error in fail: Repository command failed
script.py:124: DeprecationWarning: invalid escape sequence \d
  match = re.match(""#define %s +(\d+)"" % name, line)
script.py:260: DeprecationWarning: invalid escape sequence \d
  pattern = ""Cuda compilation tools, release \d+\.\d+, V(\d+\.\d+\.\d+)""
script.py:553: DeprecationWarning: invalid escape sequence \w
  match = re.match(""^(/[^/ ]*)+/lib/\w+-linux-gnu/?$"", os.environ[env_name])
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cuda.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cublas_api.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cusolver_common.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/curand.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cufft.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cusparse.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cudnn.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cudnn_version.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
INFO: Repository rules_cc instantiated at:
  /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/WORKSPACE:15:10: in <toplevel>
  /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/tensorflow/workspace2.bzl:13:20: in workspace
  /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/tensorflow/workspace.bzl:1001:20: in tf_repositories
Repository rule tf_http_archive defined at:
  /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/third_party/repo.bzl:131:34: in <toplevel>
INFO: Repository bazel_skylib instantiated at:
  /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/WORKSPACE:15:10: in <toplevel>
  /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/tensorflow/workspace2.bzl:13:20: in workspace
  /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/tensorflow/workspace.bzl:1065:20: in tf_repositories
Repository rule tf_http_archive defined at:
  /home/river/Downloads/Ubuntu_installation_essential_components/tensorflow/third_party/repo.bzl:131:34: in <toplevel>
ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': no such package '@local_config_cuda//cuda': Repository command failed
script.py:124: DeprecationWarning: invalid escape sequence \d
  match = re.match(""#define %s +(\d+)"" % name, line)
script.py:260: DeprecationWarning: invalid escape sequence \d
  pattern = ""Cuda compilation tools, release \d+\.\d+, V(\d+\.\d+\.\d+)""
script.py:553: DeprecationWarning: invalid escape sequence \w
  match = re.match(""^(/[^/ ]*)+/lib/\w+-linux-gnu/?$"", os.environ[env_name])
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cuda.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cublas_api.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cusolver_common.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/curand.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cufft.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cusparse.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cudnn.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cudnn_version.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
WARNING: Target pattern parsing failed.
ERROR: no such package '@local_config_cuda//cuda': Repository command failed
script.py:124: DeprecationWarning: invalid escape sequence \d
  match = re.match(""#define %s +(\d+)"" % name, line)
script.py:260: DeprecationWarning: invalid escape sequence \d
  pattern = ""Cuda compilation tools, release \d+\.\d+, V(\d+\.\d+\.\d+)""
script.py:553: DeprecationWarning: invalid escape sequence \w
  match = re.match(""^(/[^/ ]*)+/lib/\w+-linux-gnu/?$"", os.environ[env_name])
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cuda.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cublas_api.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cusolver_common.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/curand.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cufft.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cusparse.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cudnn.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
script.py:123: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/cuda-11.2/include/cudnn_version.h' mode='r' encoding='utf-8'>
  for line in io.open(path, ""r"", encoding=""utf-8"").readlines():
ResourceWarning: Enable tracemalloc to get the object allocation traceback
INFO: Elapsed time: 7.982s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: tensorflow/tools/pip_package
    Fetching @local_config_tensorrt; fetching
```
"
46797,Trying to train a custom object detection model,"Hey guys!
I have been trying to train a model of Object detection using the the Tensorflow models that you guys provide and while i have been trying to do this for the last 3 weeks there are some issues which are coming again and again like there is nor attribute input to convolution box predictor as those issues are resolved now there is a new issue of checkpoint which i am not able to solve or find a way to solve it i would request to update me on this one 
![Problem1](https://user-images.githubusercontent.com/51516774/106319221-1e211380-6297-11eb-8395-bf5d3a09478a.jpg)
"
46794,"ValueError: Input 0 of layer encoder1_ is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 64, 4, 850)","          inputs_p = Input(shape=(5,4,850)) #4 time steps, 5 features , num_sds
          decoder_inputs = Input(shape=(5,4,850)) #1time step, 5 features , num_sds
          neighbhourhood = Input(shape=(4,850,850)) #1time step, 5 features , num_sds


          encoder_inputs = MyModel_conv_accross_time()(inputs_p , neighbhourhood)


          enc = LSTM(cfg['units'],activation='tanh',return_state=True,return_sequences=True,name='encoder1_') 
          decoder_outputs, state_h, state_c  = enc(encoder_inputs)


ValueError: Input 0 of layer encoder1_ is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 64, 4, 850)


MyModel_conv_accross_time  returns results with shape (batch,64,4,850)"
46792,TFlite conversion wierd Java Script error,"HI, I tried to convert my pytorch model to a deployable tflite model on my coral edge TPU:
And my torch model architecture is:
```
EncoderDecoder(
  (encoder): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (decoder): CatLinear(
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (dropout): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=512, out_features=55, bias=True)
  )
  (criterion): SmoothL1Loss()
)

```
### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): pip package
- Module Versions:
PyTorch: 1.7.1
Onnx: 1.8.0
Onnx_tf: 1.7.0
Tensorflow: 2.3.0

### 2. Code
I followed the instructions and I successfully converted from torch to onnx and to tensorflow.
However, when it comes to the tflite model, I met some problem.
The first method is:
```
def representative_dataset():
    for _ in range(100):
      data = np_input
      yield [data.astype(np.float32)]
        
converter = tf.lite.TFLiteConverter.from_saved_model(tfpath)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8  # or tf.uint8
converter.inference_output_type = tf.int8 
tflite_model = converter.convert()
open(""test.tflite"", ""wb"").write(tflite_model)
```


During the conversion, the page froze and evetually gave me an error: ``Javascript Error: too much recurtion``
I also tried run a python script instead of in a Jupyter notebook, the terminal output seems indicate a successful conversion, but there is no tflite file generated. The output is:
```
  %0 = ""tfl.pad""(%arg0, %cst) : (tensor<1x3x960x360xf32>, tensor<4x2xi32>) -> tensor<1x3x966x366xf32>
  %1 = ""tfl.transpose""(%0, %cst_5) : (tensor<1x3x966x366xf32>, tensor<4xi32>) -> tensor<1x966x366x3xf32>
  %2 = ""tfl.split""(%cst_4, %1) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x966x366x3xf32>) -> tensor<1x966x366x3xf32>
  %3 = ""tfl.conv_2d""(%2, %cst_12, %cst_48) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x966x366x3xf32>, tensor<64x7x7x3xf32>, tensor<64xf32>) -> tensor<1x480x180x64xf32>
  %4 = ""tfl.transpose""(%3, %cst_6) : (tensor<1x480x180x64xf32>, tensor<4xi32>) -> tensor<1x64x480x180xf32>
  %5 = ""tfl.pad""(%4, %cst_0) : (tensor<1x64x480x180xf32>, tensor<4x2xi32>) -> tensor<1x64x482x182xf32>
  %6 = ""tfl.transpose""(%5, %cst_5) : (tensor<1x64x482x182xf32>, tensor<4xi32>) -> tensor<1x482x182x64xf32>
  %7 = ""tfl.split""(%cst_4, %6) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x482x182x64xf32>) -> tensor<1x482x182x64xf32>
  %8 = ""tfl.conv_2d""(%7, %cst_13, %cst_49) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x482x182x64xf32>, tensor<64x3x3x64xf32>, tensor<64xf32>) -> tensor<1x480x180x64xf32>
  %9 = ""tfl.transpose""(%8, %cst_6) : (tensor<1x480x180x64xf32>, tensor<4xi32>) -> tensor<1x64x480x180xf32>
  %10 = ""tfl.pad""(%9, %cst_0) : (tensor<1x64x480x180xf32>, tensor<4x2xi32>) -> tensor<1x64x482x182xf32>
  %11 = ""tfl.transpose""(%10, %cst_5) : (tensor<1x64x482x182xf32>, tensor<4xi32>) -> tensor<1x482x182x64xf32>
  %12 = ""tfl.split""(%cst_4, %11) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x482x182x64xf32>) -> tensor<1x482x182x64xf32>
  %13 = ""tfl.conv_2d""(%12, %cst_14, %cst_50) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x482x182x64xf32>, tensor<64x3x3x64xf32>, tensor<64xf32>) -> tensor<1x480x180x64xf32>
  %14 = ""tfl.transpose""(%13, %cst_6) : (tensor<1x480x180x64xf32>, tensor<4xi32>) -> tensor<1x64x480x180xf32>
  %15 = ""tfl.add""(%14, %4) {fused_activation_function = ""RELU""} : (tensor<1x64x480x180xf32>, tensor<1x64x480x180xf32>) -> tensor<1x64x480x180xf32>
  %16 = ""tfl.pad""(%15, %cst_0) : (tensor<1x64x480x180xf32>, tensor<4x2xi32>) -> tensor<1x64x482x182xf32>
  %17 = ""tfl.transpose""(%16, %cst_5) : (tensor<1x64x482x182xf32>, tensor<4xi32>) -> tensor<1x482x182x64xf32>
  %18 = ""tfl.split""(%cst_4, %17) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x482x182x64xf32>) -> tensor<1x482x182x64xf32>
  %19 = ""tfl.conv_2d""(%18, %cst_15, %cst_51) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x482x182x64xf32>, tensor<64x3x3x64xf32>, tensor<64xf32>) -> tensor<1x480x180x64xf32>
  %20 = ""tfl.transpose""(%19, %cst_6) : (tensor<1x480x180x64xf32>, tensor<4xi32>) -> tensor<1x64x480x180xf32>
  %21 = ""tfl.pad""(%20, %cst_0) : (tensor<1x64x480x180xf32>, tensor<4x2xi32>) -> tensor<1x64x482x182xf32>
  %22 = ""tfl.transpose""(%21, %cst_5) : (tensor<1x64x482x182xf32>, tensor<4xi32>) -> tensor<1x482x182x64xf32>
  %23 = ""tfl.split""(%cst_4, %22) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x482x182x64xf32>) -> tensor<1x482x182x64xf32>
  %24 = ""tfl.gather""(%cst_1, %cst_52) {axis = 0 : i32} : (tensor<4xi64>, tensor<0xi64>) -> tensor<0xi64>
  %25 = ""tfl.sparse_to_dense""(%cst_11, %cst_2, %24, %cst_7) : (tensor<0x1xi64>, tensor<1xi64>, tensor<0xi64>, tensor<i64>) -> tensor<2xi64>
  %26 = ""tf.AddV2""(%25, %cst_10) {device = """"} : (tensor<2xi64>, tensor<2xi64>) -> tensor<2xi64>
  %27 = ""tfl.conv_2d""(%23, %cst_16, %cst_53) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x482x182x64xf32>, tensor<64x3x3x64xf32>, tensor<64xf32>) -> tensor<1x480x180x64xf32>
  %28 = ""tfl.transpose""(%27, %cst_6) : (tensor<1x480x180x64xf32>, tensor<4xi32>) -> tensor<1x64x480x180xf32>
  %29 = ""tfl.add""(%28, %15) {fused_activation_function = ""RELU""} : (tensor<1x64x480x180xf32>, tensor<1x64x480x180xf32>) -> tensor<1x64x480x180xf32>
  %30 = ""tfl.pad""(%29, %cst_0) : (tensor<1x64x480x180xf32>, tensor<4x2xi32>) -> tensor<1x64x482x182xf32>
  %31 = ""tfl.transpose""(%30, %cst_5) : (tensor<1x64x482x182xf32>, tensor<4xi32>) -> tensor<1x482x182x64xf32>
  %32 = ""tfl.split""(%cst_4, %31) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x482x182x64xf32>) -> tensor<1x482x182x64xf32>
  %33 = ""tfl.conv_2d""(%32, %cst_17, %cst_54) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x482x182x64xf32>, tensor<64x3x3x64xf32>, tensor<64xf32>) -> tensor<1x480x180x64xf32>
  %34 = ""tfl.transpose""(%33, %cst_6) : (tensor<1x480x180x64xf32>, tensor<4xi32>) -> tensor<1x64x480x180xf32>
  %35 = ""tfl.pad""(%34, %cst_0) : (tensor<1x64x480x180xf32>, tensor<4x2xi32>) -> tensor<1x64x482x182xf32>
  %36 = ""tfl.transpose""(%35, %cst_5) : (tensor<1x64x482x182xf32>, tensor<4xi32>) -> tensor<1x482x182x64xf32>
  %37 = ""tfl.split""(%cst_4, %36) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x482x182x64xf32>) -> tensor<1x482x182x64xf32>
  %38 = ""tfl.conv_2d""(%37, %cst_18, %cst_55) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x482x182x64xf32>, tensor<64x3x3x64xf32>, tensor<64xf32>) -> tensor<1x480x180x64xf32>
  %39 = ""tfl.transpose""(%38, %cst_6) : (tensor<1x480x180x64xf32>, tensor<4xi32>) -> tensor<1x64x480x180xf32>
  %40 = ""tfl.add""(%39, %29) {fused_activation_function = ""RELU""} : (tensor<1x64x480x180xf32>, tensor<1x64x480x180xf32>) -> tensor<1x64x480x180xf32>
  %41 = ""tfl.pad""(%40, %cst_0) : (tensor<1x64x480x180xf32>, tensor<4x2xi32>) -> tensor<1x64x482x182xf32>
  %42 = ""tfl.transpose""(%41, %cst_5) : (tensor<1x64x482x182xf32>, tensor<4xi32>) -> tensor<1x482x182x64xf32>
  %43 = ""tfl.split""(%cst_4, %42) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x482x182x64xf32>) -> tensor<1x482x182x64xf32>
  %44 = ""tfl.conv_2d""(%43, %cst_19, %cst_56) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x482x182x64xf32>, tensor<128x3x3x64xf32>, tensor<128xf32>) -> tensor<1x240x90x128xf32>
  %45 = ""tfl.transpose""(%44, %cst_6) : (tensor<1x240x90x128xf32>, tensor<4xi32>) -> tensor<1x128x240x90xf32>
  %46 = ""tfl.pad""(%45, %cst_0) : (tensor<1x128x240x90xf32>, tensor<4x2xi32>) -> tensor<1x128x242x92xf32>
  %47 = ""tfl.transpose""(%46, %cst_5) : (tensor<1x128x242x92xf32>, tensor<4xi32>) -> tensor<1x242x92x128xf32>
  %48 = ""tfl.split""(%cst_4, %47) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x242x92x128xf32>) -> tensor<1x242x92x128xf32>
  %49 = ""tfl.conv_2d""(%48, %cst_20, %cst_57) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x242x92x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x240x90x128xf32>
  %50 = ""tfl.transpose""(%49, %cst_6) : (tensor<1x240x90x128xf32>, tensor<4xi32>) -> tensor<1x128x240x90xf32>
  %51 = ""tfl.transpose""(%40, %cst_5) : (tensor<1x64x480x180xf32>, tensor<4xi32>) -> tensor<1x480x180x64xf32>
  %52 = ""tfl.split""(%cst_4, %51) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x480x180x64xf32>) -> tensor<1x480x180x64xf32>
  %53 = ""tfl.conv_2d""(%52, %cst_21, %cst_58) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x480x180x64xf32>, tensor<128x1x1x64xf32>, tensor<128xf32>) -> tensor<1x240x90x128xf32>
  %54 = ""tfl.transpose""(%53, %cst_6) : (tensor<1x240x90x128xf32>, tensor<4xi32>) -> tensor<1x128x240x90xf32>
  %55 = ""tfl.add""(%50, %54) {fused_activation_function = ""RELU""} : (tensor<1x128x240x90xf32>, tensor<1x128x240x90xf32>) -> tensor<1x128x240x90xf32>
  %56 = ""tfl.pad""(%55, %cst_0) : (tensor<1x128x240x90xf32>, tensor<4x2xi32>) -> tensor<1x128x242x92xf32>
  %57 = ""tfl.transpose""(%56, %cst_5) : (tensor<1x128x242x92xf32>, tensor<4xi32>) -> tensor<1x242x92x128xf32>
  %58 = ""tfl.split""(%cst_4, %57) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x242x92x128xf32>) -> tensor<1x242x92x128xf32>
  %59 = ""tfl.conv_2d""(%58, %cst_22, %cst_59) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x242x92x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x240x90x128xf32>
  %60 = ""tfl.transpose""(%59, %cst_6) : (tensor<1x240x90x128xf32>, tensor<4xi32>) -> tensor<1x128x240x90xf32>
  %61 = ""tfl.pad""(%60, %cst_0) : (tensor<1x128x240x90xf32>, tensor<4x2xi32>) -> tensor<1x128x242x92xf32>
  %62 = ""tfl.transpose""(%61, %cst_5) : (tensor<1x128x242x92xf32>, tensor<4xi32>) -> tensor<1x242x92x128xf32>
  %63 = ""tfl.split""(%cst_4, %62) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x242x92x128xf32>) -> tensor<1x242x92x128xf32>
  %64 = ""tfl.conv_2d""(%63, %cst_23, %cst_60) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x242x92x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x240x90x128xf32>
  %65 = ""tfl.transpose""(%64, %cst_6) : (tensor<1x240x90x128xf32>, tensor<4xi32>) -> tensor<1x128x240x90xf32>
  %66 = ""tfl.add""(%65, %55) {fused_activation_function = ""RELU""} : (tensor<1x128x240x90xf32>, tensor<1x128x240x90xf32>) -> tensor<1x128x240x90xf32>
  %67 = ""tfl.pad""(%66, %cst_0) : (tensor<1x128x240x90xf32>, tensor<4x2xi32>) -> tensor<1x128x242x92xf32>
  %68 = ""tfl.transpose""(%67, %cst_5) : (tensor<1x128x242x92xf32>, tensor<4xi32>) -> tensor<1x242x92x128xf32>
  %69 = ""tfl.split""(%cst_4, %68) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x242x92x128xf32>) -> tensor<1x242x92x128xf32>
  %70 = ""tfl.conv_2d""(%69, %cst_24, %cst_61) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x242x92x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x240x90x128xf32>
  %71 = ""tfl.transpose""(%70, %cst_6) : (tensor<1x240x90x128xf32>, tensor<4xi32>) -> tensor<1x128x240x90xf32>
  %72 = ""tfl.pad""(%71, %cst_0) : (tensor<1x128x240x90xf32>, tensor<4x2xi32>) -> tensor<1x128x242x92xf32>
  %73 = ""tfl.transpose""(%72, %cst_5) : (tensor<1x128x242x92xf32>, tensor<4xi32>) -> tensor<1x242x92x128xf32>
  %74 = ""tfl.split""(%cst_4, %73) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x242x92x128xf32>) -> tensor<1x242x92x128xf32>
  %75 = ""tfl.conv_2d""(%74, %cst_25, %cst_62) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x242x92x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x240x90x128xf32>
  %76 = ""tfl.transpose""(%75, %cst_6) : (tensor<1x240x90x128xf32>, tensor<4xi32>) -> tensor<1x128x240x90xf32>
  %77 = ""tfl.add""(%76, %66) {fused_activation_function = ""RELU""} : (tensor<1x128x240x90xf32>, tensor<1x128x240x90xf32>) -> tensor<1x128x240x90xf32>
  %78 = ""tfl.pad""(%77, %cst_0) : (tensor<1x128x240x90xf32>, tensor<4x2xi32>) -> tensor<1x128x242x92xf32>
  %79 = ""tfl.transpose""(%78, %cst_5) : (tensor<1x128x242x92xf32>, tensor<4xi32>) -> tensor<1x242x92x128xf32>
  %80 = ""tfl.split""(%cst_4, %79) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x242x92x128xf32>) -> tensor<1x242x92x128xf32>
  %81 = ""tfl.conv_2d""(%80, %cst_26, %cst_63) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x242x92x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x240x90x128xf32>
  %82 = ""tfl.transpose""(%81, %cst_6) : (tensor<1x240x90x128xf32>, tensor<4xi32>) -> tensor<1x128x240x90xf32>
  %83 = ""tfl.pad""(%82, %cst_0) : (tensor<1x128x240x90xf32>, tensor<4x2xi32>) -> tensor<1x128x242x92xf32>
  %84 = ""tfl.transpose""(%83, %cst_5) : (tensor<1x128x242x92xf32>, tensor<4xi32>) -> tensor<1x242x92x128xf32>
  %85 = ""tfl.split""(%cst_4, %84) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x242x92x128xf32>) -> tensor<1x242x92x128xf32>
  %86 = ""tfl.conv_2d""(%85, %cst_27, %cst_64) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x242x92x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x240x90x128xf32>
  %87 = ""tfl.transpose""(%86, %cst_6) : (tensor<1x240x90x128xf32>, tensor<4xi32>) -> tensor<1x128x240x90xf32>
  %88 = ""tfl.add""(%87, %77) {fused_activation_function = ""RELU""} : (tensor<1x128x240x90xf32>, tensor<1x128x240x90xf32>) -> tensor<1x128x240x90xf32>
  %89 = ""tfl.pad""(%88, %cst_0) : (tensor<1x128x240x90xf32>, tensor<4x2xi32>) -> tensor<1x128x242x92xf32>
  %90 = ""tfl.transpose""(%89, %cst_5) : (tensor<1x128x242x92xf32>, tensor<4xi32>) -> tensor<1x242x92x128xf32>
  %91 = ""tfl.split""(%cst_4, %90) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x242x92x128xf32>) -> tensor<1x242x92x128xf32>
  %92 = ""tfl.conv_2d""(%91, %cst_28, %cst_65) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x242x92x128xf32>, tensor<256x3x3x128xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %93 = ""tfl.transpose""(%92, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %94 = ""tfl.pad""(%93, %cst_0) : (tensor<1x256x120x45xf32>, tensor<4x2xi32>) -> tensor<1x256x122x47xf32>
  %95 = ""tfl.transpose""(%94, %cst_5) : (tensor<1x256x122x47xf32>, tensor<4xi32>) -> tensor<1x122x47x256xf32>
  %96 = ""tfl.split""(%cst_4, %95) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x122x47x256xf32>) -> tensor<1x122x47x256xf32>
  %97 = ""tfl.conv_2d""(%96, %cst_29, %cst_66) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x122x47x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %98 = ""tfl.transpose""(%97, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %99 = ""tfl.transpose""(%88, %cst_5) : (tensor<1x128x240x90xf32>, tensor<4xi32>) -> tensor<1x240x90x128xf32>
  %100 = ""tfl.split""(%cst_4, %99) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x240x90x128xf32>) -> tensor<1x240x90x128xf32>
  %101 = ""tfl.conv_2d""(%100, %cst_30, %cst_67) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x240x90x128xf32>, tensor<256x1x1x128xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %102 = ""tfl.transpose""(%101, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %103 = ""tfl.add""(%98, %102) {fused_activation_function = ""RELU""} : (tensor<1x256x120x45xf32>, tensor<1x256x120x45xf32>) -> tensor<1x256x120x45xf32>
  %104 = ""tfl.pad""(%103, %cst_0) : (tensor<1x256x120x45xf32>, tensor<4x2xi32>) -> tensor<1x256x122x47xf32>
  %105 = ""tfl.transpose""(%104, %cst_5) : (tensor<1x256x122x47xf32>, tensor<4xi32>) -> tensor<1x122x47x256xf32>
  %106 = ""tfl.split""(%cst_4, %105) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x122x47x256xf32>) -> tensor<1x122x47x256xf32>
  %107 = ""tfl.conv_2d""(%106, %cst_31, %cst_68) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x122x47x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %108 = ""tfl.transpose""(%107, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %109 = ""tfl.pad""(%108, %cst_0) : (tensor<1x256x120x45xf32>, tensor<4x2xi32>) -> tensor<1x256x122x47xf32>
  %110 = ""tfl.transpose""(%109, %cst_5) : (tensor<1x256x122x47xf32>, tensor<4xi32>) -> tensor<1x122x47x256xf32>
  %111 = ""tfl.split""(%cst_4, %110) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x122x47x256xf32>) -> tensor<1x122x47x256xf32>
  %112 = ""tfl.conv_2d""(%111, %cst_32, %cst_69) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x122x47x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %113 = ""tfl.transpose""(%112, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %114 = ""tfl.add""(%113, %103) {fused_activation_function = ""RELU""} : (tensor<1x256x120x45xf32>, tensor<1x256x120x45xf32>) -> tensor<1x256x120x45xf32>
  %115 = ""tfl.pad""(%114, %cst_0) : (tensor<1x256x120x45xf32>, tensor<4x2xi32>) -> tensor<1x256x122x47xf32>
  %116 = ""tfl.transpose""(%115, %cst_5) : (tensor<1x256x122x47xf32>, tensor<4xi32>) -> tensor<1x122x47x256xf32>
  %117 = ""tfl.split""(%cst_4, %116) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x122x47x256xf32>) -> tensor<1x122x47x256xf32>
  %118 = ""tfl.conv_2d""(%117, %cst_33, %cst_70) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x122x47x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %119 = ""tfl.transpose""(%118, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %120 = ""tfl.pad""(%119, %cst_0) : (tensor<1x256x120x45xf32>, tensor<4x2xi32>) -> tensor<1x256x122x47xf32>
  %121 = ""tfl.transpose""(%120, %cst_5) : (tensor<1x256x122x47xf32>, tensor<4xi32>) -> tensor<1x122x47x256xf32>
  %122 = ""tfl.split""(%cst_4, %121) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x122x47x256xf32>) -> tensor<1x122x47x256xf32>
  %123 = ""tfl.conv_2d""(%122, %cst_34, %cst_71) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x122x47x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %124 = ""tfl.transpose""(%123, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %125 = ""tfl.add""(%124, %114) {fused_activation_function = ""RELU""} : (tensor<1x256x120x45xf32>, tensor<1x256x120x45xf32>) -> tensor<1x256x120x45xf32>
  %126 = ""tfl.pad""(%125, %cst_0) : (tensor<1x256x120x45xf32>, tensor<4x2xi32>) -> tensor<1x256x122x47xf32>
  %127 = ""tfl.transpose""(%126, %cst_5) : (tensor<1x256x122x47xf32>, tensor<4xi32>) -> tensor<1x122x47x256xf32>
  %128 = ""tfl.split""(%cst_4, %127) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x122x47x256xf32>) -> tensor<1x122x47x256xf32>
  %129 = ""tfl.conv_2d""(%128, %cst_35, %cst_72) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x122x47x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %130 = ""tfl.transpose""(%129, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %131 = ""tfl.pad""(%130, %cst_0) : (tensor<1x256x120x45xf32>, tensor<4x2xi32>) -> tensor<1x256x122x47xf32>
  %132 = ""tfl.transpose""(%131, %cst_5) : (tensor<1x256x122x47xf32>, tensor<4xi32>) -> tensor<1x122x47x256xf32>
  %133 = ""tfl.split""(%cst_4, %132) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x122x47x256xf32>) -> tensor<1x122x47x256xf32>
  %134 = ""tfl.conv_2d""(%133, %cst_36, %cst_73) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x122x47x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %135 = ""tfl.transpose""(%134, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %136 = ""tfl.add""(%135, %125) {fused_activation_function = ""RELU""} : (tensor<1x256x120x45xf32>, tensor<1x256x120x45xf32>) -> tensor<1x256x120x45xf32>
  %137 = ""tfl.pad""(%136, %cst_0) : (tensor<1x256x120x45xf32>, tensor<4x2xi32>) -> tensor<1x256x122x47xf32>
  %138 = ""tfl.transpose""(%137, %cst_5) : (tensor<1x256x122x47xf32>, tensor<4xi32>) -> tensor<1x122x47x256xf32>
  %139 = ""tfl.split""(%cst_4, %138) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x122x47x256xf32>) -> tensor<1x122x47x256xf32>
  %140 = ""tfl.conv_2d""(%139, %cst_37, %cst_74) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x122x47x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %141 = ""tfl.transpose""(%140, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %142 = ""tfl.pad""(%141, %cst_0) : (tensor<1x256x120x45xf32>, tensor<4x2xi32>) -> tensor<1x256x122x47xf32>
  %143 = ""tfl.transpose""(%142, %cst_5) : (tensor<1x256x122x47xf32>, tensor<4xi32>) -> tensor<1x122x47x256xf32>
  %144 = ""tfl.split""(%cst_4, %143) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x122x47x256xf32>) -> tensor<1x122x47x256xf32>
  %145 = ""tfl.conv_2d""(%144, %cst_38, %cst_75) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x122x47x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %146 = ""tfl.transpose""(%145, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %147 = ""tfl.add""(%146, %136) {fused_activation_function = ""RELU""} : (tensor<1x256x120x45xf32>, tensor<1x256x120x45xf32>) -> tensor<1x256x120x45xf32>
  %148 = ""tfl.pad""(%147, %cst_0) : (tensor<1x256x120x45xf32>, tensor<4x2xi32>) -> tensor<1x256x122x47xf32>
  %149 = ""tfl.transpose""(%148, %cst_5) : (tensor<1x256x122x47xf32>, tensor<4xi32>) -> tensor<1x122x47x256xf32>
  %150 = ""tfl.split""(%cst_4, %149) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x122x47x256xf32>) -> tensor<1x122x47x256xf32>
  %151 = ""tfl.conv_2d""(%150, %cst_39, %cst_76) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x122x47x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %152 = ""tfl.transpose""(%151, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %153 = ""tfl.pad""(%152, %cst_0) : (tensor<1x256x120x45xf32>, tensor<4x2xi32>) -> tensor<1x256x122x47xf32>
  %154 = ""tfl.transpose""(%153, %cst_5) : (tensor<1x256x122x47xf32>, tensor<4xi32>) -> tensor<1x122x47x256xf32>
  %155 = ""tfl.split""(%cst_4, %154) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x122x47x256xf32>) -> tensor<1x122x47x256xf32>
  %156 = ""tfl.conv_2d""(%155, %cst_40, %cst_77) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x122x47x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x120x45x256xf32>
  %157 = ""tfl.transpose""(%156, %cst_6) : (tensor<1x120x45x256xf32>, tensor<4xi32>) -> tensor<1x256x120x45xf32>
  %158 = ""tfl.add""(%157, %147) {fused_activation_function = ""RELU""} : (tensor<1x256x120x45xf32>, tensor<1x256x120x45xf32>) -> tensor<1x256x120x45xf32>
  %159 = ""tfl.pad""(%158, %cst_0) : (tensor<1x256x120x45xf32>, tensor<4x2xi32>) -> tensor<1x256x122x47xf32>
  %160 = ""tfl.transpose""(%159, %cst_5) : (tensor<1x256x122x47xf32>, tensor<4xi32>) -> tensor<1x122x47x256xf32>
  %161 = ""tfl.split""(%cst_4, %160) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x122x47x256xf32>) -> tensor<1x122x47x256xf32>
  %162 = ""tfl.conv_2d""(%161, %cst_41, %cst_78) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x122x47x256xf32>, tensor<512x3x3x256xf32>, tensor<512xf32>) -> tensor<1x60x23x512xf32>
  %163 = ""tfl.transpose""(%162, %cst_6) : (tensor<1x60x23x512xf32>, tensor<4xi32>) -> tensor<1x512x60x23xf32>
  %164 = ""tfl.pad""(%163, %cst_0) : (tensor<1x512x60x23xf32>, tensor<4x2xi32>) -> tensor<1x512x62x25xf32>
  %165 = ""tfl.transpose""(%164, %cst_5) : (tensor<1x512x62x25xf32>, tensor<4xi32>) -> tensor<1x62x25x512xf32>
  %166 = ""tfl.split""(%cst_4, %165) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x62x25x512xf32>) -> tensor<1x62x25x512xf32>
  %167 = ""tfl.conv_2d""(%166, %cst_42, %cst_79) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x62x25x512xf32>, tensor<512x3x3x512xf32>, tensor<512xf32>) -> tensor<1x60x23x512xf32>
  %168 = ""tfl.transpose""(%167, %cst_6) : (tensor<1x60x23x512xf32>, tensor<4xi32>) -> tensor<1x512x60x23xf32>
  %169 = ""tfl.transpose""(%158, %cst_5) : (tensor<1x256x120x45xf32>, tensor<4xi32>) -> tensor<1x120x45x256xf32>
  %170 = ""tfl.split""(%cst_4, %169) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x120x45x256xf32>) -> tensor<1x120x45x256xf32>
  %171 = ""tfl.conv_2d""(%170, %cst_43, %cst_80) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x120x45x256xf32>, tensor<512x1x1x256xf32>, tensor<512xf32>) -> tensor<1x60x23x512xf32>
  %172 = ""tfl.transpose""(%171, %cst_6) : (tensor<1x60x23x512xf32>, tensor<4xi32>) -> tensor<1x512x60x23xf32>
  %173 = ""tfl.add""(%168, %172) {fused_activation_function = ""RELU""} : (tensor<1x512x60x23xf32>, tensor<1x512x60x23xf32>) -> tensor<1x512x60x23xf32>
  %174 = ""tfl.pad""(%173, %cst_0) : (tensor<1x512x60x23xf32>, tensor<4x2xi32>) -> tensor<1x512x62x25xf32>
  %175 = ""tfl.transpose""(%174, %cst_5) : (tensor<1x512x62x25xf32>, tensor<4xi32>) -> tensor<1x62x25x512xf32>
  %176 = ""tfl.split""(%cst_4, %175) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x62x25x512xf32>) -> tensor<1x62x25x512xf32>
  %177 = ""tfl.conv_2d""(%176, %cst_44, %cst_81) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x62x25x512xf32>, tensor<512x3x3x512xf32>, tensor<512xf32>) -> tensor<1x60x23x512xf32>
  %178 = ""tfl.transpose""(%177, %cst_6) : (tensor<1x60x23x512xf32>, tensor<4xi32>) -> tensor<1x512x60x23xf32>
  %179 = ""tfl.pad""(%178, %cst_0) : (tensor<1x512x60x23xf32>, tensor<4x2xi32>) -> tensor<1x512x62x25xf32>
  %180 = ""tfl.transpose""(%179, %cst_5) : (tensor<1x512x62x25xf32>, tensor<4xi32>) -> tensor<1x62x25x512xf32>
  %181 = ""tfl.split""(%cst_4, %180) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x62x25x512xf32>) -> tensor<1x62x25x512xf32>
  %182 = ""tfl.conv_2d""(%181, %cst_45, %cst_82) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x62x25x512xf32>, tensor<512x3x3x512xf32>, tensor<512xf32>) -> tensor<1x60x23x512xf32>
  %183 = ""tfl.transpose""(%182, %cst_6) : (tensor<1x60x23x512xf32>, tensor<4xi32>) -> tensor<1x512x60x23xf32>
  %184 = ""tfl.add""(%183, %173) {fused_activation_function = ""RELU""} : (tensor<1x512x60x23xf32>, tensor<1x512x60x23xf32>) -> tensor<1x512x60x23xf32>
  %185 = ""tfl.pad""(%184, %cst_0) : (tensor<1x512x60x23xf32>, tensor<4x2xi32>) -> tensor<1x512x62x25xf32>
  %186 = ""tfl.transpose""(%185, %cst_5) : (tensor<1x512x62x25xf32>, tensor<4xi32>) -> tensor<1x62x25x512xf32>
  %187 = ""tfl.split""(%cst_4, %186) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x62x25x512xf32>) -> tensor<1x62x25x512xf32>
  %188 = ""tfl.conv_2d""(%187, %cst_46, %cst_83) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""RELU"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x62x25x512xf32>, tensor<512x3x3x512xf32>, tensor<512xf32>) -> tensor<1x60x23x512xf32>
  %189 = ""tfl.transpose""(%188, %cst_6) : (tensor<1x60x23x512xf32>, tensor<4xi32>) -> tensor<1x512x60x23xf32>
  %190 = ""tfl.pad""(%189, %cst_0) : (tensor<1x512x60x23xf32>, tensor<4x2xi32>) -> tensor<1x512x62x25xf32>
  %191 = ""tfl.transpose""(%190, %cst_5) : (tensor<1x512x62x25xf32>, tensor<4xi32>) -> tensor<1x62x25x512xf32>
  %192 = ""tfl.split""(%cst_4, %191) {num_splits = 1 : i32} : (tensor<i32>, tensor<1x62x25x512xf32>) -> tensor<1x62x25x512xf32>
  %193 = ""tfl.conv_2d""(%192, %cst_47, %cst_84) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = ""NONE"", padding = ""VALID"", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x62x25x512xf32>, tensor<512x3x3x512xf32>, tensor<512xf32>) -> tensor<1x60x23x512xf32>
  %194 = ""tfl.transpose""(%193, %cst_6) : (tensor<1x60x23x512xf32>, tensor<4xi32>) -> tensor<1x512x60x23xf32>
  %195 = ""tfl.add""(%194, %184) {fused_activation_function = ""RELU""} : (tensor<1x512x60x23xf32>, tensor<1x512x60x23xf32>) -> tensor<1x512x60x23xf32>
  %196 = ""tfl.mean""(%195, %cst_3) {keep_dims = true} : (tensor<1x512x60x23xf32>, tensor<2xi32>) -> tensor<1x512x1x1xf32>
  %197 = ""tfl.cast""(%26) : (tensor<2xi64>) -> tensor<2xi32>
  %198 = ""tfl.reshape""(%196, %197) : (tensor<1x512x1x1xf32>, tensor<2xi32>) -> tensor<1x512xf32>
  %199 = ""tfl.fully_connected""(%198, %cst_8, %cst_9) {fused_activation_function = ""NONE"", keep_num_dims = false, weights_format = ""DEFAULT""} : (tensor<1x512xf32>, tensor<55x512xf32>, tensor<55xf32>) -> tensor<1x55xf32>
  ""std.return""(%199) : (tensor<1x55xf32>) -> ()
}) {sym_name = ""main"", tf.entry_function = {control_outputs = """", inputs = ""input"", outputs = ""Identity""}, type = (tensor<1x3x960x360xf32>) -> tensor<1x55xf32>} : () -> ()
```
When I use another method, the tflite model seem converted successful,
```
converter = tf.lite.TFLiteConverter.from_saved_model(tfpath)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [
  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.
]
tflite_model = converter.convert()
open(""test.tflite"", ""wb"").write(tflite_model)
```
But since this is not quantized, when I deployed the model on my Coral USB TPU, it stated:
`ERROR: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.` Which makes sense since I added` tf.lite.OpsSet.SELECT_TF_OPS`. And I used the edgetpu compiler, which gave me the same error. It seems I can only convert my tensorflow to tflite model successfully using this parameter 'tf.lite.OpsSet.SELECT_TF_OPS' (other wise I will have a wierd Javascript Error.
I am kinda stuck between a unsupported, yet converted tflite model and a wierd error that did not even generated a tflite model.

I also tried a definetaly unreasonable combination:
```
def representative_dataset():
    for _ in range(100):
      data = np_input
      yield [data.astype(np.float32)]
        
converter = tf.lite.TFLiteConverter.from_saved_model(tfpath)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
**converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]**
converter.inference_input_type = tf.int8  # or tf.uint8
converter.inference_output_type = tf.int8 
tflite_model = converter.convert()
open(""test.tflite"", ""wb"").write(tflite_model)
```
Which gave me a tflite model, with unsupported ops and uint8 as i/o

Does anyone met this problem and know how to solve this? Thank you! 


"
46791,Do not use XLA. Build configuration,"Hi, 

this is related to building TensorFlow from source, but in case it's my wrongdoing I didn't want to mark it as a bug.

Tensorflow 2.2.1
Keras 2.3.1

I have a VAE model in which decoder is autoregressive and and one of the layer looks like this:

```python
class AutoregressiveGRU(layers.Layer):

    def __init__(
            self,
            output_dim: int,
            output_len: int,
            recurrent: layers.Recurrent,
            **kwargs,
    ):
        self.output_dim = output_dim
        self.output_len = output_len
        self.initial_state = None
        self.recurrent = recurrent
        super(AutoregressiveGRU, self).__init__(**kwargs)

    def build(self, input_shape):
        super(AutoregressiveGRU, self).build(input_shape)

    def call(self, x):
        outputs = []
        current_output = backend.zeros_like(backend.repeat(x, 1))
        current_state = x
        for _ in range(self.output_len):
            current_output, current_state = self.recurrent(
                current_output,
                initial_state=current_state,
            )
            outputs.append(current_output)
        result = layers.concatenate(outputs, axis=1)
        result = backend.reshape(result, (-1, self.output_len, self.output_dim))
        return result
```

I am calculating some higher-order gradients and I am getting errors such as:

```shell
InvalidArgumentError: Operation 'gradients_2/autoregressive_gru_1_3/gru_3/while_grad/autoregressive_gru_1_3/gru_3/while_grad' has no attr named '_XlaCompile'.

```

I looked at [XLA known issues](https://www.tensorflow.org/xla/known_issues) and found out that this might be related to the for-loop that is not bounded to constant number of iterations. I have rewritten the `for-loop` in that layer with `tf.while_loop` that has `maximum_iteration` parameter set, but the problem (error mentioned above) persists:

```python
    def call(self, x):
        outputs = []
        current_output = backend.zeros_like(backend.repeat(x, 1))
        current_state = x
        i = tf.constant(0)
        c = lambda i, a, b, ta: i < 25
        def turn(i, current_statex, current_outputx, ta):
            current_output_cur, current_state_cur = self.recurrent(
                current_outputx,
                initial_state=current_statex,
            )
            ta.write(i, current_output_cur)
            tf.add(i, 1)
            return [i, current_state_cur, current_output_cur, ta]

        i, a, b, ta =  tf.while_loop(c, turn, [i, current_state, current_output, tf.TensorArray(tf.float32, size=25)], maximum_iterations=tf.constant(25))
        result = ta.stack()
        return backend.reshape(result, (-1, self.output_len, self.output_dim))
```

I decided to drop XLA all together and so I compiled TensorFlow from source setting:
```
build:xla --action_env=TF_ENABLE_XLA=0
build:xla --define=with_xla_support=false
```

And it still  comes with the same error. Is there something wrong with what I am doing?

I apologize but I am not able to put the entire model here for various reasons. If I remove the autoregressive layer, everything works.

EDIT:
```
tf.config.list_physical_devices()
```
now returns only cpu `physical_device:CPU` ano no `physical_device:XLA_CPU`. So why is XLA even used during training? 
```
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
```"
46790,tf-nightly ResNet50V2 building error,"**System information**
Colab

**Describe the current behavior**
Tf-nightly notebook:
https://colab.research.google.com/drive/1-A_C9bQL0cRdJ5F2ETlJl9GaZmukYVaq?usp=sharing

**Describe the expected behavior**
Tf 2.4.1 notebook:
https://colab.research.google.com/drive/1lRlGfQljmqAwOsP_npItl_aElCI9KPMD?usp=sharing"
46788,Win10: ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home 15063
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.4.1
- Python version: 3.8 (64-bit)
- Installed using virtualenv? pip? conda?: pip inside virtualenv
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: no cuda (Intel HD Graphics)
- GPU model and memory: Intel HD Graphics Integrated (Memory: N/A)

**Describe the problem**
It looks like i am unable to import tensorflow. this is my first time starting with tensorflow and i was trying this code:

```python
import tensorflow as tf

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist

x_train = tf.keras.utils.normalize(x_train, axis=1)
x_test = tf.keras.utils.normalize(x_test, axis=1)

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))

model.compile(optimizer=""adam"",
              loss=""sparse_categorical_crossentropy"",
              metrics=[""accuracy""])

model.fit(x_train, y_train, epochs=3)

model.save(""m\\mnist_model.model"")
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
venv\Scripts\activate.bat
pip install numpy tensorflow
python main.py
```


**Any other info / logs**
```
Traceback (most recent call last):
  File ""D:\Xcodz\tensorflowmachinelearning\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:/Xcodz/tensorflowmachinelearning/main.py"", line 1, in <module>
    import tensorflow as tf
  File ""D:\Xcodz\tensorflowmachinelearning\venv\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""D:\Xcodz\tensorflowmachinelearning\venv\lib\site-packages\tensorflow\python\__init__.py"", line 39, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""D:\Xcodz\tensorflowmachinelearning\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""D:\Xcodz\tensorflowmachinelearning\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```"
46787,"Add Torch (Flash light) ""Android""","Hi,
I wanna add Torch to this app. sometime light is not good  in area so I have to use flash light in app
But I can't use this code in app 
mCameraManager.setTorchMode(mCameraId, true);
The error is: camera ""0"" is in use
Or flash light just blink for a second
How can I use this feature in app?"
46786,C++ compilation of rule failed - Error tensorflow building from source,"
------------------------

### System information


-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
-   
-   **TensorFlow installed from (source or binary)**: wanting to install from source
-   **TensorFlow version (use command below)**: 2.3
-   **Python version**: 3.5
-   **Bazel version (if compiling from source)**: 3.1, when using bazel version in the console
-   **GCC/Compiler version (if compiling from source)**: 5.4.0
-   **CUDA/cuDNN version**: 10.1 and 7.6
-   **GPU model and memory**: Nvidia Geforce 740 
-   **Exact command to reproduce**:

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Im am trying to install tensorflow from source on a basically fresh installation of Ubuntu 16.04.

I installed CUDA and CuDNN and installed bazel successfully. I then i used:
```
git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
git checkout branch_name  r2.3
./configure

```


### Source code / logs
./configure generated following configuration:

```
You have bazel 3.1.0 installed.
Please specify the location of python. [Default is /usr/bin/python3]: 


Found possible Python library paths:
  /usr/lib/python3/dist-packages
  /usr/local/lib/python3.5/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: 
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: 
No TensorRT support will be enabled for TensorFlow.

Found CUDA 10.1 in:
    /usr/local/cuda-10.1/targets/x86_64-linux/lib
    /usr/local/cuda-10.1/targets/x86_64-linux/include
Found cuDNN 7 in:
    /usr/lib/x86_64-linux-gnu
    /usr/include


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as ""x.y"" or ""compute_xy"" to include both virtual and binary GPU code, or as ""sm_xy"" to only include the binary code.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.0]: 


WARNING: XLA does not support CUDA compute capabilities lower than 3.5. Disable XLA when running on older GPUs.
Do you want to use clang as CUDA compiler? [y/N]: 
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 


Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: 
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=ngraph      	# Build with Intel nGraph support.
	--config=numa        	# Build with NUMA support.
	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
	--config=v2          	# Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
	--config=noaws       	# Disable AWS S3 filesystem support.
	--config=nogcp       	# Disable GCP support.
	--config=nohdfs      	# Disable HDFS support.
	--config=nonccl      	# Disable NVIDIA NCCL support.
Configuration finished

```
And then i ran
 ```
bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
```
to build my tensorflow.


After waiting a while i get following error messages:

```
C++ compilation of rule '//tensorflow/core/kernels:scatter_functor_gpu' failed (Exit 1)
```

Anyone knows the source of this error and how to fix it or how i could successfully build tensorflow?
The most important aspect of the installation by source is the gpu support so cuda=y and the compute capability set to 3.0 as my gpu has that compute capability which is the reason i need to build from source in the first place



"
46785,Op with name (StatefulPartitionedCall/sequential/conv2d/BiasAdd) and type (Conv) kernel not found in CPUExecutionProvider,"I followed the practices described in to build onnxruntime for all 4 targets (in android) https://github.com/microsoft/onnxruntime/blob/master/docs/ONNX_Runtime_for_Mobile_Platforms.md

1. converted onnx to ort files with basic optimization via --optimization_level basic  & another ort files allowing onnx optimization in ort.

2. Tried Release build with 
./build.sh --config Release--android --android_sdk_path /Android --android_ndk_path /Android/ndk/21.1.6352462/ --android_abi x86 --android_api 29 --minimal_build extended --use_nnapi  --disable_exceptions --build_shared_lib --skip_tests --include_ops_by_config <config file produced by step 1>
(For all ABI types)
3. My config files contain 
`ai.onnx;9;MatMul,Sub`
`ai.onnx;12;Add,Conv,Gemm,MaxPool,Mul,Relu,Reshape,Softmax,Transpose`

I am running on Api 30 on x86 emulator but getting exception on both types of (ort: one with basioc optimization & one without optimization)
`exception of type Ort::Exception: Failed to find kernel for Conv(11) (node StatefulPartitionedCall/sequential/conv2d/BiasAdd). Op with name (StatefulPartitionedCall/sequential/conv2d/BiasAdd) and type (Conv) kernel not found in CPUExecutionProvider. No matching hash for 8328794455908578232""`
Is there kernel named ""BiasAdd"" ? 


"
46784,Enabling GPU support for Tensorflow in virtualenv,"I am attempting to setup `Tensorflow` with GPU support on virtualenv. 
I have a native version with system interpreter - `Tensorflow 2.4.1`, which works fine and does see the `GPU`. 
And  in virtualenv I use `Tensorflow 2.0.0` with Python 3.7.9. 

When running in the interpreter on the system with `Tensorflow 2.4.1` I receive following greeting message : 

`I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0`

And the command `tf.config.experimental.list_physical_devices(""GPU"")` shows my GPU. 
However perforing the same actions in virtualenv I do not receive this greeting message, and the output of the command above is an empty list. 

**System information**
- OS Platform and Distribution : (Linux Ubuntu 20.04):
- TensorFlow version: 2.0.0
- Python version: 3.7.9
- Installed using pip in virtualenv
- CUDA/cuDNN version: 11.0
- GPU model and memory: RTX 2080Ti

I've installed the `Tensorflow 2.0.0` via pip inside virtualenv. And the `CUDA` setup was performed as described here 
https://www.tensorflow.org/install/gpu?hl=ur with some changes for `Ubuntu 20.04`.

My question is : what needs to be done in order to enable GPU support inside virtualenv? 


"
46783,Micro: port op FAKE_QUANT from Lite,"@tensorflow/micro

**System information**
Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or binary): source
Tensorflow version (commit SHA if source): master
Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Sparkfun Edge

**Describe the problem**
I am about to port The TF Lite kernel op FAKE_QUANT to TFLite Micro.

**Please provide the exact sequence of commands/steps when you ran into the problem**
PR 1: refactor flatbuffer_conversions parsing function
PR 2: refactor reference implementation from lite/kernels/internal/reference/reference_ops.h into its own header with only the changes to pass internal CI build checks.
PR 3: copy the kernel from lite to micro any make the micro op and its testing code to work.
"
46782,"tf.keras.Model.fit() training works fine but custom training loop fails for identical model, optimizer, and loss function","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, Anaconda
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.4.0
- Python version: 3.8.0
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

v2.4.0-rc4-71-g582c8d236cb 2.4.0

**Describe the current behavior**
Code
`from tensorflow.python.eager import backprop
import tensorflow as tf
import numpy as np
import math

print(""TensorFlow version: {}"".format(tf.__version__))
print(""Eager execution: {}"".format(tf.executing_eagerly()))


#Equation to generate data
#y = x * 0.1
def calulate(x):
    return sum([i*0.1 for i in x])

#Generate samples in batch
def samples(size):
    x = np.random.random((size, 4))
    y = np.zeros((size))
    for i in range(size):
        y[i] = calulate(x[i])
    return x,y

#Model
model = tf.keras.Sequential([
  tf.keras.layers.Dense(1, input_shape=(4,))
])

#loss function and optimizer
loss = tf.keras.losses.MeanSquaredError(reduction=""auto"")
optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)

#Validation function
def validate():
    x = np.random.random((5, 4))
    y = [calulate(i) for i in x]
    e = model.predict(x)
    print(""{} ==> {} , {}"".format(x, y, e))

#Model.fit
def train_default(epoch) :
    x, y = samples(64000)
    model.compile(optimizer=optimizer, loss=loss)
    history = model.fit(x, y, epochs=epoch, validation_split = 0.2)


#Custom train
def train_custom(steps):
    x = []
    y = []
    for _ in range(2000):
        xe, ye = samples(32)
        x.append(xe)
        y.append(ye)

    for episod in range(steps):
        episod_loss = tf.keras.metrics.Mean()
        for i in range(2000):
            with tf.GradientTape() as tape:
                e = model(x[i], training=True)
                l = loss(y[i], e)
            grads = tape.gradient(l, model.trainable_weights)
            #optimizer.minimize(l, model.trainable_variables, tape=tape)
            optimizer.apply_gradients(zip(grads, model.trainable_weights))
            episod_loss.update_state(l)
        print(""episod: {} loss: {}"".format(episod, episod_loss.result()))
        print(model.trainable_weights)


#Tensorflow extension
loss_tracker = tf.keras.metrics.Mean(name=""loss"")
mae_metric = tf.keras.metrics.MeanAbsoluteError(name=""mae"")

class CustomModel(tf.keras.Model):
    def train_step(self, data):
        x, y = data

        with tf.GradientTape() as tape:
            y_pred = self(x, training=True)  # Forward pass
            l = loss(y, y_pred)

        #Compute gradients
        trainable_vars = self.trainable_variables
        gradients = tape.gradient(l, trainable_vars)

        #Update weights
        self.optimizer.apply_gradients(zip(gradients, trainable_vars))

        #Compute our own metrics
        loss_tracker.update_state(l)
        mae_metric.update_state(y, y_pred)
        return {""loss"": loss_tracker.result(), ""mae"": mae_metric.result()}

    @property
    def metrics(self):
        return [loss_tracker, mae_metric]

def train_extended(steps):
    #Construct an instance of CustomModel
    inputs = tf.keras.Input(shape=(4,))
    outputs = tf.keras.layers.Dense(1)(inputs)
    model = CustomModel(inputs, outputs)

    #We don't passs a loss or metrics here.
    model.compile(optimizer=optimizer)

    x = []
    y = []
    for _ in range(2000):
        xe, ye = samples(32)
        x.append(xe)
        y.append(ye)

    for episod in range(steps):
        for i in range(2000):
            model.fit(x[i], y[i], epochs=1, verbose= 0)
        print(""episod: {}"".format(episod))
        print(model.trainable_variables)


##Works
#train_default(5)
#validate()

#Works
#train_extended(5)
#validate()

#Don't work
train_custom(5)
validate()`
**Describe the expected behavior**
train_custom function should also works like other 
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46781,cudnn 8.1.0 support ( + Bazel 4.0.0 ),"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: master 2.5.0
- Python version: 3.9.1
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): Visual Studio 2019
- CUDA/cuDNN version: 11.2/8.1.0
- GPU model and memory: RTX3090 GDDR6 24GB



**Describe the problem**
build failed
**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel build

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
ERROR: D:/repo/tensorflow/tensorflow/compiler/xla/service/cpu/BUILD:496:11: C++ compilation of rule '//tensorflow/compiler/xla/service/cpu:dot_op_emitter' failed (Exit 2): python.exe failed: error executing command
```

```
cl : Command line warning D9035 : option 'experimental:preprocessor' has been deprecated and will be removed in a future release
cl : Command line warning D9036 : use 'Zc:preprocessor' instead of 'experimental:preprocessor'
C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\utility(246): warning C4244: 'initializing': conversion from '_Ty' to '_Ty1', possible loss of data
        with
        [
            _Ty=uint64_t
        ]
        and
        [
            _Ty1=unsigned int
        ]
external/llvm-project/llvm/include\llvm/ADT/SmallBitVector.h(725): note: see reference to function template instantiation 'std::pair<unsigned int,llvm::ArrayRef<uint64_t>>::pair<unsigned __int64,llvm::ArrayRef<uint64_t>,0>(std::pair<unsigned __int64,llvm::ArrayRef<uint64_t>> &&) noexcept' being compiled
external/llvm-project/llvm/include\llvm/ADT/SmallBitVector.h(724): note: see reference to function template instantiation 'std::pair<unsigned int,llvm::ArrayRef<uint64_t>>::pair<unsigned __int64,llvm::ArrayRef<uint64_t>,0>(std::pair<unsigned __int64,llvm::ArrayRef<uint64_t>> &&) noexcept' being compiled
external/llvm-project/mlir/include\mlir/Dialect/Linalg/Transforms/CodegenStrategy.h(74): error C2668: 'mlir::linalg::sfinae_enqueue': ambiguous call to overloaded function
external/llvm-project/mlir/include\mlir/Dialect/Linalg/Transforms/CodegenStrategy.h(51): note: could be 'void mlir::linalg::sfinae_enqueue<mlir::linalg::LinalgTilingPattern,LinalgOpType,mlir::linalg::LinalgTilingOptions>(mlir::OwningRewritePatternList &,OptionsType,mlir::MLIRContext *,llvm::StringRef,mlir::linalg::LinalgTransformationFilter)'
        with
        [
            LinalgOpType=mlir::linalg::GenericOp,
            OptionsType=mlir::linalg::LinalgTilingOptions
        ]
external/llvm-project/mlir/include\mlir/Dialect/Linalg/Transforms/CodegenStrategy.h(38): note: or       'void mlir::linalg::sfinae_enqueue<mlir::linalg::LinalgTilingPattern,LinalgOpType,mlir::linalg::LinalgTilingOptions,std::enable_if<false,void>>(mlir::OwningRewritePatternList &,OptionsType,mlir::MLIRContext *,llvm::StringRef,mlir::linalg::LinalgTransformationFilter)'
        with
        [
            LinalgOpType=mlir::linalg::GenericOp,
            OptionsType=mlir::linalg::LinalgTilingOptions
        ]
external/llvm-project/mlir/include\mlir/Dialect/Linalg/Transforms/CodegenStrategy.h(75): note: while trying to match the argument list '(mlir::OwningRewritePatternList, mlir::linalg::LinalgTilingOptions, mlir::MLIRContext *, std::string, mlir::linalg::LinalgTransformationFilter)'
external/llvm-project/mlir/include\mlir/Dialect/Linalg/Transforms/CodegenStrategy.h(72): note: while compiling class template member function 'mlir::OwningRewritePatternList mlir::linalg::Tile<LinalgOpType>::buildRewritePatterns(mlir::MLIRContext *,mlir::linalg::LinalgTransformationFilter)'
        with
        [
            LinalgOpType=mlir::linalg::GenericOp
        ]
C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\memory(2536): note: see reference to class template instantiation 'mlir::linalg::Tile<LinalgOpType>' being compiled
        with
        [
            LinalgOpType=mlir::linalg::GenericOp
        ]
C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\memory(2535): note: while compiling class template member function 'void std::default_delete<mlir::linalg::Tile<LinalgOpType>>::operator ()(_Ty *) noexcept const'
        with
        [
            LinalgOpType=mlir::linalg::GenericOp,
            _Ty=mlir::linalg::Tile<mlir::linalg::GenericOp>
        ]
C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\memory(2647): note: see reference to function template instantiation 'void std::default_delete<mlir::linalg::Tile<LinalgOpType>>::operator ()(_Ty *) noexcept const' being compiled
        with
        [
            LinalgOpType=mlir::linalg::GenericOp,
            _Ty=mlir::linalg::Tile<mlir::linalg::GenericOp>
        ]
C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\memory(2574): note: see reference to class template instantiation 'std::default_delete<mlir::linalg::Tile<LinalgOpType>>' being compiled
        with
        [
            LinalgOpType=mlir::linalg::GenericOp
        ]
external/llvm-project/mlir/include\mlir/Dialect/Linalg/Transforms/CodegenStrategy.h(160): note: see reference to class template instantiation 'std::unique_ptr<mlir::linalg::Tile<LinalgOpType>,std::default_delete<mlir::linalg::Tile<LinalgOpType>>>' being compiled
        with
        [
            LinalgOpType=mlir::linalg::GenericOp
        ]
tensorflow/compiler/xla/service/cpu/dot_op_emitter.cc(325): note: see reference to function template instantiation 'mlir::linalg::CodegenStrategy &mlir::linalg::CodegenStrategy::tile<mlir::linalg::GenericOp>(mlir::linalg::LinalgTilingOptions,mlir::linalg::LinalgTransformationFilter::FilterFunction)' being compiled
```"
46780,TFLite Converter Version  InCompatibility Issue,"

### 2. Code

Please find this [notebook](https://colab.research.google.com/drive/1slj7OwIZ8M567BDUyNLUI7w-Eag7b55R?usp=sharing)

### 3. Failure after conversion

Model conversion working with `tensorflow-2.3.0` and `tf-nightly` versions and not working with `tensorflow=2.4`(default colab version). Similary model inference is working only with `tensorflow-2.3.0` and not working with both `tensorflow-2.4` and `tf-nightly`

CC: @abattery @khanhlvg "
46777,"Deprecation warnings Model.state_updates when calling keras model `predict` after `get_weights`, in static execution","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): No
- TensorFlow version (use command below): 2.4.1
- Python version: 3.6.12
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**

Similar to #44178 I am seeing the following deprecation warning:

```
/path/to/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  warnings.warn('`Model.state_updates` will be removed in a future version. '
```

That is happening only in static execution (not eager mode). And it seems only when calling `get_weights` before calling `predict`.

**Describe the expected behavior**

No warning.

**Standalone code to reproduce the issue**

```python
import numpy as np
import tensorflow as tf
from tensorflow.python.framework.ops import disable_eager_execution


def build_model():
    model = tf.keras.models.Sequential([
        tf.keras.layers.Dense(1, input_shape=(1,)),
        tf.keras.layers.Dense(10),
        tf.keras.layers.Dense(1)
    ])
    model.compile(optimizer='sgd', loss='mse')
    return model


def do_test():
    x = np.asarray([[0], [1]])
    y = x
    model = build_model()
    model.fit(x=x, y=y, epochs=1000, verbose=0)
    model.get_weights()
    result = model.predict(x=x)
    print('result:', result)
    print('result close?:', np.allclose(result, y, atol=0.01))


def test_with_graph_static_execution():
    with tf.Graph().as_default():  # pylint: disable=not-context-manager
        do_test()


def test_without_explicit_graph_using_static_execution():
    disable_eager_execution()
    do_test()


def test_without_graph_eager_execution():
    do_test()


test_with_graph_static_execution()
# test_without_explicit_graph_using_static_execution()
# test_without_graph_eager_execution()
```

In the above example code, you may comment / uncomment to call the desired test function. Out of the three, `test_without_graph_eager_execution` is not showing the warning, `test_with_graph_static_execution` and `test_without_explicit_graph_using_static_execution` are.

The specific model doesn't seem to be relevant, neither whether it was first fit.

Removing the call to `get_weights` will also avoid the warning (but the warning only appears when then calling `predict`).
(Of course, in the real use case the weights will be used)

The main motivation for using the static execution is to improve performance.

**Other info / logs**

<details>
<summary>traceback</summary>

```
  File ""/path/to/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_v1.py"", line 991, in predict
    use_multiprocessing=use_multiprocessing)
  File ""/path/to/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py"", line 712, in predict
    callbacks=callbacks)
  File ""/path/to/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py"", line 185, in model_iteration
    f = _make_execution_function(model, mode)
  File ""/path/to/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py"", line 555, in _make_execution_function
    return model._make_execution_function(mode)
  File ""/path/to/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_v1.py"", line 2084, in _make_execution_function
    self._make_predict_function()
  File ""/path/to/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_v1.py"", line 2072, in _make_predict_function
    updates=self.state_updates,
  File ""/path/to/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 2325, in state_updates
    warnings.warn('`Model.state_updates` will be removed in a future version. '
```
</details>"
46776,flattening operation using tf.reshape inside @tf.function graph raises ValueError,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `No`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Windows 10 19042.746`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): `binary`
- TensorFlow version (use command below): `2.4.1`
- Python version: `3.8.5`
- CUDA/cuDNN version: `11.0/8.0`
- GPU model and memory: `2x RTX2080 12GB`

**Describe the current behavior**
Calling function wrapped with @tf.function and reshaping operation properly reshapes tensor with value `-1` for flattening raises `ValueError`

**Describe the expected behavior**
Calling function wrapped with @tf.function and reshaping operation properly reshapes tensor with value `-1` for flattening converts tensor into `1D` shape

**Standalone code to reproduce the issue**
```python
@tf.function
def tf_function_wrapped_function():
  reshaped = tf.reshape(tf.ones((64, 64)), -1)
```

**Full TraceBack**

```python
Traceback (most recent call last):
  File "".\tests\test_tf_dark_com_preds.py"", line 36, in <module>
    test_tf_reshape()
  File "".\tests\test_tf_dark_com_preds.py"", line 32, in test_get_com_preds
    assert test_tf_reshape()
  File ""C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\eager\def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\eager\def_function.py"", line 871, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\eager\def_function.py"", line 725, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File ""C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\eager\function.py"", line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File ""C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\eager\function.py"", line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\eager\function.py"", line 3196, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\eager\def_function.py"", line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:
    .\tests\test_tf_reshape.py:27 tf_function_wrapped_function  *
        reshaped = tf.reshape(tf.ones((64, 64)), -1)
    C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\util\dispatch.py:201 wrapper  **
        return target(*args, **kwargs)
    C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\ops\array_ops.py:195 reshape
        result = gen_array_ops.reshape(tensor, shape, name)
    C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\ops\gen_array_ops.py:8376 reshape
        _, _, _op, _outputs = _op_def_library._apply_op_helper(
    C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\framework\op_def_library.py:748 _apply_op_helper
        op = g._create_op_internal(op_type_name, inputs, dtypes=None,
    C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\framework\func_graph.py:590 _create_op_internal
        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access
    C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\framework\ops.py:3528 _create_op_internal
        ret = Operation(
    C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\framework\ops.py:2015 __init__
        self._c_op = _create_c_op(self._graph, node_def, inputs,
    C:\Users\iam\.conda\envs\alyce\lib\site-packages\tensorflow\python\framework\ops.py:1856 _create_c_op
        raise ValueError(str(e))

    ValueError: Shape must be rank 1 but is rank 0 for '{{node Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](ones, Reshape/shape)' with input shapes: [64,64], [].
```
**Findings**

1. This example raises `ValueError`
```python
@tf.function
def tf_function_wrapped_function():
  reshaped = tf.reshape(tf.ones((64, 64)), 64*64)
```

2. This example do not raise any error
```python
@tf.function
def tf_function_wrapped_function():
  reshaped = tf.reshape(tf.ones((64, 64)), [1, 64*64])
```

3. This example raises `ValueError`
```python
@tf.function
def tf_function_wrapped_function():
  reshaped = tf.reshape(tf.ones((64, 64, 64)), 64*64)
```

4. This example do not raise any error
 ```python
def tf_function_wrapped_function():
  reshaped = tf.reshape(tf.ones((64, 64)), -1)
```

5. This is an alternative way that I passed this ValueError
 ```python
@tf.function
def tf_function_wrapped_function():
  reshaped = tf.reshape(tf.ones((64, 64)), (1, 64*64))[0]
```
"
46775,hexagon,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
46773,Time series tutorial throws error when selecting multiple columns,"**Tensorflow version is 2.4.0**.

## URL(s) with the issue:
https://www.tensorflow.org/tutorials/structured_data/time_series

Issue is also listed as a [StackOverflow question](https://stackoverflow.com/questions/65944671/how-to-select-multiple-label-columns-for-the-tensorflow-time-series-tutorial).


## Description of issue (what needs changing):
The current time series tutorial only works when specifying one label, or leaving `label_columns=None` which defaults to all columns as labels. When selecting multiple columns in the WindowGenerator, such as:
```python
OUT_STEPS = 24
multi_window = WindowGenerator(input_width=24,
                               label_width=OUT_STEPS,
                               shift=OUT_STEPS,label_columns=['T (degC)','p (mbar)'])
```

the tutorial throws the error:
```
ValueError: Dimensions must be equal, but are 19 and 2 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](feed_back/transpose, IteratorGetNext:1)' with input shapes: [?,24,19], [?,24,2].
```
### Clear description

As someone who is new to the framework, it is not clear how to adapt the tutorial to address an arbitrary subset of columns as labels, given the error provided."
46772,Using MaxPooling1D with 4D and higher Tensors,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.3.1
- Are you willing to contribute it (Yes/No): Not sure?

**Describe the feature and the current behavior/state.**

Currently, MaxPooling1D layer only takes 3D tensor as input, and data_format argument specifies if features are first or last.
If tensor is 4D, an error gets thrown. However, the same API can be used to handle higher-dimensional data, e. 4D tensors, and there are use-cases for that. For example, when trying to implement multiple instance learning, data is organized in bags of instances, and for time series would become 4D.

```
n = 6
sample_size = 300
code_size = 50
learning_rate = 0.001
n_bags= None

# autoencoder: n_bags X n_instances_in_bag X n_samples (timesteps) X n_measurements
input_window = Input(shape=(n_bags,sample_size, n)) 
x = Conv1D(filters=40, kernel_size=21, activation='relu', padding='valid')(input_window)
x = MaxPooling1D(pool_size=2)(x)
```

Currently, this throws an error:
```
ValueError: Input 0 of layer max_pooling1d_4 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, None, 280, 40]
```

but there is no reason why this can't work. Note that Conv1D layer works just fine with this.

**Will this change the current api? How?**
I believe the API can remain the same


"
46770,Inconsistency of computations with different batch size,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.9
- CUDA/cuDNN version: 10.1
- GPU model and memory: Tesla K80 11441MiB

**Describe the current behavior**

Computations with batch size 2 or two consecutive computations with batch size 1 lead to different results if the number of units is bigger than 64 (for tf.keras.layers.Dense) or the last dimension is equal to 1 (tf.matmul).


**Describe the expected behavior**
Results supposed to be same. 


**Standalone code to reproduce the issue**
```python
linear = tf.keras.layers.Dense(units=65)
data = 50*tf.ones(shape=[2, 93, 3286])
r = linear(data)
r_0 = linear(data[:1])
r_1 = linear(data[1:])
print(tf.reduce_max(tf.abs(r[:1]-r_0)/tf.abs(r[:1])), tf.reduce_max(tf.abs(r[:1]-r_0)))
print(tf.reduce_max(tf.abs(r[1:]-r_1)/tf.abs(r[1:])), tf.reduce_max(tf.abs(r[1:]-r_1)))
```

```python
data_1 = 1.22222*tf.random.normal(shape=(2, 20, 10, 1))
data_2 = 0.37*tf.random.normal(shape=(2, 20, 10, 52))
r = tf.matmul(data_1, data_2, transpose_a=True)
r_0 = tf.matmul(data_1[:1], data_2[:1], transpose_a=True)
r_1 = tf.matmul(data_1[1:], data_2[1:], transpose_a=True)
print(tf.reduce_max(tf.abs(r[:1]-r_0)/tf.abs(r[:1])), tf.reduce_max(tf.abs(r[:1]-r_0)))
print(tf.reduce_max(tf.abs(r[1:]-r_1)/tf.abs(r[1:])), tf.reduce_max(tf.abs(r[1:]-r_1)))
```
"
46769,PoseNet model readme points to the wrong paper reference,"## URL(s) with the issue:

Please provide a link to the documentation entry, for example:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/models/pose_estimation/overview.md
or
https://www.tensorflow.org/lite/models/pose_estimation/overview

## Description of issue (what needs changing):
In Further Reading the reference is pointing to the wrong PoseNet paper. It points to
https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Kendall_PoseNet_A_Convolutional_ICCV_2015_paper.pdf
which is also called PoseNet but it is about camera relocalization, not body pose detection.

### Correct links

According to this blog post
https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5
I think the correct papers are here:
https://arxiv.org/abs/1701.01779
and
https://arxiv.org/abs/1803.08225

"
46766,C API to efficiently share weights and access tensor data during inferencing,"**System information**
- TensorFlow version (you are using): 2.3
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
I believe the existing Session API is thread safe so that multiple inferences can be run simultaneously for the same model. It is not clear if doing so also shares the model weights (which are constants during inferencing) so that only a single copy of the weights is required.

The tensor input and output C APIs should have options to use input tensors in-place, from binary blobs, from either CPU/system memory or device (e.g. GPU) memory. This ""zero-copy"" API would remove any copy overhead and any overhead related to protobuf creation.

**Will this change the current api? How?**
Yes, likely need new C API.

**Who will benefit with this feature?**
Inference applications that need to integrate with TF library and get maximum performance."
46765,numpy() is not working on Tensor object in TF2.x,"**Please consider the following code snippet**

from tensorflow.keras.layers import Layer

class SimpleDense(Layer):
    
    def __init__(self, units=32):
        '''Initializes the instance attributes'''
        super(SimpleDense, self).__init__()
        self.units = units

    def build(self, input_shape):
        '''Create the state of the layer (weights)'''
        # initialize the weights
        w_init = tf.random_normal_initializer()
        self.w = tf.Variable(name=""kernel"",
            initial_value=w_init(shape=(input_shape[-1], self.units),
                                 dtype='float32'),
            trainable=True)

        # initialize the biases
        b_init = tf.zeros_initializer()
        self.b = tf.Variable(name=""bias"",
            initial_value=b_init(shape=(self.units,), dtype='float32'),
            trainable=True)

    def call(self, inputs):
        '''Defines the computation from inputs to outputs'''
        print(inputs.numpy().shape)
        print(self.w.numpy().shape)
        print(tf.matmul(inputs,self.w).numpy().shape)
        print(self.b.numpy().shape)
        print((tf.matmul(inputs,self.w)+self.b).numpy().shape)
        return tf.matmul(inputs, self.w) + self.b

my_dense = SimpleDense(units=1)
x = tf.ones((3, 2))
y = my_dense(x)   # I am able to execute all the print of the call method.

xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)
ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)

my_layer = SimpleDense(units=1)
model = tf.keras.Sequential([my_layer])
model.compile(optimizer='sgd', loss='mean_squared_error')
model.fit(xs, ys, epochs=500,verbose=0)  # I am not able to execute any of the print of the call method.

- There error is following.
AttributeError: in converted code:
        print(inputs.numpy().shape)

    AttributeError: 'Tensor' object has no attribute 'numpy'

_**I am not able to understand the above error as per my knowledge Tensor object has numpy() attribute available in tf2.x version and I am using TF2.0**_

Please Explain why i am getting the above error. It will be very helpful.

"
46764,Add placement API for C interface - control subset of devices to make visible for model,"**System information**
- TensorFlow version: 2.3
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
During inference it may be necessary to control how a model is loaded onto the available devices (e.g. GPUs). Two cases that illustrate this are:
- The model is created with explicit device assignments that use more/different devices then are available at inference time. The inference application should be able to query which devices are required by the model and somehow map those devices onto the set of devices that are currently available.
- The model is created without explicit device assignments but the inference application wants to control which device the model should load onto (instead of loading onto the default, ""0"" device).

The existing GPU options has a visible_device_list setting that seems like it could provide at least part of a solution. Unfortunately, it seems all/most of the GPU options are actually global and not per-session / per-model and so visible_device_list is not actually a solution. This is discussed in #311 and #8136 (the second issue is closed but the underlying issue is not resolved).

**Will this change the current api? How?**
It seems likely.

**Who will benefit with this feature?**
Any application that wants to control how a model is loaded, such as inference applications and servers.
"
46763,Performance and functional parity of C and Python API for the graph mode,"**System information**
- TF 2.3
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
Currently the TF C/C++ API is incomplete (e.g. does not have API to save savedmodel, does not expose all optimization and configuration options) compared to the Python API. It also seems that the Python API enables or performs additional optimization passes that are not available when using the C/C++ API.

**Will this change the current api? How?**
Yes. The C/C++ API will likely need to be enhanced significantly. Ideally this complete functionality will be implemented in a C API to ensure maximum ABI compatibility and portability.

**Who will benefit with this feature?**
Applications that want a more portable, high-performance solution that does not require using python. We are particularly interested in applications like model servers. A C API would be the most portable and performant and is relatively easy to integrate and wrap into other languages. Conceptually the python API (and any other language binding) should be a wrapper over the C API that presents the API in a language appropriate way but that does otherwise add (or remove) functionality.
"
46762,MHA not attending the specified dimension,"Hi, it looks like if I add a channel dimension, the number of parameters in the Dense layer is no longer correct:
This is ok:

inputs = Input(shape=[1800])
y = MultiHeadAttention(num_heads=10,
key_dim=10,
use_bias=False,
attention_axes = 0,
)(inputs,inputs)
model = Model(inputs=inputs, outputs=y)
print(model.summary())  # This shows that we have 720,000  parameters
This is not:

inputs = Input(shape=[1800,1]). # added channel dim here
y = MultiHeadAttention(num_heads=10,
key_dim=10,
use_bias=False,
attention_axes = 0,  #if this is set to None the same error persists
)(inputs,inputs)
model = Model(inputs=inputs, outputs=y)
print(model.summary()) # this is not correct, it shows 400 parameters, although I specify to attend the first axis"
46760,Multiheadattention layer dimensions,"## This works ok
inputs = Input(shape=[1800])
y = MultiHeadAttention(num_heads=10,
key_dim=10,
use_bias=False,
attention_axes = 0,
)(inputs,inputs)
model = Model(inputs=inputs, outputs=y)
print(model.summary())

## This is not working properly:

inputs = Input(shape=[1800,1]). # added channel dim here
y = MultiHeadAttention(num_heads=10,
key_dim=10,
use_bias=False,
attention_axes = 0,
)(inputs,inputs)
model = Model(inputs=inputs, outputs=y)
print(model.summary())"
46759,How to install Tensorflow on AIX7.2 server,"I am trying to install Tensorflow on AIX7.2 server.  Usually, the ""any"" wheel file is good on AIX.  Otherwise, I may try to build it with tar.zip source file.  However,  Tensorflow has neither ""any"" wheel file nor tar.zip source file at PYPI website.  I tried to download tensorflow-master.zip file here, but the installation try failed as there is no setup.py file.  Is there any chance I can install Tensorflow on AIX?

Thanks.  "
46757,tf.linalg.triangular_solve adjoint option description is wrong,"Link:
https://www.tensorflow.org/api_docs/python/tf/linalg/triangular_solve

The following description about ""adjoint"" looks the other way around to me:
""If adjoint is True then the innermost matrices in output satisfy matrix equations sum_k matrix[..., i, k] * output[..., k, j] = rhs[..., i, j]. If adjoint is False then the innermost matrices in output satisfy matrix equations sum_k adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]."""
46756,"""minlength"" attribute for tf.math.bincount not honored during run_eagerly=False","-Microsoft Windows 10 version 10.0.18363 Build 18363
-pip install tensorflow
-TensorFlow v2.4.0-49-g85c8b2a817f 2.4.1
-Python 3.7.6

I am doing a Monte Carlo simulation inside my custom metric to determine the probabilities over 10k samples. I have used the minlength and maxlength attributes of the `tf.math.bincount` such that the size of the tensor `result` should be same as tensor `mus`
Upon using `tf.math.bincount` in a custom metric like below,

```
    distr = tfp.distributions.Normal(loc=mus, scale=sigmas)
    samples_min = tf.math.argmin(distr.sample((10000,)), axis=1)
    result = tf.math.bincount(tf.cast(tf.reshape(samples_min, (10000,)), dtype=tf.int32), minlength=mus.shape[0], maxlength=mus.shape[0], dtype=tf.float32) / tf.constant(10000, dtype=tf.float32)

    filter1 = tf.where(tf.squeeze(y_public_estimate) < result, tf.ones_like(result), tf.zeros_like(result))

```
Now if I run the above code with `model.compile(run_eagerly=False...` it throws below error,  and so I tried to debug the issue with `model.compile(run_eagerly=True...` and it doesn't produce any error ever. 

I suspect the `InvalidArgumentError` is generated in the less-than operation between ` tf.squeeze(y_public_estimate)` and `result `  where their shapes are mismatched, but it only happens when `run_eagerly=False` not when `run_eagerly=True` and btw the length of the tensor `y_public_estimate` is same as tensor `mus`, so I am thinking, maybe the `minlength` or `maxlength` attribute in `tf.math.bincount` does not seem to work with `run_eagerly=False`

```
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-99-3eba1530fe17> in <module>
     10 
     11 model = build_model(continuous, categoricals_map)
---> 12 history = model.fit(train_generator, validation_data=valid_generator, epochs=900, callbacks=[terminate_onnan, check_pointer, early_stop], verbose=1, workers=NUM_CORES)

e:\Miniconda3\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1098                 _r=1):
   1099               callbacks.on_train_batch_begin(step)
-> 1100               tmp_logs = self.train_function(iterator)
   1101               if data_handler.should_sync:
   1102                 context.async_wait()

e:\Miniconda3\lib\site-packages\tensorflow\python\eager\def_function.py in __call__(self, *args, **kwds)
    826     tracing_count = self.experimental_get_tracing_count()
    827     with trace.Trace(self._name) as tm:
--> 828       result = self._call(*args, **kwds)
    829       compiler = ""xla"" if self._experimental_compile else ""nonXla""
    830       new_tracing_count = self.experimental_get_tracing_count()

e:\Miniconda3\lib\site-packages\tensorflow\python\eager\def_function.py in _call(self, *args, **kwds)
    853       # In this case we have created variables on the first call, so we run the
    854       # defunned version which is guaranteed to never create variables.
--> 855       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
    856     elif self._stateful_fn is not None:
    857       # Release the lock early so that multiple threads can perform the call

e:\Miniconda3\lib\site-packages\tensorflow\python\eager\function.py in __call__(self, *args, **kwargs)
   2941        filtered_flat_args) = self._maybe_define_function(args, kwargs)
   2942     return graph_function._call_flat(
-> 2943         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
   2944 
   2945   @property

e:\Miniconda3\lib\site-packages\tensorflow\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1917       # No tape is watching; skip to running the function.
   1918       return self._build_call_outputs(self._inference_function.call(
-> 1919           ctx, args, cancellation_manager=cancellation_manager))
   1920     forward_backward = self._select_forward_and_backward_functions(
   1921         args,

e:\Miniconda3\lib\site-packages\tensorflow\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    558               inputs=args,
    559               attrs=attrs,
--> 560               ctx=ctx)
    561         else:
    562           outputs = execute.execute_with_cancellation(

e:\Miniconda3\lib\site-packages\tensorflow\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

InvalidArgumentError:  Incompatible shapes: [18] vs. [17]
	 [[node Less (defined at <ipython-input-95-93a59f364a63>:39) ]] [Op:__inference_train_function_130872]

Errors may have originated from an input operation.
Input Source operations connected to node Less:
 truediv (defined at <ipython-input-95-93a59f364a63>:37)

Function call stack:
train_function
```

"
46755,An error when loading quantized model ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source): tf-nightly 2.5.0.dev20210112


**Provide the text output from tflite_convert**

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-4-774313fb0438> in <module>()
    156     else:
    157         with quantize_scope:
--> 158             loaded_model = tf.keras.models.load_model('q_aware_model_fine_tuned.h5')
    159         inputs = [tf.keras.layers.Input(shape=(height, width, 1), name=""input_{}"".format(i)) for i in range(4)]
    160         q_aware_model = tf.keras.models.Model(inputs, loaded_model(inputs))

2 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py in load_weights_from_hdf5_group(f, layers)
    706     symbolic_weights = _legacy_weights(layer)
    707     weight_values = preprocess_weights_for_loading(
--> 708         layer, weight_values, original_keras_version, original_backend)
    709     if len(weight_values) != len(symbolic_weights):
    710       raise ValueError('Layer #' + str(k) + ' (named ""' + layer.name +

ValueError: Layer #9 (named ""quant_activation"" in the current model) was found to correspond to layer quant_activation in the save file. However the new layer quant_activation expects 3 weights, but the saved weights have 1 elements.
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/181562QquolAr3Yz5eKflZMH0zLKrzpSF?usp=sharing

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
46754,error: 'tfl.max_pool_2d' op quantization parameters violate the same scale constraint,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): tf-nightly 2.5.0.dev20210112

### 2. Code

https://colab.research.google.com/drive/18SeujsYiwNr3bwpamGBnQ09EG8ord7I2#scrollTo=BOs2yEVkHRmx

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results and/or has lesser accuracy.
- Model produces correct results, but it is slower than expected.

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    216                                                  debug_info_str,
--> 217                                                  enable_mlir_converter)
    218       return model_str

5 frames
Exception: /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206:0: error: 'tfl.max_pool_2d' op quantization parameters violate the same scale constraint: !quant.uniform<i8:f32, 0.04703366522695504:-1> vs. !quant.uniform<i8:f32, 0.047032601225609871:-1>
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/pooling.py:300:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize_wrapper.py:167:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:625:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1032:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:563:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:428:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1032:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/tflite_keras_util.py:184:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:612:0: note: called from


During handling of the above exception, another exception occurred:

ConverterError                            Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    218       return model_str
    219     except Exception as e:
--> 220       raise ConverterError(str(e))
    221 
    222   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:

ConverterError: /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206:0: error: 'tfl.max_pool_2d' op quantization parameters violate the same scale constraint: !quant.uniform<i8:f32, 0.04703366522695504:-1> vs. !quant.uniform<i8:f32, 0.047032601225609871:-1>
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/pooling.py:300:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize_wrapper.py:167:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:625:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1032:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:563:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:428:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1032:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/tflite_keras_util.py:184:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:612:0: note: called from"
46753,Recommend replacement list for some incompatible ops in TFLite,"Hi TensorFlow Lite Authors,  

It's glad to hear that there are some workaround for incompatible ops, such as ResizeOp, in TFLite. Would you mind share something like recommend replacement list for some of these bad ops? It will take us away from some troubles on early stage, the design stage, not the model deployment stage that things all are embarrassed to developers.

Looking for your reply,
Sun Aries."
46750,Implementation of Ordinary Differential Equations,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): The nightly build
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.** 
We don't have a solution in Tensorflow for UNEVEN time series data. There are implementations using Torch for ODE (Ordinary Differential Equations) RNN.

**Will this change the current api? How?**
Not sure

**Who will benefit with this feature?**
I will be.... but this is a huge gap in Tensorflow right now. There are lots of data that are generated with uneven gap between them. Tensorflow does not have a viable solution right now.

**Any Other info.**
https://www.sciencedirect.com/science/article/abs/pii/S095219762030292X
https://towardsdatascience.com/paper-summary-neural-ordinary-differential-equations-37c4e52df128

I don't know, there are many papers on them."
46745,Loading and stitching TF graphs has tf.Variable conflict even if using the name scope in loading,"**System information**
- OS Platform and Distribution: MacOS Catalina 10.15.6
- TensorFlow installed: from binary
- TensorFlow version: The issue could be reproduced by TF1.x (TF 1.15.2) and TF2.x (TF 2.4.1)
- Python version: 3.6.5

**Describe the current behavior**
I have the following code `tf_stitch_keras_model_build_save.py` that simply creates a TF Keras model and saves it into a checkpoint. I ran the Python script twice and generated two checkpoints `./foo/model` with input shape 4 and output shape 3 (by running `$ python tf_stitch_keras_save.py -i 4 -o 3 -p ./foo/model`) and `./bar/model` with input shape 3 and output shape 2 (by running `$ python tf_stitch_keras_save.py -i 3 -o 2 -p ./bar/model`). Then I ran another Python script `python tf_stitch_keras_restore.py -p1 ./foo/model -p2 ./bar/model` that is supposed to load these two checkpoints into a new TF graph with model foo's output stitching to model bar's input.

- tf_stitch_keras_model_build_save.py:
```
import argparse
from typing import Tuple

import numpy as np
import tensorflow.compat.v1 as tf
from tensorflow.keras import models
from tensorflow.keras import layers

tf.disable_v2_behavior()


def build_model(input_shape: int, output_shape: int) -> Tuple[tf.Tensor, tf.Tensor]:
    graph = tf.get_default_graph()
    with graph.as_default():
        model = models.Sequential()
        model.add(layers.Dense(16, activation='relu', input_shape=(input_shape,), name=""layer_0""))
        model.add(layers.Dense(16, activation='relu', name=""layer_1""))
        model.add(layers.Dense(output_shape, activation='sigmoid', name=""layer_2""))

        input_tensor = tf.placeholder(dtype=tf.float32, shape=[None, input_shape])
        output_tensor = model(input_tensor)
        graph.add_to_collection(""INPUT"", input_tensor)
        graph.add_to_collection(""OUTPUT"", output_tensor)
    return input_tensor, output_tensor


def save_model(sess: tf.Session, path: str) -> None:
    saver = tf.train.Saver()
    sess.run(tf.global_variables_initializer())
    save_path = saver.save(sess, path)
    print(f""Saved the model in {save_path}"")


def parse_arguments() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser()
    parser.add_argument(""-i"", ""--input_shape"", type=int)
    parser.add_argument(""-o"", ""--output_shape"", type=int)
    parser.add_argument(""-p"", ""--path"", type=str)
    return parser


def main():
    parser = parse_arguments()
    args = parser.parse_args()
    input_tensor, output_tensor = build_model(args.input_shape, args.output_shape)
    print(f""Finished building the model: Input tensor {input_tensor} and output tensor {output_tensor}."")
    sess = tf.Session()
    sess.run(tf.global_variables_initializer())
    res = sess.run(output_tensor, feed_dict={input_tensor: np.random.rand(1, args.input_shape)})
    print(f""The random output is {res}."")
    save_model(sess, args.path)


main()
```
-  tf_stitch_keras_restore.py:
```
import argparse
from typing import Dict, List

import tensorflow.compat.v1 as tf


def load_and_stitch_graph(
    path: str,
    sess: tf.Session,
    input_map: Dict[str, tf.Tensor],
    return_values: List[str],
    scope: str = """",
) -> List[tf.Tensor]:
    """"""
    :param path: The path of the model to be loaded from.
    :param sess: The tensorflow session for loading a model.
    :param input_map: dict key is the tag name of the tensor for another Tensor as
           dict value stitches to.
    :param return_values: The tag name for the returned tensors.
    :param scope: The name used for loading a model.
    :return:
    """"""
    # Load the checkpoint in the tmp graph.
    tmp_graph = tf.Graph()
    with tmp_graph.as_default():
        saver = tf.train.import_meta_graph(path + "".meta"", import_scope=scope)

    # Structure the input map for stitching the graph when loading.
    input_map_for_import_graph_def = {
        tmp_graph.get_collection(key)[0].name: val
        for key, val in input_map.items()
    }
    return_values_for_import_graph_def: List[tf.Tensor] = [
        tmp_graph.get_collection(val)[0].name
        for val in return_values
    ]

    # Load and stitch.
    with sess.graph.as_default():
        return_tensors = tf.import_graph_def(
            tmp_graph.as_graph_def(),
            input_map=input_map_for_import_graph_def,
            name="""",
            return_elements=return_values_for_import_graph_def
        )
        # only restore if there's something to restore
        if saver is not None:
            saver.restore(sess, path)

    return return_tensors


def parse_arguments() -> argparse.ArgumentParser:
    """"""
    Stitch the model loaded from path1 to the model loaded from path2.
    """"""
    parser = argparse.ArgumentParser()
    parser.add_argument(""-p1"", ""--path1"", type=str)
    parser.add_argument(""-p2"", ""--path2"", type=str)
    return parser


def main():
    parser = parse_arguments()
    args = parser.parse_args()
    graph = tf.get_default_graph()
    sess = tf.Session(graph=graph)

    with graph.as_default():
        input1, output1 = load_and_stitch_graph(
            path=args.path1,
            sess=sess,
            scope=""foo"",
            input_map={},
            return_values=[""INPUT"", ""OUTPUT""]
        )

        out2 = load_and_stitch_graph(
            path=args.path2,
            sess=sess,
            scope=""bar"",
            input_map={""INPUT"": output1},
            return_values=[""OUTPUT""]
        )
    sess.run(out2[0], feed_dict={input1: [[1, 2, 3, 4]]})


main()

```

However, when it tries to load model `bar` and stitches the graph with model `foo`, `tf.import_graph_def` crashes with the following error:
```
Traceback (most recent call last):
  File ""/Users/rukon/tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1375, in _do_call
    return fn(*args)
  File ""/Users/rukon/tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1360, in _run_fn
    target_list, run_metadata)
  File ""/Users/rukon/tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1453, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Matrix size-incompatible: In[0]: [1,4], In[1]: [3,16]
	 [[{{node foo/sequential/layer_0/Relu}}]]
```
After digging into the error, looks there is a tf.Variable conflict even though we added the name scope during loading model, and it tries to hook up the model ""bar"" first hidden layer to the model ""foo"" input, my best guess is internally somehow tf.Variables are messed up on reference. I understand Tensorflow would deprecate the usage of tf graph as well as its utilities, but currently wrt the backward compatibility with TF 1.x, I'd expect it should still work.

**Describe the expected behavior**

**Standalone code to reproduce the issue**
The issue could be 100% reproduced by running the above code with the system info.

"
46744,Distributed training for transformer model.,"Hello,

I am attempting to adapt TensorFlow's transformer tutorial to work on multiple GPUs using there distributed training tutorial,

Transformer: https://www.tensorflow.org/tutorials/text/transformer
Distributed training: https://www.tensorflow.org/tutorials/distribute/custom_training

However, when I execute the program I get the error: ""TypeError: train_step() argument after ** must be a mapping, not Tensor"" in `per_replica_losses = strategy.run(train_step, args=(inp, tar),)`.


The code that is causing the issue is as follows:
`train_step_signature = [
    tf.TensorSpec(shape=(None, None), dtype=tf.int64),
    tf.TensorSpec(shape=(None, None), dtype=tf.int64),
]

@tf.function(input_signature=train_step_signature)
def train_step(inp, tar):
  #inp, tar = dataset_inputs
  tar_inp = tar[:, :-1]
  tar_real = tar[:, 1:]

  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)

  with tf.GradientTape() as tape:
    predictions, _ = transformer(inp, tar_inp,
                                 True,
                                 enc_padding_mask,
                                 combined_mask,
                                 dec_padding_mask)
    loss = loss_function(tar_real, predictions)

  gradients = tape.gradient(loss, transformer.trainable_variables)
  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))

  train_loss(loss)
  train_accuracy(accuracy_function(tar_real, predictions))`

@tf.function(input_signature=train_step_signature)
def distributed_train_step(inp, tar):
  per_replica_losses = strategy.run(train_step, args=(inp, tar),)

  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,
                         axis=None)

for epoch in range(EPOCHS):
  start = time.time()
  BatchTime = time.time()

  train_loss.reset_states()
  train_accuracy.reset_states()

  for (batch, (dataset_inputs)) in enumerate(train_dataset):

      distributed_train_step(dataset_inputs)

      if batch % 50 == 0:

           print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, batch, train_loss.result(), train_accuracy.result()))

      if batch % 100 == 0:
          ckpt_save_path = ckpt_manager.save()
          print ('Saving checkpoint for batch {} at {}'.format(batch,
                                                                 ckpt_save_path))
          print(""Time taken: {}"".format(time.time() - BatchTime))
          BatchTime = time.time()

  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,
                                               train_loss.result(),
                                              train_accuracy.result()))
print ('Time taken for 1 epoch: {} secs\n'.format(time.time() - start))`


Thanks


"
46740,Converting TF2 Object detection API model to frozen graph,"Win10, Tensorflow 2.4, Object detection API bcc9ab69195489dae89ad784f882f81f90bf93e4.

`ssd_resnet50_v1_fpn_640x640_coco17_tpu-8` model trained using Tensorflow object detection API using
https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py

After exported to `Save model`:
 `.\exporter_main_v2.py --input_type image_tensor --pipeline_config_path .\models\my_ssd_resnet50_v1_fpn\pipeline.config --trained_checkpoint_dir .\models\my_ssd_resnet50_v1_fpn\ --output_directory .\exported-models\models\Bel_model` using
https://github.com/tensorflow/models/blob/master/research/object_detection/exporter_main_v2.py

On this step inference work fine with Tensorflow.

Inference from `Saved model`:
<details>

````
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)
import pathlib
import tensorflow as tf

tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)

# Enable GPU dynamic memory allocation
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)


PATH_TO_LABELS = ""label_map.pbtxt"" 

# %%
# Load the model
# ~~~~~~~~~~~~~~
# Next we load the downloaded model
import time
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as viz_utils

PATH_TO_SAVED_MODEL = ""models\\Bel_model\\saved_model""

print('Loading model...', end='')
start_time = time.time()

# Load saved model and build the detection function
detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)

end_time = time.time()
elapsed_time = end_time - start_time
print('Done! Took {} seconds'.format(elapsed_time))

# %%
# Load label map data (for plotting)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Label maps correspond index numbers to category names, so that when our convolution network
# predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility
# functions, but anything that returns a dictionary mapping integers to appropriate string labels
# would be fine.

category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,
                                                                    use_display_name=True)

# %%
# Putting everything together
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~
# The code shown below loads an image, runs it through the detection model and visualizes the
# detection results, including the keypoints.
#
# Note that this will take a long time (several minutes) the first time you run this code due to
# tf.function's trace-compilation --- on subsequent runs (e.g. on new images), things will be
# faster.
#
# Here are some simple things to try out if you are curious:
#
# * Modify some of the input images and see if detection still works. Some simple things to try out here (just uncomment the relevant portions of code) include flipping the image horizontally, or converting to grayscale (note that we still expect the input image to have 3 channels).
# * Print out `detections['detection_boxes']` and try to match the box locations to the boxes in the image.  Notice that coordinates are given in normalized form (i.e., in the interval [0, 1]).
# * Set ``min_score_thresh`` to other values (between 0 and 1) to allow more detections in or to filter out more detections.
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings

def load_image_into_numpy_array(path):
    """"""Load an image from file into a numpy array.

    Puts image into numpy array to feed into tensorflow graph.
    Note that by convention we put it into a numpy array with shape
    (height, width, channels), where channels=3 for RGB.

    Args:
      path: the file path to the image

    Returns:
      uint8 numpy array with shape (img_height, img_width, 3)
    """"""
    return np.array(Image.open(path))

IMAGE_PATHS = ['1.png', '2.png']

for image_path in IMAGE_PATHS:

    print('Running inference for {}... '.format(image_path), end='')

    image_np = load_image_into_numpy_array(image_path)

    # Things to try:
    # Flip horizontally
    # image_np = np.fliplr(image_np).copy()

    # Convert image to grayscale
    # image_np = np.tile(
    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)

    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.
    input_tensor = tf.convert_to_tensor(image_np)
    # The model expects a batch of images, so add an axis with `tf.newaxis`.
    input_tensor = input_tensor[tf.newaxis, ...]

    # input_tensor = np.expand_dims(image_np, 0)
    detections = detect_fn(input_tensor)

    # All outputs are batches tensors.
    # Convert to numpy arrays, and take index [0] to remove the batch dimension.
    # We're only interested in the first num_detections.
    num_detections = int(detections.pop('num_detections'))
    detections = {key: value[0, :num_detections].numpy()
                   for key, value in detections.items()}
    detections['num_detections'] = num_detections

    # detection_classes should be ints.
    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)

    image_np_with_detections = image_np.copy()

    viz_utils.visualize_boxes_and_labels_on_image_array(
          image_np_with_detections,
          detections['detection_boxes'],
          detections['detection_classes'],
          detections['detection_scores'],
          category_index,
          use_normalized_coordinates=True,
          max_boxes_to_draw=200,
          min_score_thresh=.30,
          agnostic_mode=False)  
    
    plt.figure()
    plt.imshow(image_np_with_detections)
    
    #***
    newname =  image_path.replace('.', '_out.') 
    plt.savefig(newname)
    
    print('Done')
plt.show()

# sphinx_gallery_thumbnail_number = 2
````
</details>

Inference from `Checkpoint`:
<details>

````
#!/usr/bin/env python
# coding: utf-8
""""""
Object Detection From TF2 Checkpoint
====================================
""""""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)
import pathlib
import tensorflow as tf

PATH_TO_LABELS = ""label_map.pbtxt"" 
PATH_TO_MODEL_DIR = ""models/Bel_model""

# %%
# Load the model
# ~~~~~~~~~~~~~~
# Next we load the downloaded model
import time
from object_detection.utils import label_map_util
from object_detection.utils import config_util
from object_detection.utils import visualization_utils as viz_utils
from object_detection.builders import model_builder

PATH_TO_CFG = PATH_TO_MODEL_DIR + ""/pipeline.config""
PATH_TO_CKPT = PATH_TO_MODEL_DIR + ""/checkpoint""

print('Loading model... ', end='')
start_time = time.time()

# Load pipeline config and build a detection model
configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)
model_config = configs['model']
detection_model = model_builder.build(model_config=model_config, is_training=False)

# Restore checkpoint
ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)
ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()

@tf.function
def detect_fn(image):
    """"""Detect objects in image.""""""

    image, shapes = detection_model.preprocess(image)
    prediction_dict = detection_model.predict(image, shapes)
    detections = detection_model.postprocess(prediction_dict, shapes)

    return detections

end_time = time.time()
elapsed_time = end_time - start_time
print('Done! Took {} seconds'.format(elapsed_time))

# %%
# Load label map data (for plotting)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Label maps correspond index numbers to category names, so that when our convolution network
# predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility
# functions, but anything that returns a dictionary mapping integers to appropriate string labels
# would be fine.

category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,
                                                                    use_display_name=True)

# %%
# Putting everything together
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~
# The code shown below loads an image, runs it through the detection model and visualizes the
# detection results, including the keypoints.
#
# Note that this will take a long time (several minutes) the first time you run this code due to
# tf.function's trace-compilation --- on subsequent runs (e.g. on new images), things will be
# faster.
#
# Here are some simple things to try out if you are curious:
#
# * Modify some of the input images and see if detection still works. Some simple things to try out here (just uncomment the relevant portions of code) include flipping the image horizontally, or converting to grayscale (note that we still expect the input image to have 3 channels).
# * Print out `detections['detection_boxes']` and try to match the box locations to the boxes in the image.  Notice that coordinates are given in normalized form (i.e., in the interval [0, 1]).
# * Set ``min_score_thresh`` to other values (between 0 and 1) to allow more detections in or to filter out more detections.
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings

def load_image_into_numpy_array(path):
    """"""Load an image from file into a numpy array.

    Puts image into numpy array to feed into tensorflow graph.
    Note that by convention we put it into a numpy array with shape
    (height, width, channels), where channels=3 for RGB.

    Args:
      path: the file path to the image

    Returns:
      uint8 numpy array with shape (img_height, img_width, 3)
    """"""
    return np.array(Image.open(path))

IMAGE_PATHS = ['1.png', '2.png']

for image_path in IMAGE_PATHS:

    print('Running inference for {}... '.format(image_path), end='')

    image_np = load_image_into_numpy_array(image_path)        
    
    plt.figure()
    plt.imshow(image_np)

    # Things to try:
    # Flip horizontally
    # image_np = np.fliplr(image_np).copy()

    # Convert image to grayscale
    # image_np = np.tile(
    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)

    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)

    detections = detect_fn(input_tensor)

    # All outputs are batches tensors.
    # Convert to numpy arrays, and take index [0] to remove the batch dimension.
    # We're only interested in the first num_detections.
    num_detections = int(detections.pop('num_detections'))
    detections = {key: value[0, :num_detections].numpy()
                  for key, value in detections.items()}
    detections['num_detections'] = num_detections

    # detection_classes should be ints.
    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)

    label_id_offset = 1
    image_np_with_detections = image_np.copy()

    viz_utils.visualize_boxes_and_labels_on_image_array(
            image_np_with_detections,
            detections['detection_boxes'],
            detections['detection_classes']+label_id_offset,
            detections['detection_scores'],
            category_index,
            use_normalized_coordinates=True,
            max_boxes_to_draw=200,
            min_score_thresh=.30,
            agnostic_mode=False)

    plt.figure()
    plt.imshow(image_np_with_detections)  
    
    #***
    newname =  image_path.replace('.', '_out_cp.') 
    plt.savefig(newname)
    
    print('Done')
plt.show()

# sphinx_gallery_thumbnail_number = 2
````
</details>


But when I try to convert `Saved model` to `Frozen graph` 
````
import tensorflow as tf
print(tf.__version__)

from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2

loaded = tf.saved_model.load('models/mnist_test')
infer = loaded.signatures['serving_default']

f = tf.function(infer).get_concrete_function(flatten_input=tf.TensorSpec(shape=[None, 28, 28, 1], dtype=tf.float32))
f2 = convert_variables_to_constants_v2(f)
graph_def = f2.graph.as_graph_def()

# Export frozen graph
with tf.io.gfile.GFile('frozen_graph.pb', 'wb') as f:
   f.write(graph_def.SerializeToString())
````
as suggested here
https://github.com/opencv/opencv/issues/16879#issuecomment-603815872
I receive error:
<details>

````
2021-01-27 14:20:25.689687: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-01-27 14:20:25.689761: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-01-27 14:20:33.819028: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-27 14:20:33.819694: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2021-01-27 14:20:33.821661: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-01-27 14:20:33.825189: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: Eclipse
2021-01-27 14:20:33.825303: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: Eclipse
2021-01-27 14:20:33.826001: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-01-27 14:20:33.826483: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
Traceback (most recent call last):
  File "".\frozen_graph.py"", line 8, in <module>
    f = tf.function(infer).get_concrete_function(input_1=tf.TensorSpec(shape=[None, 640, 640, 3], dtype=tf.float32))
  File ""C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\eager\def_function.py"", line 1299, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\eager\def_function.py"", line 1205, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\eager\def_function.py"", line 725, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File ""C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\eager\function.py"", line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File ""C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\eager\function.py"", line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\eager\function.py"", line 3196, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\eager\def_function.py"", line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\eager\function.py:1669 __call__  *
        return self._call_impl(args, kwargs)
    C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\eager\function.py:1685 _call_impl  **
        raise structured_err
    C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\eager\function.py:1678 _call_impl
        return self._call_with_structured_signature(args, kwargs,
    C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\eager\function.py:1756 _call_with_structured_signature
        self._structured_signature_check_missing_args(args, kwargs)
    C:\Users\Bleach\miniconda3\envs\TFstd\lib\site-packages\tensorflow\python\eager\function.py:1775 _structured_signature_check_missing_args
        raise TypeError(""{} missing required arguments: {}"".format(

    TypeError: signature_wrapper(*, input_tensor) missing required arguments: input_tensor
````
</details>"
46739,Difference between regular and fast nms in TFLite ,"What is the difference between regular and fast Non-Max-Suppression (NMS) in TFLite ? is there any documentation on that?
I mean it terms of accuracy/performance. I understand there is a difference in the time complexity, but why do they yield different results? 

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/detection_postprocess.cc

"
46738,ImportError: DLL load failed while importing _pywrap_tensorflow_internal:,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): 
- TensorFlow version: 2.4.1
- Python version:3.8
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
I am not able to install tensorflow using pip on anaconda (& sypder)
It has worked on my other Computer but not on the Windows10, i have uninstalled and reinstalled everything several times, but it just wont work. I can install other libraries, but not tensorflow - i do not understand why.

I know this post is a duplicate, but the answers in previous posts didnt help me since i am new to coding and everything....Sorry for bothering though
And no i do not want to use google collab, but install & use tensorflow on my computer

I would be very happy if someone could help me!!


**Provide the exact sequence of commands / steps that you executed before running into the problem**
ImportError: Traceback (most recent call last):
  File ""C:\Users\go-pa\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: Das angegebene Modul wurde nicht gefunden.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
46737,bqml kmeans -> tflite: Call_once op doesn't support multiple subgraphs with inputs,"Filing on request of tflite group

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 & macOS 11.0.1
- TensorFlow installed from (source or binary): pip tf-nightly 
- TensorFlow version (use command below): 2.5.0-dev20210123 (git: v1.12.1-49539-g18d8bcbe72b)
- Python version: 3.7

**Describe the current behavior**
Export saved model from bqml to GCS. Load saved model and test:
![Screen Shot 2021-01-26 at 12 21 34 PM](https://user-images.githubusercontent.com/5230786/106028324-ccf80080-6099-11eb-9e45-a24188eee451.png)

create tflite model using from_saved_model:
![Screen Shot 2021-01-26 at 12 26 28 PM](https://user-images.githubusercontent.com/5230786/106028363-da14ef80-6099-11eb-8aa4-d7a2c13c848b.png)

load tflite model with interpreter to test:
![Screen Shot 2021-01-26 at 12 29 29 PM](https://user-images.githubusercontent.com/5230786/106028401-e39e5780-6099-11eb-93a4-3c229194501a.png)

**Describe the expected behavior**
Load tflite model and make predictions using interpreter to validate successful conversion

**Standalone code to reproduce the issue**
toy saved model from bqml k-means, notebook to repro, and tflite model can be found here: https://drive.google.com/drive/folders/1HfAU7ZK6CHvRFl_hSfw42RzlAfvXS-PJ?usp=sharing
"
46735,RaggedTensor processing float type  causes memory leak,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>



**System information**
- TF 1.15.3
- Linux
- python 3.7

**Describe the current behavior**
text_input_flatten is a 3D tensor, [batch_size, seq_length, embedding_size], dtype=tf.float32
text_mask is a 2D tensor, [batch_size, seq_length], dtype=tf.bool

text_input_ragged = tf.RaggedTensor.from_tensor(text_input_flatten)
text_input_ragged = tf.ragged.boolean_mask(text_input_ragged, text_mask, name=""ragged_text_input"")
new_text_input = text_input_ragged.to_tensor(default_value=0)
new_length = tf.shape(new_text_input)[1]
new_text_input = tf.pad(new_text_input, [[0, 0], [0, seq_length * emb_size - new_length], [0, 0]], constant_values=0)

the memory usage is increasing rapidly, finally, the program will crash.
When I changed the text_input_flatten dtype to tf.int32, it works normally.

![memory](https://user-images.githubusercontent.com/8108725/106013911-e7f95d80-60f7-11eb-97e5-b4fe31c38bfc.png)
**Describe the expected behavior**"
46733,Support request for tanh activation function during quantization aware training (TensorFlow Model Optimization),"**System information**
- TensorFlow version (you are using): 2.4.1
- Are you willing to contribute it (Yes/No): Yes 



**Describe the feature and the current behavior/state.**

When using `tfmot.quantization.keras.quantize_model()` to convert a `tf.keras.model` that uses a `tanh` activation function to a `tf.keras.model prepared for quantization,` the following error message appears:

**Case I:** ValueError: Only some Keras activations under `tf.keras.activations` are supported. For other activations, use `Quantizer` directly, and update layer config using `QuantizeConfig`.

Minimal example to reproduce:

```
import tensorflow as tf
import tensorflow_model_optimization as tfmot

i = tf.keras.layers.Input(shape=(24, 24, 3))
x = tf.keras.layers.Conv2D(10, kernel_size=1, activation='tanh')(i)
model = tf.keras.Model(inputs=i, outputs=x)

quant_aware_model = tfmot.quantization.keras.quantize_model(model)
```

**Case II:** Even worse - when specifying the activation function explicitly as `tf.nn.tanh(x)`, one receives the following misleading error message:

TypeError: in user code: TypeError: tf__call() got an unexpected keyword argument 'name'

Minimal example to reproduce:

```
import tensorflow as tf
import tensorflow_model_optimization as tfmot

i = tf.keras.layers.Input(shape=(24, 24, 3))
x = tf.keras.layers.Conv2D(10, kernel_size=1)(i)
x = tf.nn.tanh(x)
model = tf.keras.Model(inputs=i, outputs=x)

quant_aware_model = tfmot.quantization.keras.quantize_model(model)
```

**Will this change the current api? How?**

No, I'd expect minor changes. Please have a look at the class [QuantizeAwareActivation](https://github.com/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/python/core/quantization/keras/quantize_aware_activation.py): in line 76-77 the author states:

"" TODO(pulkitb): Other activations such as elu, tanh etc., should just work on inclusion. Verify in TFLite before enabling.""

**Who will benefit with this feature?**

All users that are interested in building tiny applications beyond classification/ recognition, which mainly uses softmax/ sigmoid activations.

**Any Other info.**

alternatively: please provide me with some more information, on how ""to use the `Quantizer` directly"", to replace the tanh activation function. Thank you very much. "
46732,How to create representative_dataset with multiple inputs on TensorFlow Lite Converter?,"I cannot find any examples online, if I was to simulate data would it look like this?

```
def representative_dataset():
    for _ in range(100):
      data1, data2 = np.random.rand(1, 256), np.random.rand(1, 50)
      yield [data1.astype(np.float32), data2.astype(np.float32)]
```"
46730,Some **function** symbols are exported as DATA from prebuilt Windows CPU tensorflow.dll,"**System information**
- Windows 10 x64
- Used `libtensorflow-cpu-windows-x86_64-2.3.1.zip` binaries.

**Describe the current behavior**
When I build Haskell `tensorflow` package with my own MSVC toolset-based GHC, I get `undefined symbol` link errors for  `TF_GetCode`, `TF_Message`, `TF_DeleteStatus`, `TF_NewStatus`, `TF_SetStatus` symbols.

And indeed, inspecting `tensorflow.lib` import library I see that these symbols are exported as `DATA` symbols, and linker doesn't generate thunks for them. But they all are functions.

I suspect the tests don't catch this because if we testing a C/Ð¡++ code, the, e.g., Visual C++ complier  sees that these functions are declared as `__declspec(dllimport)` and correctly generates indirect calls for them, thus using `__imp_`-decorated names for these functions.

Also we shouldn't, perhaps, have the problems (I haven't tried this tho) when compiling this code with stock mingw-based GHC. This is because mingw tools (GNU ld + GCC startup code) implement runtime pseudo-relocs, which allows the client object code to link against `__imp_foo` anywhere the code expects `foo`.

I've glanced into the code and have understood that export of the symbols is implemented in a python script which uses heuristics to guess if it shall export the symbol as `DATA` or not.

Apparently these heuristics are broken.

Apart from this: if tensorflow API already have `TF_CAPI_EXPORT` annotations everywhere, why doesn't it use the standard  `dllexport` definition for `TF_CAPI_EXPORT` **when building** the library to export all relevant symbols, why does it implement some broken hard-to-maintain custom mechanism?

Sorry if this is a dumb question, there should exist compelling reasons to do so, I believe."
46729,Cash on tflite::Interpreter::AllocateTensors(),"I'm trying to make an audio classifier as [android YAMNet](https://farmaker47.medium.com/classification-of-sounds-using-android-mobile-phone-and-the-yamnet-ml-model-539bc199540) with C++ language on JNI, however, I got the crash on tflite::Interpreter::AllocateTensors. And my tflite version maybe 2.3.

Here is my code snippet
```
  bool YAMNet::Classify(const std::vector<float> &wave_data, const int sample_rate,
                          const int top_k, std::vector<Recognition> &recognitions) {

        static const int kDefaultSampleRate = 16000;// Hz
        if (kDefaultSampleRate != sample_rate) {
            Trace_Err(""Error: YAMNet input must be 16kHz."");
            assert(false);
            return false;
        }

        std::vector<int> input_tensor_indices;
        input_tensor_indices = interpreter_ -> inputs();
        interpreter_->ResizeInputTensor(input_tensor_indices[input_index_of_wave_],
                                        {1, (int)wave_data.size()});

        interpreter_->AllocateTensors();
...
```
And then, I got the crash as following:
```
2021-01-27 18:15:36.478 20012-20012/com.tomato.ketchup A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x28 in tid 20012 (.tomato.ketchup), pid 20012 (.tomato.ketchup)
2021-01-27 18:15:36.839 20012-20055/com.tomato.ketchup E/ketchup: ###### CSeedUdp::ProcessSend sendto() failed, errno=101(Network is unreachable), fd=58
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG: Build fingerprint: 'xiaomi/wayne/wayne:9/PKQ1.180904.001/V11.0.5.0.PDCCNXM:user/release-keys'
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG: Revision: '0'
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG: ABI: 'arm64'
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG: pid: 20012, tid: 20012, name: .tomato.ketchup  >>> com.tomato.ketchup <<<
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG: signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x28
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG: Cause: null pointer dereference
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG:     x0  0000000000000000  x1  0000000000000000  x2  0000007c4b800000  x3  0000000000000004
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG:     x4  0000000000000096  x5  0000007c633a3848  x6  00003e8000000001  x7  00003e8000000001
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG:     x8  0000000000000000  x9  0000007c3abfe358  x10 00000000000000d9  x11 0000007c4b896650
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG:     x12 0000000000000008  x13 0000000000000000  x14 0000000000000011  x15 0000000000000001
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG:     x16 0000007c4fa760f0  x17 0000007c4f973910  x18 00000000ffffffff  x19 0000000000000000
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG:     x20 0000000000000000  x21 0000007c4b86ff80  x22 0000007c4fa25993  x23 0000000000000000
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG:     x24 0000000000000000  x25 0000000000000000  x26 0000007cf1aaa5e0  x27 0000007c4fa71a08
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG:     x28 0000007c3abfe360  x29 0000007fdb66e470
2021-01-27 18:15:36.859 20105-20105/? A/DEBUG:     sp  0000007fdb66e410  lr  0000007c4f974fc4  pc  0000007c4f975018
2021-01-27 18:15:37.182 20105-20105/? A/DEBUG: backtrace:
2021-01-27 18:15:37.182 20105-20105/? A/DEBUG:     #00 pc 0000000000235018  /data/app/com.tomato.ketchup-V1Z97Zn_3BrgXuDk3RSqeA==/base.apk (offset 0xedbb000) (tflite::Subgraph::ModifyGraphWithDelegate(TfLiteDelegate*)+252)
2021-01-27 18:15:37.182 20105-20105/? A/DEBUG:     #01 pc 0000000000238b98  /data/app/com.tomato.ketchup-V1Z97Zn_3BrgXuDk3RSqeA==/base.apk (offset 0xedbb000) (tflite::Interpreter::AllocateTensors()+220)
```

Dose anyone have any idea on this?"
46728,What is the accuracy of PoseNet??,"Is anyone here tried re-training posenet?
I recognised there are no official codes to re-train a posenet model,
so I'm going to make a TF based pose-estimation architecture in python -> train it with COCO data -> convert it to TFLite style.
If there is anyone else already tried something similar to this, how did you guys compare the accuracy (and loss) of the newer posenet with the official one? (or other pose estimations like alphapose/openpose with posenet...)
Because I could not find the accuracy of the pre-trained posenet model from any official place (like official blogs or papers).
please help
"
46727,FR for keras.preprocessing.image_dataset_from_directory label_mode parameter to accept enum as input,"**System information**
- TensorFlow version (you are using): 2.4.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

When calling the `tf.keras.preprocessing.image_dataset_from_directory()` function, the parameter `label_mode=` accepts 3 values: `int`, `categorical` and `binary`. However, the string object is not deterministic: for that, I propose to add another option, which would be to specify the value using an enumeration which IS deterministic.

**Will this change the current api? How?**

No

**Who will benefit with this feature?**

Users who want more structured code.

**Any Other info.**

This behavior is, as far as I know, already available for some features in Keras."
46726,different result on dict of tensors by getting `_enable_dict_to_input_mapping` in tf.python.keras.engine.functional.py,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Linux Ubuntu 18.04 
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.4.1, 2.3.2, 2.3.0, cpu, gpu both
- Python version: 3.7

**Describe the current behavior**

`_enable_dict_to_input_mapping` of same dict of tensors `{'text': (a, b)}` is `False` in tf 2.4.1, but `True` in tf 2.3.2

**Describe the expected behavior**

expect same False or True

**Standalone code to reproduce the issue**

Tensorflow 2.3.2
```python
>>> import tensorflow as tf
>>> tf.__version__
'2.3.2'
>>> # copy from https://github.com/tensorflow/tensorflow/blob/9edbe5075f79a4a95ed14a2be831f9b59e61f49d/tensorflow/python/keras/engine/functional.py#L136
>>> from tensorflow.python.util import nest
>>> def get_enable_dict_to_input_mapping_232(_nested_inputs):
...     _enable_dict_to_input_mapping = (not nest.is_sequence(_nested_inputs) or (isinstance(_nested_inputs, (list, tuple, dict)) and not any(nest.is_sequence(t) for t in _nested_inputs)))
...     return _enable_dict_to_input_mapping

>>> a = tf.keras.Input(shape=(None,), dtype=tf.int32, name='a')
>>> b = tf.keras.Input(shape=(None,), dtype=tf.int32, name='b')
>>> c = {'text': (a, b) }

>>> get_enable_dict_to_input_mapping_232(c)
True
```


Tensorflow 2.4.1
```python
>>> import tensorflow as tf
>>> tf.__version__
'2.4.1'
>>> # copy from https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/keras/engine/functional.py#L142
>>> from tensorflow.python.util import nest
>>> def get_enable_dict_to_input_mapping_241(_nested_inputs):
...     if not nest.is_nested(_nested_inputs):
...         _enable_dict_to_input_mapping = True
...     elif (isinstance(_nested_inputs, (list, tuple)) and not any(nest.is_nested(t) for t in _nested_inputs)):
...         _enable_dict_to_input_mapping = True
...     elif (isinstance(_nested_inputs, dict) and not any(nest.is_nested(t) for t in _nested_inputs.values())):
...         _enable_dict_to_input_mapping = True
...     else:
...         _enable_dict_to_input_mapping = False
...     return _enable_dict_to_input_mapping

>>> a = tf.keras.Input(shape=(None,), dtype=tf.int32, name='a')
>>> b = tf.keras.Input(shape=(None,), dtype=tf.int32, name='b')
>>> c = {'text': (a, b) }

>>> get_enable_dict_to_input_mapping(c)
False
```

`_enable_dict_to_input_mapping` of same dict of tensors `{'text': (a, b)}` is `False` in tf 2.4.1 and `True` in tf 2.3.2

This leads to different result in `_flatten_to_reference_inputs` defined in [Functional._flatten_to_reference_inputs](https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/keras/engine/functional.py#L574)

- in tf 2.3.2, for `inputs = {'text': (a, b)}`, returns `[(a, b)]`, and then raise Exception  `AttributeError: 'tuple' object has no attribute '_keras_mask'` in [Functional._run_internal_graph](https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/keras/engine/functional.py#L536) while assigning `input_t._keras_mask = mask`
- in tf 2.4.1, for `inputs = {'text': (a, b)}`, returns `[a, b]`, and then all is okay while assigning `input_t._keras_mask = mask`


**Refs**

difference impl of getting `_enable_dict_to_input_mapping` in `tf.python.keras.engine.functional.py` between tf 2.4.1-[_enable_dict_to_input_mapping](https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/keras/engine/functional.py#L142) and tf 2.3.2 - [_enable_dict_to_input_mapping](https://github.com/tensorflow/tensorflow/blob/9edbe5075f79a4a95ed14a2be831f9b59e61f49d/tensorflow/python/keras/engine/functional.py#L136)

tf 2.4.1
```python
    if not nest.is_nested(self._nested_inputs):
      self._enable_dict_to_input_mapping = True
    elif (isinstance(self._nested_inputs, (list, tuple)) and
          not any(nest.is_nested(t) for t in self._nested_inputs)):
      self._enable_dict_to_input_mapping = True
    elif (isinstance(self._nested_inputs, dict) and
          not any(nest.is_nested(t) for t in self._nested_inputs.values())):
      self._enable_dict_to_input_mapping = True
    else:
      self._enable_dict_to_input_mapping = False

    if not keras_tensor.keras_tensors_enabled():
      if any(not hasattr(tensor, '_keras_history') for tensor in self.outputs):
        base_layer_utils.create_keras_history(self._nested_outputs)
```

tf 2.3.2
```
  self._enable_dict_to_input_mapping = (
        not nest.is_sequence(self._nested_inputs) or
        (isinstance(self._nested_inputs, (list, tuple, dict)) and
         not any(nest.is_sequence(t) for t in self._nested_inputs)))
```

**Additional**
I cannot upgrade tensorflow to 2.4.1 on the production env, since the cuda version is 10.1, does not supported by tensorflow 2.4.1 (it requires cuda 11.0), If I install tensorflow-gpu 2.4.1, I  cannot get the GPUs using `tf.config.list_physical_devices('GPU')` (empty list will be returned)"
46725,Reshape before Softmax leads runtime error:Unnecessary dynamic-sized tensors,"### 1. System information

- OS: Win10 & Ubuntu 1804
- TensorFlow installation: Pip
- TensorFlow library: 2.4 & 2.4.1

### 2. Code

`
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

def convert_to_lite(model,out_path,enable_selected_tf_ops=False):
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    out_model = converter.convert()
    with open(out_path, ""wb"") as fp:
        fp.write(out_model)

def failed_on_android_gpu_for_dynamic_size():
    ipt = layers.Input((256,64,3))
    x = ipt
    x = layers.Reshape((16384,3))(x)
    x = layers.Softmax(axis=1)(x)
    x = layers.Flatten()(x)
    x = layers.Dense(1)(x)
    model = keras.Model(inputs=[ipt],outputs=[x])
    convert_to_lite(model,'failed_on_android_gpu.tflite')

def work_reshape_only():
    ipt = layers.Input((256,64,3))
    x = ipt
    x = layers.Reshape((16384,3))(x)
    # x = layers.Softmax(axis=1)(x)
    x = layers.Flatten()(x)
    x = layers.Dense(1)(x)
    model = keras.Model(inputs=[ipt],outputs=[x])
    convert_to_lite(model,'work_reshape_only.tflite')
[Reshape_before_Softmax_leads_runtime_error.zip](https://github.com/tensorflow/tensorflow/files/5879355/Reshape_before_Softmax_leads_runtime_error.zip)


def work_softmax_only():
    ipt = layers.Input((256,64,3))
    x = ipt
    # x = layers.Reshape((16384,3))(x)
    x = layers.Softmax(axis=1)(x)
    x = layers.Flatten()(x)
    x = layers.Dense(1)(x)
    model = keras.Model(inputs=[ipt],outputs=[x])
    convert_to_lite(model,'work_softmax_only.tflite')

if __name__ == ""__main__"":
    failed_on_android_gpu_for_dynamic_size()
    work_reshape_only()
    work_softmax_only()
`
### 5. (optional) Any other info / logs
Run the 'failed_on_android_gpu.tflite' on android with gpu delegate cause exception:
Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.
The other 2 tflite files which with Reshape/Softmax only works fine, so the dynamic-size tensor is unnecessary.

I also tested nn.softmax or math.reduced_sum, has same problem. Maybe 'reduce_sum_with_dims' is the real 

problem."
46724,`tf.matmul` and `tf.tensordot` behave different in converted concrete function in TensorFlowLite ,"### 1. System information

- OS Platform and Distribution: MacOS 10.15 and Ubuntu 18.04 LTS on Colab machine
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): `tensorflow                    2.4.0`

### 2. Code

This notebook demonstrates the bug with the simplest example I came up with.

https://colab.research.google.com/gist/ebraraktas/ab87170deb38eae979b37795015e44bc

### 3. Failure after conversion

I implemented RFFT for TFLite using `tf.matmul` and saved the module concrete function. But invoking saved tflite model repeatedly returns different results. However, replacing `tf.matmul`Â with `tf.tensordot` fixes the strange behavior. Therefore, I have prepared the notebook above to demonstrate the bug. I have realized interesting cases which change the behavior:

- If negative sign is removed from output returned from `DummyMatmul` or `DummyTensordot` (`result` variable), outputs are same
- If we use `tf.Module` directly, outputs are same (colab demo shows it)
- Somehow, size of the right hand side matrix matters (colab demo shows it)
- Difference occurs after first iteration (colab demo shows it), and for some inputs it gets larger with every iteration 
"
46721,*** The TAGS command line option is no longer supported in the TFLM Makefile..,"@tensorflow/micro

i was following guides from Build Arm Cortex-M voice assistant with Google TensorFlow Lite, link as below:
https://developer.arm.com/solutions/machine-learning-on-arm/developer-material/how-to-guides/build-arm-cortex-m-voice-assistant-with-google-tensorflow-lite 

so when i come across the command below:
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed TAGS=""CMSIS disco_f746ng"" generate_micro_speech_mbed_project

This error pops out:
*** The TAGS command line option is no longer supported in the TFLM Makefile..

i tried to remove TAGS=""..."" but it after it compiles it did not work as expected.
I also tried OPTIMIZED_KERNEL_DIR, it returns error below:
tensorflow/lite/micro/tools/make/Makefile:552: disco_f746ng.inc: No such file or directory
make: *** No rule to make target 'disco_f746ng.inc'.  Stop.

Correct me if i am wrong, based on my understanding CMSIS and disco_f746ng are folders specified in ./tensorflow/tensorflow/lite/micro/examples/micro_speech
Which the original TAGS are used to search out the makefile.inc inside both folders and make the file. So the question may be what can i use to replace what TAGS? OR are there any other ways to use OPTIMIZED_KERNEL_DIR?

Thank you in advanced for helping.

"
46720, An error occurs when processing data delivered to tensorflow serving.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4
- Python version: 3.7.9
- CUDA/cuDNN version: None
- GPU model and memory: None

**Describe the current behavior**
An error occurs when transferring data that is confirmed to be operating normally to tensorflow serving

**Describe the expected behavior**
When transmitting data confirmed to be working normally to TensorFlow Serving, it should operate normally

**Standalone code to reproduce the issue**
This Is my model's signature
```
signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['age'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1)
        name: serving_default_age:0
    inputs['balance'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1)
        name: serving_default_balance:0
    inputs['campaign'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1)
        name: serving_default_campaign:0
    inputs['contact'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: serving_default_contact:0
    inputs['day'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1)
        name: serving_default_day:0
    inputs['default'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: serving_default_default:0
    inputs['duration'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1)
        name: serving_default_duration:0
    inputs['education'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: serving_default_education:0
    inputs['housing'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: serving_default_housing:0
    inputs['job'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: serving_default_job:0
    inputs['loan'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: serving_default_loan:0
    inputs['marital'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: serving_default_marital:0
    inputs['month'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: serving_default_month:0
    inputs['pdays'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1)
        name: serving_default_pdays:0
    inputs['poutcome'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: serving_default_poutcome:0
    inputs['previous'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1)
        name: serving_default_previous:0
    inputs['seq'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 5)
        name: serving_default_seq:0
    inputs['y'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: serving_default_y:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['dense_1'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 171)
        name: StatefulPartitionedCall:0
  Method name is: tensorflow/serving/predict
```
load the model and predict with sample_data works fine

```
loded_model = tf.keras.models.load_model(model_path, compile=True)
sample_data = {
        'seq': np.expand_dims(np.array([110, 115, 49, 71, 50]), axis=0),
        'age': np.expand_dims(np.array(32), axis=0),
        'job': np.expand_dims(np.array('management'), axis=0),
        'marital': np.expand_dims(np.array('married'), axis=0),
        'education': np.expand_dims(np.array('primary'), axis=0),
        'default': np.expand_dims(np.array('no'), axis=0),
        'balance': np.expand_dims(np.array(67), axis=0),
        'housing': np.expand_dims(np.array('no'), axis=0),
        'loan': np.expand_dims(np.array('no'), axis=0),
        'contact': np.expand_dims(np.array('unknown'), axis=0),
        'day': np.expand_dims(np.array(24), axis=0),
        'month': np.expand_dims(np.array('jun'), axis=0),
        'duration': np.expand_dims(np.array(9), axis=0),
        'campaign': np.expand_dims(np.array(1), axis=0),
        'pdays': np.expand_dims(np.array(-1), axis=0),
        'previous': np.expand_dims(np.array(0), axis=0),
        'poutcome': np.expand_dims(np.array('unknown'), axis=0),
        'y': np.expand_dims(np.array('no'), axis=0)
    }
loded_model(sample_data)
<tf.Tensor: shape=(1, 171), dtype=float32, numpy=
array([[5.27819619e-02, 7.91415647e-02, 2.05127634e-02, 4.92982864e-02,
        8.63614008e-02, 5.65255731e-02, 4.22200933e-02, 6.70532882e-02,
        2.94332802e-02, 5.92661090e-02, 3.92056666e-02, 6.91237226e-02,
        1.33277355e-02, 8.19469616e-03, 5.87656125e-02, 5.18164076e-02,
        6.20538630e-02, 9.00777951e-02, 4.28347066e-02, 2.19823830e-02,
        1.49062146e-07, 2.01256057e-07, 1.53366202e-07, 1.27340172e-07,
        1.86510434e-07, 1.98491620e-07, 1.82937896e-07, 1.32476117e-07,
        1.31851834e-07, 1.40986472e-07, 1.99838468e-07, 1.58420590e-07,
        1.17166692e-07, 9.00412758e-08, 1.95417840e-07, 1.31040650e-07,
        1.60380964e-07, 1.07113330e-07, 1.39082644e-07, 1.42982330e-07,
        1.21180648e-07, 1.54600315e-07, 1.02207764e-07, 2.41572224e-07,
        1.50535001e-07, 1.23603499e-07, 1.76933810e-07, 1.29627537e-07,
        2.25440814e-07, 2.21079134e-07, 1.40433457e-07, 1.21948943e-07,
        1.12487960e-07, 1.82974887e-07, 1.94294685e-07, 1.49468548e-07,
        9.63142881e-08, 1.64101479e-07, 8.75015900e-08, 1.78585822e-07,
        1.18338065e-07, 1.34275794e-07, 1.94435557e-07, 9.40549114e-08,
        7.68365709e-08, 9.09561138e-08, 2.07228780e-07, 1.23126767e-07,
        1.52446063e-07, 1.45874452e-07, 1.97502175e-07, 1.05272626e-07,
        2.01461347e-07, 2.27837347e-07, 2.44192165e-07, 1.04354719e-07,
        1.47167256e-07, 1.86789734e-07, 1.95981102e-07, 1.83554263e-07,
        1.42765145e-07, 9.52495824e-08, 2.68968222e-07, 1.77189975e-07,
        9.28885981e-08, 1.18023948e-07, 1.40940770e-07, 1.22296697e-07,
        1.37569558e-07, 1.37506873e-07, 8.40115391e-08, 1.25378747e-07,
        2.05835846e-07, 1.08780618e-07, 5.62952067e-08, 1.59157153e-07,
        1.29730566e-07, 1.50789603e-07, 1.63185859e-07, 1.54063102e-07,
        1.42086819e-07, 1.31032266e-07, 1.95424562e-07, 8.60203855e-08,
        2.31950693e-07, 1.25126334e-07, 2.37775524e-07, 1.93945539e-07,
        7.71898456e-08, 1.51705976e-07, 1.75589378e-07, 2.89475594e-07,
        1.35602036e-07, 1.80231439e-07, 2.15656939e-07, 1.21509544e-07,
        1.46606226e-07, 1.69434031e-07, 8.56758717e-08, 1.21774391e-07,
        2.94665796e-07, 1.73765784e-07, 1.44480254e-07, 1.25448224e-07,
        1.26027047e-07, 1.53907735e-07, 1.21600536e-07, 1.80686797e-07,
        1.34774865e-07, 1.55523523e-07, 1.34890200e-07, 1.37089174e-07,
        1.40633560e-07, 1.36167046e-07, 1.17650742e-07, 1.60875459e-07,
        1.26850381e-07, 1.48223222e-07, 1.11685516e-07, 1.30754032e-07,
        1.99773112e-07, 9.96520626e-08, 1.44601273e-07, 2.22673521e-07,
        1.37150110e-07, 9.27915593e-08, 1.32079876e-07, 1.45855807e-07,
        1.98044447e-07, 8.85873419e-08, 1.73917329e-07, 9.99040353e-08,
        2.03707074e-07, 9.97928140e-08, 1.81921166e-07, 1.35442946e-07,
        1.58751504e-07, 1.62741699e-07, 1.55544441e-07, 1.72405649e-07,
        8.22981931e-08, 2.17250758e-07, 1.59198137e-07, 1.26780478e-07,
        1.79329419e-07, 1.99787223e-07, 2.10311356e-07, 1.92279757e-07,
        1.51305883e-07, 1.15883971e-07, 1.22970349e-07]], dtype=float32)>

```

However, an error occurs when serving with same data.

```
def processing_input(seq = list, age=int, job=str, marital=str, education=str, default=str, balance=int,
                         housing=str, loan=str, contact=str, day=int, month=str, duration=int,campaign=int, pdays=int, previous=int,poutcome=str,y=str):
    input = {
        'seq': np.expand_dims(np.array(seq), axis=0).tolist(),
        'age': np.expand_dims(np.array(age), axis=0).tolist(),
        'job': np.expand_dims(np.array(job), axis=0).tolist(),
        'marital': np.expand_dims(np.array(marital), axis=0).tolist(),
        'education': np.expand_dims(np.array(education), axis=0).tolist(),
        'default': np.expand_dims(np.array(default), axis=0).tolist(),
        'balance': np.expand_dims(np.array(balance), axis=0).tolist(),
        'housing': np.expand_dims(np.array(housing), axis=0).tolist(),
        'loan': np.expand_dims(np.array(loan), axis=0).tolist(),
        'contact': np.expand_dims(np.array(contact), axis=0).tolist(),
        'day': np.expand_dims(np.array(day), axis=0).tolist(),
        'month': np.expand_dims(np.array(month), axis=0).tolist(),
        'duration': np.expand_dims(np.array(duration), axis=0).tolist(),
        'campaign': np.expand_dims(np.array(campaign), axis=0).tolist(),
        'pdays': np.expand_dims(np.array(pdays), axis=0).tolist(),
        'previous': np.expand_dims(np.array(previous), axis=0).tolist(),
        'poutcome': np.expand_dims(np.array(poutcome), axis=0).tolist(),
        'y': np.expand_dims(np.array(y), axis=0).tolist()
    }
    data = json.dumps({'inputs': input})
    return data

data = processing_input([0,0,0,152,151],32,'tech','none','string','no',3,'no','no','unknown',3,'june',2,1,5,2,'name','no')
json_response = requests.post(f'http://{model_adr}/v1/models/{model_name}:predict', data=data)
prediction = json.loads(str(json_response.content, 'utf-8'))

```
and i get 

```
{'error': 'Invalid reduction dimension (1 for input with 1 dimension(s)\n\t [[{{node model/category_encoding_8/Min}}]]'}
```

I put data that can be accepted as input in the model, why doesn't it work at serving time?


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46719,tf wide and deep model save error,"I am using TF 2.2, the `save` method raises error, 

very brief code to reproduce, nearly all code are from TF official doc https://www.tensorflow.org/api_docs/python/tf/keras/experimental/WideDeepModel
```
import tensorflow as tf
from tensorflow.python.keras.premade.linear import LinearModel
from tensorflow.python.keras.premade.wide_deep import WideDeepModel
import numpy as np

linear_model = LinearModel()
dnn_model = tf.keras.Sequential([tf.keras.layers.Dense(units=64),
                              tf.keras.layers.Dense(units=1)])
combined_model = WideDeepModel(linear_model, dnn_model)
combined_model.compile(optimizer=['sgd', 'adam'], loss='mse', metrics=['mse'])
# define dnn_inputs and linear_inputs as separate numpy arrays or
# a single numpy array if dnn_inputs is same as linear_inputs.
linear_inputs = np.random.random((2, 3))
dnn_inputs = np.random.random((2, 3))
y = np.random.randint(0, 2, (2, 2))

combined_model.fit([linear_inputs, dnn_inputs], y, epochs=1)
combined_model.save('tf-wide-deep')
```
error is 
```
1/1 [==============================] - 0s 365us/step - loss: 0.4376 - mse: 0.4376
2021-01-27 13:36:54.121411: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.

Error
Traceback (most recent call last):
  File ""/home/litchy/rec-pro/tf-models/test_tf_models.py"", line 23, in test_wide_deep
    combined_model.save('tf-wide-deep')
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1052, in save
    signatures, options)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py"", line 138, in save_model
    signatures, options)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 951, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 1037, in _build_meta_graph
    asset_info.asset_index)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 697, in _serialize_object_graph
    saveable_view.function_name_map)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 737, in _write_object_proto
    metadata=obj._tracking_metadata)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 2742, in _tracking_metadata
    return self._trackable_saved_model_saver.tracking_metadata
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py"", line 54, in tracking_metadata
    return json_utils.Encoder().encode(self.python_properties)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 41, in python_properties
    return self._python_properties_internal()
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py"", line 38, in _python_properties_internal
    self.obj, include_optimizer=True, require_config=False))
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saving_utils.py"", line 188, in model_metadata
    model.optimizer.get_config()
AttributeError: 'ListWrapper' object has no attribute 'get_config'

```"
46718,Typo Recognize Flowers with TensorFlow Lite on Android,"## URL(s) with the issue:
https://codelabs.developers.google.com/codelabs/recognize-flowers-with-tensorflow-on-android#4

## Description of issue (what needs changing):
Copy the TensorFlow Lite model model.tflite and label.txt that you trained earlier to assets folder at `lite/codelabs/flower_classification/start/app/src/main/assets/.`

The path used above is incorrect and needs to be updated to `lite/codelabs/flower_classification/android/start/app/src/main/assets/`

Thanks,
George
"
46715,enable tf.shape on ragged keras input tensor,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.4.1
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**

current behavior:
currently. tf.shape can't be called on ragged keras input tensor. for example, 
```shell
#!/usr/bin/python3
import tensorflow as tf;

inputs = tf.keras.Input((None, 1), ragged = True);
batch = tf.keras.layers.Lambda(lambda x: tf.shape(x)[0])(inputs);
```
can't get a variable to be infered. tf.shape is necessary because the input tensor shape is not decided before a specific tensor is feed into the keras model.

feature:
support tf.shape on ragged keras input tensor.

**Will this change the current api? How?**

No change to current api

**Who will benefit with this feature?**

developer who use functional or sequential tf.keras.Model to handle NLP related application.

**Any Other info.**
"
46713,Issue with stateful metrics initialization in ProgbarLogger inside the model.evaluate() function,"**System information**
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from PyPI
- TensorFlow version: 2.4.0
- Python version: 3.6


**Expected behavior**

When using `model.evaluate(validation_dataset)` function, the `ProgbarLogger` callback, that is initialized inside it, should log all the Model's metrics as-is (register them as stateful metrics). 

From `tf.keras.callbacks.ProgbarLogger` docs:
> 
>stateful_metrics | Iterable of string names of metrics that shouldÂ notÂ be averaged over an epoch. Metrics in this list will be logged as-is. All others will be averaged over time (e.g. loss, etc). If not provided, defaults to theÂ Model's metrics. 
>-- | --

**Behavior in TF 2.3.1**

The `_maybe_init_progbar()` function, which initializes the stateful metrics list, is called inside the `on_test_batch_end()` method. This means that the Model has been evaluated at least once, and therefore the Model's `metrics` attribute is available for the `ProgbarLogger` to initialize the list of stateful metrics.

From `tf.keras.Model` docs:

> Note: metrics_names are available only after a keras.Model has been trained/evaluated on actual data.

**Current behavior in TF 2.4.0**

After b31f069d3abc8446a5d370c6fa65f9df0a7720b6 commit the `_maybe_init_progbar()` function is called inside `on_epoch_begin()`, `on_test_begin()` and `on_predict_begin()`, which means that the Model does not yet contain the list of compiled metrics and the `stateful_metrics` list is not initialized properly. This causes simple metrics such as `tf.keras.metrics.Accuracy` to be averaged over time and then logged to the console.
"
46711,Allow reusing existing tensors for outputs of TF_SessionRun(),"In the C API, `TF_SessionRun()` allocates new output tensors on every call. This leads to frequent allocation/deallocation and memory copies in some situations. It would be useful to be able to reuse existing tensors for output.

The current API takes `TF_Tensor** output_values` and will update that variable to point to newly allocated output tensors. I propose that if `output_values` points to existing tensors, those tensors should be used for output instead of allocating new tensors."
46708,Using the function signatures loaded from a SavedModel requires the original trackable object be kept in scope.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.7
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): `v2.4.0-rc4-71-g582c8d236cb 2.4.0`
- Python version: 3.8.5

**Describe the current behavior**

Loading a SavedModel from disk and extracting a signature from it works only while the result of `tf.saved_model.load` has not be collected by the Python garbage collector. For example, the following code fails:

```python
def load_model(path_to_saved_model):
    saved_model = tf.saved_model.load(path_to_saved_model)
    return saved_model.signatures[""serving_default""]

load_model('./my_model.ckpt')(...) # throws ""Error while reading resource variable...""
```

but this code snippet runs successfully:
```python
saved_model = tf.saved_model.load('./my_model.ckpt')
model = saved_model.signatures[""serving_default""]
model(...) # No exception is thrown
```

The issue can be worked around by manually attaching the original trackable object to the return value of the function, preventing the Python garbage collector from collecting the object:
```python
def load_model_with_backref(path_to_saved_model):
    saved_model = tf.saved_model.load(path_to_saved_model)
    model = saved_model.signatures[""serving_default""]
    model._backref_to_saved_model = saved_model
    return model
load_model('./my_model.ckpt')(...) # No exception is thrown
```

The exception thrown can, depending on the model and environment, sometimes be:
> AssertionError: Called a function referencing variables which have been deleted. This likely means that function-local variables were created and not referenced elsewhere in the program. This is generally a mistake; consider storing variables in an object attribute on first call.

The exception can also manifest as:
> FailedPreconditionError: Error while reading resource variable _AnonymousVar30 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar30/N10tensorflow3VarE does not exist.
	 [[{{node StatefulPartitionedCall/model/layer/batch_normalization_3/FusedBatchNormV3/ReadVariableOp_1}}]] [Op:__inference_signature_wrapper_11671]

This may be a similar issue to https://github.com/tensorflow/tensorflow/issues/37615.

**Standalone code to reproduce the issue**
```python
import os

# Disable ultra-verbose TF logging
os.environ[""TF_CPP_MIN_LOG_LEVEL""] = ""4""  # noqa
import tensorflow as tf


def load_model(path_to_saved_model):
    saved_model = tf.saved_model.load(path_to_saved_model)
    return saved_model.signatures[""serving_default""]


def load_model_with_backref(path_to_saved_model):
    saved_model = tf.saved_model.load(path_to_saved_model)
    model = saved_model.signatures[""serving_default""]
    model._backref_to_saved_model = saved_model
    return model


def use_model(model):
    input_tensors = [
        tensor for tensor in model.inputs if tensor.dtype != tf.resource
    ]
    return model(
        *[
            tf.random.uniform(shape=[dim or 1 for dim in _input.shape])
            for _input in input_tensors
        ]
    )


if __name__ == ""__main__"":
    import sys

    model_path = sys.argv[-1]
    try:
        use_model(load_model(model_path))
        print(
            f""â TensorFlow {tf.__version__} loaded model {model_path} without ""
            ""needing to set a back-reference to the SavedModel on the ""
            ""ConcreteFunction.""
        )
    except Exception as e:
        print(
            f""â TensorFlow {tf.__version__} failed to load model without""
            f"" setting back-reference {model_path}:\n{e}""
        )

    try:
        use_model(load_model_with_backref(model_path))
        print(
            f""â TensorFlow {tf.__version__} loaded model {model_path} by""
            "" setting a back-reference to the SavedModel on the""
            "" ConcreteFunction.""
        )
    except Exception as e:
        print(
            f""â TensorFlow {tf.__version__} failed to load model when setting""
            f"" back-reference {model_path}:\n{e}""
        )

```

When run on TensorFlow 2.4.0, the above script prints:
```
â TensorFlow 2.4.0 failed to load model without setting back-reference ../model.ckpt:
 Error while reading resource variable _AnonymousVar46 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar46/N10tensorflow3VarE does not exist.
	 [[{{node StatefulPartitionedCall/model/layer_name_here/batch_normalization_12/ReadVariableOp_1}}]] [Op:__inference_signature_wrapper_11671]

Function call stack:
signature_wrapper

â TensorFlow 2.4.0 loaded model ../model.ckpt by setting a back-reference to the SavedModel on the ConcreteFunction.
```"
46707,Converting a model with Int8 fake quant nodes from a saved model file fails,"**System information**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.15.6
- TensorFlow installed from (source or binary): TensorFlow 2.4.1 PyPI pip package.
- TensorFlow version (or github SHA if from source): 2.4.1.

**Command used to run the converter or code if youâre using the Python API**

Suppose `keras_model` is a Keras model containing QAT fake quantiser ops, like `tf.quantization.fake_quant_with_min_max_vars`. Then, the following conversion code using `from_saved_model` fails to output a valid Int8 model and throws an error.

```python
with open(""converted_saved_model.tflite"", ""wb"") as f:
    tf.keras.models.save_model(keras_model, ""tmp-saved-model"", save_format=""tf"")
    converter = tf.lite.TFLiteConverter.from_saved_model(""tmp-saved-model"")
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8
    f.write(converter.convert())
```

Note that `from_keras_model` works correctly.

See a minimal reproduction with the following colab notebook: https://colab.research.google.com/drive/1s3AkxetmaIHKcB3M69cBSVbOfhNx8106?usp=sharing

**The output from the converter invocation**

The above snippet fails with:

```
ValueError: The inference_input_type and inference_output_type must be tf.float32.
```

For more detail, see the linked colab notebook.

**Also, please include a link to the saved model or GraphDef**

Can be found in the linked colab notebook.

**Failure details**

Attempting to convert and setting the inference input/output type to int8 causes the error above.

Attempting to convert without setting those types (such that they default to float) doesn't cause an error but does yield a broken Int8 model with lots of dangling quant/dequant ops pairs:

<img width=""500"" alt=""image"" src=""https://user-images.githubusercontent.com/7688302/105897373-f9673a80-600f-11eb-95ad-683671cbf825.png"">"
46706,"Tesnorflow Sparse operations are slow - Comparison between Dense, SparseTensor and raw_ops sparse ","**System information**
- Tensorflow 2.4.0
- colab - basic settings

**Description**

I am trying to convert my code to run with `Sparse Matrices` on Tensorflow but looks like the performance is quite bad. I tried using `SparseTensor` and `tf.raw_ops.Sparse...` functions. Below is a comparsion for some of the functions. Pleaese refer the [colab code](https://colab.research.google.com/drive/1urRVOW4hR3i_7koNtXOnUTa5bhl7WXPC?usp=sharing) to generate the results.  

Following results are for a matrix with 75% zeros and time in seconds.  

|Method | Dense | SparseTensor | Raw_ops|
| --- | --- | --- | --- |
|Element-wise Multiplication	     | 0.0511	   |  0.5765	      |    0.5677|
|Exponential	                             |0.0438   	   |   0.0121	      |   0.0149 |
|Devision	                                     | 0.0625	   |   0.5718	      |   0.5614 |
|Reduce Sum                                |0.0194	   |    1.1918	      |   1.1648 |
|Matrix Multiplication	              |0.0576	   |   0.1589	      |  0.1553  |

Functions used:
|Method | Dense | SparseTensor | Raw_ops|
| --- | --- | --- | --- |
|Element-wise Multiplication	     | `tf.multiply()`	   | ` *`	      |   `tf.raw_ops.SparseDenseCwiseMul()`|
|Exponential	                             |`tf.exp()` 	   |  ` tf.sparse.map_values(tf.exp,x)`	      |` tf.exp(`)    |
|Devision	                                     | `tf.divide()`	   |  `/`      |  ` tf.raw_ops.SparseDenseCwiseDiv()` |
|Reduce Sum                                |`tf.reduce_sum()`   |    `tf.sparse.reduce_sum()`	      |   `tf.raw_ops.SparseReduceSum()` |
|Matrix Multiplication	              |`tf.matmul()`	   |  `tf.sparse.sparse_dense_matmul()`	      |  `tf.raw_ops.SparseTensorDenseMatMul()`  |


As per the results on sparse tensors, elementvise operations take 10x while Reduce_sum has taken 100x time to run.  

Is Tensorflow Sparse operations are written focusing on optimising the memory and not run time? Is there a fix for this? 

"
46705,x,x
46702,tf.data.Dataset.list_files is increadibly slow on Tensorflow 2.3.1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 11.1
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

Running the following snippet on Tensorflow 2.3.1 takes several minutes:

```python
import tensorflow as tf
tf.data.Dataset.list_files(""s3://commoncrawl/*.txt"")
```

The same snippet on Tensorflow 2.4.1 takes under a second. There is a single file in this path that matches. This makes this API unusable on 2.3.1.

If I run the command with `AWS_LOG_LEVEL=0` then I see there are a huge number of these messages:

```
2021-01-26 17:17:35.606039: I tensorflow/core/platform/s3/aws_logging.cc:71] Connection has been released. Continuing.
2021-01-26 17:17:35.607345: I tensorflow/core/platform/s3/aws_logging.cc:71] Connection has been released. Continuing.
2021-01-26 17:17:35.610330: I tensorflow/core/platform/s3/aws_logging.cc:71] Connection has been released. Continuing.
```

**Describe the expected behavior**

The snippet should execute instantly

**Standalone code to reproduce the issue**

Export your environment variables:

```
export AWS_REGION=us-east-1
export AWS_LOG_LEVEL=0
```

then run the following code:

```
import tensorflow as tf
tf.data.Dataset.list_files(""s3://commoncrawl/*.txt"")
```

**Other info / logs**

I've attached a complete log from running the above snippet. It's very large.

[out.log](https://github.com/tensorflow/tensorflow/files/5874958/out.log)"
46701,floating point exception in tf.signal.stft ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
floating point exception in `tf.signal.stft`

**Describe the expected behavior**
expect no crash


**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.signal.stft(signals=np.array([3.2031196e+38], dtype=np.float32), frame_step=1, frame_length=1, fft_length=False, pad_end=True)
~~~

Output:
~~~python
Floating point exception (core dumped)
~~~"
46700,tf.math.reduce_prod aborts when keepdims contain large values,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
`tf.math.reduce_prod` aborts when `keepdims` contain large values

**Describe the expected behavior**
expect an exception message if the input is not expected, instead of crash.

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.math.reduce_prod(input_tensor=1, keepdims=np.array([63600, 1], dtype=np.float16))
~~~


Output:
~~~python
2021-01-26 17:02:24.497049: F ./tensorflow/python/eager/pywrap_tensor_conversion.h:58] Check failed: !PyErr_Occurred()
Aborted (core dumped)
~~~"
46699,tf.keras.backend.constant abortion,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
`tf.keras.backend.constant` abortion

**Describe the expected behavior**
expect an exception message if the input is not expected, instead of crash.

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.keras.backend.constant(value=np.ones((0,1,1)), shape=[36,23,53,24,117,82,47,124,112,69,53,0])
~~~

Output:
~~~python
2021-01-26 16:30:57.093291: F tensorflow/core/framework/tensor_shape.cc:405] Check failed: 0 <= new_num_elements (0 vs. -1)
Aborted (core dumped)
~~~"
46698,tf.sequence_mask abortion when lengths contains large value,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A



**Describe the current behavior**
`tf.sequence_mask` abortion when lengths contains large value

**Describe the expected behavior**
expect an exception message if the input is not expected, instead of crash.
**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.sequence_mask(lengths=np.array([3.05524638e+307], dtype=np.float64))
~~~

Output:
~~~python
2021-01-26 16:02:42.088240: F tensorflow/core/framework/tensor_shape.cc:187] Non-OK-status: InitDims(dim_sizes) status: Internal: Expected shape dimensions to be non-negative, got -9223372036854775808
Aborted (core dumped)
~~~

"
46696,tf.math.segment_min abortion when segment_ids contains large value,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
`tf.math.segment_min` abortion when `segment_ids` contains large value
**Describe the expected behavior**
expect an exception message if the input is not expected, instead of crash.

**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.math.segment_min(data=np.ones((1,2,1,1,1), dtype=np.uint16), segment_ids=[5053997376933981534])
~~~

output:
~~~python
2021-01-26 15:49:10.870684: F tensorflow/core/framework/tensor_shape.cc:405] Check failed: 0 <= new_num_elements (0 vs. -8338749319841588546)
Aborted (core dumped)
~~~"
46693,tf.keras.backend.reshape abortion when shape contain large values,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A


**Describe the current behavior**
`tf.keras.backend.reshape` abortion when `shape` contain large values

**Describe the expected behavior**
expect an exception message if the input is not expected, instead of crash. 


**Standalone code to reproduce the issue**
~~~python
import tensorflow as tf
import numpy as np
tf.keras.backend.reshape(x=[1], shape=np.array([21943, 45817, 30516, 61760, 38987], dtype=np.uint16))
~~~

Output:
~~~python
2021-01-26 15:32:50.289333: F tensorflow/core/framework/tensor_shape.cc:405] Check failed: 0 <= new_num_elements (0 vs. -1)
Aborted (core dumped)
~~~"
46692,"Cannot copy between a TensorFlowLite tensor with shape [1, 1917, 4] and a Java object with shape [1, 10,4]","Im useing tensorflow - object detection my questions is like this but!

https://stackoverflow.com/questions/57393407/java-lang-illegalargumentexception-cannot-copy-between-a-tensorflowlite-tensor

**java.lang.IllegalArgumentException: Cannot copy between a TensorFlowLite tensor with shape [1, 1917, 4] and a Java object with shape [1, 10,4].**

a guy answerd to this questions and sayed your should change in python side! but he didnt talk about which lines or which .py codes Im useing mobile_ssd_v2_float and too many people cant solve it! Is there any answers for this question?

this is pic of my .tflite file form Netron
![yez6b](https://user-images.githubusercontent.com/42836468/105861333-d9317e80-6003-11eb-91a4-452a60b7e632.png)
"
46690,predictions = model(inputs) outputs nan,"Hi

This is a great project and is very useful, but I have encountered an error with model predicting

I have used an lstm as the model input. Once I run window.plot(model=lstm_model) the output of predictions is just a 2D array with ""nan"" as each value. The shape of this array is 2, 79, 1

Please help

P.S. Here's my code for reference

print(""Initiating the time series forcasting module"")

print(""Importing modules"")
import pandas as pd
import os
import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import tensorflow as tf

print(""Collecting data"")
df = pd.read_csv(""data.csv"")
dates = pd.to_datetime((df.pop(""Date"")), format = ""%Y/%m/%d"")

print(""Splitting data"")
column_indices = {name: i for i, name in enumerate(df.columns)}
n = len(df)
train_df = df[0:int(n*0.9)]
test_df = df[int(n*0.9):]
print(str(len(train_df)) + "" plots for training"")
print(str(len(test_df)) + "" plots for testing"")
num_features = df.shape[1]

print(""Normalizing data"")
train_mean = train_df.mean()
train_std = train_df.std()
train_df = (train_df - train_mean) / train_std
test_df = (test_df - train_mean) / train_std
df_std = (df - train_mean) / train_std

print(""Creating classes"")
class WindowGenerator():
    def __init__(self, input_width, label_width, shift,
                label_columns=None, train_df=train_df, test_df=test_df):
        print(""Generating windows"")
        self.train_df = train_df
        self.test_df = test_df
        
        self.label_columns = label_columns
        if label_columns is not None:
            self.label_column_indices = {name: i for i, name in
                                         enumerate(label_columns)}
        self.column_indices = {name: i for i, name in
                               enumerate(train_df.columns)}
        self.input_width = input_width
        self.label_width = label_width
        self.shift = shift
        
        self.total_window_size = input_width + shift
        self.input_slice = slice(0, input_width)
        self.input_indices = np.arange(self.total_window_size)[self.input_slice]
        
        self.label_start = self.total_window_size - self.label_width
        self.labels_slice = slice(self.label_start, None)
        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]
    
    def __repr__(self):
        return ""\n"".join([""Total window size: "" + str(self.total_window_size),
                          ""Input indices: "" + str(self.input_indices),
                          ""Label indices: "" + str(self.label_indices),
                          ""Label column names: "" + str(self.label_columns)])
    
    def split_window(self, features):
        print(""Splitting windows"")
        inputs = features[:, self.input_slice, :]
        labels = features[:, self.labels_slice, :]
        if self.label_columns is not None:
            labels = tf.stack(
                [labels[:, :, self.column_indices[name]] for name in self.label_columns],
                axis=-1)
        inputs.set_shape([None, self.input_width, None])
        labels.set_shape([None, self.label_width, None])
        return inputs, labels
    
    def plot(self, plot_col, model=None, max_subplots=3):
        print(""Plotting data"")
        inputs, labels = self.example
        plt.figure(figsize=(12,8))
        plot_col_index = self.column_indices[plot_col]
        max_n = min(max_subplots, len(inputs))
        for n in range(max_n):
            plt.subplot(3,1,n+1)
            plt.ylabel(plot_col)
            plt.plot(self.input_indices, inputs[n, :, plot_col_index],
                     label=""Inputs"", marker=""."", zorder=-10)
            if self.label_columns:
                label_col_index = self.label_column_indices.get(plot_col, None)
            else:
                label_col_index = plot_col_index
                
            if plot_col_index is None:
                continue
            
            plt.scatter(self.label_indices, labels[n, :, label_col_index],
                        edgecolors=""k"", label=""Labels"", c='#2ca02c', s=64)
            
            if model is not None:
                predictions = model(inputs)
                plt.scatter(self.label_indices, predictions[n, :, label_col_index],
                    marker='X', edgecolors='k', label='Predictions',
                    c='#ff7f0e', s=64)
            if n == 0:
                plt.legend()
        plt.xlabel(""Date"")
        plt.show()
    
    def make_ds(self,data):
        print(""Generating dataset"")
        data = np.array(data, dtype=np.float32)
        ds = tf.keras.preprocessing.timeseries_dataset_from_array(
            data=data,
            targets=None,
            sequence_length=self.total_window_size,
            sequence_stride=1,
            shuffle=True,
            batch_size=32,)
        ds = ds.map(self.split_window)
        return ds
    
    @property
    def train(self):
        return self.make_ds(self.train_df)
    
    @property
    def test(self):
        return self.make_ds(self.test_df)
    
    @property
    def example(self):
        result = getattr(self, ""_example"", None)
        if result is None:
            result = next(iter(self.train))
            self._example = result
        return result
    
class Baseline(tf.keras.Model):
  def __init__(self, label_index=None):
    print(""Creating baseline model"")
    super().__init__()
    self.label_index = label_index

  def call(self, inputs):
    if self.label_index is None:
      return inputs
    result = inputs[:, :, self.label_index]
    return result[:, :, tf.newaxis]
    
wide_window = WindowGenerator(
    input_width=24, label_width=24, shift=24,
    label_columns=['ConfirmedCases'])

def compile_and_fit(model, window, patience=2, MAX_EPOCHS=20):
  model.compile(loss=tf.losses.MeanSquaredError(),
                optimizer=tf.optimizers.Adam(),
                metrics=[tf.metrics.MeanAbsoluteError()])

  history = model.fit(window.train, epochs=MAX_EPOCHS)
  return history

lstm_model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(32, return_sequences=True),
    tf.keras.layers.Dense(units=1)
])

history = compile_and_fit(lstm_model, wide_window)

wide_window.plot(model=lstm_model, plot_col=""ConfirmedCases"")

"
46689,Bazel cannot grab libstdc++ when paths for them are not default.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: master branch
- Python version: 3.6
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: 10.1 / 7.6.5
- GPU model and memory: Titan Xp



**Describe the problem**
During the installation, bazel cannot link the path for LD_LIBRARY_PATH.
Errors occur when bazel compiles `tensorflow/compiler/...`

**Provide the exact sequence of commands / steps that you executed before running into the problem**
1. Install tensorflow from source with non-default path for LD_LIBRARY_PATH. (e.g. ~/opt/gcc/8.3.0/lib64)

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I added some lines into `tensorflow/core/kernels/mlir_generated/build_defs.bzl` to fix this and it works.
```
+++ b/tensorflow/core/kernels/mlir_generated/build_defs.bzl
@@ -53,6 +53,7 @@ def _gen_mlir_op_impl(ctx):
                 ctx.outputs.out.path,
             )
         ),
+        use_default_shell_env=True,
     )
 
 _gen_mlir_op_rule = rule(
@@ -114,6 +115,7 @@ def _gen_kernel_fatbin_impl(ctx):
             ""--enable_ftz=%s"" % (ctx.attr.data_type == ""f32""),
         ],
         mnemonic = ""compile"",
+        use_default_shell_env=True,
     )
```
"
46687,[TF2] Converted quantized TFLite model suffers severe precision/recall drop,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS High Sierra
- TensorFlow installed from (source or binary): Source
- TensorFlow version (or github SHA if from source): 2.5.0-dev20201209
- Trained on custom dataset using  https://github.com/tensorflow/models/blob/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config 
- tflite_runtime version: 2.5.0


**Command used to run the converter or code if youâre using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
converter = tf.lite.TFLiteConverter.from_saved_model('/Path/To/Tensorflow/Model/saved_model')
def representative_data_gen():
  image_urls = glob.glob(os.path.join(""/Path/To/Imageset"",'*'))[:250]

  for image in image_urls:
    try:
      img = cv2.imread(image)
      img = cv2.resize(img, (300, 300))
      img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)
      img = img/255.0 
      img = img.astype(np.float32)
      image_list.append(img)
    except Exception as e:
        print(f'{str(e)} : {image}')
        continue

  image_list = np.array(image_list)
  img = tf.data.Dataset.from_tensor_slices(image_list).batch(1)
  for i in img.take(250):
    yield [i]

converter.representative_dataset = representative_data_gen
converter.optimizations = [tf.lite.Optimize.DEFAULT] # size and latency
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS]
converter.target_spec.supported_types = [tf.int8]
tflite_quant_model = converter.convert()

#Save
tflite_models_dir = pathlib.Path(""/filepath/quantized_export_tflite_uint8"")
tflite_models_dir.mkdir(exist_ok=True, parents=True)
tflite_model_quant_file = tflite_models_dir/""quantized_model.tflite""
tflite_model_quant_file.write_bytes(tflite_quant_model)
```

**The output from the converter invocation**

```
# Compiles tflite model successfully.
```

**Failure details**

The Tensorflow model used is a custom trained version of the MobileNet SSD V2 model using the Tensorflow Object Detection API (TF V2). This model is to be deployed on the Google Coral Dev board, and as such requires full integer quantisation (falling back to float32 for the final custom op) when converting to TFLite format. To export the model after training, export_tflite_graph_tf2.py is used (https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md) , before the quantization step is carried out. Once the post training quantization is complete, the resulting converted .tflite model runs successfully, however upon evaluation (using coco metrics), suffers a severe drop (>50% decrease) in performance compared to the original model, which achieves very high precision/recall when evaluated in the same manner. 

The code used to generate inference is below:

```
# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=""quantized_model.tflite"")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
width = input_details[0]['shape'][2]
height = input_details[0]['shape'][1]

# Load image
img = cv2.imread(image)
(H, W) = img.shape[:2] # Used to multiply normalized output bounding box co-ords to return to image coords
img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)
img = cv2.resize(img, (width, height))

if input_details[0][""dtype""] == np.uint8:
        input_scale, input_zero_point = input_details[0][""quantization""]
        img = img / input_scale + input_zero_point

img = np.expand_dims(img, axis=0)
img = np.uint8(img)

# Generate inference
interpreter.set_tensor(input_details[0]['index'], img)
interpreter.invoke()

# Output
boxes = interpreter.get_tensor(output_details[0]['index'])[0]
classes = interpreter.get_tensor(output_details[1]['index'])[0]
scores = interpreter.get_tensor(output_details[2]['index'])[0]

```"
46686,Model's allocation of node fails after conversion to TFLite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux 2
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source): tf-nightly (2.5.0)


**Command used to run the converter or code if youâre using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
  model_concrete_function = model.inference_decode.get_concrete_function()
  converter = tf.lite.TFLiteConverter.from_concrete_functions(
      [model_concrete_function]
  )
  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]
  
  if args.quantized:
      converter.optimizations = [tf.lite.Optimize.DEFAULT]
      output_file_name = os.path.join(args.outdir, 'model_quant.tflite')
  else:
      output_file_name = os.path.join(args.outdir, 'model.tflite')
  
  tflite_model = converter.convert()
```

**The output from the converter invocation**

```
2021-01-26 09:30:17.656931: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-01-26 09:30:17.656958: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/dmmatwic/anaconda3/envs/tflite_x86/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:37: UserWarning: You are currently using a nightly version of TensorFlow (2.5.0-dev20210125).
TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not.
If you encounter a bug, do not file an issue on GitHub.
warnings.warn(
2021-01-26 09:30:20.220470: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-01-26 09:30:20.220498: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-01-26 09:30:20.220517: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dev-dsk-dmmatwic-1b-a5a0da5a.eu-west-1.amazon.com): /proc/driver/nvidia/version does not exist
2021-01-26 09:30:20.220718: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:From /home/dmmatwic/anaconda3/envs/tflite_x86/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5039: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.
Instructions for updating:
The validate_indices argument has no effect. Indices are always validated on CPU and never validated on GPU.
2021-01-26 09:30:22,167 (deprecation:528) WARNING: From /home/dmmatwic/anaconda3/envs/tflite_x86/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5039: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.
Instructions for updating:
The validate_indices argument has no effect. Indices are always validated on CPU and never validated on GPU.
2021-01-26 09:30:22.977251: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2021-01-26 09:30:22.977359: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2021-01-26 09:30:22.995718: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2500000000 Hz
2021-01-26 09:30:23.040599: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:935] Optimization results for grappler item: graph_to_optimize
function_optimizer: Graph size after: 900 nodes (122), 1564 edges (136), time = 10.878ms.
function_optimizer: Graph size after: 900 nodes (0), 1564 edges (0), time = 9.301ms.
Optimization results for grappler item: while_body_3883
function_optimizer: function_optimizer did nothing. time = 0.006ms.
function_optimizer: function_optimizer did nothing. time = 0.002ms.
Optimization results for grappler item: while_body_4324
function_optimizer: function_optimizer did nothing. time = 0.004ms.
function_optimizer: function_optimizer did nothing. time = 0.001ms.
Optimization results for grappler item: while_cond_3882
function_optimizer: function_optimizer did nothing. time = 0.004ms.
function_optimizer: function_optimizer did nothing. time = 0.001ms.
Optimization results for grappler item: while_cond_4323
function_optimizer: function_optimizer did nothing. time = 0.003ms.
function_optimizer: function_optimizer did nothing. time = 0.001ms.
2021-01-26 09:30:24,125 (lite:659) INFO: Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False
2021-01-26 09:30:24.216881: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:332] Ignored output_format.
2021-01-26 09:30:24.216915: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:335] Ignored drop_control_dependency.
2021-01-26 09:30:24.305204: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var MLIR_CRASH_REPRODUCER_DIRECTORY to enable.
2021-01-26 09:30:25.025058: I tensorflow/lite/tools/optimize/quantize_weights.cc:233] Skipping quantization of tensor arg5 because it has no allocated buffer.
2021-01-26 09:30:25.026738: I tensorflow/lite/tools/optimize/quantize_weights.cc:233] Skipping quantization of tensor arg5 because it has no allocated buffer.
2021-01-26 09:30:25,077 (convert_model:102) INFO: Model of size 10.273849 MBs saved to model_tflite/model_quant.tflite
```

**Also, please include a link to the saved model or GraphDef**

```
No link because it's internal company's model
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
 I get
```
ERROR: tensorflow/lite/kernels/kernel_util.cc:404 d1 == d2 || d1 == 1 || d2 == 1 was not true.
ERROR: Node number 3 (ADD) failed to prepare.
```
when running


**TfLiteInterpreterAllocateTensors(interpreter)**

in TFLite C++ API.
The conversion to tflite model runs fine.

The node looks like that in Netron

![add_node](https://user-images.githubusercontent.com/32575801/105830725-268efb00-5fc6-11eb-804f-18d16651d07d.png)


I'm not sure what exactly does this error mean. As far as I can see these conditions are met, with [1, 128] and [1, 128, 128] d1 is in fact equal to d2, while d1 and d2 also being 1? Unless I misunderstood how it works. This happens during tensors allocation, so I understand that this has nothing to do with input data shapes? Thanks :)"
46685,"get ""Tensor(""args_0:0"", shape=(), dtype=string)"" when using tf.data.TextLineDataset.map()","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux version 3.16.0-7-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 3.16.59-1 (2018-10-03)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): unknown 1.15.3
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: no gpu used
- GPU model and memory: no gpu used

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

I am reading data from a hdfs path using TextLineDataset. I use `for` to iter over the dataset everything goes well but when it comes to `map`, all I get is `Tensor(""args_0:0"", shape=(), dtype=string)` (I don'y know there it comes from). The issue can be reproduced with tf ver 2.4.1.

Here is the code:

```python
path = 'hdfs://path-to-file'
dataset = tf.data.Dataset.list_files(path)
dataset = tf.data.TextLineDataset(dataset)
for line in dataset:
    print(line)
```

output using `for`:

```
...
tf.Tensor(b'1\t[1, 15, 1907, 190706, 19070605, 161, ""nan"", ""nan"", ""nan"", 2, 7, 37, ""nan"", ""nan"", 1, 0, ""nan"", ""nan"", 1819, 181903, 18190301, ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", 0, 1, 1, 1, 0, 0, ""201"", ""2.486379972076975"", ""1"", ""0"", ""0.0"", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]', shape=(), dtype=string)
tf.Tensor(b'0\t[1, 13, 1909, 190911, 19091101, 195, ""nan"", ""nan"", ""nan"", 2, ""nan"", ""nan"", ""nan"", ""nan"", 1, 0, ""nan"", ""nan"", 1909, 190901, 19090101, ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", ""nan"", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]', shape=(), dtype=string)
...
```

---

```python
def parse_line(line):
    print(line)
    return line

path = 'hdfs://path-to-file'
dataset = tf.data.Dataset.list_files(path)
dataset = tf.data.TextLineDataset(dataset).map(lambda x: parse_line(x))
```

output using `map`: (this is all I get)

```
Tensor(""args_0:0"", shape=(), dtype=string)
```

**Describe the expected behavior**

map func should get element in the dataset rather than `Tensor(""args_0:0"", shape=(), dtype=string)`

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

provided above

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

no log
"
46684,Time issue in micro_speec,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source):
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

When the _micro_speech_ loop is executed for the first time, `current_time` is 0. In this case, the Feature Provider requests `kFeatureSliceCount` audio data packages of `kFeatureSliceDurationMs` length. However, since `previous_time` is set equal to  `current_time` after calling `feature_provider->PopulateFeatureData()`. So running the next time, current time has increased by the number of ms that the audio provider has been recording but also have 990 ms of data already been used. The Feature Provider just sees the difference in the recorded time since the last call and asks for more data that should be available. But since audio provider has no data, it waits till the data has been recorded which takes exactly the time that is missing which are 990 ms.

Am I the only one with this issue? Is it my mistake or common?

There are multiple ways to fix this: 
1) start the time of the audio provider at -990 ms
2) don't let the feature provider request data if there is none recorded (needs audio provider init to be called separately I guess)
3) don't set `previous_time` to `current_time` but to `how_many_new_slices * kFeatureSliceStrideMs`


"
46683,micro_speech: ESP32 Audio Codec Chip not initialized,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): not sure
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32 LyraT v4.3

The example _micro_speech_ does configure an I2S bus to receive audio data. This seems to me as if there is an audio codec chip required as provided on the LyraT eval board. However, the audio codec chip is not being initialized so it does not know that it is supposed to send audio data with 16k sampling rate, 16 bit resolution, one channel and act as a replica.

[Here](https://github.com/tensorflow/tensorflow/tree/dec8e0b11f4f87693b67e125e67dfbc68d26c205/tensorflow/lite/micro/examples/micro_speech#deploy-to-esp32) it says that two boards have been tested. The DevKit has no microphone and the ESP-EYE has a ""digital mic"". May the EYE'S mic just sends data with this spec by default; I could not find any information about it. So the code might deploy to both and run on both but I doubt it works.

For me, it fixed it to add the initialization of the ES8388. While doing so, I removed the ""manual"" I2S-handling and replaced it with an audio pipeline.

Maybe it would not harm the example to run on the ESP-EYE, if the audio codec chip was being initialized by default or the board information from menu_config of the IDF would help.
"
46682,how can i use Sequential to achieve the process of Forward propagation,"I really want know how to use Sequential to achieve the process of Forward propagation,like sess,run
"
46680,When ryzen build tf_to_gpu_binary.exe failed: error executing command error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS : Windows 10 20H2
- TensorFlow version: 2.4.1
- Python version: python=3.9
- Building anaconda env
- Bazel version : using bazelisk
- CUDA/cuDNN version: cuda 11.1, cuDNN 8.0.5
- GPU model and memory: RTX2080, 8G



When i build tensorflow in 10900k build succeed. But error is occur when i try to build ryzen 5600x or ryzen3700x.


> INFO: Found 1 target...
INFO: Deleting stale sandbox base C:/users/user/_bazel_user/d3ty3xtx/sandbox
ERROR: C:/users/user/documents/cpplibrarys/tensorflow/tensorflow/core/kernels/mlir_generated/BUILD:149:1: compile tensorflow/core/kernels/mlir_generated/abs_i64_kernel_cubin.sm_75.bin failed (Exit 1): tf_to_gpu_binary.exe failed: error executing command
  cd C:/users/user/_bazel_user/d3ty3xtx/execroot/org_tensorflow
bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_gpu_binary.exe --same_shape=0,1 --unroll_factors=4 --tile_sizes=256 --arch=sm_75 --input=bazel-out/x64_windows-opt/bin/tensorflow/core/kernels/mlir_generated/abs_i64.mlir --output=bazel-out/x64_windows-opt/bin/tensorflow/core/kernels/mlir_generated/abs_i64_kernel_cubin.sm_75.bin
Execution platform: @local_execution_config_platform//:platform
2021-01-26 17:38:55.379641: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:194] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
warning: Linking two modules of different data layouts: 'C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.1/nvvm/libdevice/libdevice.10.bc' is 'e-i64:64-v16:16-v32:32-n16:32:64' whereas 'acme' is 'e-i64:64-i128:128-v16:16-v32:32-n16:32:64'
2021-01-26 17:38:55.768832: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0
2021-01-26 17:38:55.845907: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295
2021-01-26 17:38:55.847744: E tensorflow/compiler/mlir/tools/kernel_gen/tf_to_gpu_binary.cc:97] Internal: Lowering to LLVM IR failed.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: C:/users/user/documents/cpplibrarys/tensorflow/tensorflow/python/data/experimental/service/BUILD:11:1 compile tensorflow/core/kernels/mlir_generated/tanh_f32_kernel_cubin.sm_75.bin failed (Exit 1): tf_to_gpu_binary.exe failed: error executing command
  cd C:/users/user/_bazel_user/d3ty3xtx/execroot/org_tensorflow
bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_gpu_binary.exe --same_shape=0,1 --unroll_factors=4 --tile_sizes=256 --arch=sm_75 --input=bazel-out/x64_windows-opt/bin/tensorflow/core/kernels/mlir_generated/tanh_f32.mlir --output=bazel-out/x64_windows-opt/bin/tensorflow/core/kernels/mlir_generated/tanh_f32_kernel_cubin.sm_75.bin
Execution platform: @local_execution_config_platform//:platform
INFO: Elapsed time: 69.840s, Critical Path: 24.63s
INFO: 0 processes.
FAILED: Build did NOT complete successfully"
46679,Integer quantization converts bias of 32-bit float type in conv2d to 8-bit int type on TFLite ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  **Ubuntu 16.04**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **RPI 3b+**
- TensorFlow installed from (source or binary): **source**
- TensorFlow version (use command below): **2.3.1**
- Python version: **3.6**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):  **5.4.0**
- CUDA/cuDNN version: 
- GPU model and memory: 

**Describe the current behavior**
![error](https://user-images.githubusercontent.com/47438617/105789041-06127100-5fc5-11eb-8430-249c2baf5b08.png)

Used network is a kind of resnet18 and this network is applied int8 quantization by using TFLite. But bias of one of the conv2d has int8 type. The other bias have int32 type. 

Then, inference with this model is not worked, like as below.
![image](https://user-images.githubusercontent.com/47438617/105789822-740b6800-5fc6-11eb-8819-95f04868bc92.png)
**Describe the expected behavior**



**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

I share you kears and tflite versions of resnet18.
[benchmark model.zip](https://github.com/tensorflow/tensorflow/files/5870712/benchmark.model.zip)


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46676,tf.raw_ops.PopulationCount for uint32 not supported but documented,"
**System information**

- OS Platform and Distribution:  (Intel Linux Ubuntu 20.04):
- TensorFlow installed from (source or binary): python pip
- TensorFlow version: '2.4.1'
- Python version: Python 3.8.6
- CPU

**Describe the current behavior**
tf.raw_ops.PopulationCount of array with type uint32 fails.

**Describe the expected behavior**
In api documentation for raw_ops.PopulationCount for Arg x: 
A Tensor. Must be one of the following types: int8, int16, int32, int64, uint8, uint16, uint32, uint64. 

So this is either a documentation error or more likely a bug, because feature is important on uint32.

**Standalone code to reproduce the issue**
a = numpy.array([3], dtype = numpy,uint32)
tf.raw_ops.PopulationCount(x=a)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/rst/PYTHON/ng3py/lib/python3.8/site-packages/tensorflow/python/util/tf_export.py"", line 404, in wrapper
    return f(**kwargs)
  File ""/home/rst/PYTHON/ng3py/lib/python3.8/site-packages/tensorflow/python/ops/gen_bitwise_ops.py"", line 547, in population_count
    return population_count_eager_fallback(
  File ""/home/rst/PYTHON/ng3py/lib/python3.8/site-packages/tensorflow/python/ops/gen_bitwise_ops.py"", line 570, in population_count_eager_fallback
    _result = _execute.execute(b""PopulationCount"", 1, inputs=_inputs_flat,
  File ""/home/rst/PYTHON/ng3py/lib/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.NotFoundError: Could not find device for node: {{node PopulationCount}} = PopulationCount[T=DT_UINT32]
All kernels registered for op PopulationCount:
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_INT32]
  device='GPU'; T in [DT_INT16]
  device='GPU'; T in [DT_UINT16]
  device='GPU'; T in [DT_INT8]
  device='GPU'; T in [DT_UINT8]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_INT16]
  device='CPU'; T in [DT_UINT16]
  device='CPU'; T in [DT_INT8]
  device='CPU'; T in [DT_UINT8]
 [Op:PopulationCount]
"
46674,[Tensorflow Lite] Build static framework for iOS,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Catalina
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5 (nightly)
- Python version: N/A
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 3.7
- GCC/Compiler version (if compiling from source): Xcode 12.3
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the problem**
I am trying to cross compile Tensorflow Lite for iOS. I would like to build a **static** framework. Here is the build command I used:

`bazel build --config=ios_arm64 -c opt //tensorflow/lite/ios:TensorFlowLiteC_framework`

The `TensorFlowLiteC_framework` target is defined in `tensorflow/tensorflow/lite/ios/BUILD.apple` as 

```
tflite_ios_static_framework(
    name = ""TensorFlowLiteC_framework"",
    hdrs = [
        "":c_api.h"",
        "":common.h"",
        "":xnnpack_delegate.h"",
        ""//tensorflow/lite/c:c_api_types.h"",
    ],
    allowlist_symbols_file = "":allowlist_TensorFlowLiteC.txt"",
    bundle_name = ""TensorFlowLiteC"",
    minimum_os_version = TFL_MINIMUM_OS_VERSION,
    deps = [
        "":tensorflow_lite_c"",
    ],
)
```

I had expected the resulting framework (please see the file attached below) to be a static framework, but it appears to be a dynamic framework instead. Inside the `TensorFlowLiteC.framework` folder, there is a binary file `TensorFlowLiteC`. If I do `file TensorFlowLiteC`, I get:

```
TensorFlowLiteC: Mach-O universal binary with 1 architecture: [arm64:Mach-O 64-bit object arm64]
TensorFlowLiteC (for architecture arm64):	Mach-O 64-bit object arm64
```
This appears to be a dynamic lib file to me. As far as I know, if this was a static archive, I should have gotten: `current ar archive`.

[TensorFlowLiteC.framework.zip](https://github.com/tensorflow/tensorflow/files/5870061/TensorFlowLiteC.framework.zip)

Is there a way to actually build Tensorflow Lite into an actual static framework for iOS?

**Provide the exact sequence of commands / steps that you executed before running into the problem**

`bazel build --config=ios_arm64 -c opt //tensorflow/lite/ios:TensorFlowLiteC_framework`

"
46673,Tensorflow does not work with RTX 3070 on Windows,"**System information**
- Code attached below
- OS: Windows 10
- TensorFlow installed from binary (`pip3 install tensorflow`)
- TensorFlow version: tried latest stable v2.4.0-49-g85c8b2a817f 2.4.1
- Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)] on win32
- CUDA/cuDNN version: cuda_11.2.0_460.89_win10\cudnn-11.1-v8.0.5.39
- GPU drivers: 460.89
- GPU model and memory: seems to be recognized correctly by TF- GeForce RTX 3070 computeCapability: 8.6 coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s



**Describe the current behavior**
Getting error:
```
2021-01-25 21:36:01.042433: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
Epoch 1/500
2021-01-25 21:36:03.304809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-01-25 21:36:03.880223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-01-25 21:36:03.911531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-01-25 21:36:04.515409: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2021-01-25 21:36:04.515498: E tensorflow/stream_executor/cuda/cuda_dnn.cc:340] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows
2021-01-25 21:36:04.515607: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cudnn_rnn_ops.cc:1514 : Unknown: Fail to find the dnn implementation.
Traceback (most recent call last):
  File ""<input>"", line 1, in <module>
  File ""C:\Users\Aleksander\.IntelliJIdea2018.3\config\plugins\python\helpers\pydev\_pydev_bundle\pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""C:\Users\Aleksander\.IntelliJIdea2018.3\config\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/Workspace_GpwScan/dnn/sandbox/reproduce_issue.py"", line 110, in <module>
    callbacks=[checkpoint, tensorboard])
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\keras\engine\training.py"", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\eager\def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\eager\def_function.py"", line 888, in _call
    return self._stateless_fn(*args, **kwds)
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\eager\function.py"", line 2943, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\eager\function.py"", line 1919, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\eager\function.py"", line 560, in call
    ctx=ctx)
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\eager\execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnknownError:    Fail to find the dnn implementation.
	 [[{{node CudnnRNN}}]]
	 [[sequential/lstm/PartitionedCall]] [Op:__inference_train_function_8782]
Function call stack:
train_function -> train_function -> train_function
```
[tf_2.4.1_issue_on_3070.txt](https://github.com/tensorflow/tensorflow/files/5869537/tf_2.4.1_issue_on_3070.txt)


Tried also with latest ```nightly 2.5.0.dev20210125``` ending up with error:
```
2021-01-25 21:31:05.429799: E tensorflow/stream_executor/dnn.cc:618] CUDNN_STATUS_EXECUTION_FAILED
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1975): 'cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'
2021-01-25 21:31:05.430291: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cudnn_rnn_ops.cc:1926 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1, 128, 1, 128, 256, 128] 
Traceback (most recent call last):
  File ""<input>"", line 1, in <module>
  File ""C:\Users\Aleksander\.IntelliJIdea2018.3\config\plugins\python\helpers\pydev\_pydev_bundle\pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""C:\Users\Aleksander\.IntelliJIdea2018.3\config\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/Workspace_GpwScan/dnn/sandbox/reproduce_issue.py"", line 108, in <module>
    callbacks=[checkpoint, tensorboard])
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\keras\engine\training.py"", line 1134, in fit
    tmp_logs = self.train_function(iterator)
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\eager\def_function.py"", line 818, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\eager\def_function.py"", line 846, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\eager\function.py"", line 2994, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\eager\function.py"", line 1939, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\eager\function.py"", line 569, in call
    ctx=ctx)
  File ""C:\Workspace_GpwScan\stubs\tensorflow\python\eager\execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InternalError:    Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1, 128, 1, 128, 256, 128] 
	 [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]
	 [[Adam/gradients/PartitionedCall_2]] [Op:__inference_train_function_8936]
Function call stack:
train_function -> train_function -> train_function
```
[tf_nightly_issue_on_3070.txt](https://github.com/tensorflow/tensorflow/files/5869438/tf_nightly_issue_on_3070.txt)


**Describe the expected behavior**
The script was working on my old gtx 980 and CUDA 10.

**Standalone code to reproduce the issue**
```
import datetime
import os

import pandas as pd
from numpy import reshape

import tensorflow as tf

EPOCHS = 500
BATCH_SIZE = 256
TEST_SET_RATIO = 0.2

LEARNING_RATE = 0.001
DECAY = 3e-5
LOSS_FUNC = 'categorical_crossentropy'
DROPOUT = 0.2
OUTPUT_PATH = ""e:\\ml""

RNN_SEQ_LEN = 128  # number of RNN/LSTM sequence features
L_AMOUNT = 2  # number of labels

MIN_ACC_TO_SAVE_MODEL = 0.6


def create_model():
    new_model = tf.keras.models.Sequential()

    # NETWORK INPUT
    new_model.add(tf.keras.layers.LSTM(RNN_SEQ_LEN, input_shape=TR_FEATURES.shape[1:], return_sequences=True))
    new_model.add(tf.keras.layers.Dropout(DROPOUT))
    new_model.add(tf.keras.layers.BatchNormalization())

    new_model.add(tf.keras.layers.LSTM(RNN_SEQ_LEN, return_sequences=True))
    new_model.add(tf.keras.layers.Dropout(DROPOUT / 2))
    new_model.add(tf.keras.layers.BatchNormalization())

    new_model.add(tf.keras.layers.LSTM(RNN_SEQ_LEN))
    new_model.add(tf.keras.layers.Dropout(DROPOUT))
    new_model.add(tf.keras.layers.BatchNormalization())

    # NETWORK OUTPUT
    new_model.add(tf.keras.layers.Dense(L_AMOUNT, activation=tf.keras.activations.softmax))

    opt = tf.keras.optimizers.Adam(LEARNING_RATE, decay=DECAY)
    new_model.compile(optimizer=opt,
                      loss=LOSS_FUNC,
                      metrics=['accuracy'])

    print(new_model.summary())
    return new_model


class CustomModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):
    def __init__(self, fp, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch', **kwargs):
        super().__init__(fp, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, **kwargs)

    def on_epoch_end(self, epoch, logs=None):
        print(""\n-------------------------------------------------------------------------------------------------------"")
        print(f""epoch: {epoch}, training_acc: {round(float(logs['accuracy']), 4)}, validation_acc: {round(float(logs['val_accuracy']), 4)}"")
        print(""-------------------------------------------------------------------------------------------------------\n"")

        if MIN_ACC_TO_SAVE_MODEL <= logs['accuracy']:
            super().on_epoch_end(epoch, logs)


if __name__ == '__main__':
    data_filename = 'input_data.csv'
    print(""Loading data file: %s"" % data_filename)
    dataset = pd.read_csv(data_filename, delimiter=',', header=None)
    dataset = dataset.drop(columns=[0, 1, 2, 3, 4, 5, 6]).values  # drop columns with additional information

    test_set_size = int(len(dataset) * TEST_SET_RATIO)
    print(""Test set split at: %d"" % test_set_size)

    train_data = dataset[:-test_set_size]
    test_data = dataset[-test_set_size:]  # use most recent data for validation (extract before shuffle)

    TR_F = train_data[:, 0:RNN_SEQ_LEN]
    TS_F = test_data[:, 0:RNN_SEQ_LEN]

    TR_L = train_data[:, RNN_SEQ_LEN:RNN_SEQ_LEN + L_AMOUNT]
    TS_L = test_data[:, RNN_SEQ_LEN:RNN_SEQ_LEN + L_AMOUNT]

    TR_FEATURES = reshape(TR_F, (len(TR_F), RNN_SEQ_LEN, 1))
    TS_FEATURES = reshape(TS_F, (len(TS_F), RNN_SEQ_LEN, 1))

    model = create_model()

    TRAINING_TIMESTAMP = datetime.datetime.now().strftime(""%Y%m%d-%H%M%S"")
    model_name = ""sscce_%s"" % TRAINING_TIMESTAMP
    os.mkdir(""%s\\models\\%s"" % (OUTPUT_PATH, model_name))
    filepath = ""%s\\models\\%s\\%s--{epoch:02d}-{val_accuracy:.3f}.model"" % (OUTPUT_PATH, model_name, model_name)
    checkpoint = CustomModelCheckpoint(filepath,
                                       monitor='val_accuracy',
                                       verbose=1,
                                       save_best_only=True,
                                       mode='max')

    log_dir = ""%s\\logs\\fit\\%s.model"" % (OUTPUT_PATH, model_name)
    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)

    model.fit(x=TR_FEATURES,
              y=TR_L,
              epochs=EPOCHS,
              batch_size=BATCH_SIZE,
              shuffle=True,
              validation_data=(TS_FEATURES, TS_L),
              callbacks=[checkpoint, tensorboard])
```

DATA FILE SAMPLE: [input_data.zip](https://github.com/tensorflow/tensorflow/files/5869582/input_data.zip)
 
**Other info / logs**

Providing also path to CUDA 11.0 installation because without it getting errors like:

```
2021-01-25 21:44:15.989317: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found
```

Full win sys PATH:

```
Path=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\libnvvp;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.0\bin;C:\cudnn-11.1-v8.0.5.39\bin;C:\Python36\Scripts\;C:\Python36;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;c:\Java\jdk1.8.0_144_x86;C:\gradle-6.0.1\bin;C:\SVN\bin;C:\MinGW\bin;C:\WinAVR-20100110\;c:\avrdude\;c:\Android\sdk\platform-tools;C:\adb\;C:\TortoiseGit\bin;C:\Git4Windows\cmd;c:\sqlite-tools-win32-x86-3130000\;C:\WINDOWS\System32;C:\WINDOWS;C:\WINDOWS\System32\wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Bitvise SSH Client;C:\Program Files (x86)\Windows Live\Shared;C:\WINDOWS\system32;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\Nsight Compute 2020.3.0\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR
```



I was trying different combinations of cuda/cudnn/tensorflow just for the sake of it but actually only `cuda_11.2.0_460.89_win10` comes with win nvidia GPU divers version high enough to support RTX 30xx series.
Still - there is no `cudnn` build designated particularly for `CUDA 11.2` yet... Maybe this is an issue...

Any idea how to make it working all together?"
46672,softmax_cross_entropy_with_logits - wrong backprop for this operation,"Hi,

I've noticed that the arithmetic for the backward operation of softmax_cross_entropy_with_logits is lacking of an additional multiplier. As can be seen in the following Xent kernel, that the operation is using, the formula for the log_cross_entropy is:
**_target - logits_**
while it should be:
_target*(1 - logits)_
When the target is dense, and doesn't sum up to exactly one, the answer is wrong. 

https://github.com/tensorflow/tensorflow/blob/dec8e0b11f4f87693b67e125e67dfbc68d26c205/tensorflow/core/kernels/xent_op.h#L118

Here is a numpy reference code for what I expect the backward should be:
```
## gradOutput is actually the target labels 
def referenceLogSoftMaxBackward(logSoftMaxOutput, gradOutput):
    '''
    accreal sum = 0;
    for (d = 0; d < dim; d++)
      sum += gradOutput_data[d];

    for (d = 0; d < dim; d++)
      gradInput_data[d] = gradOutput_data[d] - exp(output_data[d])*sum;
    '''
    shape = gradOutput.shape
    dims_to_normalize_tuple = tuple(np.arange(len(shape))[1:])

    # Sum reduction over all dimensions except for batch
    sum = np.sum(gradOutput, axis=dims_to_normalize_tuple, keepdims=True)

    # Compound operation:
    # Elementwise exponential and then multiplication by broadcasted tensor
    # followed by element-wise subtraction
    gradInput = gradOutput - np.exp(logSoftMaxOutput) * sum

    return gradInput
```

Can you please check this out and comment?

Thanks."
46667,Updates to the TFLM Makfile that are not backwards compatible,"**System information**

-   OS Platform and Distribution: Linux Ubuntu 20.10 
-   TensorFlow version: 2.4.1
-   Python version: 3.8
-   CPU Intel Core i7
-   GPU: NVIDIA GeForce GTX
-   STM32CubeIDE-Lnx: 1.3.0
-   STM32 Nucleo-64 development board

**Describe the problem**

I would like to run the Makefile in the Tensorflow Lite for Microcontrollers directory in order to run inference on ST microcontroller above. My problem is that I cannot use the 
TAGS =âportable_optimizedâ command line option /cc @advaitjain

**Source code / logs**

tensorflow/lite/micro/tools/make/Makefile:61: *** The TAGS command line option is no longer supported in the TFLM Makefile..

Thanks in advance."
46666,Old Lookup Bug still active?,"I am using Tensorflow 1.x 
OS: Mac OS or Linux can be testet e.g in Cola

The following demo code works with GPU but not with CPU. It looks like this from 2018 - I think it should work on both:
```
`
vocab = [{'this':1},
         {'is':2},
         {'just':3},
         {'the':4},
         {'a':5},
         {'demo':6},
         {'code':7},
         {'tensorflow':8},
         {'test':9}]

features = [[1, 2, 3, 4, 5], [5, 6, 7, 8, 9]]

EMBEDDING_SIZE = 1
with tf.Session() as sess:
    features_embedded = tf.contrib.layers.embed_sequence(
        ids=features,
        vocab_size=len(vocab),
        embed_dim=EMBEDDING_SIZE,
        scope='words',
        reuse=tf.AUTO_REUSE
        )
    word_list = tf.unstack(features_embedded, axis=1)
    sess.run(tf.global_variables_initializer())`
```

Leads to InvalidArgumentError: indices[1,4] = 9 is not in [0, 9)
	 [[{{node words/embedding_lookup}}]]

Or GPU:
[[[-0.03936231]
  [-0.62959105]
  [ 0.05874097]
  [-0.39156422]
  [-0.50708985]]

 [[-0.50708985]
  [-0.2946922 ]
  [-0.32304823]
  [ 0.514025  ]
  [ 0.        ]]]


It is something like this bug: https://github.com/tensorflow/tensorflow/issues/17417
"
46665,neuro-symbolic,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
46664,Tensorflow 2.4 Compile,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  with command  pip install tensorflow-gpu==2.4.0
- TensorFlow version: 2.4.0
- Python version: Python 3.6.9
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: cuda :11.0,  cuDNN :  8.0.2
- Driver Version: 450.102.04
- GPU model and memory: Gigabyte Nvidia GForce 1660 6GB



**Describe the problem**

I execute the basic command 
import tensorflow as tf
print(tf.test.gpu_device_name())

to see if tensorflow 2.4 is execute in my ubuntu i have all installed than we need for this version like cuda version, cuddn version and driver version. What maybe is the problem ? 
With tensorflow 2.3 compile successfully but he cannnot load the cuddn library and cuda.

**Any other info / logs**
From compiler i get this message : 
2021-01-25 16:27:37.386741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Traceback (most recent call last):
  File ""test.py"", line 1, in <module>
    import tensorflow as tf
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py"", line 435, in <module>
    _ll.load_library(_main_dir)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/load_library.py"", line 153, in load_library
    py_tf.TF_LoadLibrary(lib)
tensorflow.python.framework.errors_impl.NotFoundError: /home/antreas/.local/lib/python3.6/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb

"
46663,Breaking change of TFLite model definition in TensorFlow 2.4.0: OperatorCode.BuiltinCode,"(source issue: https://github.com/jackwish/tflite/issues/9)

**This change breaks software stacks that depend on the built TFLite model parser, e.g. [tvm](https://github.com/apache/tvm), [tflite2onnx](https://github.com/jackwish/tflite2onnx), and etc.**

Starting from [TensorFlow 2.4.0](https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/schema/schema.fbs#L220), the `BuiltinOperator` switches to `int32` from `byte`. As a result, the `OperatorCode.builtin_code` is now an `int32` too, and code like `op_code.BuiltinCode()` is broken. 

```
// An OperatorCode can be an enum value (BuiltinOperator) if the operator is a
// builtin, or a string if the operator is custom.
table OperatorCode {
  // This field is for backward compatibility. This field will be used when
  // the value of the extended builtin_code field has less than
  // BulitinOperator_PLACEHOLDER_FOR_GREATER_OP_CODES.
  deprecated_builtin_code:byte;
  custom_code:string;

  // The version of the operator. The version need to be bumped whenever new
  // parameters are introduced into an op.
  version:int = 1;

  // This field is introduced for resolving op builtin code shortage problem
  // (the original BuiltinOperator enum field was represented as a byte).
  // This field will be used when the value of the extended builtin_code field
  // has greater than BulitinOperator_PLACEHOLDER_FOR_GREATER_OP_CODES.
  builtin_code:BuiltinOperator;
}
``` 

For any code that uses `op_code.BuiltinCode()`, a workaround like the below (or [this PR](https://github.com/jackwish/tflite/pull/10/files)) is needed.

```py

if op_code.BuiltinCode() < BuiltinOperator.PLACEHOLDER_FOR_GREATER_OP_CODES:
    opc = op_code.DeprecatedBuiltinCode()
else:
    opc = op_code.BuiltinCode()
```"
46662,"Reshape after conversion has two dynamic shapes, fails inference","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux 2
- TensorFlow installed from (source or binary): With pip install tensorflow
- TensorFlow version (or github SHA if from source): 2.4.0


**Command used to run the converter or code if youâre using the Python API**

    model_concrete_function = model.inference_encode.get_concrete_function()
    converter = tf.lite.TFLiteConverter.from_concrete_functions(
        [model_concrete_function]
    )
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]

    if args.quantized:
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        output_file_name = os.path.join(args.outdir, 'model_quant.tflite')
    else:
        output_file_name = os.path.join(args.outdir, 'model.tflite')

    tflite_model = converter.convert()

**The output from the converter invocation**

```
2021-01-25 12:34:22.930736: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-01-25 12:34:22.930757: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-01-25 12:34:25.599105: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-25 12:34:25.599281: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-01-25 12:34:25.599294: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-01-25 12:34:25.599313: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dev-dsk-dmmatwic-1b-a5a0da5a.eu-west-1.amazon.com): /proc/driver/nvidia/version does not exist
2021-01-25 12:34:25.599516: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-01-25 12:34:25.600785: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-25 12:34:28.607374: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2021-01-25 12:34:28.607500: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2021-01-25 12:34:28.607690: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-25 12:34:28.627718: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2500000000 Hz
2021-01-25 12:34:28.634934: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize
  function_optimizer: function_optimizer did nothing. time = 0.005ms.
  function_optimizer: function_optimizer did nothing. time = 0ms.

2021-01-25 12:34:29,117 (lite:619) INFO: Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False
2021-01-25 12:34:29.139440: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.
2021-01-25 12:34:29.139470: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.
2021-01-25 12:34:29.183040: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-25 12:34:29,771 (convert:102) INFO: Model of size 6.231964 MBs saved to model_tflite/model.tflite
```

**Also, please include a link to the saved model or GraphDef**
I can't include a model since it's company's internal model.

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:

Reshape nodes have shapes of [-1, -1, 128] instead of [1, -1, 128] and inference therefore fails
**Here's a screenshot of this part from Netron, the selected node is the Reshape node** 
![Untitled 2](https://user-images.githubusercontent.com/32575801/105708210-61385b00-5f14-11eb-8e8d-4be25947043c.png)

These nodes are part of tf.keras.layers.Conv1D, which is created with
**tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding=""same"")**

Inference log
**ERROR: tensorflow/lite/kernels/reshape.cc:58 stretch_dim != -1 (0 != -1)
ERROR: Node number 69 (RESHAPE) failed to prepare.**

"
46661,Memory Leak in VGG16 based model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1
- Python version: 3.8.5
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: 11.0 / 8.0.5
- GPU model and memory: Nvidia Quadro M2200 (4 Gb)


**Describe the current behavior**
Running predictions (and also training) with a **VGG16** (from Keras Model Zoo) based model leads to a steadily increasing memory usage until either the all predictions are completed or the system memory is exhausted and the process dies.
See the script below to reproduce the issue. It plots the memory consumption for each iteration of predicting with the defined model.
The memory consumption for TensorFlow 2.4 looks like this:
![Memory_Leak_Plot_TF_2_4](https://user-images.githubusercontent.com/7513153/105699507-c174d000-5f07-11eb-8d8e-feff12628172.png)
The memory consumption of TensorFlow 2.3 behaves as expected:
![Memory_Leak_Plot_TF_2_3](https://user-images.githubusercontent.com/7513153/105699551-d5b8cd00-5f07-11eb-973c-20bbb91e370a.png)
**Note:** Running the same script TensorFlow 2.4 consumes >8 Gb of RAM while TensorFlow 2.3 only consumes ~1.3 Gb.
**Note 2:** The critical part of this model is the VGG16 model from tf.keras.applications. Using a ResNet50 model instead the memory leak does not occur.

**Describe the expected behavior**
The memory consumption in TensorFlow 2.4 is similar to TensorFlow 2.3 such that running an increased number of iterations does not lead to a potentially infinite main memory consumption.

**Standalone code to reproduce the issue**
The required packages to run the script below are: tqdm, psutil, matplotlib, numpy, tensorflow=2.4
```python
import tensorflow as tf
import numpy as np
import tqdm
import os
import psutil
import matplotlib.pyplot as plt


class TestModel(tf.keras.models.Model):
    def __init__(self, input_shape):
        model = tf.keras.applications.VGG16(input_shape=input_shape[1:], include_top=False)
        output_encoder = model.get_layer('block5_pool').output
        decoder = tf.keras.layers.Conv2D(3, 3, padding='SAME')(output_encoder)
        decoder = tf.keras.layers.UpSampling2D(size=(32,32))(decoder)
        decoder = tf.keras.layers.Concatenate()([model.input, decoder])
        decoder = tf.keras.layers.Conv2D(3, 3, padding='SAME')(decoder)
        super().__init__(model.input, decoder)

def run_predictions(iterations):
    input_shape = 1, 256, 256, 3
    model = TestModel(input_shape)
    inputs = np.random.rand(*input_shape)
    memory_used = []
    for _ in tqdm.tqdm(range(iterations)):
        process = psutil.Process(os.getpid())
        memory_used += [process.memory_info().rss / 1024.0 / 1024.0]
        model.predict(inputs, batch_size=1)
    return memory_used

if __name__ == ""__main__"":
    memory_used = run_predictions(5000)
    plt.plot(memory_used)
    plt.xlabel(""Iteration"")
    plt.ylabel(""Memroy Usage (MB)"")
    plt.show()
```

**Other info / logs**
I found another bug that also deals with a memory leak in TensorFlow 2.4 (#46475). However, the OS there is Ubuntu Linux 20.04 while the bug described above was only reproducible on Windows 10 and not in a Linux based colab. Furthermore, the issue described in the other bug seems to be related to ReLU activation. As I was able to reproduce the issue with VGG16 but not ResNet50 (Both contain ReLU activations)  I assume that this is a different issue.
"
46660,Third-party Tensorflow 2.4.0,"Hello TensorFlow team,
I'm looking for version 2.4.0 of Tensorflow for all used third-party with the version status. Is there a document that refers to all third-party versions and versions?
Best regards,
Fabian"
46659,Loading a model with a Lambda layer causes a 'str' object is not callable exception,"I'm running tf 2.3.1 on Python 3.7.6 (via Kaggle). Running this code...

import tensorflow as tf

```
model1 = tf.keras.Sequential([
    tf.keras.layers.Input(shape = (81,), dtype = 'uint8'), 
    tf.keras.layers.Lambda(tf.keras.backend.one_hot, arguments={'num_classes': 10}, output_shape=(81, 10)),
])

tf.keras.models.save_model(model1, './model')
model2 = tf.keras.models.load_model('./model', custom_objects={'one_hot' : tf.keras.backend.one_hot})
model2.summary()
```

causes a rather long exception, quoted in full below. It seems to be the Lambda layer that causes issues; save-loading works fine without it. I've tried adding `custom_objects={'one_hot' : tf.keras.backend.one_hot}` and suchlike to the load call, but it doesn't fix it. 


```---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/backend.py in wrapper(*args, **kwargs)
    200     try:
--> 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):

TypeError: 'str' object is not callable

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
<ipython-input-22-9347e5c173dd> in <module>
      7 
      8 tf.keras.models.save_model(model1, './model')
----> 9 model2 = tf.keras.models.load_model('./model', custom_objects={'one_hot' : tf.keras.backend.one_hot})
     10 model2.summary()

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile, options)
    185     if isinstance(filepath, six.string_types):
    186       loader_impl.parse_saved_model(filepath)
--> 187       return saved_model_load.load(filepath, compile, options)
    188 
    189   raise IOError(

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in load(path, compile, options)
    119 
    120   model = tf_load.load_internal(
--> 121       path, options=options, loader_cls=KerasObjectLoader)
    122 
    123   # pylint: disable=protected-access

/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py in load_internal(export_dir, tags, options, loader_cls)
    631       try:
    632         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,
--> 633                             ckpt_options)
    634       except errors.NotFoundError as err:
    635         raise FileNotFoundError(

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in __init__(self, *args, **kwargs)
    192     self._models_to_reconstruct = []
    193 
--> 194     super(KerasObjectLoader, self).__init__(*args, **kwargs)
    195 
    196     # Now that the node object has been fully loaded, and the checkpoint has

/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py in __init__(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options)
    128       self._concrete_functions[name] = _WrapperFunction(concrete_function)
    129 
--> 130     self._load_all()
    131     self._restore_checkpoint()
    132 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _load_all(self)
    219 
    220     # Finish setting up layers and models. See function docstring for more info.
--> 221     self._finalize_objects()
    222 
    223   @property

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _finalize_objects(self)
    528 
    529     # Initialize graph networks, now that layer dependencies have been resolved.
--> 530     self._reconstruct_all_models()
    531 
    532   def _unblock_model_reconstruction(self, layer_id, layer):

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _reconstruct_all_models(self)
    546       all_initialized_models.add(model_id)
    547       model, layers = self.model_layer_dependencies[model_id]
--> 548       self._reconstruct_model(model_id, model, layers)
    549       self._add_object_graph_edges(self._proto.nodes[model_id], model_id)
    550       _finalize_config_layers([model])

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _reconstruct_model(self, model_id, model, layers)
    576               dtype=layers[0].dtype,
    577               name=layers[0].name + '_input'))
--> 578       model.__init__(layers, name=config['name'])
    579       if not model.inputs:
    580         first_layer = self._get_child_layer_node_ids(model_id, model.name)[0]

/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--> 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py in __init__(self, layers, name)
    140         layers = [layers]
    141       for layer in layers:
--> 142         self.add(layer)
    143 
    144   @property

/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--> 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py in add(self, layer)
    219       # If the model is being built continuously on top of an input layer:
    220       # refresh its output.
--> 221       output_tensor = layer(self.outputs[0])
    222       if len(nest.flatten(output_tensor)) != 1:
    223         raise ValueError(SINGLE_LAYER_OUTPUT_ERROR_MSG)

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    924     if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):
    925       return self._functional_construction_call(inputs, args, kwargs,
--> 926                                                 input_list)
    927 
    928     # Maintains info about the `Layer.call` stack.

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)
   1115           try:
   1116             with ops.enable_auto_cast_variables(self._compute_dtype_object):
-> 1117               outputs = call_fn(cast_inputs, *args, **kwargs)
   1118 
   1119           except errors.OperatorNotAllowedInGraphError as e:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py in call(self, inputs, mask, training)
    901     with backprop.GradientTape(watch_accessed_variables=True) as tape,\
    902         variable_scope.variable_creator_scope(_variable_creator):
--> 903       result = self.function(inputs, **kwargs)
    904     self._check_variables(created_variables, tape.watched_variables())
    905     return result

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/backend.py in wrapper(*args, **kwargs)
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a
    204       # TypeError, when given unexpected types.  So we need to catch both.
--> 205       result = dispatch(wrapper, args, kwargs)
    206       if result is not OpDispatcher.NOT_SUPPORTED:
    207         return result

TypeError: 'module' object is not callable```"
46658,Error in prediction:Invalid argument: Default MaxPoolingOp only supports NHWC on device type CPU for TensorFlow C++ API Reference,"<em>Please make sure that this is a bug. As per our

**System information**
- OS Platform ï¼Ubuntu 16.04
- TensorFlow installed from source :
- TensorFlow version (use command below): TensorFlow Core v2.4.1  TensorFlow C++ API Reference
- Python version: 3.5
- Bazel version : release: release 1.2.1
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010


LOG OUTPUT

2021-01-25 10:39:38.260369: E external/org_tensorflow/tensorflow/core/common_runtime/executor.cc:661] Executor failed to create kernel. Invalid argument: Default MaxPoolingOp only supports NHWC on device type CPU
         [[{{node v_}}]]
2021-01-25 10:39:38.261762: E external/org_tensorflow/tensorflow/core/common_runtime/executor.cc:661] Executor failed to create kernel. Invalid argument: Default MaxPoolingOp only supports NHWC on device type CPU
         [[{{node v_}}]]
Error in prediction:Invalid argument: Default MaxPoolingOp only supports NHWC on device type CPU
         [[{{node v_}}]]
"
46657,Guide for porting reference ops to TFLite micro,"## URL(s) with the issue:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md

## Description of issue (what needs changing):

> TODO(b/165627437): Create and link to a guide to porting reference ops.

This TODO is still open. It feels like TFLite micro is getting more and more attention and recently many ops are in the process to be ported. I'm also working on two ops (#45693) and I would highly appreciate such a guide since I'm struggling to port the tests from TFLite to micro.
How are the TODOs handled in tensorflow? Is someone working on that or is it just open until somebody picks it up?
"
46656,Issue with tflite converter in tf-nightly:  'tf.If' op 'then_branch' input type tensor<?xf32> is incompatible with input type tensor<?xi64> at index 0,"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04.5
- Python version: 3.7.4
- TensorFlow version: tf-nightly-2.5.0.dev20210124

Hello, I have a new issue with the tflite converter which is happening only when using nightly (it isn't happening when using tensorflow main branch). I tried as much as I can to create the minimal code to reproduce: 

    !pip install tf-nightly
    import tensorflow as tf
    import os
    import numpy as np
    
    class EXAMPLE(tf.Module):
    
        @tf.function(input_signature=[tf.TensorSpec(shape=[100], dtype=tf.float32)])
        def calculate(self, x):
        
          maxima_ind = tf.where(x > 0.8)
          maxima_ind = tf.gather(maxima_ind,0,axis=1)
    
          maxima_ind = tf.cast(maxima_ind, dtype=tf.float32)
    
          if len(maxima_ind) > 10:
              maxima_ind = tf.cast(maxima_ind, dtype=tf.float32)
    
          return maxima_ind
          
    to_export = EXAMPLE()
    np.random.seed(54)
    buffer_size = 100
    x1  = tf.convert_to_tensor(np.random.rand(buffer_size).astype('float32'))
    
    
    solution = to_export.calculate(x1)
    print(solution)
    models_dir = '/content/model_example/'
    tf.saved_model.save(to_export, models_dir)
    imported = tf.saved_model.load(models_dir)
    converter = tf.lite.TFLiteConverter.from_saved_model(models_dir) # path to the SavedModel directory
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                            tf.lite.OpsSet.SELECT_TF_OPS]
    
    tflite_model = converter.convert()
    with open(models_dir + 'model_example.tflite', 'wb') as f:
      f.write(tflite_model)

When running it, I'm getting this error: 

    Exception                                 Traceback (most recent call last)
    /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
        216                                                  debug_info_str,
    --> 217                                                  enable_mlir_converter)
        218       return model_str
    
    4 frames
    Exception: <unknown>:0: error: loc(""cond@__inference_calculate_3155""): 'tf.If' op 'then_branch' input type tensor<?xf32> is incompatible with input type tensor<?xi64> at index 0
    
    
    During handling of the above exception, another exception occurred:
    
        ConverterError                            Traceback (most recent call last)
        /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
            218       return model_str
            219     except Exception as e:
        --> 220       raise ConverterError(str(e))
            221 
            222   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:
        
        ConverterError: <unknown>:0: error: loc(""cond@__inference_calculate_3155""): 'tf.If' op 'then_branch' input type tensor<?xf32> is incompatible with input type tensor<?xi64> at index 0

You can also use this gist (which include the above code): https://colab.research.google.com/gist/AiaHaruv/6cac62614ef85f76db8bcfcfa0b8baae/conversion_bug.ipynb
I understand there is a thing with the types but I'm using casting before the if statement and inside of it I'm actually doing nothing, and it isn't happening in the main branch..  
Any help will be appreciated. Thank you 

"
46655,"google.protobuf.text_format.ParseError: 161:14 : Message type ""object_detection.protos.Optimizer"" has no field named ""i"".","sparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aarju/anaconda3/envs/demo_model/lib:/usr/lib/x86_64-linux-gnu:/home/aarju/anaconda3/envs/caffe/lib:/usr/lib/x86_64-linux-gnu
2021-01-25 14:30:04.810886: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aarju/anaconda3/envs/demo_model/lib:/usr/lib/x86_64-linux-gnu:/home/aarju/anaconda3/envs/caffe/lib:/usr/lib/x86_64-linux-gnu
2021-01-25 14:30:04.810902: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-01-25 14:30:04.811643: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-01-25 14:30:04.814596: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-25 14:30:04.814714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-25 14:30:04.814742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]
WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
W0125 14:30:04.820366 140452454930176 cross_device_ops.py:1321] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
I0125 14:30:04.821369 140452454930176 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 113, in <module>
    tf.compat.v1.app.run()
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""model_main_tf2.py"", line 104, in main
    model_lib_v2.train_loop(
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/object_detection/model_lib_v2.py"", line 466, in train_loop
    configs = get_configs_from_pipeline_file(
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/object_detection/utils/config_util.py"", line 139, in get_configs_from_pipeline_file
    text_format.Merge(proto_str, pipeline_config)
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py"", line 728, in Merge
    return MergeLines(
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py"", line 802, in MergeLines
    return parser.MergeLines(lines, message)
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py"", line 827, in MergeLines
    self._ParseOrMerge(lines, message)
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py"", line 849, in _ParseOrMerge
    self._MergeField(tokenizer, message)
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py"", line 974, in _MergeField
    merger(tokenizer, message, field)
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py"", line 1048, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py"", line 974, in _MergeField
    merger(tokenizer, message, field)
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py"", line 1048, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py"", line 939, in _MergeField
    raise tokenizer.ParseErrorPreviousToken(
google.protobuf.text_format.ParseError: 161:14 : Message type ""object_detection.protos.Optimizer"" has no field named ""i"".


### System information


-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:: 2.4
-   **Python version**: : 3.7
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**: 10.2
-   **GPU model and memory**:
-   **Exact command to reproduce**:


"
46653,"Ignoring visible gpu device (device: 0, name: GeForce GTX 780M compute capability: 3.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): From source
- TensorFlow version: 2.4.1
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): bazel 3.1.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
- CUDA/cuDNN version:  10.1/8
- GPU model and memory: dual GeForce GTX 780M with 2 GB each


**Describe the problem**
 
 I built tensorflow (version 2.4.1) from source becuase my old gpu compute capability is 3.0.
 I followed the instructions from https://www.tensorflow.org/install/source
 and from https://medium.com/@mccann.matt/compiling-tensorflow-with-cuda-3-0-support-42d8fe0bf3b5
 
 I did the build process 5 times, every time I change some parameters in ./configure
 I also manualy edited .tf_configure.bazelrc (suggested parameters from https://github.com/tensorflow/tensorflow/issues/24126#issuecomment-443847200) to turn XLA off by
 removing --config=XLA
 and 
 adding the line build --define with_xla_support=false
 
 and every time I run python to check if tensorflow is using my gpu, I got False as shown below.
 
 `>>> tf.test.is_gpu_available(True,3.0)
2021-01-25 09:21:44.146701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-25 09:21:44.148484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 780M computeCapability: 3.0
coreClock: 0.797GHz coreCount: 8 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 149.01GiB/s
2021-01-25 09:21:44.148617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-25 09:21:44.150416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:07:00.0 name: GeForce GTX 780M computeCapability: 3.0
coreClock: 0.797GHz coreCount: 8 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 149.01GiB/s
2021-01-25 09:21:44.150466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2021-01-25 09:21:44.150508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2021-01-25 09:21:44.150535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2021-01-25 09:21:44.150559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-01-25 09:21:44.150585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-01-25 09:21:44.150611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-01-25 09:21:44.150638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2021-01-25 09:21:44.150664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-01-25 09:21:44.150773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-25 09:21:44.152515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-25 09:21:44.154623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-25 09:21:44.156318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1816] Ignoring visible gpu device (device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.
2021-01-25 09:21:44.156445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-25 09:21:44.158101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1816] Ignoring visible gpu device (device: 1, name: GeForce GTX 780M, pci bus id: 0000:07:00.0, compute capability: 3.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.
2021-01-25 09:21:44.158151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-25 09:21:44.158161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 
2021-01-25 09:21:44.158167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y 
2021-01-25 09:21:44.158173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N 
False
`
So I did not know what do now."
46652,"Keras model could save to h5 but not savedModel, call() missing argument","I am using TF 2.2, the model is a keras model written in `tf.keras.engine.training_v1.Model`. I could save the model to h5 using `model.save(save_format='h5)`, but if save using savedModel by just `model.save()`. the error is 
```
TypeError: call() missing 1 required positional argument: 'state'
```
How could it be?.. The big question here is that: why is there some keras model which work well and could saved to .h5 but have this error when saved to SavedModel

Full stack:
```
Traceback (most recent call last):
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/contextlib.py"", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/backend.py"", line 423, in learning_phase_scope
    yield
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 951, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 1008, in _build_meta_graph
    checkpoint_graph_view)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_serialization.py"", line 75, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 143, in list_functions
    self._serialization_cache)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1656, in _list_functions_for_serialization
    Model, self)._list_functions_for_serialization(serialization_cache)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer_v1.py"", line 2439, in _list_functions_for_serialization
    .list_functions_for_serialization(serialization_cache))
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py"", line 87, in list_functions_for_serialization
    fns = self.functions_to_serialize(serialization_cache)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 77, in functions_to_serialize
    serialization_cache).functions_to_serialize)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 92, in _get_serialized_attributes
    serialization_cache)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py"", line 53, in _get_serialized_attributes_internal
    serialization_cache))
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 101, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 153, in wrap_layer_functions
    original_fns = _replace_child_layer_functions(layer, serialization_cache)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 272, in _replace_child_layer_functions
    serialization_cache).functions)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 92, in _get_serialized_attributes
    serialization_cache)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 101, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 153, in wrap_layer_functions
    original_fns = _replace_child_layer_functions(layer, serialization_cache)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 272, in _replace_child_layer_functions
    serialization_cache).functions)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 92, in _get_serialized_attributes
    serialization_cache)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 101, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 191, in wrap_layer_functions
    fn.get_concrete_function()
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 546, in get_concrete_function
    self.call_collection.add_trace(*args, **kwargs)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 421, in add_trace
    fn.get_concrete_function(*args, **kwargs)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 547, in get_concrete_function
    return super(LayerCall, self).get_concrete_function(*args, **kwargs)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 959, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 865, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 506, in _initialize
    *args, **kwds))
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 524, in wrapper
    ret = method(*args, **kwargs)
  File ""/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 566, in call_and_return_conditional_losses
    return layer_call(inputs, *args, **kwargs), layer.get_losses_for(inputs)
TypeError: call() missing 1 required positional argument: 'state'

```
The model is not short, so I am not posting it. If you need I would post it."
46650,How can I build this for Intel GPU (to use OpenCL),"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Source 
- TensorFlow version: Release 2.5.1
- Python version: Python 2.7.15+
- Installed using virtualenv? pip? conda?: 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
- CUDA/cuDNN version: NA
- GPU model and memory: Intel GPU 


**Describe the problem**
Compiled with -DCL_DELEGATE_NO_GL flags in Makefile however I get the following error : 
./tensorflow/lite/delegates/gpu/api.h:262:17: error: expected unqualified-id before âintâ
   virtual absl::Status SetInputShape(index,const Dimensions& dimensions) = 0;

**Provide the exact sequence of commands / steps that you executed before running into the problem**
1> Add -DCL_DELEGATE_NO_GL in Makefile 
2> Added tensorflow/lite/delegates/gpu/*.cc to the list of sources in Makefile 
3> Included /usr/include to add cl.h 

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
COMPLETE ERROR LOGS: 
In file included from /usr/include/EGL/eglplatform.h:130:0,
                 from /usr/include/EGL/egl.h:39,
                 from ./tensorflow/lite/delegates/gpu/gl/portable_gl31.h:21,
                 from ./tensorflow/lite/delegates/gpu/api.h:50,
                 from tensorflow/lite/delegates/gpu/api.cc:16:
./tensorflow/lite/delegates/gpu/api.h:262:17: error: expected unqualified-id before âintâ
   virtual absl::Status SetInputShape(index,const Dimensions& dimensions) = 0;
                 ^
./tensorflow/lite/delegates/gpu/api.h:271:17: error: expected unqualified-id before âintâ
   virtual absl::Status SetInputObjectDef(int index, ObjectDef def) = 0;
                 ^
./tensorflow/lite/delegates/gpu/api.h:272:17: error: expected unqualified-id before âintâ
   virtual absl::Status SetOutputObjectDef(int index, ObjectDef def) = 0;
                 ^
./tensorflow/lite/delegates/gpu/api.h:273:17: error: expected unqualified-id before âintâ
   virtual absl::Status SetAllInputObjectDefsTo(ObjectDef def) {
                 ^
./tensorflow/lite/delegates/gpu/api.h:280:17: error: expected unqualified-id before âintâ
   virtual absl::Status SetAllOutputObjectDefsTo(ObjectDef def) {
                 ^
./tensorflow/lite/delegates/gpu/api.h:293:17: error: expected unqualified-id before âintâ
   virtual absl::Status Build(std::unique_ptr<InferenceRunner>* runner) = 0;
                 ^
./tensorflow/lite/delegates/gpu/api.h:310:17: error: expected unqualified-id before âintâ
   virtual absl::Status GetInputObject(int index, TensorObject* object) = 0;
                 ^
./tensorflow/lite/delegates/gpu/api.h:311:17: error: expected unqualified-id before âintâ
   virtual absl::Status GetOutputObject(int index, TensorObject* object) = 0;
                 ^
./tensorflow/lite/delegates/gpu/api.h:312:17: error: expected unqualified-id before âintâ
   virtual absl::Status SetInputObject(int index, TensorObject object) = 0;
                 ^
./tensorflow/lite/delegates/gpu/api.h:313:17: error: expected unqualified-id before âintâ
   virtual absl::Status SetOutputObject(int index, TensorObject object) = 0;
                 ^
./tensorflow/lite/delegates/gpu/api.h:315:17: error: expected unqualified-id before âintâ
   virtual absl::Status Run() = 0;"
46648,tf.repeat fails,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: 3.*
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: no GPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
```
n = 50000
many_ones = tf.cast(tf.concat([tf.ones(n), [n,]], axis = 0), 'int32')
array = tf.concat([tf.range(n), [n, ]], axis = 0)
tf.repeat(array, many_ones)
```
returns

> InvalidArgumentError: Size 0 must be non-negative, not -1794917296 [Op:Reshape]

**Describe the expected behavior**
`np.repeat` returns
> array([    0,     1,     2, ..., 50000, 50000, 50000], dtype=int32)

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

the following code would work for small ns, but fail/be very slow for big ns
```
n = 50000
many_ones = tf.cast(tf.concat([tf.ones(n), [n,]], axis = 0), 'int32')
array = tf.concat([tf.range(n), [n, ]], axis = 0)
tf.repeat(array, many_ones)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46645,Reloading weights give small difference,"
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, I modified a TPU colab notebook
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
- TensorFlow installed from (source or binary): colab
- TensorFlow version (use command below): 2.4
- Python version:
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: TPU v2
- GPU model and memory: None

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
During the training, I am computing the validation accuracy at each epochs, with a callback function and then save the weight when the model improved.
When reloading the weight inside the same session, the model give small difference regarding the validation metric. I don't know if the issue comes from the loading or saving part.


**Describe the expected behavior**
the model should has the same validation performance .


**Standalone code to reproduce the issue**

link of the colab to reproduce the results : 
https://colab.research.google.com/drive/1LnEgPmVtfuX9yaFZftpbOUlPPU4ecUvL#scrollTo=7Qv8rC4aVOFB&uniqifier=2


As you can see : 0.9588235294117647 is different from  0.9573529411764706
> Epoch 1/5
> 
> Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.
>  6/23 [======>.......................] - ETA: 6s - loss: 1.6750 - accuracy: 0.2327WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 11.4604s). Check your callbacks.
> WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 11.4604s). Check your callbacks.
> 23/23 [==============================] - 131s 410ms/step - loss: 1.6348 - accuracy: 0.2524
> val_loss: 1.5019999742507935 -- val_categorical_accuracy: 0.365 -- samples : 680
> 
>  model saved, improvement from 0.0 to 0.36470588235294116
> 
> Epoch 2/5
> 
> Epoch 00002: LearningRateScheduler reducing learning rate to 8.8e-05.
> 23/23 [==============================] - 9s 410ms/step - loss: 1.1962 - accuracy: 0.5953
> val_loss: 0.5659999847412109 -- val_categorical_accuracy: 0.854 -- samples : 680
> 
>  model saved, improvement from 0.36470588235294116 to 0.8544117647058823
> 
> Epoch 3/5
> 
> Epoch 00003: LearningRateScheduler reducing learning rate to 0.000166.
> 23/23 [==============================] - 9s 411ms/step - loss: 0.4679 - accuracy: 0.8442
> val_loss: 0.19499999284744263 -- val_categorical_accuracy: 0.934 -- samples : 680
> 
>  model saved, improvement from 0.8544117647058823 to 0.9338235294117647
> 
> Epoch 4/5
> 
> Epoch 00004: LearningRateScheduler reducing learning rate to 0.000244.
> 23/23 [==============================] - 9s 412ms/step - loss: 0.2451 - accuracy: 0.9188
> val_loss: 0.125 -- val_categorical_accuracy: 0.954 -- samples : 680
> 
>  model saved, improvement from 0.9338235294117647 to 0.9544117647058824
> 
> Epoch 5/5
> 
> Epoch 00005: LearningRateScheduler reducing learning rate to 0.000322.
> 23/23 [==============================] - 10s 416ms/step - loss: 0.1769 - accuracy: 0.9334
> val_loss: 0.1289999932050705 -- val_categorical_accuracy: 0.959 -- samples : 680
> 
>  model saved, improvement from 0.9544117647058824 to 0.9588235294117647
> 
> Loading best model... ckpt_model.h5
> final acc :  0.9573529411764706"
46644,Unable to tf.saved_model.load() from a trained Keras model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8

**Describe the current behavior**
I have a Saved Model.  When I attempt to load it in the JVM, it crashes the JVM - see https://github.com/tensorflow/java/issues/194 .  When I use `tf.saved_model.load()`, it fails complaining about, `The same saveable will be restored with two names: layer_with_weights-0/layer_with_weights-1/layer_with_weights-0/_table/.ATTRIBUTES/table`.

The model does work in TF-Serving and when using `keras.models.load_model()`

**Describe the expected behavior**
The model should load everywhere and should not cause a core dump in the JVM.

**Standalone code to reproduce the issue**
The model is proprietary.  I am struggling with how to triage the issue into something that I can share.  If you have thoughts, please let me know!

**Other info / logs**
The SavedModel is created from a Keras model.

See https://github.com/tensorflow/java/issues/194 for some JVM dump logs."
46641,tf.transpose returns incorrect shape or throws concatenation error when part of keras model,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): pip installed
- TensorFlow version (use command below): 2.4.1
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: Cuda 11.0/ 8.0.4
- GPU model and memory: NVIDIA GeForce GTX 1050 / 4.0GB Memory

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

- When run as part of a keras model, tf.tranpose of a rank 2 tensor gives unexpected shape . 
- When run  eagerly tf.transpose gives expected shape. 
- If the first dimension is greater than 32 then tf.transpose either returns an incorrect shape or throws a concatenation error
- This issue also affects tf.matmul(a, b, transpose_b=True)

**Describe the expected behavior**
Given a tensor of shape(i, j) tf.transpose returns a tensor of  shape (j, i) . As it does in eager mode
Used for calculating similarities, similar in this example https://keras.io/examples/vision/metric_learning/

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/1MIXzVp1Jqsu-eypWFeNavW1bk3-B0UTG?usp=sharing


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46640,AttributeError: 'Tensor' object has no attribute 'numpy',"Hi, guys, recently I'm trying to built my own metrics class using the sklearn.metrics, but when I running the update_state funcation inherit from the tensorflow.keras.metrics.Metric, I find the argument in update_state function which are y_true and y_pred is Tensor object but I need numpy array, I have tried the method given in the documentation which says using y_true.numpy but I got an error: AttributeError: 'Tensor' object has no attribute 'numpy'. I have tried many methods following the Internet but it still doesn't work. Could you help me solve this? Here are my code, thanks!

class SelfF1(Metric):
    def __init__(self, average, name=""self_f1"", **kwargs):
        super(SelfF1, self).__init__(name=name, **kwargs)
        self.f1_value = self.add_weight(name=""sf"", initializer=""zeros"", dtype=""float64"")
        self.average = average

    def update_state(self, y_true, y_pred, sample_weight=None):

        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1,))
        if len(y_true.shape) == 2 and y_true.shape[1] != 1:
            y_true = tf.reshape(tf.argmax(y_true, axis=1), shape=(-1,))

        f1_value = f1_score(y_true=y_true.numpy(), y_pred=y_pred.numpy(), average=self.average)

        self.f1_value.assign(f1_value)

    def result(self):
        return self.f1_value

    def reset_states(self):
        self.f1_value.assign(0.0)"
46638,Valid device NotFoundError when running BatchNormalization op of Tensorflow 2.0.0,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 2019
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7
- Bazel version (if compiling from source):  N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
As declared in the specification, tf.keras.layers.BatchNormalization should support to set the dtype to 'float64' . However, per our experiment, running it as the Norm layer in float64  will trigger some unexpected error: tensorflow.python.framework.errors_impl.NotFoundError: Could not find valid device for node.Node:{{node FusedBatchNormV3}}

**Describe the expected behavior**
No exception during execution

**Standalone code to reproduce the issue**
x = np.random.randn(1, 2, 4, 4)
x=tf.convert_to_tensor(x, dtype=tf.float16)
tf__Norm_64=tf.keras.layers.BatchNormalization(
        axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,
        beta_initializer='zeros', gamma_initializer='ones',
        moving_mean_initializer='zeros', moving_variance_initializer='ones',dtype='float64'
)
out_16_64 = tf_Norm_64(x_16)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46637,tf.raw_ops.ImageProjectiveTransformV3 interpolates pixels that are outside image boundary (instead of using `fill_value`),"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian testing
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.0
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: NA
- GPU model and memory: NA



**Describe the current behavior**
`tf.raw_ops.ImageProjectiveTransformV3` interpolates pixels that are outside image boundary (instead of using fill_value)
In the example below, the corner pixels are mapped from coordinates that lie outside the image. Hence, they must be set to fill_value (like, for example, scipy.ndimage.affine_transform and skimage.transform.AffineTransform). However, they are interpolated instead

**Describe the expected behavior**
Pixels outside image boundaries should be set to `fill_value`. Namely, the corner pixels, in the example below must be zeros.

**Standalone code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf
import tensorflow_addons as tfa

# Rotate 45 degrees
transform = tfa.image.angles_to_projective_transforms(np.pi/4, 3, 3)

x = tf.ones((1, 3, 3, 1))
res = tf.raw_ops.ImageProjectiveTransformV3(images=x,
                                            transforms=transform,
                                            output_shape=(3,3),
                                            interpolation=""BILINEAR"",
                                            fill_value=0)
np.squeeze(res)

array([[0.58578646, 1.        , 0.58578634],
       [1.        , 1.        , 1.        ],
       [0.58578646, 1.        , 0.58578634]], dtype=float32)
```
"
46636,Remove py_proto_library Macro from tensorflow/core/platform/default/build_config.bzl,"tensorflow/core/platform/default/build_config.bzl contains a py_proto_library macro (Re-defined protocol buffer rule) with a comment that it should be removed once the protobuf dependency version is updated to include the commit shown in the comment.

The referenced protobuf commit (294b5758c373cbab4b72f35f4cb62dc1d8332b68) has been in protobuf since v3.6.0 from 2018-06-13.

Also, TensorFlow has the following protobuf version references:
```
master      tensorflow/workspace.bzl: protobuf 3.9.2, tensorflow/tools/pip_package/setup.py: protobuf >=3.9.2
2.0 branch  tensorflow/workspace.bzl: protobuf 3.8.0, tensorflow/tools/pip_package/setup.py: protobuf >=3.6.1
```
"
46635,"Missing GPU op for zeros_like for RaggedTensorVariant, error occurs when Ragged Tensor fed thru tf.map_fn","**System information**

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, included below
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
TensorFlow installed from (source or binary): pip binary
TensorFlow version (use command below): v1.12.1-49539-g18d8bcbe72b 2.5.0-dev20210123
Python version: '3.8.6 | packaged by conda-forge | (default, Nov 27 2020, 19:31:52) \n[GCC 9.3.0]'
Bazel version (if compiling from source): n/a
GCC/Compiler version (if compiling from source): n/a
CUDA/cuDNN version: 11.0 / 8
GPU model and memory: TITAN X (Pascal) computeCapability: 6.1

**Describe the current behavior**

I have a keras layer `RescaleB` that accepts a ragged tensor with shape [batch, (time), in_dim]. The layer calls `map_fn` to process each example in the batch separately, scaling the values along the inner dimension by a trainable gain vector. (The details of the operation aren't critical, but the ragged tensor going into map_fn is.)

Using this layer fails with `No unary variant unary_op function found for unary variant op enum: 1 Variant type_name: RaggedTensorVariant for device type: GPU` on a node whose name ends with `rescale_b/map/while/TensorArrayV2Write/TensorListSetItem_grad/zeros_like` which suggests that the zeros_like operation 
isn't defined for Ragged Tensors on GPU?

In this simple example, i also include `RescaleA`, which accomplishes the same task using `tf.ragged.map_flat_values`, although in my real use case I need `map_fn`. This is a simplified example.

**Describe the expected behavior**

I'd expect `RescaleB` and `RescaleA` to function identically.


**Standalone code to reproduce the issue**

https://colab.research.google.com/drive/1mHycCXJL94VuCGkXIJ0bIXtbYamyZo78

I've reproduced the issue locally with tf-nightly-gpu TF 2.5, but I can't seem to get the nightly version to see the GPU on Colab. The Colab notebook is using TF 2.4, but the issue remains in TF 2.5 nightly.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

This may be the same issue as #44231 but hopefully the additional detail here is helpful. 
"
46634,tensorflow.greater returns a wrong bool,"### System information
[tf_env.txt](https://github.com/tensorflow/tensorflow/files/5861094/tf_env.txt)


-   I used the custom script shown below
-   Windows 10 Family version 19041.746
-   TensorFlow is installed from source
-   v2.4.0-49-g85c8b2a817f 2.4.1
-   Python 3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)] on win32
-   CUDA v11.1
-   CPU Intel Core i7-3770 @ 3.40GHz
-   GPU: GeForce GTX 1060 6GB

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
when I use the greater function from the package it gives me **True** when 1 > 1000** and **False when 1 > 10000**. I think the error is obvious enough

EDIT: Issue Fixed, it was obviously the fact that I was using Int8. I guess Python made me unused to check for overflows. Sorry for that dumb issue ^-^

### Source code / logs
>>> import tensorflow as tf
initialization is successful
>>>tf.greater(tf.convert_to_tensor(1, dtype=tf.int8), tf.convert_to_tensor(1000, dtype=tf.int8))
<tf.Tensor: shape=(), dtype=bool, numpy=True>

>>>tf.greater(tf.convert_to_tensor(1, dtype=tf.int8), tf.convert_to_tensor(10000, dtype=tf.int8))
<tf.Tensor: shape=(), dtype=bool, numpy=False>
"
46633,memory leak of tf2.3 with LSTM,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Red Hat Enterprise Linux Server 7.9 (Maipo)
- TensorFlow version (use command below): 2.3.1
- Python version: 3.7.4

**Describe the current behavior**
memory leak with training batch when using LSTM layer (no problem with dense `layer)`
**Describe the expected behavior**
no memory leak
**Standalone code to reproduce the issue**
      
import numpy as np
import tensorflow
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import Callback

import resource
class MemoryCallback(Callback):
    def on_epoch_end(self, epoch, log={}):
        print('')
        print('Memory usage: ', resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)
        
if __name__ == ""__main__"":
        n_sample=1000
        n_timestep =1000
        num_channel = 1
        batch_size=100
        epochs=10
        i_train_on_batch = False
        
        train = np.random.rand(n_sample, n_timestep, num_channel)
        label = np.random.rand(n_sample, num_channel)
        
        x=layers.Input(shape=(n_timestep,num_channel))
        z=  layers.LSTM(num_channel)(x)  
        model = keras.Model(inputs=x, outputs=z)
        
        model.compile(optimizer=""adam"", loss=""mse"")
        if i_train_on_batch:
           for epoch in range(epochs):
               for step in range(n_sample//batch_size):
                   model.train_on_batch(train[step*batch_size:(step+1)*batch_size], label[step*batch_size:(step+1)*batch_size],)
               print('Epoch ', epoch,'/', epochs, '  Memory usage: ', resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)
        else:
           model.fit(train, label, batch_size=batch_size, epochs=epochs, callbacks=[MemoryCallback()])

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

###################################################
i_train_on_batch = False:
###################################################

bash-4.2$ python memory_leak_epoch.py 
2021-01-23 16:17:38.709232: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-01-23 16:17:43.397736: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-01-23 16:17:43.404166: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-01-23 16:17:43.404195: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (taurusi4181.taurus.hrsk.tu-dresden.de): /proc/driver/nvidia/version does not exist
2021-01-23 16:17:43.406436: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Epoch 1/10
10/10 [==============================] - ETA: 0s - loss: 0.2690
Memory usage:  424672
10/10 [==============================] - 4s 364ms/step - loss: 0.2690
Epoch 2/10
10/10 [==============================] - ETA: 0s - loss: 0.2612
Memory usage:  475888
10/10 [==============================] - 4s 370ms/step - loss: 0.2612
Epoch 3/10
10/10 [==============================] - ETA: 0s - loss: 0.2533
Memory usage:  527780
10/10 [==============================] - 4s 374ms/step - loss: 0.2533
Epoch 4/10
10/10 [==============================] - ETA: 0s - loss: 0.2453
Memory usage:  578732
10/10 [==============================] - 4s 376ms/step - loss: 0.2453
Epoch 5/10
10/10 [==============================] - ETA: 0s - loss: 0.2373
Memory usage:  627480
10/10 [==============================] - 4s 381ms/step - loss: 0.2373
Epoch 6/10
10/10 [==============================] - ETA: 0s - loss: 0.2293
Memory usage:  679224
10/10 [==============================] - 4s 386ms/step - loss: 0.2293
Epoch 7/10
10/10 [==============================] - ETA: 0s - loss: 0.2212
Memory usage:  728328
10/10 [==============================] - 4s 385ms/step - loss: 0.2212
Epoch 8/10
10/10 [==============================] - ETA: 0s - loss: 0.2130
Memory usage:  777960
10/10 [==============================] - 4s 385ms/step - loss: 0.2130
Epoch 9/10
10/10 [==============================] - ETA: 0s - loss: 0.2050
Memory usage:  827592
10/10 [==============================] - 4s 390ms/step - loss: 0.2050
Epoch 10/10
10/10 [==============================] - ETA: 0s - loss: 0.1969
Memory usage:  877752
10/10 [==============================] - 4s 388ms/step - loss: 0.1969
bash-4.2$ 
###################################################
i_train_on_batch = True:
###################################################

bash-4.2$ python memory_leak_epoch.py 
2021-01-23 16:15:53.238289: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-01-23 16:15:58.148876: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-01-23 16:15:58.155607: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-01-23 16:15:58.155647: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (taurusi4181.taurus.hrsk.tu-dresden.de): /proc/driver/nvidia/version does not exist
2021-01-23 16:15:58.158445: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Epoch  0 / 10   Memory usage:  419684
Epoch  1 / 10   Memory usage:  472220
Epoch  2 / 10   Memory usage:  523804
Epoch  3 / 10   Memory usage:  574228
Epoch  4 / 10   Memory usage:  623068
Epoch  5 / 10   Memory usage:  673756
Epoch  6 / 10   Memory usage:  724180
Epoch  7 / 10   Memory usage:  774076
Epoch  8 / 10   Memory usage:  824500
Epoch  9 / 10   Memory usage:  874660



"
46632,object detection identifying even there is no image,"hello guys i have been working in tensor flow object detection I have choose mobile ssd net model and trained the model but i am  getting a very false model it is detecting even when there is no image in the video stream.
![image](https://user-images.githubusercontent.com/53184702/105580005-ca528e00-5daf-11eb-95ed-097ceeded753.png)
Even it detects the same thing while a white blank wall is before it my accuracy is good.
"
46631,An error maybe about protobufï¼,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.3.0-gpu
- Python version: 3.6.0
- Installed using virtualenv? pip? conda?:  pip
- CUDA/cuDNN version: 10.1 / 7.6.4
- GPU model and memory: 1050Ti ï¼16G



**Describe the problem**

My tensorflow is installed in the new virtual environment of anaconda.And at first my protobuf version is 3.6.0

Today, I tried to run a tensorflow program, but it reported this error.

``` File ""E:\Anaconda3.5\envs\ten2\lib\site-packages\tensorflow\python\ops\resource_variable_ops.py"", line 1666, in _init_from_args
    graph_mode=self._in_graph_mode)
  File ""E:\Anaconda3.5\envs\ten2\lib\site-packages\tensorflow\python\ops\resource_variable_ops.py"", line 243, in eager_safe_variable_handle
    shape, dtype, shared_name, name, graph_mode, initial_value)
  File ""E:\Anaconda3.5\envs\ten2\lib\site-packages\tensorflow\python\ops\resource_variable_ops.py"", line 179, in _variable_handle_from_shape_and_dtype
    handle_data.shape_and_type.append(
AttributeError: 'google.protobuf.pyext._message.RepeatedCompositeCo' object has no attribute 'append'

Process finished with exit code 1
```

Then,i try to search some informations ,some ways suggest to upgrade the version of protobuf to the latest version, the 3.14.0.
But,after upgrading,there is new problems.It show import error.
```
  File ""E:\Anaconda3.5\envs\ten2\lib\site-packages\tensorflow\core\framework\function_pb2.py"", line 7, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""E:\Anaconda3.5\envs\ten2\lib\site-packages\google\protobuf\descriptor.py"", line 48, in <module>
    from google.protobuf.pyext import _message
ImportError: DLL load failed: æ¾ä¸å°æå®çç¨åºã
```

It work well in tensorflow1.14.0 and cuda 10.0.What should i do if i still want to use tensorflow2.3.0ï¼
"
46630,[MLIR] compile error,"when I build the latest tensorflow mlir, commit id c30ad4ae0ca1a6240ec8619d5027a272394726a5, 
with 
`bazel build --override_repository=llvm-project=$LLVM_SRC -c opt tensorflow/compiler/mlir:tf-opt` or even 
`bazel build -c opt tensorflow/compiler/mlir:tf-opt`
I always get the message as below :
`tensorflow/tensorflow/compiler/mlir/xla/BUILD:176:11: C++ compilation of rule '//tensorflow/compiler/mlir/xla:mhlo_to_lhlo_with_xla' failed (Exit 1): gcc failed: error executing command /path/to/gcc650/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' ... (remaining 320 argument(s) skipped)                                                                                                                                                                                                                                    tensorflow/compiler/mlir/xla/transforms/mhlo_to_lhlo_with_xla.cc: In instantiation of 'mlir::LhloDialectEmitter::EmitGemm(const xla::HloCustomCallInstruction*)::<lambda(auto:10)> [with auto:10 = mlir::lmhlo_gpu::GEMMOp]':         tensorflow/compiler/mlir/xla/transforms/mhlo_to_lhlo_with_xla.cc:670:38:   required from here                                                                                                                                         tensorflow/compiler/mlir/xla/transforms/mhlo_to_lhlo_with_xla.cc:651:32: error: cannot call member function 'mlir::DenseIntElementsAttr mlir::LhloDialectEmitter::GetI64DenseElementsAttr(const T&) [with T = google::protobuf::RepeatedField<long int>]' without object                                                                                                                                                                                                             GetI64DenseElementsAttr(hlo_dims.lhs_batch_dimensions()),                                                                                                                                                                             ~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                     tensorflow/compiler/mlir/xla/transforms/mhlo_to_lhlo_with_xla.cc:652:32: error: cannot call member function 'mlir::DenseIntElementsAttr mlir::LhloDialectEmitter::GetI64DenseElementsAttr(const T&) [with T = google::protobuf::RepeatedField<long int>]' without object                                                                                                                                                                                                             GetI64DenseElementsAttr(hlo_dims.rhs_batch_dimensions()),                                                                                                                                                                             ~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                     tensorflow/compiler/mlir/xla/transforms/mhlo_to_lhlo_with_xla.cc:653:32: error: cannot call member function 'mlir::DenseIntElementsAttr mlir::LhloDialectEmitter::GetI64DenseElementsAttr(const T&) [with T = google::protobuf::RepeatedField<long int>]' without object                                                                                                                                                                                                             GetI64DenseElementsAttr(hlo_dims.lhs_contracting_dimensions()),                                                                                                                                                                       ~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                               tensorflow/compiler/mlir/xla/transforms/mhlo_to_lhlo_with_xla.cc:654:32: error: cannot call member function 'mlir::DenseIntElementsAttr mlir::LhloDialectEmitter::GetI64DenseElementsAttr(const T&) [with T = google::protobuf::RepeatedField<long int>]' without object                                                                                                                                                                                                             GetI64DenseElementsAttr(hlo_dims.rhs_contracting_dimensions()),                                                                                                                                                                       ~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                               tensorflow/compiler/mlir/xla/transforms/mhlo_to_lhlo_with_xla.cc: In instantiation of 'mlir::LhloDialectEmitter::EmitGemm(const xla::HloCustomCallInstruction*)::<lambda(auto:10)> [with auto:10 = mlir::lmhlo_gpu::GEMM_BiasOp]':    tensorflow/compiler/mlir/xla/transforms/mhlo_to_lhlo_with_xla.cc:678:43:   required from here                                                                                                                                         tensorflow/compiler/mlir/xla/transforms/mhlo_to_lhlo_with_xla.cc:651:32: error: cannot call member function 'mlir::DenseIntElementsAttr mlir::LhloDialectEmitter::GetI64DenseElementsAttr(const T&) [with T = google::protobuf::RepeatedField<long int>]' without object                                                                                                                                                                                                             GetI64DenseElementsAttr(hlo_dims.lhs_batch_dimensions()),                                                                                                                                                                             ~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                     tensorflow/compiler/mlir/xla/transforms/mhlo_to_lhlo_with_xla.cc:652:32: error: cannot call member function 'mlir::DenseIntElementsAttr mlir::LhloDialectEmitter::GetI64DenseElementsAttr(const T&) [with T = google::protobuf::RepeatedField<long int>]' without object                                                                                                                                                                                                             GetI64DenseElementsAttr(hlo_dims.rhs_batch_dimensions()),                                                                                                                                                                             ~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                     tensorflow/compiler/mlir/xla/transforms/mhlo_to_lhlo_with_xla.cc:653:32: error: cannot call member function 'mlir::DenseIntElementsAttr mlir::LhloDialectEmitter::GetI64DenseElementsAttr(const T&) [with T = google::protobuf::RepeatedField<long int>]' without object                                                                                                                                                                                                             GetI64DenseElementsAttr(hlo_dims.lhs_contracting_dimensions()),`

I have remove all the unrelated enviroment variables in the bash, but it still occurs. I have no idea, could anyone give some suggestions?

**System information**
- OS Platform and Distribution : CentOS Linux release 7.8.2003
- GCC/Compiler version : 6.5.0
- CUDA/cuDNN version: V10.0.130

"
46629,Linux C library for TensorFlow 2.4.1 contains macOS dylib files,"**Describe the problem**

I'm looking for the prebuilt TensorFlow C library for Linux (no GPU support).

I see from the [documentation](https://www.tensorflow.org/install/lang_c) that the C library is available for version 2.4.0 although there is already TensorFlow 2.4.1 out.

If I download the 2.4.0 library - the contact is correct:

```
wget https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-2.4.0.tar.gz
tar xvf libtensorflow-cpu-linux-x86_64-2.4.0.tar.gz
[ ... ]
./lib/
./lib/libtensorflow.so.2.4.0
./lib/libtensorflow_framework.so.2.4.0
./lib/libtensorflow_framework.so
./lib/libtensorflow_framework.so.2
./lib/libtensorflow.so
./lib/libtensorflow.so.2
```

Instead, if I download version 2.4.1 (I just change the URL), the content is for macOS (dylib instead of so):

```
wget https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-2.4.1.tar.gz
tar xvf libtensorflow-cpu-linux-x86_64-2.4.1.tar.gz
[ ... ]
./lib/
./lib/libtensorflow.2.4.1.dylib
./lib/libtensorflow_framework.2.4.1.dylib
./lib/libtensorflow_framework.dylib
./lib/libtensorflow_framework.2.dylib
./lib/libtensorflow.dylib
./lib/libtensorflow.2.dylib
```"
46628,Process finished with exit code 132 (interrupted by signal 4: SIGILL),"![image](https://user-images.githubusercontent.com/24789356/105575143-48a93300-5da4-11eb-9260-4846a809e2ea.png)
i use tensorflow 2.4.1  in mac"
46627,Function contrastive_loss is not supported when converted,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:a GNU/Linux system with Linux kernel 4.15.0 on 1 6-core 3.60GHz Intel Core CPU i7-6850K with 64 GB RAM equipped with a NVIDIA Corporation GP102 GPUs
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below):tensorflow2-GPU
- Python version:3.6

**Describe the current behavior**
When I converted the trained hdf5 model to pb, the following function non-support occurred ï¼contrastive_loss

**Describe the expected behavior**
The hdf5 model should be successfully converted.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
from __future__ import absolute_import
from __future__ import print_function
import numpy as np

import random
from keras.datasets import mnist
from keras.models import Model
from keras.layers import Input, Flatten, Dense, Dropout, Lambda
from keras.optimizers import RMSprop
from keras import backend as K
import time
begin_time = time.time()
num_classes = 10
epochs = 20


def euclidean_distance(vects):
    x, y = vects
    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)
    return K.sqrt(K.maximum(sum_square, K.epsilon()))


def eucl_dist_output_shape(shapes):
    shape1, shape2 = shapes
    return (shape1[0], 1)


def contrastive_loss(y_true, y_pred):
    '''Contrastive loss from Hadsell-et-al.'06
    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf
    '''
    margin = 1
    square_pred = K.square(y_pred)
    margin_square = K.square(K.maximum(margin - y_pred, 0))
    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)


def create_pairs(x, digit_indices):
    '''Positive and negative pair creation.
    Alternates between positive and negative pairs.
    '''
    pairs = []
    labels = []
    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1
    for d in range(num_classes):
        for i in range(n):
            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]
            pairs += [[x[z1], x[z2]]]
            inc = random.randrange(1, num_classes)
            dn = (d + inc) % num_classes
            z1, z2 = digit_indices[d][i], digit_indices[dn][i]
            pairs += [[x[z1], x[z2]]]
            labels += [1, 0]
    return np.array(pairs), np.array(labels)


def create_base_network(input_shape):
    '''Base network to be shared (eq. to feature extraction).
    '''
    input = Input(shape=input_shape)
    x = Flatten()(input)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.6)(x)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.1)(x)
    x = Dense(128, activation='relu')(x)
    return Model(input, x)


def compute_accuracy(y_true, y_pred):
    '''Compute classification accuracy with a fixed threshold on distances.
    '''
    pred = y_pred.ravel() < 0.5
    return np.mean(pred == y_true)


def accuracy(y_true, y_pred):
    '''Compute classification accuracy with a fixed threshold on distances.
    '''
    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))


# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
input_shape = x_train.shape[1:]

# create training+test positive and negative pairs
digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]
tr_pairs, tr_y = create_pairs(x_train, digit_indices)

digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]
te_pairs, te_y = create_pairs(x_test, digit_indices)

# network definition
base_network = create_base_network(input_shape)

input_a = Input(shape=input_shape)
input_b = Input(shape=input_shape)

# because we re-use the same instance `base_network`,
# the weights of the network
# will be shared across the two branches
processed_a = base_network(input_a)
processed_b = base_network(input_b)

distance = Lambda(euclidean_distance,
                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])

model = Model([input_a, input_b], distance)

# train
rms = RMSprop()
model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])
model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,
          batch_size=128,
          epochs=epochs,
          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))
# compute final accuracy on training and test sets
y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])
tr_acc = compute_accuracy(tr_y, y_pred)
y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])
te_acc = compute_accuracy(te_y, y_pred)
start_time = time.time()
end_time = time.time()
time_data = end_time - start_time
print('Training Time costs', start_time - begin_time)
print('Tesing Time costs', time_data)
print('Test accuracy:' ,te_acc)
model.save('model/151.h5')
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
Using TensorFlow backend.
2020-10-23 10:09:30.768594: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-10-23 10:09:32.233609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6325
pciBusID: 0000:05:00.0
totalMemory: 10.92GiB freeMemory: 10.77GiB
2020-10-23 10:09:32.340284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6325
pciBusID: 0000:09:00.0
totalMemory: 10.92GiB freeMemory: 10.77GiB
2020-10-23 10:09:32.341621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2020-10-23 10:09:33.016225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-23 10:09:33.016290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2020-10-23 10:09:33.016303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2020-10-23 10:09:33.016312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2020-10-23 10:09:33.016476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10426 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-10-23 10:09:33.199564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10428 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)
E1023 10:09:33.461142 140655137916672 keras_to_tensorflow.py:94] Input file specified only holds the weights, and not the model definition. Save the model using model.save(filename.h5) which will contain the network architecture as well as its weights. If the model is saved using the model.save_weights(filename) function, either input_model_json or input_model_yaml flags should be set to to import the network architecture prior to loading the weights. 
Check the keras documentation for more details (https://keras.io/getting-started/faq/)
Traceback (most recent call last):
  File ""keras_to_tensorflow.py"", line 181, in <module>
    app.run(main)
  File ""/home/dl/anaconda3/envs/dong/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/dl/anaconda3/envs/dong/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""keras_to_tensorflow.py"", line 127, in main
    model = load_model(FLAGS.input_model, FLAGS.input_model_json, FLAGS.input_model_yaml)
  File ""keras_to_tensorflow.py"", line 105, in load_model
    raise wrong_file_err
  File ""keras_to_tensorflow.py"", line 62, in load_model
    model = keras.models.load_model(input_model_path)
  File ""/home/dl/anaconda3/envs/dong/lib/python3.6/site-packages/keras/engine/saving.py"", line 419, in load_model
    model = _deserialize_model(f, custom_objects, compile)
  File ""/home/dl/anaconda3/envs/dong/lib/python3.6/site-packages/keras/engine/saving.py"", line 312, in _deserialize_model
    sample_weight_mode=sample_weight_mode)
  File ""/home/dl/anaconda3/envs/dong/lib/python3.6/site-packages/keras/engine/training.py"", line 139, in compile
    loss_function = losses.get(loss)
  File ""/home/dl/anaconda3/envs/dong/lib/python3.6/site-packages/keras/losses.py"", line 133, in get
    return deserialize(identifier)
  File ""/home/dl/anaconda3/envs/dong/lib/python3.6/site-packages/keras/losses.py"", line 114, in deserialize
    printable_module_name='loss function')
  File ""/home/dl/anaconda3/envs/dong/lib/python3.6/site-packages/keras/utils/generic_utils.py"", line 165, in deserialize_keras_object
    ':' + function_name)
ValueError: Unknown loss function:contrastive_loss

```"
46626,Operator Softsign and Softplus are not supported by the standard TensorFlow Lite runtime,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:a GNU/Linux system with Linux kernel 4.15.0 on 1 6-core 3.60GHz Intel Core CPU i7-6850K with 64 GB RAM equipped with a NVIDIA Corporation GP102 GPUs
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below):tensorflow2-GPU
- Python version:3.6

**Describe the current behavior**
When I converted the trained hdf5 model to tflite, the following operator non-support occurred ï¼Softsign

**Describe the expected behavior**
The hdf5 model should be successfully converted to the format of tflite.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
batch_size = 80
epochs = 171
num_classes = 10
import os
save_dir = 'model'
model_name = 'model.h5'
import keras as keras
(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()
img_rows, img_cols = x_train.shape[1], x_train.shape[2]

x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
input_shape = (img_rows, img_cols, 1)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

import keras as keras
model = keras.models.Sequential()
model.add(keras.layers.ThresholdedReLU(theta=0.3514439122821289))
model.add(keras.layers.LeakyReLU(alpha=0.4855740853866919))
model.add(keras.layers.AveragePooling2D(pool_size = (1, 2), padding='same'))

model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(num_classes, activation='softsign'))
model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])
model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))

model_path = os.path.join(save_dir, model_name)
model.save(model_path)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: AVERAGE_POOL_2D, CAST, FULLY_CONNECTED, GREATER, MAXIMUM, MUL. Here is a list of operators for which you will need custom implementations: Softsign.
```
"
46625,Operator Softplus is not supported by the standard TensorFlow Lite runtime,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): a GNU/Linux system with Linux kernel 4.15.0 on 1 6-core 3.60GHz Intel Core CPU i7-6850K with 64 GB RAM equipped with a NVIDIA Corporation GP102 GPUs
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): tensorflow2.1.0-GPU
- Python version: 3.6

**Describe the current behavior**
When I converted the trained hdf5 model to tflite, the following operator non-support occurred ï¼Softplus

**Describe the expected behavior**
The hdf5 model should be successfully converted to the format of tflite.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
batch_size = 122
epochs = 148
num_classes = 10
import os
save_dir = 'model'
model_name = 'trained_model.h5'
import keras as keras
(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()
img_rows, img_cols = x_train.shape[1], x_train.shape[2]

x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
input_shape = (img_rows, img_cols, 1)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

import keras as keras
model = keras.models.Sequential()
model.add(keras.layers.ThresholdedReLU(theta=0.3597445834106594))
model.add(keras.layers.MaxPooling2D(pool_size = (1, 1), strides = (1, 1), padding = 'valid'))

model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(num_classes, activation='softplus'))
model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])
model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))

model_path = os.path.join(save_dir, model_name)
model.save(model_path)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CAST, FULLY_CONNECTED, GREATER, MAX_POOL_2D, MUL. Here is a list of operators for which you will need custom implementations: Softplus.
```
"
46624,"NaN occurs when building with Dropout, Conv2DTranspose, LeakyReLU, ELU, PReLU, Flatten and Dense","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:a GNU/Linux system with Linux kernel 4.15.0 on 1 6-core 3.60GHz Intel Core CPU i7-6850K with 64 GB RAM equipped with a NVIDIA Corporation GP102 GPUs
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below):tensorflow2-GPU
- Python version:3.6

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I got the NaN loss when I tried to train my model

**Describe the expected behavior**
The loss should be a number

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
batch_size = 56
epochs = 75
num_classes = 10
import os
save_dir = 'model'
model_name = 'trained_model.h5'
import tensorflow.keras as keras
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
img_rows, img_cols = x_train.shape[1], x_train.shape[2]

x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
input_shape = (img_rows, img_cols, 1)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
import time
begin_time = time.time()
import tensorflow.keras as keras
model = keras.models.Sequential()
model.add(keras.layers.Dropout(rate = 0.21019177254509236,noise_shape=None, seed = 5))
model.add(keras.layers.Conv2DTranspose(filters=7,kernel_size=(11, 11), strides=(11, 11), padding='same',activation='tanh',kernel_initializer='Constant'))
model.add(keras.layers.LeakyReLU(alpha=0.28649457154482805))
model.add(keras.layers.ELU(alpha=0.7631891438465761))
model.add(keras.layers.PReLU(alpha_initializer='Constant'))

model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(num_classes, activation='selu'))
model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])
model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))
start_time = time.time()
score = model.evaluate(x_test, y_test, verbose=0)
end_time = time.time()
time_data = end_time - start_time
print('Training Time costs', start_time - begin_time)
print('Tesing Time costs', time_data)
print('Test accuracy:', score[1])
model_path = os.path.join(save_dir, model_name)
model.save(model_path)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
Epoch 175
10721072 [==============================] - 641s 598msstep - loss nan - accuracy 0.0987 - val_loss nan - val_accuracy 0.0980
Epoch 275
10721072 [==============================] - 651s 607msstep - loss nan - accuracy 0.0987 - val_loss nan - val_accuracy 0.0980
Epoch 375
10721072 [==============================] - 671s 626msstep - loss nan - accuracy 0.0987 - val_loss nan - val_accuracy 0.0980
Epoch 475
10721072 [==============================] - 684s 638msstep - loss nan - accuracy 0.0987 - val_loss nan - val_accuracy 0.0980
Epoch 575
 7601072 [====================.........] - ETA 307 - loss nan - accuracy 0.0989
```
"
46623,UnimplementedError | InvalidArgumentError when running tf.nn.conv2d with data_format NCHW,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 2019
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.1
- Python version: 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
As declared in the specification, tf.nn.con2d should support both ""NHWC"" and ""NCHW"" format. However, per our experiment, running it with data in ""NCHW"" format will trigger some unexpected behaviors.

*data_format â An optional `string` from: `""NHWC"", ""NCHW""`. Defaults to `""NHWC""`. Specify the data format of the input and output data. With the default format ""NHWC"", the data is stored in the order of: [batch, height, width, channels]. Alternatively, the format could be ""NCHW"", the data storage order of: [batch, channels, height, width].*

**Code to reproduce **
x = np.random.randn(1, 3, 12, 12)
x_tf = tf.convert_to_tensor(x, dtype=tf.float32)

weights=np.ones([2,2,3,8])
weights_tf = tf.convert_to_tensor(weights, dtype=tf.float32)
stride=1
sess = tf.compat.v1.Session()
tf_conv2d = tf.nn.conv2d(x_tf,
                         weights_tf,
                         strides=[1, stride, stride, 1],
                         padding=""SAME"",data_format=""NCHW"",use_cudnn_on_gpu=False)
sess.run(tf.global_variables_initializer())
tf_result = sess.run(tf_conv2d)
print(tf_result.shape)

when set strides=[1,1,1,1]  trigger a bug:
""UnimplementedError (see above for traceback): Generic conv implementation only supports NHWC tensor format for now.""

when set strides=[1,2,2,1]  trigger a bug:
""InvalidArgumentError (see above for traceback): Current implementation does not yet support strides in the batch and depth dimensions.""

**Describe the expected behavior**
No exception during execution

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46622,"NaN occurs when building with BatchNormalization, PReLU, Flatten and Dense","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:a GNU/Linux system with Linux kernel 4.15.0 on 1 6-core 3.60GHz Intel Core CPU i7-6850K with 64 GB RAM equipped with a NVIDIA Corporation GP102 GPUs
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below):tensorflow2-GPU
- Python version:3.6

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I got the NaN loss when I tried to train my model

**Describe the expected behavior**
The loss should be a number

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
batch_size = 112
epochs = 119
num_classes = 10
import os
save_dir = 'model'
model_name = 'test971_trained_model.h5'
import tensorflow.keras as keras
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')
img_rows, img_cols = x_train.shape[1], x_train.shape[2]
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
model = keras.models.Sequential()
model.add(keras.layers.BatchNormalization(momentum = 0.4639004933194679,epsilon=0.6515653837017596))
model.add(keras.layers.PReLU(alpha_initializer='Zeros'))

model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(num_classes))
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])
model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))
model_path = os.path.join(save_dir, model_name)
model.save(model_path)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
Epoch 1/119

  112/50000 [..............................] - ETA: 37:05 - loss: nan - accuracy: 0.0804

  448/50000 [..............................] - ETA: 9:20 - loss: nan - accuracy: 0.0826 

  784/50000 [..............................] - ETA: 5:22 - loss: nan - accuracy: 0.0778
```
"
46621,"tf.reduce_max returns wrong answers on large tensors e.g., (2048,2048,1024)","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): docker run nvcr.io/nvidia/tensorflow:20.12-tf2-py3
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11
- GPU model and memory: RTX 3090, 24GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Computing the max of a large 3d matrix returns the incorrect answer

**Describe the expected behavior**
I would expect the value of the function to correct!

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
for i in range(12):
    n = 2**i
    x = np.arange(n*n*1024, dtype=np.float32).reshape((n,n,1024))
    print(x.shape, np.max(x), tf.reduce_max(x).numpy())
```
```

(1, 1, 1024) 1023.0 1023.0
(2, 2, 1024) 4095.0 4095.0
(4, 4, 1024) 16383.0 16383.0
(8, 8, 1024) 65535.0 65535.0
(16, 16, 1024) 262143.0 262143.0
(32, 32, 1024) 1048575.0 1048575.0
(64, 64, 1024) 4194303.0 4194303.0
(128, 128, 1024) 16777215.0 16777215.0
(256, 256, 1024) 67108864.0 67108864.0
(512, 512, 1024) 268435460.0 268435460.0
(1024, 1024, 1024) 1073741800.0 1073741800.0

(2048, 2048, 1024) 4294967300.0 -3.4028235e+38

```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46620,TFLite outputs different inference results for the same input,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (or github SHA if from source): 2.3.1


**Command used to run the converter or code if youâre using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

**Notebook Link: https://github.com/BernardoGO/tflite_convert_bug/blob/main/BiLSTM%20Conversion%20Test.ipynb**

```
converter = tf.lite.TFLiteConverter.from_keras_model(new_model)
#converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
#converter.allow_custom_ops=True
tflite_model = converter.convert()

open(""tf_test.tflite"", ""wb"").write(tflite_model)
```

**The output from the converter invocation**

```
INFO:tensorflow:Assets written to: /tmp/tmp4xjrqwpb/assets
Out[9]: 476052
```

**Graph Definition**

```
new_model = Sequential()
new_model.add(Input(name='input', batch_size=1, shape=(925, 3)) )
new_model.add(Dense(8))
new_model.add(LSTM(64, return_sequences=True))
new_model.add(LSTM(64, return_sequences=True))
new_model.add(LSTM(64, return_sequences=True))
new_model.add(LSTM(64, return_sequences=True))
new_model.add(Activation('softmax', name='softmax'))

new_model.summary()
```

**Failure details**

- Producing wrong results and/or decrease in accuracy

The model was converted successfully, but the output differs for each execution. The same does not happen for the non-converted TensorFlow model, which always yields the same results.
I've attached a notebook that shows how to reproduce the problem and how to detect it. After a few runs, the output gets more consistent.
It only happens when using LSTMs and seems to get even worse when using return_sequences=True.

**Any other info / logs**

- I've used this function to check if the output is the same after each execution:
```
def equal(tensor1, tensor2):
    for i, j in zip(tensor1.reshape(-1), tensor2.reshape(-1)):
        if abs(i - j) > 0.001:
            return False
    return True
```

![image](https://user-images.githubusercontent.com/1606650/105568097-9fb3f700-5d15-11eb-96c7-762667033f89.png)

"
46619,Error MTCNN with tensorflow ROCM ,"Traceback (most recent call last):
  File ""webcam.py"", line 51, in <module>
    main()
  File ""webcam.py"", line 32, in main
    boxes, _ = detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)
  File ""/home/taitang/tracking/mtcnn-face-detect/src/detect_face.py"", line 361, in detect_face
    tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]
ValueError: could not broadcast input array from shape (457,628,3) into shape (0,628,3)

i tried to run pretrain model MTCNN with Tensorflow ROCM and I received error message as above. Any one help me? Thanks"
46618,custom hardware support for tensorflow,"Tensorflow currently has support for CPU and GPU devices, adding a new device seems possible but the documentation is out of date. The most recent activity on this seems to be from git hub issue: https://github.com/tensorflow/tensorflow/issues/4359

Is there more current documentation or is there a best practice for adding a device? Has anyone been through the process of adding custom ML hardware under tensorflow?"
46617,TF 2.4.1 and tf_nightly-2.5.0.dev20210122 dump core on Intel Xeon ES462 under Ubuntu 20.04.1,"**System information**
System: Intel Xeon ES462 under Ubuntu 20.04.1
Python 3.8.5
TensorFlow 2.4.1 and tf_nightly-2.5.0.dev20210122-cp38-cp38-manylinux2010_x86_64.whl

**Describe the current behavior**
Core dumped with illegal instruction (vpxor)

**Describe the expected behavior**
Core not dumped

**Standalone code to reproduce the issue**
import tensorflow

**Other info / logs** Include any logs or source code that would be helpful to
Partial backtrace:
```
Program terminated with signal SIGILL, Illegal instruction.
#0  0x00007fee27336930 in nsync::nsync_mu_init(nsync::nsync_mu_s_*) () from /home/REDACTED/virtualenv3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
[Current thread is 1 (Thread 0x7fee80a8d740 (LWP 68631))]
(gdb) bt
#0  0x00007fee27336930 in nsync::nsync_mu_init(nsync::nsync_mu_s_*) () from /home/REDACTED/virtualenv3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#1  0x00007fee18748c5b in tensorflow::monitoring::Counter<2>* tensorflow::monitoring::Counter<2>::New<char const (&) [46], char const (&) [58], char const (&) [11], char const (&) [7]>(char const (&) [46], char const (&) [58], char const (&) [11], char const (&) [7]) ()
   from /home/REDACTED/virtualenv3/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#2  0x00007fee1870d31e in _GLOBAL__sub_I_loader.cc () from /home/REDACTEDr/virtualenv3/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#3  0x00007fee80e6fb8a in ?? () from /lib64/ld-linux-x86-64.so.2

(gdb) disassemble
Dump of assembler code for function _ZN5nsync13nsync_mu_initEPNS_11nsync_mu_s_E:
=> 0x00007fee27336930 <+0>:	vpxor  %xmm0,%xmm0,%xmm0
   0x00007fee27336934 <+4>:	push   %rbp
   0x00007fee27336935 <+5>:	mov    %rsp,%rbp
   0x00007fee27336938 <+8>:	vmovups %xmm0,(%rdi)
   0x00007fee2733693c <+12>:	pop    %rbp
   0x00007fee2733693d <+13>:	retq   
```
"
46616,XLA Convolution Causes Segmentation Fault,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04
- TensorFlow installed from (source or binary): From source, commit: 78ba23b6bcd7fe416aad1da4fe47b2b6036e09ad
- TensorFlow version (use command below): commit: 78ba23b6bcd7fe416aad1da4fe47b2b6036e09ad
- Python version: 3.8.5
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: 11.0/8.0.4
- GPU model and memory: GeForce RTX 2070, Driver: 460.32.03

**Describe the current behavior**

I'm currently working on writing XLA support for another language. Recently, I upgraded to CUDA 11.0 and cuDNN 8.0.4. Previously, we were using CUDA 10.2 and cuDNN 7. After the switch, all of our convolution tests started producing SegFaults. We also get some warnings during execution:

```
warning: Linking two modules of different target triples: '/usr/local/cuda-11.0/nvvm/libdevice/libdevice.10.bc' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'
```

Occasionally, it will warn about failing to find an optimal convolution algorithm and fall back to the default before SegFaulting.

I suspect it has something to do with a version mismatch. I was originally running off an older commit (prior to 2.4 getting released), and upgraded to the most recent commit to see if it would fix it, but the issue persists.

**Standalone code to reproduce the issue**

An XLA computation similar to this should reproduce (I'm working in a separate language to build up the computations).

```
  xla::XlaBuilder* builder = new xla::XlaBuilder(""conv"");
  xla::Shape input_shape = xla::ShapeUtil::MakeShape(xla::PrimitiveType::F32, {32, 3, 120, 120});
  xla::Shape kernel_shape = xla::ShapeUtil::MakeShape(xla::PrimitiveType::F32, {32, 3, 3, 3});

  xla::XlaOp inp = xla::RngUniform(*builder, input_shape);
  xla::XlaOp kernel = xla::RngUniform(*builder, kernel_shape);

  xla::ConvolutionDimensionNumbers dimension_numbers;
  dimension_numbers.set_input_batch_dimension(0);
  dimension_numbers.set_input_feature_dimension(1);
  dimension_numbers.set_kernel_output_feature_dimension(0);
  dimension_numbers.set_kernel_input_feature_dimension(1);
  dimension_numbers.set_output_batch_dimension(0);
  dimension_numbers.set_output_feature_dimension(1);

  xla::XlaOp result = xla::ConvGeneralDilated(inp,
                                              kernel,
                                              /*padding=*/{},
                                              /*lhs_dilation=*/{},
                                              /*rhs_dilation=*/{},
                                              /*conv_dimnos=*/dimension_numbers);
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Core Dump backtrace:

```
#0  0x00007fae997adc84 in ?? () from /lib/x86_64-linux-gnu/libcuda.so.1
#1  0x00007fae9974144b in ?? () from /lib/x86_64-linux-gnu/libcuda.so.1
#2  0x00007fae997417b8 in ?? () from /lib/x86_64-linux-gnu/libcuda.so.1
#3  0x00007fae99998697 in ?? () from /lib/x86_64-linux-gnu/libcuda.so.1
#4  0x00007fae99998c02 in ?? () from /lib/x86_64-linux-gnu/libcuda.so.1
#5  0x00007fae99759d8a in ?? () from /lib/x86_64-linux-gnu/libcuda.so.1
#6  0x00007fae9999e3e0 in ?? () from /lib/x86_64-linux-gnu/libcuda.so.1
#7  0x00007fae99713243 in ?? () from /lib/x86_64-linux-gnu/libcuda.so.1
#8  0x00007fae99714555 in ?? () from /lib/x86_64-linux-gnu/libcuda.so.1
#9  0x00007fae997bab93 in cuLaunchKernel () from /lib/x86_64-linux-gnu/libcuda.so.1
#10 0x00007faa1d62f8bb in ?? () from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#11 0x00007faa1d671686 in ?? () from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#12 0x00007faa1a926124 in cudnn::cnn::cudnnIm2Col4d(cudnnContext*, cudnnTensor4dStruct*, void const*, cudnnFilter4dStruct*, cudnnConvolutionStruct*, void*) ()
   from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#13 0x00007faa1a8e05a0 in cudnn::cnn::GemmConvolveEngine<cudnn::cnn::gemm_convolve_launch_pf<double, double, double, double>, false, 9, 2>::execute_internal_impl(cudnn::backend::VariantPack const&, CUstream_st*) () from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#14 0x00007faa1a537033 in cudnn::cnn::EngineInterface::execute(cudnn::backend::VariantPack const&, CUstream_st*) () from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#15 0x00007faa1a563960 in cudnn::cnn::EngineContainer<(cudnnBackendEngineName_t)2, 4096ul>::execute_internal_impl(cudnn::backend::VariantPack const&, CUstream_st*) ()
   from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#16 0x00007faa1a537033 in cudnn::cnn::EngineInterface::execute(cudnn::backend::VariantPack const&, CUstream_st*) () from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#17 0x00007faa1a5be18c in cudnn::cnn::AutoTransformationExecutor::execute_pipeline(cudnn::cnn::ConvolutionEngine&, cudnn::backend::VariantPack const&, CUstream_st*) const ()
   from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#18 0x00007faa1a5d9871 in cudnn::cnn::GeneralizedConvolutionEngine<cudnn::cnn::EngineContainer<(cudnnBackendEngineName_t)2, 4096ul> >::execute_internal_impl(cudnn::backend::VariantPack const&, CUs--Type <RET> for more, q to quit, c to continue without paging--
tream_st*) () from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#19 0x00007faa1a537033 in cudnn::cnn::EngineInterface::execute(cudnn::backend::VariantPack const&, CUstream_st*) () from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#20 0x00007faa1a53e730 in cudnn::backend::execute(cudnnContext*, cudnn::backend::ExecutionPlan&, cudnn::backend::VariantPack&) () from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#21 0x00007faa1a63f40c in cudnn::backend::EnginesAlgoMap<cudnnConvolutionFwdAlgo_t, 8>::execute_wrapper(cudnnContext*, cudnnConvolutionFwdAlgo_t, cudnn::backend::ExecutionPlan&, cudnn::backend::VariantPack&) () from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#22 0x00007faa1a638ad9 in cudnn::backend::convolutionForward(cudnnContext*, void const*, cudnnTensorStruct const*, void const*, cudnnFilterStruct const*, void const*, cudnnConvolutionStruct const*, cudnnConvolutionFwdAlgo_t, void*, unsigned long, bool, void const*, void const*, void const*, cudnnActivationStruct const*, cudnnTensorStruct const*, void*) ()
   from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#23 0x00007faa1a73ae96 in cudnn::cnn::convolutionForward(cudnnContext*, void const*, cudnnTensorStruct*, void const*, cudnnFilterStruct*, void const*, cudnnConvolutionStruct*, cudnnConvolutionFwdAlgo_t, void*, unsigned long, void const*, cudnnTensorStruct*, void*) () from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#24 0x00007faa1a73b94c in cudnnConvolutionForward () from /lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8
#25 0x00007fadf91ab772 in cudnnConvolutionForward () from /home/sean/projects/exla/_build/test/lib/exla/priv/libexla.so
#26 0x00007fadf9191c6d in stream_executor::gpu::CudnnSupport::DoConvolve(stream_executor::dnn::ConvolutionKind, stream_executor::dnn::DataType, stream_executor::dnn::DataType, stream_executor::Stream*, stream_executor::dnn::BatchDescriptor const&, stream_executor::DeviceMemoryBase, stream_executor::dnn::FilterDescriptor const&, stream_executor::DeviceMemoryBase, stream_executor::dnn::BatchDescriptor const&, stream_executor::DeviceMemoryBase, stream_executor::dnn::ConvolutionDescriptor const&, stream_executor::dnn::AlgorithmDesc, stream_executor::DeviceMemory<unsigned char>, stream_executor::dnn::ProfileResult*) () from /home/sean/projects/exla/_build/test/lib/exla/priv/libexla.so
#27 0x00007fadf72a1735 in tensorflow::Status xla::gpu::(anonymous namespace)::RunGpuConvImpl<double, double, double>(xla::gpu::GpuConvParams const&, stream_executor::ScratchAllocator*, stream_executor::Stream*, xla::gpu::RunConvOptions) () from /home/sean/projects/exla/_build/test/lib/exla/priv/libexla.so
#28 0x00007fadf72a4a2e in xla::gpu::RunGpuConv(xla::gpu::GpuConvConfig const&, absl::lts_2020_02_25::Span<stream_executor::DeviceMemoryBase>, stream_executor::DeviceMemoryBase, stream_executor::ScratchAllocator*, stream_executor::Stream*, xla::gpu::RunConvOptions) () from /home/sean/projects/exla/_build/test/lib/exla/priv/libexla.so
#29 0x00007fadf72a70e4 in xla::gpu::RunGpuConv(xla::gpu::GpuConvConfig const&, absl::lts_2020_02_25::Span<stream_executor::DeviceMemoryBase>, stream_executor::DeviceMemoryBase, stream_executor::DeviceMemoryBase, stream_executor::Stream*, xla::gpu::RunConvOptions) () from /home/sean/projects/exla/_build/test/lib/exla/priv/libexla.so
#30 0x00007fadf72473fb in xla::gpu::ConvolutionThunk::ExecuteOnStream(xla::gpu::Thunk::ExecuteParams const&) () from /home/sean/projects/exla/_build/test/lib/exla/priv/libexla.so
--Type <RET> for more, q to quit, c to continue without paging--
#31 0x00007fadf72573bb in xla::gpu::GpuExecutable::ExecuteThunks(xla::ServiceExecutableRunOptions const*, xla::gpu::BufferAllocations const&, bool, xla::HloExecutionProfile*) ()
   from /home/sean/projects/exla/_build/test/lib/exla/priv/libexla.so
#32 0x00007fadf725c2cc in xla::gpu::GpuExecutable::ExecuteAsyncOnStreamImpl(xla::ServiceExecutableRunOptions const*, absl::lts_2020_02_25::variant<absl::lts_2020_02_25::Span<xla::ShapedBuffer const* const>, absl::lts_2020_02_25::Span<xla::ExecutionInput> >, xla::HloExecutionProfile*) () from /home/sean/projects/exla/_build/test/lib/exla/priv/libexla.so
#33 0x00007fadf725c8f8 in xla::gpu::GpuExecutable::ExecuteAsyncOnStream(xla::ServiceExecutableRunOptions const*, std::vector<xla::ExecutionInput, std::allocator<xla::ExecutionInput> >, xla::HloExecutionProfile*) () from /home/sean/projects/exla/_build/test/lib/exla/priv/libexla.so
#34 0x00007fadfd69b286 in xla::Executable::ExecuteAsyncOnStreamWrapper(xla::ServiceExecutableRunOptions const*, std::vector<xla::ExecutionInput, std::allocator<xla::ExecutionInput> >) ()
   from /home/sean/projects/exla/_build/test/lib/exla/priv/libexla.so
#35 0x00007fadf90c0df7 in xla::LocalExecutable::RunAsync(absl::lts_2020_02_25::Span<xla::Shape const* const>, std::vector<xla::ExecutionInput, std::allocator<xla::ExecutionInput> >, xla::ExecutableRunOptions) () from /home/sean/projects/exla/_build/test/lib/exla/priv/libexla.so
#36 0x00007fadf90c17c8 in xla::LocalExecutable::RunAsync(std::vector<xla::ExecutionInput, std::allocator<xla::ExecutionInput> >, xla::ExecutableRunOptions) ()
```

Forgive me if this is a CUDA version issue, or if this is a question better asked in the XLA Dev Group."
46615,ExponentialMovingAverage Does Not Work Under tf.function (TF 2.4),"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
The average variable becomes None and seems like the Tensor is not tracked.
**Describe the expected behavior**
Tensor being properly tracked and valid average value being returned.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Colab: https://colab.research.google.com/drive/17W7CVfDqx-HTbcRMphhQYg6WCq-ELg_K?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Autograph logs show that the function is traced twice. While the first pass shows everything alright, including the tensor being properly tracked, the second pass seems not to be the case although the generated graph has been reused."
46613,ERRORS ,"

- Windows 10 64-bit 
- python 3.8.3 and pip 20.3.3

every time I try to install I get the same error messages:
ERROR: Could not find a version that satisfies the requirement tensorflow
ERROR: No matching distribution found for tensorflow

im kind of at a loss for what to do, any help would be appreciated 
"
46610,Object Detection API to Tensorflow Lite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source): 2.4.0
- CUDA 11.0

I have successfully trained my own model using the Object Detection API. 
As a pre-trained model I used ssd_resnet50v1_fpn_640x60.
The detection works fine.

Now I want to convert the trained model to Tensorflow Lite.
I used export_tflite_graph_tf2.py and after that the TensorFlow Lite-Konverter-API:

```
import tensorflow as tf

# Convert the model
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory from export_tflite_graph_tf2.py
tflite_model = converter.convert()

# Save the model.
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
```

The model.tflite was succesfully created but unfortunately when I run the detection, nothing is detected.
tflite-runtime: 2.5.0
I used this guide https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md and with the coco_ssd_mobilenet_v1_1.0_quant_2018_06_29 everything works.

I got no errors, just no detection with my own model at all.
does anyone have an idea what this can be due to?

"
46609,Trilinear interpolation in UpSampling3D,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.4
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Current UpSampling3D implementation only has the nearest-neighbor interpolation. UpSampling2D has both nearest-neighbor and bilinear interpolations. 

**Will this change the current api? How?**
Yes, with trilinear interpolation UpSampling3D will have an argument like interpolation='trilinear', similar to the one in UpSampling2D, interpolation='bilinear'. 

**Who will benefit with this feature?**
3D vision tasks that use linear interpolation upsampling features, such as in 3D medical image segmentation. 

**Any Other info.**"
46608,Deleting a model and clearing the session if other models are still loaded and in use,"In my Python application I load several TF 2.4 / Keras models in parallel and use their `predict()` functions in separate threads. The single GPU in the machine is locked by a Python `Lock`, so that these threads cannot run ""their"" TF models at the same time. Now at some point a thread can decide to delete its currently loaded TF model (via Python's `del` command) and load another one (via `tensorflow.keras.models.load_model()`). However, in that case the other threads with their loaded TF models must not be affected.

Now I want to free all memory when I delete a model in a thread and load another model. So I thought about calling `tf.keras.backend.clear_session()` after deleting a model. But it seems that is not an option in my case, since other models are still loaded and in use, as described above.

I might put all these models into their own processes (instead of using threads), but then I might run into the problem that I cannot lock and make use of that single GPU from multiple processes in parallel. So is there another, ""official"" method to properly free all memory after deleting a TF/Keras model in such a multi-model setup?"
46607,INFO:absl:using experimental converter:if you encountered a problem please file a bug,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Command used to run the converter or code if youâre using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
```

**The output from the converter invocation**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
46606,No GPU support for Windows10 + CUDA 11.0 + Tensorflow 2.4.1: Could not load dynamic library 'cudart64_110.dll',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10
- TensorFlow installed from (source or binary): pip / packet manager of PyCharm
- TensorFlow version: 2.4.1
- Python version: 3.8
- Installed using virtualenv? pip? conda?: pip / from PyCharm settings menu but it is pip install tensorflow
- CUDA/cuDNN version: CUDA: cuda_11.0.2_451.48_win10 and cuDNN: 8.0.4: cudnn-11.0-windows-x64-v8.0.4.30
- GPU model and memory: GeForce MX330 with 2GB

**Describe the problem**
Hi Guys, I've been trying for around 6hours to get Tensorflow 2.4.1 working with GPU support and following tutorial from pyimagesearch:
https://www.pyimagesearch.com/2018/09/10/keras-tutorial-how-to-get-started-with-keras-deep-learning-and-python/
Using only CPU it worked fine.
I have followed this guide here:
https://www.tensorflow.org/install/gpu
I installed the newest drivers for my GeforceMX330, as well as VisualStudio, CUDA11.0 and the cuDNN 8.0.4 version. Please see my log output


**Any other info / logs**
`train_vgg.py --dataset animals --model output/smallvggnet.model --label-bin output/smallvggnet_lb.pickle --plot output/smallvggnet_plot.png
2021-01-22 15:21:23.627735: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-01-22 15:21:23.628081: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[INFO] loading images...
2021-01-22 15:21:42.850382: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-22 15:21:42.852694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2021-01-22 15:21:43.635517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce MX330 computeCapability: 6.1
coreClock: 1.594GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 52.21GiB/s
2021-01-22 15:21:43.636419: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-01-22 15:21:43.637390: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2021-01-22 15:21:43.638212: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2021-01-22 15:21:43.639402: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2021-01-22 15:21:43.640209: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2021-01-22 15:21:43.641187: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found
2021-01-22 15:21:43.642002: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2021-01-22 15:21:43.642798: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2021-01-22 15:21:43.643052: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-01-22 15:21:43.645778: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-01-22 15:21:43.647564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-22 15:21:43.647835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-01-22 15:21:43.648038: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
[INFO] training network...
2021-01-22 15:21:44.544947: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)`"
46605,Subclassed tf.keras.Model can't access intermediate layer's output,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
*Yes*
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
*Google Colab*
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
*No*
- TensorFlow installed from (source or binary):
*Binary, pip install*
- TensorFlow version (use command below):
*2.4*
- Python version:
*Colab's version: 3.6.9""
- Bazel version (if compiling from source):
*N/A - Colab*
- GCC/Compiler version (if compiling from source):
*N/A - Colab*
- CUDA/cuDNN version:
*N/A - Colab without GPU*
- GPU model and memory:
*N/A - Colab without GPU*

**Describe the current behavior**

Accessing internal layer's output of a sublcassed `Model` leads to `AttributeError: Layer XXX has no inbound nodes` exception. The code to reproduce the issue given below or avaiable [here](https://colab.research.google.com/drive/1w5p68LvzwPnYKzpDm6HzsRsRXlBp35hq?usp=sharing) 

```python
import tensorflow as tf

class MyModel(tf.keras.Model):

  def __init__(self, name='MyModel', **kwargs):
    super(MyModel, self).__init__(name=name, **kwargs)
    self.dense1 = tf.keras.layers.Dense(4, name='layer1')
    self.dense2 = tf.keras.layers.Dense(2, name='layer2')

  def call(self, inputs, training=None, mask=None):
    x = self.dense1(inputs)
    return self.dense2(x)

x_in = tf.keras.layers.Input(shape=(2,), dtype=tf.float32)
my_model = MyModel()
y = my_model(x_in, training=False)
mid_feat = my_model.get_layer('layer1').output
```

This happens when using tensorflow `2.4`, however it does work with `2.3`. Something must have changed between the two versions. 

**Describe the expected behavior**

The old behaviour, where we can access internal layer's outputs from a model whether it has been build with `functional` API or sublclassed `Model`.
"
46604,The Example Code in tf.feature_column.categorical_column_with_identity is not Executable/Complete/Self-Sufficient,"## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_identity#linear_model

## Description of issue (what needs changing): 
The example code cannot be Executed as it is. We have to add the namespaces by searching in the [tensorflow.org site](https://www.tensorflow.org/).

Complete/Self-Sufficient/Stand-Alone example code will be very helpful, especially for the New Developers.

Similar issue was raised in #46203 (was waiting for it to be resolved) but it is closed now."
46603,Broken link in doc,"**Link to Doc:**

https://www.tensorflow.org/tutorials/audio/simple_audio


![-2021-jan-22-008](https://user-images.githubusercontent.com/20347013/105484563-87ba8400-5cd1-11eb-8daf-370b3601ff0f.jpg)


**Dead Link(Name of Link: contributing five minutes of your own voice):**

https://aiyprojects.withgoogle.com/open_speech_recording


![-2021-jan-22-010](https://user-images.githubusercontent.com/20347013/105484575-8b4e0b00-5cd1-11eb-91aa-283abea5e457.jpg)
"
46602,Race condition in port picker leads to test failures,"**System information**
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7.4
- Bazel version (if compiling from source): 3.7.1
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: 11.0

**Describe the current behavior**

Running the TensorFlow tests in parallel through bazel leads to various failures all ultimately with a failed start of the gRPC server due to ""Address already in use"".
As the reason I suspect a race condition in tensorflow/core/platform/default/net.cc function `PickUnusedPortOrDie`: When multiple processes try to pick a random, unused port, they may end up picking a port just picked but not yet used by another test process.

This does not always happen but often enough to become a problem on our 6-GPU system (i.e. 6 parallel processes). I also think the problem is amplified by the use of `rand()` without properly (i.e. randomly or even at all) seeding it first which means the process likely try the same ports in the same order.

This is supported by the output of the next test:
```
W tensorflow/core/platform/default/net.cc:65] bind(port=52649) failed: Address already in use
W tensorflow/core/platform/default/net.cc:65] bind(port=54915) failed: Address already in use
W tensorflow/core/platform/default/net.cc:65] bind(port=64017) failed: Address already in use
```

I.e. how high are the chances that 3 random ports in order are already used? Hence the ports chosen are not random.

**Describe the expected behavior**

Tests succeed (by choosing real unused ports)
I'd suggest to ""block"" a port through other means, currently a static `std::unordered_set` is used, but e.g. a temporary file/folder would be more appropriate.

**Other info / logs** 
```

[ RUN      ] CAPI.RemoteExecuteSilentCopiesAsyncFunc
2021-01-21 21:18:32.222204: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-21 21:18:32.224170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-01-21 21:18:32.478962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0035:05:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.50GiB deviceMemoryBandwidth: 836.37GiB/s
2021-01-21 21:18:32.478977: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2021-01-21 21:18:32.481822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2021-01-21 21:18:32.481866: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2021-01-21 21:18:32.483470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-01-21 21:18:32.484308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-01-21 21:18:32.486499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-01-21 21:18:32.488202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2021-01-21 21:18:32.492019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2021-01-21 21:18:32.528329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-01-21 21:18:33.198519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-21 21:18:33.198528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-01-21 21:18:33.198533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-01-21 21:18:33.211048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:1/device:GPU:0 with 30150 MB memory) -> physical GPU (device: 0, n
ame: Tesla V100-SXM2-32GB, pci bus id: 0035:05:00.0, compute capability: 7.0)
E0121 21:18:33.212193952  159657 server_chttp2.cc:40]        {""created"":""@1611263913.212114250"",""description"":""No address added out of total 1 resolved"",""file"":""external/com_github_grpc_grpc/src/core/ext/tran
sport/chttp2/server/chttp2_server.cc"",""file_line"":395,""referenced_errors"":[{""created"":""@1611263913.212112418"",""description"":""Failed to add any wildcard listeners"",""file"":""external/com_github_grpc_grpc/src/cor
e/lib/iomgr/tcp_server_posix.cc"",""file_line"":342,""referenced_errors"":[{""created"":""@1611263913.212096081"",""description"":""Unable to configure socket"",""fd"":33,""file"":""external/com_github_grpc_grpc/src/core/lib/i
omgr/tcp_server_utils_posix_common.cc"",""file_line"":216,""referenced_errors"":[{""created"":""@1611263913.212090911"",""description"":""Address already in use"",""errno"":98,""file"":""external/com_github_grpc_grpc/src/core/
lib/iomgr/tcp_server_utils_posix_common.cc"",""file_line"":189,""os_error"":""Address already in use"",""syscall"":""bind""}]},{""created"":""@1611263913.212112068"",""description"":""Unable to configure socket"",""fd"":33,""file""
:""external/com_github_grpc_grpc/src/core/lib/iomgr/tcp_server_utils_posix_common.cc"",""file_line"":216,""referenced_errors"":[{""created"":""@1611263913.212108551"",""description"":""Address already in use"",""errno"":98,""
file"":""external/com_github_grpc_grpc/src/core/lib/iomgr/tcp_server_utils_posix_common.cc"",""file_line"":189,""os_error"":""Address already in use"",""syscall"":""bind""}]}]}]}
2021-01-21 21:18:33.212232: E tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:533] Unknown: Could not start gRPC server
tensorflow/c/eager/c_api_remote_test_util.cc:81: Failure
Value of: tensorflow::GrpcServer::Create( server_def, tensorflow::Env::Default(), &worker_server1) .ok()
  Actual: false
Expected: true
[  FAILED  ] CAPI.RemoteExecuteSilentCopiesAsyncFunc (998 ms)
```

Other failing tests are //tensorflow/c/eager:c_api_cluster_test_gpu, //tensorflow/c/eager:c_api_remote_function_test_gpu, //tensorflow/c/eager:c_api_remote_test_gpu"
46600,TensorflowLite 1.15.2  aar build failure in Win10,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution :**win10**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:**no**
- TensorFlow installed from (source or binary):**source**
- TensorFlow version:**1.15.2**
- Python version:**3.7.9**
- Installed using virtualenv? pip? conda?: **no,using bazel and the default python in system**
- Bazel version (if compiling from source):**0.26.1**
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: **no**
- GPU model and memory:**no**



**Describe the problem**

I was trying to build the tensorflow-lite-1.15.2.aar from source on my local WIN10 PC,
I downloaded the source code and installed bazel following instructions online.
The version of  ANDROID_NDK is 18.1.5063045  and ANDOIRD_SDK is 23
After configuring the bazelrc, I executed the build command and got the following error:

```
[18 / 56] Processing Android resources for //tensorflow/lite/java:tensorflow-lite_dummy_app_for_so; 1s local ... (12 actions, 11 running)
ERROR: D:/code/tensorflow-1.15.2/tensorflow-1.15.2/tensorflow/lite/java/BUILD:22:1: Processing Android resources for //tensorflow/lite/java:tensorflow-lite_dummy_app_for_so failed (Exit 1): ResourceProcessorBusyBox.exe failed: error executing command
  cd C:/users/c00/_bazel_c00/7oqu2vjd/execroot/org_tensorflow
  SET ANDROID_BUILD_TOOLS_VERSION=30.0.0
    SET ANDROID_NDK_API_LEVEL=18
    SET ANDROID_NDK_HOME=D:/softwares/AndroidSDK/ndk/18.1.5063045
    SET ANDROID_SDK_API_LEVEL=23
    SET ANDROID_SDK_HOME=D:/softwares/AndroidSDK
    SET PATH=C:\Program Files\Git\usr\bin;C:\Program Files\Git\bin;C:\WINDOWS;C:\WINDOWS\System32;C:\WINDOWS\System32\WindowsPowerShell\v1.0;C:\Users\c00\bin;C:\Program Files\Git\mingw64\bin;C:\Program Files\Git\usr\local\bin;C:\Program Files\Git\usr\bin;C:\Program Files\Git\usr\bin;C:\Program Files\Git\mingw64\bin;C:\Program Files\Git\usr\bin;C:\Users\c00\bin;%PyCharm%;%GoLand%;%IntelliJ IDEA%;C:\WINDOWS\system32\config\systemprofile\go\bin;C:\Program Files\Python37;C:\Program Files\Python37\Scripts;D:\softwares\apache-maven-3.6.3\bin;D:\softwares\AndroidSDK\platform-tools\adb.exe;C:\Program Files (x86)\GnuWin32\bin;C:\Windows\System32;C:\Program Files\Git\usr\bin\git.exe;C:\Program Files\Git LFS;C:\Program Files\Java\jdk1.8.0_202\bin;C:\Program Files\Java\jdk1.8.0_202\jre\bin;D:\softwares\PyCharm 2020.1\bin;D:\softwares\GoLand 2020.1.3\bin;D:\softwares\IntelliJ IDEA 2020.2\bin;C:\Users\c00\go\bin;C:\Program Files\Git\usr\bin\vendor_perl;C:\Program Files\Git\usr\bin\core_perl
    SET PYTHON_BIN_PATH=C:/Program Files/Python37/python.exe
    SET PYTHON_LIB_PATH=C:/Program Files/Python37/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TF2_BEHAVIOR=0
    SET TF_CONFIGURE_IOS=0
    SET TF_ENABLE_XLA=1
  bazel-out/x64_windows-opt/bin/external/bazel_tools/src/tools/android/java/com/google/devtools/build/android/ResourceProcessorBusyBox.exe @bazel-out/x64_windows-opt/bin/tensorflow/lite/java/tensorflow-lite_dummy_app_for_so_symbols/R.txt-0.params
Execution platform: @bazel_tools//platforms:host_platform
ä¸æ 22, 2021 5:18:13 ä¸å com.google.devtools.build.android.ResourceProcessorBusyBox processRequest
ä¸¥é: Error during processing
java.nio.file.InvalidPathException: Illegal character [:] in path at index 4: ///C:/Users/C00520~1/AppData/Local/Temp/android_resources_tmp5724987117968661034/linked/bin.-pb.apk
        at sun.nio.fs.WindowsPathParser.nextSlash(WindowsPathParser.java:212)
        at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:111)
        at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:77)
        at sun.nio.fs.WindowsPath.parse(WindowsPath.java:94)
        at sun.nio.fs.WindowsFileSystem.getPath(WindowsFileSystem.java:255)
        at java.nio.file.Paths.get(Paths.java:84)
        at com.google.devtools.build.android.aapt2.ProtoApk.asApkPath(ProtoApk.java:203)
        at com.google.devtools.build.android.aapt2.ResourceLinker.link(ResourceLinker.java:555)
        at com.google.devtools.build.android.aapt2.ResourceLinker.link(ResourceLinker.java:536)
        at com.google.devtools.build.android.Aapt2ResourcePackagingAction.main(Aapt2ResourcePackagingAction.java:185)
        at com.google.devtools.build.android.ResourceProcessorBusyBox$Tool$14.call(ResourceProcessorBusyBox.java:144)
        at com.google.devtools.build.android.ResourceProcessorBusyBox.processRequest(ResourceProcessorBusyBox.java:240)
        at com.google.devtools.build.android.ResourceProcessorBusyBox.main(ResourceProcessorBusyBox.java:203)

Exception in thread ""main"" java.nio.file.InvalidPathException: Illegal character [:] in path at index 4: ///C:/Users/C00520~1/AppData/Local/Temp/android_resources_tmp5724987117968661034/linked/bin.-pb.apk
        at sun.nio.fs.WindowsPathParser.nextSlash(WindowsPathParser.java:212)
        at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:111)
        at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:77)
        at sun.nio.fs.WindowsPath.parse(WindowsPath.java:94)
        at sun.nio.fs.WindowsFileSystem.getPath(WindowsFileSystem.java:255)
        at java.nio.file.Paths.get(Paths.java:84)
        at com.google.devtools.build.android.aapt2.ProtoApk.asApkPath(ProtoApk.java:203)
        at com.google.devtools.build.android.aapt2.ResourceLinker.link(ResourceLinker.java:555)
        at com.google.devtools.build.android.aapt2.ResourceLinker.link(ResourceLinker.java:536)
        at com.google.devtools.build.android.Aapt2ResourcePackagingAction.main(Aapt2ResourcePackagingAction.java:185)
        at com.google.devtools.build.android.ResourceProcessorBusyBox$Tool$14.call(ResourceProcessorBusyBox.java:144)
        at com.google.devtools.build.android.ResourceProcessorBusyBox.processRequest(ResourceProcessorBusyBox.java:240)
        at com.google.devtools.build.android.ResourceProcessorBusyBox.main(ResourceProcessorBusyBox.java:203)
Target //tensorflow/lite/java:tensorflow-lite failed to build
INFO: Elapsed time: 2.462s, Critical Path: 1.37s
INFO: 14 processes: 14 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully

```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
_bazel build --cxxopt='--std=c++11' -c opt --fat_apk_cpu=x86,x86_64,arm64-v8a,armeabi-v7a //tensorflow/lite/java:tensorflow-lite
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Here is the tf_configure.bazelrc content I got ,
- I have JDK1.8 installed before ,so I added the ""java_toolchain"" setting
- I used the ./configure to interactively configure it,but I couldn't get these ""action_env"" adout android, so I add those action_env manually.
- I tried to remove some of the ""build:opt"" ï¼it didn't workï¼cause I don't really understand all of them
- I tried to change the SDK and NDK higher ,to like 29/30, it didn't solve the problem either.
```
build --action_env PYTHON_BIN_PATH=""C:/Program Files/Python37/python.exe""
build --action_env PYTHON_LIB_PATH=""C:/Program Files/Python37/lib/site-packages""
build --python_path=""C:/Program Files/Python37/python.exe""
build:xla --define with_xla_support=true
build --config=xla
build:opt --copt=-march=native
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
build --config monolithic
build --copt=-w --host_copt=-w
build --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI
build --verbose_failures
build --distinct_host_configuration=false
build --define=override_eigen_strong_inline=true
build:v2 --define=tf_api_version=2
build --java_toolchain=@bazel_tools//tools/jdk:toolchain_hostjdk8
build --action_env ANDROID_NDK_HOME=""D:/softwares/AndroidSDK/ndk/18.1.5063045""
build --action_env ANDROID_NDK_API_LEVEL=""18""
build --action_env ANDROID_BUILD_TOOLS_VERSION=""30.0.0""
build --action_env ANDROID_SDK_API_LEVEL=""23""
build --action_env ANDROID_SDK_HOME=""D:/softwares/AndroidSDK""
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_tag_filters=-benchmark-test,-no_oss,-oss_serial
test --build_tag_filters=-benchmark-test,-no_oss
test --test_tag_filters=-no_windows,-gpu
test --build_tag_filters=-no_windows,-gpu
build --action_env TF_CONFIGURE_IOS=""0""
```

I am new to bazel and tensorflow , I feel there must be something wrong with my bazelrc, but I can't find similar problem online, so I'm trying to seek for help here. Thanks."
46599,Conversion img_to_array and array_to_img does not work in TF 2.4,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4
- Python version: 3.6.1
- CUDA/cuDNN version: 11
- GPU model and memory: RTX2060 6GB

I try to convert numpy array ones to img and img to array with preprocessing.image functions.

Code to repoduce issue:

```
import numpy as np
from tensorflow.compat.v1.keras.preprocessing.image import array_to_img, img_to_array

input_array_ones = np.ones((4, 8, 1), dtype=np.uint8)
img_ones = array_to_img(input_array_ones)
output_array_ones = img_to_array(img_ones, dtype=np.uint8)
```

```
>>> (input_array_ones) = [[[1],  [1],  [1],  [1],  [1],  [1],  [1],  [1]],, [[1],  [1],  [1],  [1],  [1],  [1],  [1],  [1]],, [[1],  [1],  [1],  [1],  [1],  [1],  [1],  [1]],, [[1],  [1],  [1],  [1],  [1],  [1],  [1],  [1]]]
>>> (img_ones) = <PIL.Image.Image image mode=L size=8x4 at 0x20990EBADA0>
>>> (output_array_ones) = [[[0],  [0],  [0],  [0],  [0],  [0],  [0],  [0]],, [[0],  [0],  [0],  [0],  [0],  [0],  [0],  [0]],, [[0],  [0],  [0],  [0],  [0],  [0],  [0],  [0]],, [[0],  [0],  [0],  [0],  [0],  [0],  [0],  [0]]]
```

Works fine with the previous version of TensorFlow (1.x).
"
46598,_pywrap_tensorflow_internal.pyd is to big after PyInstaller pack,"Hi,

I'm working on packing our Algo pipe Micro-services built from 4 services that are wrapping Algo API's using TensorFlow 2.3.1.
I'm using PyInstaller with a unified spec file to pack all 4 services into one folder so all services executables will use shared resources.

One of the resources is ""_pywrap_tensorflow_internal.pyd"" file.

The issue is that after the latest version this file size has increased from about 140 MB to 694 MB.
I did not found any related issue yet, I'm thinking that the PyInstaller has increased this file size due to our version progress.

What could be the reason?
Is there an option to decrease this file size?


**System information**
- OS Platform: Win:
- TensorFlow installed: from source
- TensorFlow version: 2.3.1
- Python version: 3.7.6 x64
- Installed using virtualenv? pip? conda?: pip
- PyInstaler version: 4.2

"
46597,Loading model from GCS takes longer than copying it to local and then loading the model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): x86_64 GNU/Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3
- Python version: 3.7

**Describe the current behavior**
```
new_model = tf.keras.models.load_model(
 'gs://benchmarking_test/bert_en_uncased_L-12_H-768_A-12_2' 
)
```
takes about 30min or so.
whereas, following works in less than a minute
```
!gsutil cp -r gs://benchmarking_test/bert_en_uncased_L-12_H-768_A-12_2 local_path
new_model = tf.keras.models.load_model(
 'local_path' 
)
```

**Describe the expected behavior**
Both should take a similar time.
"
46595,tf.keras.preprocessing.image_dataset_from_directory includes hidden dirs as classes,"I am using google colab, and filed this as an issue there but they told me to file it here instead. https://github.com/googlecolab/colabtools/issues/1824

 It seems that google colab uses . prefixed hidden directories `.ipynb_checkpoints`, which image_dataset_from_directory thinks is a class.

Describe the current behavior:
When passing class names it produces the error:
ValueError: The class_names passed did not match the names of the subdirectories of the target directory. Expected: ['.ipynb_checkpoints', 'no_skip', 'skip'], but received: ['no_skip', 'skip']
When not passing class names it picks up 3 classes, not two.

Describe the expected behavior:
tf.keras.preprocessing.image_dataset_from_directory(...) should not include hidden .directories.

The web browser you are using (Chrome, Firefox, Safari, etc.):
Not relevant

Link (not screenshot!) to a minimal, public, self-contained notebook that
reproduces this issue (click the Share button, then Get Shareable Link):
https://colab.research.google.com/drive/1sI2Zk7-YjIOg3nRDyHtUtczwjevQfdPF?usp=sharing"
46594,How to get the walltime of tensorflow trace?,"I'm using `tensorflow.keras.callbacks.TensorBoard` API to collect gpu kernels events. 

I need to know the Jiffies time or the walltime of Linux, but not the time relative to the training task as shown in the following picture. 

So how could I get the system time?

![9sjgS](https://user-images.githubusercontent.com/20624289/105435140-c3d0f300-5c97-11eb-8247-aff2a505e519.png)

My Code:
```python
import os
import sys

import numpy as np
import tensorflow as tf
from tensorflow import keras

print(tf.__version__)
print(sys.version_info)

gpus = tf.config.experimental.list_physical_devices(""GPU"")
tf.config.experimental.set_memory_growth(gpus[0], True)
tf.config.experimental.set_visible_devices(gpus[0], ""GPU"")

fashion_mnist = keras.datasets.fashion_mnist
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
x_valid = x_train[:5000]
y_valid = y_train[:5000]
x_train = x_train[5000:]
y_train = y_train[5000:]

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

x_train_scaled = scaler.fit_transform(x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28, 1)
x_valid_scaled = scaler.transform(x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28, 1)
x_test_scaled = scaler.transform(x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28, 1)

model = keras.models.Sequential()
model.add(keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='selu', input_shape=(28, 28, 1)))
model.add(keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='selu'))
model.add(keras.layers.MaxPool2D(pool_size=2))
model.add(keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='selu'))
model.add(keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='selu'))
model.add(keras.layers.MaxPool2D(pool_size=2))
model.add(keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='selu'))
model.add(keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='selu'))
model.add(keras.layers.MaxPool2D(pool_size=2))

model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(128, activation='relu'))
model.add(keras.layers.Dense(10, activation='softmax'))

model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),
              optimizer=keras.optimizers.SGD(learning_rate=1e-2), metrics=['accuracy'])

logdir = os.path.join('.', 'cnn-callbacks')
if os.path.exists(logdir) == False:
    os.mkdir(logdir)
output_model_file = os.path.join(logdir, ""fashion_mnist_model.h5"")
print(output_model_file)
callbacks = [
    keras.callbacks.TensorBoard(logdir, profile_batch=tuple(range(3, 13))),
    keras.callbacks.ModelCheckpoint(output_model_file, save_best_only=True),
    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3),
]

history = model.fit(x_train_scaled, y_train, epochs=10, validation_data=(x_valid_scaled, y_valid), callbacks=callbacks,
                    batch_size=1024)
```"
46593,TFLite from file descriptor on Android 11,"**System information**
- TensorFlow version (you are using): Likely https://github.com/mozilla/tensorflow/tree/23ad988fcde60fb01f9533e95004bbc4877a9143
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

This issue is a continuation of mozilla/DeepSpeech#3507. TFLite is used in the app, but the model is provided by the user and usually in `/sdcard/Download`.

Currently, TFLite accepts arrays or file paths. With Android's scoped storage and SAF, it's hard to use file paths to the external storage without either compatibility edge cases or overly invasive permissions. On Android 10, I could use the workaround of converting the file descriptor I received from Android to a path like `""/proc/self/fd/"" + fd`. On Android 11, that stopped working. It seems to be no longer possible to open a file under `/proc/self/fd/` that points to external storage without requesting the read permission I was hoping to avoid.

I would like TFLite to be compatible with Android 11's external storage. The following solutions come to mind:

- Duplicate `tflite::FlatBufferModel::BuildFromFile` into `tflite::FlatBufferModel::BuildFromFileDescriptor`
- Add https://stackoverflow.com/a/59004193/10477326
- On Android builds, manually add a conditional to detect the `/proc/self/fd/` prefix and use a `dup` instead of a `fopen`

**Will this change the current api? How?**

Not unless we choose the `BuildFromFileDescriptor` solution.

**Who will benefit with this feature?**

Developers and users of apps that:

- Explore, educate, or demonstrate machine learning, and
- Run on up-to-date Android versions, and
- Load user-supplied models, and
- Usually take large (~1 GiB) models that reside on external storage, which we cannot afford to read into memory or duplicate on disk, and
- Would like to respect privacy by obeying scoped storage and SAF by not requesting file permissions to everything but rather allow the user to pick only the files necessary
"
46592,ISSUES.md link broken,"## URL(s) with the issue:

Most files under https://github.com/tensorflow/tensorflow/tree/f2d8cfe09234329e14c98798540f146bd94558e0/.github/ISSUE_TEMPLATE

## Description of issue (what needs changing):

The links to the [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md) are broken.

### Clear description

For example, why should someone use this method? How is it useful?

I don't know why there is a separate GitHub policy aside from the CONTRIBUTING.md, but it seems important and people are supposed to read it

### Correct links

Is the link to the source code correct? No

### Parameters defined

Are all parameters defined and formatted correctly? N/A

### Returns defined

Are return values defined? N/A

### Raises listed and defined

Are the errors defined? N/A

### Usage example

Is there a usage example? N/A

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content? N/A

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? No
"
46591,Misleading warning when loading weights from hdf5 format weights,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows, Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.0, nightly
- Python version: 3.7
- CUDA/cuDNN version: 11.0, 8.0.4
- GPU model and memory: 1060, 6GB


**Describe the current behavior**
When loading weights with `skip_mismatch=True`, and if the stored weights don't match with the current layer weights, 
the warning seems to show misleading shapes for the stored weights.

**Describe the expected behavior**
I have attached a minimal code to produce the warning. The warning seems confusing. The expected shapes of weights shown in 
the warning should be `((3, 4, 7, 32) vs (3, 4, 7, 16))` rather than `((3, 4, 7, 32) vs (16, 7, 3, 4))`. I suspect the transpose here is causing the change of shape. 
https://github.com/tensorflow/tensorflow/blob/3c84fc9a4def10a80dcf5901c57210d3562f13cd/tensorflow/python/keras/saving/hdf5_format.py#L407-L411


**Standalone code to reproduce the issue**
```python
import tensorflow as tf

model = tf.keras.Sequential(
    tf.keras.layers.Conv2D(16, [3, 4], use_bias=False, input_shape=[10, 10, 7]))
model.save_weights('test.h5')

tf.keras.backend.clear_session()

new_model = tf.keras.Sequential(
    tf.keras.layers.Conv2D(32, [3, 4], use_bias=False, input_shape=[10, 10, 7]))
new_model.load_weights('test.h5', skip_mismatch=True, by_name=True)

WARNING:tensorflow:Skipping loading of weights for layer conv2d due to mismatch in shape ((3, 4, 7, 32) vs (16, 7, 3, 4)).

```
"
46589,Mixed Precision - Conv3D - error: No algorithm worked!,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes, I wrote a custom code.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux (CentOS 7)
- TensorFlow installed from (source or binary):
Installed using PIP
- TensorFlow version (use command below):
v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version:
3.8.0
- CUDA/cuDNN version:
CUDA/11.1.1
cuDNN/8.0.4.30-CUDA-11.1.1
- GPU model and memory:
2 NVIDIA A100-PCIE-40GB
2 GPUs on the same computer

**Describe the current behavior**
When running the code with double precision, the code does not generate errors. When running with mixed precision, launches an error:

**Describe the expected behavior**
Not having errors when running with mixed precision.

**Standalone code to reproduce the issue**
I tried to create a google colab for this code. There is no error there, but I could not get a google colab with 2 GPUs, like in my enviroment.
```
import tensorflow as tf
from tensorflow.keras.mixed_precision import experimental as mixed_precision
from tensorflow.keras import layers, Model, optimizers
import numpy as np

# If you comment the following 2 lines, the code runs
policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_policy(policy)


mirrored_strategy = tf.distribute.MirroredStrategy()
with mirrored_strategy.scope():
    x_input = layers.Input(shape=(60, 60, 2, 32))

    x = layers.Conv3D(filters=32, kernel_size=(3, 3, 1), strides=(1, 1, 1), padding = 'same')(x_input)
    x = layers.BatchNormalization()(x)
    x_out = layers.ReLU()(x)

    test_model = Model(inputs=x_input, outputs=x_out, name='test_model')
    adam = optimizers.Adam(learning_rate=1E-4)

test_model.compile(optimizer=adam, loss=""mse"", metrics=[""mae""])

input_data = np.random.random((1000, 60, 60, 2, 32))
target_data = np.random.random((1000, 60, 60, 2, 32))

ds_tuple = tf.data.Dataset.from_tensor_slices((input_data,target_data))
ds_tuple = ds_tuple.shuffle(1000).batch(100)

history = test_model.fit(ds_tuple, epochs=10, verbose=1)
```

**Other info / logs** 
This is the log of the run when I try running with mixed precision:
```
2021-01-21 15:37:22.318957: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-21 15:37:36.119468: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-21 15:37:36.123358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-01-21 15:37:36.201391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:3b:00.0 name: A100-PCIE-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-01-21 15:37:36.204229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:d8:00.0 name: A100-PCIE-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-01-21 15:37:36.204423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-21 15:37:37.945043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-01-21 15:37:37.945235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-01-21 15:37:37.998423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-01-21 15:37:38.072705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-01-21 15:37:38.207114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-01-21 15:37:38.574293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-01-21 15:37:38.612582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-01-21 15:37:38.624584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2021-01-21 15:37:38.624772: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-21 15:37:38.626778: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
WARNING:tensorflow:From /scratch/user/eee/conda/myEnvs/tf_2.4/lib/python3.8/site-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale
2021-01-21 15:37:38.638220: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-01-21 15:37:38.638847: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-21 15:37:38.840057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:3b:00.0 name: A100-PCIE-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-01-21 15:37:38.842228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:d8:00.0 name: A100-PCIE-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-01-21 15:37:38.842375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-21 15:37:38.842436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-01-21 15:37:38.842486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-01-21 15:37:38.842536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-01-21 15:37:38.842585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-01-21 15:37:38.842635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-01-21 15:37:38.842683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-01-21 15:37:38.842733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-01-21 15:37:38.850268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2021-01-21 15:37:38.850360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-21 15:37:40.396681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-21 15:37:40.396829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2021-01-21 15:37:40.396881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y
2021-01-21 15:37:40.396925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N
2021-01-21 15:37:40.407031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 37570 MB memory) -> physical GPU (device: 0, name: A100-PCIE-40GB, pci bus id: 0000:3b:00.0, compute capability: 8.0)
2021-01-21 15:37:40.414936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 37570 MB memory) -> physical GPU (device: 1, name: A100-PCIE-40GB, pci bus id: 0000:d8:00.0, compute capability: 8.0)
     --->     Running Tensorflow in Mixed Precision...
WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:
  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)

2021-01-21 15:37:47.583748: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: ""TensorSliceDataset/_2""
op: ""TensorSliceDataset""
input: ""Placeholder/_0""
input: ""Placeholder/_1""
attr {
  key: ""Toutput_types""
  value {
    list {
      type: DT_DOUBLE
      type: DT_DOUBLE
    }
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: 60
        }
        dim {
          size: 60
        }
        dim {
          size: 2
        }
        dim {
          size: 32
        }
      }
      shape {
        dim {
          size: 60
        }
        dim {
          size: 60
        }
        dim {
          size: 2
        }
        dim {
          size: 32
        }
      }
    }
  }
}

2021-01-21 15:37:48.602974: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-01-21 15:37:48.606716: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000000000 Hz
Epoch 1/10
2021-01-21 15:37:56.331798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-01-21 15:39:18.436971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-01-21 15:39:28.779314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-01-21 15:39:31.933180: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_grad_ops_3d.cc:1994 : Not found: No algorithm worked!
Traceback (most recent call last):
  File ""main.py"", line 31, in <module>
    history = test_model.fit(ds_tuple, epochs=10, verbose=1)
  File ""/scratch/user/eee/conda/myEnvs/tf_2.4/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File ""/scratch/user/eee/conda/myEnvs/tf_2.4/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""/scratch/user/eee/conda/myEnvs/tf_2.4/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 888, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/scratch/user/eee/conda/myEnvs/tf_2.4/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2942, in __call__
    return graph_function._call_flat(
  File ""/scratch/user/eee/conda/myEnvs/tf_2.4/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""/scratch/user/eee/conda/myEnvs/tf_2.4/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 555, in call
    outputs = execute.execute(
  File ""/scratch/user/eee/conda/myEnvs/tf_2.4/lib/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.NotFoundError: 3 root error(s) found.
  (0) Not found:  No algorithm worked!
         [[node gradient_tape/test_model/conv3d/Conv3D/Conv3DBackpropFilterV2 (defined at /threading.py:932) ]]
  (1) Not found:  No algorithm worked!
         [[node gradient_tape/test_model/conv3d/Conv3D/Conv3DBackpropFilterV2 (defined at /threading.py:932) ]]
         [[cond_4/then/_40/cond_4/cond/pivot_t/_256/_187]]
  (2) Not found:  No algorithm worked!
         [[node gradient_tape/test_model/conv3d/Conv3D/Conv3DBackpropFilterV2 (defined at /threading.py:932) ]]
         [[div_no_nan/ReadVariableOp_3/_108]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_2870]

Function call stack:
train_function -> train_function -> train_function

```
"
46587,"error: cannot initialize a member subobject of type 'ternaryfunc' (aka '_object *(*)(_object *, _object *, _object *)') with an lvalue of type 'PyObject *(PyObject *)' (aka '_object *(_object *)'): different number of parameters (3 vs 1)","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- OS X 10.15.7 - Catalina
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- source
- TensorFlow version:
- Master
- Python version:
- Anaconda 3.6
- Installed using virtualenv? pip? conda?:
- Conda
- Bazel version (if compiling from source):
- bazelisk
- GCC/Compiler version (if compiling from source):
- Apple clang version 12.0.0 (clang-1200.0.32.28)
- CUDA/cuDNN version:
- GPU model and memory:
- CPU



**Describe the problem**

ERROR: /Users/davidlaxer/tensorflow/tensorflow/python/lib/core/BUILD:49:11: C++ compilation of rule '//tensorflow/python/lib/core:bfloat16_lib' failed (Exit 1): wrapped_clang failed: error executing command external/local_config_cc/wrapped_clang '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 63 argument(s) skipped)
tensorflow/python/lib/core/bfloat16.cc:219:5: error: cannot initialize a member subobject of type 'ternaryfunc' (aka '_object *(*)(_object *, _object *, _object *)') with an lvalue of type 'PyObject *(PyObject *)' (aka '_object *(_object *)'): different number of parameters (3 vs 1)
    PyBfloat16_Negative,  // nb_negative
    ^~~~~~~~~~~~~~~~~~~
tensorflow/python/lib/core/bfloat16.cc:229:5: error: cannot initialize a member subobject of type 'binaryfunc' (aka '_object *(*)(_object *, _object *)') with an lvalue of type 'PyObject *(PyObject *)' (aka '_object *(_object *)'): different number of parameters (2 vs 1)
    PyBfloat16_Int,       // nb_int
    ^~~~~~~~~~~~~~
tensorflow/python/lib/core/bfloat16.cc:333:1: error: unknown type name 'Py_hash_t'; did you mean 'npy_hash_t'?
Py_hash_t PyBfloat16_Hash(PyObject* self) {
^~~~~~~~~
npy_hash_t
bazel-out/darwin-opt/bin/external/local_config_python/numpy_include/numpy/npy_common.h:357:14: note: 'npy_hash_t' declared here
typedef long npy_hash_t;
             ^
3 errors generated.
**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel build --config=opt  //tensorflow/tools/pip_package:build_pip_package


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
46586,What is mac osx tensorflow=2.0.0 equivalent to in windows 64bit?,"I have a mac book pro and I've been using tensorflow 2.0.0, but my lab computer is a windows (likely 64bit). I want to make sure that this lab computer has the equivalent package as my mac. Can anyone tell me which tensorflow version for windows is equivalent to mac osx 2.0.0?"
46583,"Jupyter kernel restarts/crashes when importing Tensorflow, 'ModuleNotFoundError: No module named 'tensorflow' in Python CLI","**System information**
Using an M1 MacBook

I cannot use environment capture because the package is not being detected. I have tried the following: restarting computer, reinstalling Conda, reinstalling individual packages, installing using different package managers, setting up new environments, using different versions of python in different environments. It was working before and then suddenly stopped. I have seen reports of it being a memory issue, but it never occurred before, and I have 16GB of RAM, it should be more than enough. 

**Describe the current behavior**

Jupyter kernel restarts/crashes when importing Tensorflow, 'ModuleNotFoundError: No module named 'tensorflow' in Python CLI

**Describe the expected behavior**

For it to import normally

Below is a video of the behaviour. 

https://drive.google.com/file/d/11hCwbneKVdx0srZN9YxCyyIwDE8BKKQN/view?usp=sharing

<img width=""724"" alt=""Screen Shot 2021-01-21 at 10 02 34 AM"" src=""https://user-images.githubusercontent.com/51058259/105384701-c9630600-5bcf-11eb-9f2c-53cb693ddf88.png"">
<img width=""723"" alt=""Screen Shot 2021-01-21 at 10 02 57 AM"" src=""https://user-images.githubusercontent.com/51058259/105384741-d7b12200-5bcf-11eb-850a-9a47cfb3c8ea.png"">
"
46582,"Hi, I actually received this issue when I am running a code which is : WARNING:tensorflow:AutoGraph could not transform <function read_image at 0x0000026A371D8700> and will run it as-is. Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index' To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46581,Tensorboard not loading scalars with reload arrow button,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): N/A
- TensorFlow version (use command below): N/A
- Python version: 3.7.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.1.106
- GPU model and memory: NVIDIA GeFroce RTX 2070, 32GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Using Jupyter Notebook, Tensorboard will not load scalars from logs.  Will not work at all.  I click the reload button on the orange header of Tensorboard and nothing happens.  Nothing... just updates the last reload date and time.  I have confirmed that the temporary files are created and that there are event files within the test folder within the temporary files.  I do not have tensorflow installed.  I have python 3.7.9, numpy, pandas, matplotlib, tb-nightly, pillow, torch.

**Describe the expected behavior**
I expected to see graphs of scalars and data that is saved in the loggers.  It does not anything.

**Standalone code to reproduce the issue**
%pylab inline
import torch
%load_ext tensorboard
import torch.utils.tensorboard as tb
import tempfile
log_dir = tempfile.mkdtemp()
%tensorboard --logdir {log_dir} --reload_interval 1
logger = tb.SummaryWriter(log_dir+'/test', flush_secs=1)
logger.add_scalar('first/number', 0, global_step=0)
logger.add_scalar('first/number', 1, global_step=1)





![Capture](https://user-images.githubusercontent.com/72282737/105374384-45a81a00-5bcd-11eb-99dc-359d80ea0b4b.PNG)





**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46580,tflite model can not inference when use tensorflow op,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- ubuntu 18.04
- TensorFlow installed from (source or binary):
- source
- TensorFlow version (use command below):
- 2.4.0
- Python version:
- 3.6.0
- Bazel version (if compiling from source):
- 3.1.-

when I convert a tf model to tflite and use tensorflow op with
```python
     converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                          tf.lite.OpsSet.SELECT_TF_OPS]
     converter.allow_custom_ops = True
```
and I managed to get the tflite file, now I want to use the TFlite model for inference.
I add ""//tensorflow/lite/delegates/flex:delegate"" in tflite_cc_shared_object deps, and rebuild tenosrflowlite lib:
```shell
bazel build --config=monolithic --define=with_select_tf_ops=true -c opt //tensorflow/lite:libtensorflowlite.so
```
and I copy libtensorflowlite.so to /usr/lib.

then, Inference program was compiled using g++, the compilation was successful, an executable program TFlite was generated,I use the ldd command to view the libraries used by tflite:
```shell
	linux-vdso.so.1 (0x00007ffe09fb1000)
	libtensorflowlite.so => /usr/lib/libtensorflowlite.so (0x00007f4017d84000)
	libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f40179fb000)
	libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f40177e3000)
	libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f40173f2000)
	libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f4017054000)
	libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f4016e4e000)
	librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f4016c46000)
	libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f4016a27000)
	/lib64/ld-linux-x86-64.so.2 (0x000055b71a930000)
```
I executed the tflite executableï¼
```shell
./tflite
```
but I get error:
```shell
ERROR: Op builtin_code out of range: 129. Are you using old TFLite binary with newer model?
ERROR: Registration failed.

Segmentation fault (core dumped)
```

Which step went wrong? "
46579,tf.config.run_functions_eagerly(run_eagerly=True) cashes on model load,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3 and 2.4 verified
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: Not required
- GPU model and memory: Not required


**Describe the current behavior**
Exception when loading saved model when a custom layer having `training=None` as argument is implemented.
```
ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (1 total):
    * Tensor(""Placeholder:0"", shape=(None, 28, 28), dtype=float32)
  Keyword arguments: {'training': False}

Expected these arguments to match one of the following 2 option(s):

Option 1:
  Positional arguments (2 total):
    * TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='inputs')
    * False
  Keyword arguments: {}

Option 2:
  Positional arguments (2 total):
    * TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='inputs')
    * True
  Keyword arguments: {}
```

**Describe the expected behavior**
No exception

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
[minimal example](https://colab.research.google.com/drive/1NBb6neAWOLhtBfORWviZB-Cy2BRrScz3?usp=sharing)

**Other info / logs**
See Colab error.
Removing the `tf.config.run_functions_eagerly` does not result in an exception and training the model works flawlessly.
"
46577,Request to add tf.Cholesky and tf.MatrixTriangularSolve to tensorflow lite operations ,"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04.5
- Python version: 3.7.4
- Tensorflow : 2.4.0

I'm trying to use the function tf.linalg.lstsq inside my module and I'm getting this error for the converter: 

**Provide the text output from tflite_convert**

    ```
    Traceback (most recent call last):
      File ""/home/aia/anaconda3/envs/notebooks/lib/python3.7/site-packages/tensorflow/lite/python/convert.py"", line 213, in toco_convert_protos
        enable_mlir_converter)
      File ""/home/aia/anaconda3/envs/notebooks/lib/python3.7/site-packages/tensorflow/lite/python/wrap_toco.py"", line 38, in wrapped_toco_convert
        enable_mlir_converter)
    Exception: <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls_1/cond/Cholesky@matrix_solve_ls_1_cond_false_28664"" at ""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.Cholesky' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls_1/cond/cholesky_solve/MatrixTriangularSolve@matrix_solve_ls_1_cond_false_28664"" at ""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls_1/cond/cholesky_solve/MatrixTriangularSolve_1@matrix_solve_ls_1_cond_false_28664"" at ""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls_1/cond/Cholesky@matrix_solve_ls_1_cond_true_28663"" at ""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.Cholesky' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls_1/cond/cholesky_solve/MatrixTriangularSolve@matrix_solve_ls_1_cond_true_28663"" at ""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls_1/cond/cholesky_solve/MatrixTriangularSolve_1@matrix_solve_ls_1_cond_true_28663"" at ""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls/cond/Cholesky@matrix_solve_ls_cond_false_25991"" at ""matrix_solve_ls/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.Cholesky' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls/cond/cholesky_solve/MatrixTriangularSolve@matrix_solve_ls_cond_false_25991"" at ""matrix_solve_ls/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls/cond/cholesky_solve/MatrixTriangularSolve_1@matrix_solve_ls_cond_false_25991"" at ""matrix_solve_ls/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls/cond/Cholesky@matrix_solve_ls_cond_true_25990"" at ""matrix_solve_ls/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.Cholesky' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls/cond/cholesky_solve/MatrixTriangularSolve@matrix_solve_ls_cond_true_25990"" at ""matrix_solve_ls/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls/cond/cholesky_solve/MatrixTriangularSolve_1@matrix_solve_ls_cond_true_25990"" at ""matrix_solve_ls/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"" at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): failed while converting: 'tf.IfRegion306_else': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
	    tf.Cholesky {device = """"}
	    tf.MatrixTriangularSolve {adjoint = false, device = """", lower = true}
	    tf.MatrixTriangularSolve {adjoint = true, device = """", lower = true}
    <unknown>:0: note: loc(""PartitionedCall""): called from
    
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""/home/aia/repos/algo-pipeline/TF_HBR.py"", line 144, in <module>
        tflite_model = converter.convert()
      File ""/home/aia/anaconda3/envs/notebooks/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 739, in convert
        result = _convert_saved_model(**converter_kwargs)
      File ""/home/aia/anaconda3/envs/notebooks/lib/python3.7/site-packages/tensorflow/lite/python/convert.py"", line 637, in convert_saved_model
        enable_mlir_converter=True)
      File ""/home/aia/anaconda3/envs/notebooks/lib/python3.7/site-packages/tensorflow/lite/python/convert.py"", line 216, in toco_convert_protos
        raise ConverterError(str(e))
    tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls_1/cond/Cholesky@matrix_solve_ls_1_cond_false_28664"" at ""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.Cholesky' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls_1/cond/cholesky_solve/MatrixTriangularSolve@matrix_solve_ls_1_cond_false_28664"" at ""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls_1/cond/cholesky_solve/MatrixTriangularSolve_1@matrix_solve_ls_1_cond_false_28664"" at ""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls_1/cond/Cholesky@matrix_solve_ls_1_cond_true_28663"" at ""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.Cholesky' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls_1/cond/cholesky_solve/MatrixTriangularSolve@matrix_solve_ls_1_cond_true_28663"" at ""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls_1/cond/cholesky_solve/MatrixTriangularSolve_1@matrix_solve_ls_1_cond_true_28663"" at ""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls/cond/Cholesky@matrix_solve_ls_cond_false_25991"" at ""matrix_solve_ls/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.Cholesky' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls/cond/cholesky_solve/MatrixTriangularSolve@matrix_solve_ls_cond_false_25991"" at ""matrix_solve_ls/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls/cond/cholesky_solve/MatrixTriangularSolve_1@matrix_solve_ls_cond_false_25991"" at ""matrix_solve_ls/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls/cond/Cholesky@matrix_solve_ls_cond_true_25990"" at ""matrix_solve_ls/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.Cholesky' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls/cond/cholesky_solve/MatrixTriangularSolve@matrix_solve_ls_cond_true_25990"" at ""matrix_solve_ls/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(callsite(""matrix_solve_ls/cond/cholesky_solve/MatrixTriangularSolve_1@matrix_solve_ls_cond_true_25990"" at ""matrix_solve_ls/cond@__inference_calcute_hbr_31510"") at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(""matrix_solve_ls_1/cond@__inference_calcute_hbr_31510"" at ""PartitionedCall@__inference_signature_wrapper_31523"") at ""PartitionedCall"")): failed while converting: 'tf.IfRegion306_else': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
	    tf.Cholesky {device = """"}
	    tf.MatrixTriangularSolve {adjoint = false, device = """", lower = true}
	    tf.MatrixTriangularSolve {adjoint = true, device = """", lower = true}
    <unknown>:0: note: loc(""PartitionedCall""): called from```

**Standalone code to reproduce the issue** 

https://colab.research.google.com/gist/AiaHaruv/396c2473b4601e9d35332884dbd02fa9/tflie_gist.ipynb

**Any other info / logs**
In the colab, the traceback is: 
          4 frames
          Exception: <unknown>:0: error: 
  loc(callsite(callsite(""matrix_solve_ls/cholesky_solve/MatrixTriangularSolve@__inference_calculate_403"" at 
  ""PartitionedCall@__inference_signature_wrapper_411"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom 
  op nor a flex op
          <unknown>:0: note: loc(""PartitionedCall""): called from
          <unknown>:0: error: 
  loc(callsite(callsite(""matrix_solve_ls/cholesky_solve/MatrixTriangularSolve_1@__inference_calculate_403"" at 
  ""PartitionedCall@__inference_signature_wrapper_411"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom 
  op nor a flex op
          <unknown>:0: note: loc(""PartitionedCall""): called from
          <unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit- 
  custom-ops flag):
	          tf.MatrixTriangularSolve {adjoint = false, device = """", lower = true}
	          tf.MatrixTriangularSolve {adjoint = true, device = """", lower = true}
          
        
    During handling of the above exception, another exception occurred:
    
    ConverterError                            Traceback (most recent call last)
    /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
        214       return model_str
        215     except Exception as e:
    --> 216       raise ConverterError(str(e))
        217 
        218   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:
    
    ConverterError: <unknown>:0: error: loc(callsite(callsite(""matrix_solve_ls/cholesky_solve/MatrixTriangularSolve@__inference_calculate_403"" at ""PartitionedCall@__inference_signature_wrapper_411"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: loc(callsite(callsite(""matrix_solve_ls/cholesky_solve/MatrixTriangularSolve_1@__inference_calculate_403"" at ""PartitionedCall@__inference_signature_wrapper_411"") at ""PartitionedCall"")): 'tf.MatrixTriangularSolve' op is neither a custom op nor a flex op
    <unknown>:0: note: loc(""PartitionedCall""): called from
    <unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
	    tf.MatrixTriangularSolve {adjoint = false, device = """", lower = true}
	    tf.MatrixTriangularSolve {adjoint = true, device = """", lower = true}

Thanks you 
"
46576,Illegal instruction (core dumped) while importing TensorFlow,"System:
 - HP EliteBook 8470p
 - Freshly installed Ubuntu 20.04 (5.8.0-38-generic)
 - Python 3.8.5
 - TensorFlow 2.4

I installed TensorFlow with 
``` 
pip install --upgrade pip
pip install tensorflow
```
as recommended on [https://www.tensorflow.org/install](https://www.tensorflow.org/install).

When I try to import TensorFlow : 
```
>>> import tensorflow as tf
```
I've got the following error:
```
Illegal instruction (core dumped)
```

I already read the following issues or SO questions:
- [https://github.com/tensorflow/tensorflow/issues/17411](https://github.com/tensorflow/tensorflow/issues/17411)
- [https://github.com/tensorflow/tensorflow/issues/45744](https://github.com/tensorflow/tensorflow/issues/45744)
- [https://tech.amikelive.com/node-887/how-to-resolve-error-illegal-instruction-core-dumped-when-running-import-tensorflow-in-a-python-program/](https://tech.amikelive.com/node-887/how-to-resolve-error-illegal-instruction-core-dumped-when-running-import-tensorflow-in-a-python-program/)
- [https://stackoverflow.com/questions/49092527/illegal-instructioncore-dumped-tensorflow](https://stackoverflow.com/questions/49092527/illegal-instructioncore-dumped-tensorflow)

Most are referring to old TensorFlow versions (1.5) or related to CPU that does not support AVX. 

My CPU does support AVX:
```
$ more /proc/cpuinfo | grep flags
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl smx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm cpuid_fault epb pti ssbd ibrs ibpb stibp fsgsbase smep erms xsaveopt dtherm ida arat pln pts md_clear flush_l1d
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl smx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm cpuid_fault epb pti ssbd ibrs ibpb stibp fsgsbase smep erms xsaveopt dtherm ida arat pln pts md_clear flush_l1d
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl smx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm cpuid_fault epb pti ssbd ibrs ibpb stibp fsgsbase smep erms xsaveopt dtherm ida arat pln pts md_clear flush_l1d
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl smx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm cpuid_fault epb pti ssbd ibrs ibpb stibp fsgsbase smep erms xsaveopt dtherm ida arat pln pts md_clear flush_l1d
```

Since my laptop is quite recent and my OS is a fresh insall, I think something sounds wrong with the TensorFlow installer. "
46575,I got this error while trying to run the webcam_demo.py example in Posenet library from tensorflow. how to resolve this?,"I got this error/warning while trying to run the webcam_demo.py example in Posenet library from Tensorflow. how to resolve this?

This is the **Git Repo** from where I forked this code : [posenet-python](https://github.com/rwightman/posenet-python)

and This is my **Output Screen** :
```
>>> 
 RESTART: A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\webcam_demo.py 
Cannot find model file ./_models\model-mobilenet_v1_101.pb, converting from tfjs...
WARNING:tensorflow:From A:\Python\lib\site-packages\tensorflow\python\tools\freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Traceback (most recent call last):
  File ""A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\webcam_demo.py"", line 66, in <module>
    main()
  File ""A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\webcam_demo.py"", line 20, in main
    model_cfg, model_outputs = posenet.load_model(args.model, sess)
  File ""A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\posenet\model.py"", line 42, in load_model
    convert(model_ord, model_dir, check=False)
  File ""A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\posenet\converter\tfjs2python.py"", line 198, in convert
    initializer_nodes="""")
  File ""A:\Python\lib\site-packages\tensorflow\python\tools\freeze_graph.py"", line 361, in freeze_graph
    checkpoint_version=checkpoint_version)
  File ""A:\Python\lib\site-packages\tensorflow\python\tools\freeze_graph.py"", line 190, in freeze_graph_with_def_protos
    var_list=var_list, write_version=checkpoint_version)
  File ""A:\Python\lib\site-packages\tensorflow\python\training\saver.py"", line 835, in __init__
    self.build()
  File ""A:\Python\lib\site-packages\tensorflow\python\training\saver.py"", line 847, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""A:\Python\lib\site-packages\tensorflow\python\training\saver.py"", line 885, in _build
    build_restore=build_restore)
  File ""A:\Python\lib\site-packages\tensorflow\python\training\saver.py"", line 489, in _build_internal
    names_to_saveables)
  File ""A:\Python\lib\site-packages\tensorflow\python\training\saving\saveable_object_util.py"", line 362, in validate_and_slice_inputs
    for converted_saveable_object in saveable_objects_for_op(op, name):
  File ""A:\Python\lib\site-packages\tensorflow\python\training\saving\saveable_object_util.py"", line 223, in saveable_objects_for_op
    yield ResourceVariableSaveable(variable, """", name)
  File ""A:\Python\lib\site-packages\tensorflow\python\training\saving\saveable_object_util.py"", line 95, in __init__
    self.handle_op = var.op.inputs[0]
IndexError: tuple index out of range
>>> 
```"
46574,How to avoid downloading when using many times of the tff.simulation.datasets.stackoverflow.load_data(),"As I see in this function, there is a parameter called cache_dir, which can be used to define the ```__pycache__```. However when I set this each time, every time when I run the code, it still tries to download the data. Is there any way that can avoid this? Or should I change the type of HDF5ClientData file to other format then I can save the data?

Thanks a lot for your help!"
46573,cannot convert tf savedmodel to onnx,"**System information**
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04
TensorFlow installed from (source or binary):
binary
TensorFlow version (use command below):
tf-nightly-gpu         2.5.0.dev20210119
Python version:
3.6 (Anaconda)
Tensorflow-onnx version:
1.8.0. build from source

my command line :
```shell
python -m tf2onnx.convert --saved-model ./model.savedmodel --output fea.onnx --custom-ops Bucketize,AsString,StringToHashBucketFast --signature_def serving_default --tag serve --opset 12 
```
But I got the following errorï¼
```shell
......
2021-01-21 11:29:41,413 - ERROR - Could not find table resource to replace placeholder unknown_172
2021-01-21 11:29:41,415 - ERROR - Could not find table resource to replace placeholder unknown_174
2021-01-21 11:29:41,416 - ERROR - Could not find table resource to replace placeholder unknown_176
2021-01-21 11:29:41,417 - ERROR - Could not find table resource to replace placeholder unknown_178
2021-01-21 11:29:41,418 - ERROR - Could not find table resource to replace placeholder unknown_180
2021-01-21 11:29:41,418 - ERROR - Could not find table resource to replace placeholder unknown_183
2021-01-21 11:29:41,418 - ERROR - Could not find table resource to replace placeholder unknown_185
2021-01-21 11:29:41,418 - ERROR - Could not find table resource to replace placeholder unknown_187
2021-01-21 11:29:41,418 - ERROR - Could not find table resource to replace placeholder unknown_189
2021-01-21 11:29:41,418 - ERROR - Could not find table resource to replace placeholder unknown_193
2021-01-21 11:29:41,418 - ERROR - Could not find table resource to replace placeholder unknown_195
2021-01-21 11:29:41,419 - ERROR - Could not find table resource to replace placeholder unknown_197
......
tensorflow.python.framework.errors_impl.InvalidArgumentError: 'func' argument to TF_GraphCopyFunction cannot be null
Exception ignored in: <bound method CapturableResourceDeleter.__del__ of <tensorflow.python.training.tracking.tracking.CapturableResourceDeleter object at 0x7f70486cbcf8>>
Traceback (most recent call last):
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py"", line 208, in __del__
    self._destroy_resource()
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 797, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 841, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 695, in _initialize
    *args, **kwds))
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2981, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3373, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3218, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 998, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 603, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/saved_model/function_deserialization.py"", line 257, in restored_function_body
    return _call_concrete_function(function, inputs)
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/saved_model/function_deserialization.py"", line 75, in _call_concrete_function
    result = function._call_flat(tensor_inputs, function._captured_inputs)  # pylint: disable=protected-access
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py"", line 116, in _call_flat
    cancellation_manager)
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1944, in _call_flat
    flat_outputs = forward_function.call(ctx, args_with_tangents)
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 590, in call
    executor_type=executor_type)
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py"", line 1206, in partitioned_call
    f.add_to_graph(graph)
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 506, in add_to_graph
    g._add_function(self)
  File ""/usr/local/anaconda3/envs/tf2.2-n/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3403, in _add_function
    gradient)

```
I want to get the ONNX model, desperate for some adviceï¼

thank you very much
"
46572,Virtual Batch Normalization using Tensorflow,"What is the recommended way to use [VBN](https://arxiv.org/pdf/1606.03498v1.pdf) using Tensorflow? 
Would it be an idea to add this to the documentation?"
46569, A function to get number of TFLite model parameters,"**System information**
- TensorFlow version (you are using): 2.3 
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.** A function to get number of TFLite model parameters

**Will this change the current api? How?** It will add a new function to Interpreter

**Who will benefit with this feature?** People who need to optimize the model. They will be able to see the change in parameter number and estimate benefits 

**Any Other info.** If there is a way to do it in a current version, please, let me know.
"
46568,typos,"There are multiple typos in the tensorflow/python/keras/layers/merge.py
Used in a **_functiona_** model
should be **_functional_**"
46567,LSTM layer not Using cuDNN even with default arguments,"**Problem description**
I am using a TF model in RLlib in my project. The model contains a ConvLSTM2D layer and a LSTM layer. However, even with default arguments, there is a warning:
`WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU`
Note that there is no complaint about my ConvLSTM2D layer.
I also tried to manually filled in all relevant arguments with values required in TF document, but the warning still persists. Can anyone help me figure out where the problem is?
Full code for constructing the model and the system information are provided below.

**Code for model construction**
Note that obs_space.shape=46800, activation=tanh, and normc_initializer is a built-in kernel initializer in RLlib.
```
        inputs = tf.keras.layers.Input(obs_space.shape, name=""observations"")

        input_depth = inputs[..., :45000]
        input_sensor = inputs[..., 45000:]

        input_depth = tf.keras.layers.Reshape(target_shape=(50, 30, 30, 1))(input_depth)
        input_sensor = tf.keras.layers.Reshape(target_shape=(50, 36))(input_sensor)

        conv_lstm = tf.keras.layers.ConvLSTM2D(filters=10, kernel_size=(3, 3))(input_depth)
        pool = tf.keras.layers.MaxPool2D()(conv_lstm)
        flat = tf.keras.layers.Flatten()(pool)

        fc1 = tf.keras.layers.Dense(512, activation=activation)(flat)
        fc2 = tf.keras.layers.Dense(128, activation=activation)(fc1)
        conv_out = tf.keras.layers.Dense(16, activation=activation)(fc2)

        sensor_lstm = tf.keras.layers.LSTM(units=64)(input_sensor)

        action_out = tf.keras.layers.Concatenate()([sensor_lstm, conv_out])
        action_out = tf.keras.layers.Dense(128, activation=activation,
                                           kernel_initializer=normc_initializer(1.0))(action_out)
        action_out = tf.keras.layers.Dense(64, activation=activation,
                                           kernel_initializer=normc_initializer(1.0))(action_out)
        final_action_out = tf.keras.layers.Dense(num_outputs,
                                                 activation=activation,
                                                 kernel_initializer=normc_initializer(1.0))(action_out)

        value_out = tf.keras.layers.Dense(
            1,
            name=""value_out"",
            activation=None,
            kernel_initializer=normc_initializer(0.01))(action_out)

        self.base_model = tf.keras.Model(
            inputs, [final_action_out, value_out])
        self.register_variables(self.base_model.variables)
```

**System information**
- OS Platform and Distribution: Ubuntu 18.04.5 LTS
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.4.0
- Python version: 3.6.9
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA version: 11.2
- cuDNN version: 8.0.5
- GPU model and memory: GeForce RTX 3080, 10009MiB
"
46566,macOS Target //tensorflow/tools/pip_package:build_pip_package failed to build in debug mode,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: macOS Big Sur 11.1
- TensorFlow installed from (source or binary): source
- TensorFlow version: commit 582c8d236cb079023657287c318ff26adb239002 (HEAD, tag: v2.4.0)
- Python version: /usr/local/anaconda3/envs/python3.8tf2.4/bin/python 3.8.5
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): Apple clang version 11.0.3 (clang-1103.0.32.62)
- CUDA/cuDNN version: no GPU, CPU-only
- GPU model and memory: no GPU
- apple clang version
Apple clang version 11.0.3 (clang-1103.0.32.62)
Target: x86_64-apple-darwin20.2.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin

**exec command**

bazel --output_base=../tensorflow-mac-cache/build_output_base --output_user_root=../tensorflow-mac-cache/build_output_user_root build --config=v2 --config=dbg --config=noaws //tensorflow/tools/pip_package:build_pip_package --repository_cache ../tensorflow-mac-cache


**Describe the problem**

**/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/install_name_tool: object: bazel-out/darwin-dbg/bin/tensorflow/python/_pywrap_tensorflow_internal.so truncated or malformed object (LC_SEGMENT_64 command 0 fileoff field plus filesize field extends past the end of the file)
Target //tensorflow/tools/pip_package:build_pip_package failed to build**

**Any other info / logs**

WARNING: The following configs were expanded more than once: [v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=254
INFO: Reading rc options for 'build' from /Users/zhouleqin/oss/tensorflow/tensorflow-mac/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /Users/zhouleqin/oss/tensorflow/tensorflow-mac/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /Users/zhouleqin/oss/tensorflow/tensorflow-mac/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/local/anaconda3/envs/python3.8tf2.4/bin/python --action_env PYTHON_LIB_PATH=/usr/local/anaconda3/envs/python3.8tf2.4/lib/python3.8/site-packages --python_path=/usr/local/anaconda3/envs/python3.8tf2.4/bin/python --config=xla --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /Users/zhouleqin/oss/tensorflow/tensorflow-mac/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /Users/zhouleqin/oss/tensorflow/tensorflow-mac/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /Users/zhouleqin/oss/tensorflow/tensorflow-mac/.bazelrc: --define=with_xla_support=true
INFO: Found applicable config definition build:v2 in file /Users/zhouleqin/oss/tensorflow/tensorflow-mac/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:dbg in file /Users/zhouleqin/oss/tensorflow/tensorflow-mac/.bazelrc: --config=opt -c dbg --cxxopt -DTF_LITE_DISABLE_X86_NEON --copt -DDEBUG_BUILD
INFO: Found applicable config definition build:opt in file /Users/zhouleqin/oss/tensorflow/tensorflow-mac/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true
INFO: Found applicable config definition build:noaws in file /Users/zhouleqin/oss/tensorflow/tensorflow-mac/.bazelrc: --define=no_aws_support=true
INFO: Found applicable config definition build:macos in file /Users/zhouleqin/oss/tensorflow/tensorflow-mac/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14
DEBUG: Rule 'io_bazel_rules_go' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1557349968 -0400""
DEBUG: Repository io_bazel_rules_go instantiated at:
  no stack (--record_rule_instantiation_callstack not enabled)
Repository rule git_repository defined at:
  /Users/zhouleqin/oss/tensorflow/tensorflow-mac-cache/build_output_base/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18: in <toplevel>
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Repository io_bazel_rules_docker instantiated at:
  no stack (--record_rule_instantiation_callstack not enabled)
Repository rule git_repository defined at:
  /Users/zhouleqin/oss/tensorflow/tensorflow-mac-cache/build_output_base/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18: in <toplevel>
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (399 packages loaded, 29982 targets configured).
INFO: Found 1 target...
ERROR: /Users/zhouleqin/oss/tensorflow/tensorflow-mac/tensorflow/python/BUILD:6068:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::grappler::graph_analyzer::SigNode::NodeOrderLess&, tensorflow::grappler::graph_analyzer::SigNode**>(tensorflow::grappler::graph_analyzer::SigNode**, tensorflow::grappler::graph_analyzer::SigNode**, tensorflow::grappler::graph_analyzer::SigNode**, tensorflow::grappler::graph_analyzer::SigNode**, tensorflow::grappler::graph_analyzer::SigNode**, tensorflow::grappler::graph_analyzer::SigNode::NodeOrderLess&) from bazel-out/darwin-dbg/bin/tensorflow/core/grappler/graph_analyzer/libgraph_analyzer_lib.a(sig_node_d733b32da0773161a7330c56df6f758b.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::grappler::graph_analyzer::SigNode::HashedPeer::LessByRank&, tensorflow::grappler::graph_analyzer::SigNode::HashedPeer*>(tensorflow::grappler::graph_analyzer::SigNode::HashedPeer*, tensorflow::grappler::graph_analyzer::SigNode::HashedPeer*, tensorflow::grappler::graph_analyzer::SigNode::HashedPeer*, tensorflow::grappler::graph_analyzer::SigNode::HashedPeer*, tensorflow::grappler::graph_analyzer::SigNode::HashedPeer*, tensorflow::grappler::graph_analyzer::SigNode::HashedPeer::LessByRank&) from bazel-out/darwin-dbg/bin/tensorflow/core/grappler/graph_analyzer/libgraph_analyzer_lib.a(sig_node_d733b32da0773161a7330c56df6f758b.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::vector<tensorflow::tfprof::CodeNode*, std::__1::allocator<tensorflow::tfprof::CodeNode*> > tensorflow::tfprof::TFMultiShow::SortNodes<tensorflow::tfprof::CodeNode>(std::__1::vector<tensorflow::tfprof::CodeNode*, std::__1::allocator<tensorflow::tfprof::CodeNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::CodeNode const*, tensorflow::tfprof::CodeNode const*)&, tensorflow::tfprof::CodeNode**>(std::__1::vector<tensorflow::tfprof::CodeNode*, std::__1::allocator<tensorflow::tfprof::CodeNode*> > tensorflow::tfprof::TFMultiShow::SortNodes<tensorflow::tfprof::CodeNode>(std::__1::vector<tensorflow::tfprof::CodeNode*, std::__1::allocator<tensorflow::tfprof::CodeNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::CodeNode const*, tensorflow::tfprof::CodeNode const*)&, std::__1::vector<tensorflow::tfprof::CodeNode*, std::__1::allocator<tensorflow::tfprof::CodeNode*> > tensorflow::tfprof::TFMultiShow::SortNodes<tensorflow::tfprof::CodeNode>(std::__1::vector<tensorflow::tfprof::CodeNode*, std::__1::allocator<tensorflow::tfprof::CodeNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::CodeNode const*, tensorflow::tfprof::CodeNode const*)&, std::__1::vector<tensorflow::tfprof::CodeNode*, std::__1::allocator<tensorflow::tfprof::CodeNode*> > tensorflow::tfprof::TFMultiShow::SortNodes<tensorflow::tfprof::CodeNode>(std::__1::vector<tensorflow::tfprof::CodeNode*, std::__1::allocator<tensorflow::tfprof::CodeNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::CodeNode const*, tensorflow::tfprof::CodeNode const*)&, std::__1::vector<tensorflow::tfprof::CodeNode*, std::__1::allocator<tensorflow::tfprof::CodeNode*> > tensorflow::tfprof::TFMultiShow::SortNodes<tensorflow::tfprof::CodeNode>(std::__1::vector<tensorflow::tfprof::CodeNode*, std::__1::allocator<tensorflow::tfprof::CodeNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::CodeNode const*, tensorflow::tfprof::CodeNode const*)&, std::__1::vector<tensorflow::tfprof::CodeNode*, std::__1::allocator<tensorflow::tfprof::CodeNode*> > tensorflow::tfprof::TFMultiShow::SortNodes<tensorflow::tfprof::CodeNode>(std::__1::vector<tensorflow::tfprof::CodeNode*, std::__1::allocator<tensorflow::tfprof::CodeNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::CodeNode const*, tensorflow::tfprof::CodeNode const*)&, tensorflow::tfprof::CodeNode) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/internal/libtfprof_code.a(tfprof_code_a26c563a46a40084f9c18fa4e14b5dfc.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::vector<tensorflow::tfprof::GraphNode*, std::__1::allocator<tensorflow::tfprof::GraphNode*> > tensorflow::tfprof::TFShow::SortNodes<tensorflow::tfprof::GraphNode>(std::__1::vector<tensorflow::tfprof::GraphNode*, std::__1::allocator<tensorflow::tfprof::GraphNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::GraphNode const*, tensorflow::tfprof::GraphNode const*)&, tensorflow::tfprof::GraphNode**>(std::__1::vector<tensorflow::tfprof::GraphNode*, std::__1::allocator<tensorflow::tfprof::GraphNode*> > tensorflow::tfprof::TFShow::SortNodes<tensorflow::tfprof::GraphNode>(std::__1::vector<tensorflow::tfprof::GraphNode*, std::__1::allocator<tensorflow::tfprof::GraphNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::GraphNode const*, tensorflow::tfprof::GraphNode const*)&, std::__1::vector<tensorflow::tfprof::GraphNode*, std::__1::allocator<tensorflow::tfprof::GraphNode*> > tensorflow::tfprof::TFShow::SortNodes<tensorflow::tfprof::GraphNode>(std::__1::vector<tensorflow::tfprof::GraphNode*, std::__1::allocator<tensorflow::tfprof::GraphNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::GraphNode const*, tensorflow::tfprof::GraphNode const*)&, std::__1::vector<tensorflow::tfprof::GraphNode*, std::__1::allocator<tensorflow::tfprof::GraphNode*> > tensorflow::tfprof::TFShow::SortNodes<tensorflow::tfprof::GraphNode>(std::__1::vector<tensorflow::tfprof::GraphNode*, std::__1::allocator<tensorflow::tfprof::GraphNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::GraphNode const*, tensorflow::tfprof::GraphNode const*)&, std::__1::vector<tensorflow::tfprof::GraphNode*, std::__1::allocator<tensorflow::tfprof::GraphNode*> > tensorflow::tfprof::TFShow::SortNodes<tensorflow::tfprof::GraphNode>(std::__1::vector<tensorflow::tfprof::GraphNode*, std::__1::allocator<tensorflow::tfprof::GraphNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::GraphNode const*, tensorflow::tfprof::GraphNode const*)&, std::__1::vector<tensorflow::tfprof::GraphNode*, std::__1::allocator<tensorflow::tfprof::GraphNode*> > tensorflow::tfprof::TFShow::SortNodes<tensorflow::tfprof::GraphNode>(std::__1::vector<tensorflow::tfprof::GraphNode*, std::__1::allocator<tensorflow::tfprof::GraphNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::GraphNode const*, tensorflow::tfprof::GraphNode const*)&, tensorflow::tfprof::GraphNode) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/internal/libtfprof_graph.a(tfprof_graph_2f61d25b8e7928c7de3fad0300552800.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::vector<tensorflow::tfprof::OpNode*, std::__1::allocator<tensorflow::tfprof::OpNode*> > tensorflow::tfprof::TFMultiShow::SortNodes<tensorflow::tfprof::OpNode>(std::__1::vector<tensorflow::tfprof::OpNode*, std::__1::allocator<tensorflow::tfprof::OpNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::OpNode const*, tensorflow::tfprof::OpNode const*)&, tensorflow::tfprof::OpNode**>(std::__1::vector<tensorflow::tfprof::OpNode*, std::__1::allocator<tensorflow::tfprof::OpNode*> > tensorflow::tfprof::TFMultiShow::SortNodes<tensorflow::tfprof::OpNode>(std::__1::vector<tensorflow::tfprof::OpNode*, std::__1::allocator<tensorflow::tfprof::OpNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::OpNode const*, tensorflow::tfprof::OpNode const*)&, std::__1::vector<tensorflow::tfprof::OpNode*, std::__1::allocator<tensorflow::tfprof::OpNode*> > tensorflow::tfprof::TFMultiShow::SortNodes<tensorflow::tfprof::OpNode>(std::__1::vector<tensorflow::tfprof::OpNode*, std::__1::allocator<tensorflow::tfprof::OpNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::OpNode const*, tensorflow::tfprof::OpNode const*)&, std::__1::vector<tensorflow::tfprof::OpNode*, std::__1::allocator<tensorflow::tfprof::OpNode*> > tensorflow::tfprof::TFMultiShow::SortNodes<tensorflow::tfprof::OpNode>(std::__1::vector<tensorflow::tfprof::OpNode*, std::__1::allocator<tensorflow::tfprof::OpNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::OpNode const*, tensorflow::tfprof::OpNode const*)&, std::__1::vector<tensorflow::tfprof::OpNode*, std::__1::allocator<tensorflow::tfprof::OpNode*> > tensorflow::tfprof::TFMultiShow::SortNodes<tensorflow::tfprof::OpNode>(std::__1::vector<tensorflow::tfprof::OpNode*, std::__1::allocator<tensorflow::tfprof::OpNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::OpNode const*, tensorflow::tfprof::OpNode const*)&, std::__1::vector<tensorflow::tfprof::OpNode*, std::__1::allocator<tensorflow::tfprof::OpNode*> > tensorflow::tfprof::TFMultiShow::SortNodes<tensorflow::tfprof::OpNode>(std::__1::vector<tensorflow::tfprof::OpNode*, std::__1::allocator<tensorflow::tfprof::OpNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::OpNode const*, tensorflow::tfprof::OpNode const*)&, tensorflow::tfprof::OpNode) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/internal/libtfprof_op.a(tfprof_op_a70008a9da797874493284813e09cc5f.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::vector<tensorflow::tfprof::ScopeNode*, std::__1::allocator<tensorflow::tfprof::ScopeNode*> > tensorflow::tfprof::TFShow::SortNodes<tensorflow::tfprof::ScopeNode>(std::__1::vector<tensorflow::tfprof::ScopeNode*, std::__1::allocator<tensorflow::tfprof::ScopeNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::ScopeNode const*, tensorflow::tfprof::ScopeNode const*)&, tensorflow::tfprof::ScopeNode**>(std::__1::vector<tensorflow::tfprof::ScopeNode*, std::__1::allocator<tensorflow::tfprof::ScopeNode*> > tensorflow::tfprof::TFShow::SortNodes<tensorflow::tfprof::ScopeNode>(std::__1::vector<tensorflow::tfprof::ScopeNode*, std::__1::allocator<tensorflow::tfprof::ScopeNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::ScopeNode const*, tensorflow::tfprof::ScopeNode const*)&, std::__1::vector<tensorflow::tfprof::ScopeNode*, std::__1::allocator<tensorflow::tfprof::ScopeNode*> > tensorflow::tfprof::TFShow::SortNodes<tensorflow::tfprof::ScopeNode>(std::__1::vector<tensorflow::tfprof::ScopeNode*, std::__1::allocator<tensorflow::tfprof::ScopeNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::ScopeNode const*, tensorflow::tfprof::ScopeNode const*)&, std::__1::vector<tensorflow::tfprof::ScopeNode*, std::__1::allocator<tensorflow::tfprof::ScopeNode*> > tensorflow::tfprof::TFShow::SortNodes<tensorflow::tfprof::ScopeNode>(std::__1::vector<tensorflow::tfprof::ScopeNode*, std::__1::allocator<tensorflow::tfprof::ScopeNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::ScopeNode const*, tensorflow::tfprof::ScopeNode const*)&, std::__1::vector<tensorflow::tfprof::ScopeNode*, std::__1::allocator<tensorflow::tfprof::ScopeNode*> > tensorflow::tfprof::TFShow::SortNodes<tensorflow::tfprof::ScopeNode>(std::__1::vector<tensorflow::tfprof::ScopeNode*, std::__1::allocator<tensorflow::tfprof::ScopeNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::ScopeNode const*, tensorflow::tfprof::ScopeNode const*)&, std::__1::vector<tensorflow::tfprof::ScopeNode*, std::__1::allocator<tensorflow::tfprof::ScopeNode*> > tensorflow::tfprof::TFShow::SortNodes<tensorflow::tfprof::ScopeNode>(std::__1::vector<tensorflow::tfprof::ScopeNode*, std::__1::allocator<tensorflow::tfprof::ScopeNode*> > const&, tensorflow::tfprof::Options const&)::'lambda'(tensorflow::tfprof::ScopeNode const*, tensorflow::tfprof::ScopeNode const*)&, tensorflow::tfprof::ScopeNode) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/internal/libtfprof_scope.a(tfprof_scope_11c51e84c798e4ddcba54fe391baf72c.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::GraphTransferer::TransferParamsComparator&, google::protobuf::internal::RepeatedPtrIterator<tensorflow::GraphTransferNodeInfo> >(google::protobuf::internal::RepeatedPtrIterator<tensorflow::GraphTransferNodeInfo>, google::protobuf::internal::RepeatedPtrIterator<tensorflow::GraphTransferNodeInfo>, google::protobuf::internal::RepeatedPtrIterator<tensorflow::GraphTransferNodeInfo>, google::protobuf::internal::RepeatedPtrIterator<tensorflow::GraphTransferNodeInfo>, google::protobuf::internal::RepeatedPtrIterator<tensorflow::GraphTransferNodeInfo>, tensorflow::GraphTransferer::TransferParamsComparator&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/hexagon/libgraph_transferer.lo(graph_transferer_22753e0a5a216a0b5219abadd4751aab.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::__less<tensorflow::boosted_trees::quantiles::WeightedQuantilesBuffer<float, float, std::__1::less<float> >::BufferEntry, tensorflow::boosted_trees::quantiles::WeightedQuantilesBuffer<float, float, std::__1::less<float> >::BufferEntry>&, tensorflow::boosted_trees::quantiles::WeightedQuantilesBuffer<float, float, std::__1::less<float> >::BufferEntry*>(tensorflow::boosted_trees::quantiles::WeightedQuantilesBuffer<float, float, std::__1::less<float> >::BufferEntry*, tensorflow::boosted_trees::quantiles::WeightedQuantilesBuffer<float, float, std::__1::less<float> >::BufferEntry*, tensorflow::boosted_trees::quantiles::WeightedQuantilesBuffer<float, float, std::__1::less<float> >::BufferEntry*, tensorflow::boosted_trees::quantiles::WeightedQuantilesBuffer<float, float, std::__1::less<float> >::BufferEntry*, tensorflow::boosted_trees::quantiles::WeightedQuantilesBuffer<float, float, std::__1::less<float> >::BufferEntry*, std::__1::__less<tensorflow::boosted_trees::quantiles::WeightedQuantilesBuffer<float, float, std::__1::less<float> >::BufferEntry, tensorflow::boosted_trees::quantiles::WeightedQuantilesBuffer<float, float, std::__1::less<float> >::BufferEntry>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/boosted_trees/libquantile_ops.lo(quantile_ops_de7a0d0c958ae29bbcf86ecb1b8f3cf0.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::ctc::ctc_beam_search::BeamComparer<float, tensorflow::ctc::ctc_beam_search::EmptyBeamState>&, tensorflow::ctc::ctc_beam_search::BeamEntry<float, tensorflow::ctc::ctc_beam_search::EmptyBeamState>**>(tensorflow::ctc::ctc_beam_search::BeamEntry<float, tensorflow::ctc::ctc_beam_search::EmptyBeamState>**, tensorflow::ctc::ctc_beam_search::BeamEntry<float, tensorflow::ctc::ctc_beam_search::EmptyBeamState>**, tensorflow::ctc::ctc_beam_search::BeamEntry<float, tensorflow::ctc::ctc_beam_search::EmptyBeamState>**, tensorflow::ctc::ctc_beam_search::BeamEntry<float, tensorflow::ctc::ctc_beam_search::EmptyBeamState>**, tensorflow::ctc::ctc_beam_search::BeamEntry<float, tensorflow::ctc::ctc_beam_search::EmptyBeamState>**, tensorflow::ctc::ctc_beam_search::BeamComparer<float, tensorflow::ctc::ctc_beam_search::EmptyBeamState>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libctc_ops.lo(ctc_decoder_ops_4698ee8777e83dca130b29b59c4317bc.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::ctc::ctc_beam_search::BeamComparer<double, tensorflow::ctc::ctc_beam_search::EmptyBeamState>&, tensorflow::ctc::ctc_beam_search::BeamEntry<double, tensorflow::ctc::ctc_beam_search::EmptyBeamState>**>(tensorflow::ctc::ctc_beam_search::BeamEntry<double, tensorflow::ctc::ctc_beam_search::EmptyBeamState>**, tensorflow::ctc::ctc_beam_search::BeamEntry<double, tensorflow::ctc::ctc_beam_search::EmptyBeamState>**, tensorflow::ctc::ctc_beam_search::BeamEntry<double, tensorflow::ctc::ctc_beam_search::EmptyBeamState>**, tensorflow::ctc::ctc_beam_search::BeamEntry<double, tensorflow::ctc::ctc_beam_search::EmptyBeamState>**, tensorflow::ctc::ctc_beam_search::BeamEntry<double, tensorflow::ctc::ctc_beam_search::EmptyBeamState>**, tensorflow::ctc::ctc_beam_search::BeamComparer<double, tensorflow::ctc::ctc_beam_search::EmptyBeamState>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libctc_ops.lo(ctc_decoder_ops_4698ee8777e83dca130b29b59c4317bc.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::__less<tensorflow::tstring, tensorflow::tstring>&, tensorflow::tstring*>(tensorflow::tstring*, tensorflow::tstring*, tensorflow::tstring*, tensorflow::tstring*, tensorflow::tstring*, std::__1::__less<tensorflow::tstring, tensorflow::tstring>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libmatching_files_op.lo(matching_files_op_a2c9e45966d3d26b4c3530dd5b51d53e.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, unsigned long long>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<unsigned long long const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<unsigned long long, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda0'(int, int)&, int*>(unsigned long long, unsigned long long, unsigned long long, unsigned long long, unsigned long long, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, unsigned long long>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<unsigned long long const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<unsigned long long, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda'(int, int)&, int*>(unsigned long long, unsigned long long, unsigned long long, unsigned long long, unsigned long long, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, long long>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<long long const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<long long, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda0'(int, int)&, int*>(long long, long long, long long, long long, long long, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, long long>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<long long const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<long long, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda'(int, int)&, int*>(long long, long long, long long, long long, long long, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, unsigned int>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<unsigned int const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<unsigned int, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda0'(int, int)&, int*>(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, unsigned int>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<unsigned int const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<unsigned int, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda'(int, int)&, int*>(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, unsigned short>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<unsigned short const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<unsigned short, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda0'(int, int)&, int*>(unsigned short, unsigned short, unsigned short, unsigned short, unsigned short, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, unsigned short>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<unsigned short const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<unsigned short, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda'(int, int)&, int*>(unsigned short, unsigned short, unsigned short, unsigned short, unsigned short, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, short>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<short const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<short, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda0'(int, int)&, int*>(short, short, short, short, short, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, short>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<short const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<short, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda'(int, int)&, int*>(short, short, short, short, short, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, unsigned char>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<unsigned char, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda0'(int, int)&, int*>(unsigned char, unsigned char, unsigned char, unsigned char, unsigned char, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, unsigned char>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<unsigned char, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda'(int, int)&, int*>(unsigned char, unsigned char, unsigned char, unsigned char, unsigned char, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, signed char>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<signed char const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<signed char, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda0'(int, int)&, int*>(signed char, signed char, signed char, signed char, signed char, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, signed char>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<signed char const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<signed char, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda'(int, int)&, int*>(signed char, signed char, signed char, signed char, signed char, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<int const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda0'(int, int)&, int*>(int, int, int, int, int, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<int const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda'(int, int)&, int*>(int, int, int, int, int, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, Eigen::half>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<Eigen::half const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<Eigen::half, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda0'(int, int)&, int*>(Eigen::half, Eigen::half, Eigen::half, Eigen::half, Eigen::half, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, Eigen::half>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<Eigen::half const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<Eigen::half, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda'(int, int)&, int*>(Eigen::half, Eigen::half, Eigen::half, Eigen::half, Eigen::half, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, Eigen::bfloat16>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<Eigen::bfloat16 const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<Eigen::bfloat16, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda0'(int, int)&, int*>(Eigen::bfloat16, Eigen::bfloat16, Eigen::bfloat16, Eigen::bfloat16, Eigen::bfloat16, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, Eigen::bfloat16>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<Eigen::bfloat16 const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<Eigen::bfloat16, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda'(int, int)&, int*>(Eigen::bfloat16, Eigen::bfloat16, Eigen::bfloat16, Eigen::bfloat16, Eigen::bfloat16, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda0'(int, int)&, int*>(float, float, float, float, float, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda'(int, int)&, int*>(float, float, float, float, float, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, double>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<double const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<double, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda0'(int, int)&, int*>(double, double, double, double, double, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, double>::Compute(tensorflow::OpKernelContext*, bool, int, Eigen::TensorMap<Eigen::Tensor<double const, 2, 1, long>, 16, Eigen::MakePointer> const&, long long, long long, Eigen::TensorMap<Eigen::Tensor<double, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, Eigen::MakePointer>)::'lambda'(long long, long long)::operator()(long long, long long) const::'lambda'(int, int)&, int*>(double, double, double, double, double, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtopk_op.lo(topk_op_5354c76f51d39c5b8f6b4b8cc0d2b1a3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<0>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<0>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_concat_op.lo(sparse_concat_op_4674e7b63e015e31356d9be955fef609.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<1>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<1>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_concat_op.lo(sparse_concat_op_4674e7b63e015e31356d9be955fef609.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<2>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<2>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_concat_op.lo(sparse_concat_op_4674e7b63e015e31356d9be955fef609.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<3>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<3>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_concat_op.lo(sparse_concat_op_4674e7b63e015e31356d9be955fef609.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<4>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<4>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_concat_op.lo(sparse_concat_op_4674e7b63e015e31356d9be955fef609.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<5>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<5>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_concat_op.lo(sparse_concat_op_4674e7b63e015e31356d9be955fef609.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::DimComparator&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::DimComparator&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_concat_op.lo(sparse_concat_op_4674e7b63e015e31356d9be955fef609.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<0>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<0>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reduce_op.lo(sparse_reduce_op_b05ba9e16702b505a468507c58621ce4.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<1>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<1>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reduce_op.lo(sparse_reduce_op_b05ba9e16702b505a468507c58621ce4.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<2>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<2>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reduce_op.lo(sparse_reduce_op_b05ba9e16702b505a468507c58621ce4.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<3>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<3>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reduce_op.lo(sparse_reduce_op_b05ba9e16702b505a468507c58621ce4.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<4>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<4>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reduce_op.lo(sparse_reduce_op_b05ba9e16702b505a468507c58621ce4.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<5>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<5>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reduce_op.lo(sparse_reduce_op_b05ba9e16702b505a468507c58621ce4.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::DimComparator&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::DimComparator&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reduce_op.lo(sparse_reduce_op_b05ba9e16702b505a468507c58621ce4.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<0>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<0>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reorder_op.lo(sparse_reorder_op_be89eeaa50bd444ea933702e4fdf59af.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<1>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<1>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reorder_op.lo(sparse_reorder_op_be89eeaa50bd444ea933702e4fdf59af.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<2>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<2>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reorder_op.lo(sparse_reorder_op_be89eeaa50bd444ea933702e4fdf59af.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<3>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<3>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reorder_op.lo(sparse_reorder_op_be89eeaa50bd444ea933702e4fdf59af.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<4>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<4>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reorder_op.lo(sparse_reorder_op_be89eeaa50bd444ea933702e4fdf59af.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<5>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<5>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reorder_op.lo(sparse_reorder_op_be89eeaa50bd444ea933702e4fdf59af.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::DimComparator&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::DimComparator&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_reorder_op.lo(sparse_reorder_op_be89eeaa50bd444ea933702e4fdf59af.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<0>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<0>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_softmax.lo(sparse_softmax_op_5efd3ee1fa1ac3f14aa4925eae52e1aa.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<1>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<1>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_softmax.lo(sparse_softmax_op_5efd3ee1fa1ac3f14aa4925eae52e1aa.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<2>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<2>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_softmax.lo(sparse_softmax_op_5efd3ee1fa1ac3f14aa4925eae52e1aa.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<3>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<3>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_softmax.lo(sparse_softmax_op_5efd3ee1fa1ac3f14aa4925eae52e1aa.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<4>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<4>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_softmax.lo(sparse_softmax_op_5efd3ee1fa1ac3f14aa4925eae52e1aa.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::FixedDimComparator<5>&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::FixedDimComparator<5>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_softmax.lo(sparse_softmax_op_5efd3ee1fa1ac3f14aa4925eae52e1aa.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::sparse::DimComparator&, long long*>(long long*, long long*, long long*, long long*, long long*, tensorflow::sparse::DimComparator&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libsparse_softmax.lo(sparse_softmax_op_5efd3ee1fa1ac3f14aa4925eae52e1aa.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::VariableInputLockHolder tensorflow::MaybeLockVariableInputMutexesInOrder<Eigen::ThreadPoolDevice, Eigen::half>(tensorflow::OpKernelContext*, bool, bool, std::__1::vector<int, std::__1::allocator<int> > const&)::'lambda'(int, int)&, int*>(Eigen::half, Eigen::half, Eigen::half, Eigen::half, Eigen::half, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtraining_ops.lo(training_ops_b043fa34f8ffc5e560b358393a8a593e.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::VariableInputLockHolder tensorflow::MaybeLockVariableInputMutexesInOrder<Eigen::ThreadPoolDevice, Eigen::bfloat16>(tensorflow::OpKernelContext*, bool, bool, std::__1::vector<int, std::__1::allocator<int> > const&)::'lambda'(int, int)&, int*>(Eigen::bfloat16, Eigen::bfloat16, Eigen::bfloat16, Eigen::bfloat16, Eigen::bfloat16, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtraining_ops.lo(training_ops_b043fa34f8ffc5e560b358393a8a593e.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::VariableInputLockHolder tensorflow::MaybeLockVariableInputMutexesInOrder<Eigen::ThreadPoolDevice, float>(tensorflow::OpKernelContext*, bool, bool, std::__1::vector<int, std::__1::allocator<int> > const&)::'lambda'(int, int)&, int*>(float, float, float, float, float, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtraining_ops.lo(training_ops_b043fa34f8ffc5e560b358393a8a593e.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::VariableInputLockHolder tensorflow::MaybeLockVariableInputMutexesInOrder<Eigen::ThreadPoolDevice, double>(tensorflow::OpKernelContext*, bool, bool, std::__1::vector<int, std::__1::allocator<int> > const&)::'lambda'(int, int)&, int*>(double, double, double, double, double, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtraining_ops.lo(training_ops_b043fa34f8ffc5e560b358393a8a593e.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::VariableInputLockHolder tensorflow::MaybeLockVariableInputMutexesInOrder<Eigen::ThreadPoolDevice, std::__1::complex<float> >(tensorflow::OpKernelContext*, bool, bool, std::__1::vector<int, std::__1::allocator<int> > const&)::'lambda'(int, int)&, int*>(std::__1::complex<float>, std::__1::complex<float>, std::__1::complex<float>, std::__1::complex<float>, std::__1::complex<float>, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtraining_ops.lo(training_ops_b043fa34f8ffc5e560b358393a8a593e.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::VariableInputLockHolder tensorflow::MaybeLockVariableInputMutexesInOrder<Eigen::ThreadPoolDevice, std::__1::complex<double> >(tensorflow::OpKernelContext*, bool, bool, std::__1::vector<int, std::__1::allocator<int> > const&)::'lambda'(int, int)&, int*>(std::__1::complex<double>, std::__1::complex<double>, std::__1::complex<double>, std::__1::complex<double>, std::__1::complex<double>, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libtraining_ops.lo(training_ops_b043fa34f8ffc5e560b358393a8a593e.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::SkipgramOp::Init(tensorflow::Env*, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int> const&, std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int> const&)&, std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int>*>(std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int>*, std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int>*, std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int>*, std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int>*, std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int>*, tensorflow::SkipgramOp::Init(tensorflow::Env*, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int> const&, std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int> const&)&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/libword2vec_kernels.lo(word2vec_kernels_81e6f553c012d7458fbb8cfb8a6d72b8.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::Status tensorflow::EinsumHelper::ReduceOperand<Eigen::ThreadPoolDevice, Eigen::bfloat16>(tensorflow::OpKernelContext*, tensorflow::Tensor const&, std::__1::vector<tensorflow::EinsumHelper::DimensionType, std::__1::allocator<tensorflow::EinsumHelper::DimensionType> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, bool*, tensorflow::Tensor*)::'lambda'(int, int)&, int*>(Eigen::bfloat16, Eigen::bfloat16, Eigen::bfloat16, Eigen::bfloat16, Eigen::bfloat16, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/linalg/libeinsum_op.lo(einsum_op_impl_bfloat16_e96046132695ada08436540f6b862e23.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::Status tensorflow::EinsumHelper::ReduceOperand<Eigen::ThreadPoolDevice, std::__1::complex<double> >(tensorflow::OpKernelContext*, tensorflow::Tensor const&, std::__1::vector<tensorflow::EinsumHelper::DimensionType, std::__1::allocator<tensorflow::EinsumHelper::DimensionType> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, bool*, tensorflow::Tensor*)::'lambda'(int, int)&, int*>(std::__1::complex<double>, std::__1::complex<double>, std::__1::complex<double>, std::__1::complex<double>, std::__1::complex<double>, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/linalg/libeinsum_op.lo(einsum_op_impl_complex128_1ddb1b9c54cc3cb1ae550daea2f10911.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::Status tensorflow::EinsumHelper::ReduceOperand<Eigen::ThreadPoolDevice, std::__1::complex<float> >(tensorflow::OpKernelContext*, tensorflow::Tensor const&, std::__1::vector<tensorflow::EinsumHelper::DimensionType, std::__1::allocator<tensorflow::EinsumHelper::DimensionType> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, bool*, tensorflow::Tensor*)::'lambda'(int, int)&, int*>(std::__1::complex<float>, std::__1::complex<float>, std::__1::complex<float>, std::__1::complex<float>, std::__1::complex<float>, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/linalg/libeinsum_op.lo(einsum_op_impl_complex64_34f20a9f7e93ea248a2771cde501aa66.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::Status tensorflow::EinsumHelper::ReduceOperand<Eigen::ThreadPoolDevice, double>(tensorflow::OpKernelContext*, tensorflow::Tensor const&, std::__1::vector<tensorflow::EinsumHelper::DimensionType, std::__1::allocator<tensorflow::EinsumHelper::DimensionType> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, bool*, tensorflow::Tensor*)::'lambda'(int, int)&, int*>(double, double, double, double, double, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/linalg/libeinsum_op.lo(einsum_op_impl_double_cdb86d35f5123022c97ee09f6889c4eb.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::Status tensorflow::EinsumHelper::ReduceOperand<Eigen::ThreadPoolDevice, float>(tensorflow::OpKernelContext*, tensorflow::Tensor const&, std::__1::vector<tensorflow::EinsumHelper::DimensionType, std::__1::allocator<tensorflow::EinsumHelper::DimensionType> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, bool*, tensorflow::Tensor*)::'lambda'(int, int)&, int*>(float, float, float, float, float, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/linalg/libeinsum_op.lo(einsum_op_impl_float_a65e15b63aa636cc95248c27d203925a.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::Status tensorflow::EinsumHelper::ReduceOperand<Eigen::ThreadPoolDevice, Eigen::half>(tensorflow::OpKernelContext*, tensorflow::Tensor const&, std::__1::vector<tensorflow::EinsumHelper::DimensionType, std::__1::allocator<tensorflow::EinsumHelper::DimensionType> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, bool*, tensorflow::Tensor*)::'lambda'(int, int)&, int*>(Eigen::half, Eigen::half, Eigen::half, Eigen::half, Eigen::half, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/linalg/libeinsum_op.lo(einsum_op_impl_half_1eb10a78ae8567588818b0b09d3982f1.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::Status tensorflow::EinsumHelper::ReduceOperand<Eigen::ThreadPoolDevice, int>(tensorflow::OpKernelContext*, tensorflow::Tensor const&, std::__1::vector<tensorflow::EinsumHelper::DimensionType, std::__1::allocator<tensorflow::EinsumHelper::DimensionType> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, bool*, tensorflow::Tensor*)::'lambda'(int, int)&, int*>(int, int, int, int, int, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/linalg/libeinsum_op.lo(einsum_op_impl_int32_2f56c4c4f95659c74b815f5a7cee0793.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::Status tensorflow::EinsumHelper::ReduceOperand<Eigen::ThreadPoolDevice, long long>(tensorflow::OpKernelContext*, tensorflow::Tensor const&, std::__1::vector<tensorflow::EinsumHelper::DimensionType, std::__1::allocator<tensorflow::EinsumHelper::DimensionType> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> > const&, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, absl::lts_2020_02_25::InlinedVector<int, 8ul, std::__1::allocator<int> >*, bool*, tensorflow::Tensor*)::'lambda'(int, int)&, int*>(long long, long long, long long, long long, long long, Eigen::ThreadPoolDevice) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/linalg/libeinsum_op.lo(einsum_op_impl_int64_435e129393df940ec8d3b4de668a1d5b.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::__less<tensorflow::tstring, tensorflow::tstring>&, tensorflow::tstring*>(tensorflow::tstring*, tensorflow::tstring*, tensorflow::tstring*, tensorflow::tstring*, tensorflow::tstring*, std::__1::__less<tensorflow::tstring, tensorflow::tstring>&) from bazel-out/darwin-dbg/bin/tensorflow/core/kernels/data/experimental/libsnapshot_dataset_op.lo(snapshot_dataset_op_91741f4343bbe6a4fc3927373da58952.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::profiler::XLinesComparatorByName&, google::protobuf::internal::RepeatedPtrOverPtrsIterator<tensorflow::profiler::XLine*, void*> >(google::protobuf::internal::RepeatedPtrOverPtrsIterator<tensorflow::profiler::XLine*, void*>, google::protobuf::internal::RepeatedPtrOverPtrsIterator<tensorflow::profiler::XLine*, void*>, google::protobuf::internal::RepeatedPtrOverPtrsIterator<tensorflow::profiler::XLine*, void*>, google::protobuf::internal::RepeatedPtrOverPtrsIterator<tensorflow::profiler::XLine*, void*>, google::protobuf::internal::RepeatedPtrOverPtrsIterator<tensorflow::profiler::XLine*, void*>, tensorflow::profiler::XLinesComparatorByName&) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/internal/cpu/libhost_tracer_utils.a(host_tracer_utils_90b6373b66ad9b998bbc11a215e407d3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::__less<tensorflow::TensorId, tensorflow::TensorId>&, tensorflow::TensorId*>(tensorflow::TensorId*, tensorflow::TensorId*, tensorflow::TensorId*, tensorflow::TensorId*, tensorflow::TensorId*, std::__1::__less<tensorflow::TensorId, tensorflow::TensorId>&) from bazel-out/darwin-dbg/bin/tensorflow/compiler/jit/libcompilation_passes.a(deadness_analysis_f1267db28f708ac918fcdae7398bb918.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::NodeComparatorID&, tensorflow::Node**>(tensorflow::Node**, tensorflow::Node**, tensorflow::Node**, tensorflow::Node**, tensorflow::Node**, tensorflow::NodeComparatorID&) from bazel-out/darwin-dbg/bin/tensorflow/compiler/jit/libcompilation_passes.a(mark_for_compilation_pass_cac15d051d331b682147f799f0293b20.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::profiler::XEventsComparator&, google::protobuf::internal::RepeatedPtrOverPtrsIterator<tensorflow::profiler::XEvent*, void*> >(google::protobuf::internal::RepeatedPtrOverPtrsIterator<tensorflow::profiler::XEvent*, void*>, google::protobuf::internal::RepeatedPtrOverPtrsIterator<tensorflow::profiler::XEvent*, void*>, google::protobuf::internal::RepeatedPtrOverPtrsIterator<tensorflow::profiler::XEvent*, void*>, google::protobuf::internal::RepeatedPtrOverPtrsIterator<tensorflow::profiler::XEvent*, void*>, google::protobuf::internal::RepeatedPtrOverPtrsIterator<tensorflow::profiler::XEvent*, void*>, tensorflow::profiler::XEventsComparator&) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/utils/libxplane_utils.a(xplane_utils_9a1bc04280f6bc8f819e1acc8e9d3fa3.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<google::protobuf::internal::CompareByDerefFirst<google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::ToolRequestOptions> const*>&, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::ToolRequestOptions> const**>(google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::ToolRequestOptions> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::ToolRequestOptions> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::ToolRequestOptions> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::ToolRequestOptions> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::ToolRequestOptions> const**, google::protobuf::internal::CompareByDerefFirst<google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::ToolRequestOptions> const*>&) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/libprofiler_service_proto_cc_impl.lo(profiler_service.pb_8737cb65d1a2d29f389fd3b6368ea2ea.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<google::protobuf::internal::CompareByFirstField<google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ProfileNode> const*> >&, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ProfileNode> const*>*>(google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ProfileNode> const*>*, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ProfileNode> const*>*, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ProfileNode> const*>*, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ProfileNode> const*>*, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ProfileNode> const*>*, google::protobuf::internal::CompareByFirstField<google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ProfileNode> const*> >&) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/libprotos_all_cc_impl.lo(tfprof_log.pb_6d69bfbededc497228a1433d58c70cc9.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<google::protobuf::internal::CompareByDerefFirst<google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const*>&, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const**>(google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const**, google::protobuf::internal::CompareByDerefFirst<google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const*>&) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/libprotos_all_cc_impl.lo(tfprof_log.pb_6d69bfbededc497228a1433d58c70cc9.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<google::protobuf::internal::CompareByFirstField<google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ExecProfile> const*> >&, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ExecProfile> const*>*>(google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ExecProfile> const*>*, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ExecProfile> const*>*, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ExecProfile> const*>*, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ExecProfile> const*>*, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ExecProfile> const*>*, google::protobuf::internal::CompareByFirstField<google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, tensorflow::tfprof::ExecProfile> const*> >&) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/libprotos_all_cc_impl.lo(tfprof_log.pb_6d69bfbededc497228a1433d58c70cc9.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<google::protobuf::internal::CompareByFirstField<google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Tuple> const*> >&, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Tuple> const*>*>(google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Tuple> const*>*, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Tuple> const*>*, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Tuple> const*>*, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Tuple> const*>*, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Tuple> const*>*, google::protobuf::internal::CompareByFirstField<google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Tuple> const*> >&) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/libprotos_all_cc_impl.lo(tfprof_log.pb_6d69bfbededc497228a1433d58c70cc9.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<google::protobuf::internal::CompareByDerefFirst<google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::ExecTime> const*>&, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::ExecTime> const**>(google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::ExecTime> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::ExecTime> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::ExecTime> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::ExecTime> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::ExecTime> const**, google::protobuf::internal::CompareByDerefFirst<google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::ExecTime> const*>&) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/libprotos_all_cc_impl.lo(tfprof_log.pb_6d69bfbededc497228a1433d58c70cc9.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<google::protobuf::internal::CompareByFirstField<google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Memory> const*> >&, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Memory> const*>*>(google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Memory> const*>*, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Memory> const*>*, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Memory> const*>*, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Memory> const*>*, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Memory> const*>*, google::protobuf::internal::CompareByFirstField<google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::tfprof::Memory> const*> >&) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/libprotos_all_cc_impl.lo(tfprof_log.pb_6d69bfbededc497228a1433d58c70cc9.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<google::protobuf::internal::CompareByDerefFirst<google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdvisorOptionsProto_CheckerOption> const*>&, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdvisorOptionsProto_CheckerOption> const**>(google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdvisorOptionsProto_CheckerOption> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdvisorOptionsProto_CheckerOption> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdvisorOptionsProto_CheckerOption> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdvisorOptionsProto_CheckerOption> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdvisorOptionsProto_CheckerOption> const**, google::protobuf::internal::CompareByDerefFirst<google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdvisorOptionsProto_CheckerOption> const*>&) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/libprotos_all_cc_impl.lo(tfprof_options.pb_c051573c5c19805f236ebf81236c99ac.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<google::protobuf::internal::CompareByFirstField<google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::TensorShapeProto> const*> >&, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::TensorShapeProto> const*>*>(google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::TensorShapeProto> const*>*, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::TensorShapeProto> const*>*, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::TensorShapeProto> const*>*, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::TensorShapeProto> const*>*, google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::TensorShapeProto> const*>*, google::protobuf::internal::CompareByFirstField<google::protobuf::internal::SortItem<int, google::protobuf::MapPair<int, tensorflow::TensorShapeProto> const*> >&) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/libprotos_all_cc_impl.lo(tfprof_output.pb_63ada445ea0a3affff8c00dfbf36f738.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<google::protobuf::internal::CompareByDerefFirst<google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdviceProto_Checker> const*>&, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdviceProto_Checker> const**>(google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdviceProto_Checker> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdviceProto_Checker> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdviceProto_Checker> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdviceProto_Checker> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdviceProto_Checker> const**, google::protobuf::internal::CompareByDerefFirst<google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::tfprof::AdviceProto_Checker> const*>&) from bazel-out/darwin-dbg/bin/tensorflow/core/profiler/libprotos_all_cc_impl.lo(tfprof_output.pb_63ada445ea0a3affff8c00dfbf36f738.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<google::protobuf::internal::CompareByDerefFirst<google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const*>&, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const**>(google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const**, google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const**, google::protobuf::internal::CompareByDerefFirst<google::protobuf::MapPair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::AttrValue> const*>&) from bazel-out/darwin-dbg/bin/tensorflow/core/protobuf/libeager_service_proto_cc_impl.lo(eager_service.pb_be4c6375cd8b11bdf5675a2df2ef5f13.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::__less<tensorflow::gtl::IntType<xla::GlobalDeviceId_tag_, long long>, tensorflow::gtl::IntType<xla::GlobalDeviceId_tag_, long long> >&, tensorflow::gtl::IntType<xla::GlobalDeviceId_tag_, long long>*>(tensorflow::gtl::IntType<xla::GlobalDeviceId_tag_, long long>*, tensorflow::gtl::IntType<xla::GlobalDeviceId_tag_, long long>*, tensorflow::gtl::IntType<xla::GlobalDeviceId_tag_, long long>*, tensorflow::gtl::IntType<xla::GlobalDeviceId_tag_, long long>*, tensorflow::gtl::IntType<xla::GlobalDeviceId_tag_, long long>*, std::__1::__less<tensorflow::gtl::IntType<xla::GlobalDeviceId_tag_, long long>, tensorflow::gtl::IntType<xla::GlobalDeviceId_tag_, long long> >&) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/gpu/libgpu_executable_run_options.a(gpu_executable_run_options_c82bcadad723fe1693d8dea4216d3923.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<xla::HloAliasAnalysis::LiveOutBuffers() const::'lambda'(xla::HloBuffer const*, xla::HloBuffer const*)&, xla::HloBuffer const**>(xla::HloBuffer const**, xla::HloBuffer const**, xla::HloBuffer const**, xla::HloBuffer const**, xla::HloBuffer const**, xla::HloAliasAnalysis::LiveOutBuffers() const::'lambda'(xla::HloBuffer const*, xla::HloBuffer const*)&) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libbuffer_assignment.a(buffer_assignment_7ff3dd807a6707c0d8f1783c4f200ccb.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<bool (*&)(xla::HloValue const*, xla::HloValue const*), xla::HloValue const**>(xla::HloValue const**, xla::HloValue const**, xla::HloValue const**, xla::HloValue const**, xla::HloValue const**, bool (*&)(xla::HloValue const*, xla::HloValue const*)) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libbuffer_assignment.a(buffer_assignment_7ff3dd807a6707c0d8f1783c4f200ccb.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::function<bool (xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval const&, xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval const&)>&, xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval*>(xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval*, xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval*, xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval*, xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval*, xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval*, std::__1::function<bool (xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval const&, xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval const&)>&) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libheap_simulator.a(heap_simulator_bd7b0db06b3e616f9556d8e2bf846d2e.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::FindChunkCandidate(xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval const&, long long) const::'lambda'(xla::HeapSimulator::Chunk const&, xla::HeapSimulator::Chunk const&)&, xla::HeapSimulator::Chunk*>(xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::FindChunkCandidate(xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval const&, long long) const::'lambda'(xla::HeapSimulator::Chunk const&, xla::HeapSimulator::Chunk const&)&, xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::FindChunkCandidate(xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval const&, long long) const::'lambda'(xla::HeapSimulator::Chunk const&, xla::HeapSimulator::Chunk const&)&, xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::FindChunkCandidate(xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval const&, long long) const::'lambda'(xla::HeapSimulator::Chunk const&, xla::HeapSimulator::Chunk const&)&, xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::FindChunkCandidate(xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval const&, long long) const::'lambda'(xla::HeapSimulator::Chunk const&, xla::HeapSimulator::Chunk const&)&, xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::FindChunkCandidate(xla::GlobalDecreasingSizeBestFitHeap<xla::HloValue>::BufferInterval const&, long long) const::'lambda'(xla::HeapSimulator::Chunk const&, xla::HeapSimulator::Chunk const&)&, xla::HloValue) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libheap_simulator.a(heap_simulator_bd7b0db06b3e616f9556d8e2bf846d2e.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::function<bool (xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval const&, xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval const&)>&, xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval*>(xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval*, xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval*, xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval*, xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval*, xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval*, std::__1::function<bool (xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval const&, xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval const&)>&) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libheap_simulator.a(heap_simulator_bd7b0db06b3e616f9556d8e2bf846d2e.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::FindChunkCandidate(xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval const&, long long) const::'lambda'(xla::HeapSimulator::Chunk const&, xla::HeapSimulator::Chunk const&)&, xla::HeapSimulator::Chunk*>(xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::FindChunkCandidate(xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval const&, long long) const::'lambda'(xla::HeapSimulator::Chunk const&, xla::HeapSimulator::Chunk const&)&, xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::FindChunkCandidate(xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval const&, long long) const::'lambda'(xla::HeapSimulator::Chunk const&, xla::HeapSimulator::Chunk const&)&, xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::FindChunkCandidate(xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval const&, long long) const::'lambda'(xla::HeapSimulator::Chunk const&, xla::HeapSimulator::Chunk const&)&, xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::FindChunkCandidate(xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval const&, long long) const::'lambda'(xla::HeapSimulator::Chunk const&, xla::HeapSimulator::Chunk const&)&, xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::FindChunkCandidate(xla::GlobalDecreasingSizeBestFitHeap<xla::MemorySpaceAssignmentRepacker::AllocationBlock>::BufferInterval const&, long long) const::'lambda'(xla::HeapSimulator::Chunk const&, xla::HeapSimulator::Chunk const&)&, xla::MemorySpaceAssignmentRepacker::AllocationBlock) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libheap_simulator.a(heap_simulator_bd7b0db06b3e616f9556d8e2bf846d2e.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<bool (*&)(xla::HloBuffer const*, xla::HloBuffer const*), xla::HloBuffer const**>(xla::HloBuffer const**, xla::HloBuffer const**, xla::HloBuffer const**, xla::HloBuffer const**, xla::HloBuffer const**, bool (*&)(xla::HloBuffer const*, xla::HloBuffer const*)) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libhlo_alias_analysis.a(hlo_alias_analysis_98b09d9b5341f72a61ead38c995a276b.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<bool (*&)(xla::HloValue const*, xla::HloValue const*), xla::HloValue const**>(xla::HloValue const**, xla::HloValue const**, xla::HloValue const**, xla::HloValue const**, xla::HloValue const**, bool (*&)(xla::HloValue const*, xla::HloValue const*)) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libhlo_alias_analysis.a(hlo_alias_analysis_98b09d9b5341f72a61ead38c995a276b.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::__less<xla::HloPosition, xla::HloPosition>&, xla::HloPosition*>(xla::HloPosition*, xla::HloPosition*, xla::HloPosition*, xla::HloPosition*, xla::HloPosition*, std::__1::__less<xla::HloPosition, xla::HloPosition>&) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libhlo_buffer.a(hlo_buffer_5dd5cb2616f0a526c1afa963f9eeb4c0.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<bool (*&)(xla::HloValue const*, xla::HloValue const*), xla::HloValue**>(xla::HloValue**, xla::HloValue**, xla::HloValue**, xla::HloValue**, xla::HloValue**, bool (*&)(xla::HloValue const*, xla::HloValue const*)) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libhlo_dataflow_analysis.a(hlo_dataflow_analysis_43d901a8c1959e1d81ae59552723fb54.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<bool (*&)(xla::HloValue const*, xla::HloValue const*), xla::HloValue const**>(xla::HloValue const**, xla::HloValue const**, xla::HloValue const**, xla::HloValue const**, xla::HloValue const**, bool (*&)(xla::HloValue const*, xla::HloValue const*)) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libhlo_value.a(hlo_value_1fd7a5734f4a8556ea8008f22635103e.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::function<bool (std::__1::pair<int, xla::HloInstruction const*>, std::__1::pair<int, xla::HloInstruction const*>)>&, std::__1::pair<int, xla::HloInstruction*>*>(std::__1::pair<int, xla::HloInstruction*>*, std::__1::pair<int, xla::HloInstruction*>*, std::__1::pair<int, xla::HloInstruction*>*, std::__1::pair<int, xla::HloInstruction*>*, std::__1::pair<int, xla::HloInstruction*>*, std::__1::function<bool (std::__1::pair<int, xla::HloInstruction const*>, std::__1::pair<int, xla::HloInstruction const*>)>&) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libhlo.a(hlo_instruction_0edf4881a3b85d91ea3a69a0a2c5f990.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<bool (*&)(xla::HloComputation*, xla::HloComputation*), xla::HloComputation**>(xla::HloComputation**, xla::HloComputation**, xla::HloComputation**, xla::HloComputation**, xla::HloComputation**, bool (*&)(xla::HloComputation*, xla::HloComputation*)) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libhlo.a(hlo_module_80ef1175230ab4359f90ce77c288b243.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<google::protobuf::internal::CompareByFirstField<google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, xla::HloScheduleProto_InstructionSequence> const*> >&, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, xla::HloScheduleProto_InstructionSequence> const*>*>(google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, xla::HloScheduleProto_InstructionSequence> const*>*, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, xla::HloScheduleProto_InstructionSequence> const*>*, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, xla::HloScheduleProto_InstructionSequence> const*>*, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, xla::HloScheduleProto_InstructionSequence> const*>*, google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, xla::HloScheduleProto_InstructionSequence> const*>*, google::protobuf::internal::CompareByFirstField<google::protobuf::internal::SortItem<long long, google::protobuf::MapPair<long long, xla::HloScheduleProto_InstructionSequence> const*> >&) from bazel-out/darwin-dbg/bin/tensorflow/compiler/xla/service/libhlo_proto_cc_impl.lo(hlo.pb_247e720ee9eb6dbacb0f50c185005e9f.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::grappler::internal::NodeMapInternal<tensorflow::GraphDef, tensorflow::NodeDef>::GetOutputsOrderedByNodeName(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const::'lambda'(tensorflow::NodeDef const*, tensorflow::NodeDef const*)&, tensorflow::NodeDef**>(tensorflow::NodeDef, tensorflow::NodeDef, tensorflow::NodeDef, tensorflow::NodeDef, tensorflow::NodeDef, tensorflow::GraphDef) from bazel-out/darwin-dbg/bin/tensorflow/core/grappler/optimizers/libarithmetic_optimizer.a(arithmetic_optimizer_00afebfd8dbac9401e7f3de830bb479c.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<tensorflow::grappler::internal::NodeMapInternal<tensorflow::GraphDef, tensorflow::NodeDef>::GetOutputsOrderedByNodeName(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const::'lambda'(tensorflow::NodeDef const*, tensorflow::NodeDef const*)&, tensorflow::NodeDef**>(tensorflow::NodeDef, tensorflow::NodeDef, tensorflow::NodeDef, tensorflow::NodeDef, tensorflow::NodeDef, tensorflow::GraphDef) from bazel-out/darwin-dbg/bin/tensorflow/core/grappler/optimizers/libconstant_folding.a(constant_folding_20910a966e3a1a4d77043c3c399dc460.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::function<bool (tensorflow::Node const*, tensorflow::Node const*)>&, tensorflow::Node**>(tensorflow::Node**, tensorflow::Node**, tensorflow::Node**, tensorflow::Node**, tensorflow::Node**, std::__1::function<bool (tensorflow::Node const*, tensorflow::Node const*)>&) from bazel-out/darwin-dbg/bin/tensorflow/core/libgraph.a(algorithm_578ef39f4d71a37f469a1d717629d65f.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::function<bool (tensorflow::Node const*, tensorflow::Node const*)>&, tensorflow::Node const**>(tensorflow::Node const**, tensorflow::Node const**, tensorflow::Node const**, tensorflow::Node const**, tensorflow::Node const**, std::__1::function<bool (tensorflow::Node const*, tensorflow::Node const*)>&) from bazel-out/darwin-dbg/bin/tensorflow/core/libgraph.a(algorithm_578ef39f4d71a37f469a1d717629d65f.o)
ld: warning: cannot export hidden symbol unsigned int std::__1::__sort5<std::__1::__less<std::__1::pair<tensorflow::Node const*, int>, std::__1::pair<tensorflow::Node const*, int> >&, std::__1::pair<tensorflow::Node const*, int>*>(std::__1::pair<tensorflow::Node const*, int>*, std::__1::pair<tensorflow::Node const*, int>*, std::__1::pair<tensorflow::Node const*, int>*, std::__1::pair<tensorflow::Node const*, int>*, std::__1::pair<tensorflow::Node const*, int>*, std::__1::__less<std::__1::pair<tensorflow::Node const*, int>, std::__1::pair<tensorflow::Node const*, int> >&) from bazel-out/darwin-dbg/bin/tensorflow/core/libgraph.a(optimizer_cse_d75b72ac47a91b0109458536f7f1df58.o)
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/install_name_tool: object: bazel-out/darwin-dbg/bin/tensorflow/python/_pywrap_tensorflow_internal.so truncated or malformed object (LC_SEGMENT_64 command 0 fileoff field plus filesize field extends past the end of the file)
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 9209.870s, Critical Path: 2417.25s
INFO: 17280 processes: 17280 local.
FAILED: Build did NOT complete successfully
"
46565,How the quantization on BERT,"tf version:2.2.0
enviroment: win10 cpu

`
import tensorflow as tf
saved_model_dir='bert_en_uncased_L-12_H-768_A-12_3'


converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
`

Here is the code for quantization  from [quantization](https://tensorflow.google.cn/lite/guide/get_started#éå)
I want to do the quantization on the device without GPU.

here is the error message, 
""ValueError: None is only supported in the 1st dimension. Tensor 'input_mask' has invalid shape '[None, None]'.""


`
2021-01-21 12:11:06.978175: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-Q99TL0E
2021-01-21 12:11:06.978491: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2021-01-21 12:11:06.984840: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c5f66f5e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-01-21 12:11:06.985036: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-21 12:11:16.651117: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2021-01-21 12:11:16.651396: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2021-01-21 12:11:16.761993: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2021-01-21 12:11:16.762196: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 1585 nodes (1367), 5592 edges (5360), time = 70.744ms.
2021-01-21 12:11:16.762434: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 2.131ms.
2021-01-21 12:11:22.677739: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2021-01-21 12:11:22.678009: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2021-01-21 12:11:41.718415: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2021-01-21 12:11:41.721239: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 1383 nodes (-203), 5188 edges (-405), time = 15370.7383ms.
2021-01-21 12:11:41.721428: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 1383 nodes (0), 5188 edges (0), time = 766.249ms.
Traceback (most recent call last):
  File ""E:/Desktop/demo_models/convert.py"", line 10, in <module>
    tflite_model = converter.convert()
  File ""D:\anaconda\envs\tf\lib\site-packages\tensorflow\lite\python\lite.py"", line 483, in convert
    _get_tensor_name(tensor), shape_list))
ValueError: None is only supported in the 1st dimension. Tensor 'input_mask' has invalid shape '[None, None]'.


`"
46564,Regarding tensorflow error in ubuntu 18.04," F tensorflow/core/platform/cpu_feature_guard.cc:38] The TensorFlow library was compiled to use FMA instructions, but these aren't available on your machine.
Aborted (core dumped)


can anyone please help me with this error."
46563,tf.Variable throws TypeError on conversion to typed numpy ndarray,"The `__array__()` method is recognized by Numpy to allow objects to be conveniently converted to a Numpy ndarray.  This doesn't work consistently for`tf.Variable` because its definition of the method uses an incorrect signature that accepts no arguments (other than `self`): https://github.com/tensorflow/tensorflow/blob/569095ba3d5a57a95595d7db685b4bb748ca7337/tensorflow/python/ops/resource_variable_ops.py#L469

This breaks Numpy usage, which expects to be able to pass a dtype argument when converting to an explicitly typed array, as in `np.array(tf.Variable(0), dtype=np.int64)`.  (The expected signature is documented a bit sparsely but can been seen [here - scroll to ""PyArray_FromArrayAttr""](https://numpy.org/devdocs/reference/c-api/array.html) or by example of how `ndarray` itself defines its `__array__` method [here](https://numpy.org/devdocs/reference/generated/numpy.ndarray.__array__.html).)

Tested against the latest nightly and latest numpy:

```
numpy==1.19.5
tf-nightly==2.5.0.dev20210119
```

#### Expected behavior:

Converting `tf.Variable` with a dtype succeeds the same as `tf.constant` with a dtype, or `tf.Variable` without a dtype: 

```
$ python -c 'import tensorflow as tf; import numpy as np; np.array(tf.constant(0), dtype=np.int32)'
$ python -c 'import tensorflow as tf; import numpy as np; np.array(tf.Variable(0))'
$
```

#### Actual behavior:

It raises a TypeError:

```
$ python -c 'import tensorflow as tf; import numpy as np; np.array(tf.Variable(0), dtype=np.int32)'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
TypeError: __array__() takes 1 positional argument but 2 were given
```

---

Note that there are various other single-argument `__array__(self)` definitions within TF that should probably also be updated:
- https://github.com/tensorflow/tensorflow/blob/5a1d7415893a2e27ee6084809820cc18d2183225/tensorflow/python/keras/engine/keras_tensor.py#L276
- https://github.com/tensorflow/tensorflow/blob/0c3d87c81ed5d8ffb868b006036b6da6a0f73a1a/tensorflow/python/framework/ops.py#L852
- https://github.com/tensorflow/tensorflow/blob/0c3d87c81ed5d8ffb868b006036b6da6a0f73a1a/tensorflow/python/framework/ops.py#L1030

On that note, I'm a bit confused why `tf.constant(0)` can be converted above because the `EagerTensorBase.__array__()` definition has the same problem as `tf.Variable`.  Indeed, this can be confirmed by trying to explicitly call it like this:

```
$ python -c 'import tensorflow as tf; import numpy as np; tf.constant(0).__array__(np.int32)'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
TypeError: __array__() takes 1 positional argument but 2 were given
```

My best guess is that there's some other path through the ""convert python object to numpy array"" flowchart that is being taken, e.g. perhaps it's because `EagerTensorBase` implements `__len__` while `ResourceVariable` does not and so the constant is interpreted as a sequence and gets converted via that path.  However, it'd still be best if `__array__()` was consistently defined with the `dtype` argument within TF code, even for types where that path isn't reachable in normal usage today."
46559,Issue on using tf.vectorized_map on a function with a tf.while_loop,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): ```conda install tensorflow-gpu``` in a conda env
- TensorFlow version (use command below): 2.2
- Python version: 3.8.3
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: 10.2
- GPU model and memory:  GeForce RTX 2060 SUPER computeCapability: 7.5, Memory  8 GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
The included code tries to vectorize a function which adds 10.0 to the input and does so through a while loop which adds 1.0 each time (for 10 times). The function runs perfectly when using tf.map_fn and fails when using tf.vectorized_map

**Describe the expected behavior**
The function would not run when using vectorized map and the error points towards  `` Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower``

**Standalone code to reproduce the issue**
```
if __name__ == ""__main__"":
    import tensorflow as tf
    @tf.function()
    def add(a):       
        i = tf.constant(0, dtype = tf.int32)
        c = tf.constant(1., dtype = tf.float32)
        loop_index = lambda  i, c, a: i < 10
        def body(i, c, a):
            a = c + a
            i = i + 1
            return i,c, a
        i,c, a = tf.while_loop(loop_index, body, [i,c, a],\
             shape_invariants=[tf.TensorShape(()), tf.TensorShape(()),tf.TensorShape([1])], back_prop= False, parallel_iterations=1)

        return a

    counter =  tf.reshape(tf.range(0, 40, delta = 1, dtype = tf.float32), shape = [40,1])

    all_ = tf.vectorized_map(add, counter) # does not work
    # all_ = tf.map_fn(add, counter)
    print(all_, '<-- should be [40,1] float32 tensor with elements [10., 11., ...49.]')
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
2021-01-20 17:26:53.074085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-01-20 17:26:53.101801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.102114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.71GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2021-01-20 17:26:53.102265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-20 17:26:53.103295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-01-20 17:26:53.104241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-01-20 17:26:53.104386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-01-20 17:26:53.105247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-01-20 17:26:53.105734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-01-20 17:26:53.107658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-01-20 17:26:53.107742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.108011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.108212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-01-20 17:26:53.108397: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2021-01-20 17:26:53.112400: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3600000000 Hz
2021-01-20 17:26:53.112694: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55853e36c7b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-01-20 17:26:53.112704: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-20 17:26:53.112820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.113110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.71GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2021-01-20 17:26:53.113143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-20 17:26:53.113154: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-01-20 17:26:53.113163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-01-20 17:26:53.113171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-01-20 17:26:53.113180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-01-20 17:26:53.113188: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-01-20 17:26:53.113197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-01-20 17:26:53.113232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.113508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.113760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-01-20 17:26:53.113779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-20 17:26:53.182683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-20 17:26:53.182703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-01-20 17:26:53.182707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-01-20 17:26:53.182837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.183090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.183343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.183550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6620 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
2021-01-20 17:26:53.184629: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55853ec63ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-01-20 17:26:53.184638: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
WARNING:tensorflow:From distransTest.py:266: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.while_loop(c, b, vars, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))
ERROR:tensorflow:Got error while pfor was converting op name: ""loop_body/PartitionedCall""
op: ""PartitionedCall""
input: ""loop_body/GatherV2""
attr {
  key: ""Tin""
  value {
    list {
      type: DT_FLOAT
    }
  }
}
attr {
  key: ""Tout""
  value {
    list {
      type: DT_FLOAT
    }
  }
}
attr {
  key: ""_read_only_resource_inputs""
  value {
    list {
    }
  }
}
attr {
  key: ""config""
  value {
    s: """"
  }
}
attr {
  key: ""config_proto""
  value {
    s: ""\n\007\n\003CPU\020\001\n\007\n\003GPU\020\0012\005*\0010J\0008\001""
  }
}
attr {
  key: ""executor_type""
  value {
    s: """"
  }
}
attr {
  key: ""f""
  value {
    func {
      name: ""__inference_add_57""
    }
  }
}
with inputs (<tf.Tensor 'loop_body/GatherV2:0' shape=(1,) dtype=float32>,)
, converted inputs [WrappedTensor(t=<tf.Tensor 'loop_body/GatherV2/params:0' shape=(40, 1) dtype=float32>, is_stacked=True, is_sparse_stacked=False)]
in user code:

    /home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *
        [converter._convert_helper(x).t for x in func._func_graph_outputs])
    /home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1460 _convert_helper  **
        raise ValueError(""No converter defined for %s\n%s\ninputs: %s. ""

    ValueError: No converter defined for StatelessWhile
    name: ""while""
    op: ""StatelessWhile""
    input: ""while/loop_counter""
    input: ""while/maximum_iterations""
    input: ""Const""
    input: ""Const_1""
    input: ""a""
    attr {
      key: ""T""
      value {
        list {
          type: DT_INT32
          type: DT_INT32
          type: DT_INT32
          type: DT_FLOAT
          type: DT_FLOAT
        }
      }
    }
    attr {
      key: ""_lower_using_switch_merge""
      value {
        b: true
      }
    }
    attr {
      key: ""_num_original_outputs""
      value {
        i: 5
      }
    }
    attr {
      key: ""_read_only_resource_inputs""
      value {
        list {
        }
      }
    }
    attr {
      key: ""body""
      value {
        func {
          name: ""while_body_20""
        }
      }
    }
    attr {
      key: ""cond""
      value {
        func {
          name: ""while_cond_19""
        }
      }
    }
    attr {
      key: ""output_shapes""
      value {
        list {
          shape {
          }
          shape {
          }
          shape {
          }
          shape {
          }
          shape {
            dim {
              size: 1
            }
          }
        }
      }
    }
    attr {
      key: ""parallel_iterations""
      value {
        i: 1
      }
    }
    
    inputs: [WrappedTensor(t=<tf.Tensor 'while/loop_counter/pfor/Const:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'while/maximum_iterations/pfor/Const:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'Const/pfor/Const:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'Const_1/pfor/Const:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_0:0' shape=(40, 1) dtype=float32>, is_stacked=True, is_sparse_stacked=False)]. 
    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower

Here are the pfor conversion stack traces:
ERROR:tensorflow:name: ""loop_body/PartitionedCall""
op: ""PartitionedCall""
input: ""loop_body/GatherV2""
attr {
  key: ""Tin""
  value {
    list {
      type: DT_FLOAT
    }
  }
}
attr {
  key: ""Tout""
  value {
    list {
      type: DT_FLOAT
    }
  }
}
attr {
  key: ""_read_only_resource_inputs""
  value {
    list {
    }
  }
}
attr {
  key: ""config""
  value {
    s: """"
  }
}
attr {
  key: ""config_proto""
  value {
    s: ""\n\007\n\003CPU\020\001\n\007\n\003GPU\020\0012\005*\0010J\0008\001""
  }
}
attr {
  key: ""executor_type""
  value {
    s: """"
  }
}
attr {
  key: ""f""
  value {
    func {
      name: ""__inference_add_57""
    }
  }
}

created at:
    File ""distransTest.py"", line 273, in <module>
    all_ = tf.vectorized_map(add, counter) # does not work
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py"", line 407, in vectorized_map
    return pfor(loop_fn, batch_size)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py"", line 198, in pfor
    outputs = f()
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 505, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2657, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 957, in wrapper
    return autograph.converted_call(
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py"", line 183, in f
    return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py"", line 237, in _pfor_impl
    loop_fn_outputs = loop_fn(loop_var)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py"", line 400, in loop_fn
    return fn(gathered_elems)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 650, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 1661, in _filtered_call
    return self._call_flat(
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 1760, in _call_flat
    flat_outputs = forward_function.call(ctx, args_with_tangents)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 621, in call
    outputs = functional_ops.partitioned_call(
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/functional_ops.py"", line 1180, in partitioned_call
    op = graph.create_op(op_name, args, tout, name=op_name, attrs=op_attrs)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 3257, in create_op
    return self._create_op_internal(op_type, inputs, dtypes, input_types, name,
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 593, in _create_op_internal
    return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 3319, in _create_op_internal
    ret = Operation(
    File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 1791, in __init__
    self._traceback = tf_stack.extract_stack()

Traceback (most recent call last):
  File ""distransTest.py"", line 273, in <module>
    all_ = tf.vectorized_map(add, counter) # does not work
  File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py"", line 407, in vectorized_map
    return pfor(loop_fn, batch_size)
  File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py"", line 198, in pfor
    outputs = f()
  File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 505, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2657, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:183 f  *
        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    /home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *
        [converter._convert_helper(x).t for x in func._func_graph_outputs])
    /home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1460 _convert_helper  **
        raise ValueError(""No converter defined for %s\n%s\ninputs: %s. ""

    ValueError: No converter defined for StatelessWhile
    name: ""while""
    op: ""StatelessWhile""
    input: ""while/loop_counter""
    input: ""while/maximum_iterations""
    input: ""Const""
    input: ""Const_1""
    input: ""a""
    attr {
      key: ""T""
      value {
        list {
          type: DT_INT32
          type: DT_INT32
          type: DT_INT32
          type: DT_FLOAT
          type: DT_FLOAT
        }
      }
    }
    attr {
      key: ""_lower_using_switch_merge""
      value {
        b: true
      }
    }
    attr {
      key: ""_num_original_outputs""
      value {
        i: 5
      }
    }
    attr {
      key: ""_read_only_resource_inputs""
      value {
        list {
        }
      }
    }
    attr {
      key: ""body""
      value {
        func {
          name: ""while_body_20""
        }
      }
    }
    attr {
      key: ""cond""
      value {
        func {
          name: ""while_cond_19""
        }
      }
    }
    attr {
      key: ""output_shapes""
      value {
        list {
          shape {
          }
          shape {
          }
          shape {
          }
          shape {
          }
          shape {
            dim {
              size: 1
            }
          }
        }
      }
    }
    attr {
      key: ""parallel_iterations""
      value {
        i: 1
      }
    }
    
    inputs: [WrappedTensor(t=<tf.Tensor 'while/loop_counter/pfor/Const:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'while/maximum_iterations/pfor/Const:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'Const/pfor/Const:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'Const_1/pfor/Const:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_0:0' shape=(40, 1) dtype=float32>, is_stacked=True, is_sparse_stacked=False)]. 
    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower

```
"
46556,TypeError: cannot pickle '_thread.lock' object in TensorFlow 2.4,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.4.0-0-g582c8d236cb 2.4.0
- Python version: 3.7.9
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Running a simple training process with MultiWorkerMirroredStrategy fails with `TypeError: can't pickle _thread.lock objects`.

**Describe the expected behavior**
The training should proceed without errors.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

The example needs to run in a distributed environment to reproduce the issue, so save the script in a file and run it in 3 different terminals.

```
TF_CONFIG='{""cluster"": {""chief"": [""localhost:2222""], ""worker"": [""localhost:2223"", ""localhost:2224""]}, ""task"": {""type"": ""chief"", ""index"": 0}}' python script.py 
TF_CONFIG='{""cluster"": {""chief"": [""localhost:2222""], ""worker"": [""localhost:2223"", ""localhost:2224""]}, ""task"": {""type"": ""worker"", ""index"": 0}}' python script.py
TF_CONFIG='{""cluster"": {""chief"": [""localhost:2222""], ""worker"": [""localhost:2223"", ""localhost:2224""]}, ""task"": {""type"": ""worker"", ""index"": 1}}' python script.py
```

```
import tensorflow as tf
import tensorflow_datasets as tfds
Â 
buffer_size = 10000
batch_size = 64
learning_rate = 1e-4
Â 
def input_fn(mode, input_context=None):
  tfds.disable_progress_bar()
  datasets, _ = tfds.load(name='mnist', with_info=True, as_supervised=True)
  mnist_dataset = ( 
      datasets['train']
      if mode == tf.estimator.ModeKeys.TRAIN else datasets['test'])
Â 
  def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255 
    return image, label
Â 
  if input_context:
    mnist_dataset = mnist_dataset.shard(input_context.num_input_pipelines,
                                        input_context.input_pipeline_id)
  return mnist_dataset.map(scale).cache().shuffle(buffer_size).batch(batch_size)
Â 
def model_fn(features, labels, mode):
  model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
      tf.keras.layers.MaxPooling2D(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(10)
  ])
  logits = model(features, training=False)
Â 
  if mode == tf.estimator.ModeKeys.PREDICT:
    predictions = {'logits': logits}
    return tf.estimator.EstimatorSpec(labels=labels, predictions=predictions)
Â 
  optimizer = tf.compat.v1.train.GradientDescentOptimizer(
      learning_rate=learning_rate)
  loss = tf.keras.losses.SparseCategoricalCrossentropy(
      from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(labels,
                                                                  logits)
  loss = tf.reduce_sum(loss) * (1. / batch_size)
  if mode == tf.estimator.ModeKeys.EVAL:
    return tf.estimator.EstimatorSpec(mode, loss=loss)
Â 
  logging_hook = tf.estimator.LoggingTensorHook({'loss': loss}, every_n_iter=10)
Â 
  return tf.estimator.EstimatorSpec(
      mode=mode,
      loss=loss,
      training_hooks=[logging_hook],
      train_op=optimizer.minimize(
          loss, tf.compat.v1.train.get_or_create_global_step()))
Â 
Â 
strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
Â 
config = tf.estimator.RunConfig(train_distribute=strategy)
Â 
classifier = tf.estimator.Estimator(
    model_fn=model_fn, model_dir='/tmp/multiworker', config=config)
Â 
tf.estimator.train_and_evaluate(
    classifier,
    train_spec=tf.estimator.TrainSpec(input_fn=input_fn),
    eval_spec=tf.estimator.EvalSpec(input_fn=input_fn))
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Full logs:
```
TF_CONFIG='{""cluster"": {""chief"": [""localhost:2222""], ""worker"": [""localhost:2223"", ""localhost:2224""]}, ""task"": {""type"": ""worker"", ""index"": 1}}' python script.py
WARNING:tensorflow:From script.py:68: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.
Instructions for updating:                                                                
use distribute.MultiWorkerMirroredStrategy instead                                                       
2021-01-20 18:24:44.477611: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-20 18:24:44.479538: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2021-01-20 18:24:44.491607: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job chief -> {0 -> localhost:2222}
2021-01-20 18:24:44.491654: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224}
2021-01-20 18:24:44.492211: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:2224
Traceback (most recent call last):                                                                                           
  File ""script.py"", line 73, in <module>                                                  
    model_fn=model_fn, model_dir='/tmp/multiworker', config=config)                                
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 183, in __init__
    config, model_dir)                                                                          
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1832, in maybe_overwrite_model_dir_and_session_config
    config = run_config.RunConfig.replace(config, session_config=session_config)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/run_config.py"", line 923, in replace
    copy.deepcopy(self),                                                             
  File ""/opt/conda/lib/python3.7/copy.py"", line 180, in deepcopy                    
    y = _reconstruct(x, memo, *rv)                                                                 
  File ""/opt/conda/lib/python3.7/copy.py"", line 281, in _reconstruct         
    state = deepcopy(state, memo)                                                              
  File ""/opt/conda/lib/python3.7/copy.py"", line 150, in deepcopy            
    y = copier(x, memo)                                                                            
  File ""/opt/conda/lib/python3.7/copy.py"", line 241, in _deepcopy_dict       
    y[deepcopy(key, memo)] = deepcopy(value, memo)          
  File ""/opt/conda/lib/python3.7/copy.py"", line 161, in deepcopy                      
    y = copier(memo)                                                                                                       
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 1542, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))                                                    
  File ""/opt/conda/lib/python3.7/copy.py"", line 180, in deepcopy                                             
    y = _reconstruct(x, memo, *rv)                                                
  File ""/opt/conda/lib/python3.7/copy.py"", line 281, in _reconstruct                                             
    state = deepcopy(state, memo)                                                   
  File ""/opt/conda/lib/python3.7/copy.py"", line 150, in deepcopy                             
    y = copier(x, memo)                                                                    
  File ""/opt/conda/lib/python3.7/copy.py"", line 241, in _deepcopy_dict              
    y[deepcopy(key, memo)] = deepcopy(value, memo)                                                                   
  File ""/opt/conda/lib/python3.7/copy.py"", line 180, in deepcopy                      
    y = _reconstruct(x, memo, *rv)                                                             
  File ""/opt/conda/lib/python3.7/copy.py"", line 281, in _reconstruct                                             
    state = deepcopy(state, memo)                                                   
  File ""/opt/conda/lib/python3.7/copy.py"", line 150, in deepcopy            
    y = copier(x, memo)                                                                      
  File ""/opt/conda/lib/python3.7/copy.py"", line 241, in _deepcopy_dict                               
    y[deepcopy(key, memo)] = deepcopy(value, memo)                            
  File ""/opt/conda/lib/python3.7/copy.py"", line 180, in deepcopy                       
    y = _reconstruct(x, memo, *rv)                                                                                             
  File ""/opt/conda/lib/python3.7/copy.py"", line 281, in _reconstruct                       
    state = deepcopy(state, memo)                                                                          
  File ""/opt/conda/lib/python3.7/copy.py"", line 150, in deepcopy                 
    y = copier(x, memo)                                                                   
  File ""/opt/conda/lib/python3.7/copy.py"", line 241, in _deepcopy_dict                     
    y[deepcopy(key, memo)] = deepcopy(value, memo)                                                                     
  File ""/opt/conda/lib/python3.7/copy.py"", line 169, in deepcopy                       
    rv = reductor(4)                                                                                                 
TypeError: can't pickle _thread.lock objects  
```"
46554,Auto-generated cortex-m0 hello world make project failing to link,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux pop-os 5.8.0-7625-generic
- TensorFlow installed from (source or binary): source 
- Tensorflow version (commit SHA if source): 2.3.2
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): cortex-M0

**Describe the problem**

**Please provide the exact sequence of commands/steps when you ran into the problem**

I've downloaded the master branch as zip, extracted the archive and navigated to the root of the directory structure and ran:

`make -f tensorflow/lite/micro/tools/make/Makefile TARGET=cortex_m_generic TARGET_ARCH=cortex-m0 microlite`

followed by

`make -f tensorflow/lite/micro/tools/make/Makefile TARGET=cortex_m_generic TARGET_ARCH=cortex-m0 generate_hello_world_make_project`

afterwards I `cd` to `tensorflow/lite/micro/tools/make/gen/cortex_m_generic_cortex-m0_default/prj/hello_world/make/` and execute `make` which results in the following error: 

`tensorflow/lite/micro/cortex_m_generic/debug_log.cc:25:10: fatal error: tensorflow/lite/micro/cortex_m_generic/debug_log_callback.h: No such file or directory
   25 | #include ""tensorflow/lite/micro/cortex_m_generic/debug_log_callback.h""
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
make: *** [Makefile:36: tensorflow/lite/micro/cortex_m_generic/debug_log.o] Error 1`

which I'm able to resolve by copying 

`debug_log_callback.h`

from 

`tensorflow/lite/micro/cortex_m_generic`

to the

`tensorflow/lite/micro/tools/make/gen/cortex_m_generic_cortex-m0_default/prj/hello_world/make/tensorflow/lite/micro/cortex_m_generic`

executing `make` from within `tensorflow/lite/micro/tools/make/gen/cortex_m_generic_cortex-m0_default/prj/hello_world/make/` which now runs smoothly and produces the individual out files until the first call to the linker: 

```
'arm-none-eabi-g++' -std=c++11 -fno-rtti -fno-exceptions -fno-threadsafe-statics -fno-unwind-tables -ffunction-sections -fdata-sections -fmessage-length=0 -DTF_LITE_STATIC_MEMORY -DTF_LITE_DISABLE_X86_NEON -O3 -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -Wswitch -Wvla -Wall -Wextra -Wstrict-aliasing -Wno-unused-parameter   -mcpu=cortex-m0 -mfpu=auto -DTF_LITE_MCU_DEBUG_LOG -mthumb -mfloat-abi=soft -funsigned-char -mlittle-endian -Wno-type-limits -Wno-unused-private-field -fomit-frame-pointer -MD -DCPU_M0=1  -I. -I./third_party/gemmlowp -I./third_party/flatbuffers/include -I./third_party/ruy -o hello_world tensorflow/lite/micro/all_ops_resolver.o tensorflow/lite/micro/cortex_m_generic/debug_log.o tensorflow/lite/micro/memory_helpers.o tensorflow/lite/micro/micro_allocator.o tensorflow/lite/micro/micro_error_reporter.o tensorflow/lite/micro/micro_interpreter.o tensorflow/lite/micro/micro_profiler.o tensorflow/lite/micro/micro_string.o tensorflow/lite/micro/micro_time.o tensorflow/lite/micro/micro_utils.o tensorflow/lite/micro/recording_micro_allocator.o tensorflow/lite/micro/recording_simple_memory_allocator.o tensorflow/lite/micro/simple_memory_allocator.o tensorflow/lite/micro/test_helpers.o tensorflow/lite/micro/benchmarks/keyword_scrambled_model_data.o tensorflow/lite/micro/memory_planner/greedy_memory_planner.o tensorflow/lite/micro/memory_planner/linear_memory_planner.o tensorflow/lite/micro/testing/test_conv_model.o tensorflow/lite/c/common.o tensorflow/lite/core/api/error_reporter.o tensorflow/lite/core/api/flatbuffer_conversions.o tensorflow/lite/core/api/op_resolver.o tensorflow/lite/core/api/tensor_utils.o tensorflow/lite/kernels/internal/quantization_util.o tensorflow/lite/kernels/kernel_util.o tensorflow/lite/schema/schema_utils.o tensorflow/lite/micro/kernels/activations.o tensorflow/lite/micro/kernels/add.o tensorflow/lite/micro/kernels/arg_min_max.o tensorflow/lite/micro/kernels/ceil.o tensorflow/lite/micro/kernels/circular_buffer.o tensorflow/lite/micro/kernels/comparisons.o tensorflow/lite/micro/kernels/concatenation.o tensorflow/lite/micro/kernels/conv.o tensorflow/lite/micro/kernels/conv_test_common.o tensorflow/lite/micro/kernels/depthwise_conv.o tensorflow/lite/micro/kernels/dequantize.o tensorflow/lite/micro/kernels/detection_postprocess.o tensorflow/lite/micro/kernels/elementwise.o tensorflow/lite/micro/kernels/ethosu.o tensorflow/lite/micro/kernels/flexbuffers_generated_data.o tensorflow/lite/micro/kernels/floor.o tensorflow/lite/micro/kernels/fully_connected.o tensorflow/lite/micro/kernels/fully_connected_common.o tensorflow/lite/micro/kernels/hard_swish.o tensorflow/lite/micro/kernels/kernel_runner.o tensorflow/lite/micro/kernels/kernel_util.o tensorflow/lite/micro/kernels/l2norm.o tensorflow/lite/micro/kernels/logical.o tensorflow/lite/micro/kernels/logistic.o tensorflow/lite/micro/kernels/maximum_minimum.o tensorflow/lite/micro/kernels/mul.o tensorflow/lite/micro/kernels/neg.o tensorflow/lite/micro/kernels/pack.o tensorflow/lite/micro/kernels/pad.o tensorflow/lite/micro/kernels/pooling.o tensorflow/lite/micro/kernels/prelu.o tensorflow/lite/micro/kernels/quantize.o tensorflow/lite/micro/kernels/quantize_common.o tensorflow/lite/micro/kernels/reduce.o tensorflow/lite/micro/kernels/reshape.o tensorflow/lite/micro/kernels/resize_nearest_neighbor.o tensorflow/lite/micro/kernels/round.o tensorflow/lite/micro/kernels/shape.o tensorflow/lite/micro/kernels/softmax.o tensorflow/lite/micro/kernels/split.o tensorflow/lite/micro/kernels/split_v.o tensorflow/lite/micro/kernels/strided_slice.o tensorflow/lite/micro/kernels/sub.o tensorflow/lite/micro/kernels/svdf.o tensorflow/lite/micro/kernels/svdf_common.o tensorflow/lite/micro/kernels/tanh.o tensorflow/lite/micro/kernels/transpose_conv.o tensorflow/lite/micro/kernels/unpack.o tensorflow/lite/micro/examples/hello_world/main.o tensorflow/lite/micro/examples/hello_world/main_functions.o tensorflow/lite/micro/examples/hello_world/model.o tensorflow/lite/micro/examples/hello_world/output_handler.o tensorflow/lite/micro/examples/hello_world/constants.o -Wl,--fatal-warnings -Wl,--gc-sections -lm
```

which errs with:

```
/usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/bin/ld: /usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/lib/thumb/v6-m/nofp/libc.a(lib_a-abort.o): in function `abort':
/build/newlib-CVVEyx/newlib-3.3.0/build/arm-none-eabi/thumb/v6-m/nofp/newlib/libc/stdlib/../../../../../../../../newlib/libc/stdlib/abort.c:59: undefined reference to `_exit'
/usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/bin/ld: /usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/lib/thumb/v6-m/nofp/libc.a(lib_a-exit.o): in function `exit':
/build/newlib-CVVEyx/newlib-3.3.0/build/arm-none-eabi/thumb/v6-m/nofp/newlib/libc/stdlib/../../../../../../../../newlib/libc/stdlib/exit.c:64: undefined reference to `_exit'
/usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/bin/ld: /usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/lib/thumb/v6-m/nofp/libc.a(lib_a-sbrkr.o): in function `_sbrk_r':
/build/newlib-CVVEyx/newlib-3.3.0/build/arm-none-eabi/thumb/v6-m/nofp/newlib/libc/reent/../../../../../../../../newlib/libc/reent/sbrkr.c:51: undefined reference to `_sbrk'
/usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/bin/ld: /usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/lib/thumb/v6-m/nofp/libc.a(lib_a-signalr.o): in function `_kill_r':
/build/newlib-CVVEyx/newlib-3.3.0/build/arm-none-eabi/thumb/v6-m/nofp/newlib/libc/reent/../../../../../../../../newlib/libc/reent/signalr.c:53: undefined reference to `_kill'
/usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/bin/ld: /usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/lib/thumb/v6-m/nofp/libc.a(lib_a-signalr.o): in function `_getpid_r':
/build/newlib-CVVEyx/newlib-3.3.0/build/arm-none-eabi/thumb/v6-m/nofp/newlib/libc/reent/../../../../../../../../newlib/libc/reent/signalr.c:83: undefined reference to `_getpid'
/usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/bin/ld: /usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/lib/thumb/v6-m/nofp/libc.a(lib_a-writer.o): in function `_write_r':
/build/newlib-CVVEyx/newlib-3.3.0/build/arm-none-eabi/thumb/v6-m/nofp/newlib/libc/reent/../../../../../../../../newlib/libc/reent/writer.c:49: undefined reference to `_write'
/usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/bin/ld: /usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/lib/thumb/v6-m/nofp/libc.a(lib_a-closer.o): in function `_close_r':
/build/newlib-CVVEyx/newlib-3.3.0/build/arm-none-eabi/thumb/v6-m/nofp/newlib/libc/reent/../../../../../../../../newlib/libc/reent/closer.c:47: undefined reference to `_close'
/usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/bin/ld: /usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/lib/thumb/v6-m/nofp/libc.a(lib_a-fstatr.o): in function `_fstat_r':
/build/newlib-CVVEyx/newlib-3.3.0/build/arm-none-eabi/thumb/v6-m/nofp/newlib/libc/reent/../../../../../../../../newlib/libc/reent/fstatr.c:55: undefined reference to `_fstat'
/usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/bin/ld: /usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/lib/thumb/v6-m/nofp/libc.a(lib_a-isattyr.o): in function `_isatty_r':
/build/newlib-CVVEyx/newlib-3.3.0/build/arm-none-eabi/thumb/v6-m/nofp/newlib/libc/reent/../../../../../../../../newlib/libc/reent/isattyr.c:52: undefined reference to `_isatty'
/usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/bin/ld: /usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/lib/thumb/v6-m/nofp/libc.a(lib_a-lseekr.o): in function `_lseek_r':
/build/newlib-CVVEyx/newlib-3.3.0/build/arm-none-eabi/thumb/v6-m/nofp/newlib/libc/reent/../../../../../../../../newlib/libc/reent/lseekr.c:49: undefined reference to `_lseek'
/usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/bin/ld: /usr/lib/gcc/arm-none-eabi/9.2.1/../../../arm-none-eabi/lib/thumb/v6-m/nofp/libc.a(lib_a-readr.o): in function `_read_r':
/build/newlib-CVVEyx/newlib-3.3.0/build/arm-none-eabi/thumb/v6-m/nofp/newlib/libc/reent/../../../../../../../../newlib/libc/reent/readr.c:49: undefined reference to `_read'
collect2: error: ld returned 1 exit status
make: *** [Makefile:42: hello_world] Error 1
```
"
46553,set_weights() for tf.keras.layers.Layer not working for type string.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Cataline 10.15.7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 2.4.0
- Python version: 3.7.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): clang 11.0.3
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
When trying to `set_weights()` for a layer where the weights are strings the data type `string` is not understood. See the standalone code below.  

**Describe the expected behavior**
The weights should be updated with no error.

**Standalone code to reproduce the issue**
```
import tensorflow as tf


def initializer(shape, dtype=None):
    return tf.reshape(tf.constant([str(x) for x in range(shape[0])]), shape)


class CustomLayer(tf.keras.layers.Layer):

    def __init__(self, length=10, **kwargs):
        super(CustomLayer, self).__init__(**kwargs)
        self.length = length

    def build(self, input_shape=None):
        self.keys = self.add_weight(shape=(self.length,),
                                    name='keys',
                                    initializer=initializer,
                                    dtype=tf.string,
                                    trainable=False)

        self.built = True

    def call(self, x):
        return self.keys

    def get_config(self):
        config = super(CustomLayer, self).get_config()
        config.update({'length': self.length})
        return config


inputs = tf.keras.layers.Input(shape=())
outputs = CustomLayer(name='lookup')(inputs)
model = tf.keras.Model(inputs, outputs)
model.compile()

model.get_layer('lookup').set_weights(model.get_layer('lookup').get_weights())
```

**Other info / logs** 
```
Traceback (most recent call last):
  File ""example.py"", line 37, in <module>
    model.get_layer('lookup').set_weights(model.get_layer('lookup').get_weights())
  File ""/Users/mans.bermell/.pyenv/versions/tensorflow2.4/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1877, in set_weights
    backend.batch_set_value(weight_value_tuples)
  File ""/Users/mans.bermell/.pyenv/versions/tensorflow2.4/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py"", line 201, in wrapper
    return target(*args, **kwargs)
  File ""/Users/mans.bermell/.pyenv/versions/tensorflow2.4/lib/python3.7/site-packages/tensorflow/python/keras/backend.py"", line 3706, in batch_set_value
    x.assign(np.asarray(value, dtype=dtype(x)))
  File ""/Users/mans.bermell/.pyenv/versions/tensorflow2.4/lib/python3.7/site-packages/numpy/core/_asarray.py"", line 83, in asarray
    return array(a, dtype, copy=False, order=order)
TypeError: data type 'string' not understood
```
"
46552,Source code for tf.signal.rfft,"Hi,

I am trying to convert tf.signal.fft into c code for my project. I have gone through the below link to understand the functionality

https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/ops/signal/fft_ops.py#L115-L141

I could not find the complete source to understand the  tf.signal.fft  API.

The source code found is returning  fft_fn(input_tensor, fft_length, Tcomplex=complex_dtype, name=name) but no complete steps.

Can someone please help to find the definition of the above function  fft_fn(..)

or

if there is any c code for this function, please provide the link or attachment.

Regards,
Yugesh.



"
46549,Build failure when using non-system gcc with later glibc,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version: HEAD
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: n/a
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 10.2.0
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a



**Describe the problem**

Build using gcc 10.2.0 compiled on system with a later version of glibc than installed on system.
The tool flatc which is compiled during the build links with the glibc from gcc 10.2.0.
When flatc is executed later in the build, the environment is cleared out and it is not possible to set LD_LIBRARY_PATH so that it would load the correct version of glibc.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

System installed libstdc++.so.6 is 3.4.25
gcc 10.2.0 built with glibc 2.28 and libstdc++.so.6 3.4.28 installed to /usr/local
Build command line:
$ TF_MKL_ROOT=~builder/1/built_tarballs/onednn/ bazel build --config=noaws --config=nogcp --config=nonccl --config=mkl_aarch64 --action_env=TF_MKL_ROOT=/home/builder/1/built_tarballs/onednn/ --action_env=LD_LIBRARY_PATH=/usr/local/lib64 --host_action_env=LD_LIBRARY_PATH=/usr/local/lib64 //tensorflow/tools/pip_package:build_pip_package --verbose_failures

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Build fails with the below messages:
ERROR: /home/debian/src/tensorflow_1dnn-git/tensorflow/lite/python/BUILD:11:22: Generating flatbuffer files for <source file tensorflow/lite/schema/schema.fbs>: failed (Exit 1): flatc failed: error executing command 
  (cd /home/debian/.cache/bazel/_bazel_debian/0988af24c3a1bb0051e8f606aa777b9e/execroot/org_tensorflow && \
  exec env - \
  bazel-out/host/bin/external/flatbuffers/flatc --python -o bazel-out/aarch64-opt/bin/tensorflow/lite/python/schema_py_srcs_no_include_all -I ./ -I bazel-out/aarch64-opt/bin -I bazel-out/aarch64-opt/bin --no-includes --no-union-value-namespacing --gen-object-api tensorflow/lite/schema/schema.fbs)
Execution platform: @local_execution_config_platform//:platform
bazel-out/host/bin/external/flatbuffers/flatc: /lib/aarch64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.26' not found (required by bazel-out/host/bin/external/flatbuffers/flatc)
Target //tensorflow/tools/pip_package:build_pip_package failed to build
"
46548,"Compared to TF1.15, do TF2 have some speedup  in CPU inference?","I find this is not a good Stackoverflow question.

So I post it here. Thank you for your time."
46547, An error occurs when inferring by loaded pretrained model,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Google colab

**Describe the current behavior**
- Error occurs when inferring from loaded model (before saving, it is successfully inferred from the same input)
- same happens even if the input signature is redefined when saving the model 

**Describe the expected behavior**
- Must be inferable from the loaded model

**Standalone code to reproduce the issue**
- here is code : https://colab.research.google.com/drive/1CJyLvind12Df-WFst4UTPMk0e5C996Tq?usp=sharing
- Links to the data are also in colab 

Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
- here  is error message
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-14-13d7f1beda6b> in <module>()
      1 loaded_bert_model = tf.saved_model.load(DATA_OUT_PATH+'/bert/saved')
      2 loaded_electra_model = tf.saved_model.load(DATA_OUT_PATH+""/electra/saved"")
----> 3 logits = loaded_bert_model(input_encodings_bert)['logits']
      4 print(""bert_saved"",logits)
      5 logits = loaded_electra_model(input_encodings_electra)['logits']

9 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/function_deserialization.py in restored_function_body(*args, **kwargs)
    271         .format(_pretty_format_positional(args), kwargs,
    272                 len(saved_function.concrete_functions),
--> 273                 ""\n\n"".join(signature_descriptions)))
    274 
    275   concrete_function_objects = []

ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (9 total):
    * {'input_ids': <tf.Tensor 'input_ids_1:0' shape=(1, 14) dtype=int32>, 'attention_mask': <tf.Tensor 'input_ids:0' shape=(1, 14) dtype=int32>}
    * None
    * None
    * None
    * None
    * None
    * None
    * None
    * False
  Keyword arguments: {}

Expected these arguments to match one of the following 2 option(s):

Option 1:
  Positional arguments (9 total):
    * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids/input_ids')}
    * None
    * None
    * None
    * None
    * None
    * None
    * None
    * True
  Keyword arguments: {}

Option 2:
  Positional arguments (9 total):
    * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids/input_ids')}
    * None
    * None
    * None
    * None
    * None
    * None
    * None
    * False
  Keyword arguments: {}
```
"
46546,TensorFlow Lite  support multi scale input?,"Did TensorFlow Lite  support multi scale input?
In same case,i need dynamic input shapes;

for examples:
the tensorflow lite mode input shape is  1x3x360x640

but I can not input 1x3x720x1080 .
(without fixed size, FC,all ops are conv).
caffe ,ncnn,TNN model, i can change the protext  to support multi scale input.

"
46540,tf.nn.convolution crashes Floating-point exception when filters has 0 in shape,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.1.0
- Python version:3.6.9
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A



**Describe the current behavior**
`tf.nn.convolution` crashes (Floating-point exception) when `filters` has 0 in shape

error message:
~~~
[1]    10129 floating point exception (core dumped)  python
~~~
**Describe the expected behavior**
expect no crash
**Standalone code to reproduce the issue**
~~~
import numpy as np
import tensorflow as tf
tf.nn.convolution(input=np.ones((1,1,1,1)), filters=np.ones((1,0,1,1)))
~~~
"
46539,"tf.keras.applications.densenet.preprocess_input does not work for data_format=""channels_first"" for symbolic tensors","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- TensorFlow installed from (source or binary): colab
- TensorFlow version (use command below): 2.4.0, v2.4.0-0-g582c8d236cb
- Python version: 3.6.9

**Describe the current behavior**
Running `tf.keras.applications.densenet.preprocess_input` on a `data_format=""channels_first""` symbolic tensor raises an Exception. This is caused by the input transposition not being applied if the `mode` parameter to [_preprocess_symbolic_input](https://github.com/tensorflow/tensorflow/blob/7a49c87f9f56a7fc169669cfe97728859798967c/tensorflow/python/keras/applications/imagenet_utils.py#L242) is set to ""torch"" (as is the case for densenet preprocessing).

See the relevant lines here:
https://github.com/tensorflow/tensorflow/blob/7a49c87f9f56a7fc169669cfe97728859798967c/tensorflow/python/keras/applications/imagenet_utils.py#L262-L281

This is not caught by the unit tests as only the default `mode=""caffe""` is tested.

The equivalent numpy function `_preprocess_numpy_input` handles this correctly (treating the input differently depending on `data_format` for all modes

**Describe the expected behavior**
Preprocessing should work for `data_format=""channels_first""`

**Standalone code to reproduce the issue**
Colab notebook with minimum example:
https://colab.research.google.com/drive/1THrNYTAAzPxw9135h-sFt-LxMz_7SEeQ?usp=sharing

"
46538,Add Windows build to nightly libtensorflow C packages,"The [C API page](https://www.tensorflow.org/install/lang_c#nightly_libtensorflow_c_packages) says that ""libtensorflow packages are built nightly and uploaded to GCS for all supported platforms"" but the [libtensorflow-nightly GCS bucket](https://storage.googleapis.com/libtensorflow-nightly) does not have builds for Windows. The README's list of [offical builds](https://github.com/tensorflow/tensorflow#official-builds) also indicates that Windows nightlies should be available.

Please make Windows libtensorflow nightlies available for download."
46537,libtensorflow-gpu-windows-x86_64-2.3.1 does not support GPUs with compute capability 5.0,"TensorFlow 2.3.1 crashes on my GPU with compute capability (CC) 5.0 with the error ""no kernel image is available for execution on the device"". I used [cuobjdump](https://docs.nvidia.com/cuda/cuda-binary-utilities/index.html#cuobjdump) to inspect tensorflow.dll to see what binary and PTX code was included. I found binary code for CC 3.5, 3.7, 5.2, 6.0, 6.1, and 7.0 as well as PTX code for CC 7.0.

PTX code is forward-compatible, but 7.0 PTX cannot run on a 5.0 GPU. Binary code is forward-compatible but only for minor version updates. This means that neither the 3.7 nor the 5.2 binary can run on a 5.0 GPU. In fact, the current configuration means that TensorFlow 2.3.1 can run on any GPU with CC 3.5 and up *except* for CC 5.0.

I suggest building for CC 5.0 instead of CC 5.2 so that TensorFlow 2.3.X can run on any GPU with CC 3.5 and up."
46536,Example code bug in documentation related to tf.data.Dataset.interleave,"## URL with the issue:
https://www.tensorflow.org/guide/data_performance

## Description of issue:
The following has been tested with TF version v2.4.0-0-g582c8d236cb.

On the above-mentioned documentation page, it is defined:

`def __new__(cls, num_samples=3):`

which is ok up to some point, but results in a bug for the variant using `interleave`, since then internally a tensor is provided as second argument, so that `num_samples` won't be 3. In fact, it alternates between 0 and 1 in `_generator`. One can easily check this out by using the `print` function - both in `__new__` and in `_generator`.

Assuming the person writing this part of the documentation wasn't aware of this and this problem is not version specific, it is very likely that the timing results are wrong accordingly when using `interleave`.

It is also worth mentioning that when using `tf.data.Dataset.range(2).interleave`, the generated data in total is doubled in size (**if fixing the above-mentioned bug**), so that the timing results cannot be compared 1:1. When using `tf.data.Dataset.range(2).interleave`, the timing results should be divided by two to allow for a fair comparison, which isn't mentioned in the documentation.

See my gist [here](https://gist.github.com/padoremu/de948c6133c365bb3249c77b172aa4fd)."
46535,AssertionError: Nesting violated for default stack of <class 'tensorflow.python.framework.ops.Graph'> objects,"I want to make a prediction(do beam search) after every save of ckpt using Estimator for saving best ckpt. So I add a saving_listeners(CheckpointSaverListener) to estimator.train. But every time I raise a mistake. 

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macos
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.15
- Python version: 3.6

Here is my CheckpointSaverListener code.
```
class SaveBestCheckpointSaverListener(tf.train.CheckpointSaverListener):
    def __init__(self, save_checkpoints_steps, keep_checkpoint_max, output_dir):
        self.best_ckpt = None
        self.best_path_match = None
        self.best_global_step_value = None
        self.save_checkpoints_steps = save_checkpoints_steps
        self.keep_checkpoint_max = keep_checkpoint_max
        self.output_dir = output_dir

    def begin(self):
        # You can add ops to the graph here.
        print('Starting the session.')
        # self.your_tensor = ...

    def before_save(self, session, global_step_value):
        print('About to write a checkpoint')

    def after_save(self, session, global_step_value):
        print('Done writing checkpoint at {}.'.format(global_step_value))
        global_step_value = int(global_step_value)
        if global_step_value == 0:
            return
        current_ckpt = 'model.ckpt-{}'.format(global_step_value)
       # do beam search prediction
        current_path_match = do_predict()
        print('current result: {} : {}'.format(current_ckpt, current_path_match))
        if not self.best_ckpt:
            self.best_ckpt = current_ckpt
            self.best_path_match = current_path_match
            self.best_global_step_value = str(global_step_value)
        else:
            if current_path_match > self.best_path_match:
                self.best_ckpt = current_ckpt
                self.best_path_match = current_path_match
                self.best_global_step_value = str(global_step_value)
                print('Saved best ckpt with path_match {}'.format(current_path_match))

    def end(self, session, global_step_value):
        print('best model {}, remove useless models.'.format(self.best_ckpt))
        # for f in os.listdir(self.output_dir):
        #     file = os.path.join(self.output_dir, f)
        #     if os.path.isfile(file) and f.startswith('model'):
        #         model_global_step = f[f.index('-') + 1:f.rindex('.')]
        #         if model_global_step != self.best_global_step_value:
        #             os.remove(file)
        #             print('remove {}'.format(file))

```
After all ckpts were saved, training process will report errors. Here are errors.
```
Traceback (most recent call last):
  File ""run_classifier_nsp_multitask_typeEmb.py"", line 797, in <module>
    tf.app.run()
  File ""/Users/bytedance/opt/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/bytedance/opt/anaconda3/lib/python3.6/site-packages/absl/app.py"", line 303, in run
    _run_main(main, args)
  File ""/Users/bytedance/opt/anaconda3/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""run_classifier_nsp_multitask_typeEmb.py"", line 767, in main
    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.num_train_steps, hooks=hooks, saving_listeners=[listener])
  File ""/Users/bytedance/opt/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 370, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/Users/bytedance/opt/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1161, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/Users/bytedance/opt/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1195, in _train_model_default
    saving_listeners)
  File ""/Users/bytedance/opt/anaconda3/lib/python3.6/contextlib.py"", line 88, in __exit__
    next(self.gen)
  File ""/Users/bytedance/opt/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 5480, in get_controller
    yield g
  File ""/Users/bytedance/opt/anaconda3/lib/python3.6/contextlib.py"", line 88, in __exit__
    next(self.gen)
  File ""/Users/bytedance/opt/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 5295, in get_controller
    type(default))
AssertionError: Nesting violated for default stack of <class 'tensorflow.python.framework.ops.Graph'> objects
```
"
46534,Segfault upon importing tensorflow,"Linux Mint 20
Python 3.8.5
No virtual environment
i7 870 (old processor)
pip3 install tensorflow, also fails with tf-nightly
TensorFlow version 2.4.0
GTX 1060 3GB

""import tensorflow"" caues a segfault"
46533,"Extracting item from a list with tf.function() :  TypeError: list indices must be integers or slices, not Tensor","
**System information**
- Have I written custom code (see below):
OS Platform and Distribution: Linux Ubuntu 18.04.5
Python version: 3.7.4
Tensorflow : 2.4.0


**Describe the current behavior**
I have a list of objects (custom type), I want to extract an object in a specific index from a list. However, when running using tf.function() I'm getting an error that the index is a tensor and it should be an integer or slices : 

    TypeError: list indices must be integers or slices, not Tensor

I know I can use tf.gather but the list can't be converted to a tensor since it includes unsupported types (specifically in my case these are loaded estimators). 

    TypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [<__main__.my_class object at 0x7f36d11b9c88>, 
    <__main__.my_class object at 0x7f36d11b9828>]. Consider casting elements to a supported type.

In addition, I can't find a way to evaluate the index to convert it to a number with the tf.function.. 

**Standalone code to reproduce the issue**

          import tensorflow as tf
          
          class my_class():
              def __init__(self,name):
                  self.name = name #
          x = [my_class('ron'),my_class('john')]
          
          def extract(idx):
              y = x[idx]
              return y
          y = extract(1)
          print(y)
          
          
          @tf.function(input_signature=[tf.TensorSpec(shape=[1], dtype=tf.int32)])
          def extract(idx):
              y = x[idx]
              return y
          
          y = extract(1)
          print(y)

Output: 

    <__main__.my_class object at 0x7f36d1841978>
    ---------------------------------------------------------------------------
    TypeError                                 Traceback (most recent call last)
    <ipython-input-9-1b61ba209201> in <module>()
         18     return y
         19 
    ---> 20 y = extract(1)
         21 print(y)
    
    8 frames
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
        983           except Exception as e:  # pylint:disable=broad-except
        984             if hasattr(e, ""ag_error_metadata""):
    --> 985               raise e.ag_error_metadata.to_exception(e)
        986             else:
        987               raise
    
    TypeError: in user code:
    
        <ipython-input-9-1b61ba209201>:17 extract  *
            y = x[idx]
    
        TypeError: list indices must be integers or slices, not Tensor.

Is there a way to evaluate the index with tf.function()? or some other function to extract the object from the list (it is a list wrapper)?
Thanks you"
46532,mkl_layout_pass_test fails due to optional BFLOAT16 support in MKL/oneDNN,"Using TF 2.4 on a haswell system

**Describe the current behavior**

Running the test //tensorflow/core/common_runtime:mkl_layout_pass_test or //tensorflow/core/kernels:mkl fails at the BFloat16 types with e.g. 
```
tensorflow/core/common_runtime/mkl_layout_pass_test.cc:270: Failure
Expected equality of these values:
  DoMklLayoutOptimizationPass()
    Which is: ""A(BFloat16Input);B(BFloat16Input);C(Conv2D)|A->C;B->C:1""
  ""A("" ""BFloat16Input"" "");B("" ""BFloat16Input"" "");C(_MklConv2D);DMT/_0(Const);"" ""DMT/_1(Const)|A->C;A:control->DMT/_0:control;A:control->"" ""DMT/_1:control;B->C:1;DMT/_0->C:2;DMT/_1->C:3""
    Which is: ""A(BFloat16Input);B(BFloat16Input);C(_MklConv2D);DMT/_0(Const);DMT/_1(Const)|A->C;A:control->DMT/_0:control;A:control->DMT/_1:control;B->C:1;DMT/_0->C:2;DMT/_1->C:3""
[  FAILED  ] MklLayoutPassTest.NodeMerge_Conv2DWithBias_Negative_NoAddBias_DT_BFLOAT16 (1 ms)
```
This is expected on non AVX512 systems as https://github.com/tensorflow/tensorflow/blob/e211aab91939c2666987cc7ccaee29ee0dd2ba41/tensorflow/core/graph/mkl_graph_util.h#L212 checks for runtime support and exits if not found causing the operation to not be changed and failing the test.

**Describe the expected behavior**

Tests pass on any valid system.

**Standalone code to reproduce the issue**

Compile TF with Bazel and `//tensorflow/core/common_runtime:mkl_layout_pass_test` as the target or run that binary manually on a non-AVX-512 system."
46531,TFLite model runs slowly in TV devices when set use NNAPI,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- Yes, all codes were written by myself. 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Win10ãAndroid
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TV devices (Hisense U7F) with mediatek 9652 SOC
- TensorFlow installed from (source or binary):
- Offical
- TensorFlow version (use command below):
- TF2.3ãTF1.14ãTF1.13.1 were tried
- Python version:
- 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the expected behavior**
Aim: Run a MobileNet TFLite model in TV devices with NNAPI in 100ms.

**Describe the current behavior**
I write a MobileNet-v2 custom code and convert it to tflite model. We set the tflite file to Hisense U7F TV devices with mediatek 9652 SOC (containing NNAPI). TV capture the image through camera (android.camera2) and inference with Interpreter but the reference time up to 300ms. It should be mentioned that the mediatek profiler reported that all OPs were run in NNAPI successfully and time consuming in NNAPI was 10ms.
Besides, we tried different TF version and its java denpendencies including 2.3, 1.14, 1.13.1. 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
The tflite model as :
[TFModel-short.zip](https://github.com/tensorflow/tensorflow/files/5834848/TFModel-short.zip)

The core java code as following:
```
                try {
                    Interpreter.Options options = (new Interpreter.Options()).setAllowFp16PrecisionForFp32(true);
                    mTFLite = new Interpreter(loadModelFile(mModelname), options);
                    mTFLite.setUseNNAPI(true);
                } catch (IOException e) {
                    e.printStackTrace();
                }

                float[][][][] firstOutput = new float[1][7][7][34];

                long startTime = System.currentTimeMillis();
                mTFLite.run(byteBuffer,firstOutput);
                long endTime = System.currentTimeMillis();
                inferenceTime = endTime - startTime;

                System.out.println(""Inference Time: ""+inferenceTime+""ms"");
                mTFLite.close();
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
The android Studio log as following:

> 2021-01-19 15:48:50.041 15661-16292/com.example.android_camera2 I/MtkExecutionBuilder: ****************** Profiler Start ******************
> 2021-01-19 15:48:50.041 15661-16292/com.example.android_camera2 I/MtkExecutionBuilder: Execution Step   : 0
> 2021-01-19 15:48:50.041 15661-16292/com.example.android_camera2 I/MtkExecutionBuilder: Execution Result : 1
> 2021-01-19 15:48:50.041 15661-16292/com.example.android_camera2 I/MtkExecutionBuilder: Device Name      : neuron-ann
> 2021-01-19 15:48:50.041 15661-16292/com.example.android_camera2 I/MtkExecutionBuilder: Operations       : CONV:CONV:DEPTHWISE_CONV:CONV:CONV:DEPTHWISE_CONV:CONV:ADD:CONV:DEPTHWISE_CONV:CONV:CONV:DEPTHWISE_CONV:CONV:ADD:CONV:DEPTHWISE_CONV:CONV:ADD:CONV:DEPTHWISE_CONV:CONV:CONV:DEPTHWISE_CONV:CONV:ADD:CONV:DEPTHWISE_CONV:CONV:ADD:CONV:DEPTHWISE_CONV:CONV:ADD:CONV:DEPTHWISE_CONV:CONV:CONV:DEPTHWISE_CONV:CONV:ADD:CONV:DEPTHWISE_CONV:CONV:ADD:CONV:DEPTHWISE_CONV:CONV:CONV:DEPTHWISE_CONV:CONV:ADD:CONV:DEPTHWISE_CONV:CONV:ADD:CONV:DEPTHWISE_CONV:CONV:CONV:DEPTHWISE_CONV:CONV:CONV
> 2021-01-19 15:48:50.041 15661-16292/com.example.android_camera2 I/MtkExecutionBuilder: Spent Time       : 13747 us
> 2021-01-19 15:48:50.041 15661-16292/com.example.android_camera2 I/MtkExecutionBuilder: ****************** Profiler End   ******************
> 2021-01-19 15:48:50.043 15661-15699/com.example.android_camera2 I/System.out: Inference Time: 319ms




"
46530,save custom training loop with keras API (train_step),"Hi, based on the #38103 issue, I'd like to reopen the discussion:

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (Windows/Linux as well)
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): last one, 2.4.0
- Python version: 3.8

**Describe the current behavior**
I'm using the feature: custom training logic with `model.fit` by overriding `model.train_step` (and `model.test_step`). It's working well, except for saving/loading cases, I have the following issue:
When I save my model (`model.save`) with the custom training logic and then I want to load it, the custom training loop is not saved and when I apply a `model.fit` for my loaded model, it comes back to the default one.


**Describe the expected behavior**
I'd expect to save as well the model.train_step (and also `test_step`). Especially with the new 2.4 feature `model.save(save_traces=True)`. Is it possible (and if yes, how) ? If no, is a such feature planned or should I write a feature request ?

**Standalone code to reproduce the issue**
[Gist](https://colab.research.google.com/gist/quetil/51c1b89bddd5e25d896678b87b62712f/save-custom-train_step-in-subclassing-model.ipynb)

Thank you in advance,"
46529,Should pb file match CUDA version?,"
I used tensorflow.git and bazel to build a model. The detail process is

1. git clone tensorflow.git
2. ./configure << tensorflow configure
3. I answered N in every question of configure process including 'Use CUDA'.
4. bazel-build my model to pb file

Then, can I use my model in any device that set CPU or GPU(any CUDA, Cudnn version)?

When I run my pb file, it occurs to fail to make cuFFT batched plan.

As I searched, it was because CUDA version doesn't match, is it right?"
46528,"tflite.Interpreter version 2.5.0 not run on widows 10  , please get simple python code example","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46527,RecvAsync is cancelled error on Ryzen High Performance mode,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 
>No

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
> Windows 10

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
>No

- TensorFlow installed from (source or binary):
>binary

- TensorFlow version (use command below):
>2.4.0

- Python version:
>3.8.7

- Bazel version (if compiling from source):
N/A

- GCC/Compiler version (if compiling from source):
N/A

- CUDA/cuDNN version:
>V11.0.221

- GPU model and memory:
>RTX 3070 FE (VRAM - 8GB, system memory- 32GB)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
>v2.4.0-rc4-71-g582c8d236cb 2.4.0

**Describe the current behavior**

>I am trying to run the sample code [here](https://www.tensorflow.org/tutorials/text/text_classification_rnn). 
1. If the computer is on Ryzen High Performance mode, while executing the statement ""model.fit()"", the code breaks with an error ""RecvAsync is cancelled"" after 2 epochs.  (attached is the screenshot of the error)
error- 
CancelledError:  [_Derived_]RecvAsync is cancelled.
	 [[{{node gradient_tape/sequential/embedding/embedding_lookup/Reshape/_54}}]] [Op:__inference_train_function_22374]

Function call stack:
train_function





2. If the computer is on Power saving mode, the model trains successfully without an error. 
In both, the above cases the CPU, RAM and GPU utilization was below 20%
 
System specifications - 
Ryzen 3700X | 32GB 3000MHz CL15 DDR4 ram | RTX 3070 | Windows 10

**Describe the expected behavior**
The code should run successfully regardless of the Power option selected. Especially in Ryzen High Performance mode, the code should run faster and without any issues. 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

I am trying to run the code from the tensorflow website - 
https://www.tensorflow.org/tutorials/text/text_classification_rnn


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.


![system_sw_info](https://user-images.githubusercontent.com/25884862/104998987-20db6780-5a52-11eb-835e-5f25b8a97cdc.png)
![tensorflow_error](https://user-images.githubusercontent.com/25884862/105003986-5a63a100-5a59-11eb-93b6-fc6203bdc681.png)
"
46526,CrossShardOptimizer must be used for model training on TPUs,"Running [the example](https://github.com/EleutherAI/gpt-neo) on a Colab TPU results in the following error:
```
File ""main.py"", line 256, in <module>
    main(args)
  File ""main.py"", line 230, in main
    estimator.train(input_fn=partial(input_fn, global_step=current_step, eval=False), max_steps=next_checkpoint)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3130, in train
    rendezvous.raise_errors()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors
    six.reraise(typ, value, traceback)
  File ""/usr/local/lib/python3.6/dist-packages/six.py"", line 703, in reraise
    raise value
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3125, in train
    saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 349, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1175, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1204, in _train_model_default
    self.config)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 2962, in _call_model_fn
    config)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1163, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3386, in _model_fn
    _validate_tpu_training_graph(ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3817, in _validate_tpu_training_graph
    'CrossShardOptimizer must be used for model training on TPUs.')
ValueError: CrossShardOptimizer must be used for model training on TPUs.
```"
46524,Tflite own trained model is not running," I am using tflite object detection android sample the project is running perfectly with default model but when i change my custom object trained model and build on phone then application crushed. Is there are some steps to change model ? I just imported my tflite model in asset folder and changed name in DetectorActivity.java and DetectorTest.java. Is there any more step i need to do please let me know.
 
 Thank you"
46523,Flow,https://github.com/tensorflow/tensorflow/blob/582c8d236cb079023657287c318ff26adb239002/tensorflow/python/data/experimental/ops/data_service_ops.py#L301-L483
46522,BatchNormalization inference equation in doc is incorrect,"
## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization

## Description of issue (what needs changing):

This documentation states the following:

> During inference (i.e. when using evaluate() or predict() or when calling the layer/model with the argument training=False (which is the default), the layer normalizes its output using a moving average of the mean and standard deviation of the batches it has seen during training. That is to say, it returns (batch - self.moving_mean) / (self.moving_var + epsilon) * gamma + beta.

This equation is incorrect, testing with the source code shows it gives the wrong output.  The correct equation that gives the right output (and matches the correct equation from literature) is:

`(batch - self.moving_mean) / sqrt(self.moving_var + epsilon) * gamma + beta.`

I.e., it is missing square-root.

Further, for more clarity (to avoid confusion for some) it would be better to write it as:

`gamma*(batch - self.moving_mean) / sqrt(self.moving_var + epsilon) + beta.`
"
46521,partially convert_variables_to_constants use variable_names_whitelist/variable_names_blacklist will make the save/restore op disappeared and can't restore after the conversion,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux CentOS 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not use Mobile device
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7
- Bazel version (if compiling from source): Not use Bazel
- GCC/Compiler version (if compiling from source): GCC7.4
- CUDA/cuDNN version: Not use
- GPU model and memory: Not use GPU

**Describe the current behavior**
code is 
'''

builder = tf.compat.v1.saved_model.Builder('converted')

with tf.compat.v1.Session(graph=tf.Graph()) as sess:

    loaded = tf.compat.v1.saved_model.loader.load(sess, [""serve""], model_dir)

    builder.add_meta_graph_and_variables(sess,[""serve""], signature_def_map=loaded.signature_def)

    graph_def = convert_variables_to_constants(

        sess,

        graph_def,

        output_node_names=output_node_list,

        variable_names_blacklist=embedding_var_list,

       #variable_names_whitelist=freeze_var_list)

with tf.compat.v1.Session(graph=tf.Graph()) as sess:

    tf.import_graph_def(graph_def, name="""")

    output_tensors = prepare_output_tensors(sess)

    input_tensors = prepare_input_tensors(sess)

    sigs = {}

    sigs['eval'] = tf.compat.v1.saved_model.signature_def_utils.predict_signature_def(output_tensors, input_tensors)

    builder.add_meta_graph(['eval'], signature_def_map=sigs)
'''
the reason to use variable_name_blacklist is because the embedding variables is larger than the limit 2GB to freeze into the inference proto buffer, so i want to partially keep them as variables and freeze other nodes, then optimize for performance improvement. 
but after i get the graph_def and add the meta graph to builder, i got a new saved model, when i loading it:
'''
with tf.compat.v1.Session(graph=tf.Graph()) as sess:

    model = tf.compat.v1.saved_model.loader.load(sess, [""eval""], model_dir)

'''
it comes out :
INFO: tensorflow : Saver not created because there are no variables in the graph to restore.

**Describe the expected behavior**
i also check the graph def after convert_variables_to_constants , i found the save/resore nodes all disappeared including the kept variables.

"
46520,dso_loader.cc Could not load dynamic library 'cupti64_110.dll'; dlerror: cupti64_110.dll not found,"**System information**
- Windows 10 - 20H2 Build 19042.746
- TensorFlow installed from (source or binary): Nightly
- TensorFlow version: 
- tensorboard==2.4.1
tensorboard-plugin-wit==1.7.0
tensorflow-estimator==2.4.0
tensorflow-gpu==2.4.0
tensorflow-hub==0.11.0
tf-estimator-nightly==2.5.0.dev2021011401
tf-nightly-gpu==2.5.0.dev20210114

- Python version: 3.8.5
- Installed using virtualenv? conda - with pip installs on top
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: 11.1/8.0.5.39 for CUDA 11.1
- GPU model and memory: RTX 3090 - 24GB



**Describe the problem**
Running through a search for the best hyper params. This means I am looping through these actions in the same process - creating ANN(LSTM), compiling , training, validating an ANN, then changing the hypers and running again etc. This used to work on TF2.1 with my Super 2080, now I have changed to TF 2.5 as it supports the 3090. The system crashes on this line with no traceback, and no exception thrown.

training_history = self.model.fit (ann_training_input_batched_scaled_3d, training_output,
                                               epochs = regressor_number_epochs, batch_size = regressor_batch_size,
                                               callbacks = callbks,
                                               verbose=1,
                                               validation_data = (ann_validation_input_batched_scaled_3d, valoutput))

This is the second iteration, so the second time this gets executed (but its with a new ANN so its the the first time with a new ANN, second time in the process). Note that if I use a CPU instead of a GPU I get the same errors about CUPTI, but it doesnt crash so quickly, it dos a few more iterations then crashes with no exception/logging etc.

Before it dies, I see these warnings and finally errors

ensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cupti64_110.dll'; dlerror: cupti64_110.dll not found
2021-01-18 17:40:51.410137: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cupti.dll'; dlerror: cupti.dll not found
2021-01-18 17:40:51.410283: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1644] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
2021-01-18 17:40:51.410657: I tensorflow/core/profiler/lib/profiler_session.cc:158] Profiler session tear down.
2021-01-18 17:40:51.410812: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1735] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.


**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
I dont understand how the process is dying, and I have the offending code wrapped in a try block, but no exception is being thrown. 

Also how do I resolve this dll CUPTI warning ? It should be using cupti64_2020.2.1.dll. It works for the first iteration.

Marcus"
46518,Very slow tf.TensorArray and a possible bug when used with range(),"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code : Yes
- OS Platform and Distribution: macOS Big Sur and Ubuntu 18 (Google colab)
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4
- Python version: 3.8.7 on macOS and 3.6 on google colab

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I created a few functions to benchmark `tf.TensorArray.write()` operations with python lists and it takes ages in comparison when writing 1000+ numbers. Here's a colab [notebook](https://colab.research.google.com/drive/1CySveLoSpbXB5uNWVcCB7ITlTN9dlYDA?usp=sharing) and the results are shown below:

    from time import perf_counter
    import tensorflow as tf
    
    
    def list_appends(n):
        l = []
        for i in range(n):
            l.append(i)
    
    def list_to_tensor(n):
        l = []
        for i in range(n):
            l.append(i)
        l = tf.convert_to_tensor(l)
        return 
    
    
    def t_array(n):
        t = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)
        for i in range(n):
            t = t.write(i, i)
        t = t.stack()
        return 
    
    
    @tf.function
    def t_array_tff(n):
        t = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)
        for i in range(n):
            t = t.write(i, i)
        t = t.stack()
        return 
    
    
    @tf.function
    def t_array_tff_tfr(n):
        t = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)
        for i in tf.range(n):
            t = t.write(i, i)
        t = t.stack()
        return 

**Tests:**

    n = 100000

    %timeit list_appends(n)

100 loops, best of 3: 9.09 ms per loop

    %timeit list_to_tensor(n)  # Same function + converts the resulting list to tf.Tensor

The slowest run took 4.30 times longer than the fastest. This could mean that an intermediate result is being cached.
10 loops, best of 3: 36 ms per loop

    %timeit t_array(n)  #  TensorArray

1 loop, best of 3: 3.25 s per loop

    %timeit t_array_tff_tfr(n)  # TensorArray + tf.function + tf.range()

1 loop, best of 3: 1.53 s per loop


The following gets stuck until I kill the code, throws a lot of errors and I'm not sure whether this is a normal behavior.

    %timeit t_array_tff(n)  # TensorArray + tf.function + range()

Error:

    ERROR:root:Internal Python error in the inspect module.
    Below is the traceback from this internal error.
    Traceback (most recent call last):
      File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
        exec(code_obj, self.user_global_ns, self.user_ns)
      File ""<ipython-input-8-2ea8237511a6>"", line 1, in <module>
        get_ipython().magic('timeit t_array_tff(n)  # TensorArray + tf.function + range()')
      File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2160, in magic
        return self.run_line_magic(magic_name, magic_arg_s)
      File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2081, in run_line_magic
        result = fn(*args,**kwargs)
      File ""<decorator-gen-59>"", line 2, in timeit
      File ""/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py"", line 188, in <lambda>
        call = lambda f, *a, **k: f(*a, **k)
      File ""/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py"", line 1057, in timeit
        time_number = timer.timeit(number)
      File ""/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py"", line 139, in timeit
        timing = self.inner(it, self.timer)
      File ""<magic-timeit>"", line 1, in inner
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 828, in __call__
        result = self._call(*args, **kwds)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 871, in _call
        self._initialize(args, kwds, add_initializers_to=initializers)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 726, in _initialize
        *args, **kwds))
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2969, in _get_concrete_function_internal_garbage_collected
        graph_function, _ = self._maybe_define_function(args, kwargs)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3361, in _maybe_define_function
        graph_function = self._create_graph_function(args, kwargs)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3206, in _create_graph_function
        capture_by_value=self._capture_by_value),
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 990, in func_graph_from_py_func
        func_outputs = python_func(*func_args, **func_kwargs)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 634, in wrapped_fn
        out = weak_wrapped_fn().__wrapped__(*args, **kwds)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 973, in wrapper
        user_requested=True,
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py"", line 459, in converted_call
        result = converted_f(*effective_args, **kwargs)
      File ""/tmp/tmp1hatjldp.py"", line 24, in tf__t_array_tff
        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(n),), None, fscope), None, loop_body, get_state, set_state, ('t',), {'iterate_names': 'i'})
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py"", line 444, in for_stmt
        _py_for_stmt(iter_, extra_test, body, None, None)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py"", line 473, in _py_for_stmt
        body(target)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py"", line 459, in protected_body
        original_body(protected_iter)
      File ""/tmp/tmp1hatjldp.py"", line 22, in loop_body
        t = ag__.converted_call(ag__.ld(t).write, (ag__.ld(i), ag__.ld(i)), None, fscope)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py"", line 350, in converted_call
        return _call_unconverted(f, args, kwargs, options, False)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py"", line 479, in _call_unconverted
        return f(*args)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py"", line 247, in wrapped
        return _add_should_use_warning(fn(*args, **kwargs),
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py"", line 1159, in write
        return self._implementation.write(index, value, name=name)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py"", line 543, in write
        name=name)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/list_ops.py"", line 202, in tensor_list_set_item
        index >= input_list_size,
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 4937, in less_equal
        ""LessEqual"", x=x, y=y, name=name)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 522, in _apply_op_helper
        preferred_dtype=default_dtype)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py"", line 163, in wrapped
        return func(*args, **kwargs)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1540, in convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py"", line 52, in _default_conversion_function
        return constant_op.constant(value, dtype, name=name)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py"", line 265, in constant
        allow_broadcast=True)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py"", line 287, in _constant_impl
        ""Const"", [], [dtype_value.type], attrs=attrs, name=name).outputs[0]
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 592, in _create_op_internal
        compute_device)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 3536, in _create_op_internal
        op_def=op_def)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 2027, in __init__
        output_type = pywrap_tf_session.TF_OperationOutputType(tf_output)
    KeyboardInterrupt
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 1823, in showtraceback
        stb = value._render_traceback_()
    AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py"", line 1132, in get_records
        return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
      File ""/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py"", line 313, in wrapped
        return f(*args, **kwargs)
      File ""/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py"", line 358, in _fixed_getinnerframes
        records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
      File ""/usr/lib/python3.6/inspect.py"", line 1490, in getinnerframes
        frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
      File ""/usr/lib/python3.6/inspect.py"", line 1452, in getframeinfo
        lines, lnum = findsource(frame)
      File ""/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py"", line 170, in findsource
        file = getsourcefile(object) or getfile(object)
      File ""/usr/lib/python3.6/inspect.py"", line 696, in getsourcefile
        if getattr(getmodule(object, filename), '__loader__', None) is not None:
      File ""/usr/lib/python3.6/inspect.py"", line 732, in getmodule
        for modname, module in list(sys.modules.items()):
    KeyboardInterrupt
    ---------------------


**Describe the expected behavior**

is this normal behavior? I was expecting better performance specially when used with `tf.function` but it's either not a proper use case or an issue.

**Standalone code to reproduce the issue**
Included in the demonstration above.

Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46516,TensorFlow 2.4.0 core dumped issue on Ubuntu 16.04,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 LTS
- TensorFlow installed from (source or binary): installed from pip, with this version: tensorflow-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7 MB)
- TensorFlow version: 2.4.0
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: virtualenv
- CUDA/cuDNN version:
- GPU model and memory: No GPU



**Describe the problem**
After installation exactly following the official guideline at: https://www.tensorflow.org/install/pip

(venv) $ python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""
Illegal instruction (core dumped)

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Exactly the same as the guideline listed above, namely
$ python3 -m venv --system-site-packages ./venv
$ source ./venv/bin/activate  # sh, bash, or zsh
(venv) $ pip install --upgrade pip
(venv) $ pip install --upgrade tensorflow

**Any other info / logs**
I also did the installations with tensorflow==1.15 and tf-nightly. Both are working fine without the ""core dumped"" issue, however, I would really like to use the stable TensorFlow version 2.4.0.

Thank you very much for your time!
"
46515,Tensorflow 2.4 about 10% slower than 2.3 for training RNN,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version (use command below): difference between 2.3 and 2.4
- Python version: 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

In TensorFlow 2.4, a basic RNN model runs about 10% slower than the same model in TensorFlow 2.3. This appears on both the CPU and GPU. I've created Colab notebooks to demonstrate the issue.

The step time reported by the progress bar also appears longer (and when I did some of my own timing, I also saw the step as longer), so I don't think it has to do with callbacks or any sort of overhead outside the step function.

**Describe the expected behavior**

I would expect them to be the same, if not better in 2.4 (since it has newer CUDA, etc.).

I know that TensorFlow 2.4 no longer has XLA enabled by default. I tried enabling it on my local machine, and found that it didn't help (in fact it made things slower in TF 2.4). Furthermore, if I enable it on Colab with `os.environ[""TF_XLA_FLAGS""] = ""--tf_xla_auto_jit=2""` I see slower speeds on GPU for both 2.3 and 2.4. So I don't think that's the problem. (Also, the fact that there's a slowdown on CPU suggests it's not an XLA thing.)

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

TF 2.3: https://colab.research.google.com/drive/1xnfP17Bzan7-ICI_JtMfiEdTvgwrLoEz?usp=sharing
TF 2.4: https://colab.research.google.com/drive/17rccQnDvLr4mAiGmAoJyK7t0hlrEpBoV?usp=sharing"
46514,Unable to selectively build TensorFlow Lite with Docker,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Big Sur 11.1
- TensorFlow installed from (source or binary): source
- TensorFlow version: master

**Describe the problem**
Unable to build custom tflite AAR packages using Docker.

My goal is to build a custom AAR for Select Tensorflow Ops based on a tflite model containing some of the select tf ops. Using the AAR hosted at JCenter is not an option as it is too big for the project. I've tried both
- Running the [script](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/build_aar_with_docker.sh) that does building inside docker itself
- Manually running the [script that builds the aars](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/build_aar.sh) from inside the docker

Both failed at exactly the same place during building `tensorflow-lite-select-tf-ops` stage with `ERROR: /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/aws/BUILD.bazel:12:11: C++ compilation of rule '@aws//:aws' failed (Exit 4)`.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
1. Built and ran the tflite-docker container following instructions from [here](https://www.tensorflow.org/lite/guide/build_android#set_up_build_environment_using_docker). First downloaded dockerfile from this place and then ran
```
docker build . -t tflite-builder -f tflite-android.Dockerfile
docker run -it -v $PWD:/host_dir tflite-builder bash
android update sdk --no-ui -a --filter tools,platform-tools,android-${ANDROID_API_LEVEL},build-tools-${ANDROID_BUILD_TOOLS_VERSION}

sudo apt install curl gnupg
curl -fsSL https://bazel.build/bazel-release.pub.gpg | gpg --dearmor > bazel.gpg
sudo mv bazel.gpg /etc/apt/trusted.gpg.d/
echo ""deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8"" | sudo tee /etc/apt/sources.list.d/bazel.list
sudo apt update && sudo apt install bazel
lsb_release -a
sudo apt install openjdk-11-jdk
```
2. From outside the docker ran the script that is supposed to build custom packages based on provided tflite models as per [instructions](https://www.tensorflow.org/lite/guide/reduce_binary_size#build_aar_files_for_android_project_2)

```
curl -o build_aar_with_docker.sh \
  https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/lite/tools/build_aar_with_docker.sh &&
chmod +x build_aar_with_docker.sh
sh build_aar_with_docker.sh \
  --input_models=$PWD/reduce_all_tf_ops.lite, \
  --target_archs=x86,x86_64,arm64-v8a,armeabi-v7a \
  --checkpoint=master
```

The model reproducing the issue is attached, it's build from this function:
```
def reduce_all(array):
    return tf.cast(tf.reduce_all(tf.cast(x, tf.bool)), tf.int32)
```
[reduce_all_tf_ops.tflite.zip](https://github.com/tensorflow/tensorflow/files/5831835/reduce_all_tf_ops.tflite.zip)

The same failure happened with other models containing other different tf ops, so the issue doesn't seem to be related to the models used.

**Failure logs**
```
...*GIT UPDATES*...
Your branch is up to date with 'origin/master'.
Extracting Bazel installation...
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=80
INFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /tensorflow_src/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env ANDROID_NDK_HOME=/android/ndk --action_env ANDROID_NDK_API_LEVEL=18 --action_env ANDROID_BUILD_TOOLS_VERSION=28.0.0 --action_env ANDROID_SDK_API_LEVEL=23 --action_env ANDROID_SDK_HOME=/android/sdk --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /tensorflow_src/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /tensorflow_src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /tensorflow_src/.bazelrc: --define=with_xla_support=true
INFO: Found applicable config definition build:linux in file /tensorflow_src/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /tensorflow_src/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Repository io_bazel_rules_docker instantiated at:
  /tensorflow_src/WORKSPACE:16:10: in <toplevel>
  /tensorflow_src/tensorflow/workspace0.bzl:65:34: in workspace
  /Users/irina/Feebris/tflite-docker/bazel-build-cache/cache/43801f1e35f242fb634ebbc6079cf6c5/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories
Repository rule git_repository defined at:
  /Users/irina/Feebris/tflite-docker/bazel-build-cache/cache/43801f1e35f242fb634ebbc6079cf6c5/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>
INFO: Analyzed target //tmp:tensorflow-lite (108 packages loaded, 8156 targets configured).
INFO: Found 1 target...
Target //tmp:tensorflow-lite up-to-date:
  bazel-bin/tmp/tensorflow-lite.aar
INFO: Elapsed time: 5603.110s, Critical Path: 382.75s
INFO: 1724 processes: 214 internal, 1510 local.
INFO: Build completed successfully, 1724 total actions
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=80
INFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /tensorflow_src/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env ANDROID_NDK_HOME=/android/ndk --action_env ANDROID_NDK_API_LEVEL=18 --action_env ANDROID_BUILD_TOOLS_VERSION=28.0.0 --action_env ANDROID_SDK_API_LEVEL=23 --action_env ANDROID_SDK_HOME=/android/sdk --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /tensorflow_src/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /tensorflow_src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /tensorflow_src/.bazelrc: --define=with_xla_support=true
INFO: Found applicable config definition build:monolithic in file /tensorflow_src/.bazelrc: --define framework_shared_object=false
INFO: Found applicable config definition build:linux in file /tensorflow_src/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /tensorflow_src/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Build options --cxxopt, --define, and --fat_apk_cpu have changed, discarding analysis cache.
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Repository io_bazel_rules_docker instantiated at:
  /tensorflow_src/WORKSPACE:16:10: in <toplevel>
  /tensorflow_src/tensorflow/workspace0.bzl:65:34: in workspace
  /Users/irina/Feebris/tflite-docker/bazel-build-cache/cache/43801f1e35f242fb634ebbc6079cf6c5/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories
Repository rule git_repository defined at:
  /Users/irina/Feebris/tflite-docker/bazel-build-cache/cache/43801f1e35f242fb634ebbc6079cf6c5/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>
INFO: Analyzed target //tensorflow/lite/tools:list_flex_ops_no_kernel_main (1 packages loaded, 781 targets configured).
INFO: Found 1 target...
Target //tensorflow/lite/tools:list_flex_ops_no_kernel_main up-to-date:
  bazel-bin/tensorflow/lite/tools/list_flex_ops_no_kernel_main
INFO: Elapsed time: 102.143s, Critical Path: 10.05s
INFO: 79 processes: 12 internal, 67 local.
INFO: Build completed successfully, 79 total actions
/tensorflow_src/tmp /tensorflow_src
/tensorflow_src
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=80
INFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /tensorflow_src/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env ANDROID_NDK_HOME=/android/ndk --action_env ANDROID_NDK_API_LEVEL=18 --action_env ANDROID_BUILD_TOOLS_VERSION=28.0.0 --action_env ANDROID_SDK_API_LEVEL=23 --action_env ANDROID_SDK_HOME=/android/sdk --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /tensorflow_src/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /tensorflow_src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /tensorflow_src/.bazelrc: --define=with_xla_support=true
INFO: Found applicable config definition build:linux in file /tensorflow_src/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /tensorflow_src/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Build options --cxxopt, --define, and --fat_apk_cpu have changed, discarding analysis cache.
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Repository io_bazel_rules_docker instantiated at:
  /tensorflow_src/WORKSPACE:16:10: in <toplevel>
  /tensorflow_src/tensorflow/workspace0.bzl:65:34: in workspace
  /Users/irina/Feebris/tflite-docker/bazel-build-cache/cache/43801f1e35f242fb634ebbc6079cf6c5/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories
Repository rule git_repository defined at:
  /Users/irina/Feebris/tflite-docker/bazel-build-cache/cache/43801f1e35f242fb634ebbc6079cf6c5/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>
INFO: Analyzed target //tmp:tensorflow-lite-select-tf-ops (310 packages loaded, 34804 targets configured).
INFO: Found 1 target...
ERROR: /Users/irina/Feebris/tflite-docker/bazel-build-cache/cache/43801f1e35f242fb634ebbc6079cf6c5/external/aws/BUILD.bazel:12:11: C++ compilation of rule '@aws//:aws' failed (Exit 4): gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 93 argument(s) skipped)
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-7/README.Bugs> for instructions.
Target //tmp:tensorflow-lite-select-tf-ops failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 7490.271s, Critical Path: 79.89s
INFO: 1549 processes: 23 internal, 1526 local.
FAILED: Build did NOT complete successfully
```"
46513,"Apple M1 `MLC` ops not supported (e.g., tf.MLCConv2D)","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

macOS 11.1 (Big Sur) running on a MacBook Pro (13-inch, M1, 2020)

- TensorFlow installed from (source or binary):

Binary, from https://github.com/apple/tensorflow_macos

- TensorFlow version (or github SHA if from source):

'2.4.0-rc0'

**Command used to run the converter or code if youâre using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
```

**The output from the converter invocation**

```
/python/framework/func_graph.py:590:0: error: 'tf.MLCConv2D' op is neither a custom op nor a flex op
```

**Also, please include a link to the saved model or GraphDef**

```
There's a similar issue here:
https://github.com/apple/tensorflow_macos/issues/133
```

**Failure details**
Conversion fails, since tf.MLCConv2D is not the same as tf.Conv2D.  The same is true for other operations like tf.MLCMatMul.

**Any other info / logs**
What's the right path forward here for using Lite, and then Lite Micro on an M1 Mac?  Should conversion from MLC be supported?  I attempted to work around this using `TF_DISABLE_MLC_EAGER` as mentioned at the very bottom of https://github.com/apple/tensorflow_macos but did not understand what syntax I should be using."
46512,Unable to import tensorflow in python3 after wheels install / Python3.7 / RPi 3B+ Raspbian aarch64,"
### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: NO
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux raspberrypi 5.10.5-v8+ #1392 SMP PREEMPT Sat Jan 9 18:56:30 GMT 2021 aarch64 GNU/Linux
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: Raspberry Pi 3 B+
-   **TensorFlow installed from (source or binary)**: source
-   **TensorFlow version (use command below)**: 2.4.0
-   **Python version**: 3.7
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**: GCC 8.3.0
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**: 
        sudo -H pip3 install tensorflow-2.4.0-cp37-cp37m-linux_aarch64.whl
        python3 -c ""import tensorflow as tf""


### Describe the problem
unable to import tensorflow module from python3 (3.7) :
pi@raspberrypi:~ $ python3 -c ""import tensorflow as tf""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>
    from tensorflow.python.eager import context
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 32, in <module>
    from tensorflow.core.framework import function_pb2
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 23, in <module>
    serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""z\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x12\x14\n\x0cunknown_rank\x18\x03 \x01(\x08\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tB\x87\x01\n\x18org.tensorflow.frameworkB\x11TensorShapeProtosP\x01ZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\xf8\x01\x01\x62\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'serialized_options'



### Source code / logs

Here is the output tf_env.txt generated by tf_env_collect.sh :

== check python ===================================================
python version: 3.7.3
python branch: 
python build version: ('default', 'Jul 25 2020 13:03:44')
python compiler version: GCC 8.3.0
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: #1392 SMP PREEMPT Sat Jan 9 18:56:30 GMT 2021
os release version: 5.10.5-v8+
os platform: Linux-5.10.5-v8+-aarch64-with-debian-10.7
linux distribution: ('debian', '10.7', '')
linux os distribution: ('debian', '10.7', '')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='raspberrypi', release='5.10.5-v8+', version='#1392 SMP PREEMPT Sat Jan 9 18:56:30 GMT 2021', machine='aarch64', processor='')
architecture: ('64bit', 'ELF')
machine: aarch64


== are we in docker =============================================
No

== compiler =====================================================
c++ (Debian 8.3.0-6) 8.3.0
Copyright (C) 2018 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy                  1.19.5
protobuf               3.0.0
tensorflow             2.4.0
tensorflow-estimator   2.4.0

== check for virtualenv =========================================
False

== tensorflow import ============================================
      7074:	find library=libcrypt.so.1 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/lib/aarch64-linux-gnu/libcrypt.so.1
      7074:	
      7074:	find library=libpthread.so.0 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/lib/aarch64-linux-gnu/libpthread.so.0
      7074:	
      7074:	find library=libdl.so.2 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/lib/aarch64-linux-gnu/libdl.so.2
      7074:	
      7074:	find library=libutil.so.1 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/lib/aarch64-linux-gnu/libutil.so.1
      7074:	
      7074:	find library=libexpat.so.1 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/lib/aarch64-linux-gnu/libexpat.so.1
      7074:	
      7074:	find library=libz.so.1 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/lib/aarch64-linux-gnu/libz.so.1
      7074:	
      7074:	find library=libm.so.6 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/lib/aarch64-linux-gnu/libm.so.6
      7074:	
      7074:	find library=libc.so.6 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/lib/aarch64-linux-gnu/libc.so.6
      7074:	
      7074:	
      7074:	calling init: /lib/aarch64-linux-gnu/libpthread.so.0
      7074:	
      7074:	
      7074:	calling init: /lib/aarch64-linux-gnu/libc.so.6
      7074:	
      7074:	
      7074:	calling init: /lib/aarch64-linux-gnu/libm.so.6
      7074:	
      7074:	
      7074:	calling init: /lib/aarch64-linux-gnu/libz.so.1
      7074:	
      7074:	
      7074:	calling init: /lib/aarch64-linux-gnu/libexpat.so.1
      7074:	
      7074:	
      7074:	calling init: /lib/aarch64-linux-gnu/libutil.so.1
      7074:	
      7074:	
      7074:	calling init: /lib/aarch64-linux-gnu/libdl.so.2
      7074:	
      7074:	
      7074:	calling init: /lib/aarch64-linux-gnu/libcrypt.so.1
      7074:	
      7074:	
      7074:	initialize program: python3
      7074:	
      7074:	
      7074:	transferring control: python3
      7074:	
      7074:	
      7074:	calling init: /usr/lib/python3.7/lib-dynload/_opcode.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	find library=libffi.so.6 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/usr/lib/aarch64-linux-gnu/libffi.so.6
      7074:	
      7074:	
      7074:	calling init: /usr/lib/aarch64-linux-gnu/libffi.so.6
      7074:	
      7074:	
      7074:	calling init: /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	find library=libstdc++.so.6 [0]; searching
      7074:	 search path=/usr/local/lib/python3.7/dist-packages/tensorflow/python/tls/aarch64:/usr/local/lib/python3.7/dist-packages/tensorflow/python/tls:/usr/local/lib/python3.7/dist-packages/tensorflow/python/aarch64:/usr/local/lib/python3.7/dist-packages/tensorflow/python:/usr/local/lib/python3.7/dist-packages/tensorflow/python/../tls/aarch64:/usr/local/lib/python3.7/dist-packages/tensorflow/python/../tls:/usr/local/lib/python3.7/dist-packages/tensorflow/python/../aarch64:/usr/local/lib/python3.7/dist-packages/tensorflow/python/..		(RUNPATH from file /usr/local/lib/python3.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so)
      7074:	  trying file=/usr/local/lib/python3.7/dist-packages/tensorflow/python/tls/aarch64/libstdc++.so.6
      7074:	  trying file=/usr/local/lib/python3.7/dist-packages/tensorflow/python/tls/libstdc++.so.6
      7074:	  trying file=/usr/local/lib/python3.7/dist-packages/tensorflow/python/aarch64/libstdc++.so.6
      7074:	  trying file=/usr/local/lib/python3.7/dist-packages/tensorflow/python/libstdc++.so.6
      7074:	  trying file=/usr/local/lib/python3.7/dist-packages/tensorflow/python/../tls/aarch64/libstdc++.so.6
      7074:	  trying file=/usr/local/lib/python3.7/dist-packages/tensorflow/python/../tls/libstdc++.so.6
      7074:	  trying file=/usr/local/lib/python3.7/dist-packages/tensorflow/python/../aarch64/libstdc++.so.6
      7074:	  trying file=/usr/local/lib/python3.7/dist-packages/tensorflow/python/../libstdc++.so.6
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/usr/lib/aarch64-linux-gnu/libstdc++.so.6
      7074:	
      7074:	find library=librt.so.1 [0]; searching
      7074:	 search path=/usr/local/lib/python3.7/dist-packages/tensorflow/python:/usr/local/lib/python3.7/dist-packages/tensorflow/python/..		(RUNPATH from file /usr/local/lib/python3.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so)
      7074:	  trying file=/usr/local/lib/python3.7/dist-packages/tensorflow/python/librt.so.1
      7074:	  trying file=/usr/local/lib/python3.7/dist-packages/tensorflow/python/../librt.so.1
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/lib/aarch64-linux-gnu/librt.so.1
      7074:	
      7074:	find library=libgcc_s.so.1 [0]; searching
      7074:	 search path=/usr/local/lib/python3.7/dist-packages/tensorflow/python:/usr/local/lib/python3.7/dist-packages/tensorflow/python/..		(RUNPATH from file /usr/local/lib/python3.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so)
      7074:	  trying file=/usr/local/lib/python3.7/dist-packages/tensorflow/python/libgcc_s.so.1
      7074:	  trying file=/usr/local/lib/python3.7/dist-packages/tensorflow/python/../libgcc_s.so.1
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/lib/aarch64-linux-gnu/libgcc_s.so.1
      7074:	
      7074:	
      7074:	calling init: /lib/aarch64-linux-gnu/libgcc_s.so.1
      7074:	
      7074:	
      7074:	calling init: /lib/aarch64-linux-gnu/librt.so.1
      7074:	
      7074:	
      7074:	calling init: /usr/lib/aarch64-linux-gnu/libstdc++.so.6
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
      7074:	
      7074:	find library=libssl.so.1.1 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/usr/lib/aarch64-linux-gnu/libssl.so.1.1
      7074:	
      7074:	find library=libcrypto.so.1.1 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/usr/lib/aarch64-linux-gnu/libcrypto.so.1.1
      7074:	
      7074:	
      7074:	calling init: /usr/lib/aarch64-linux-gnu/libcrypto.so.1.1
      7074:	
      7074:	
      7074:	calling init: /usr/lib/aarch64-linux-gnu/libssl.so.1.1
      7074:	
      7074:	
      7074:	calling init: /usr/lib/python3.7/lib-dynload/_hashlib.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/lib/python3.7/lib-dynload/termios.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/lib/python3.7/lib-dynload/_csv.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	find library=libopenblas.so.0 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/usr/lib/aarch64-linux-gnu/libopenblas.so.0
      7074:	
      7074:	find library=libgfortran.so.5 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/usr/lib/aarch64-linux-gnu/libgfortran.so.5
      7074:	
      7074:	
      7074:	calling init: /usr/lib/aarch64-linux-gnu/libgfortran.so.5
      7074:	
      7074:	
      7074:	calling init: /usr/lib/aarch64-linux-gnu/libopenblas.so.0
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/core/_multiarray_umath.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/core/_multiarray_tests.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/linalg/lapack_lite.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/linalg/_umath_linalg.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	find library=libbz2.so.1.0 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/lib/aarch64-linux-gnu/libbz2.so.1.0
      7074:	
      7074:	
      7074:	calling init: /lib/aarch64-linux-gnu/libbz2.so.1.0
      7074:	
      7074:	
      7074:	calling init: /usr/lib/python3.7/lib-dynload/_bz2.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	find library=liblzma.so.5 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/lib/aarch64-linux-gnu/liblzma.so.5
      7074:	
      7074:	
      7074:	calling init: /lib/aarch64-linux-gnu/liblzma.so.5
      7074:	
      7074:	
      7074:	calling init: /usr/lib/python3.7/lib-dynload/_lzma.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	find library=libmpdec.so.2 [0]; searching
      7074:	 search cache=/etc/ld.so.cache
      7074:	  trying file=/usr/lib/aarch64-linux-gnu/libmpdec.so.2
      7074:	
      7074:	
      7074:	calling init: /usr/lib/aarch64-linux-gnu/libmpdec.so.2
      7074:	
      7074:	
      7074:	calling init: /usr/lib/python3.7/lib-dynload/_decimal.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/fft/_pocketfft_internal.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/random/mtrand.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/random/bit_generator.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/random/_common.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/random/_bounded_integers.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/random/_mt19937.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/random/_philox.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/random/_pcg64.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/random/_sfc64.cpython-37m-aarch64-linux-gnu.so
      7074:	
      7074:	
      7074:	calling init: /usr/local/lib/python3.7/dist-packages/numpy/random/_generator.cpython-37m-aarch64-linux-gnu.so
      7074:	
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>
    from tensorflow.python.eager import context
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py"", line 32, in <module>
    from tensorflow.core.framework import function_pb2
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 23, in <module>
    serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""z\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x12\x14\n\x0cunknown_rank\x18\x03 \x01(\x08\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tB\x87\x01\n\x18org.tensorflow.frameworkB\x11TensorShapeProtosP\x01ZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\xf8\x01\x01\x62\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'serialized_options'
      7074:	
      7074:	calling fini: python3 [0]
      7074:	
      7074:	
      7074:	calling fini: /lib/aarch64-linux-gnu/libcrypt.so.1 [0]
      7074:	
      7074:	
      7074:	calling fini: /lib/aarch64-linux-gnu/libutil.so.1 [0]
      7074:	
      7074:	
      7074:	calling fini: /lib/aarch64-linux-gnu/libexpat.so.1 [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/python3.7/lib-dynload/_opcode.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/aarch64-linux-gnu/libffi.so.6 [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/aarch64-linux-gnu/libstdc++.so.6 [0]
      7074:	
      7074:	
      7074:	calling fini: /lib/aarch64-linux-gnu/librt.so.1 [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/python3.7/lib-dynload/_hashlib.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/aarch64-linux-gnu/libssl.so.1.1 [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/aarch64-linux-gnu/libcrypto.so.1.1 [0]
      7074:	
      7074:	
      7074:	calling fini: /lib/aarch64-linux-gnu/libdl.so.2 [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/python3.7/lib-dynload/termios.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/python3.7/lib-dynload/_csv.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/core/_multiarray_umath.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/core/_multiarray_tests.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/linalg/lapack_lite.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/linalg/_umath_linalg.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/aarch64-linux-gnu/libopenblas.so.0 [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/aarch64-linux-gnu/libgfortran.so.5 [0]
      7074:	
      7074:	
      7074:	calling fini: /lib/aarch64-linux-gnu/libgcc_s.so.1 [0]
      7074:	
      7074:	
      7074:	calling fini: /lib/aarch64-linux-gnu/libz.so.1 [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/python3.7/lib-dynload/_bz2.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /lib/aarch64-linux-gnu/libbz2.so.1.0 [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/python3.7/lib-dynload/_lzma.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /lib/aarch64-linux-gnu/liblzma.so.5 [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/python3.7/lib-dynload/_decimal.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/lib/aarch64-linux-gnu/libmpdec.so.2 [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/fft/_pocketfft_internal.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/random/mtrand.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/random/bit_generator.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/random/_common.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/random/_bounded_integers.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/random/_mt19937.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/random/_philox.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/random/_pcg64.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/random/_sfc64.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /usr/local/lib/python3.7/dist-packages/numpy/random/_generator.cpython-37m-aarch64-linux-gnu.so [0]
      7074:	
      7074:	
      7074:	calling fini: /lib/aarch64-linux-gnu/libm.so.6 [0]
      7074:	
      7074:	
      7074:	calling fini: /lib/aarch64-linux-gnu/libpthread.so.0 [0]
      7074:	

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_env_collect.sh: line 146: nvidia-smi: command not found

== cuda libs  ===================================================

== tensorflow installed from info ==================
Name: tensorflow
Version: 2.4.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /usr/local/lib/python3.7/dist-packages
Required-by: 

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(2, 7, 16, 'final', 0)

== bazel version  ===============================================
"
46511,Tracing of tf function is stuck when the function contains custom CRF layer that wraps tfa crf functions inside,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Big Sur
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): from pypi
- TensorFlow version (use command below): 2.4
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
When wrapping `crf` functions from `tensorflow_addons` into a custom Keras layer and then creating a training function with it that will be converted into `tf.function` with dynamic first dimension of the input shape, the process is stuck during tracing when trying to create gradient tensors. if I create `tf.function` with static shapes, it works.

If I use `tfa.text.crf.crf_decode` and `tfa.text.crf.crf_log_likelihood` directly without custom Keras layer wrapper, tracing `tf.function` seems to be working.

The problem appeared in version `2.4`, it is working in `2.3`

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
import tensorflow_addons as tfa

potentials = tf.random.uniform((3,4,5))
sequence_lengths = tf.ones((3,))
tag_indices = tf.ones((3,4), dtype=tf.int32)

class CRF(tf.keras.layers.Layer):
    def build(self, input_shape: tf.TensorShape) -> None:
        self.transition_params = self.add_weight(
            shape=(5, 5),
            regularizer=tf.keras.regularizers.l2(0.1),
            name=""transitions"",
        )
        self.built = True
    
    def call(self, potentials, sequence_lengths):
        x = tfa.text.crf.crf_decode(
            potentials, self.transition_params, sequence_lengths
        )
        y = tfa.text.crf.crf_log_likelihood(
            potentials, tag_indices, sequence_lengths, self.transition_params
        )
        return x, y

crf = CRF()

def foo(potentials, sequence_lengths):
    with tf.GradientTape(persistent=True) as tape:
        x, y = crf(potentials, sequence_lengths)

    return x, y

tf_foo_static =  tf.function(foo)
tf_foo_static(potentials, sequence_lengths)  # works fine

tf_foo_dynamic = tf.function(foo, input_signature=[tf.TensorSpec((None, None, 5)), tf.TensorSpec((None,))])
tf_foo_dynamic(potentials, sequence_lengths)  # the execution is stuck without raising any error
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

When the process is terminated for `tfa.text.crf.crf_log_likelihood`, it looks like the gradient calculation through [`tf.scan` in `crf_forward`](https://github.com/tensorflow/addons/blob/6e7e06c56c2044e12a0d05d1381c6071defdf216/tensorflow_addons/text/crf.py#L366) is stuck, if we add `back_prop=False`, it manage to do the tracing, but it is a part of the loss function, so we need to backdrop the gradient. 

When the process is terminated for `tfa.text.crf.crf_decode`, it looks like the gradient calculation through [`tf.keras.layers.RNN` in `crf_decode_forward`](https://github.com/tensorflow/addons/blob/6e7e06c56c2044e12a0d05d1381c6071defdf216/tensorflow_addons/text/crf.py#L492) is stuck.
"
46508,Unsafe conversion from pointer to uint64_t in Ethos-U kernel,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source):
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Ethos-U

**Describe the problem**
Example:
reinterpret_cast<uint64_t>((void*)0x78000000)=0000000078000000
reinterpret_cast<uint64_t>((void*)0x80000000)=ffffffff80000000
reinterpret_cast<uint64_t>((void*)0x88000000)=ffffffff88000000

This happens specifically for GCC and prevents using addresses at 0x80000000 or above.

**Please provide the exact sequence of commands/steps when you ran into the problem**

"
46507,Instead of x2 variable name should be x0,"https://www.tensorflow.org/guide/autodiff
Instead of x2 variable name should be x0 in last line

x0 = tf.Variable(3.0)
x1 = tf.Variable(0.0)

with tf.GradientTape() as tape:
  // Update x1 = x1 + x0.
  x1.assign_add(x0)
  // The tape starts recording from x1.
  y = x1**2   # y = (x1 + x0)**2

// This doesn't work.
print(tape.gradient(y, x0))   // dy/dx0 = 2*(x1 + x2)[](url)"
46506,python3 pip Install Error: No matching distribution found for tensorflow==2.2.0,"I have macOS Big Sur on a Apple Silicon M1 and I'm unable to install Tensorflow in python3.
I removed xcode python3 and installed brew arm64 python3 (x86 python3 doesn't work as well)

(This is  a follow up of closed https://github.com/tensorflow/tensorflow/issues/39130)

I checked successful 64 bis version 
`python3 -c ""import sys; print(sys.version)"" or python -c ""import struct; print(struct.calcsize('P')*8)""`

> 3.8.7 (default, Dec 30 2020, 02:09:32) 
> [Clang 12.0.0 (clang-1200.0.32.28)]


<img width=""606"" alt=""image"" src=""https://user-images.githubusercontent.com/3314607/104881650-f6aa7c80-5961-11eb-8cbb-6128190a0a3a.png"">

Can this work anyhow, or who knows, how to make this work ?

"
46504,micro: port op BATCH_MATMUL from lite,"@tensorflow/micro

This issue tracks my work porting operator BATCH_MATMUL from lite to micro.

The port will be submitted in a number of PRs. Here's a rough flight plan per @advaitjain and @petewarden:

PR 1: Extract the code for parsing the op from a flatbuffer out of ParseOpDataTfLite in tensorflow/lite/core/api/flatbuffer_conversions.cc into a standalone function that can be called from micro's op resolver
PR 2: Extract the reference implementation out of tensorflow/lite/kernels/internal/reference/reference_ops.h into its own header which can be included without dragging in reference_ops.h's dependences
PR 3: Copy operator from lite to micro making minimal changes and not including in the build
PR 4: Delete extra code from the micro copy of the operator
PR 5: Port micro copy of operator as necessary and add a corresponding test
"
46503,Can I use cmdline option `--allow_nudging_weights_to_use_fast_gemm_kernel` via python API?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source from git
- TensorFlow version (or github SHA if from source): 2.3.0


**Command used to run the converter or code if youâre using the Python API**

```
// input, output and weight settings above..
converter = tf.lite.TFLiteConverter.from_session(sess, input_tensors, output_tensors)
...
tflite_model = converter.convert()
```


**The output from the converter invocation**

```
2021-01-05 08:02:27.757106: F tensorflow/lite/toco/graph_transformations/ensure_uint8_weights_safe_for_fast_int8_kernels.cc:190] Bad value for Conv2D_4/filter at index 134, previous bad value at index 132, distance=2, kMinDistanceBetweenBadValues=16. Consider passing --allow_nudging_weights_to_use_fast_gemm_kernel if you don't care about accuracy.
Fatal Python error: Aborted
```

**Failure details**
- We randomly generate Fully Connected weights and convert the tf session to tflite using `toco` - python API. It seems that `toco` doesn't allow a certain type of weights with some zero values in the vicinity to other zero values.
- The console output says I need to pass `--allow_nudging_weights_to_use_fast_gemm_kernel`, which is only useful for the command line. I cannot find a way to pass it via Python API.

Is there any way that I can pass the `--allow_nudging_weights_to_use_fast_gemm_kernel` option via Python API?"
46502,Docker image tensorflow:latest-gpu-jupyter - Setting a password doesn't work,"Using image from here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/devel-gpu-jupyter.Dockerfile

Downloaded from dockerhub with `docker pull tensorflow/tensorflow:latest-gpu-jupyter`

When running the jupyter server, we can normally set up a password in the login page.

However, with this image I get an error 500 after configuring the password.

The password is effectively written to `/root/.jupyter/jupyter_notebook_config.json` but it isn't taken into account by the jupyter server. I.e. you can't connect just as if you had put a wrong password.

On the other hand, this works perfectly when using images from [jupyter/docker-stacks](https://github.com/jupyter/docker-stacks/)."
46501,Sagemaker endpoint serving doesnt work for multiple timestep `and` multiple inputs (mulit input-output LSTM),"Update: Minimum Reproducible code
https://colab.research.google.com/drive/1RJ2ou705xfrqjeFGImvMk02lTxfFPZek?usp=sharing

I have a LSTM network that has 3 inputs and 3 outputs(built with [functional api][1] in Tf.keras) , that I am trying to deploy as sagemaker endpoint. I have input shape of (None,10,1) for each input/feature, which means 10 timesteps.(I later concatenate the embeddings, but its irrelevant here) 

Everything works fine on training time on sagemaker training jobs as well and training completes and artifacts are made successfully. But at time of invocation, endpoint is not working to predict `1 example, having 10 timesteps with 3 inputs` , I have tried multiple things but cant provide three inputs for prediction(input_1,input_2,input_1).

As I said that each input has 10 timesteps, so have shape (10,1). Endpoint only returns the output if I format my payload as below, but by doing so, it treats each time-step as separate example/instance and return 10 predictions for each output

    {'inputs':{
               'input_1': [[0], [0], [0], [0], [2], [12], [11], [7], [7], [2]],
               'input_2': [[0], [0], [0], [0], [30], [21], [2], [15], [27], [30]],
               'input_3': [[0], [0], [0], [0], [6], [2], [3], [13], [15], [6]]}
              } # gives len(pred['output_1""])) == 10

This is expected as it consider this request as 10 examples, but in my case it is one example with 10-timesteps for each feature (1,10,1). So I tried different things from the [documentation][2]. Like using instances.

    {'instances': [
                    {
                          'input_1': [[0],[0], [0],[0],[2],[12],[11], [7], [7], [2]],
                          'input_2': [[0], [0], [0], [0], [30], [21], [2], [15], [27], [30]],
                          'input_3': [[0], [0], [0], [0], [6], [2], [3], [13], [15], [6]]
                    }
                  ]
    }

But it gives this error.

>  transpose expects a vector of size 4. But input(1) is a vector of
> size 3\\n\\t [[{{node transpose_1}}]]\\n\\t
> [[functional_1/lstm/PartitionedCall]]\\n\\t
> [[StatefulPartitionedCall/StatefulPartitionedCall]]\""\n}""}""

Document also gives example and says

> for models with multiple named inputs, just include all the keys in the input dict

but when I use this, I get error saying `Missing 'inputs' or 'instances' key\""\n}""`

    {'input_1': [[0], [0], [0], [0], [2], [12], [11], [7], [7], [2]],
     'input_2': [[0], [0], [0], [0], [30], [21], [2], [15], [27], [30]],
     'input_3': [[0], [0], [0], [0], [6], [2], [3], [13], [15], [6]]}


My invocation code is below.

    import boto3
    import json
    
    sm = boto3.client('sagemaker-runtime')    
    endpoint_name = ""tensorflow--------------------4""
    response = sm.invoke_endpoint(EndpointName=endpoint_name, 
                                  Body=json.dumps(payload),
                                  ContentType='application/json')



I am not sure how to solve this issue, looking forward for help


  [1]: https://keras.io/guides/functional_api/
  [2]: https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/deploying_tensorflow_serving.html






**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Sagemaker and Ubuntu 20
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.3.1
- Python version: 3.7

**Standalone code to reproduce the issue**

I am not sure about the standalone code as sagemaker endpoint is confidential, and what should I share for this, i would be thankful for the suggestion on this too."
46499,TfLite converter crashes when quantization is enabled,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A 
- GPU model and memory: N/A

I have TF model in saved_model format. When converting to TFlite without quantization, everything works and I'm able to run inference, no problem. When converting using full integer quantization with a representative dataset, I get the following exception:

Traceback (most recent call last):
  File ""C:/REPOSITORIES/PoolNet2TFv2/tfliteInf.py"", line 93, in <module>
    quantize(""poolnet_640_tf"")
  File ""C:/REPOSITORIES/PoolNet2TFv2/tfliteInf.py"", line 35, in quantize
    quant_model = converter.convert()
  File ""C:\REPOSITORIES\PoolNet2TFv2\venv38local\lib\site-packages\tensorflow\lite\python\lite.py"", line 1076, in convert
    return super(TFLiteConverterV2, self).convert()
  File ""C:\REPOSITORIES\PoolNet2TFv2\venv38local\lib\site-packages\tensorflow\lite\python\lite.py"", line 899, in convert
    return super(TFLiteFrozenGraphConverterV2,
  File ""C:\REPOSITORIES\PoolNet2TFv2\venv38local\lib\site-packages\tensorflow\lite\python\lite.py"", line 638, in convert
    result = self._calibrate_quantize_model(result, **flags)
  File ""C:\REPOSITORIES\PoolNet2TFv2\venv38local\lib\site-packages\tensorflow\lite\python\lite.py"", line 450, in _calibrate_quantize_model
    return calibrate_quantize.calibrate_and_quantize(
  File ""C:\REPOSITORIES\PoolNet2TFv2\venv38local\lib\site-packages\tensorflow\lite\python\optimize\calibrator.py"", line 95, in calibrate_and_quantize
    return self._calibrator.QuantizeModel(
RuntimeError: Quantization not yet supported for op:

see [here](https://drive.google.com/file/d/19D3BuJSEXHsM0eH0L1Cad3gX-9JkkXYX/view?usp=sharing) a zip file containing the TF model (poolnet_640_tf), a folder with 3 images for the representative dataset (norm_images) and quantize.py, my conversion code. 

Thank you


"
46498,Issues when Cross-building TFLite GPU Delegate and loading the built so file in Python,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS x86_64 PC
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): 582c8d2
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): RK3399 Ubuntu 18.04 LTS aarch64

**Describe the problem**

Host PC environment:
OS: Ubuntu 18.04 x86_64 AMD64
native gcc(g++): 7.5.0
cross-compiler aarch64-linux-gnu-gcc(aarch64-linux-gnu-g++): 8.3.0, which is download automatically by bazel when building
bazel: 3.7.2
python: virtual env python 3.7

Target Device environment:
Device: RK3399
CPU: armv8
GPU: Mali T860
OS: Ubuntu 18.04 aarch64
native gcc(g++): 7.5.0
OpenCL: 1.2

I have two issues: the first is one **when cross-building OpenCL backend TFLite GPU delegate on the host PC**; the second is **when loading the TFLite GPU delegate so file** in Python on the target device platform.

First, I could NOT build **OpenCL(v1.2) backend TFLite GPU delegate** for OpenCL version 1.2.

![image](https://user-images.githubusercontent.com/47862419/104850767-fa231100-592b-11eb-94e1-82fba7d297bb.png)

So I built **OpenCL(v2.2) backend TFLite GPU delegate**.
I tried to use the built OpenCL(v2.2) TFLite GPU delegate in Python on RK3399 aarch64 but I met the following issue.

![image](https://user-images.githubusercontent.com/47862419/104851345-69e6cb00-592f-11eb-984c-d4bc18def731.png)

**Please provide the exact sequence of commands/steps when you ran into the problem**
I followed the following steps on my host PC.

sudo apt update
sudo apt-get install software-properties-common
sudo apt update
sudo apt install git curl
sudo apt install python3.7 python3.7-dev python3.7-venv python3.7-distutils
sudo apt install mesa-common-dev libegl1-mesa-dev libgles2-mesa-dev

cd ~
python3.7 -m venv py37
source ~/py37/bin/activate
pip install cython
pip install wheel
pip install numpy

git clone -b r2.4 https://github.com/tensorflow/tensorflow.git tensorflow_r2.4
cd tensorflow_r2.4
./configure

![image](https://user-images.githubusercontent.com/47862419/104850283-2be6a880-5929-11eb-9b09-7572ddb59263.png)

For OpenCL 1.2:
bazel build -s -c opt --config=elinux_aarch64 --copt=""-DMESA_EGL_NO_X11_HEADERS"" --copt=""-DEGL_NO_X11"" --copt=""-DCL_DELEGATE_NO_GL"" --copt=""-DCL_TARGET_OPENCL_VERSION=120"" tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so

But this failed as the above figure.
So I built again for OpenCL 2.2
bazel build -s -c opt --config=elinux_aarch64 --copt=""-DMESA_EGL_NO_X11_HEADERS"" --copt=""-DEGL_NO_X11"" --copt=""-DCL_DELEGATE_NO_GL"" --copt=""-DCL_TARGET_OPENCL_VERSION=220"" tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so
This building was successfull and I got a tflite gpu delegate so file.

I tried to load the built GPU delegate so file in Python as the following.

![image](https://user-images.githubusercontent.com/47862419/104851016-520e4780-592d-11eb-9457-b49bb752efca.png)

But I met an issue as the above figure.

What I want to know are:
1) how to build OpenCL(v1.2 rather than v2.2) backend TFLite GPU delegate so file on the host PC or the target platform
2) how to fix the issue when loading the built TFLite GPU delegate so file in Python.
"
46497,Add option to write tensor to raw byte string,"`tf.io.serialize_tensor` appears to serialize to protobuf. It would be nice to have the option to serialize to a raw byte string as this allows for a lot more flexibility when dealing with data in unsupported formats (e.g. > 16 int bit depth audio data).

I know that this is possible with the `.numpy()` option. However, `.numpy()` is not available in graph mode, meaning there is no way to serialize to byte string in `tensorflow-serving`.

Ideally, `tensorflow-io` would solve this problem. However, as yet there does [not appear](https://github.com/tensorflow/io/issues/414) to be an easy way to get `tensorflow-serving` to support `tensorflow-io` ops."
46496,Illegal instruction (core dumped) with tf <= that 1.15 and cpu with no AVX instructions,"On a Intel Q9659 cpu that does not support AVX instructions, I have a `Illegal instruction (core dumped)`. So I have installed a previous version, but I'm still getting the error.

This Quad core cpu has the following flags

```
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx lm constant_tsc arch_perfmon pebs bts rep_good nopl cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 lahf_lm pti tpr_shadow vnmi flexpriority dtherm
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx lm constant_tsc arch_perfmon pebs bts rep_good nopl cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 lahf_lm pti tpr_shadow vnmi flexpriority dtherm
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx lm constant_tsc arch_perfmon pebs bts rep_good nopl cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 lahf_lm pti tpr_shadow vnmi flexpriority dtherm
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx lm constant_tsc arch_perfmon pebs bts rep_good nopl cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 lahf_lm pti tpr_shadow vnmi flexpriority dtherm
```

and

```
loreto@ombromanto:~$ grep flags -m1 /proc/cpuinfo | cut -d "":"" -f 2 | tr '[:upper:]' '[:lower:]' | { read FLAGS; OPT=""-march=native""; for flag in $FLAGS; do case ""$flag"" in ""sse4_1"" | ""sse4_2"" | ""ssse3"" | ""fma"" | ""cx16"" | ""popcnt"" | ""avx"" | ""avx2"") OPT+="" -m$flag"";; esac; done; MODOPT=${OPT//_/\.}; echo ""$MODOPT""; }
-march=native -mssse3 -mcx16 -msse4.1
```



Here are detailed information about this system: 

`bash <(curl -s https://raw.githubusercontent.com/tensorflow/tensorflow/master/tools/tf_env_collect.sh) && cat tf_env.txt`

```
== check python ===================================================
python version: 3.7.5
python branch: 
python build version: ('default', 'Nov  7 2019 10:50:52')
python compiler version: GCC 8.3.0
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: #46~18.04.1-Ubuntu SMP Fri Jul 10 07:21:24 UTC 2020
os release version: 5.4.0-42-generic
os platform: Linux-5.4.0-42-generic-x86_64-with-Ubuntu-18.04-bionic
linux distribution: ('Ubuntu', '18.04', 'bionic')
linux os distribution: ('Ubuntu', '18.04', 'bionic')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='ombromanto', release='5.4.0-42-generic', version='#46~18.04.1-Ubuntu SMP Fri Jul 10 07:21:24 UTC 2020', machine='x86_64', processor='x86_64')
architecture: ('64bit', 'ELF')
machine: x86_64


== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy                1.19.5
protobuf             3.14.0
tensorflow           1.14.0
tensorflow-estimator 1.14.0

== check for virtualenv =========================================
False

== tensorflow import ============================================
...
== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Sun Jan 17 17:33:54 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 105...  Off  | 00000000:01:00.0  On |                  N/A |
| 45%   23C    P8    N/A /  75W |    241MiB /  4033MiB |      1%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1053      G   /usr/lib/xorg/Xorg                 16MiB |
|    0   N/A  N/A      1132      G   /usr/bin/gnome-shell               56MiB |
|    0   N/A  N/A      1934      G   /usr/lib/xorg/Xorg                106MiB |
|    0   N/A  N/A      2080      G   /usr/bin/gnome-shell               27MiB |
|    0   N/A  N/A      3447      G   ...AAAAAAAAA= --shared-files       21MiB |
|    0   N/A  N/A      6932      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A      7286      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A     10042      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A     10159      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A     10256      G   /usr/lib/firefox/firefox            1MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================

== tensorflow installed from info ==================
Name: tensorflow
Version: 1.14.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /home/loreto/.venv/lib/python3.7/site-packages
Required-by: 

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 7, 5, 'final', 0)

== bazel version  ===============================================

```"
46495,Converted models gives wrong outputs,"**System information**
Run on Colab; tensorflow-gpu==2.3.1 for the first part, then tf-nightly-gpu (after runtime restart).

**Command used to run the converter or code if youâre using the Python API**
Colab link with the project:
https://colab.research.google.com/drive/1V7fo4TgfAvMxme9AOBbdYggW-I7-tXTr?usp=sharing

**The output from the converter invocation**
On Colab, no verbose output but model.tflite is created

**Also, please include a link to the saved model or GraphDef**
Here the link of the .pb model (which was obtained using onnx_to_tensorflow):
https://drive.google.com/drive/folders/1RiwVVbzTNymzdmy_sRZxIWWSOGE3EwOx?usp=sharing

**Failure details**
I obtained a converted model.tflite file but the outputs are wrong (see Colab notebook for comparison)

**Any other info / logs**
As explained in the notebook, the tflite coinversion works with tensorflow-gpu==2.3.1 but to run the model tf-nightly-gpu is required (after runtime restart). If I do differently, Colab crashes.

"
46494,tools:summarize_graph fails to open TFHub models due to parsing errors,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: Python 3.8.6 (default, Oct  9 2020, 11:59:16) 
- Bazel version (if compiling from source): Bazelisk version: v1.6.1
- GCC/Compiler version (if compiling from source): [GCC 9.3.0] on linux
- CUDA/cuDNN version: not relevant
- GPU model and memory: not relevant

**Describe the current behavior**

`summarize_graph` is not able to load downloaded and extracted models from TFHub e.g. https://tfhub.dev/deepmind/biggan-128/2 due to parsing errors.

```
$ bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph='/media/paulgavrikov/DATA/noCNN/model_conversion/biggan/compare_gan_ssgan_128x128_1/saved_model.pb'  --print_structure=true
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:324] Error parsing text-format tensorflow.GraphDef: 1:1: Invalid control characters encountered in text.
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:324] Error parsing text-format tensorflow.GraphDef: 1:2: Interpreting non ascii codepoint 154.
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:324] Error parsing text-format tensorflow.GraphDef: 1:2: Expected identifier, got: ï¿½
2021-01-17 12:13:33.563477: E tensorflow/tools/graph_transforms/summarize_graph_main.cc:320] Loading graph '/media/paulgavrikov/DATA/noCNN/model_conversion/biggan/compare_gan_ssgan_128x128_1/saved_model.pb' failed with Can't parse /media/paulgavrikov/DATA/noCNN/model_conversion/biggan/compare_gan_ssgan_128x128_1/saved_model.pb as binary proto
	 (both text and binary parsing failed for file /media/paulgavrikov/DATA/noCNN/model_conversion/biggan/compare_gan_ssgan_128x128_1/saved_model.pb)
2021-01-17 12:13:33.563504: E tensorflow/tools/graph_transforms/summarize_graph_main.cc:322] usage: bazel-bin/tensorflow/tools/graph_transforms/summarize_graph
```

**Describe the expected behavior**

The tool should load the model"
46493,Efficient and simple encoding for large tensors (such as `encode_raw`) for the use with tensorflow serving needed,"**System information**
- TensorFlow version (you are using): 2.4.0
- Are you willing to contribute it (Yes/No): Yes - tough I have no experience with developing tf ops

**Describe the feature and the current behavior/state.**
The stock gRPC/protobuf encoding for requests used in tensorflow serving carries large per-value processing overhead,
even though that encoding is the recommended encoding for optimal performance.
This might not matter much on the server side, where the encoding time is usually dwarved by the model processing time.
However, on the client side, decoding of the repeated values within the tensor proto may cause significant processing load.
(In my particular reinforcement learning case, the majority of time is spent decoding protobuf).

On the request side, this can be avoided by dumping binary data into a string and then using `tf.io.decode_raw` in the model.
However, for the response, a corresponding `tf.io.encode_raw` is missing.
Furthermore, there seems to be no graph mode compatible way to ""view""/""bitcast"" data into a `tf.string`
(even the workaround presented in https://stackoverflow.com/questions/43403147/how-to-create-a-encode-raw-tensorflow-function ported to TF 2.4.0 is not usable, because apparently `tf.strings.join` is not supported in graph mode). 

Of course, one could work around by implementing a custom API using the C++ API of tensorflow serving,
but that is a large effort with a much more limited application than a general `tf.io.encode_raw`.

**Will this change the current api? How?**
No.

**Who will benefit with this feature?**
Users of tensorflow serving requiring large prediction outputs. As a basic IO operation, many more use cases may be around.

"
46492,"documentation missing, tf.keras.Model.fit shuffle argument is being ignored when passing a tf.data.dataset","## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit

## Description of issue (what needs changing):

There's an issue with the shuffle argument description, it doesn't state that the ""shuffle"" argument is being ignored
when the argument ""x"" is a tf.data.dataset in tf.keras.model.fit.

### Clear description

I was inspecting the source code in tf.keras.model.fit and found that when the input arg x to the [data handler](https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/engine/training.py#L1050) is a tf.data.dataset, it ends up using the [dataset adapter](https://github.com/tensorflow/tensorflow/blob/582c8d236cb079023657287c318ff26adb239002/tensorflow/python/keras/engine/data_adapter.py#L671) which silently ignores the shuffle argument. 

This issue is not clearly explained in the description of the shuffle argument below:

_""""""Boolean (whether to shuffle the training data before each epoch) or str (for 'batch'). This argument is ignored when x is a generator. 'batch' is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when steps_per_epoch is not None.""""""_

I would recommend to write something like this instead ""_This argument is ignored when x is a generator or a tf.data.Dataset._"" 

I can contribute by fixing the docs if you agree that this should be done.

Thank you in advance for your review!


 


"
46491,(Donkey Car: Epoch failure during train command) Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, uses Donkey Car train function.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): I am not sure, using Anaconda Prompt
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.4.0 (have also tried 2.3.0 and 2.3.2)
- Python version: 3.7.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2
- GPU model and memory: GTX 1080 * GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

When executing the Train command, it eventually fails with error: `W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated. [[{{node PyFunc}}]]`

**Describe the expected behavior**

100 Epochs should be ran through.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

`(donkey) C:\Users\Kelvin>python C:\Users\Kelvin\mycar\train.py --tub C:\Users\Kelvin\mycar\data\ --model C:\Users\Kelvin\mycar\models\mypilot.h5`

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Sorry if anything is unclear, I am fairly new to this. This is in reference to autorope/donkeycar#742 . Basically, we are trying to train a neural network and go through 100 Epochs, but run into this error. I have tried with 2.3.2 and 2.4.0 and updated Cuda 10.2 and updated my graphics drivers and have had no luck.

Here is the full log when I run into the issue:

[console with 2.4.0.txt](https://github.com/tensorflow/tensorflow/files/5825583/console.with.2.4.0.txt)

"
46490,help me to solve this i am running a windows machine 8 gb ram python 3.8 cudnn 6.5 cuda 11 geforce 210,"
(base) C:\Users\ADMIN>python
Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python38\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\__init__.py"", line 39, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\ADMIN\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
>>>                                                                                                                                                                     "
46489,Please Help Me To Sort This Out ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- windows
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:2
- Python version:3.8
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:6.5
- GPU model and memory:geforce 210 



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
46488,Keras saved model returns different result than original model using Batch Normalization on multiple GPUs (Distributed training),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary via pip3
- TensorFlow version (use command below): 2.3.1
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: Geforce GTX 1080 Ti 4x11GB

I got a different result when using evaluate function on a saved model when compare with the original model. This only happens when Batch Normalization is included in the model and when training on multiple GPUs with MirroredStrategy.

Here is my model
```
with strategy.scope():
  model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
      tf.keras.layers.MaxPooling2D(),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(10)
  ])

  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                optimizer=tf.keras.optimizers.Adam(),
                metrics=['accuracy'])
```

Multiple GPUs with MirroredStrategy
```
strategy = tf.distribute.MirroredStrategy()
print('Number of devices: {}'.format(strategy.num_replicas_in_sync))
```
Output
```
Number of devices: 2
```

Evaluate after training
```
eval_loss, eval_acc = model.evaluate(eval_dataset)

print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))
```

Output
```
79/79 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.9884
Eval loss: 0.04239395260810852, Eval Accuracy: **0.9883999824523926**
```

Save model and evaluate again
```
path = 'saved_model/'
model.save(path, save_format='tf')
with strategy.scope():
  replicated_model = tf.keras.models.load_model(path)
  replicated_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                           optimizer=tf.keras.optimizers.Adam(),
                           metrics=['accuracy'])

  eval_loss, eval_acc = replicated_model.evaluate(eval_dataset)
  print ('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))
```
Output
```
79/79 [==============================] - 0s 6ms/step - loss: 0.0424 - accuracy: 0.9883
Eval loss: 0.04239019751548767, Eval Accuracy: **0.9883000254631042**
```

 - Without BN

Output from evaluate
```
79/79 [==============================] - 0s 6ms/step - loss: 0.0450 - accuracy: 0.9837
Eval loss: 0.04498908668756485, Eval Accuracy: **0.9836999773979187**
```

Save model and repeat evaluate
```
79/79 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9837
Eval loss: 0.04498908668756485, Eval Accuracy: **0.9836999773979187**
```

I have searched for similar issues and thought that this is because [BN computes differently during training and interference ](https://keras.io/api/layers/normalization_layers/batch_normalization/) but when I tried with one GPU, this issue didn't occur.

[Code for reproduce results](https://colab.research.google.com/drive/14iv88UJwFSv1SaVzmEl9RMOa1EH8IiRG?usp=sharing)
"
46487,typo / missing space in RuntimeError,"I just signed up here to report this, sorry if I'm doing everything wrong or something.
I just got the follwing:
```
RuntimeError: in user code:

    <ipython-input-74-5015738e55b1>:22 fitting  *
        grads = tape.gradient(value, model.trainable_weights)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py:1027 gradient  **
        raise RuntimeError(""A non-persistent GradientTape can only be used to""

    RuntimeError: A non-persistent GradientTape can only be used tocompute one set of gradients (or jacobians)
```
And I think there is a space missing in the last line's ""tocompute""."
46486,[TFLite] OpenCL strange performance compared to OpenGL,"I've run some tests and I keep seeing the behavior below, where CPU execution and OpenGL execution match all expectations (histogram shape, speed), but OpenCL performs unpredictably. The graph refers to tests run on Pixel 4 with an extremely simple model (400x400x1 input => 2D mean => 1x1 output), collecting about 3k samples for each plot.

![cl_plot](https://user-images.githubusercontent.com/15526561/104822300-c370cc00-5841-11eb-90f1-d4bdc14a8802.png)

- The first plot `cpu` is for CPU execution (no delegate). Execution takes 10ms on average. 
- The second `ssbo_mono_gl` is for GPU execution with OpenGL. Input is passed as SSBO with the correct dimensions (400x400x1). Shape is nice and it's faster than CPU, as one would expect.
- The third `ssbo_mono_cl` is for GPU execution with OpenCL. Input is passed as SSBO with the correct dimensions (400x400x1). I can see several issues:
  - On average, 2.5 times slower than OpenGL.
  - The results cluster around two speed levels. 
  
  I'm not concerned with OpenCL slower than OpenGL in theory (might be due to SSBO input) **but** histogram shows that it's averagely slower just because of the right cluster. The left cluster performs just fine, actually better than GL. This looks suspicious to me.

- Things get even weirder in the fourth plot `ssbo_dhwc4_cl` where I pass a dhwc4 (400x400x4) SSBO to the delegate. What I see:
  - OpenCL performance gets about 4 times slower, which seems to suggest that most time is spent on conversions? The model is always the same (single channel).
  - The majority of samples now belongs to the fast cluster! Why would this shift happen?
  
I'd like to ask two questions,
1. Is there a known explanation for this (especially the two clusters, and the DHWC4 shift)? Maybe the SSBO to OpenCL conversion should be investigated.
2. If it's not tensorflow's fault but rather weird behavior from the GPU driver, are we really sure that OpenCL should be the preferred implementation in the V2 delegate? With this data in hand I would choose OpenGL hands down, yet TF prefers OpenCL when available. I know I can use `TFLITE_GPU_EXPERIMENTAL_FLAGS_GL_ONLY`, I'm just questioning the default."
46485,Tensorflow DOESNOT WORKS WITH GPU,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
46484,TypeError: '<' not supported between instances of 'function' and 'str',"<em>Please make sure that this is a bug. As per our[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),we only address code/doc bugs, performance issues, feature requests andbuild/installation issues on GitHub. tag:bug_template</em>

**System information**
- I'm training the model on google collaboratory

**Describe the current behavior**
I've trained and saved my model, on importing the model it gives this error on model evaluation, but model.predict() works perfectly

**Testing Code**
`model_path = ""/content/drive/MyDrive/Train Data/Models/text_block_model_new_batch.h5""`
`model = tf.keras.models.load_model(model1_path,custom_objects={'dice_coef':dice_coef,'dice_coef_loss':dice_coef_loss})`
`results = model.evaluate(X_test,Y_test)`



![Screenshot (40)](https://user-images.githubusercontent.com/54077406/104814641-16448680-5836-11eb-8057-9bcd29159d9f.png)

"
46483,InvalidArgumentError: 5 nodes in a cycle ,"Hello,
I am trying to read image data from TFRecords,parse it , decode the images and the batch it. The moment I use @tf.function for decoding the images using a dataset.map() method, I get the following error. 
Here is the code and output:

Thank in advance! 

```
class DataParser(Hyperparameters):

   
    def __init__(self): 
        self.TFRECORDS_FORMAT=Hyperparameters.TFRECORDS_FORMAT
        self.BATCH_SIZE=Hyperparameters.BATCH_SIZE
        self.HEIGHT=Hyperparameters.HEIGHT
        self.WIDTH=Hyperparameters.WIDTH
        
    def readTFRecs(self,dir_name): 
        
        TFRecFiles=tf.constant(tf.io.gfile.listdir(dir_name))
        TFRecFiles=tf.map_fn(lambda name:dir_name+'/'+name,TFRecFiles)
        TFRecDataset=tf.data.TFRecordDataset(TFRecFiles)#.batch(self.BATCH_SIZE).prefetch(1)
        self.dataset_len=tf.data.experimental.cardinality(TFRecDataset).numpy()
        Dataset = TFRecDataset.map(lambda example:tf.io.parse_example(example,self.TFRECORDS_FORMAT))
        return Dataset
    
    @tf.function
    def decode_image(self,entry):
       return tf.image.decode_image(entry['image'],channels=3) #[batch_size,h,w,3]
    
    
    @tf.function
    def makeDataset(self,TFRecDataset):
        Dataset = TFRecDataset.map(lambda entry: self.decode_image(entry))
        return iter(Dataset)



dp=DataParser()  
TFRecDataset=dp.readTFRecs('../input/cassava-tfrecords-512x512')  
Iter=dp.makeDataset(TFRecDataset)  
next(Iter)  
```


Gives the error:


```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-29-f39735f1a1fd> in <module>
      1 dp=DataParser()
      2 TFRecDataset=dp.readTFRecs('../input/cassava-tfrecords-512x512')
----> 3 Iter=dp.makeDataset(TFRecDataset)
      4 next(Iter)

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    844               *args, **kwds)
    845       # If we did not create any variables the trace we have is good enough.
--> 846       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
    847 
    848     def fn_with_cond(*inner_args, **inner_kwds):

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)
   1846                            resource_variable_ops.BaseResourceVariable))],
   1847         captured_inputs=self.captured_inputs,
-> 1848         cancellation_manager=cancellation_manager)
   1849 
   1850   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1922       # No tape is watching; skip to running the function.
   1923       return self._build_call_outputs(self._inference_function.call(
-> 1924           ctx, args, cancellation_manager=cancellation_manager))
   1925     forward_backward = self._select_forward_and_backward_functions(
   1926         args,

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    548               inputs=args,
    549               attrs=attrs,
--> 550               ctx=ctx)
    551         else:
    552           outputs = execute.execute_with_cancellation(

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

InvalidArgumentError: 5 nodes in a cycle [Op:__inference_makeDataset_2557]
```"
46482,Addition of Pull request template,"I noticed that this repository has a issue related template, but is missing PR related template. Adding this will have high value to the community as it will help for first time contributers to navigate through their issue effectively."
46480,get_variable  missing reuse parameter,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
     Yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
    MacOSX 10.14.5 Mojave
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**: pip
-   **TensorFlow version (use command below)**:2.4.0
-   **Python version**: 
python --version
Python 3.6.6 :: Anaconda, Inc.
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```
v2.4.0-rc4-71-g582c8d236cb 2.4.0


### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

tg.get_variable cannot reuse  existing variable.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

tf.get_variable cannot pass in the reuse parameter, see  logs below:

(TensorFlow-LiveLessons) bash-3.2$ python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
v2.4.0-rc4-71-g582c8d236cb 2.4.0


(TensorFlow-LiveLessons) bash-3.2$ python
Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) 
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow.compat.v1 as tf
>>> tf.disable_v2_behavior()
WARNING:tensorflow:From /Users/philren/.local/share/virtualenvs/TensorFlow-LiveLessons-G6MnyUB7/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
>>> n_input = 784
>>> n_dense = 128
>>> W = tf.Variable(tf.random_normal([n_input, n_dense]))
>>> tf.get_variable('W', [n_input, n_dense], \
...                       initializer=tf.keras.initializers.VarianceScaling(
...                       scale=1.0, mode=""fan_avg"",
...                       distribution=""truncated_normal""
...                         ))
<tf.Variable 'W:0' shape=(784, 128) dtype=float32_ref>
>>> tf.get_variable('W', [n_input, n_dense], \
...                       initializer=tf.keras.initializers.VarianceScaling(
...                       scale=1.0, mode=""fan_avg"",
...                       distribution=""truncated_normal""
...                         ))
Traceback (most recent call last):
  File ""<stdin>"", line 4, in <module>
  File ""/Users/philren/.local/share/virtualenvs/TensorFlow-LiveLessons-G6MnyUB7/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 1593, in get_variable
    aggregation=aggregation)
  File ""/Users/philren/.local/share/virtualenvs/TensorFlow-LiveLessons-G6MnyUB7/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 1336, in get_variable
    aggregation=aggregation)
  File ""/Users/philren/.local/share/virtualenvs/TensorFlow-LiveLessons-G6MnyUB7/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 591, in get_variable
    aggregation=aggregation)
  File ""/Users/philren/.local/share/virtualenvs/TensorFlow-LiveLessons-G6MnyUB7/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 543, in _true_getter
    aggregation=aggregation)
  File ""/Users/philren/.local/share/virtualenvs/TensorFlow-LiveLessons-G6MnyUB7/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 893, in _get_single_variable
    (err_msg, """".join(traceback.format_list(tb))))
ValueError: Variable W already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:

  File ""<stdin>"", line 4, in <module>

>>> tf.get_variable('W', [n_input, n_dense], \
...                       initializer=tf.keras.initializers.VarianceScaling(
...                       scale=1.0, mode=""fan_avg"",
...                       distribution=""truncated_normal"",
...                               reuse=tf.AUTO_REUSE))
Traceback (most recent call last):
  File ""<stdin>"", line 5, in <module>
  File ""/Users/philren/.local/share/virtualenvs/TensorFlow-LiveLessons-G6MnyUB7/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 538, in new_func
    return func(*args, **kwargs)
  File ""/Users/philren/.local/share/virtualenvs/TensorFlow-LiveLessons-G6MnyUB7/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 605, in new_func
    return func(*args, **kwargs)
TypeError: __init__() got an unexpected keyword argument 'reuse'
>>> exit()


Digging into the  source code tensorflow/python/ops/variable_scope.py, missing parameter  reuse

@tf_export(v1=[""get_variable""])
def get_variable(name,
                 shape=None,
                 dtype=None,
                 initializer=None,
                 regularizer=None,
                 trainable=None,
                 collections=None,
                 caching_device=None,
                 partitioner=None,
                 validate_shape=True,
                 use_resource=None,
                 custom_getter=None,
                 constraint=None,
                 synchronization=VariableSynchronization.AUTO,
                 aggregation=VariableAggregation.NONE):
  return get_variable_scope().get_variable(
      _get_default_variable_store(),
      name,
      shape=shape,
      dtype=dtype,
      initializer=initializer,
      regularizer=regularizer,
      trainable=trainable,
      collections=collections,
      caching_device=caching_device,
      partitioner=partitioner,
      validate_shape=validate_shape,
      use_resource=use_resource,
      custom_getter=custom_getter,
      constraint=constraint,
      synchronization=synchronization,
      aggregation=aggregation)

if we can add  this  parameter to  the parameter list the above problem could be fixed.
Thanks

# The argument list for get_variable must match arguments to get_local_variable.
# So, if you are updating the arguments, also update arguments to
# get_local_variable below.
@tf_export(v1=[""get_variable""])
def get_variable(name,
                 shape=None,
                 dtype=None,
                 initializer=None,
                 regularizer=None,
                 trainable=None,
                 collections=None,
                 caching_device=None,
                 partitioner=None,
                 validate_shape=True,
                 use_resource=None,
                 custom_getter=None,
                 constraint=None,
                 synchronization=VariableSynchronization.AUTO,
                 aggregation=VariableAggregation.NONE,
                 reuse=None):
  return get_variable_scope().get_variable(
      _get_default_variable_store(),
      name,
      shape=shape,
      dtype=dtype,
      initializer=initializer,
      regularizer=regularizer,
      trainable=trainable,
      collections=collections,
      caching_device=caching_device,
      partitioner=partitioner,
      validate_shape=validate_shape,
      use_resource=use_resource,
      custom_getter=custom_getter,
      constraint=constraint,
      synchronization=synchronization,
      aggregation=aggregation,
      reuse=reuse)

Xiquan Ren"
46479,"Tensorflow issues: Not creating XLA devices, tf_xla_enable_xla_devices not set, This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.","Hi, I've just started to install TensorFlow, and I'm facing some issues. 

I'm trying to use PyCharm, so I installed anaconda and created a virtual environment with the versions being:
Python 3.8.5
pip 20.3.3
tensorflow 2.4.0.

But, I see errors when trying to run a simple tf.constant(""hello"").
The two errors are:

1. I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2. I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.

I've been struggling for a long time...Thanks in advance.
"
46478,"Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 448 but received input with shape (None, 14944)","**Sytem Information:**

- Platform : google colab
- language -python
- library:tensorflow

**Implementation**

- CNN
- sentiment analysis
- text classification

**Code**
```python
from keras.utils import to_categorical
X_train, X_test, Y_train, y_test = train_test_split(X,y, test_size = 0.15, random_state = 42)
Y_train = to_categorical(Y_train.astype(int))
y_test = to_categorical(y_test.astype(int))
model.fit(X_train, Y_train, epochs=10, batch_size=32,verbose = 1,callbacks = callbacks_list,validation_data=(X_test,y_test))

**Error information**
Epoch 1/10
WARNING:tensorflow:Model was constructed with shape (None, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=""created by layer 'embedding_input'""), but it was called on an input with incompatible shape (None, 934).
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-19-3aeda4411868> in <module>()
      6 Y_train = to_categorical(Y_train.astype(int))
      7 y_test = to_categorical(y_test.astype(int))
----> 8 model.fit(X_train, Y_train, epochs=10, batch_size=32,verbose = 1,callbacks = callbacks_list,validation_data=(X_test,y_test))

9 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    975           except Exception as e:  # pylint:disable=broad-except
    976             if hasattr(e, ""ag_error_metadata""):
--> 977               raise e.ag_error_metadata.to_exception(e)
    978             else:
    979               raise

ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **
        outputs = model.train_step(data)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step
        y_pred = self(x, training=True)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__
        outputs = call_fn(inputs, *args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:375 call
        return super(Sequential, self).call(inputs, training=training, mask=mask)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:425 call
        inputs, training=training, mask=mask)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph
        outputs = node.layer(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__
        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility
        ' but received input with shape ' + display_shape(x.shape))

    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 448 but received input with shape (None, 14944)
```"
46477,bazel coverage only generates empty coverage report,"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from: source
- TensorFlow version: 2.1.0
- Python version: 3.6.9
- Installed using : source
- Bazel version (if compiling from source): 0.29.0
- GCC/Compiler version (if compiling from source): gcc 7.5.0
- CUDA/cuDNN version: N
- GPU model and memory: RTX 2080 super



**Describe the problem**
The following command is used to test and get test coverage.
```
bazel coverage -s --instrument_test_targets --coverage_report_generator=@bazel_tools//tools/test:coverage_report_generator --coverage_support=@bazel_tools//tools/test:coverage_support --collect_code_coverage --jobs 5 //tensorflow
```

But I only get `~/tensorflow-2.1.0/bazel-testlogs/tensorflow/tensorflow/baseline_coverage.dat` and the data is only filenames and online `end_of_record`.

I am not sure if it is caused by the wrong command.

"
46475,Memory leak in Conv2D/Activation on GPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary, the standard docker distribution
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.0
- GPU model and memory: GeForce RTX 2070, 8GB

**Describe the current behavior**
I upgraded to TF 2.4.0 from TF 2.1.2, and training a very simple convolutional network, which worked fine in 2.1.2, started running out of memory during training. I distilled a simple reproducible example that demonstrates the issue. Each training epoch consumes about 50MB of additional memory and, given enough epochs, it grows to infinity (or 32 GB in my case). It only occurs on GPU, the same thing runs fine on CPU.

**Describe the expected behavior**
Memory not growing, or growing only very little

**Standalone code to reproduce the issue**
```
import gc
import os
import psutil
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense, Conv2D, Flatten, BatchNormalization, Activation

physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], True)


input_tensor = tf.keras.layers.Input(shape=(512,64,1))

x = Conv2D(filters=32, kernel_size=(5,5), strides=(2,2), padding='same')(input_tensor)
# Commented out on purpose - see Note 1 below
# x = BatchNormalization()(x)
x = Activation('relu')(x)

x = Conv2D(filters=64, kernel_size=(4,4), strides=(2,2), padding='same')(x)
# Commented out on purpose - see Note 1 below
# x = BatchNormalization()(x)
x = Activation('relu')(x)

x = Conv2D(filters=128, kernel_size=(4,4), strides=(2,1), padding='same')(x)
# Commented out on purpose - see Note 1 below
# x = BatchNormalization()(x)
x = Activation('relu')(x)

x = Conv2D(filters=128, kernel_size=(4,4), strides=(2,1), padding='same')(x)
# Commented out on purpose - see Note 1 below
# x = BatchNormalization()(x)
x = Activation('relu')(x)

x = Flatten()(x)

x = Dense(5, activation='sigmoid')(x)

model = tf.keras.Model(inputs=input_tensor, outputs=x)


train_x = np.random.random((2048, 512, 64, 1))
train_y = np.random.random((2048, 5))

model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam())

process = psutil.Process(os.getpid())

for i in range(50):
    model.fit(train_x, train_y, epochs=1, batch_size=32, verbose=0)
    gc.collect()
    print(i, process.memory_info().rss // 1000000)
```

**Note 1**
Now, if you uncomment the BatchNormalization() layers creation, the memory problem disappears. So, it is somehow caused by the Activation layer following immediately the Conv2D

**Note 2**
The memory problem also occurs if I train multiple epochs in a single fit() call, such as 
```
model.fit(train_x, train_y, epochs=50, batch_size=32)
```
I used the for loop only to be able to call garbage collection and print the memory.

**Note 3**
A Conv2D layer with activation embedded in it, such as
```
Conv2D(filters=128, kernel_size=(4,4), strides=(2,1), padding='same', activation='relu')
```
also causes the memory issue



"
46474,"tensorflow.io.gfile.GFile: utf-8 can't decode byte 0xe9 (with both 'r' and 'rb' arguments), while normal open can read the file","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: Windows 10
- TensorFlow installed from: binary via pip
- TensorFlow version: 2.4.0
- Tensorflow IO version: 0.17.0
- Tensorflow datasets: 4.2.0
- Python version: 3.7.7
- CUDA/cuDNN version: 11.2.67/8.0.5.39
- GPU model and memory: GTX 965M/8Gb

**Describe the current behavior**
I am trying to generate a tensorflow dataset using tfds, by following this tutorial: https://www.tensorflow.org/datasets/add_dataset. I do so using the dataset from https://achrafothman.net/site/asl-smt/ (Corpus sample data) which consists of 2 text files, one in English, and the other in American SIgn Language glossed (still text). The files are utf-8-sig encoded, but the same behaviour happens when I save the files as utf-8. Before doing the tfds dataset, I simply opened the file with open, and that worked just fine. However, I am now trying to open them while creating my own dataset, so I import tfds. However, this library raises an error when one uses os.open, saying that we should use its own function, GFile. I then replaced my open with gfile.GFile(filename, 'r'), but it produces the following error when I am running the test (`python -m asgl_dataset.asgl_dataset_test`) (It does pass some tests before raising an error, which I guess are not important to paste here):
```
======================================================================
ERROR: test_download_and_prepare_as_dataset (__main__.AslgDatasetTest)
AslgDatasetTest.test_download_and_prepare_as_dataset
Run the decorated test method.
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""D:\Anaconda\envs\deeplearning_37\lib\site-packages\tensorflow_datasets\testing\test_utils.py"", line 276, in decorated
    f(self, *args, **kwargs)
  File ""D:\Anaconda\envs\deeplearning_37\lib\site-packages\tensorflow_datasets\testing\dataset_builder_testing.py"", line 307, in test_download_and_prepare_as_dataset
    self._download_and_prepare_as_dataset(self.builder)
  File ""D:\Anaconda\envs\deeplearning_37\lib\site-packages\tensorflow_datasets\testing\dataset_builder_testing.py"", line 372, in _download_and_prepare_as_dataset
    builder.download_and_prepare(download_config=download_config)
  File ""D:\Anaconda\envs\deeplearning_37\lib\site-packages\tensorflow_datasets\core\dataset_builder.py"", line 446, in download_and_prepare
    download_config=download_config,
  File ""D:\Anaconda\envs\deeplearning_37\lib\site-packages\tensorflow_datasets\core\dataset_builder.py"", line 1181, in _download_and_prepare
    leave=False,
  File ""D:\Anaconda\envs\deeplearning_37\lib\site-packages\tensorflow_datasets\core\dataset_builder.py"", line 1176, in <listcomp>
    for split_name, generator
  File ""D:\Anaconda\envs\deeplearning_37\lib\site-packages\tensorflow_datasets\core\split_builder.py"", line 295, in submit_split_generation
    return self._build_from_generator(**build_kwargs)
  File ""D:\Anaconda\envs\deeplearning_37\lib\site-packages\tensorflow_datasets\core\split_builder.py"", line 359, in _build_from_generator
    leave=False,
  File ""D:\Anaconda\envs\deeplearning_37\lib\site-packages\tqdm\std.py"", line 1165, in __iter__
    for obj in iterable:
  File ""D:\Anaconda\envs\deeplearning_37\lib\site-packages\tensorflow_datasets\testing\dataset_builder_testing.py"", line 402, in _iter_examples
    for key, ex in generator:
  File ""D:\Documents\Epitech\Gesture\gesturesoftware\src\backend\aslg pc12 dataset\aslg_dataset\aslg_dataset.py"", line 79, in _generate_examples
    english = gfile.GFile('english_processed_utf8.txt', 'rb').read()
  File ""D:\Anaconda\envs\deeplearning_37\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 117, in read
    self._preread_check()
  File ""D:\Anaconda\envs\deeplearning_37\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 80, in _preread_check
    compat.path_to_str(self.__name), 1024 * 512)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 85: invalid continuation byte
```
From my understanding, I think that GFile simply does not handle special characters, such as 'Ã©'. After searching the web, I found that a common solution was to use GFile(filename, 'rb') (instead of 'r', so that the file is read as bytes), but this results in the exact same behavior. 

**Describe the expected behavior**
The files should open properly using GFile, or AT LEAST let the user use open, and let me move on to parse the text they contain so that I can produce my dataset. 

**Standalone code to reproduce the issue**
The files were downloaded from the previously mentioned link (https://achrafothman.net/site/asl-smt/), and then first processed using a small script. The files with '_utf8' in the name were opened with Windows' notepad, and then I used 'saved as', and selected the encoding to be 'utf-8' instead of 'utf-8 without bom'.

Small script:
```python
def delete_end_dots(input_file_name, output_file):
    with open(input_file_name, ""r"", encoding=""utf-8"") as input_f, open(output_file, ""w+"", encoding=""utf-8"") as out_f:
        for line in input_f:
            line = line.strip()
            splitted = line.split("" "")
            if splitted[-1] == '.':
                splitted = splitted[:-1]
            line = "" "".join(splitted)
            print(line, file=out_f)


delete_end_dots(""sample-corpus-asl-en.asl.txt"", ""asl_processed.txt"")
delete_end_dots(""sample-corpus-asl-en.en.txt"", ""english_processed.txt"")
```

aslg_dataset.py:
```python

""""""aslg_dataset dataset.""""""

import sys
print(""started on kernel {}"".format(print(sys.executable)))

import tensorflow_datasets as tfds
import re
import tensorflow.io.gfile as gfile

# TODO(aslg_dataset): Markdown description  that will appear on the catalog page.
_DESCRIPTION = """"""
## ASLG-SMT Dataset 
## by Achraf Othman and Mohamed Jemni
This dataset has 87706 sentences, in both english and American Sign Language, glossed.
We added some processing compared to the original dataset: punctuation is split from the words for english (some sentences did not apply this rule).
we also assert that each word is separated from anything else, for both (e.g. 123word becomes 123 word).
We finally delete any duplicate spaces. 
""""""

# TODO(aslg_dataset): BibTeX citation
_CITATION = """"""@INPROCEEDINGS{8336054,
author={A. {Othman} and M. {Jemni}},
booktitle={2017 6th International Conference on Information and Communication Technology and Accessibility (ICTA)},
title={An XML-gloss annotation system for sign language processing},
year={2017},
volume={},
number={},
pages={1-7},
doi={10.1109/ICTA.2017.8336054}}
""""""


class AslgDataset(tfds.core.GeneratorBasedBuilder):
  """"""DatasetBuilder for aslg_dataset dataset.""""""

  VERSION = tfds.core.Version('1.0.0')
  RELEASE_NOTES = {
      '1.0.0': 'Initial release.',
  }

  def _info(self) -> tfds.core.DatasetInfo:
    """"""Returns the dataset metadata.""""""
    # TODO(aslg_dataset): Specifies the tfds.core.DatasetInfo object
    return tfds.core.DatasetInfo(
        builder=self,
        description=_DESCRIPTION,
        features=tfds.features.FeaturesDict({
            # These are the features of your dataset like images, labels ...
            'input_text': tfds.features.Text(),
            'output_text': tfds.features.Text(),
        }),
        # If there's a common (input, target) tuple from the
        # features, specify them here. They'll be used if
        # `as_supervised=True` in `builder.as_dataset`.
        supervised_keys=None,  # Set to `None` to disable
        citation=_CITATION,
    )

  def _split_generators(self, _):
    """"""Returns SplitGenerators.""""""
    # TODO(aslg_dataset): Downloads the data and defines the splits
    # path = dl_manager.download_and_extract('https://todo-data-url')

    # TODO(aslg_dataset): Returns the Dict[split names, Iterator[Key, Example]]
    return {
        # 'train': self._generate_examples(path / 'train_imgs'),
        'train': self._generate_examples()
    }

  def _generate_examples(self):
    """"""Yields examples.
    File encoding is utf-8-sig""""""
    english = gfile.GFile('english_processed_utf8.txt', 'rb').read() ## I tried to open the file, and then use readlines, but it produces the same error
    asl = gfile.GFile('asl_processed_utf8.txt', 'rb').read() ## '_utf8' in the file name describes the same file as without, except it was saved with an utf-8 encoding instead of utf-8-sig. The exact same behaviour occurs with both files (with and without '_utf8')
    # with open('english_processed.txt', encoding='utf-8-sig') as english_f, open('asl_processed.txt', encoding='utf-8-sig') as asl_f:
    english = [eng for eng in english.split('\n') if eng]
    asl = [a for a in asl.split('\n') if a]
    for i, sentences in enumerate(zip(english, asl)):
      eng_sen, asl_sen = self._clean_sentences(*sentences)
      yield i, {
        'input_text': eng_sen.strip(),
        'output_text': asl_sen.strip()
      }

  @staticmethod
  def _clean_sentences(eng_sen, asl_sen):
    eng = eng_sen.replace(""!"", "" ! "").replace(""."", "" . "").replace("","", "" , "")
    eng = re.sub(r'([\-\'a-zA-ZÃ-ÃÃ-Ã¶Ã¸-Ã¿]+)', r' \1 ', eng)
    eng = re.sub(r' +', ' ', eng)

    asl = re.sub(r'([0-9]+(?:[.][0-9]*)?)', r' \1 ', asl_sen)
    asl = re.sub(r' +', ' ', asl)

    return eng, asl

```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

The directory in which everything happens has been generated using `tfds new`. The only file I modified was the one pasted before, which is the main python file. We then use `tfds build` before running the test."
46471,Use TensorFlow with GPU RTX 3090 support on Windows (not WSL2) ,"Is there a set of instructions for using a RTX 3090 with CUDA and tensorflow python API on windows ? I dont mind what versions I need, or what I have to build etc, I would just like a definitive set of instructions on how to get this working. 

CUDA version
CUDNN version
Tensorflow version
Python version

Thanks. "
46465,Switch TFLM CI to use clang+bazel,"@tensorflow/micro

Using clang instead of gcc with bazel will mirror the internal checks and reduce the likelihood of internal changes breaking the github TFLM CI (e.g. https://github.com/tensorflow/tensorflow/issues/46415).

It will also allow showing the results of the sanitizer builds externally as well.
"
46464,Query: Convert Tensorflow NMT with attention model to tfjs,"I'm following the TensorFlow NMT with attention (link) guide to build a character level transliteration model. I'm able to train the model and make inference calls in an .ipynb notebook. I'm able to save training checkpoints and load them later. However, my front end application is built on electron js. Therefore, I need to convert the encoder-decoder model to tfjs. Would anybody provide some guidance to convert my model to tfjs? I'd be happy to provide source code if needed."
46463,Can't get Tensorflow 2.0 to properly distribute training across multiple GPUs,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Redhat Linux 7.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.0
- Python version: 3.7.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: Cuda 10.1/cuDNN 7.6.5
- GPU model and memory: 2x Titan RTX, 24gb each



**Describe the problem**
I have two GPUs, both of which are visible to Tensorflow (and Tensorflow confirms this). However, when I try to train a model using a mirrored strategy it only trains a tiny bit on the second GPU. If I make the first GPU invisible with `export CUDA_VISIBLE_DEVICES=1`, then it will actually train on the second GPU. So I know it is capable of training on both. Furthermore, if I start a model training on the first GPU and then do `export CUDA_VISIBLE_DEVICES=1` and try to train another model, it will train on the second GPU. So I know that Tensorflow can find both GPUs and can train on both GPUs and can have both GPUs training at the same time, but I cannot get it to properly train a single model on both GPUs. 

Running `export CUDA_VISIBLE_DEVICES=0,1` does nothing; Tensorflow will still only train a tiny bit on the second GPU. 


**Provide the exact sequence of commands / steps that you executed before running into the problem**
As stated above, I first ran `export CUDA_VISIBLE_DEVICES=0,1`. I have also tried training without running this command first. The exact code I am using to build my model is below. I have a convolutional neural network called FullModel():
```python
strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    net = FullModel()

for epoch in range(100):
    # Custom training loop
```
I have also tried the following:
```python
strategy = tf.distribute.MirroredStrategy(devices=[""/gpu:0"", ""/gpu:1""])
with strategy.scope():
    net = FullModel()
```


**Any other info / logs**
The output of `nvidia-smi` right after beginning training:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.82       Driver Version: 440.82       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN RTX           Off  | 00000000:1B:00.0 Off |                  N/A |
| 52%   70C    P2   199W / 280W |  23537MiB / 24220MiB |     51%      Default |
+-------------------------------+----------------------+----------------------+
|   1  TITAN RTX           Off  | 00000000:68:00.0 Off |                  N/A |
| 41%   47C    P8     4W / 280W |    262MiB / 24219MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     14382      C   python                                     23525MiB |
|    1      3337      G   /usr/bin/X                                    27MiB |
|    1      4783      G   /usr/bin/gnome-shell                          58MiB |
|    1     14382      C   python                                       163MiB |
+-----------------------------------------------------------------------------+
```
Notice that job 14382 IS doing something on GPU 1. But it is only taking up 163mb on that GPU. I thought that maybe I just could train in larger batches or something to maximize my available GPU memory but that doesn't seem to change the situation. For some reason it just isn't using all of that GPU.

The output of `nvidia-smi` after I run `export CUDA_VISIBLE_DEVICES=1` and start another job training:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.82       Driver Version: 440.82       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN RTX           Off  | 00000000:1B:00.0 Off |                  N/A |
| 53%   71C    P2   136W / 280W |  23537MiB / 24220MiB |     43%      Default |
+-------------------------------+----------------------+----------------------+
|   1  TITAN RTX           Off  | 00000000:68:00.0 Off |                  N/A |
| 41%   62C    P2   246W / 280W |  23499MiB / 24219MiB |     75%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     14382      C   python                                     23525MiB |
|    1      3337      G   /usr/bin/X                                    27MiB |
|    1      4783      G   /usr/bin/gnome-shell                          58MiB |
|    1     14382      C   python                                       163MiB |
|    1     19376      C   python                                     23237MiB |
+-----------------------------------------------------------------------------+
```
"
46462,Tensorflow Lite OpenCL delegate outputs NaN's when CPU works fine,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 11
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy S20 w/ Qualcomm chipset
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): Nightly
- Python version: 3.6
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 8.4
- CUDA/cuDNN version: N/A
- GPU model and memory: Adreno 650

**Describe the current behavior**
For my model, the CPU (with or without XNNPACK delegate) produces the correct outputs on Snapdragon 865. However, some of the outputs from the OpenCL GPU delegate are completely wrong. I see NaN's and numbers like 5.83379e+29 in some of the output tensors in the network. The model has more than 1 output, other output tensors of the same model , however, show entirely correct results.

As far as I am aware, I have turned off FP16 optimizations so that model runs at full 32 bit floating point precision:

        TfLiteGpuDelegateOptionsV2 options;
        options.is_precision_loss_allowed = 0;
        options.inference_preference = TFLITE_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER;
        options.inference_priority1 = TFLITE_GPU_INFERENCE_PRIORITY_MAX_PRECISION;
        options.inference_priority2 = TFLITE_GPU_INFERENCE_PRIORITY_AUTO;
        options.inference_priority3 = TFLITE_GPU_INFERENCE_PRIORITY_AUTO;
 
**Describe the expected behavior**
CPU outputs and GPU delegate outputs should match.

**Standalone code to reproduce the issue**
You can find the C++ sample code (along with the .tflite model, the original Keras model, Keras->TFLite conversion script, complete sample output from CPU and OpenCL GPU) that reproduces this error at https://github.com/DwayneDuane/tensorflow_lite_opencl_bug
"
46461,"Doc : keras.utils.plot_model prints the shape as (None, n) but outdated (?, n) is given in doc  ","## URL(s) with the issue:

https://www.tensorflow.org/guide/keras/functional

## Description of issue (what needs changing):

keras.utils.plot_model prints the shape as (None, n) but given in doc as (?, n)

### Clear description

Watch the line `keras.utils.plot_model(model, ""my_first_model_with_shape_info.png"", show_shapes=True)` in the doc link provided above.The output shown there is outdated

### Correct links

[Gist](https://colab.research.google.com/drive/19dlb-Qcoo2EBDigpZ8E75cb63woYI_EI?usp=sharing) here to show the changes.
Tensorflow version: 2.4

### Submit a pull request?
 Yes

"
46460,tensorflow/core/kernels/sparse_matmul_op_test segfaults due to wrong alignment,"Using TensorFlow 2.4.0 on an x86 system with GCC 8.3.0

**Describe the current behavior**

The test code has an over-aligned class: https://github.com/tensorflow/tensorflow/blob/f18495306f26fa2e1d3351c03838cde265eb6690/tensorflow/core/kernels/sparse_matmul_op_test.cc#L265-L327

As this is used as a test fixture in https://github.com/tensorflow/tensorflow/blob/f18495306f26fa2e1d3351c03838cde265eb6690/tensorflow/core/kernels/sparse_matmul_op_test.cc#L329 this class is allocated via `new` by GoogleTest

In C++14 this is not supported, in C++17 it is. See the GCC manual for e.g.:
```
'-Waligned-new'
     Warn about a new-expression of a type that requires greater
     alignment than the 'alignof(std::max_align_t)' but uses an
     allocation function without an explicit alignment parameter.  This
     option is enabled by '-Wall'.
```

Also compare the results at https://gcc.godbolt.org/z/PnnceM

As the result the class may not be aligned correctly and create a segfault when running https://github.com/tensorflow/tensorflow/blob/f18495306f26fa2e1d3351c03838cde265eb6690/tensorflow/core/kernels/sparse_matmul_op_test.cc#L330 (which GCC vectorizes assuming the alignment)

I have found that the alignment of the class varies based on even the folder where the binary is run from. So reproducing requires a bit of experimenting but the above descriptions should make it clear that this is fragile.

**Other info / logs**

I suggest to enable the `-Waligned-new` as an error to catch such mistakes in the future.
A workaround here is to enable the GCC flag `-faligned-new` which provides the C++17 `new` functions. Alternatively moving those fields out of the class will also work."
46459,Sparse IndexedSlices warning due to tf.gather() and LossScaleOptimizer,"**System information**

    Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
    OS Platform and Distribution: Ubuntu 18.04.5 LTS
    TensorFlow installed from: binary
    TensorFlow version: 2.2.0
    Python version: 3.6.9
    CUDA/cuDNN version: 10.1.243 / 7.6.5
    GPU model and memory: NVidia Tesla V100-SXM2-32GB

**Describe the current behavior**
Use `tf.gather()` with `LossScalerOptimizer` triggers this warning:

`/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.`

A fix (see colab notebook) using `tf.gather_nd()` removes the warning but breaks `saved_model_cli`.

**Describe the expected behavior**
The warning is unexpected (why does it appear only when using `LossScaleOptimizer` ?)  
The fix is not expected to trigger a `saved_model_cli` error

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1vNX8ssp3nUTY_YOOml-ZfAa5yzPVHkl_?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
Possibly related issues:
- https://github.com/tensorflow/tensorflow/issues/38168
- https://github.com/tensorflow/tensorflow/issues/36948
"
46458,TypeError: An op outside of the function building code is being passed,"Following the [documentation](https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic) I re-arranged functions into a class, I changed the model and made a few other modifications, however the code fails to work if `tf.function` is enabled, otherwise it works perfectly fine. By commenting out line 97, the error is gone:

    self.model.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))

**Error**

    Traceback (most recent call last):
      File ""/Users/emadboctor/Desktop/code/drl-algos/a2c.py"", line 109, in <module>
        agn.fit()
      File ""/Users/emadboctor/Desktop/code/drl-algos/a2c.py"", line 103, in fit
        self.train_step()
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 828, in __call__
        result = self._call(*args, **kwds)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 888, in _call
        return self._stateless_fn(*args, **kwds)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2942, in __call__
        return graph_function._call_flat(
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 1918, in _call_flat
        return self._build_call_outputs(self._inference_function.call(
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 555, in call
        outputs = execute.execute(
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 75, in quick_execute
        raise e
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 59, in quick_execute
        tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
    TypeError: An op outside of the function building code is being passed
    a ""Graph"" tensor. It is possible to have Graph tensors
    leak out of the function building context by including a
    tf.init_scope in your function building code.
    For example, the following function will fail:
      @tf.function
      def has_init_scope():
        my_constant = tf.constant(1.)
        with tf.init_scope():
          added = my_constant * 2
    The graph tensor has name: while:4

**Code**

    import gym
    import numpy as np
    import tensorflow as tf
    from tensorflow.keras.layers import Conv2D, Dense, Flatten, Input
    from tensorflow.keras.losses import Huber
    from tensorflow.keras.models import Model
    from tensorflow.keras.optimizers import Adam


    class A2C:
        def __init__(self, env, gamma=0.99, fc_units=512):
            self.env = env
            self.available_actions = env.action_space.n
            self.model = self.create_model(fc_units)
            self.state = tf.cast(self.env.reset(), tf.float32)
            self.gamma = gamma
            self.division_eps = np.finfo(np.float32).eps.item()
            self.loss = Huber(reduction=tf.keras.losses.Reduction.SUM)
    
        def create_model(self, fc_units):
            x0 = Input(self.env.observation_space.shape)
            x = Conv2D(32, 8, 4, activation='relu')(x0)
            x = Conv2D(64, 4, 2, activation='relu')(x)
            x = Conv2D(32, 3, 1, activation='relu')(x)
            x = Flatten()(x)
            x = Dense(fc_units, activation='relu')(x)
            actor = Dense(self.available_actions)(x)
            critic = Dense(1)(actor)
            model = Model(x0, [actor, critic])
            model.call = tf.function(model.call)
            return model
    
        def env_step(self, action):
            state, reward, done, _ = self.env.step(action)
            return (
                state.astype(np.float32),
                np.array(reward, np.int32),
                np.array(done, np.int32),
            )
    
        def tf_env_step(self, action):
            return tf.numpy_function(
                self.env_step, [action], [tf.float32, tf.int32, tf.int32]
            )
    
        def get_returns(self, rewards, standardize=True):
            n = tf.shape(rewards)[0]
            returns = tf.TensorArray(dtype=tf.float32, size=n)
            rewards = tf.cast(rewards[::-1], dtype=tf.float32)
            discounted_sum = tf.constant(0.0)
            discounted_sum_shape = discounted_sum.shape
            for i in tf.range(n):
                reward = rewards[i]
                discounted_sum = reward + self.gamma * discounted_sum
                discounted_sum.set_shape(discounted_sum_shape)
                returns = returns.write(i, discounted_sum)
            returns = returns.stack()[::-1]
            if standardize:
                returns = (returns - tf.math.reduce_mean(returns)) / (
                    tf.math.reduce_std(returns) + self.division_eps
                )
            return returns
    
        def play_episode(self, max_steps=10000):
            action_probs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)
            values = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)
            rewards = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)
            initial_shape = self.state.shape
            for i in tf.range(max_steps):
                actor_out, value = self.model(tf.expand_dims(self.state, 0))
                action = tf.random.categorical(actor_out, 1)[0, 0]
                action_prob = tf.nn.softmax(actor_out)
                self.state, reward, done = self.tf_env_step(action)
                self.state.set_shape(initial_shape)
                action_probs = action_probs.write(i, action_prob[0, action])
                values = values.write(i, tf.squeeze(value))
                rewards = rewards.write(i, reward)
                if tf.cast(done, tf.bool):
                    self.state = tf.cast(self.env.reset(), tf.float32)
                    break
            return [item.stack() for item in [action_probs, values, rewards]]
    
        def compute_loss(self, returns, values, action_probs):
            advantage = returns - values
            action_log_probs = tf.math.log(action_probs)
            actor_loss = -tf.math.reduce_sum(action_log_probs * advantage)
            critic_loss = self.loss(values, returns)
            return actor_loss + critic_loss
    
        @tf.function
        def train_step(self):
            with tf.GradientTape() as tape:
                action_probs, values, rewards = self.play_episode()
                returns = self.get_returns(rewards)
                loss = self.compute_loss(returns, values, action_probs)
            grads = tape.gradient(loss, self.model.trainable_variables)
            self.model.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))
            episode_reward = tf.math.reduce_sum(rewards)
            return episode_reward
    
        def fit(self, learning_rate=7e-4):
            self.model.compile(optimizer=Adam(learning_rate))
            self.train_step()
    
    
    if __name__ == '__main__':
        gym_env = gym.make('PongNoFrameskip-v4')
        agn = A2C(gym_env)
        agn.fit()
"
46456,Two SavedModel roundtrips lose track of a Resource's initializer and its assets,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): any
- TensorFlow installed from (source or binary): either
- TensorFlow version (use command below): 2.4.0, nightly
- Python version: any

**Describe the current behavior**
 1) Creating `MyLookupModel` as below and doing tf.saved_model.save, load on it recreates the `._vocab_table._initializer` but does not track it as a trackable subobject of `._vocab_table`.
 2) Doing tf.saved_model.save, load once more initializes the `._vocab_table` from the vocab file asset of the first SavedModel, not the second SavedModel - or crashes, if the first SavedModel is no longer available.

Item 1 appears to be a general issue with restored resource objects (not peculiar to StaticHashTable), and item 2 appears to be a direct consequence of it.

The end-to-end effect of this was reported in issue https://github.com/tensorflow/hub/issues/719 for a first SavedModel stored on TF Hub and a second SavedModel built from it by the user (with more parts added, and using Keras, but that seems immaterial).

**Describe the expected behavior**
 1) Saving and restoring `MyLookupModel` recreates the `._vocab_table._initializer` and tracks it as a trackable subobject of `._vocab_table`.
 2) Saving and restoring the model once more initializes the `._vocab_table` from the vocab file asset of the second SavedModel - with no need for the first SavedModel to be available in that time and place.

**Standalone code to reproduce the issue**

See also b/177326279

```python
class MyLookupModel(tf.train.Checkpoint):
  def __init__(self, vocab_file):
    super().__init__()
    vocab_initializer = tf.lookup.TextFileInitializer(
        vocab_file,
        key_dtype=tf.string, key_index=tf.lookup.TextFileIndex.WHOLE_LINE,
        value_dtype=tf.int64, value_index=tf.lookup.TextFileIndex.LINE_NUMBER)
    self._vocab_table = tf.lookup.StaticHashTable(vocab_initializer,
                                                  default_value=-1)

  @tf.function(input_signature=[tf.TensorSpec((None,), tf.string)])
  def __call__(self, inputs):
    return self._vocab_table.lookup(inputs)

ORIGINAL_VOCAB = ""/tmp/original/vocab.txt""
tf.io.gfile.makedirs(os.path.dirname(ORIGINAL_VOCAB))
with tf.io.gfile.GFile(ORIGINAL_VOCAB, ""w"") as f:
  for x in [""a"", ""b"", ""c"", ""d""]:
    f.write(x + ""\n"")

model0 = MyLookupModel(ORIGINAL_VOCAB)
tf.saved_model.save(model0, ""/tmp/model1"")
model1 = tf.saved_model.load(""/tmp/model1"")
tf.saved_model.save(model1, ""/tmp/model2"")
# If ""/tmp/model1/assets/vocab.txt"" is deleted at this point, the next line crashes.
model2 = tf.saved_model.load(""/tmp/model2"") 
```
"
46455,Import Issue of cross-built tflite package,"System information

Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 x86_64 amd64 PC
TensorFlow installed from (source or binary): v2.4
Tensorflow version (commit SHA if source): 582c8d2
Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): RK3399 Ubuntu 18.04 aarch64


Describe the problem:

I built the tflite runtime whl on host PC and tried to import the whl package file in python 3.7.
But I met the following issue.

![image](https://user-images.githubusercontent.com/47862419/104740652-264f5e00-5783-11eb-8add-5d517757adf2.png)

Host PC environment:
OS: Ubuntu 18.04 x86_64 AMD64
native gcc(g++): 7.5.0
ldd: 2.27 
cross-compiler aarch64-linux-gnu-gcc(aarch64-linux-gnu-g++): 8.3.0 (This is downloaded and used automatically when building )
bazel: 3.1.0
python: virtual env python 3.7

Target device environment:
OS: Ubuntu 18.04 LTS aarch64
native gcc(g++): 7.5.0
ldd: 2.27
python: 3.7

Please provide the exact sequence of commands/steps when you ran into the problem

I followed the following steps on my host PC.

sudo apt update
sudo apt-get install software-properties-common
sudo apt update
sudo apt install git curl
sudo apt install python3.7 python3.7-dev python3.7-venv python3.7-distutils
sudo apt install mesa-common-dev libegl1-mesa-dev libgles2-mesa-dev

cd ~
python3.7 -m venv py37
source ~/py37/bin/activate
pip install cython
pip install wheel
pip install numpy

git clone -b r2.4 https://github.com/tensorflow/tensorflow.git tensorflow_r2.4
cd tensorflow_r2.4
python configure.py

![image](https://user-images.githubusercontent.com/47862419/104741092-b2fa1c00-5783-11eb-81a2-7315f1660250.png)

./tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh aarch64

The whl file ""tflite_runtime-2.4.0-py3-none-linux_aarch64.whl"" is outputted in the folder ""tensorflow_r2.4/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3/dist"".

When importing the tflite run-time package on the target device platform, The issue occurs.

from tflite_runtime.interpreter import Interpreter


"
46454,No estimated time using model.fit() with TFRecord Dataset.,"There is no estimated time when I call model.fit() with TFRecord Dataset.

```
   2448/Unknown - 894s 364ms/step - loss: 0.0703
```"
46453,TensorRT converter fails for CombinedNonMaxSuppression,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04**
- TensorFlow installed from (source or binary): **Binary**
- TensorFlow version (use command below): **TF:2.5.0-dev20210114**
- Python version: **3.7**
- CUDA/cuDNN version: **11.0, 8.0.4**
- GPU model and memory: **1060**

**Describe the current behavior**
TensorRT converter crashes with a segmentation fault when I try to export my `saved_model`.
Interestingly, if I set `minimum_segment_size=10`, it works because it skips 

*Replaced segment 5 consisting of 7 nodes by StatefulPartitionedCall/decode_predictions/TRTEngineOp_0_5.
2021-01-15 15:21:38.915310: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:858] Segment consists of nodes: StatefulPartitionedCall/decode_predictions/combined_non_max_suppression/CombinedNonMaxSuppression, StatefulPartitionedCall/decode_predictions/combined_non_max_suppression/CombinedNonMaxSuppression/max_output_size_per_class, StatefulPartitionedCall/decode_predictions/combined_non_max_suppression/Const, StatefulPartitionedCall/decode_predictions/combined_non_max_suppression/iou_threshold, StatefulPartitionedCall/decode_predictions/combined_non_max_suppression/score_threshold, StatefulPartitionedCall/decode_predictions/transpose_1, StatefulPartitionedCall/decode_predictions/transpose_1/perm*

I have attached the full log after running with these flags
`TF_CPP_VMODULE=trt_engine_op=2,convert_nodes=2,convert_graph=2,segment=2,trt_shape_optimization_profiles=2,trt_engine_resource_ops=2 python trt.py`

**Standalone code to reproduce the issue**
```python
import os

import tensorflow as tf

## Download and extract the zip 
## URL: https://drive.google.com/file/d/1Zxqdnm2iHpJGdUl17cAi-lV7wZ3UhMDA/view

params = tf.experimental.tensorrt.ConversionParams(
    precision_mode='FP32',
    maximum_cached_engines=1,
    minimum_segment_size=5)

converter = tf.experimental.tensorrt.Converter(
    input_saved_model_dir='retinanet-18-640-30x-64-tpu',
    conversion_params=params)
converter.convert()

def input_fn(steps=1):
    for i in range(steps):
        yield (tf.random.uniform([640, 640, 3]), tf.constant(1, dtype=tf.int32))
        
converter.build(input_fn=input_fn)
converter.save('trt')
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
[trt_log.txt](https://github.com/tensorflow/tensorflow/files/5819748/trt_log.txt)
"
46450,unable to load weights from directories other than the working directory,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  binary
- TensorFlow version (use command below): tf-nightly-gpu v2.5.0.dev20201214
- Python version: 3.8.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA v11.0
- GPU model and memory: Tesla T4 15109MiB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
If i use model.load_weights(dir) and specify a directory similarly to how it's done in the docs:

checkpoint_filepath = ""./checkpoints/training_checkpoints_tests/cp.ckpt""
checkpoint_dir = os.path.dirname(checkpoint_filepath)

 if os.path.exists(checkpoint_dir):
            model.load_weights(checkpoint_filepath)
            print('Checkpoints loaded')
        else:
            !mkdir -p './checkpoints/training_checkpoints_tests'
            print('No checkpoints found')

however the script never actually reads into the directory i'm specifying. If i instead load checkpoints directly from the working directory:

checkpoint_filepath = ""/training_checkpoints_tests/cp.ckpt""
checkpoint_dir = os.path.dirname(checkpoint_filepath)

 if os.path.exists(checkpoint_dir):
            model.load_weights(checkpoint_filepath)
            print('Checkpoints loaded')
        else:
            !mkdir -p '/training_checkpoints_tests'
            print('No checkpoints found')

it works no problem. This second approach is fine if you have few models or checkpoints, but the direcotry quickly fills with folders and folders of checkpoints of different models and runs and it'd be better to keep all checkpoint in a folder

**Describe the expected behavior**
load checkpoints from sub-directories

**Standalone code to reproduce the issue**
See above
"
46449,no kernel image is available for execution on the device,"
**System information**
- I have  written custom code to YOLO V4:
- In Windows 10:
- TensorFlow version (use command below): 2.3.1
- Python version: 3.7.9

- CUDA/cuDNN version: CUDA 10.1 with cuDNN == cudnn-10.1-windows10-x64-v7.6.4.38
- GPU model and memory: NVIDIA GEFORCE 940MX [In acer E5 laptop]

I have got error like this 
`2021-01-15 13:27:54.527065: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2021-01-15 13:28:41.927373: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2021-01-15 13:28:42.898934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce 940MX computeCapability: 5.0
coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 29.80GiB/s
2021-01-15 13:28:42.899439: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2021-01-15 13:28:44.140267: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2021-01-15 13:28:45.049662: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2021-01-15 13:28:45.267345: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2021-01-15 13:28:48.207716: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2021-01-15 13:28:49.165815: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2021-01-15 13:28:52.588923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2021-01-15 13:28:52.878248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
GPUs [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Loading Darknet_weights from: ../model_data/yolov3.weights
2021-01-15 13:28:53.793044: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-01-15 13:28:53.950440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x11f09ecb740 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-01-15 13:28:53.950804: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-15 13:28:54.109305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce 940MX computeCapability: 5.0
coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 29.80GiB/s
2021-01-15 13:28:54.109697: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2021-01-15 13:28:54.109873: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2021-01-15 13:28:54.110285: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2021-01-15 13:28:54.110996: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2021-01-15 13:28:54.111835: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2021-01-15 13:28:54.112742: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2021-01-15 13:28:54.113099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2021-01-15 13:28:54.113452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-01-15 13:28:54.927364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-15 13:28:54.927667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-01-15 13:28:54.927788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-01-15 13:28:54.928260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1464 MB memory) -> physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0)
2021-01-15 13:28:54.953337: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x11f1afa1690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-01-15 13:28:54.953588: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce 940MX, Compute Capability 5.0
2021-01-15 13:28:54.979368: I tensorflow/core/common_runtime/eager/execute.cc:611] Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0
2021-01-15 13:28:55.014682: F .\tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: no kernel image is available for execution on the device

Process finished with exit code -1073740791 (0xC0000409)`

I have mention about my hardware in above.I have states I have mention about my hardware in above. Any help would be greatly appreciated"
46447,Make tf.image.resize compatible with XLA compilation,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.4
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

Currently, XLA compilation does not work for `tf.image.resize` when method is `tf.image.ResizeMethod.BILINEAR` or `tf.image.ResizeMethod.NEAREST_NEIGHBOR.` Because `half_pixel_centers` is forced to true [here](https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/ops/image_ops_impl.py#L1623-L1627), but the tf2xla kernel forces `half_pixel_centers` to false [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/kernels/image_resize_ops.cc#L592).

This makes users unable to do upsampling/downsampling for images on TPU.

**Will this change the current api? How?**

No, just change underlying behavior.

**Who will benefit with this feature?**

Everyone who needs to use down/up sampling method for XLA.

**Any Other info.**

Colab to reproduce errors.

https://colab.research.google.com/drive/1RKW1U3pqoc7w58ifq0qjb6WqBJQ3cD9V?usp=sharing
"
46444,Spurious results from a full-integer TensorFlow Lite model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.5.0-dev20210114 (`tf-nightly`)
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

I have been able to convert the [Boundless model](https://tfhub.dev/s?q=google%2Fboundless) with full integer quantization. However, the results of the model are spurious. 

**Describe the expected behavior**

The result should be consistent with the results from other TFLite variants of the same model. 

Here's the expected result - 

![image](https://user-images.githubusercontent.com/22957388/104683094-3bdd6d00-571c-11eb-87fa-f927b3c5a713.png)

The masked and the generated images are from the model. 

Here's the result from the integer model - 

![image](https://user-images.githubusercontent.com/22957388/104683131-4f88d380-571c-11eb-9655-5ce8f2f49fc2.png)

Notice how the masked and the generated images are spurious. Is this because I am constructing the representative dataset to only have 50 examples? Is the converter not able to appropriately approximate the activation ranges? 

**Standalone code to reproduce the issue**

Colab Notebook https://colab.research.google.com/gist/sayakpaul/5f52b65c849e751e81e4073d6cf737bf/boundless_tflite.ipynb

Cc: @abattery 
"
46443,An issue on cross-building Tensorflow Lite for Python,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 x86_64 amd64 PC
- TensorFlow installed from (source or binary): v2.4
- Tensorflow version (commit SHA if source): 582c8d2
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): RK3399 Ubuntu 18.04 aarch64

**Describe the problem**
I am going to get tflite whl for Python3 on aarch64.
So I tried to cross-build tflite whl on Ubuntu 18.04 x86_64 host PC.
But while compiling the source I met the following issue.

![image](https://user-images.githubusercontent.com/47862419/104678949-87494880-5727-11eb-9b5d-850b3e81bf9d.png)

Host PC environment:
OS: Ubuntu 18.04 x86_64 AMD64
native gcc(g++): 7.5.0
cross-compiler aarch64-linux-gnu-gcc(aarch64-linux-gnu-g++): 7.5.0
bazel: 3.1.0
python: virtual env python 3.7

**Please provide the exact sequence of commands/steps when you ran into the problem**

I followed the following steps on my host PC.

sudo apt update
sudo apt-get install software-properties-common
sudo apt update
sudo apt install git curl
sudo apt install python3.7 python3.7-dev python3.7-venv python3.7-distutils
sudo apt install mesa-common-dev libegl1-mesa-dev libgles2-mesa-dev

cd ~
python3.7 -m venv py37
source ~/py37/bin/activate
pip install cython
pip install wheel
pip install numpy

git clone -b r2.4 https://github.com/tensorflow/tensorflow.git tensorflow_r2.4
cd tensorflow_r2.4
python configure.py
![image](https://user-images.githubusercontent.com/47862419/104679377-81079c00-5728-11eb-9f23-a9bd0a3f8ff9.png)

./tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh aarch64

"
46442,Can't link against TensorFlowLiteC.framework (iOS) when built on recent TF versions (regression),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OSX 11.1
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): master
- Python version: 3.8.2
- Bazel version (if compiling from source): 3.7.2 and 3.1.0
- GCC/Compiler version (if compiling from source): clang 12.0.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

It looks like there might be a regression in the build system responsible for generating the `TensorFlowLiteC.framework` iOS library. I've bisected it to 3e9fccb0cb9a, which is a little odd since that's just a bazel version bump... I'm using [am15h/tflite_flutter_plugin](https://github.com/am15h/tflite_flutter_plugin) (which binds directly to the TFLite C API) and can build my own `TensorFlowLiteC.framework` successfully and use it with that plugin up until the aforementioned commit.

From 3e9fccb0cb9a forward (bisection script provided below) I get the following link errors:

<details>
  <summary>Build output</summary>

```
$ flutter build ios
Warning: You are using these overridden dependencies:
! tflite_flutter 0.5.0 from path external/tflite_flutter_plugin
Running ""flutter pub get"" in RoutespotterApp...                     0.7s
Building com.mgalgs.routespotter for device (ios-release)...
Automatically signing iOS for device deployment using specified development team in Xcode project: PH2D8HJC83
Running pod install...                                              2.3s
Running Xcode build...
Xcode build done.                                            4.3s
Failed to build iOS app
Error output from Xcode build:
â³
    ** BUILD FAILED **


Xcode's output:
â³
    Undefined symbols for architecture arm64:
      ""tflite::tensor_utils::MatrixBatchVectorMultiplyAccumulate(signed char const*, int, int, signed char const*, float const*, int, int*, float*,
      tflite::CpuBackendContext*)"", referenced from:
          l4840 in TensorFlowLiteC
      ""tflite::ops::builtin::Register_FLOOR()"", referenced from:
          l4485 in TensorFlowLiteC
      ""tflite::ops::custom::Register_MFCC()"", referenced from:
          l4485 in TensorFlowLiteC
      ""_xnn_reallocate"", referenced from:
          l4440 in TensorFlowLiteC
      ""_xnn_aligned_allocate"", referenced from:
          l4440 in TensorFlowLiteC
      ""_xnn_aligned_deallocate"", referenced from:
          l4440 in TensorFlowLiteC
      ""flatbuffers::EnsureDirExists(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)"", referenced from:
          l3532 in TensorFlowLiteC
      ""flatbuffers::FileExists(char const*)"", referenced from:
          l2367 in TensorFlowLiteC
      ""flatbuffers::LoadFile(char const*, bool, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >*)"", referenced from:
          l2367 in TensorFlowLiteC
      ""flatbuffers::AbsolutePath(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)"", referenced from:
          l2254 in TensorFlowLiteC
      ""tflite::tensor_utils::VectorBatchVectorCwiseProductAccumulate(short const*, int, short const*, int, int, int, short*)"", referenced from:
          l1730 in TensorFlowLiteC
      ""tflite::tensor_utils::VectorScalarMultiply(signed char const*, int, float, float*)"", referenced from:
          l1729 in TensorFlowLiteC
      ""tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)"", referenced from:
          l1728 in TensorFlowLiteC
          l1729 in TensorFlowLiteC
      ""tflite::tensor_utils::CwiseClipping(short*, int, short)"", referenced from:
          l1727 in TensorFlowLiteC
          l1731 in TensorFlowLiteC
      ""tflite::tensor_utils::MatrixBatchVectorMultiply(signed char const*, int, signed char const*, int, int, int, int, int, signed char*, signed char)"", referenced from:
          l1727 in TensorFlowLiteC
      ""tflite::tensor_utils::TwoGateSaturatingAdd(signed char const*, signed char, signed char const*, signed char, int, int, int, int, int, int, short*)"", referenced from:
          l1727 in TensorFlowLiteC
      ""tflite::tensor_utils::ApplySigmoidFloat(short const*, int, int, short*)"", referenced from:
          l1727 in TensorFlowLiteC
      ""tflite::tensor_utils::CwiseMul(short const*, short const*, int, int, int, short*)"", referenced from:
          l1727 in TensorFlowLiteC
          l1731 in TensorFlowLiteC
      ""tflite::tensor_utils::ApplyTanhFloat(short const*, int, int, int, short*)"", referenced from:
          l1727 in TensorFlowLiteC
      ""tflite::tensor_utils::ApplyTanh(int, short const*, int, int, short*)"", referenced from:
          l1726 in TensorFlowLiteC
          l1730 in TensorFlowLiteC
      ""tflite::tensor_utils::CwiseMul(short const*, short const*, int, int, int, int, int, signed char*)"", referenced from:
          l1726 in TensorFlowLiteC
      ""flatbuffers::StripExtension(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)"", referenced from:
          l814 in TensorFlowLiteC
          l1889 in TensorFlowLiteC
          l3564 in TensorFlowLiteC
      ""tflite::tensor_utils::MatrixBatchVectorMultiplyAccumulate(signed char const*, int const*, signed char const*, int, int, int, int, int, int, int*, signed char*,
      tflite::CpuBackendContext*)"", referenced from:
          l1726 in TensorFlowLiteC
      ""tflite::tensor_utils::CwiseClipping(float*, int, float)"", referenced from:
          l1722 in TensorFlowLiteC
          l1724 in TensorFlowLiteC
      ""tflite::Subgraph::HasDelegates()"", referenced from:
          l1472 in TensorFlowLiteC
      ""tflite::Subgraph::IsCancelled()"", referenced from:
          l1469 in TensorFlowLiteC
      ""tflite::tensor_utils::AsymmetricQuantizeFloats(float const*, int, signed char*, float*, int*)"", referenced from:
          l278 in TensorFlowLiteC
          l290 in TensorFlowLiteC
          l414 in TensorFlowLiteC
          l1254 in TensorFlowLiteC
          l1417 in TensorFlowLiteC
          l1724 in TensorFlowLiteC
          l4108 in TensorFlowLiteC
          ...
      ""tflite::Subgraph::SetExecutionPlan(std::__1::vector<int, std::__1::allocator<int> > const&)"", referenced from:
          l1465 in TensorFlowLiteC
      ""tflite::tensor_utils::ApplyLayerNorm(short const*, short const*, int const*, int, int, int, int, int, short*)"", referenced from:
          l1726 in TensorFlowLiteC
          l1730 in TensorFlowLiteC
      ""_xnn_deallocate"", referenced from:
          l4440 in TensorFlowLiteC
      ""tflite::Subgraph::SetTensorParametersReadWrite(int, TfLiteType, char const*, unsigned long, int const*, TfLiteQuantization, bool, unsigned long, int const*)"",
      referenced from:
          l1462 in TensorFlowLiteC
          l1464 in TensorFlowLiteC
          l3451 in TensorFlowLiteC
      ""tflite::Subgraph::SetTensorParametersReadOnly(int, TfLiteType, char const*, unsigned long, int const*, TfLiteQuantization, char const*, unsigned long,
      tflite::Allocation const*, TfLiteSparsity*)"", referenced from:
          l1461 in TensorFlowLiteC
          l1463 in TensorFlowLiteC
          l3451 in TensorFlowLiteC
      ""tflite::Subgraph::AddTensors(int, int*)"", referenced from:
          l1459 in TensorFlowLiteC
          l3454 in TensorFlowLiteC
      ""flatbuffers::SaveFile(char const*, char const*, unsigned long, bool)"", referenced from:
          l812 in TensorFlowLiteC
          l1892 in TensorFlowLiteC
          l3563 in TensorFlowLiteC
      ""tflite::Subgraph::AddNodeWithParameters(std::__1::vector<int, std::__1::allocator<int> > const&, std::__1::vector<int, std::__1::allocator<int> > const&,
      std::__1::vector<int, std::__1::allocator<int> > const&, char const*, unsigned long, void*, TfLiteRegistration const*, int*)"", referenced from:
          l1454 in TensorFlowLiteC
          l3443 in TensorFlowLiteC
      ""tflite::Subgraph::Invoke()"", referenced from:
          l1458 in TensorFlowLiteC
          l3008 in TensorFlowLiteC
          l4742 in TensorFlowLiteC
          l5015 in TensorFlowLiteC
      ""tflite::tensor_utils::Sub1Vector(short const*, int, short*)"", referenced from:
          l1727 in TensorFlowLiteC
          l1731 in TensorFlowLiteC
      ""tflite::Subgraph::ResetVariableTensors()"", referenced from:
          l1460 in TensorFlowLiteC
      ""tflite::tensor_utils::ApplySigmoid(short const*, int, int, short*)"", referenced from:
          l1730 in TensorFlowLiteC
      ""flatbuffers::StripPath(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)"", referenced from:
          l814 in TensorFlowLiteC
          l1889 in TensorFlowLiteC
          l3564 in TensorFlowLiteC
      ""tflite::Subgraph::ReleaseNonPersistentMemory()"", referenced from:
          l1457 in TensorFlowLiteC
          l5015 in TensorFlowLiteC
      ""tflite::tensor_utils::SparseMatrixBatchVectorMultiplyAccumulate1x4(float const*, int const*, int const*, int, int, float const*, int, float*)"", referenced from:
          l1282 in TensorFlowLiteC
          l1286 in TensorFlowLiteC
      ""tflite::Subgraph::ResizeInputTensorStrict(int, std::__1::vector<int, std::__1::allocator<int> > const&)"", referenced from:
          l1456 in TensorFlowLiteC
      ""tflite::tensor_utils::SparseMatrixBatchVectorMultiplyAccumulate(signed char const*, unsigned char const*, int, int, signed char const*, float const*, int, float*)"",
      referenced from:
          l1724 in TensorFlowLiteC
          l1729 in TensorFlowLiteC
      ""tflite::Subgraph::ResizeInputTensor(int, std::__1::vector<int, std::__1::allocator<int> > const&)"", referenced from:
          l1455 in TensorFlowLiteC
          l3007 in TensorFlowLiteC
          l3009 in TensorFlowLiteC
          l4741 in TensorFlowLiteC
      ""tflite::tensor_utils::MatrixBatchVectorMultiply(short const*, signed char const*, int, int, int const*, int, int, int, int, signed char*)"", referenced from:
          l1727 in TensorFlowLiteC
      ""tflite::Subgraph::ReserveNodes(int)"", referenced from:
          l1452 in TensorFlowLiteC
          l3443 in TensorFlowLiteC
      ""tflite::Subgraph::SetExternalContext(TfLiteExternalContextType, TfLiteExternalContext*)"", referenced from:
          l1445 in TensorFlowLiteC
      ""tflite::Subgraph::SetCustomAllocationForTensor(int, TfLiteCustomAllocation const&)"", referenced from:
          l1446 in TensorFlowLiteC
      ""tflite::tensor_utils::MatrixBatchVectorMultiplyAccumulate(float const*, int, int, float const*, int, float*)"", referenced from:
          l1252 in TensorFlowLiteC
          l1416 in TensorFlowLiteC
          l1722 in TensorFlowLiteC
          l1728 in TensorFlowLiteC
          l4106 in TensorFlowLiteC
      ""tflite::Subgraph::RemoveAllDelegates()"", referenced from:
          l1451 in TensorFlowLiteC
          l1470 in TensorFlowLiteC
          l1471 in TensorFlowLiteC
      ""tflite::Subgraph::SetVariables(std::__1::vector<int, std::__1::allocator<int> >)"", referenced from:
          l1449 in TensorFlowLiteC
          l3454 in TensorFlowLiteC
      ""flatbuffers::ConCatPathFileName(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char,
      std::__1::char_traits<char>, std::__1::allocator<char> > const&)"", referenced from:
          l2367 in TensorFlowLiteC
      ""tflite::tensor_utils::ReductionSumVector(signed char const*, int*, int, int)"", referenced from:
          l1724 in TensorFlowLiteC
          l4108 in TensorFlowLiteC
          l4109 in TensorFlowLiteC
          l4554 in TensorFlowLiteC
          l4864 in TensorFlowLiteC
      ""tflite::tensor_utils::CwiseAdd(short const*, short const*, int, int, short*)"", referenced from:
          l1727 in TensorFlowLiteC
          l1731 in TensorFlowLiteC
      ""tflite::Subgraph::SetOutputs(std::__1::vector<int, std::__1::allocator<int> >)"", referenced from:
          l1448 in TensorFlowLiteC
          l3454 in TensorFlowLiteC
      ""tflite::Subgraph::Subgraph(tflite::ErrorReporter*, TfLiteExternalContext**, std::__1::vector<std::__1::unique_ptr<tflite::Subgraph,
      std::__1::default_delete<tflite::Subgraph> >, std::__1::allocator<std::__1::unique_ptr<tflite::Subgraph, std::__1::default_delete<tflite::Subgraph> > > >*,
      std::__1::unordered_map<int, std::__1::unique_ptr<tflite::resource::ResourceBase, std::__1::default_delete<tflite::resource::ResourceBase> >, std::__1::hash<int>,
      std::__1::equal_to<int>, std::__1::allocator<std::__1::pair<int const, std::__1::unique_ptr<tflite::resource::ResourceBase,
      std::__1::default_delete<tflite::resource::ResourceBase> > > > >*)"", referenced from:
          l1441 in TensorFlowLiteC
      ""flatbuffers::PosixPath(char const*)"", referenced from:
          l2367 in TensorFlowLiteC
      ""tflite::tensor_utils::CwiseClipping(signed char*, int, signed char)"", referenced from:
          l1726 in TensorFlowLiteC
          l1727 in TensorFlowLiteC
      ""tflite::tensor_utils::Sub1Vector(float const*, int, float*)"", referenced from:
          l1722 in TensorFlowLiteC
          l1724 in TensorFlowLiteC
      ""tflite::tensor_utils::BatchVectorBatchVectorDotProduct(short const*, short const*, int, int, int*)"", referenced from:
          l1418 in TensorFlowLiteC
      ""tflite::tensor_utils::MatrixBatchVectorMultiplyAccumulate(signed char const*, int, int, signed char const*, float const*, int, float*, float const*, int const*,
      int*, int*, bool*, tflite::CpuBackendContext*)"", referenced from:
          l1254 in TensorFlowLiteC
          l1417 in TensorFlowLiteC
          l1724 in TensorFlowLiteC
          l1729 in TensorFlowLiteC
          l4108 in TensorFlowLiteC
      ""tflite::Subgraph::SetCancellationFunction(void*, bool (*)(void*))"", referenced from:
          l1468 in TensorFlowLiteC
      ""tflite::tensor_utils::ReductionSumVector(int const*, int*, int, int)"", referenced from:
          l1418 in TensorFlowLiteC
      ""_xnn_allocate"", referenced from:
          l4440 in TensorFlowLiteC
      ""tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int)"", referenced from:
          l1728 in TensorFlowLiteC
          l1729 in TensorFlowLiteC
      ""tflite::tensor_utils::VectorVectorDotProduct(float const*, float const*, int)"", referenced from:
          l1416 in TensorFlowLiteC
          l1417 in TensorFlowLiteC
      ""tflite::tensor_utils::IsZeroVector(float const*, int)"", referenced from:
          l1254 in TensorFlowLiteC
          l1417 in TensorFlowLiteC
          l1722 in TensorFlowLiteC
          l1724 in TensorFlowLiteC
          l4108 in TensorFlowLiteC
      ""tflite::tensor_utils::ApplyLayerNormFloat(short const*, short const*, int, int, int const*, int, int, short*)"", referenced from:
          l1727 in TensorFlowLiteC
      ""tflite::Subgraph::ModifyGraphWithDelegate(TfLiteDelegate*)"", referenced from:
          l1451 in TensorFlowLiteC
          l1470 in TensorFlowLiteC
      ""tflite::tensor_utils::MatrixScalarMultiplyAccumulate(signed char const*, int, int, int, int*)"", referenced from:
          l764 in TensorFlowLiteC
          l1981 in TensorFlowLiteC
      ""tflite::Subgraph::SetInputs(std::__1::vector<int, std::__1::allocator<int> >)"", referenced from:
          l1447 in TensorFlowLiteC
          l3454 in TensorFlowLiteC
      ""tflite::tensor_utils::ReductionSumVector(float const*, float*, int, int)"", referenced from:
          l1416 in TensorFlowLiteC
          l1417 in TensorFlowLiteC
      ""tflite::tensor_utils::MatrixBatchVectorMultiplyAccumulate(signed char const*, int const*, signed char const*, int, int, int, int, int, int, int*, short*,
      tflite::CpuBackendContext*)"", referenced from:
          l1726 in TensorFlowLiteC
          l1730 in TensorFlowLiteC
      ""tflite::tensor_utils::SymmetricQuantizeFloats(float const*, int, signed char*, float*, float*, float*)"", referenced from:
          l1254 in TensorFlowLiteC
          l1417 in TensorFlowLiteC
          l1724 in TensorFlowLiteC
          l4108 in TensorFlowLiteC
          l4542 in TensorFlowLiteC
          l4551 in TensorFlowLiteC
          l4837 in TensorFlowLiteC
          ...
      ""tflite::Subgraph::AllocateTensors()"", referenced from:
          l1450 in TensorFlowLiteC
          l3006 in TensorFlowLiteC
          l3008 in TensorFlowLiteC
          l4741 in TensorFlowLiteC
          l5015 in TensorFlowLiteC
    ld: symbol(s) not found for architecture arm64
    clang: error: linker command failed with exit code 1 (use -v to see invocation)
    note: Using new build system
    note: Building targets in parallel
    note: Planning build
    note: Constructing build description
    warning: The iOS deployment target 'IPHONEOS_DEPLOYMENT_TARGET' is set to 8.0, but the range of supported deployment target versions is 9.0 to 14.3.99. (in target
    'url_launcher' from project 'Pods')
    warning: The iOS deployment target 'IPHONEOS_DEPLOYMENT_TARGET' is set to 8.0, but the range of supported deployment target versions is 9.0 to 14.3.99. (in target
    'video_player' from project 'Pods')
    warning: The iOS deployment target 'IPHONEOS_DEPLOYMENT_TARGET' is set to 8.0, but the range of supported deployment target versions is 9.0 to 14.3.99. (in target
    'shared_preferences' from project 'Pods')
    warning: The iOS deployment target 'IPHONEOS_DEPLOYMENT_TARGET' is set to 8.0, but the range of supported deployment target versions is 9.0 to 14.3.99. (in target
    'path_provider' from project 'Pods')
    warning: The iOS deployment target 'IPHONEOS_DEPLOYMENT_TARGET' is set to 8.0, but the range of supported deployment target versions is 9.0 to 14.3.99. (in target
    'package_info' from project 'Pods')
    warning: The iOS deployment target 'IPHONEOS_DEPLOYMENT_TARGET' is set to 8.0, but the range of supported deployment target versions is 9.0 to 14.3.99. (in target
    'image_picker' from project 'Pods')
    warning: The iOS deployment target 'IPHONEOS_DEPLOYMENT_TARGET' is set to 8.0, but the range of supported deployment target versions is 9.0 to 14.3.99. (in target
    'flutter_isolate' from project 'Pods')
    warning: The iOS deployment target 'IPHONEOS_DEPLOYMENT_TARGET' is set to 8.0, but the range of supported deployment target versions is 9.0 to 14.3.99. (in target
    'camera' from project 'Pods')
    warning: The iOS deployment target 'IPHONEOS_DEPLOYMENT_TARGET' is set to 8.0, but the range of supported deployment target versions is 9.0 to 14.3.99. (in target
    'Flutter' from project 'Pods')

Encountered error while building for device.
```
</details>


**Describe the expected behavior**

I expect to be able to build a `TensorFlowLiteC.framework` and link against it from a Flutter application.

**Standalone code to reproduce the issue**

These steps must be run on an OSX machine.

If needed, install bazel versions 3.1.0 *and* 3.7.2:

```
(cd ""~/.bazel/bin"" && curl -fLO https://releases.bazel.build/3.1.0/release/bazel-3.1.0-darwin-x86_64 && chmod +x bazel-3.1.0-darwin-x86_64)
(cd ""~/.bazel/bin"" && curl -fLO https://releases.bazel.build/3.7.2/release/bazel-3.7.2-darwin-x86_64 && chmod +x bazel-3.7.2-darwin-x86_64)
```

Download [this gist](https://gist.github.com/mgalgs/3a79a6aa4b9ca237e0bea047d2326550) to a `$WORKSPACE` of your choosing, then:

```
cd $WORKSPACE
git clone --recurse-submodules https://github.com/mgalgs/object_detection_flutter.git
cd <tensorflow_dir>
./configure  # answer yes when it asks about iOS support

# Checkout the breaker and you should see a build failure in our test app.
git checkout 3e9fccb0cb9a5f55a4e67e3011c20ff31c3cce67
APPDIR=$WORKSPACE/object_detection_flutter $WORKSPACE/tflite_ios_bisect.sh

# Now checkout the parent of the breaking commit and build again. Should succeed.
git checkout 3e9fccb0cb9a5f55a4e67e3011c20ff31c3cce67~
APPDIR=$WORKSPACE/object_detection_flutter $WORKSPACE/tflite_ios_bisect.sh
```

You can also run `tflite_ios_bisect.sh` with `git bisect` as documented at the top of the file. Theoretically you should land on the same breaking commit that I've indicated above...

**Other info / logs**

Relevant discussion at `tflite_flutter_plugin`: https://github.com/am15h/tflite_flutter_plugin/issues/64"
46437,cudart64_101.dll not found,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: Conda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: 10.2 and 7.6.5
- GPU model and memory: RTX 2070 Super

**Describe the problem**
I am trying to install TensorFlow and be able to use it on my computer. I am only writing ""import tensorflow"" in my python file and getting several errors. I am using conda and created a new virtual environment and downloaded tensorflow and tensorboard. I also downloaded the 10.1 file and put it in my bin folder but still getting the same error.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
python
import tensorflow

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Here is the error that I am currently getting:
 tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-01-14 14:04:25.725481: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
"
46436,"Passing ""Accuracy"" to model.compile() parameter ""metrics"" (instead of ""accuracy"") returns 0 / epoch without throwing an error","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Big Sur 11.0.1
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: Python 3.8.3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Current Behavior**
It seems that when ""Accuracy"" is passed as a string (instead of ""accuracy"" lowercase) to the metric parameter, the compile deserializes it to get  `tf.keras.metrics.Accuracy` directly instead of fetching `tf.keras.metrics.MeanMetricWrapper` as defined in `_get_metric_object()` from compile_utils. Therefore, the accuracy metric is still visible during Epochs but incorrectly calculated  (always equal to 0) without throwing any warnings/errors.

**Expected Behavior**
Passing ""Accuracy"" instead of ""accuracy"" should result in a ValueError instead of failing silently and returning 0 value for each epoch. 


**Reproducable code**
For scenario 1 (correct case)- 

```python
#Scenario 1: Lower case accuracy (accuracy displayed is proper)

from tensorflow import keras
from tensorflow.keras import layers

X_train = np.random.random((100,8))
y_train = np.random.randint(0,2,(100,))

model = keras.Sequential(
    [
     layers.Dense(10,activation=""relu"",input_shape=(8,)),
     layers.Dense(10,activation=""relu""),
     layers.Dense(1,activation=""sigmoid"")
    ]
)

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
model.fit(X_train,y_train,batch_size=64,epochs=2,verbose=2)
print(model.metrics)

# Epoch 1/2
# 2/2 - 0s - loss: 0.6900 - accuracy: 0.4900
# Epoch 2/2
# 2/2 - 0s - loss: 0.6892 - accuracy: 0.5000   #<------
        
# [<tensorflow.python.keras.metrics.Mean object at 0x7f90e6626d90>, 
#  <tensorflow.python.keras.metrics.MeanMetricWrapper object at 0x7f90e5ac73a0>]  #<------
```

And scenario 2 (Incorrect case)- 

```python
#Scenario 2: Uppercase case Accuracy (accuracy displayed / epoch always 0)

from tensorflow import keras
from tensorflow.keras import layers

X_train = np.random.random((100,8))
y_train = np.random.randint(0,2,(100,))

model = keras.Sequential(
    [
     layers.Dense(10,activation=""relu"",input_shape=(8,)),
     layers.Dense(10,activation=""relu""),
     layers.Dense(1,activation=""sigmoid"")
    ]
)

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['Accuracy'])
model.fit(X_train,y_train,batch_size=64,epochs=2,verbose=2)
print(model.metrics)

# Epoch 1/2
# 2/2 - 0s - loss: 0.7021 - accuracy: 0.0000e+00
# Epoch 2/2
# 2/2 - 0s - loss: 0.6999 - accuracy: 0.0000e+00   #<------
        
# [<tensorflow.python.keras.metrics.Mean object at 0x7f90c80e4bb0>, 
#  <tensorflow.python.keras.metrics.Accuracy object at 0x7f90ca039a30>]  #<------
```

I don't think this was intentional, else it should have thrown a ValueError. I have described the details on this SO post.
"
46432,Missing include files in libtensorflow-cpu-windows-x86_64-2.4.0.zip,"In the page https://www.tensorflow.org/install/lang_c there are links to two zip files for the Windows installation of the TensorFlow C API. 

These Windows zips: libtensorflow-cpu-windows-x86_64-2.4.0.zip and libtensorflow-gpu-windows-x86_64-2.4.0.zip are missing some of the includes:
```
.\include\tensorflow\c\c_api_experimental.h
.\include\tensorflow\c\c_api_macros.h
.\include\tensorflow\c\tensor_interface.h
.\include\tensorflow\c\tf_file_statistics.h
.\include\tensorflow\c\tf_tstring.h
```

This means that using this zip files (and unlike with the zip files of 2.3.1) you cannot build.

Thanks!"
46431,"Blas SGEMM launch failed : m=25600, n=64, k=64 [Op:Conv2D] when building model and restoring weights","
### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**: binary
-   **TensorFlow version (use command below)**: tf-nightly-gpu 2.4.0-dev20201016
-   **Python version**: 3.8.5
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:  Cuda = 11.2 
-   **GPU model and memory**: GeForce RTX 2060 6000MB
-   **Exact command to reproduce**: 

num_classes = 1
pipeline_config = 'object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config'
checkpoint_path = 'object_detection/test_data/checkpoint/ckpt-0'


configs = config_util.get_configs_from_pipeline_file(pipeline_config)
model_config = configs['model']
model_config.ssd.num_classes = num_classes
model_config.ssd.freeze_batchnorm = True
detection_model = model_builder.build(
      model_config=model_config, is_training=True)

fake_box_predictor = tf.compat.v2.train.Checkpoint(
    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,
    # _prediction_heads=detection_model._box_predictor._prediction_heads,
    #    (i.e., the classification head that we *will not* restore)
    _box_prediction_head=detection_model._box_predictor._box_prediction_head,
    )
fake_model = tf.compat.v2.train.Checkpoint(
          _feature_extractor=detection_model._feature_extractor,
          _box_predictor=fake_box_predictor)
ckpt = tf.compat.v2.train.Checkpoint(model=fake_model)
ckpt.restore(checkpoint_path).expect_partial()

image, shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))
prediction_dict = detection_model.predict(image, shapes)
_ = detection_model.postprocess(prediction_dict, shapes)


It fails ath the second last line
"
46430,Error when trying to save transformer model to saved model format.,"Hello,

I am following transformer example below

https://www.tensorflow.org/tutorials/text/transformer

Everything is working as expected and saving checkpoint as well, and I want to now save this to SavedModel format using ""transformer.save()""  but it is throwing the below error.

**TypeError: call() missing 4 required positional arguments: 'tar', 'enc_padding_mask', 'look_ahead_mask', and 'dec_padding_mask'**

TypeError                                 Traceback (most recent call last)
<ipython-input-107-92d91001b9bf> in <module>
----> 1 transformer.save('./saved_model/')

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
   1976     ```
   1977     """"""
-> 1978     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
   1979                     signatures, options)
   1980 

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    131         model, filepath, overwrite, include_optimizer)
    132   else:
--> 133     saved_model_save.save(model, filepath, overwrite, include_optimizer,
    134                           signatures, options)
    135 

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)
     78     # we use the default replica context here.
     79     with distribution_strategy_context._get_default_replica_context():  # pylint: disable=protected-access
---> 80       save_lib.save(model, filepath, signatures, options)
     81 
     82   if not include_optimizer:

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in save(obj, export_dir, signatures, options)
    973   meta_graph_def = saved_model.meta_graphs.add()
    974 
--> 975   _, exported_graph, object_saver, asset_info = _build_meta_graph(
    976       obj, export_dir, signatures, options, meta_graph_def)
    977   saved_model.saved_model_schema_version = constants.SAVED_MODEL_SCHEMA_VERSION

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in _build_meta_graph(obj, export_dir, signatures, options, meta_graph_def)
   1044   checkpoint_graph_view = _AugmentedGraphView(obj)
   1045   if signatures is None:
-> 1046     signatures = signature_serialization.find_function_to_export(
   1047         checkpoint_graph_view)
   1048 

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py in find_function_to_export(saveable_view)
     73   # If the user did not specify signatures, check the root object for a function
     74   # that can be made into a signature.
---> 75   functions = saveable_view.list_functions(saveable_view.root)
     76   signature = functions.get(DEFAULT_SIGNATURE_ATTR, None)
     77   if signature is not None:

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in list_functions(self, obj, extra_functions)
    142     obj_functions = self._functions.get(obj, None)
    143     if obj_functions is None:
--> 144       obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access
    145           self._serialization_cache)
    146       self._functions[obj] = obj_functions

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in _list_functions_for_serialization(self, serialization_cache)
   2587     self.test_function = None
   2588     self.predict_function = None
-> 2589     functions = super(
   2590         Model, self)._list_functions_for_serialization(serialization_cache)
   2591     self.train_function = train_function

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in _list_functions_for_serialization(self, serialization_cache)
   3016 
   3017   def _list_functions_for_serialization(self, serialization_cache):
-> 3018     return (self._trackable_saved_model_saver
   3019             .list_functions_for_serialization(serialization_cache))
   3020 

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py in list_functions_for_serialization(self, serialization_cache)
     85         `ConcreteFunction`.
     86     """"""
---> 87     fns = self.functions_to_serialize(serialization_cache)
     88 
     89     # The parent AutoTrackable class saves all user-defined tf.functions, and

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in functions_to_serialize(self, serialization_cache)
     76 
     77   def functions_to_serialize(self, serialization_cache):
---> 78     return (self._get_serialized_attributes(
     79         serialization_cache).functions_to_serialize)
     80 

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in _get_serialized_attributes(self, serialization_cache)
     92       return serialized_attr
     93 
---> 94     object_dict, function_dict = self._get_serialized_attributes_internal(
     95         serialization_cache)
     96 

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py in _get_serialized_attributes_internal(self, serialization_cache)
     49     # cache (i.e. this is the root level object).
     50     if len(serialization_cache[constants.KERAS_CACHE_KEY]) == 1:
---> 51       default_signature = save_impl.default_save_signature(self.obj)
     52 
     53     # Other than the default signature function, all other attributes match with

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in default_save_signature(layer)
    203   original_losses = _reset_layer_losses(layer)
    204   fn = saving_utils.trace_model_call(layer)
--> 205   fn.get_concrete_function()
    206   _restore_layer_losses(original_losses)
    207   return fn

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in get_concrete_function(self, *args, **kwargs)
   1165       ValueError: if this object has not yet been called on concrete values.
   1166     """"""
-> 1167     concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
   1168     concrete._garbage_collector.release()  # pylint: disable=protected-access
   1169     return concrete

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _get_concrete_function_garbage_collected(self, *args, **kwargs)
   1071       if self._stateful_fn is None:
   1072         initializers = []
-> 1073         self._initialize(args, kwargs, add_initializers_to=initializers)
   1074         self._initialize_uninitialized_variables(initializers)
   1075 

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    694     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)
    695     self._concrete_stateful_fn = (
--> 696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
    697             *args, **kwds))
    698 

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2853       args, kwargs = None, None
   2854     with self._lock:
-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2856     return graph_function
   2857 

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   3211 
   3212       self._function_cache.missed.add(call_context_key)
-> 3213       graph_function = self._create_graph_function(args, kwargs)
   3214       self._function_cache.primary[cache_key] = graph_function
   3215       return graph_function, args, kwargs

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3063     arg_names = base_arg_names + missing_arg_names
   3064     graph_function = ConcreteFunction(
-> 3065         func_graph_module.func_graph_from_py_func(
   3066             self._name,
   3067             self._python_function,

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--> 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    599         # the function a weak reference to itself to avoid a reference cycle.
--> 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    601     weak_wrapped_fn = weakref.ref(wrapped_fn)
    602 

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/saving_utils.py in _wrapped_model(*args)
    132     with base_layer_utils.call_context().enter(
    133         model, inputs=inputs, build_graph=False, training=False, saving=True):
--> 134       outputs = model(inputs, training=False)
    135 
    136     # Outputs always has to be a flat dict.

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    983 
    984         with ops.enable_auto_cast_variables(self._compute_dtype_object):
--> 985           outputs = call_fn(inputs, *args, **kwargs)
    986 
    987         if self._activity_regularizer:

~/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    300   def wrapper(*args, **kwargs):
    301     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
--> 302       return func(*args, **kwargs)
    303 
    304   if inspect.isfunction(func) or inspect.ismethod(func):

TypeError: call() missing 4 required positional arguments: 'tar', 'enc_padding_mask', 'look_ahead_mask', and 'dec_padding_mask'



"
46429,[tf-nightly] `keras.callbacks.EarlyStopping` stops training immediately after the first epoch even if monitored score has improved,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.


### Code to reproduce 

```python
import tensorflow as tf
import keras

from unittest import mock
from functools import reduce


def print_attr(obj, attr):
    print(attr.ljust(20), "":"", reduce(lambda a, b: getattr(a, b), attr.split("".""), obj))


def print_divider(title):
    print(f""\n========== {title} =========="")


def print_es_attrs(es):
    for attr in [
        ""patience"",
        ""stopped_epoch"",
        ""wait"",
        ""best"",
        ""best_weights"",
        ""model.stop_training"",
    ]:
        print_attr(es, attr)


es = keras.callbacks.EarlyStopping(
    monitor=""loss"", mode=""min"", patience=0, restore_best_weights=True, verbose=1
)
es.model = mock.MagicMock(stop_training=False)

print_divider(""TF and Keras version"")
print(""tf:"", tf.version.GIT_VERSION, tf.version.VERSION)
print(""keras:"", keras.__version__)


es.on_train_begin()
print_divider(""After train_begin"")
print_es_attrs(es)

print_divider(""Call on_epoch_end"")
es.on_epoch_end(epoch=0, logs={""loss"": 1.0})

print_divider(""After on_epoch_end"")
print_es_attrs(es)
```

This prints out:

```diff
  ========== TF and Keras version ==========
+ tf: v1.12.1-48978-gad524691510 2.5.0-dev20210114 <- using tf-nightly
  keras: 2.4.3
  
  ========== After train_begin ==========
  patience             : 0
  stopped_epoch        : 0
  wait                 : 0
+ best                 : inf
  best_weights         : None
+ model.stop_training  : False
  
  ========== Call on_epoch_end ==========
  Restoring model weights from the end of the best epoch.
  
  ========== After on_epoch_end ==========
  patience             : 0
  stopped_epoch        : 0
  wait                 : 0
+ best                 : 1.0
  best_weights         : <MagicMock name='mock.get_weights()' id='140324772920720'>
+ model.stop_training  : True  <- should this be False because score has improved from inf to 1.0?
```

Sorry if I'm wrong but is this intended behavior?"
46428,"loss function input ""y_pred"" should be full list of model-outputs","

**System information**
- TensorFlow version (you are using): 2.4
- Are you willing to contribute it (Yes/No): Yes, but it seems that multiple other things might depend on it



**Describe the feature and the current behavior/state.**
In the current version of Keras, the loss function is applied for each output of the model elementwise (if there are multiple), or one can define for each individual output one loss function. This seems to be not really consistent with other fundamentals in Keras / TF, and it would be better to have at least the possibility to get the full list of model-outputs as a y_pred input of the loss function. It's especially confusing since in the train_step
https://github.com/tensorflow/tensorflow/blob/a338a52543e06c26772c2f5007b6a5aad6768fa3/tensorflow/python/keras/engine/training.py#L790-L791
one passes the full list of model-outputs as y_pred, but the loss function is run multiple times for each individual model-output and hence gets every element of the list separately as y_pred

**Will this change the current api? How?**
Yes, there wouldn't be multiple losses for a model but only one. One could still get the same results by building a ""wrapper"" around the individual losses and adding it as a loss. 

**Who will benefit from this feature?**
Everyone who wants to build more complex models, especially if you have different output dimensions in your model-output, where the proposed solution is in https://github.com/keras-team/keras/issues/14140 would not work anymore (e.g., one output an image and one output a label).  

**Any Other info.**
"
46427,Error when load model with layer tensorflow.keras.layers.experimental.preprocessing.Normalization(),"Hello,
I have an issue with tensorflow.keras.layers.experimental.preprocessing.Normalization(). 
I can't load my model when I use it. 


**System information**
- Have I custom un example script provided TensorFlow code
- Linux Ubuntu 20.04
- TensorFlow installed from binary

```
== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Thu Jan 14 12:47:29 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 166...  On   | 00000000:08:00.0  On |                  N/A |
|  0%   49C    P8    12W / 120W |    535MiB /  5941MiB |      7%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1217      G   /usr/lib/xorg/Xorg                346MiB |
|    0   N/A  N/A      1943      G   /usr/bin/kwin_x11                  57MiB |
|    0   N/A  N/A      1956      G   /usr/bin/plasmashell               72MiB |
|    0   N/A  N/A      2367      G   ...gAAAAAAAAA --shared-files       10MiB |
|    0   N/A  N/A      3078      G   ...AAAAAAAA== --shared-files       41MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so.11.0.221
/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-11.0/doc/man/man7/libcudart.7
/usr/local/cuda-11.0/doc/man/man7/libcudart.so.7

== tensorflow installed from info ==================
Name: tensorflow
Version: 2.4.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /home/user/works/test-libs/venv/lib/python3.8/site-packages
Required-by: 

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 8, 5, 'final', 0)

== bazel version  ===============================================
```


**Describe the current behavior**
I can't load my model when I use it. 


**Describe the expected behavior**
I would like to be able to read a model with this layer. I know it's an experimental layer but it should work.  If you have no idea how to solve it, can you advise me of an alternative?

Thank you :-)


**Standalone code to reproduce the issue**
```python
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers.experimental import preprocessing


data = [{""a"": 20.0, ""b"": 5.0, ""c"": 0.2972786923202068}, {""a"": 20.0, ""b"": 10.0, ""c"": 0.10673704592967688}]
train_dataset = pd.DataFrame.from_dict(data)

train_features = train_dataset.copy()
train_labels = train_features.pop('c')

normalizer = preprocessing.Normalization()
normalizer.adapt(np.array(train_features))

dnn_model = keras.Sequential([
    normalizer,
    layers.Dense(64, activation='relu'),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)
])

dnn_model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(0.001))
dnn_model.save('file.h5')


# ValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.
new_model = tf.keras.models.load_model('file.h5')
```


**logs**
```
2021-01-14 12:27:41.950145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-14 12:27:42.758932: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-14 12:27:42.759555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-01-14 12:27:42.796836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-14 12:27:42.797239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5
coreClock: 1.8GHz coreCount: 24 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s
2021-01-14 12:27:42.797264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-14 12:27:42.798974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-01-14 12:27:42.799021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-01-14 12:27:42.799743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-01-14 12:27:42.799901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-01-14 12:27:42.801635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-01-14 12:27:42.802036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-01-14 12:27:42.802131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-01-14 12:27:42.802239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-14 12:27:42.802663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-14 12:27:42.802998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-01-14 12:27:42.803643: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-14 12:27:42.803719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-14 12:27:42.804062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5
coreClock: 1.8GHz coreCount: 24 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s
2021-01-14 12:27:42.804079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-14 12:27:42.804092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-01-14 12:27:42.804101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-01-14 12:27:42.804110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-01-14 12:27:42.804119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-01-14 12:27:42.804128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-01-14 12:27:42.804136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-01-14 12:27:42.804145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-01-14 12:27:42.804191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-14 12:27:42.804558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-14 12:27:42.804884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-01-14 12:27:42.804907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-14 12:27:43.183218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-14 12:27:43.183266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-01-14 12:27:43.183273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-01-14 12:27:43.183488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-14 12:27:43.183873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-14 12:27:43.184214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-14 12:27:43.184529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4868 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5)
Traceback (most recent call last):
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py"", line 2873, in zeros
    shape = constant_op._tensor_shape_tensor_conversion_function(
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 355, in _tensor_shape_tensor_conversion_function
    raise ValueError(
ValueError: Cannot convert a partially known TensorShape to a Tensor: (None,)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""save.py"", line 30, in <module>
    new_model = tf.keras.models.load_model('file.h5')
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py"", line 206, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects,
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 183, in load_model_from_hdf5
    model = model_config_lib.model_from_config(model_config,
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/saving/model_config.py"", line 64, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/layers/serialization.py"", line 173, in deserialize
    return generic_utils.deserialize_keras_object(
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 354, in deserialize_keras_object
    return cls.from_config(
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py"", line 494, in from_config
    model.add(layer)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py"", line 517, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py"", line 223, in add
    output_tensor = layer(self.outputs[0])
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 951, in __call__
    return self._functional_construction_call(inputs, args, kwargs,
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1090, in _functional_construction_call
    outputs = self._keras_tensor_symbolic_call(
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 822, in _keras_tensor_symbolic_call
    return self._infer_output_signature(inputs, args, kwargs, input_masks)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 862, in _infer_output_signature
    self._maybe_build(inputs)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 2710, in _maybe_build
    self.build(input_shapes)  # pylint:disable=not-callable
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/normalization.py"", line 174, in build
    self.mean = self._add_state_variable(
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_preprocessing_layer.py"", line 110, in _add_state_variable
    weight = self.add_weight(
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 623, in add_weight
    variable = self._add_variable_with_custom_getter(
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py"", line 805, in _add_variable_with_custom_getter
    new_variable = getter(
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_utils.py"", line 130, in make_variable
    return tf_variables.VariableV1(
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/ops/variables.py"", line 260, in __call__
    return cls._variable_v1_call(*args, **kwargs)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/ops/variables.py"", line 206, in _variable_v1_call
    return previous_getter(
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/ops/variables.py"", line 199, in <lambda>
    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py"", line 2604, in default_variable_creator
    return resource_variable_ops.ResourceVariable(
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/ops/variables.py"", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1574, in __init__
    self._init_from_args(
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1712, in _init_from_args
    initial_value = initial_value()
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py"", line 114, in __call__
    return array_ops.zeros(shape, dtype)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py"", line 201, in wrapper
    return target(*args, **kwargs)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py"", line 2819, in wrapped
    tensor = fun(*args, **kwargs)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py"", line 2877, in zeros
    shape = ops.convert_to_tensor(shape, dtype=dtypes.int32)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py"", line 163, in wrapped
    return func(*args, **kwargs)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 1540, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 339, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 264, in constant
    return _constant_impl(value, dtype, shape, name, verify_shape=False,
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 276, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 301, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/home/user/works/test-libs/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 98, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
ValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.

```
"
46426,[RNN] models cannot run in TFLite with delegates,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Qualcomm Snapdragon 865
- TensorFlow installed from (source or binary): Source 
- TensorFlow version (or github SHA if from source): Nightly


**Command used to run the converter or code if youâre using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
tf_model = tf.keras.models.load_model('./my_model.h5')

for i in range(4):
    tf_model.inputs[i].shape._dims[0] = tf_python.framework.tensor_shape.Dimension(1)

model_func = tf.function(lambda a: tf_model(a))
concrete_func = model_func.get_concrete_function([tf.TensorSpec(tf_model.inputs[0].shape, tf_model.inputs[0].dtype), tf.TensorSpec(tf_model.inputs[1].shape, tf_model.inputs[1].dtype), tf.TensorSpec(tf_model.inputs[2].shape, tf_model.inputs[2].dtype), tf.TensorSpec(tf_model.inputs[3].shape, tf_model.inputs[3].dtype)])

tf_out = concrete_func([input_1, gru0_1_h_in, gru1_1_h_in, out_quats_gru1_h_in])
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
tflite_model = converter.convert()
```

**The output from the converter invocation**

```
2021-01-14 11:16:28.325520: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:933] Optimization results for grappler item: graph_to_optimize
  function_optimizer: Graph size after: 389 nodes (195), 590 edges (225), time = 6.75ms.
  function_optimizer: Graph size after: 389 nodes (0), 590 edges (0), time = 3.64ms.
Optimization results for grappler item: while_body_2339
  function_optimizer: function_optimizer did nothing. time = 0.004ms.
  function_optimizer: function_optimizer did nothing. time = 0.001ms.
Optimization results for grappler item: while_cond_2338
  function_optimizer: function_optimizer did nothing. time = 0.004ms.
  function_optimizer: function_optimizer did nothing. time = 0.001ms.
Optimization results for grappler item: while_cond_2708
  function_optimizer: function_optimizer did nothing. time = 0.003ms.
  function_optimizer: function_optimizer did nothing. time = 0ms.
Optimization results for grappler item: while_body_2709
  function_optimizer: function_optimizer did nothing. time = 0.003ms.
  function_optimizer: function_optimizer did nothing. time = 0.001ms.
Optimization results for grappler item: while_body_1969
  function_optimizer: function_optimizer did nothing. time = 0.003ms.
  function_optimizer: function_optimizer did nothing. time = 0.001ms.
Optimization results for grappler item: while_cond_1968
  function_optimizer: function_optimizer did nothing. time = 0.003ms.
  function_optimizer: function_optimizer did nothing. time = 0.002ms.

2021-01-14 11:16:28.851727: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:332] Ignored output_format.
2021-01-14 11:16:28.851756: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:335] Ignored drop_control_dependency.
2021-01-14 11:16:28.895692: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:194] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.

```

**Also, please include a link to the saved model or GraphDef**

```
My Keras model contains a GRU layer, here is what the Keras layer converts to in TFLite:

![Screenshot from 2021-01-14 06-12-45](https://user-images.githubusercontent.com/67419721/104586228-348e6480-5633-11eb-9558-047cd559280b.png)


```

**Failure details**
Model conversion was successful. and runs on CPU. However, when I try to initialize an OpenCL delegate, I get the following run time error:

ERROR: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.
interpreter->ModifyGraphWithDelegate failed

I suspect the problem is with those `While` ops generated by the converter. My GRU layer is stateless, where I manually manage the layer state (tf.keras.layers.GRU is defined with arguments: return_sequences=True, stateful=False, unroll=False. It is called with one of the model's inputs passed to the initial_state argument), and with the sequence dimension of 1. Is it possible to tell the TFLite converter to generate a graph that doesn't contain a while loop? Since in my situation I don't actually need to have a loop in my GRU.

**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
46425,Remove no_cuda_on_cpu_tap tag and fix tests,"This is using TF 2.4.0

**Describe the problem**

When building and running tests I stumbled over the seemingly required test tag `no_cuda_on_cpu_tap` which is only documented in one place:
```
    # Running cuda on cpu will trigger tests guarded by GOOGLE_CUDA but NCHW
    # won't be available, which result in test failures. So disable that.
```

This sounds like a workaround for a problem when writing the tests. The most obvious incarnation for this is e.g. `//tensorflow/core/common_runtime:ring_reducer_test`. That is added with `tf_cuda_cc_test` which adds 2 tests: One with `_gpu` suffix gpu tags and one without. However as the test code uses `GOOGLE_CUDA` to decide whether to test on CPU or GPU the CPU test version cannot be run when TF is built with CUDA, which is (AFAIK) the regular case.

Hence my suggestion would be to ""fix"" the tests to run only on GPU if it is tagged with `gpu` and pass that to the test code as a define (e.g. `TF_TEST_USE_GPU`)

"
46424,"how to restore  part of the model,  then save the whole model after training?","I want to finetine a base model using a new dataset.
The model have two part: part1 + part2
I only want to restore the variables of part1.

1.restore the model using:
    saver = tf.train.Saver(variables_of_part1, max_to_keep=1000)
2.Training
3.Save the model
But the new model saved lost the variables of part2.

How can I realize ""restore part of a model, trainning, then save the whole model""?

My tensorflow version is 1.10."
46423,writer_test of serialization failed for squeeznet,"**System information**
- OS Platform and Distribution  Linux Ubuntu 16.04
- TensorFlow installed from source
- TensorFlow version (use command below):
- Python version: Python 3.5.2
- Bazel version (if compiling from source): Build label: 3.7.2
- GCC/Compiler version (if compiling from source) gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609

**Describe the current behavior**

- download squeezenet (squeezenet.tflit)
- build write test of serialization : bazel build -c opt //tensorflow/lite/tools/serialization:writer_test
-  bazel-bin/tensorflow/lite/tools/serialization/writer_test [model folder]/squeezenet.tflite
```
ERROR: tensorflow/lite/kernels/reshape.cc:69 num_input_elements != num_output_elements (1001 != 1)
ERROR: Node number 38 (RESHAPE) failed to prepare.

AllocateTensors failed on the round-tripped model.
```
**Describe the expected behavior**
pass write test

**Standalone code to reproduce the issue**
- download squeezenet (squeezenet.tflit)
- build write test of serialization : bazel build -c opt //tensorflow/lite/tools/serialization:writer_test
-  bazel-bin/tensorflow/lite/tools/serialization/writer_test [model folder]/squeezenet.tflite

**Other info / logs** Include any logs or source code that would be helpful to
```
ERROR: tensorflow/lite/kernels/reshape.cc:69 num_input_elements != num_output_elements (1001 != 1)
ERROR: Node number 38 (RESHAPE) failed to prepare.

AllocateTensors failed on the round-tripped model.
```
A proposal of fix is at: https://github.com/tensorflow/tensorflow/pull/46422 
"
46421,"LSTM doesnot work after tf_upgrade_v2 with keras.models.load_model, but tf.keras.models.load_model works","**System information**
- Linux Ubuntu 16.04
- TensorFlow installed from pip
- TensorFlow version: v2.1.0-rc2-17-ge5bf8de 2.1.0
- Keras version: 2.3.1
- Python version: 3.6.12
- CUDA/cuDNN version: 11.1/7

At first, I have codes written by tensorflow v1 that can't run. so I use 

```shell
tf_upgrade_v2 --infile tensorflow_backend.py --outfile tensorflow_backend.py
```
to  upgrade the keras .py file in xx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/

it works after upgrade, however, later I found it goes wrong when load LSTM model(.h5)

the LSTM model can be acessed [here](https://github.com/SingleBone/origin_models/blob/main/lstm0-sinewave_origin.h5)

**the current behavior**
when load a LSTM model with **keras.models.load_model**

```python
import keras
model = keras.models.load_model('lstm0-sinewave_origin.h5')
```

, got RuntimeError
```bash
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/saving.py"", line 492, in load_wrapper
    return load_function(*args, **kwargs)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/saving.py"", line 584, in load_model
    model = _deserialize_model(h5dict, custom_objects, compile)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/saving.py"", line 274, in _deserialize_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/saving.py"", line 627, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/layers/__init__.py"", line 168, in deserialize
    printable_module_name='layer')
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/utils/generic_utils.py"", line 147, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/sequential.py"", line 302, in from_config
    model.add(layer)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/sequential.py"", line 166, in add
    layer(x)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 541, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 76, in symbolic_fn_wrapper
    return func(*args, **kwargs)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 463, in __call__
    self.build(unpack_singleton(input_shapes))
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 502, in build
    self.cell.build(step_input_shape)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 1942, in build
    constraint=self.bias_constraint)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 282, in add_weight
    constraint=constraint)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 621, in variable
    value, dtype=dtype, name=name, constraint=constraint)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 814, in variable
    constraint=constraint)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 260, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 254, in _variable_v2_call
    shape=shape)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 235, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py"", line 2645, in default_variable_creator_v2
    shape=shape)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 262, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 1411, in __init__
    distribute_strategy=distribute_strategy)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 1543, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1280, in convert_to_tensor
    raise RuntimeError(""Attempting to capture an EagerTensor without ""
RuntimeError: Attempting to capture an EagerTensor without building a function.
```

**the expected behavior**
when use **tensorflow.keras.models.load_model**

```python
import tensorflow
model = tensorflow.keras.models.load_model('lstm0-sinewave_origin.h5')
```
, it works without error

**the whole process to triger this issue**
```bash
(tensorflow) root@53125cc00c44:/data/origin_model# python
Python 3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56) 
[GCC 7.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
# here is where it goes wrong
>>> import keras
>>> model = keras.models.load_model('lstm0-sinewave_origin.h5')
WARNING:tensorflow:From /root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2021-01-14 07:36:41.711121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-01-14 07:36:41.728295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-01-14 07:36:41.729095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: 
pciBusID: 0000:84:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-01-14 07:36:41.729486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-14 07:36:41.732935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-01-14 07:36:41.735810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-01-14 07:36:41.736327: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-01-14 07:36:41.739862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-01-14 07:36:41.741934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-01-14 07:36:41.749515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-01-14 07:36:41.753192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2021-01-14 07:36:41.753681: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2021-01-14 07:36:41.772855: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2197465000 Hz
2021-01-14 07:36:41.776310: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b853a3c2f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-01-14 07:36:41.776354: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-14 07:36:42.013802: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b853aa2730 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-01-14 07:36:42.013851: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2021-01-14 07:36:42.013862: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1
2021-01-14 07:36:42.015095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-01-14 07:36:42.015643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: 
pciBusID: 0000:84:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-01-14 07:36:42.015709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-14 07:36:42.015745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-01-14 07:36:42.015784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-01-14 07:36:42.015809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-01-14 07:36:42.015829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-01-14 07:36:42.015849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-01-14 07:36:42.015883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-01-14 07:36:42.018395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2021-01-14 07:36:42.018444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-14 07:36:42.020294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-14 07:36:42.020317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 
2021-01-14 07:36:42.020328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N N 
2021-01-14 07:36:42.020337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   N N 
2021-01-14 07:36:42.022501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10171 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-01-14 07:36:42.023440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 2116 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/saving.py"", line 492, in load_wrapper
    return load_function(*args, **kwargs)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/saving.py"", line 584, in load_model
    model = _deserialize_model(h5dict, custom_objects, compile)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/saving.py"", line 274, in _deserialize_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/saving.py"", line 627, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/layers/__init__.py"", line 168, in deserialize
    printable_module_name='layer')
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/utils/generic_utils.py"", line 147, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/sequential.py"", line 302, in from_config
    model.add(layer)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/sequential.py"", line 166, in add
    layer(x)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 541, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 76, in symbolic_fn_wrapper
    return func(*args, **kwargs)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 463, in __call__
    self.build(unpack_singleton(input_shapes))
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 502, in build
    self.cell.build(step_input_shape)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 1942, in build
    constraint=self.bias_constraint)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 282, in add_weight
    constraint=constraint)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 621, in variable
    value, dtype=dtype, name=name, constraint=constraint)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 814, in variable
    constraint=constraint)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 260, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 254, in _variable_v2_call
    shape=shape)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 235, in <lambda>
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py"", line 2645, in default_variable_creator_v2
    shape=shape)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py"", line 262, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 1411, in __init__
    distribute_strategy=distribute_strategy)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 1543, in _init_from_args
    name=""initial_value"", dtype=dtype)
  File ""/root/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1280, in convert_to_tensor
    raise RuntimeError(""Attempting to capture an EagerTensor without ""
RuntimeError: Attempting to capture an EagerTensor without building a function.
# tensorflow.keras.models.load_model 
>>> import tensorflow
>>> model = tensorflow.keras.models.load_model('lstm0-sinewave_origin.h5')
2021-01-14 07:39:55.578518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-01-14 07:39:55.579080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: 
pciBusID: 0000:84:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-01-14 07:39:55.579141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-14 07:39:55.579165: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-01-14 07:39:55.579186: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-01-14 07:39:55.579207: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-01-14 07:39:55.579224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-01-14 07:39:55.579241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-01-14 07:39:55.579259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-01-14 07:39:55.581588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2021-01-14 07:39:55.581630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-14 07:39:55.581644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 
2021-01-14 07:39:55.581652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N N 
2021-01-14 07:39:55.581659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   N N 
2021-01-14 07:39:55.583609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10171 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-01-14 07:39:55.584122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 2116 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1)
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
>>> import tensorflow
>>> model = tensorflow.keras.models.load_model('lstm0-sinewave_origin.h5')
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
```"
46420,PIP Tensorflow-gpu,"I read in docs that for new version of tensorflow gpu support is integrated 
so if i run: pip install tensorflow, i have both cpu and gpu support.

Now the question is: why is still present 
pip install tensorflow-gpu 2.4.0 ???
https://pypi.org/project/tensorflow-gpu/

anyway
i installed  TS whit command ""pip install tensorflow""

if i run 
```
C:\Users\Kit>nvcc -V 
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Wed_Jul_22_19:09:35_Pacific_Daylight_Time_2020
Cuda compilation tools, release 11.0, V11.0.221
Build cuda_11.0_bu.relgpu_drvr445TC445_37.28845127_0
```
so everithink seems fine
also for 
C:\Users\Kit>nvidia-smi
Thu Jan 14 08:02:30 2021
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.89       Driver Version: 460.89       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 105... WDDM  | 00000000:01:00.0  On |                  N/A |
| 35%   14C    P8    N/A /  75W |    758MiB /  4096MiB |      2%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

but when i run 
```
from keras import backend as K
print(tf.config.list_physical_devices('GPU'))
or
import tensorflow as tf
print(tf.test.gpu_device_name())
```
i can see only cpu

but if i install whit
pip install tensorflow-gpu 2.4.0

i can see cpu AND gpu in python

I'M A BIT CONFUSED




"
46419,TF2.4/XLA assertion in Electra model when deferring compilation on GPU,"Attached are gzip versions of
1) git.patch
2) dummy_p1.tfrecord
3) run_electra_bug.sh

Environment:
1) Google TF-2.4 container: tensorflow/tensorflow:2.4.0-gpu
2) single GV100 32GB

Reproduction steps:

1) git clone git@github.com:NVIDIA/DeepLearningExamples.git
2) cd DeepLearningExamples/TensorFlow2/LanguageModeling/ELECTRA/
3) copy the attached git.patch file to ./
4) cp the attached run_electra_bug file to ./scripts
5) cp the attached dummy_p1.tfrecord file to ./data
6) git apply git.patch
7) bash scripts/docker/build.sh
8) bash scripts/docker/launch.sh
9) TF_XLA_FLAGS=--tf_xla_always_defer_compilation=true bash scripts/run_electra_bug.sh 1 6e-3 amp 1  (run this within the docker container started in 8).

The resulting error:
```
0]<stderr>:Traceback (most recent call last):
[0]<stderr>:  File ""/workspace/electra/run_pretraining.py"", line 493, in <module>
[0]<stderr>:    args = main(start_time)
[0]<stderr>:  File ""/workspace/electra/run_pretraining.py"", line 427, in main
[0]<stderr>:    local_step==1, take_step=local_step % args.gradient_accumulation_steps == 0)
[0]<stderr>:  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 828, in __call__
[0]<stderr>:    result = self._call(*args, **kwds)
[0]<stderr>:  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 888, in _call
[0]<stderr>:    return self._stateless_fn(*args, **kwds)
[0]<stderr>:  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2943, in __call__
[0]<stderr>:    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
[0]<stderr>:  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 1919, in _call_flat
[0]<stderr>:    ctx, args, cancellation_manager=cancellation_manager))
[0]<stderr>:  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 560, in call
[0]<stderr>:    ctx=ctx)
[0]<stderr>:  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
[0]<stderr>:    inputs, attrs, num_outputs)
[0]<stderr>:tensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.
[0]<stderr>:	 [[{{node cluster_11_1/merge_oidx_69/_148}}]] [Op:__inference_train_one_step_88467]
[0]<stderr>:
[0]<stderr>:Function call stack:
[0]<stderr>:train_one_step
[0]<stderr>:
Process 0 exit with status code 1.
Traceback (most recent call last):
  File ""/usr/local/bin/horovodrun"", line 8, in <module>
    sys.exit(run_commandline())
  File ""/usr/local/lib/python3.6/dist-packages/horovod/runner/launch.py"", line 768, in run_commandline
    _run(args)
  File ""/usr/local/lib/python3.6/dist-packages/horovod/runner/launch.py"", line 758, in _run
    return _run_static(args)
  File ""/usr/local/lib/python3.6/dist-packages/horovod/runner/launch.py"", line 615, in _run_static
    _launch_job(args, settings, nics, command)
  File ""/usr/local/lib/python3.6/dist-packages/horovod/runner/launch.py"", line 731, in _launch_job
    args.verbose)
  File ""/usr/local/lib/python3.6/dist-packages/horovod/runner/launch.py"", line 704, in run_controller
    gloo_run()
  File ""/usr/local/lib/python3.6/dist-packages/horovod/runner/launch.py"", line 720, in gloo_run_fn
    gloo_run(settings, nics, env, driver_ip, command)
  File ""/usr/local/lib/python3.6/dist-packages/horovod/runner/gloo_run.py"", line 284, in gloo_run
    launch_gloo(command, exec_command, settings, nics, env, server_ip)
  File ""/usr/local/lib/python3.6/dist-packages/horovod/runner/gloo_run.py"", line 271, in launch_gloo
    .format(name=name, code=exit_code))
```"
46417,"when i use custom loss and gpu, fit kernel died","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): window 10
- TensorFlow version (use command below): tf-nightly-gpu 2.5.0 210112
- Python version:3.8
- CUDA/cuDNN version: 11.1 / maybe 8(?)
- GPU model and memory: RTX 3090 24GB MEM

2. TF 2.0: v1.12.1-48890-g670cc3fa48f 2.5.0-dev20210113



my custom loss function looks like this,

```
import tensorflow as tf
from keras import backend as K
from tensorflow.keras.losses import Loss

@tf.function
def mase(y_true, y_pred, seasonality=1):
    def _naive_forecasting(actual, seasonality: int = 1):
        return actual[:-seasonality]
    
    def _error(actual, predicted):
        return actual - predicted
    
    def _mae(actual, predicted):
        return K.mean(K.abs(_error(actual, predicted)))
    
#     K.print_tensor(y_true,message='\ny_true==')
#     K.print_tensor(y_pred,message='\ny_pred==')
#     K.print_tensor(_mae(y_true, y_pred) / _mae(y_true[seasonality:], _naive_forecasting(y_true, seasonality)),message='\nminus==')
#     print(y_true, y_pred)
    return _mae(y_true, y_pred) / _mae(y_true[seasonality:], _naive_forecasting(y_true, seasonality))

```

and use like this,
```
model.compile(loss=MASE(1), optimizer=Adam(lr=0.001))
...
model.fit(x_concat_data[train], y_concat_data[train], batch_size=batch_size, epochs=epoch, verbose=2, shuffle=True)
...
model.evaluate(x_concat_data[validation], y_concat_data[validation], batch_size=batch_size, callbacks=[early_stopping])
```
I use rtx 3090 and want to train with gpu

cpu training is good!
BUT! when i use gpu, python kernel is dead!
kernel output like this

2021-01-14 09:33:55.296929: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:127] None of the MLIR optimization passes are enabled (registered 2)
Epoch 1/1000
d:/>

what is my problem?"
46416,Timeseries example does not work with Preprocessing layers,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/tutorials/structured_data/time_series

## Description of issue (what needs changing):
The examples use methods such as 
```
data = np.array(data, dtype=np.float32)
ds = tf.keras.preprocessing.timeseries_dataset_from_array(
      data=data,
      targets=None,
      sequence_length=self.total_window_size,
      sequence_stride=1,
      shuffle=True,
      batch_size=32,)
```
But, this pretty much disables the usage of preprocessing layers to be built. And also, such an elaborate example does not use sequence features or input layer methods. The method ```timeseries_dataset_from_array``` pretty much did away any usage of preprocessing layers in the model. We can not effectively use feature layer engineering because we have to convert all the feature columns into float. 

"
46415,TFLM CI is currently broken,"@tensorflow/micro

https://github.com/tensorflow/tensorflow/commit/02e9e26b27a59fef75f69575d54aa4af96605af5 added a compiler flag that [breaks the TFLM bazel build](https://source.cloud.google.com/results/invocations/b6a8674a-60c7-4426-8e9d-b5d96294f455/log) with the following error:
```
ERROR: /tmpfs/src/github/tensorflow/tensorflow/lite/kernels/internal/BUILD:685:11: C++ compilation of rule '//tensorflow/lite/kernels/internal:portable_tensor_utils' failed (Exit 1): gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 35 argument(s) skipped)
gcc: error: unrecognized argument to -fsanitize= option: 'shift-base'
```

The underlying issue seems to be that the gcc version on the TFLM docker image (gcc (Debian 8.3.0-6) 8.3.0) does not support this argument.

Depending on your local gcc version, this may or may not be reproducible locally.

For example, for me: gcc (Debian 10.2.0-19) 10.2.0

```
bazel clean
bazel build -s tensorflow/lite/c:common
```

has the shift-base argument:
```
/usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -MD -MF bazel-out/k8-opt/bin/tensorflow/lite/c/_objs/common/common.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/lite/c/_objs/common/common.o' -iquote . -iquote bazel-out/k8-opt/bin -w -DAUTOLOAD_DYNAMIC_KERNELS -DFARMHASH_NO_CXX_STRING -Wno-sign-compare -O3 -fno-exceptions '-fno-sanitize=shift-base' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/lite/c/common.c -o bazel-out/k8-opt/bin/tensorflow/lite/c/_objs/common/common.o)
```

but the build passes."
46414,InceptionResNetV2: BatchNormalization layer does not work outside during validation/evaluation,"TF version : **v2.4.0-0-g582c8d236cb 2.4.0**
Python: 3.6.9/3.8
OS Version: Ubuntu 18.04/Windows 10

`BatchNormalization` layer does not work during evaluation and validation phase in `InceptionResNetV2`. Please note that the same data was used for training, validation and evaluation. Dataset consists of 40 examples of cats/dogs. Dataset is balanced (20cat/20dog)

1. Train history **with** Batch Normalization :

```shell
starting script
starting training
Epoch 1/12
4/4 [==============================] - 21s 2s/step - loss: 1.3195 - accuracy: 0.4600 - val_loss: 0.7235 - val_accuracy: 0.5000
Epoch 2/12
4/4 [==============================] - 3s 715ms/step - loss: 1.8840 - accuracy: 0.5500 - val_loss: 0.7115 - val_accuracy: 0.5000
Epoch 3/12
4/4 [==============================] - 3s 714ms/step - loss: 0.6748 - accuracy: 0.6833 - val_loss: 3.8985 - val_accuracy: 0.5000
Epoch 4/12
4/4 [==============================] - 3s 714ms/step - loss: 0.3799 - accuracy: 0.7900 - val_loss: 7.1380 - val_accuracy: 0.5000
Epoch 5/12
4/4 [==============================] - 3s 718ms/step - loss: 0.2764 - accuracy: 0.9267 - val_loss: 7.7212 - val_accuracy: 0.5000
Epoch 6/12
4/4 [==============================] - 3s 718ms/step - loss: 0.1726 - accuracy: 0.9467 - val_loss: 6.9867 - val_accuracy: 0.5000
Epoch 7/12
4/4 [==============================] - 3s 723ms/step - loss: 0.0975 - accuracy: 1.0000 - val_loss: 5.7449 - val_accuracy: 0.5000
Epoch 8/12
4/4 [==============================] - 3s 724ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 4.4831 - val_accuracy: 0.5000
Epoch 9/12
4/4 [==============================] - 3s 726ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.7662 - val_accuracy: 0.5000
Epoch 10/12
4/4 [==============================] - 3s 733ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.0623 - val_accuracy: 0.5000
Epoch 11/12
4/4 [==============================] - 3s 732ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4364 - val_accuracy: 0.5000
Epoch 12/12
4/4 [==============================] - 3s 736ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9331 - val_accuracy: 0.5000
starting testing
4/4 [==============================] - 1s 197ms/step - loss: 1.9331 - accuracy: 0.5000
[1.9330692291259766, 0.5]
script complete
```

1. Train history **without** Batch Normalization:
```shell
starting script
starting training
Epoch 1/50
4/4 [==============================] - 14s 1s/step - loss: 0.7497 - accuracy: 0.3833 - val_loss: 0.6936 - val_accuracy: 0.5000
Epoch 2/50
4/4 [==============================] - 2s 674ms/step - loss: 0.7000 - accuracy: 0.4100 - val_loss: 0.6927 - val_accuracy: 0.5000
Epoch 3/50
4/4 [==============================] - 2s 671ms/step - loss: 0.6941 - accuracy: 0.4300 - val_loss: 0.6923 - val_accuracy: 0.5000
Epoch 4/50
4/4 [==============================] - 2s 673ms/step - loss: 0.6930 - accuracy: 0.4633 - val_loss: 0.6913 - val_accuracy: 0.5000
Epoch 5/50
4/4 [==============================] - 2s 677ms/step - loss: 0.6923 - accuracy: 0.4600 - val_loss: 0.6884 - val_accuracy: 0.5000
Epoch 6/50
4/4 [==============================] - 2s 678ms/step - loss: 0.6889 - accuracy: 0.4767 - val_loss: 0.6775 - val_accuracy: 0.5000
Epoch 7/50
4/4 [==============================] - 2s 686ms/step - loss: 0.6793 - accuracy: 0.5033 - val_loss: 0.6452 - val_accuracy: 0.6750
Epoch 8/50
4/4 [==============================] - 2s 679ms/step - loss: 0.6553 - accuracy: 0.7533 - val_loss: 0.6098 - val_accuracy: 0.6750
Epoch 9/50
4/4 [==============================] - 2s 680ms/step - loss: 0.5917 - accuracy: 0.7000 - val_loss: 0.6536 - val_accuracy: 0.6250
Epoch 10/50
4/4 [==============================] - 2s 679ms/step - loss: 0.6050 - accuracy: 0.6333 - val_loss: 0.4657 - val_accuracy: 0.8250
Epoch 11/50
4/4 [==============================] - 2s 683ms/step - loss: 0.5150 - accuracy: 0.7667 - val_loss: 0.4900 - val_accuracy: 0.8250
Epoch 12/50
4/4 [==============================] - 2s 681ms/step - loss: 0.4826 - accuracy: 0.8333 - val_loss: 0.4770 - val_accuracy: 0.7250
Epoch 13/50
4/4 [==============================] - 2s 677ms/step - loss: 0.4328 - accuracy: 0.8267 - val_loss: 0.3850 - val_accuracy: 0.8250
Epoch 14/50
4/4 [==============================] - 2s 683ms/step - loss: 0.3578 - accuracy: 0.8600 - val_loss: 0.2969 - val_accuracy: 0.8500
Epoch 15/50
4/4 [==============================] - 3s 736ms/step - loss: 0.2813 - accuracy: 0.8533 - val_loss: 0.2176 - val_accuracy: 0.9000
Epoch 16/50
4/4 [==============================] - 2s 680ms/step - loss: 0.1951 - accuracy: 0.9100 - val_loss: 0.1658 - val_accuracy: 0.9000
Epoch 17/50
4/4 [==============================] - 2s 677ms/step - loss: 0.2913 - accuracy: 0.8467 - val_loss: 0.2642 - val_accuracy: 0.9000
Epoch 18/50
4/4 [==============================] - 2s 677ms/step - loss: 0.2781 - accuracy: 0.9300 - val_loss: 0.3536 - val_accuracy: 0.8250
Epoch 19/50
4/4 [==============================] - 2s 680ms/step - loss: 0.3337 - accuracy: 0.8200 - val_loss: 0.3058 - val_accuracy: 0.8500
Epoch 20/50
4/4 [==============================] - 2s 669ms/step - loss: 0.3164 - accuracy: 0.8533 - val_loss: 0.2551 - val_accuracy: 0.9000
Epoch 21/50
4/4 [==============================] - 2s 671ms/step - loss: 0.2508 - accuracy: 0.8900 - val_loss: 0.2346 - val_accuracy: 0.9500
Epoch 22/50
4/4 [==============================] - 2s 668ms/step - loss: 0.2010 - accuracy: 0.9800 - val_loss: 0.1793 - val_accuracy: 0.9250
Epoch 23/50
4/4 [==============================] - 2s 671ms/step - loss: 0.1348 - accuracy: 0.9433 - val_loss: 0.1695 - val_accuracy: 0.9250
Epoch 24/50
4/4 [==============================] - 2s 664ms/step - loss: 0.1983 - accuracy: 0.9167 - val_loss: 0.4384 - val_accuracy: 0.8250
Epoch 25/50
4/4 [==============================] - 2s 670ms/step - loss: 0.6678 - accuracy: 0.7767 - val_loss: 0.2072 - val_accuracy: 0.9250
Epoch 26/50
4/4 [==============================] - 2s 667ms/step - loss: 0.3736 - accuracy: 0.7867 - val_loss: 0.3285 - val_accuracy: 0.8750
Epoch 27/50
4/4 [==============================] - 2s 671ms/step - loss: 0.3321 - accuracy: 0.8600 - val_loss: 0.4592 - val_accuracy: 0.7250
Epoch 28/50
4/4 [==============================] - 2s 668ms/step - loss: 0.4189 - accuracy: 0.7733 - val_loss: 0.3381 - val_accuracy: 0.8750
Epoch 29/50
4/4 [==============================] - 2s 671ms/step - loss: 0.2884 - accuracy: 0.9167 - val_loss: 0.2362 - val_accuracy: 0.9250
Epoch 30/50
4/4 [==============================] - 2s 669ms/step - loss: 0.2109 - accuracy: 0.9433 - val_loss: 0.1939 - val_accuracy: 0.9250
Epoch 31/50
4/4 [==============================] - 2s 666ms/step - loss: 0.1309 - accuracy: 0.9633 - val_loss: 0.2058 - val_accuracy: 0.9000
Epoch 32/50
4/4 [==============================] - 2s 673ms/step - loss: 0.2605 - accuracy: 0.8733 - val_loss: 0.2232 - val_accuracy: 0.8750
Epoch 33/50
4/4 [==============================] - 2s 675ms/step - loss: 0.1198 - accuracy: 0.9367 - val_loss: 0.1587 - val_accuracy: 0.9250
Epoch 34/50
4/4 [==============================] - 2s 667ms/step - loss: 0.1421 - accuracy: 0.9567 - val_loss: 0.1156 - val_accuracy: 0.9250
Epoch 35/50
4/4 [==============================] - 2s 669ms/step - loss: 0.0929 - accuracy: 0.9367 - val_loss: 0.0473 - val_accuracy: 1.0000
Epoch 36/50
4/4 [==============================] - 2s 671ms/step - loss: 0.0733 - accuracy: 0.9667 - val_loss: 0.0537 - val_accuracy: 0.9750
Epoch 37/50
4/4 [==============================] - 2s 670ms/step - loss: 0.0925 - accuracy: 0.9833 - val_loss: 0.0829 - val_accuracy: 0.9250
Epoch 38/50
4/4 [==============================] - 2s 667ms/step - loss: 0.1385 - accuracy: 0.9400 - val_loss: 0.4641 - val_accuracy: 0.8500
Epoch 39/50
4/4 [==============================] - 2s 666ms/step - loss: 0.4502 - accuracy: 0.8567 - val_loss: 0.1805 - val_accuracy: 0.9000
Epoch 40/50
4/4 [==============================] - 2s 669ms/step - loss: 0.2034 - accuracy: 0.9200 - val_loss: 0.0498 - val_accuracy: 1.0000
Epoch 41/50
4/4 [==============================] - 2s 667ms/step - loss: 0.0675 - accuracy: 0.9800 - val_loss: 0.1448 - val_accuracy: 0.9250
Epoch 42/50
4/4 [==============================] - 2s 670ms/step - loss: 0.0969 - accuracy: 0.9533 - val_loss: 0.0311 - val_accuracy: 1.0000
Epoch 43/50
4/4 [==============================] - 2s 678ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000
Epoch 44/50
4/4 [==============================] - 2s 678ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9750
Epoch 45/50
4/4 [==============================] - 2s 676ms/step - loss: 0.2596 - accuracy: 0.9267 - val_loss: 0.2702 - val_accuracy: 0.9000
Epoch 46/50
4/4 [==============================] - 2s 674ms/step - loss: 0.3273 - accuracy: 0.9167 - val_loss: 0.7219 - val_accuracy: 0.7500
Epoch 47/50
4/4 [==============================] - 2s 672ms/step - loss: 0.5580 - accuracy: 0.7633 - val_loss: 0.1916 - val_accuracy: 0.9500
Epoch 48/50
4/4 [==============================] - 2s 674ms/step - loss: 0.3112 - accuracy: 0.9300 - val_loss: 0.1998 - val_accuracy: 0.9750
Epoch 49/50
4/4 [==============================] - 2s 676ms/step - loss: 0.1679 - accuracy: 0.9533 - val_loss: 0.2122 - val_accuracy: 0.9000
Epoch 50/50
4/4 [==============================] - 2s 675ms/step - loss: 0.1413 - accuracy: 0.9733 - val_loss: 0.1079 - val_accuracy: 0.9500
starting testing
4/4 [==============================] - 1s 184ms/step - loss: 0.1079 - accuracy: 0.9500
[0.10788657516241074, 0.949999988079071]
script complete
```

Link to fully reproduce (with dataset, takes about 3 minutes) :
 https://colab.research.google.com/drive/1QJVZC-2u9aq2RaSCUlmRQeMbZ2QzMHyx?usp=sharing

This was inspired by https://stackoverflow.com/q/65415799/9730862 (I'm not the OP, slightly modified setup)

I know similar issues were raised in the past but taking into account that this behaviour also affects  built-in models  such as `InceptionResNetV2` I'm starting this thread in hope for reveletion. 

Cheers!

Edit: Normally, I would be happy to debug the model and see what is going on but frankly I'm not sure how to do this. In PyTorch I can run each operation step-by-step, does eagerly running models provide similar opprtunity?


"
46413,How the trim existed model for a given tflite model?,"Given a tflite model, is there any way to trim the model?

It is, for example, for squeezent, 
```
1. Placeholder
2. maxpool
3. fire 1
4. fire 2
5. fire 3
.....
41. average pooling
42. flattern
43. softmax
```
I need a way to trim and keep 
```
3. fire 1
4. fire 2
5. fire 3
```
for this case, the input is replaced to fire1 and output is as fire 3.

I wonder if tensorflow provides such functionaliry?

Thanks~"
46409,TfLite: Internal error: Cannot create interpreter: Didn't find op for builtin opcode 'CONV_2D' version '5',"I was trying to create the digit classifier Android app from [codelabs](https://developer.android.com/codelabs/digit-classifier-tflite#0)

At runtime, I get this error:

E/AndroidRuntime: FATAL EXCEPTION: pool-2-thread-1
    Process: org.tensorflow.lite.codelabs.digitclassifier, PID: 18122
    java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Didn't find op for builtin opcode 'CONV_2D' version '5'
    
    Registration failed.
    
        at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:72)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:237)
        at org.tensorflow.lite.codelabs.digitclassifier.DigitClassifier.initializeInterpreter(DigitClassifier.kt:66)
        at org.tensorflow.lite.codelabs.digitclassifier.DigitClassifier.access$initializeInterpreter(DigitClassifier.kt:31)
        at org.tensorflow.lite.codelabs.digitclassifier.DigitClassifier$initialize$1.run(DigitClassifier.kt:48)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
        at java.lang.Thread.run(Thread.java:923)

I have tried changing the tflite version on build.gradle. Any other ideas on how to resolve this issue?"
46408,tf.math.tanh makes silently crash Python,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64 Bits build 21286
- TensorFlow installed from (source or binary): binary from pip
- TensorFlow version (use command below): 2.5.0-dev20210113
- Python version: Python 3.8.5 with Miniconda 4.9.2
- CUDA/cuDNN version: CUDA 11.0 / CuDNN 8.0.6
- GPU model and memory: GeForce RTX 2080 Super with Max-Q Design with 8Go

**Describe the current behavior**
The Python interpreter crashes silently without any error when using the `tf.math.tanh()` function.

**Describe the expected behavior**
Works without crashing

**Standalone code to reproduce the issue**
```
import tensorflow as tf
x = tf.constant([-float(""inf""), -5, -0.5, 1, 1.2, 2, 3, float(""inf"")])
tf.math.tanh(x)
```
**Other info / logs** 
When running `python -u -m trace -t crash.py` the last lines are:
```
 --- modulename: gen_math_ops, funcname: tanh
gen_math_ops.py(10769):   _ctx = _context._context or _context.context()
gen_math_ops.py(10770):   tld = _ctx._thread_local_data
gen_math_ops.py(10771):   if tld.is_eager:
gen_math_ops.py(10772):     try:
gen_math_ops.py(10773):       _result = pywrap_tfe.TFE_Py_FastPathExecute(
gen_math_ops.py(10774):         _ctx, ""Tanh"", name, x)
gen_math_ops.py(10773):       _result = pywrap_tfe.TFE_Py_FastPathExecute(
```
You can also find in attachment a screenshot of the crash.
![crash](https://user-images.githubusercontent.com/959590/104497672-011feb80-55db-11eb-8b6b-a65b8f6aeb69.png)
"
46407,Support for directly importing Dense layer from keras API,"**System information**
- TensorFlow version (you are using): TF 4.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**

Why Dense?

While i was writing code i noticed Dense layer is not supported in importing directly in keras but input layer is there. In that case anyhow we have to mention full path dependency because this layer is the most basic layer and frequently used while building the architecture even if not initially used then at least last few layers are dense layers only mostly. It can be used as feed forward neural network as well as in the output layer.so I think it will be good if this layer can be directly imported from keras without any path dependencies,

[ `from tensorflow.python.keras.engine.input_layer import Input`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/__init__.py) 

Just adding Dense here like this will do



**Will this change the current api? How?**

Nothing is going to change in api. This will be just an additional functionality for the users to serve their purpose easily.


"
46405,LSTM crashing during training - Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: Win 10 Enterprice LTSC
- TensorFlow installed from: binary
- TensorFlow version: v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: Python 3.8.5
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: Build cuda_11.0_bu.relgpu_drvr445TC445_37.28845127_0 / cuDNN v 8.0.5 for CUDA 11.0
- GPU model and memory: GTX 960 (Asus Strix Direct DCU2 OC 4GB)

**Describe the current behavior**
When training a network with LSTM layers it crashes randomly during epochs. 

**Standalone code to reproduce the issue**
https://github.com/Kalhama/tensorflow-lstm-crash

**Things I've checked and are ok / have no effect**
â Only occurs when training on GPU
â Only occurs when using LSTM layers
â Underclocking GPU, raising voltages etc.. (in case stock overclock would be unstable)
â CPU and GPU temps (either never exceeds 60 deg C)
â Different driver versions. I earlier had 460.89 but it's the same on 451.82
â There is enough VRAM / RAM. (I used `tf.config.experimental.set_memory_growth()` and then Win task manager to check VRAM utilization. Only used max 1GB of VRAM on large networks)

**Things I've checked and have some effect, but do not remove problem completely**
â Different network sizes. All networks seem to have this issue but larger networks feel to be more prone to crash fast
â Different batch sizes and different train data sizes. Overall larger batches and longer epochs are more stable. 

**Other info / logs**
```2021-01-12 21:38:15.476512: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2021-01-12 21:38:15.476581: E tensorflow/stream_executor/dnn.cc:616] CUDNN_STATUS_INTERNAL_ERROR
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1859): 'cudnnRNNForwardTraining( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.handles(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_desc.handle(), output_c_data->opaque(), workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'
2021-01-12 21:38:15.483573: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:220] Unexpected Event status: 1

2
```

Sometimes the error looks like this:
```
2021-01-12 21:41:41.096689: E tensorflow/stream_executor/dnn.cc:616] CUDNN_STATUS_INTERNAL_ERROR
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1972): 'cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'
2021-01-12 21:41:41.127515: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cudnn_rnn_ops.cc:1926 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 3, 200, 1, 200, 32, 200]
Traceback (most recent call last):
  File ""c:/Users/User/Code/tensorflow/main.py"", line 61, in <module>
    main()
  File ""c:/Users/User/Code/tensorflow/main.py"", line 40, in main
    model.train(
  File ""c:\Users\User\Code\tensorflow\core\model.py"", line 47, in train
    self.model.fit(
  File ""C:\Users\User\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\keras\engine\training.py"", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File ""C:\Users\User\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\User\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\def_function.py"", line 855, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""C:\Users\User\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\function.py"", line 2942, in __call__
    return graph_function._call_flat(
  File ""C:\Users\User\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\function.py"", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""C:\Users\User\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\function.py"", line 555, in call
    outputs = execute.execute(
  File ""C:\Users\User\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InternalError:    Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 3, 200, 1, 200, 32, 200]
         [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]
         [[Adam/gradients/PartitionedCall_2]] [Op:__inference_train_function_7900]

Function call stack:
train_function -> train_function -> train_function
```"
46403,IndexError webcam object detection,"Hi,

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.10
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: 3.8.6
- GPU model and memory: None

I followed the tutorial [here](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/object_detection_camera.html#sphx-glr-download-auto-examples-object-detection-camera-py) to make a real time object detection. I followed all the step to install tensorflow and tensorflow object detection API and everything was working on their test files. I came back to the tutorial and launch the code everything was working good (model downloaded, ...) but I came with an IndexError issue.

Error :
```
object_detection_camera.py:167 detect_fn  *
        image, shapes = detection_model.preprocess(image)
    /home/name/.local/lib/python3.8/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:482 preprocess  *
        normalized_inputs = self._feature_extractor.preprocess(inputs)
    /home/name/.local/lib/python3.8/site-packages/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py:204 preprocess  *
        if resized_inputs.shape.as_list()[3] == 3:

    IndexError: list index out of range
```

Here the code :
```
#!/usr/bin/env python
# coding: utf-8
""""""
Detect Objects Using Your Webcam
================================
""""""

# %%
# This demo will take you through the steps of running an ""out-of-the-box"" detection model to
# detect objects in the video stream extracted from your camera.

# %%
# Create the data directory
# ~~~~~~~~~~~~~~~~~~~~~~~~~
# The snippet shown below will create the ``data`` directory where all our data will be stored. The
# code will create a directory structure as shown bellow:
#
# .. code-block:: bash
#
#     data
#     âââ models
#
# where the ``models`` folder will will contain the downloaded models.
import os

DATA_DIR = os.path.join(os.getcwd(), 'data')
MODELS_DIR = os.path.join(DATA_DIR, 'models')
for dir in [DATA_DIR, MODELS_DIR]:
    if not os.path.exists(dir):
        os.mkdir(dir)

# %%
# Download the model
# ~~~~~~~~~~~~~~~~~~
# The code snippet shown below is used to download the object detection model checkpoint file,
# as well as the labels file (.pbtxt) which contains a list of strings used to add the correct
# label to each detection (e.g. person).
#
# The particular detection algorithm we will use is the `SSD ResNet101 V1 FPN 640x640`. More
# models can be found in the `TensorFlow 2 Detection Model Zoo <https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md>`_.
# To use a different model you will need the URL name of the specific model. This can be done as
# follows:
#
# 1. Right click on the `Model name` of the model you would like to use;
# 2. Click on `Copy link address` to copy the download link of the model;
# 3. Paste the link in a text editor of your choice. You should observe a link similar to ``download.tensorflow.org/models/object_detection/tf2/YYYYYYYY/XXXXXXXXX.tar.gz``;
# 4. Copy the ``XXXXXXXXX`` part of the link and use it to replace the value of the ``MODEL_NAME`` variable in the code shown below;
# 5. Copy the ``YYYYYYYY`` part of the link and use it to replace the value of the ``MODEL_DATE`` variable in the code shown below.
#
# For example, the download link for the model used below is: ``download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz``
import tarfile
import urllib.request

# Download and extract model
MODEL_DATE = '20200711'
MODEL_NAME = 'ssd_resnet101_v1_fpn_640x640_coco17_tpu-8'
MODEL_TAR_FILENAME = MODEL_NAME + '.tar.gz'
MODELS_DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/'
MODEL_DOWNLOAD_LINK = MODELS_DOWNLOAD_BASE + MODEL_DATE + '/' + MODEL_TAR_FILENAME
PATH_TO_MODEL_TAR = os.path.join(MODELS_DIR, MODEL_TAR_FILENAME)
PATH_TO_CKPT = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'checkpoint/'))
PATH_TO_CFG = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'pipeline.config'))
if not os.path.exists(PATH_TO_CKPT):
    print('Downloading model. This may take a while... ', end='')
    urllib.request.urlretrieve(MODEL_DOWNLOAD_LINK, PATH_TO_MODEL_TAR)
    tar_file = tarfile.open(PATH_TO_MODEL_TAR)
    tar_file.extractall(MODELS_DIR)
    tar_file.close()
    os.remove(PATH_TO_MODEL_TAR)
    print('Done')

# Download labels file
LABEL_FILENAME = 'mscoco_label_map.pbtxt'
LABELS_DOWNLOAD_BASE = \
    'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'
PATH_TO_LABELS = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, LABEL_FILENAME))
if not os.path.exists(PATH_TO_LABELS):
    print('Downloading label file... ', end='')
    urllib.request.urlretrieve(LABELS_DOWNLOAD_BASE + LABEL_FILENAME, PATH_TO_LABELS)
    print('Done')

# %%
# Load the model
# ~~~~~~~~~~~~~~
# Next we load the downloaded model

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging
import tensorflow as tf
from object_detection.utils import label_map_util
from object_detection.utils import config_util
from object_detection.utils import visualization_utils as viz_utils
from object_detection.builders import model_builder

tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)

# Enable GPU dynamic memory allocation
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)

# Load pipeline config and build a detection model
configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)
model_config = configs['model']
detection_model = model_builder.build(model_config=model_config, is_training=False)

# Restore checkpoint
ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)
ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()

@tf.function
def detect_fn(image):
    """"""Detect objects in image.""""""

    image, shapes = detection_model.preprocess(image)
    prediction_dict = detection_model.predict(image, shapes)
    detections = detection_model.postprocess(prediction_dict, shapes)

    return detections, prediction_dict, tf.reshape(shapes, [-1])


# %%
# Load label map data (for plotting)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Label maps correspond index numbers to category names, so that when our convolution network
# predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility
# functions, but anything that returns a dictionary mapping integers to appropriate string labels
# would be fine.
category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,
                                                                    use_display_name=True)

# %%
# Define the video stream
# ~~~~~~~~~~~~~~~~~~~~~~~
# We will use `OpenCV <https://pypi.org/project/opencv-python/>`_ to capture the video stream
# generated by our webcam. For more information you can refer to the `OpenCV-Python Tutorials <https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html#capture-video-from-camera>`_
import cv2

cap = cv2.VideoCapture(0)

# %%
# Putting everything together
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~
# The code shown below loads an image, runs it through the detection model and visualizes the
# detection results, including the keypoints.
#
# Note that this will take a long time (several minutes) the first time you run this code due to
# tf.function's trace-compilation --- on subsequent runs (e.g. on new images), things will be
# faster.
#
# Here are some simple things to try out if you are curious:
#
# * Modify some of the input images and see if detection still works. Some simple things to try out here (just uncomment the relevant portions of code) include flipping the image horizontally, or converting to grayscale (note that we still expect the input image to have 3 channels).
# * Print out `detections['detection_boxes']` and try to match the box locations to the boxes in the image.  Notice that coordinates are given in normalized form (i.e., in the interval [0, 1]).
# * Set ``min_score_thresh`` to other values (between 0 and 1) to allow more detections in or to filter out more detections.
import numpy as np

while True:
    # Read frame from camera
    ret, image_np = cap.read()

    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
    image_np_expanded = np.expand_dims(image_np, axis=0)

    # Things to try:
    # Flip horizontally
    # image_np = np.fliplr(image_np).copy()

    # Convert image to grayscale
    # image_np = np.tile(
    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)

    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)
    detections, predictions_dict, shapes = detect_fn(input_tensor)

    label_id_offset = 1
    image_np_with_detections = image_np.copy()

    viz_utils.visualize_boxes_and_labels_on_image_array(
          image_np_with_detections,
          detections['detection_boxes'][0].numpy(),
          (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),
          detections['detection_scores'][0].numpy(),
          category_index,
          use_normalized_coordinates=True,
          max_boxes_to_draw=200,
          min_score_thresh=.30,
          agnostic_mode=False)

    # Display output
    cv2.imshow('object detection', cv2.resize(image_np_with_detections, (800, 600)))

    if cv2.waitKey(25) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```
"
46402,New feature request:implementation of _get_control_flow_context function,"For interpretability of siamese-like networks with two legs (blocks of BiLSTM), I need to get the gradients of output (similarity value between 0-1) with respect to two inputs (two sequence) for which I use the gradient tape. But then I run to the following error: 

_tf.GradientTape.gradients() does not support graph control flow operations like tf.cond or tf.while at this time. Use tf.gradients() instead. If you need this feature, please file a feature request at https://github.com/tensorflow/tensorflow/issues/new_

coming from: tensor flow/python/eager/backprop.py - def _get_control_flow_context

Could you please explain how this can be solved? Can use of this function be avoided for now or can you please explain what I need to implement there?
 
Training the network was fine and prediction results look good. The issue is only with interpretability of the method. Here is where my code faces this error:


```
# convert to tensor and reshape
sample_seq_1 = tf.convert_to_tensor(train_seq1[0], dtype=tf.float32)
sample_seq_2 = tf.convert_to_tensor(train_seq2[0], dtype=tf.float32)
sample_seq_1 = tf.expand_dims(sample_seq_1, 0)
sample_seq_2 = tf.expand_dims(sample_seq_2, 0)

# inference in tape
with tf.GradientTape(persistent=True) as tape:
    tape.watch([sample_seq_1, sample_seq_2])
    similarity_value_pred = siamese_net_model([sample_seq_1, sample_seq_2])[0,0]

# getting gradients
tape.gradient(similarity_value_pred, [sample_seq_1, sample_seq_1])
```

"
46401,DataFrameIterator is not exported,"https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/keras/preprocessing/image.py#L464

The `DataFrameIterator` class is not exported, so it can't be extended from outside the framework."
46400,Installation of OpenCL backend Tensorflow Lite runtime package,"**System information**
- OS Platform and Distribution: Ubuntu 18.04 aarch64
- Mobile device:  RK3399 with Mali T860 GPU
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.4.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?:  virtualenv
- GCC/Compiler version (if compiling from source): gcc 7.5
- CUDA/cuDNN version: None
- GPU model and memory: Mali T860

**Describe the problem**

I am going to install OpenCL backend TensorFlow Lite runtime for Python on RK3399 Ubuntu 18.04 aarch64 platform.
I looked at the document and blogs but could NOT find any method to install OpenCL backend TensorFlow Lite runtime for Python.
I think that OpenCL backend TensorflowLite for Python should be installed from the source.
If so, how should it be built and installed?
Could u provide a proper method asap?
Thanks
"
46396,Converting Tensorflow to TFLite error,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, EXP, LEAKY_RELU, LOGISTIC, MAX_POOL_2D, MUL, PAD, RESHAPE, RESIZE_BILINEAR, SPLIT_V, STRIDED_SLICE, TANH. Here is a list of operators for which you will need custom implementations: Softplus.
```

**Standalone code to reproduce the issue** 
import tensorflow as tf
from absl import app, flags, logging
from absl.flags import FLAGS
import numpy as np
import cv2
from core.yolov4 import YOLOv4, YOLOv3, YOLOv3_tiny, decode
import core.utils as utils
import os
from core.config import cfg

flags.DEFINE_string('weights', './checkpoints/yolov4-416', 'path to weights file')
flags.DEFINE_string('output', './checkpoints/yolov4-416-fp32.tflite', 'path to output')
flags.DEFINE_integer('input_size', 416, 'path to output')
flags.DEFINE_string('quantize_mode', 'float32', 'quantize mode (int8, float16, float32)')
flags.DEFINE_string('dataset', ""/Volumes/Elements/data/coco_dataset/coco/5k.txt"", 'path to dataset')

def representative_data_gen():
  fimage = open(FLAGS.dataset).read().split()
  for input_value in range(10):
    if os.path.exists(fimage[input_value]):
      original_image=cv2.imread(fimage[input_value])
      original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
      image_data = utils.image_preprocess(np.copy(original_image), [FLAGS.input_size, FLAGS.input_size])
      img_in = image_data[np.newaxis, ...].astype(np.float32)
      print(""calibration image {}"".format(fimage[input_value]))
      yield [img_in]
    else:
      continue

def save_tflite():
  converter = tf.lite.TFLiteConverter.from_saved_model(FLAGS.weights)

  if FLAGS.quantize_mode == 'float16':
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_types = [tf.compat.v1.lite.constants.FLOAT16]
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
    converter.allow_custom_ops = True
  elif FLAGS.quantize_mode == 'int8':
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
    converter.allow_custom_ops = True
    converter.representative_dataset = representative_data_gen

  tflite_model = converter.convert()
  open(FLAGS.output, 'wb').write(tflite_model)

  logging.info(""model saved to: {}"".format(FLAGS.output))

def demo():
  interpreter = tf.lite.Interpreter(model_path=FLAGS.output)
  interpreter.allocate_tensors()
  logging.info('tflite model loaded')

  input_details = interpreter.get_input_details()
  print(input_details)
  output_details = interpreter.get_output_details()
  print(output_details)

  input_shape = input_details[0]['shape']

  input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)

  interpreter.set_tensor(input_details[0]['index'], input_data)
  interpreter.invoke()
  output_data = [interpreter.get_tensor(output_details[i]['index']) for i in range(len(output_details))]

  print(output_data)

def main(_argv):
  save_tflite()
  demo()

if __name__ == '__main__':
    try:
        app.run(main)
    except SystemExit:
        pass




**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
46395,YOLOv4 not completely quantized -> Edge TPU compilation fails,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (or github SHA if from source): tf-nightly


**Command used to run the converter or code if youâre using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
import numpy as np

def representative_dataset_gen():
	i = 1
	for image in range(100):
		image = np.random.random((1, 416, 416, 3)).astype('float32')
		print(i, image.shape)
		i += 1
		yield [image]

converter = tf.lite.TFLiteConverter.from_saved_model('/content/drive/MyDrive/YOLO/saved_model')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
converter._experimental_new_quantizer = True
converter.allow_custom_ops = True
converter.representative_dataset = representative_dataset_gen
tflite_quant_model = converter.convert()
with open('/content/drive/MyDrive/YOLO/saved_model/yolov4_full_integer_quant.tflite', 'wb') as w:
	w.write(tflite_quant_model)
print(""Full Integer Quantization complete! - yolov4_full_integer_quant.tflite"")
```

**The output from the converter invocation**

```
There is no issue here
```

**Also, please include a link to the saved model or GraphDef**

The link contains the Saved_Model and the quantized TFLite model.
https://drive.google.com/drive/folders/1m4KOjdWHmtBpHPau8Oxu7bC5efkdCRy_?usp=sharing

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Despite using the target spec BUILTINS_INT8, the model is not quantized completely (exp and log operations)
- This then causes an issue when using the EdgeTPU compiler, with an error
```
Edge TPU Compiler version 15.0.340273435
Invalid model: /content/drive/MyDrive/Clutterbot/YOLO/saved_model/yolov4_full_integer_quant.tflite
Model not quantized
```

@abattery @jingpu Can you please help me out here? I thought Exp and Log operations were common enough to have been quantized, or am I missing something here?
"
46394,ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list).,"Im getting this valueError in colab gpu env with keras tensorflow ver 2.
ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list). on running the following code :

def ctc_lambda_func(args):
    y_pred, labels, input_length, label_length = args
    # the 2 is critical here since the first couple outputs of the RNN
    # tend to be garbage:
    # print ""y_pred_shape: "", y_pred.shape
    y_pred = y_pred[:, 2:, :]
    # print ""y_pred_shape: "", y_pred.shape
    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)

# ---- CTC ----
    
labels = Input(name='the_labels', shape=[None], dtype=dtype)       # transcription data (batch_size * y_seq_size)
input_length = Input(name='input_length', shape=X_train_length.shape, dtype=dtype)  # unpadded len of all x_sequences in batch
label_length = Input(name='label_length', shape=label_length.shape, dtype=dtype)  # unpadded len of all y_sequences in batch


# Lambda layer with ctc_loss function due to Keras not supporting CTC layers
loss_out = Lambda(function=ctc_lambda_func, name='ctc', output_shape=(1,))([y_pred, np.float32, Y_train, np.float32, X_train_length, np.float32, label_length, np.float32])
network_model = Model(inputs=[input_data, labels, input_length, label_length], outputs=y_pred)    


"
46393,Checksum error with GCC download,"@tensorflow/micro

**Short description**

```
tensorflow/lite/micro/tools/make/targets/apollo3evb_makefile.inc:14: *** Something went wrong with the GCC download: Bad checksum. Expected: bc8ae26d7c429f30d583a605a4bcf9bc, Got: e588d21be5a0cc9caa60938d2422b058.  Stop.
```

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina
- TensorFlow installed from (source or binary): n/a
- Tensorflow version (commit SHA if source): latest from git clone b860885da901ed641015bc75b9ac06fc4a1c5a57
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): SparkFun_edge

**Reproduction instructions**

```
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge hello_world_bin
```

**Describe the problem**

**Please provide the exact sequence of commands/steps when you ran into the problem**

"
46392,Training loss not decreasing if both mixed-precision and XLA/JIT is enabled (with deep model),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- Linux Ubuntu 18.04:
- TensorFlow installed from binary
- TensorFlow 2.4.0
- Python 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA 11/cuDNN 8:
- GPU model and memory Titan RTX/2080Ti:

**Describe the current behavior**

Training a deep model, e.g., ResNet50, with both mixed-precision and XLA/JIT simultaneously enabled results in the training loss not decreasing.
Mixed-precision alone or XLA/JIT with float32 works both fine.

**Describe the expected behavior**

Enabling XLA/JIT and mixed-precision training should behave the same as if only mixed-precision is enabled.

**Standalone code to reproduce the issue**
[Minimal Colab notebook to reproduce issue](https://colab.research.google.com/drive/1FLRd52ZejrD-jSc3fHVYrK4L-QE-73JA?usp=sharing)

**Notes**
Note that this bug does not occur for small models like the ConvNet in the mixed-precision training guide.
Also, the fact that training with mixed-precision alone works fine might point to where there could be an issue here."
46391,merge,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
46390,Support for LSTM and GRU ,"Hello,

I wonder if there is support for LSTM and GRU within TensorFlow Lite for Microcontrollers (audio NN models) or any plan to have these operations? 

Thank you.

Best regards,
Peter"
46389,Support for LSTM and GRU,"Hello,

I wonder if there is support for LSTM and GRU within TensorFlow Lite for Microcontrollers (audio NN models) or any plan to have these operations? 

Thank you.

Best regards,
Peter"
46388,Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors,"**Description**

We converted the Matterpot Mask RCNN object detection model (using hdf5 weight file) into tflite format using tensorflow (version 2.3.0).  We are able to get the prediction in android using the version 'org.tensorflow:tensorflow-lite:2.4.0'. Inference time in android devices takes around 40 seconds using CPU (kirin 655 ). So we aiming to use the GPU support to improve inference time for our model in Android devices but the following error is raised 
`Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors`. 
We tried using batch size as 1 but the same error is raised.

We have included below link where we have shared `H5 format model, converted tflite model and text file containing keras model summary`
LINK : https://drive.google.com/drive/folders/1nTzifGDX7wXxYNXnHFw4a3Sz0p0_GdBe?usp=sharing

Is there tflite GPU support for graph with dynamic sized tensors or how can we mitigate this issue?

**We have included two images of graph visualized using graphviz**
"
46387,TF2.4 ParameterServerStrategy tf.range in step_fn is slower than np.arange,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**TF on yarn**(running machine system is CentOS 7)
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):2.4.0
- Python version:3.6
- CUDA/cuDNN version: no gpu
- GPU model and memory: no gpu
- CPU info: please see it below
- Training config: chief:  8cpus,25G memory; worker: 30 instances, 8 cpus per instance, 25G memory per instance;ps: 8 instances, 12 cpus per instance, 25G memory per instance

**Describe the current behavior**

I built a model using ParameterServerStrategy, and I used tf.range(steps_per_invocation) in step_fn to execute more steps. But I found there was a about 0.4 second between one loop end and next loop start, but when I changed to np.arnage(steps_per_invocation), the gap can be ignored.This is very similar to https://github.com/tensorflow/tensorflow/issues/40708.

```python
@tf.function
def train_fn(iterator):
    print(""Flag_A_retrace!!!"", time.time())
    tf.print(""Flag_A"", tf.timestamp())
    losses = 0.0
    for inner_index in tf.range(FLAGS.steps_per_invocation):
        tf.print(""Flag_G"", tf.timestamp(), inner_index)
        parsed_feature_dict, label_dict, weight_dict = next(iterator)
        tf.print(""Flag_H"", tf.timestamp(), inner_index)
        replica_fn = train_step(model, metrics, optimizer)
        tf.print(""Flag_I"", tf.timestamp(), inner_index)
        losses = strategy.run(replica_fn, args=(parsed_feature_dict, label_dict, weight_dict)) # we just need last loss
        tf.print(""Flag_J"", tf.timestamp(), inner_index)
    tf.print(""Flag_B"", tf.timestamp())
    return strategy.reduce(tf.distribute.ReduceOp.SUM, losses, axis=None)
```

The time between Flag_J and next Flag_G is 0.4 second

```python
@tf.function
def train_fn(iterator):
    print(""Flag_A_retrace!!!"", time.time())
    tf.print(""Flag_A"", tf.timestamp())
    losses = 0.0
    for inner_index in np.arange(FLAGS.steps_per_invocation):
        tf.print(""Flag_G"", tf.timestamp(), inner_index)
        parsed_feature_dict, label_dict, weight_dict = next(iterator)
        tf.print(""Flag_H"", tf.timestamp(), inner_index)
        replica_fn = train_step(model, metrics, optimizer)
        tf.print(""Flag_I"", tf.timestamp(), inner_index)
        losses = strategy.run(replica_fn, args=(parsed_feature_dict, label_dict, weight_dict)) # we just need last loss
        tf.print(""Flag_J"", tf.timestamp(), inner_index)
    tf.print(""Flag_B"", tf.timestamp())
    return strategy.reduce(tf.distribute.ReduceOp.SUM, losses, axis=None)
```
The time between Flag_J and next Flag_G can be ignored.

**Describe the expected behavior**
1.  tf.range performance should be the same as np.arange
2. 0.4 second in just one step is very slow because it accouts for abount 94% of one step execute time.


"
46386,Tensorflow Lite Build issue on RK3399 Ubuntu 18.04 aarch64,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04 aarch64
- TensorFlow installed from (source or binary):  source
- Tensorflow version (commit SHA if source):  098231f
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):  RK3399 Ubuntu 18.04 aarch64

**Describe the problem**
I was going to build the tensorflow lite with CMake on RK3399 Ubuntu 18.04 aarch64 device.

OS: Ubuntu 18.04 aarch64
CMake: 3.18.0
gcc(g++): 10.1.0
GPU: Mali T860
OpenCL: 1.2

I cloned the TensorFlow and was going to build tflite supporting ARM GPU (OpenCL) with CMake.

_git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
mkdir tflite_build
cd tflite_build
cmake ../tensorflow/lite -DTFLITE_ENABLE_GPU=ON_

The configuration was successful.
I started to build the command ""cmake --build . -j"" but I met the following error.

![image](https://user-images.githubusercontent.com/47862419/104396628-00109f00-5586-11eb-9fcb-0f57eee17347.png)


Could u please let me know how to fix it?
Thanks

"
46385,Wrong warning when a saved model (from TF2.4) is loaded using tf-nightly ,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): TF2.4, tf-nightly
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the current behavior**
Using TF2.4, a Keras model was saved using `model.save`.  Later, when I tried to load the saved model using  `tf-nightly`, code throws unexpected error as shown below.

```
2.5.0-dev20210112
WARNING:tensorflow:SavedModel saved prior to TF 2.4 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named ""keras_metadata.pb"" in the SavedModel directory.
WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.
```
 


**Describe the expected behavior**

The following warning should be revised as the initial model was saved using `TF 2.4` but warning complains that the model was saved prior to TF 2.4.

`WARNING:tensorflow:SavedModel saved prior to TF 2.4 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named ""keras_metadata.pb"" in the SavedModel directory.`

The above warning was noticed only when the model was saved in `tf` format. The above warning doesn't appear when the model was saved in `h5` format.

**Standalone code to reproduce the issue**

Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/e3ec0d7b92034affc4b7644a89dc7ebc/untitled483.ipynb).



**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
This issue was originally opened earlier [here](https://github.com/tensorflow/tensorflow/issues/45288) "
46384,"tensorflow 2.4.0  the predict function outputs an error, when the same code works on another TF versions. ","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform : Windows 10
- TensorFlow installed from ): 2.4.0, using instal_tensorflow(version = ""2.4.0"" )
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.0 / 8.0.2
- GPU model and memory: RTX 3070




**Describe the current behavior**
I can run this code https://blogs.rstudio.com/ai/posts/2019-08-23-unet/ on the kaggles notebook (which runs TF 2.3.0),
but on my PC, intel + nvidia 3070, TF 2.4, the code can run and train.  BUT the PREDICT function doesnt work. 
The exact same code the predict function works as expected on Kaggles


**Describe the expected behavior**
The predicitions functions results in predictions, not errors

**Standalone code to reproduce the issue**
https://www.kaggle.com/rpsantosakaggle/unet-carvana

**Other info / logs** 
 predictions <- predict(model, batch)
Error in py_call_impl(callable, dots$args, dots$keywords) : 
  ValueError: in user code:

    C:\Users\rpsan\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\keras\engine\training.py:1478 predict_function  *
        return step_function(self, iterator)
    C:\Users\rpsan\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\keras\engine\training.py:1468 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    C:\Users\rpsan\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    C:\Users\rpsan\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    C:\Users\rpsan\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:3417 _call_for_each_re





*have run many other codes that worked seamlesly, but with this one, it bugs. 
 tf_config()
TensorFlow v2.4.0 ()
Python v3.6 (C:/Users/rpsan/AppData/Local/r-miniconda/envs/r-reticulate/python.exe)"
46380,Add support for converting mixed_float16 models to TF_lite,"**System information**
- Windows 10
- tensorflow==2.4.0 installed via pip

**Project details:**
* [notebook](https://captaindario.github.io/DaKanjiRecognizer-ML/DaKanjiRecognizer.html)
* [github repository](https://github.com/CaptainDario/DaKanjiRecognizer-ML)

**Command used to run the converter or code if youâre using the Python API**

```
# Convert the model
converter = tf.lite.TFLiteConverter.from_saved_model(tf_models_dir) # path to the SavedModel directory
tflite_model = converter.convert()

# Save the model.
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
```

**The output from the converter invocation**

```
---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
E:\projects\DaKanjiRecognizer\.venv_dev\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    209     try:
--> 210       model_str = wrap_toco.wrapped_toco_convert(model_flags_str,
    211                                                  toco_flags_str, input_data_str,

E:\projects\DaKanjiRecognizer\.venv_dev\lib\site-packages\tensorflow\lite\python\wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
     31   """"""Wraps TocoConvert with lazy loader.""""""
---> 32   return _pywrap_toco_api.TocoConvert(
     33       model_flags_str,

Exception: <unknown>:0: error: loc(callsite(callsite(""DaKanjiRecognizer/conv2D_1_input/Conv2D@__inference__wrapped_model_1048891"" at ""StatefulPartitionedCall@__inference_signature_wrapper_1049439"") at ""StatefulPartitionedCall"")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x64x64x1xf16>'
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: error: loc(callsite(callsite(""DaKanjiRecognizer/conv2D_2/Conv2D@__inference__wrapped_model_1048891"" at ""StatefulPartitionedCall@__inference_signature_wrapper_1049439"") at ""StatefulPartitionedCall"")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x31x31x32xf16>'
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: error: loc(callsite(callsite(""DaKanjiRecognizer/conv2D_3/Conv2D@__inference__wrapped_model_1048891"" at ""StatefulPartitionedCall@__inference_signature_wrapper_1049439"") at ""StatefulPartitionedCall"")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x14x14x32xf16>'
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: error: loc(callsite(callsite(""DaKanjiRecognizer/conv2D_4/Conv2D@__inference__wrapped_model_1048891"" at ""StatefulPartitionedCall@__inference_signature_wrapper_1049439"") at ""StatefulPartitionedCall"")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x6x6x64xf16>'
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from


During handling of the above exception, another exception occurred:

ConverterError                            Traceback (most recent call last)
<ipython-input-15-758d3ba4bcca> in <module>
      7 # Convert the model
      8 converter = tf.lite.TFLiteConverter.from_saved_model(tf_models_dir)
----> 9 tflite_model = converter.convert()
     10 
     11 # Save the model.

E:\projects\DaKanjiRecognizer\.venv_dev\lib\site-packages\tensorflow\lite\python\lite.py in convert(self)
    737     converter_kwargs.update(quant_mode.converter_flags())
    738 
--> 739     result = _convert_saved_model(**converter_kwargs)
    740     calibrate_and_quantize, flags = quant_mode.quantizer_flags()
    741     if calibrate_and_quantize:

E:\projects\DaKanjiRecognizer\.venv_dev\lib\site-packages\tensorflow\lite\python\convert.py in convert_saved_model(saved_model_dir, saved_model_version, saved_model_tags, saved_model_exported_names, **kwargs)
    630     model_flags.saved_model_exported_names.extend(saved_model_exported_names)
    631   toco_flags = build_toco_flags(**kwargs)
--> 632   data = toco_convert_protos(
    633       model_flags.SerializeToString(),
    634       toco_flags.SerializeToString(),

E:\projects\DaKanjiRecognizer\.venv_dev\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    214       return model_str
    215     except Exception as e:
--> 216       raise ConverterError(str(e))
    217 
    218   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:

ConverterError: <unknown>:0: error: loc(callsite(callsite(""DaKanjiRecognizer/conv2D_1_input/Conv2D@__inference__wrapped_model_1048891"" at ""StatefulPartitionedCall@__inference_signature_wrapper_1049439"") at ""StatefulPartitionedCall"")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x64x64x1xf16>'
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: error: loc(callsite(callsite(""DaKanjiRecognizer/conv2D_2/Conv2D@__inference__wrapped_model_1048891"" at ""StatefulPartitionedCall@__inference_signature_wrapper_1049439"") at ""StatefulPartitionedCall"")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x31x31x32xf16>'
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: error: loc(callsite(callsite(""DaKanjiRecognizer/conv2D_3/Conv2D@__inference__wrapped_model_1048891"" at ""StatefulPartitionedCall@__inference_signature_wrapper_1049439"") at ""StatefulPartitionedCall"")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x14x14x32xf16>'
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: error: loc(callsite(callsite(""DaKanjiRecognizer/conv2D_4/Conv2D@__inference__wrapped_model_1048891"" at ""StatefulPartitionedCall@__inference_signature_wrapper_1049439"") at ""StatefulPartitionedCall"")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x6x6x64xf16>'
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from



```

**Also, please include a link to the saved model or GraphDef**
There is no TF lite mixed precision model but [here is a model trained with default precision](https://github.com/CaptainDario/DaKanjiRecognizer/tree/main/data).


**Any other info / logs**

When I train the model using ```mixed_float16``` set with:
```
physical_devices = tf.config.list_physical_devices('GPU') 
tf.config.experimental.set_memory_growth(physical_devices[0], True)

from tensorflow.keras.mixed_precision import experimental as mixed_precision
policy = mixed_precision.Policy('float32')
#policy = mixed_precision.Policy('mixed_float16')      # <-- uncomment this
mixed_precision.set_policy(policy)
```
the converter crashes. As stated [here](https://www.tensorflow.org/lite/guide/ops_compatibility) (if I understand correctly) there is currently no support for this scenario. <br/>
If this is not planned to be implemented, are there any workarounds to still use float16 on supported GPUs. So one can still speed up training and is able to train larger models."
46379,Model Subclassing 'NoneType' object has no attribute 'shape',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
class MyVGG(tf.keras.Model):
   I don't understand why is the problem please help!
 
    def __init__(self, num_classes):
        super(MyVGG, self).__init__()
        
        #self.input_l = tf.keras.layers.Conv2D(filters=64,kernel_size=3, activation='relu', input_shape=(150,150,3))
        #create blocks of Vgg 
        self.block_a = Block(filters=64 ,  kernel_size=3, repetitions= 2) 
        self.block_b = Block(filters=128 , kernel_size=3 , repetitions= 2) 
        self.block_c = Block(filters=256 , kernel_size=3, repetitions= 3) 
        self.block_d = Block(filters=512 , kernel_size=3 , repetitions= 3) 
        self.block_e = Block(filters=512 , kernel_size=3 , repetitions= 3) 
        
        # Define a Flatten layer
        self.flatten = tf.keras.layers.Flatten()
        # Define a Dense Layer 
        self.dense = tf.keras.layers.Dense(256, activation='relu')
        # Add  the softmax classifier using a Dense layer
        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')
    
    def call(self, inputs):
    
        #x = self.input_l(inputs)
        #Chain all the layers 
        x = self.block_a(inputs) 
        x = self.block_b(x) 
        x = self.block_c(x) 
        x = self.block_d(x) 
        x = self.block_e(x) 
        x = self.flatten(x) 
        x = self.dense(x) 
        x = self.classifier(x) 
        return x
model_vgg = MyVGG(num_classes=2)

model_vgg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history = model_vgg.fit_generator(train_generator, 
                                  epochs=10, 
                                  verbose=1, 
                                  validation_data = validation_generator)


**Describe the expected behavior**

**Standalone code to reproduce the issue**
/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in _maybe_build(self, inputs)
   2616     if not self.built:
   2617       input_spec.assert_input_compatibility(
-> 2618           self.input_spec, inputs, self.name)
   2619       input_list = nest.flatten(inputs)
   2620       if input_list and self._dtype_policy.compute_dtype is None:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py in assert_input_compatibility(input_spec, inputs, layer_name)
    164         spec.min_ndim is not None or
    165         spec.max_ndim is not None):
--> 166       if x.shape.ndims is None:
    167         raise ValueError('Input ' + str(input_index) + ' of layer ' +
    168                          layer_name + ' is incompatible with the layer: '

AttributeError: 'NoneType' object has no attribute 'shape'

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46377,Problem with pypi package installation in linux debian(parrot os),"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Parrot Os 4.10 64bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):pypi
- TensorFlow version:
- Python version:3.9.1
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
When i run the following commands either with pip3 or just pip basically, i run into an issue like :
`ERROR: Could not find a version that satisfies the requirement tensorflow
ERROR: No matching distribution found for tensorflow
`
I even read the article from this website
[https://tutorialforlinux.com/2020/10/02/step-by-step-tensorflow-parrot-linux-installation-guide/](tutorialforlinux)
I have run the various commands yet to no avail
**Provide the exact sequence of commands / steps that you executed before running into the problem**
pip install tensorflow
pip install tensorflow-cpu
pip install tf-nightly
pip install tf-nightly-gpu

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
46373,"Failure to train distributed with strategy mirrored, custom training, functions supplied in class","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian Buster with ROCm 3.7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tensorflow-rocm 2.3.0 -  v2.3.0-rc1-2358-gc0826c7973 2.3.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: Radeon VII

**Describe the current behavior**

Training works on single GPU, fails on dual GPU

**Describe the expected behavior**

Should also work on dual GPU

**Standalone code to reproduce the issue**

I'm trying to run YOLOV3 tensorflow from https://github.com/ethanyanjiali/deep-vision.git with VOC_2007 data set

**Other info / logs**

I compared the code to example code for MirroredStrategy and could not find any ad hoc visible mistake. Only major difference is that the training is realized in a separate trainer class.

By running in standard eager execution I get the following error output: [log.txt](https://github.com/tensorflow/tensorflow/files/5804098/log.txt)

When switching off eager execution I get the following output (which might indicate the problem, if the change from eager to non-eager does not create systematic difference): [log_no_eager.txt](https://github.com/tensorflow/tensorflow/files/5804099/log_no_eager.txt)

I moved the generation of the optimizer into the mirrored strategy scope in main and passed it as parameter to the constructor of the trainer class, but that did not solve the problem.

The error message seems similar to [that issue](https://github.com/tensorflow/tensorflow/issues/41768), but there was no reproducible solution mentioned. 

"
46371,Exporting a TF Estimator with a `hub.text_embedding_column_v2` does not include the pretrained model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): AI Platform runtime 2.3 or Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

This issue has been observed with the estimator API only, not Keras. I'm not entirely sure if it's a problem with estimator, export, or a tf hub issue.

**Describe the current behavior**

When exporting a TF Estimator which uses a `hub.text_embedding_column_v2` (the new version of tf-hub's `text_embedding_column_v2` that supports pretrained models in TF 2 SavedModel format), the export directory does not include the pretrained model asset files. Instead, the model seems to reference the local path the model was trained with.
When `text_embedding_column_v2` is fed with a url (i.e. `tfhub.dev/../my-model`), the model references the cached local path.

When the local path doesn't exist anymore, or when using the exported model in a different machine altogether, calling `tf.saved_model.load` fails with a `FileNotFound` exception:

When defining the embedding column with a local path to the pretrained model:
```
 ...
 hub.text_embedding_column_v2('/home/.../my-local-model')
 ...
 estimator = ...
 ...
 tf.estimator.export_saved_model(...)

...
 # on another machine or when removing /home/.../my-local-model:
...
tf.saved_model.load(...)

NotFoundError:  /content/local_nnlm50_2/assets/tokens.txt; No such file or directory
	 [[{{node dnn/input_from_feature_columns/input_layer/text_feature0_hub_module_embedding/StatefulPartitionedCall_1/StatefulPartitionedCall/text_file_init/InitializeTableFromTextFileV2}}]] [Op:__inference_pruned_10883]
```

When defining the embedding column with a cached pretrained model from a `tfhub.dev` url (not reproducible in Colab since tf hub cache doesn't kick in there):
```
 ...
 hub.text_embedding_column_v2('https://tfhub.dev/google/nnlm-en-dim50/2')
 ...
 estimator = ...
 ...
 tf.estimator.export_saved_model(...)

...
 # on another machine or when removing cache dir /tmp/tfhub_modules:
...
tf.saved_model.load(...)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.NotFoundError:  /tmp/tfhub_modules/74a841d6eb84e8d93d913d716fb5440d020cc291/assets/tokens.txt; No such file or directory
         [[{{node dnn/input_from_feature_columns/input_layer/topClickQuery_1st_hub_module_embedding/StatefulPartitionedCall_1/StatefulPartitionedCall/text_file_init/InitializeTableFromTextFileV2}}]] [Op:__inference_pruned_1658]
```

**Describe the expected behavior**

The expected behavior is for the export directory to include the pretrained model's assets, like it does when using `hub.text_embedding_column` (v1) with TF 1 format modules. And more importantly: loading the exported estimators should not fail even when loaded in a different machine, as well as not when the original local path to the pretrained model doesn't exist anymore.
The entire exported estimator should be contained within the export directory. 

**Standalone code to reproduce the issue**
Here's a Colab replicating the issue:
https://colab.research.google.com/drive/1Tr5M0m_EVRd5sFdgDX-EbVsk47UokPxD?usp=sharing

Overview of Colab:
- Download both versions of nnlm50 to local (TF 1 module, TF 2 SavedModel)
- Define two estimators: one with `text_embedding_column` (v1) and the local TF 1 format pretrained model, and the other with `text_embedding_column_v2` and the local TF 2 format pretrained model
- Train and export the estimators to SavedModels
- Print contents of export dir: **TF 1 format has the nnlm50 assets, TF 2 format does not**
- Try to load both estimators from disk: **success**
- Delete both local nnlm50 directories used for training the estimators
- Try to load the v1 estimator from disk again: **success**
- Try to load the v2 estimator from disk again: **fails**

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
46367,MultiWorkerMirroredStrategy documents old communication=tf.distribute.experimental.CollectiveCommunication.NCCL,"## URL(s) with the issue:

https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras

## Description of issue (what needs changing):

The page says
> To override the automatic choice, specify a valid value to the communication parameter of MultiWorkerMirroredStrategy's constructor, e.g. communication=tf.distribute.experimental.CollectiveCommunication.NCCL.

However `MultiWorkerMirroredStrategy`s ctor has changed to expect a `communication_options` parameter instead.

It should be described on this page how to actually change the distribution implementation with current TF 2.4

Note that the deprecated `tf.distribute.experimental.MultiWorkerMirroredStrategy()` still has that parameter but TF warns about usage of this class and the tutorial page doesn't mention that (old) class."
46366,LayerNormalization crashes on empty inputs when run on CPU,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from: binary
- TensorFlow version: 2.4.0
- Python version: 3.6.9

**Describe the current behavior**

`tf.keras.layers.LayerNormalization` crashes when the input is empty and the layer is executed on CPU.

**Describe the expected behavior**

The layer should not crash but return a tensor with the same shape.

**Standalone code to reproduce the issue**

```python
import os
os.environ[""CUDA_VISIBLE_DEVICES""] = """"
import tensorflow as tf
layer = tf.keras.layers.LayerNormalization()
layer(tf.zeros([1, 0, 10]))
```

**Other info / logs**

The code above exits with this error:

```text
Floating point exception (core dumped)
```
"
46365,micro_speech example: FeatureProvider tries to read audio data that is in the future,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): -
- TensorFlow installed from (source or binary): source / Arduino library
- Tensorflow version (commit SHA if source): -
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Arduino Nano 33

**Describe the problem**

The audio capture subsystem keeps track of the latest audio capture time. This is the `time_in_ms` passed into `PopulateFeatureData()` from micro_speech/feature_provider.cc. `PopulateFeatureData` will then work backwards from this timestamp to fetch audio data for any slices that it hasn't cached yet.

I believe the code should be as follows: https://github.com/hollance/tensorflow/commit/9fe6428a70ebb78fb471c5ddf8ff3d6fb7f8b14d

Reason: `current_step` is the index of the last slice that will be read. Since each slice is 30ms in length, we must subtract that from the timestamp, otherwise the last slice will go (partially) out of bounds and we will read stale data from the audio capture ring buffer.

For example, if the `time_in_ms` is 2010 (this the point in time *up to* which audio has been captured), the current code will set `current_step` to 2010 / 20 = 100. In the loop that computes new slices, this step value is multiplied again by 20 to create `slice_start_ms`, which becomes 2000. Then we read 30ms worth of audio starting from `slice_start_ms`. But we don't have 30ms worth of audio left in the capture buffer, only 10. The current implementation will try to read 20ms into the future, which is really old data from roughly 0.5 seconds ago.

Apparently making this change will cause `feature_provider_mock_test` to fail. I haven't looked into this in detail yet but I'm a little suspicious at the provided duration of 970ms. The correct duration for a 49x40 spectrogram is 990ms (or really anything between 990 and 1009ms, but those extra ms aren't used because they don't fill up a full window). I suspect the reason 970 was used here is that the sample is actually 1000ms and 30ms was (mistakenly) subtracted to work around the bug in feature_provider.cc.
"
46363,Kernel Silently dies while Generating an Image,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.5.0-dev20210111
- Python version: 3.8.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.1 ,8.0.5
- GPU model and memory: RTX 3070 8GB

**Describe the current behavior**
The Kernel silently dies when it tried to generate the image made via the generator.

**Describe the expected behavior**
Should generate the image and continue the code

**Standalone code to reproduce the issue**
[Using the example here on the Tensorflow site for GANs](https://www.tensorflow.org/tutorials/generative/dcgan)
While executing it till we generate the image via the untrained generator. The notebook just stops, looking at the logs shows that the kernel then gets restarted.

**Other info / logs**
```
[I 2021-01-12 16:02:30.618 ServerApp] Kernel started: 0227f971-d1fe-44a3-8db7-a948217de0bb
2021-01-12 16:02:51.057848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-01-12 16:02:54.205477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2021-01-12 16:02:54.226746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1760] Found device 0 with properties:
pciBusID: 0000:0a:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.77GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2021-01-12 16:02:54.226918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-01-12 16:02:54.258395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-01-12 16:02:54.258550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-01-12 16:02:54.279408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-01-12 16:02:54.284138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-01-12 16:02:54.345037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-01-12 16:02:54.348822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-01-12 16:02:54.350356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-01-12 16:02:54.350512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1902] Adding visible gpu devices: 0
2021-01-12 16:02:57.436724: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-01-12 16:02:57.437783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1760] Found device 0 with properties:
pciBusID: 0000:0a:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.77GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2021-01-12 16:02:57.438036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1902] Adding visible gpu devices: 0
2021-01-12 16:02:57.821516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1300] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-12 16:02:57.821707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1306]      0
2021-01-12 16:02:57.821818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1319] 0:   N
2021-01-12 16:02:57.822077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1446] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5474 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:0a:00.0, compute capability: 8.6)
2021-01-12 16:03:00.249533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-01-12 16:03:00.804621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-01-12 16:03:00.805722: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2021-01-12 16:03:00.810208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-01-12 16:03:01.400017: I tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Loaded cuDNN version 8005
```

The kernel then crashes after this and jupyter restarts it

```
[I 2021-01-12 16:03:39.603 ServerApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 0227f971-d1fe-44a3-8db7-a948217de0bb restarted
kernel 0227f971-d1fe-44a3-8db7-a948217de0bb restarted
[I 2021-01-12 16:03:39.626 ServerApp] Starting buffering for 0227f971-d1fe-44a3-8db7-a948217de0bb:c751d222-0788-4d6b-8fb6-b564f4dd14f5
```"
46362,ModuleNotFoundError: No module named 'tensorflow.core',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Windows 10):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- Installed from whl:  tensorflow_gpu-2.4.0-cp36-cp36m-win_amd64.whl
- TensorFlow version: 2.4.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip within conda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: NVIDIA GeForce RTX 2080 Ti



**Describe the problem**

I have installed the following packages in a conda environment
absl-py                   0.4.1                     <pip>
absl-py                   0.7.1                    py36_0    <unknown>
absl-py                   0.10.0                    <pip>
astunparse                1.6.3                     <pip>
beautifulsoup4            4.9.3                     <pip>
cachetools                4.1.0                     <pip>
certifi                   2018.4.16                py36_0
chardet                   4.0.0                     <pip>
Cython                    0.29.14                   <pip>
flatbuffers               1.12                      <pip>
gast                      0.3.3                     <pip>
google                    3.0.0                     <pip>
google-auth               1.14.1                    <pip>
google-auth-oauthlib      0.4.2                     <pip>
google-pasta              0.2.0                     <pip>
grpcio                    1.32.0                    <pip>
h5py                      2.10.0                    <pip>
idna                      2.10                      <pip>
Keras                     2.4.3                     <pip>
Keras-Preprocessing       1.1.2                     <pip>
Markdown                  3.2.1                     <pip>
numpy                     1.19.2                    <pip>
oauthlib                  3.1.0                     <pip>
opt-einsum                3.3.0                     <pip>
packaging                 20.8                      <pip>
pip                       10.0.1                   py36_0
pkgconfig                 1.5.1                     <pip>
protobuf                  3.14.0                    <pip>
pyasn1                    0.4.5                      py_0    <unknown>
pyasn1                    0.4.8                     <pip>
pyasn1-modules            0.2.8                     <pip>
pyparsing                 2.4.7                     <pip>
python                    3.6.5                h0c2934d_0
PyYAML                    5.3                       <pip>
requests                  2.25.1                    <pip>
requests-oauthlib         1.3.0                     <pip>
rsa                       4.0                       <pip>
scipy                     1.5.2                     <pip>
setuptools                39.1.0                   py36_0
setuptools                46.2.0                    <pip>
six                       1.15.0                    <pip>
soupsieve                 2.1                       <pip>
tensorboard               2.4.0                     <pip>
tensorboard-plugin-wit    1.7.0                     <pip>
tensorflow-estimator      2.4.0                     <pip>
tensorflow-gpu            2.4.0                     <pip>
termcolor                 1.1.0                     <pip>
typing-extensions         3.7.4.1                   <pip>
urllib3                   1.26.2                    <pip>
vc                        14                   h0510ff6_3
vs2015_runtime            14.0.25123                    3
Werkzeug                  1.0.1                     <pip>
wheel                     0.35.0                    <pip>
wheel                     0.31.1                   py36_0
wincertstore              0.2              py36h7fe50ca_0
wrapt                     1.12.1                    <pip>

I am working within a firewall so packages are installed painstakingly one by one. It takes days to get it right

Running python code
import numpy as np
import tensorflow as tf
import google
import datetime
from tensorflow import keras
import os
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization

(Running from command line)

I get:

 c:\Users\mosheho\NLP>python Keras_embeddings.py
2021-01-12 14:24:20.125275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
Traceback (most recent call last):
  File ""Keras_embeddings.py"", line 51, in <module>
    from tensorflow import keras
  File ""C:\Users\mosheho\AppData\Local\Continuum\anaconda3\envs\tensorflow2_test\lib\site-packages\tensorflow\keras\__init__.py"", line 14, in <module>
    from . import activations
  File ""C:\Users\mosheho\AppData\Local\Continuum\anaconda3\envs\tensorflow2_test\lib\site-packages\tensorflow\keras\activations\__init__.py"", line 10, in <module>
    from tensorflow.python.keras.activations import deserialize
  File ""C:\Users\mosheho\AppData\Local\Continuum\anaconda3\envs\tensorflow2_test\lib\site-packages\tensorflow\python\__init__.py"", line 41, in <module>
    from tensorflow.python.eager import context
  File ""C:\Users\mosheho\AppData\Local\Continuum\anaconda3\envs\tensorflow2_test\lib\site-packages\tensorflow\python\eager\context.py"", line 32, in <module>
    from tensorflow.core.framework import function_pb2
ModuleNotFoundError: No module named 'tensorflow.core'

I do not know where to start. This is in TF 2.4 where most issues have been in TF 1 versions
Thanks

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
46361,custom normalizer_fn in tf.feature_column.numeric_column & tf.Keras Denselayer API results in failure when loading saved model.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes. 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Cloud AI platform notebook
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No.
- TensorFlow installed from (source or binary): Binary. 
- TensorFlow version (use command below): 2.4
- Python version: 3.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Describe the current behavior**
When using the `tf.feature_column.numeric` column api with a custom normalizer function, and passing the feature columns to ``tf.keras`` functional API via ```tf.keras.denselayer``` results in the model unable to be loaded once saved.

This is due to the fact the custom normalizer is not found. 

**Describe the expected behavior**
The model loads as usual. 


**Standalone code to reproduce the issue**
 This [colab]( https://colab.research.google.com/gist/fuhailin/15cc24100e6de025a98688f4927cebac/untitled418.ipynb#scrollTo=YsjNrRf-pG8B) was posted to StackOverflow and illustrates exactly the same problem.

**Other info / logs** 
```python
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-7-865d10c0a905> in <module>
      1 model = load_model(
----> 2     model_directory=""./checkpoint""
      3 )

<ipython-input-6-62298af7498d> in load_model(model_directory)
     10     """"""
     11 
---> 12     model = tf.keras.models.load_model(model_directory, compile=False)
     13 
     14     return model

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile, options)
    210       if isinstance(filepath, six.string_types):
    211         loader_impl.parse_saved_model(filepath)
--> 212         return saved_model_load.load(filepath, compile, options)
    213 
    214   raise IOError(

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in load(path, compile, options)
    136   # Recreate layers and metrics using the info stored in the metadata.
    137   keras_loader = KerasObjectLoader(metadata, object_graph_def)
--> 138   keras_loader.load_layers()
    139 
    140   # Generate a dictionary of all loaded nodes.

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in load_layers(self)
    374       self.loaded_nodes[node_metadata.node_id] = self._load_layer(
    375           node_metadata.node_id, node_metadata.identifier,
--> 376           node_metadata.metadata)
    377 
    378     for node_metadata in metric_list:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _load_layer(self, node_id, identifier, metadata)
    403     # Detect whether this object can be revived from the config. If not, then
    404     # revive from the SavedModel instead.
--> 405     obj, setter = self._revive_from_config(identifier, metadata, node_id)
    406     if obj is None:
    407       obj, setter = revive_custom_object(identifier, metadata)

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _revive_from_config(self, identifier, metadata, node_id)
    421       obj = (
    422           self._revive_graph_network(metadata, node_id) or
--> 423           self._revive_layer_from_config(metadata, node_id))
    424 
    425     if obj is None:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _revive_layer_from_config(self, metadata, node_id)
    481     try:
    482       obj = layers_module.deserialize(
--> 483           generic_utils.serialize_keras_class_and_config(class_name, config))
    484     except ValueError:
    485       if must_restore_from_config:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)
    175       module_objects=LOCAL.ALL_OBJECTS,
    176       custom_objects=custom_objects,
--> 177       printable_module_name='layer')

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    356             custom_objects=dict(
    357                 list(_GLOBAL_CUSTOM_OBJECTS.items()) +
--> 358                 list(custom_objects.items())))
    359       with CustomObjectScope(custom_objects):
    360         return cls.from_config(cls_config)

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/feature_column/base_feature_layer.py in from_config(cls, config, custom_objects)
    139     config_cp = config.copy()
    140     config_cp['feature_columns'] = serialization.deserialize_feature_columns(
--> 141         config['feature_columns'], custom_objects=custom_objects)
    142     config_cp['partitioner'] = generic_utils.deserialize_keras_object(
    143         config['partitioner'], custom_objects)

/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/serialization.py in deserialize_feature_columns(configs, custom_objects)
    184   return [
    185       deserialize_feature_column(c, custom_objects, columns_by_name)
--> 186       for c in configs
    187   ]
    188 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/serialization.py in <listcomp>(.0)
    184   return [
    185       deserialize_feature_column(c, custom_objects, columns_by_name)
--> 186       for c in configs
    187   ]
    188 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/serialization.py in deserialize_feature_column(config, custom_objects, columns_by_name)
    136       cls_config,
    137       custom_objects=custom_objects,
--> 138       columns_by_name=columns_by_name)
    139 
    140   # If the name already exists, re-use the column from columns_by_name,

/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py in from_config(cls, config, custom_objects, columns_by_name)
   2620     kwargs = _standardize_and_copy_config(config)
   2621     kwargs['normalizer_fn'] = serialization._deserialize_keras_object(  # pylint: disable=protected-access
-> 2622         config['normalizer_fn'], custom_objects=custom_objects)
   2623     kwargs['dtype'] = dtypes.as_dtype(config['dtype'])
   2624 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/serialization.py in _deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    271       obj = custom_objects.get(object_name)
    272     else:
--> 273       obj = module_objects.get(object_name)
    274       if obj is None:
    275         raise ValueError(

AttributeError: 'NoneType' object has no attribute 'get'

```

Any pointers how to tackle this? "
46359,tflite custom Bazel build for wasm target ,"I am using tflite in  c++ cross platform library. I plan to build  them with emscripten for wasm. I wish to use the shared libraries (emscripten).  I am new to bazel but i didnt find any custom build for emscripten target in  the repository. 
I can see that xnnpack helps us with building  optimized kernels for  all targets(including wasm). 
Media pipe also claims to use wasm and it supports both tensorflow and tflite but i dont find any emscripten build in their repository as well.

I need flatbuffer &  inference portion of tflite in wasm







"
46357,how to use doc,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
46356,Duplicate classes (com.google.flatbuffers) when flatbuffers is already in project,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android/macOS 11
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version: TF Lite 
- Python version: 2.7.3
- Installed using virtualenv? pip? conda?: -
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -



**Describe the problem**

I tried to include ARCore and Sceneform in the same project to show a 3D model on detected objects. But I can't compile, because Sceneform already includes flatbuffers.


**Provide the exact sequence of commands / steps that you executed before running into the problem**
- Download TF Lite example from https://github.com/tensorflow/examples
- Add Sceneform to project
- Duplicate class errors related to com.google.flatbuffers.


**Any other info / logs**
I found this possibly related issue: https://github.com/tensorflow/tensorflow/issues/33472

Is it now possible on Android to use an external dependency on flatbuffers, or another project like Sceneform that already includes flatbuffers?
"
